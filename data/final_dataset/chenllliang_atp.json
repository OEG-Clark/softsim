{"home.repos.pwc.inspect_result.chenllliang_atp.blink.main_solr.main": [[19, 100], ["print", "blink.read_sentences_from_file", "blink.get_model", "NER.get_model.predict", "blink.get_model", "CG.get_model.process_mentions_for_candidate_generator", "blink.get_model", "R.get_model.rerank", "blink.present_annotated_sentences", "os.path.exists", "os.listdir", "print", "input", "blink.write_dicts_as_json_per_line", "blink.write_dicts_as_json_per_line", "CG.get_model.get_candidates", "blink.write_dicts_as_json_per_line", "blink.write_dicts_as_json_per_line", "blink.write_end2end_pickle_output", "blink.present_annotated_sentences", "input.strip", "print", "shutil.rmtree", "ValueError", "blink.get_sentences_txt_file_path", "blink.get_mentions_txt_file_path", "blink.get_model", "blink.get_mentions_txt_file_path", "blink.get_mentions_txt_file_path", "blink.get_end2end_pretty_output_file_path", "CDF.get_model.get_data_for_entity"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.read_sentences_from_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker.get_model", "home.repos.pwc.inspect_result.chenllliang_atp.blink.ner.Flair.predict", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker.get_model", "home.repos.pwc.inspect_result.chenllliang_atp.blink.candidate_generation.BM45_Candidate_Generator.process_mentions_for_candidate_generator", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker.get_model", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker.rerank", "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.present_annotated_sentences", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.write_dicts_as_json_per_line", "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.write_dicts_as_json_per_line", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Simple_Candidate_Generator.get_candidates", "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.write_dicts_as_json_per_line", "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.write_dicts_as_json_per_line", "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.write_end2end_pickle_output", "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.present_annotated_sentences", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.get_sentences_txt_file_path", "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.get_mentions_txt_file_path", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker.get_model", "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.get_mentions_txt_file_path", "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.get_mentions_txt_file_path", "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.get_end2end_pretty_output_file_path", "home.repos.pwc.inspect_result.chenllliang_atp.blink.candidate_data_fetcher.Wikimedia_Data_Fetcher.get_data_for_entity"], ["def", "main", "(", "parameters", ")", ":", "\n", "    ", "print", "(", "\"Parameters:\"", ",", "parameters", ")", "\n", "# Read data", "\n", "sentences", "=", "utils", ".", "read_sentences_from_file", "(", "\n", "parameters", "[", "\"path_to_input_file\"", "]", ",", "\n", "one_sentence_per_line", "=", "parameters", "[", "\"one_sentence_per_line\"", "]", ",", "\n", ")", "\n", "\n", "# Identify mentions", "\n", "ner_model", "=", "NER", ".", "get_model", "(", "parameters", ")", "\n", "ner_output_data", "=", "ner_model", ".", "predict", "(", "sentences", ")", "\n", "sentences", "=", "ner_output_data", "[", "\"sentences\"", "]", "\n", "mentions", "=", "ner_output_data", "[", "\"mentions\"", "]", "\n", "\n", "output_folder_path", "=", "parameters", "[", "\"output_folder_path\"", "]", "\n", "\n", "if", "(", "\n", "(", "output_folder_path", "is", "not", "None", ")", "\n", "and", "os", ".", "path", ".", "exists", "(", "output_folder_path", ")", "\n", "and", "os", ".", "listdir", "(", "output_folder_path", ")", "\n", ")", ":", "\n", "        ", "print", "(", "\n", "\"The given output directory ({}) already exists and is not empty.\"", ".", "format", "(", "\n", "output_folder_path", "\n", ")", "\n", ")", "\n", "answer", "=", "input", "(", "\"Would you like to empty the existing directory? [Y/N]\\n\"", ")", "\n", "\n", "if", "answer", ".", "strip", "(", ")", "==", "\"Y\"", ":", "\n", "            ", "print", "(", "\"Deleting {}...\"", ".", "format", "(", "output_folder_path", ")", ")", "\n", "shutil", ".", "rmtree", "(", "output_folder_path", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty.\"", ".", "format", "(", "\n", "output_folder_path", "\n", ")", "\n", ")", "\n", "\n", "", "", "if", "output_folder_path", "is", "not", "None", ":", "\n", "        ", "utils", ".", "write_dicts_as_json_per_line", "(", "\n", "sentences", ",", "utils", ".", "get_sentences_txt_file_path", "(", "output_folder_path", ")", "\n", ")", "\n", "utils", ".", "write_dicts_as_json_per_line", "(", "\n", "mentions", ",", "utils", ".", "get_mentions_txt_file_path", "(", "output_folder_path", ")", "\n", ")", "\n", "\n", "# Generate candidates and get the data that describes the candidates", "\n", "", "candidate_generator", "=", "CG", ".", "get_model", "(", "parameters", ")", "\n", "candidate_generator", ".", "process_mentions_for_candidate_generator", "(", "\n", "sentences", "=", "sentences", ",", "mentions", "=", "mentions", "\n", ")", "\n", "\n", "for", "mention", "in", "mentions", ":", "\n", "        ", "mention", "[", "\"candidates\"", "]", "=", "candidate_generator", ".", "get_candidates", "(", "mention", ")", "\n", "if", "parameters", "[", "\"consider_additional_datafetcher\"", "]", ":", "\n", "            ", "data_fetcher", "=", "CDF", ".", "get_model", "(", "parameters", ")", "\n", "for", "candidate", "in", "mention", "[", "\"candidates\"", "]", ":", "\n", "                ", "data_fetcher", ".", "get_data_for_entity", "(", "candidate", ")", "\n", "\n", "", "", "", "if", "output_folder_path", "is", "not", "None", ":", "\n", "        ", "utils", ".", "write_dicts_as_json_per_line", "(", "\n", "mentions", ",", "utils", ".", "get_mentions_txt_file_path", "(", "output_folder_path", ")", "\n", ")", "\n", "\n", "# Reranking", "\n", "", "reranking_model", "=", "R", ".", "get_model", "(", "parameters", ")", "\n", "reranking_model", ".", "rerank", "(", "mentions", ",", "sentences", ")", "\n", "\n", "if", "output_folder_path", "is", "not", "None", ":", "\n", "        ", "utils", ".", "write_dicts_as_json_per_line", "(", "\n", "mentions", ",", "utils", ".", "get_mentions_txt_file_path", "(", "output_folder_path", ")", "\n", ")", "\n", "utils", ".", "write_end2end_pickle_output", "(", "sentences", ",", "mentions", ",", "output_folder_path", ")", "\n", "utils", ".", "present_annotated_sentences", "(", "\n", "sentences", ",", "\n", "mentions", ",", "\n", "utils", ".", "get_end2end_pretty_output_file_path", "(", "output_folder_path", ")", ",", "\n", ")", "\n", "\n", "# Showcase results", "\n", "", "utils", ".", "present_annotated_sentences", "(", "sentences", ",", "mentions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.candidate_generation.Candidate_Generator.__init__": [[20, 22], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "parameters", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.candidate_generation.Candidate_Generator.get_candidates": [[23, 26], ["None"], "methods", ["None"], ["", "def", "get_candidates", "(", "self", ",", "mention_data", ")", ":", "\n", "        ", "\"\"\"Given the mentions from the named entity recognition model, generates candidates for each mention and adds them as an additional field to the mention dictionary\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.candidate_generation.BM45_Candidate_Generator.__init__": [[31, 47], ["pysolr.Solr", "k.strip", "params[].split"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "solr_address", "=", "params", "[", "\"solr_address\"", "]", "\n", "self", ".", "raw_solr_fields", "=", "params", "[", "\"raw_solr_fields\"", "]", "\n", "self", ".", "solr", "=", "pysolr", ".", "Solr", "(", "self", ".", "solr_address", ",", "always_commit", "=", "True", ",", "timeout", "=", "100", ")", "\n", "self", ".", "rows", "=", "params", "[", "\"rows\"", "]", "\n", "self", ".", "query", "=", "params", "[", "\"query\"", "]", "\n", "self", ".", "keys", "=", "[", "k", ".", "strip", "(", ")", "for", "k", "in", "params", "[", "\"keys\"", "]", ".", "split", "(", "\",\"", ")", "]", "\n", "self", ".", "c", "=", "0", "\n", "self", ".", "query_arguments", "=", "{", "\n", "\"fl\"", ":", "\"* score\"", ",", "\n", "\"rows\"", ":", "self", ".", "rows", ",", "\n", "\"defType\"", ":", "\"edismax\"", ",", "\n", "}", "\n", "\n", "if", "params", "[", "\"boosting\"", "]", "is", "not", "None", ":", "\n", "            ", "self", ".", "query_arguments", "[", "\"bf\"", "]", "=", "params", "[", "\"boosting\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.candidate_generation.BM45_Candidate_Generator._filter_result": [[48, 67], ["cand.get", "cand.get", "range", "sents.append", "cand.get"], "methods", ["None"], ["", "", "def", "_filter_result", "(", "self", ",", "cand", ",", "detailed", "=", "True", ")", ":", "\n", "        ", "wikidata_id", "=", "cand", ".", "get", "(", "\"wikidata_id\"", ",", "None", ")", "\n", "res", "=", "{", "\n", "\"wikidata_id\"", ":", "wikidata_id", ",", "\n", "\"wikipedia_id\"", ":", "cand", "[", "\"id\"", "]", ",", "\n", "\"wikipedia_title\"", ":", "cand", "[", "\"title\"", "]", ",", "\n", "}", "\n", "\n", "if", "detailed", ":", "\n", "            ", "res", "[", "\"aliases\"", "]", "=", "cand", ".", "get", "(", "\"aliases\"", ",", "None", ")", "\n", "sents", "=", "[", "]", "\n", "\n", "for", "k", "in", "range", "(", "0", ",", "10", ")", ":", "\n", "                ", "key", "=", "\"sent_desc_{}\"", ".", "format", "(", "k", "+", "1", ")", "\n", "sents", ".", "append", "(", "cand", ".", "get", "(", "key", ",", "\"\"", ")", ")", "\n", "\n", "", "res", "[", "\"sentences\"", "]", "=", "sents", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.candidate_generation.BM45_Candidate_Generator.get_candidates": [[68, 116], ["query.format.format.format", "query.format.format.format", "solr.search", "candidate_generation.BM45_Candidate_Generator._filter_result", "sys.exc_info", "print", "print", "repr", "print", "candidate_generation.BM45_Candidate_Generator.solr_escape", "blink.get_sent_context", "blink.get_sent_context", "str"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.zeshel.create_BLINK_zeshel_data.LogFormatter.format", "home.repos.pwc.inspect_result.chenllliang_atp.zeshel.create_BLINK_zeshel_data.LogFormatter.format", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Simple_Candidate_Generator._filter_result", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.solr_escape", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.get_sent_context", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.get_sent_context"], ["", "def", "get_candidates", "(", "self", ",", "mention_data", ")", ":", "\n", "        ", "solr", "=", "self", ".", "solr", "\n", "\n", "# Build query", "\n", "keys", "=", "self", ".", "keys", "\n", "query", "=", "self", ".", "query", "\n", "if", "not", "self", ".", "raw_solr_fields", ":", "\n", "            ", "query", "=", "query", ".", "format", "(", "\n", "*", "[", "\n", "BM45_Candidate_Generator", ".", "solr_escape", "(", "mention_data", "[", "key", "]", ")", "\n", "if", "key", "in", "mention_data", "\n", "else", "utils", ".", "get_sent_context", "(", "mention_data", ",", "key", ")", "\n", "for", "key", "in", "keys", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "query", "=", "query", ".", "format", "(", "\n", "*", "[", "\n", "mention_data", "[", "key", "]", "\n", "if", "key", "in", "mention_data", "\n", "else", "utils", ".", "get_sent_context", "(", "mention_data", ",", "key", ")", "\n", "for", "key", "in", "keys", "\n", "]", "\n", ")", "\n", "\n", "", "try", ":", "\n", "            ", "results", "=", "solr", ".", "search", "(", "query", ",", "**", "self", ".", "query_arguments", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "exc_type", ",", "exc_obj", ",", "exc_tb", "=", "sys", ".", "exc_info", "(", ")", "\n", "print", "(", "\"\\nException:\"", ",", "exc_type", ",", "\"- line\"", ",", "exc_tb", ".", "tb_lineno", ")", "\n", "print", "(", "repr", "(", "e", ")", ")", "\n", "\n", "c", "=", "self", ".", "c", "\n", "if", "c", "<", "10", ":", "\n", "                ", "print", "(", "\n", "\"Exception with: \\naddress: {} \\nquery: {} \\nmention_data: {} \\n\"", ".", "format", "(", "\n", "self", ".", "solr_address", ",", "query", ",", "str", "(", "mention_data", ")", "\n", ")", "\n", ")", "\n", "", "self", ".", "c", "=", "c", "+", "1", "\n", "\n", "return", "[", "]", "\n", "\n", "# Filter the data in the retrieved objects, while ignoring the ones without a wikidata_id (only a very small fraction in the dataset; they are noise)", "\n", "", "filtered_results", "=", "[", "\n", "self", ".", "_filter_result", "(", "cand", ")", "for", "cand", "in", "results", ".", "docs", "if", "\"wikidata_id\"", "in", "cand", "\n", "]", "\n", "return", "filtered_results", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.candidate_generation.BM45_Candidate_Generator.process_mentions_for_candidate_generator": [[117, 122], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "process_mentions_for_candidate_generator", "(", "sentences", ",", "mentions", ")", ":", "\n", "        ", "for", "m", "in", "mentions", ":", "\n", "            ", "m", "[", "\"context\"", "]", "=", "sentences", "[", "m", "[", "\"sent_idx\"", "]", "]", "\n", "", "return", "mentions", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.candidate_generation.BM45_Candidate_Generator.solr_escape": [[123, 137], ["re.sub", "re.sub", "re.sub", "BM45_Candidate_Generator.ESCAPE_CHARS_RE.sub", "re.sub.lower", "x.group().lower", "x.group().lower", "x.group().lower", "x.group", "x.group", "x.group"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "solr_escape", "(", "string", ")", ":", "\n", "        ", "if", "(", "string", "==", "\"OR\"", ")", "or", "(", "string", "==", "\"AND\"", ")", ":", "\n", "            ", "return", "string", ".", "lower", "(", ")", "\n", "\n", "", "interior", "=", "r\"\\s+(OR|AND)\\s+\"", "\n", "start", "=", "r\"^(OR|AND) \"", "\n", "end", "=", "r\" (OR|AND)$\"", "\n", "\n", "string", "=", "re", ".", "sub", "(", "interior", ",", "lambda", "x", ":", "x", ".", "group", "(", "0", ")", ".", "lower", "(", ")", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "start", ",", "lambda", "x", ":", "x", ".", "group", "(", "0", ")", ".", "lower", "(", ")", ",", "string", ")", "\n", "string", "=", "re", ".", "sub", "(", "end", ",", "lambda", "x", ":", "x", ".", "group", "(", "0", ")", ".", "lower", "(", ")", ",", "string", ")", "\n", "\n", "return", "BM45_Candidate_Generator", ".", "ESCAPE_CHARS_RE", ".", "sub", "(", "r\"\\\\\\g<char>\"", ",", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.candidate_generation.get_model": [[15, 17], ["candidate_generation.BM45_Candidate_Generator"], "function", ["None"], ["def", "get_model", "(", "params", ")", ":", "\n", "    ", "return", "BM45_Candidate_Generator", "(", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.ner.NER_model.__init__": [[16, 18], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "parameters", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.ner.NER_model.predict": [[19, 27], ["None"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "sents", ")", ":", "\n", "        ", "\"\"\"Sents: List of plain text consequtive sentences. \n        Returns a dictionary consisting of a list of sentences and a list of mentions, where for each mention AT LEAST (it may give additional information) the following information is given:\n            sent_idx - the index of the sentence that contains the mention\n            text - the textual span that we hypothesise that represents an entity\n            start_pos - the character idx at which the textual mention starts \n            end_pos - the character idx at which the mention ends\"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.ner.Flair.__init__": [[30, 32], ["flair.models.SequenceTagger.load"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["    ", "def", "__init__", "(", "self", ",", "parameters", "=", "None", ")", ":", "\n", "        ", "self", ".", "model", "=", "SequenceTagger", ".", "load", "(", "\"ner\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.ner.Flair.predict": [[33, 43], ["enumerate", "flair.data.Sentence", "ner.Flair.model.predict", "mentions.extend", "flair.data.Sentence.to_dict"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.blink.ner.Flair.predict", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend"], ["", "def", "predict", "(", "self", ",", "sentences", ")", ":", "\n", "        ", "mentions", "=", "[", "]", "\n", "for", "sent_idx", ",", "sent", "in", "enumerate", "(", "sentences", ")", ":", "\n", "            ", "sent", "=", "Sentence", "(", "sent", ",", "use_tokenizer", "=", "True", ")", "\n", "self", ".", "model", ".", "predict", "(", "sent", ")", "\n", "sent_mentions", "=", "sent", ".", "to_dict", "(", "tag_type", "=", "\"ner\"", ")", "[", "\"entities\"", "]", "\n", "for", "mention", "in", "sent_mentions", ":", "\n", "                ", "mention", "[", "\"sent_idx\"", "]", "=", "sent_idx", "\n", "", "mentions", ".", "extend", "(", "sent_mentions", ")", "\n", "", "return", "{", "\"sentences\"", ":", "sentences", ",", "\"mentions\"", ":", "mentions", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.ner.get_model": [[11, 13], ["ner.Flair"], "function", ["None"], ["def", "get_model", "(", "parameters", "=", "None", ")", ":", "\n", "    ", "return", "Flair", "(", "parameters", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.candidate_data_fetcher.Wikimedia_Data_Fetcher.__init__": [[16, 18], ["pickle.load", "open"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["    ", "def", "__init__", "(", "self", ",", "path_to_data", ")", ":", "\n", "        ", "self", ".", "data", "=", "pickle", ".", "load", "(", "open", "(", "path_to_data", ",", "\"rb\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.candidate_data_fetcher.Wikimedia_Data_Fetcher.get_data_for_entity": [[19, 49], ["range", "sents.append", "data[].get"], "methods", ["None"], ["", "def", "get_data_for_entity", "(", "self", ",", "entity_data", ")", ":", "\n", "        ", "\"\"\"Given an entity data dictionary that contains some linking data (ex. title or ID), additional information (ex. description, aliases etc.) is added to the given entity dictionary\"\"\"", "\n", "data", "=", "self", ".", "data", "\n", "title", "=", "entity_data", "[", "\"wikipedia_title\"", "]", "\n", "\n", "if", "\"wikidata_info\"", "in", "data", "[", "title", "]", ":", "\n", "            ", "if", "(", "\"aliases\"", "in", "data", "[", "title", "]", "[", "\"wikidata_info\"", "]", ")", "and", "(", "\n", "data", "[", "title", "]", "[", "\"wikidata_info\"", "]", "[", "\"aliases\"", "]", "\n", ")", "is", "not", "None", ":", "\n", "                ", "aliases", "=", "[", "\n", "alias", "\n", "for", "alias", "in", "data", "[", "title", "]", "[", "\"wikidata_info\"", "]", "[", "\"aliases\"", "]", "\n", "if", "alias", "not", "in", "emoji", ".", "UNICODE_EMOJI", "\n", "]", "\n", "", "else", ":", "\n", "                ", "aliases", "=", "None", "\n", "", "", "else", ":", "\n", "            ", "aliases", "=", "None", "\n", "\n", "", "entity_data", "[", "\"aliases\"", "]", "=", "aliases", "\n", "\n", "sents", "=", "[", "]", "\n", "\n", "for", "k", "in", "range", "(", "0", ",", "10", ")", ":", "\n", "            ", "key", "=", "\"sent_desc_{}\"", ".", "format", "(", "k", "+", "1", ")", "\n", "sents", ".", "append", "(", "data", "[", "title", "]", ".", "get", "(", "key", ",", "\"\"", ")", ")", "\n", "\n", "", "entity_data", "[", "\"sentences\"", "]", "=", "sents", "\n", "\n", "return", "entity_data", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.candidate_data_fetcher.get_model": [[11, 13], ["candidate_data_fetcher.Wikimedia_Data_Fetcher"], "function", ["None"], ["def", "get_model", "(", "parameters", ")", ":", "\n", "    ", "return", "Wikimedia_Data_Fetcher", "(", "parameters", "[", "\"path_to_candidate_data_dict\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.reranker.get_model": [[10, 12], ["blink.candidate_ranking.bert_reranking.BertReranker"], "function", ["None"], ["def", "get_model", "(", "params", ")", ":", "\n", "    ", "return", "BertReranker", "(", "params", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense._print_colorful_text": [[42, 63], ["colorama.init", "print", "enumerate", "print", "len", "termcolor.colored", "int", "str", "len", "int", "int", "int", "int", "int", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["def", "_print_colorful_text", "(", "input_sentence", ",", "samples", ")", ":", "\n", "    ", "init", "(", ")", "# colorful output", "\n", "msg", "=", "\"\"", "\n", "if", "samples", "and", "(", "len", "(", "samples", ")", ">", "0", ")", ":", "\n", "        ", "msg", "+=", "input_sentence", "[", "0", ":", "int", "(", "samples", "[", "0", "]", "[", "\"start_pos\"", "]", ")", "]", "\n", "for", "idx", ",", "sample", "in", "enumerate", "(", "samples", ")", ":", "\n", "            ", "msg", "+=", "colored", "(", "\n", "input_sentence", "[", "int", "(", "sample", "[", "\"start_pos\"", "]", ")", ":", "int", "(", "sample", "[", "\"end_pos\"", "]", ")", "]", ",", "\n", "\"grey\"", ",", "\n", "HIGHLIGHTS", "[", "idx", "%", "len", "(", "HIGHLIGHTS", ")", "]", ",", "\n", ")", "\n", "if", "idx", "<", "len", "(", "samples", ")", "-", "1", ":", "\n", "                ", "msg", "+=", "input_sentence", "[", "\n", "int", "(", "sample", "[", "\"end_pos\"", "]", ")", ":", "int", "(", "samples", "[", "idx", "+", "1", "]", "[", "\"start_pos\"", "]", ")", "\n", "]", "\n", "", "else", ":", "\n", "                ", "msg", "+=", "input_sentence", "[", "int", "(", "sample", "[", "\"end_pos\"", "]", ")", ":", "]", "\n", "", "", "", "else", ":", "\n", "        ", "msg", "=", "input_sentence", "\n", "print", "(", "\"Failed to identify entity from text:\"", ")", "\n", "", "print", "(", "\"\\n\"", "+", "str", "(", "msg", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense._print_colorful_prediction": [[65, 73], ["print", "print", "termcolor.colored", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "_print_colorful_prediction", "(", "\n", "idx", ",", "sample", ",", "e_id", ",", "e_title", ",", "e_text", ",", "e_url", ",", "show_url", "=", "False", "\n", ")", ":", "\n", "    ", "print", "(", "colored", "(", "sample", "[", "\"mention\"", "]", ",", "\"grey\"", ",", "HIGHLIGHTS", "[", "idx", "%", "len", "(", "HIGHLIGHTS", ")", "]", ")", ")", "\n", "to_print", "=", "\"id:{}\\ntitle:{}\\ntext:{}\\n\"", ".", "format", "(", "e_id", ",", "e_title", ",", "e_text", "[", ":", "256", "]", ")", "\n", "if", "show_url", ":", "\n", "        ", "to_print", "+=", "\"url:{}\\n\"", ".", "format", "(", "e_url", ")", "\n", "", "print", "(", "to_print", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense._annotate": [[75, 97], ["ner_model.predict", "[].lower", "[].lower", "mention[].lower", "int", "int", "samples.append"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.blink.ner.Flair.predict"], ["", "def", "_annotate", "(", "ner_model", ",", "input_sentences", ")", ":", "\n", "    ", "ner_output_data", "=", "ner_model", ".", "predict", "(", "input_sentences", ")", "\n", "sentences", "=", "ner_output_data", "[", "\"sentences\"", "]", "\n", "mentions", "=", "ner_output_data", "[", "\"mentions\"", "]", "\n", "samples", "=", "[", "]", "\n", "for", "mention", "in", "mentions", ":", "\n", "        ", "record", "=", "{", "}", "\n", "record", "[", "\"label\"", "]", "=", "\"unknown\"", "\n", "record", "[", "\"label_id\"", "]", "=", "-", "1", "\n", "# LOWERCASE EVERYTHING !", "\n", "record", "[", "\"context_left\"", "]", "=", "sentences", "[", "mention", "[", "\"sent_idx\"", "]", "]", "[", "\n", ":", "mention", "[", "\"start_pos\"", "]", "\n", "]", ".", "lower", "(", ")", "\n", "record", "[", "\"context_right\"", "]", "=", "sentences", "[", "mention", "[", "\"sent_idx\"", "]", "]", "[", "\n", "mention", "[", "\"end_pos\"", "]", ":", "\n", "]", ".", "lower", "(", ")", "\n", "record", "[", "\"mention\"", "]", "=", "mention", "[", "\"text\"", "]", ".", "lower", "(", ")", "\n", "record", "[", "\"start_pos\"", "]", "=", "int", "(", "mention", "[", "\"start_pos\"", "]", ")", "\n", "record", "[", "\"end_pos\"", "]", "=", "int", "(", "mention", "[", "\"end_pos\"", "]", ")", "\n", "record", "[", "\"sent_idx\"", "]", "=", "mention", "[", "\"sent_idx\"", "]", "\n", "samples", ".", "append", "(", "record", ")", "\n", "", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense._load_candidates": [[99, 151], ["torch.load", "blink.indexer.faiss_indexer.DenseHNSWFlatIndexer.deserialize_from", "open", "fin.readlines", "logger.info", "blink.indexer.faiss_indexer.DenseFlatIndexer", "json.loads", "blink.indexer.faiss_indexer.DenseHNSWFlatIndexer", "ValueError", "entity[].split", "len", "int", "entity[].strip", "split[].strip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseHNSWFlatIndexer.deserialize_from", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "_load_candidates", "(", "\n", "entity_catalogue", ",", "entity_encoding", ",", "faiss_index", "=", "None", ",", "index_path", "=", "None", ",", "logger", "=", "None", "\n", ")", ":", "\n", "# only load candidate encoding if not using faiss index", "\n", "    ", "if", "faiss_index", "is", "None", ":", "\n", "        ", "candidate_encoding", "=", "torch", ".", "load", "(", "entity_encoding", ")", "\n", "indexer", "=", "None", "\n", "", "else", ":", "\n", "        ", "if", "logger", ":", "\n", "            ", "logger", ".", "info", "(", "\"Using faiss index to retrieve entities.\"", ")", "\n", "", "candidate_encoding", "=", "None", "\n", "assert", "index_path", "is", "not", "None", ",", "\"Error! Empty indexer path.\"", "\n", "if", "faiss_index", "==", "\"flat\"", ":", "\n", "            ", "indexer", "=", "DenseFlatIndexer", "(", "1", ")", "\n", "", "elif", "faiss_index", "==", "\"hnsw\"", ":", "\n", "            ", "indexer", "=", "DenseHNSWFlatIndexer", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Error! Unsupported indexer type! Choose from flat,hnsw.\"", ")", "\n", "", "indexer", ".", "deserialize_from", "(", "index_path", ")", "\n", "\n", "# load all the 5903527 entities", "\n", "", "title2id", "=", "{", "}", "\n", "id2title", "=", "{", "}", "\n", "id2text", "=", "{", "}", "\n", "wikipedia_id2local_id", "=", "{", "}", "\n", "local_idx", "=", "0", "\n", "with", "open", "(", "entity_catalogue", ",", "\"r\"", ")", "as", "fin", ":", "\n", "        ", "lines", "=", "fin", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "entity", "=", "json", ".", "loads", "(", "line", ")", "\n", "\n", "if", "\"idx\"", "in", "entity", ":", "\n", "                ", "split", "=", "entity", "[", "\"idx\"", "]", ".", "split", "(", "\"curid=\"", ")", "\n", "if", "len", "(", "split", ")", ">", "1", ":", "\n", "                    ", "wikipedia_id", "=", "int", "(", "split", "[", "-", "1", "]", ".", "strip", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "wikipedia_id", "=", "entity", "[", "\"idx\"", "]", ".", "strip", "(", ")", "\n", "\n", "", "assert", "wikipedia_id", "not", "in", "wikipedia_id2local_id", "\n", "wikipedia_id2local_id", "[", "wikipedia_id", "]", "=", "local_idx", "\n", "\n", "", "title2id", "[", "entity", "[", "\"title\"", "]", "]", "=", "local_idx", "\n", "id2title", "[", "local_idx", "]", "=", "entity", "[", "\"title\"", "]", "\n", "id2text", "[", "local_idx", "]", "=", "entity", "[", "\"text\"", "]", "\n", "local_idx", "+=", "1", "\n", "", "", "return", "(", "\n", "candidate_encoding", ",", "\n", "title2id", ",", "\n", "id2title", ",", "\n", "id2text", ",", "\n", "wikipedia_id2local_id", ",", "\n", "indexer", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense.__map_test_entities": [[154, 171], ["open", "fin.readlines", "logger.info", "json.loads"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads"], ["", "def", "__map_test_entities", "(", "test_entities_path", ",", "title2id", ",", "logger", ")", ":", "\n", "# load the 732859 tac_kbp_ref_know_base entities", "\n", "    ", "kb2id", "=", "{", "}", "\n", "missing_pages", "=", "0", "\n", "n", "=", "0", "\n", "with", "open", "(", "test_entities_path", ",", "\"r\"", ")", "as", "fin", ":", "\n", "        ", "lines", "=", "fin", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "entity", "=", "json", ".", "loads", "(", "line", ")", "\n", "if", "entity", "[", "\"title\"", "]", "not", "in", "title2id", ":", "\n", "                ", "missing_pages", "+=", "1", "\n", "", "else", ":", "\n", "                ", "kb2id", "[", "entity", "[", "\"entity_id\"", "]", "]", "=", "title2id", "[", "entity", "[", "\"title\"", "]", "]", "\n", "", "n", "+=", "1", "\n", "", "", "if", "logger", ":", "\n", "        ", "logger", ".", "info", "(", "\"missing {}/{} pages\"", ".", "format", "(", "missing_pages", ",", "n", ")", ")", "\n", "", "return", "kb2id", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense.__load_test": [[173, 208], ["open", "fin.readlines", "logger.info", "json.loads", "str", "record[].lower", "record[].lower", "record[].lower", "test_samples.append", "len", "len", "len", "len", "int", "record[].strip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads"], ["", "def", "__load_test", "(", "test_filename", ",", "kb2id", ",", "wikipedia_id2local_id", ",", "logger", ")", ":", "\n", "    ", "test_samples", "=", "[", "]", "\n", "with", "open", "(", "test_filename", ",", "\"r\"", ")", "as", "fin", ":", "\n", "        ", "lines", "=", "fin", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "record", "=", "json", ".", "loads", "(", "line", ")", "\n", "record", "[", "\"label\"", "]", "=", "str", "(", "record", "[", "\"label_id\"", "]", ")", "\n", "\n", "# for tac kbp we should use a separate knowledge source to get the entity id (label_id)", "\n", "if", "kb2id", "and", "len", "(", "kb2id", ")", ">", "0", ":", "\n", "                ", "if", "record", "[", "\"label\"", "]", "in", "kb2id", ":", "\n", "                    ", "record", "[", "\"label_id\"", "]", "=", "kb2id", "[", "record", "[", "\"label\"", "]", "]", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "\n", "# check that each entity id (label_id) is in the entity collection", "\n", "", "", "elif", "wikipedia_id2local_id", "and", "len", "(", "wikipedia_id2local_id", ")", ">", "0", ":", "\n", "                ", "try", ":", "\n", "                    ", "key", "=", "int", "(", "record", "[", "\"label\"", "]", ".", "strip", "(", ")", ")", "\n", "if", "key", "in", "wikipedia_id2local_id", ":", "\n", "                        ", "record", "[", "\"label_id\"", "]", "=", "wikipedia_id2local_id", "[", "key", "]", "\n", "", "else", ":", "\n", "                        ", "continue", "\n", "", "", "except", ":", "\n", "                    ", "continue", "\n", "\n", "# LOWERCASE EVERYTHING !", "\n", "", "", "record", "[", "\"context_left\"", "]", "=", "record", "[", "\"context_left\"", "]", ".", "lower", "(", ")", "\n", "record", "[", "\"context_right\"", "]", "=", "record", "[", "\"context_right\"", "]", ".", "lower", "(", ")", "\n", "record", "[", "\"mention\"", "]", "=", "record", "[", "\"mention\"", "]", ".", "lower", "(", ")", "\n", "test_samples", ".", "append", "(", "record", ")", "\n", "\n", "", "", "if", "logger", ":", "\n", "        ", "logger", ".", "info", "(", "\"{}/{} samples considered\"", ".", "format", "(", "len", "(", "test_samples", ")", ",", "len", "(", "lines", ")", ")", ")", "\n", "", "return", "test_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense._get_test_samples": [[210, 218], ["main_dense.__load_test", "main_dense.__map_test_entities"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense.__load_test", "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense.__map_test_entities"], ["", "def", "_get_test_samples", "(", "\n", "test_filename", ",", "test_entities_path", ",", "title2id", ",", "wikipedia_id2local_id", ",", "logger", "\n", ")", ":", "\n", "    ", "kb2id", "=", "None", "\n", "if", "test_entities_path", ":", "\n", "        ", "kb2id", "=", "__map_test_entities", "(", "test_entities_path", ",", "title2id", ",", "logger", ")", "\n", "", "test_samples", "=", "__load_test", "(", "test_filename", ",", "kb2id", ",", "wikipedia_id2local_id", ",", "logger", ")", "\n", "return", "test_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense._process_biencoder_dataloader": [[220, 235], ["blink.biencoder.data_process.process_mention_data", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.process_mention_data"], ["", "def", "_process_biencoder_dataloader", "(", "samples", ",", "tokenizer", ",", "biencoder_params", ")", ":", "\n", "    ", "_", ",", "tensor_data", "=", "process_mention_data", "(", "\n", "samples", ",", "\n", "tokenizer", ",", "\n", "biencoder_params", "[", "\"max_context_length\"", "]", ",", "\n", "biencoder_params", "[", "\"max_cand_length\"", "]", ",", "\n", "silent", "=", "True", ",", "\n", "logger", "=", "None", ",", "\n", "debug", "=", "biencoder_params", "[", "\"debug\"", "]", ",", "\n", ")", "\n", "sampler", "=", "SequentialSampler", "(", "tensor_data", ")", "\n", "dataloader", "=", "DataLoader", "(", "\n", "tensor_data", ",", "sampler", "=", "sampler", ",", "batch_size", "=", "biencoder_params", "[", "\"eval_batch_size\"", "]", "\n", ")", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense._run_biencoder": [[237, 261], ["biencoder.model.eval", "tqdm.tqdm", "labels.extend", "nns.extend", "all_scores.extend", "torch.no_grad", "label_ids.data.numpy", "biencoder.encode_context().numpy", "numpy.ascontiguousarray", "indexer.search_knn", "biencoder.score_candidate", "scores.data.numpy.topk", "scores.data.numpy.data.numpy", "indicies.data.numpy.data.numpy", "biencoder.encode_context"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseHNSWFlatIndexer.search_knn", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.score_candidate", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.encode_context"], ["", "def", "_run_biencoder", "(", "biencoder", ",", "dataloader", ",", "candidate_encoding", ",", "top_k", "=", "100", ",", "indexer", "=", "None", ")", ":", "\n", "    ", "biencoder", ".", "model", ".", "eval", "(", ")", "\n", "labels", "=", "[", "]", "\n", "nns", "=", "[", "]", "\n", "all_scores", "=", "[", "]", "\n", "for", "batch", "in", "tqdm", "(", "dataloader", ")", ":", "\n", "        ", "context_input", ",", "_", ",", "label_ids", "=", "batch", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "indexer", "is", "not", "None", ":", "\n", "                ", "context_encoding", "=", "biencoder", ".", "encode_context", "(", "context_input", ")", ".", "numpy", "(", ")", "\n", "context_encoding", "=", "np", ".", "ascontiguousarray", "(", "context_encoding", ")", "\n", "scores", ",", "indicies", "=", "indexer", ".", "search_knn", "(", "context_encoding", ",", "top_k", ")", "\n", "", "else", ":", "\n", "                ", "scores", "=", "biencoder", ".", "score_candidate", "(", "\n", "context_input", ",", "None", ",", "cand_encs", "=", "candidate_encoding", "# .to(device)", "\n", ")", "\n", "scores", ",", "indicies", "=", "scores", ".", "topk", "(", "top_k", ")", "\n", "scores", "=", "scores", ".", "data", ".", "numpy", "(", ")", "\n", "indicies", "=", "indicies", ".", "data", ".", "numpy", "(", ")", "\n", "\n", "", "", "labels", ".", "extend", "(", "label_ids", ".", "data", ".", "numpy", "(", ")", ")", "\n", "nns", ".", "extend", "(", "indicies", ")", "\n", "all_scores", ".", "extend", "(", "scores", ")", "\n", "", "return", "labels", ",", "nns", ",", "all_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense._process_crossencoder_dataloader": [[263, 270], ["torch.utils.data.TensorDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "_process_crossencoder_dataloader", "(", "context_input", ",", "label_input", ",", "crossencoder_params", ")", ":", "\n", "    ", "tensor_data", "=", "TensorDataset", "(", "context_input", ",", "label_input", ")", "\n", "sampler", "=", "SequentialSampler", "(", "tensor_data", ")", "\n", "dataloader", "=", "DataLoader", "(", "\n", "tensor_data", ",", "sampler", "=", "sampler", ",", "batch_size", "=", "crossencoder_params", "[", "\"eval_batch_size\"", "]", "\n", ")", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense._run_crossencoder": [[272, 287], ["crossencoder.model.eval", "crossencoder.to", "blink.crossencoder.train_cross.evaluate", "numpy.argsort"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.evaluate"], ["", "def", "_run_crossencoder", "(", "crossencoder", ",", "dataloader", ",", "logger", ",", "context_len", ",", "device", "=", "\"cuda\"", ")", ":", "\n", "    ", "crossencoder", ".", "model", ".", "eval", "(", ")", "\n", "accuracy", "=", "0.0", "\n", "crossencoder", ".", "to", "(", "device", ")", "\n", "\n", "res", "=", "evaluate", "(", "crossencoder", ",", "dataloader", ",", "device", ",", "logger", ",", "context_len", ",", "zeshel", "=", "False", ",", "silent", "=", "False", ")", "\n", "accuracy", "=", "res", "[", "\"normalized_accuracy\"", "]", "\n", "logits", "=", "res", "[", "\"logits\"", "]", "\n", "\n", "if", "accuracy", ">", "-", "1", ":", "\n", "        ", "predictions", "=", "np", ".", "argsort", "(", "logits", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "predictions", "=", "[", "]", "\n", "\n", "", "return", "accuracy", ",", "predictions", ",", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense.load_models": [[289, 339], ["blink.biencoder.biencoder.load_biencoder", "main_dense._load_candidates", "logger.info", "open", "json.load", "blink.crossencoder.crossencoder.load_crossencoder", "logger.info", "logger.info", "open", "json.load", "getattr", "getattr"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.load_biencoder", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._load_candidates", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.load_crossencoder", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["", "def", "load_models", "(", "args", ",", "logger", "=", "None", ")", ":", "\n", "\n", "# load biencoder model", "\n", "    ", "if", "logger", ":", "\n", "        ", "logger", ".", "info", "(", "\"loading biencoder model\"", ")", "\n", "", "with", "open", "(", "args", ".", "biencoder_config", ")", "as", "json_file", ":", "\n", "        ", "biencoder_params", "=", "json", ".", "load", "(", "json_file", ")", "\n", "biencoder_params", "[", "\"path_to_model\"", "]", "=", "args", ".", "biencoder_model", "\n", "", "biencoder", "=", "load_biencoder", "(", "biencoder_params", ")", "\n", "\n", "crossencoder", "=", "None", "\n", "crossencoder_params", "=", "None", "\n", "if", "not", "args", ".", "fast", ":", "\n", "# load crossencoder model", "\n", "        ", "if", "logger", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading crossencoder model\"", ")", "\n", "", "with", "open", "(", "args", ".", "crossencoder_config", ")", "as", "json_file", ":", "\n", "            ", "crossencoder_params", "=", "json", ".", "load", "(", "json_file", ")", "\n", "crossencoder_params", "[", "\"path_to_model\"", "]", "=", "args", ".", "crossencoder_model", "\n", "", "crossencoder", "=", "load_crossencoder", "(", "crossencoder_params", ")", "\n", "\n", "# load candidate entities", "\n", "", "if", "logger", ":", "\n", "        ", "logger", ".", "info", "(", "\"loading candidate entities\"", ")", "\n", "", "(", "\n", "candidate_encoding", ",", "\n", "title2id", ",", "\n", "id2title", ",", "\n", "id2text", ",", "\n", "wikipedia_id2local_id", ",", "\n", "faiss_indexer", ",", "\n", ")", "=", "_load_candidates", "(", "\n", "args", ".", "entity_catalogue", ",", "\n", "args", ".", "entity_encoding", ",", "\n", "faiss_index", "=", "getattr", "(", "args", ",", "'faiss_index'", ",", "None", ")", ",", "\n", "index_path", "=", "getattr", "(", "args", ",", "'index_path'", ",", "None", ")", ",", "\n", "logger", "=", "logger", ",", "\n", ")", "\n", "\n", "return", "(", "\n", "biencoder", ",", "\n", "biencoder_params", ",", "\n", "crossencoder", ",", "\n", "crossencoder_params", ",", "\n", "candidate_encoding", ",", "\n", "title2id", ",", "\n", "id2title", ",", "\n", "id2text", ",", "\n", "wikipedia_id2local_id", ",", "\n", "faiss_indexer", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense.run": [[342, 586], ["ValueError", "main_dense._process_biencoder_dataloader", "main_dense._run_biencoder", "blink.crossencoder.data_process.prepare_crossencoder_data", "blink.crossencoder.train_cross.modify", "main_dense._process_crossencoder_dataloader", "main_dense._run_crossencoder", "wikipedia_id2local_id.items", "logger.info", "blink.get_model", "input", "main_dense._annotate", "main_dense._print_colorful_text", "logger.info", "logger.info", "print", "main_dense._print_colorful_text", "zip", "print", "print", "main_dense._print_colorful_text", "zip", "print", "zip", "logger.info", "main_dense._get_test_samples", "main_dense._print_colorful_prediction", "range", "print", "print", "main_dense._print_colorful_prediction", "index_list.tolist.tolist", "index_list.tolist.reverse", "predictions.append", "scores.append", "print", "print", "len", "zip", "x.append", "y.append", "predictions.append", "len", "sample_prediction.append", "sample_scores.append", "len", "len", "len", "sample_prediction.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._process_biencoder_dataloader", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._run_biencoder", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.data_process.prepare_crossencoder_data", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.train_cross.modify", "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense._process_crossencoder_dataloader", "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense._run_crossencoder", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker.get_model", "home.repos.pwc.inspect_result.chenllliang_atp.blink.main_dense._annotate", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._print_colorful_text", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._print_colorful_text", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._print_colorful_text", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._get_test_samples", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._print_colorful_prediction", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._print_colorful_prediction", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "run", "(", "\n", "args", ",", "\n", "logger", ",", "\n", "biencoder", ",", "\n", "biencoder_params", ",", "\n", "crossencoder", ",", "\n", "crossencoder_params", ",", "\n", "candidate_encoding", ",", "\n", "title2id", ",", "\n", "id2title", ",", "\n", "id2text", ",", "\n", "wikipedia_id2local_id", ",", "\n", "faiss_indexer", "=", "None", ",", "\n", "test_data", "=", "None", ",", "\n", ")", ":", "\n", "\n", "    ", "if", "not", "test_data", "and", "not", "args", ".", "test_mentions", "and", "not", "args", ".", "interactive", ":", "\n", "        ", "msg", "=", "(", "\n", "\"ERROR: either you start BLINK with the \"", "\n", "\"interactive option (-i) or you pass in input test mentions (--test_mentions)\"", "\n", "\"and test entitied (--test_entities)\"", "\n", ")", "\n", "raise", "ValueError", "(", "msg", ")", "\n", "\n", "", "id2url", "=", "{", "\n", "v", ":", "\"https://en.wikipedia.org/wiki?curid=%s\"", "%", "k", "\n", "for", "k", ",", "v", "in", "wikipedia_id2local_id", ".", "items", "(", ")", "\n", "}", "\n", "\n", "stopping_condition", "=", "False", "\n", "while", "not", "stopping_condition", ":", "\n", "\n", "        ", "samples", "=", "None", "\n", "\n", "if", "args", ".", "interactive", ":", "\n", "            ", "logger", ".", "info", "(", "\"interactive mode\"", ")", "\n", "\n", "# biencoder_params[\"eval_batch_size\"] = 1", "\n", "\n", "# Load NER model", "\n", "ner_model", "=", "NER", ".", "get_model", "(", ")", "\n", "\n", "# Interactive", "\n", "text", "=", "input", "(", "\"insert text:\"", ")", "\n", "\n", "# Identify mentions", "\n", "samples", "=", "_annotate", "(", "ner_model", ",", "[", "text", "]", ")", "\n", "\n", "_print_colorful_text", "(", "text", ",", "samples", ")", "\n", "\n", "", "else", ":", "\n", "            ", "if", "logger", ":", "\n", "                ", "logger", ".", "info", "(", "\"test dataset mode\"", ")", "\n", "\n", "", "if", "test_data", ":", "\n", "                ", "samples", "=", "test_data", "\n", "", "else", ":", "\n", "# Load test mentions", "\n", "                ", "samples", "=", "_get_test_samples", "(", "\n", "args", ".", "test_mentions", ",", "\n", "args", ".", "test_entities", ",", "\n", "title2id", ",", "\n", "wikipedia_id2local_id", ",", "\n", "logger", ",", "\n", ")", "\n", "\n", "", "stopping_condition", "=", "True", "\n", "\n", "# don't look at labels", "\n", "", "keep_all", "=", "(", "\n", "args", ".", "interactive", "\n", "or", "samples", "[", "0", "]", "[", "\"label\"", "]", "==", "\"unknown\"", "\n", "or", "samples", "[", "0", "]", "[", "\"label_id\"", "]", "<", "0", "\n", ")", "\n", "\n", "# prepare the data for biencoder", "\n", "if", "logger", ":", "\n", "            ", "logger", ".", "info", "(", "\"preparing data for biencoder\"", ")", "\n", "", "dataloader", "=", "_process_biencoder_dataloader", "(", "\n", "samples", ",", "biencoder", ".", "tokenizer", ",", "biencoder_params", "\n", ")", "\n", "\n", "# run biencoder", "\n", "if", "logger", ":", "\n", "            ", "logger", ".", "info", "(", "\"run biencoder\"", ")", "\n", "", "top_k", "=", "args", ".", "top_k", "\n", "labels", ",", "nns", ",", "scores", "=", "_run_biencoder", "(", "\n", "biencoder", ",", "dataloader", ",", "candidate_encoding", ",", "top_k", ",", "faiss_indexer", "\n", ")", "\n", "\n", "if", "args", ".", "interactive", ":", "\n", "\n", "            ", "print", "(", "\"\\nfast (biencoder) predictions:\"", ")", "\n", "\n", "_print_colorful_text", "(", "text", ",", "samples", ")", "\n", "\n", "# print biencoder prediction", "\n", "idx", "=", "0", "\n", "for", "entity_list", ",", "sample", "in", "zip", "(", "nns", ",", "samples", ")", ":", "\n", "                ", "e_id", "=", "entity_list", "[", "0", "]", "\n", "e_title", "=", "id2title", "[", "e_id", "]", "\n", "e_text", "=", "id2text", "[", "e_id", "]", "\n", "e_url", "=", "id2url", "[", "e_id", "]", "\n", "_print_colorful_prediction", "(", "\n", "idx", ",", "sample", ",", "e_id", ",", "e_title", ",", "e_text", ",", "e_url", ",", "args", ".", "show_url", "\n", ")", "\n", "idx", "+=", "1", "\n", "", "print", "(", ")", "\n", "\n", "if", "args", ".", "fast", ":", "\n", "# use only biencoder", "\n", "                ", "continue", "\n", "\n", "", "", "else", ":", "\n", "\n", "            ", "biencoder_accuracy", "=", "-", "1", "\n", "recall_at", "=", "-", "1", "\n", "if", "not", "keep_all", ":", "\n", "# get recall values", "\n", "                ", "top_k", "=", "args", ".", "top_k", "\n", "x", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "top_k", ")", ":", "\n", "                    ", "temp_y", "=", "0.0", "\n", "for", "label", ",", "top", "in", "zip", "(", "labels", ",", "nns", ")", ":", "\n", "                        ", "if", "label", "in", "top", "[", ":", "i", "]", ":", "\n", "                            ", "temp_y", "+=", "1", "\n", "", "", "if", "len", "(", "labels", ")", ">", "0", ":", "\n", "                        ", "temp_y", "/=", "len", "(", "labels", ")", "\n", "", "x", ".", "append", "(", "i", ")", "\n", "y", ".", "append", "(", "temp_y", ")", "\n", "# plt.plot(x, y)", "\n", "", "biencoder_accuracy", "=", "y", "[", "0", "]", "\n", "recall_at", "=", "y", "[", "-", "1", "]", "\n", "print", "(", "\"biencoder accuracy: %.4f\"", "%", "biencoder_accuracy", ")", "\n", "print", "(", "\"biencoder recall@%d: %.4f\"", "%", "(", "top_k", ",", "y", "[", "-", "1", "]", ")", ")", "\n", "\n", "", "if", "args", ".", "fast", ":", "\n", "\n", "                ", "predictions", "=", "[", "]", "\n", "for", "entity_list", "in", "nns", ":", "\n", "                    ", "sample_prediction", "=", "[", "]", "\n", "for", "e_id", "in", "entity_list", ":", "\n", "                        ", "e_title", "=", "id2title", "[", "e_id", "]", "\n", "sample_prediction", ".", "append", "(", "e_title", ")", "\n", "", "predictions", ".", "append", "(", "sample_prediction", ")", "\n", "\n", "# use only biencoder", "\n", "", "return", "(", "\n", "biencoder_accuracy", ",", "\n", "recall_at", ",", "\n", "-", "1", ",", "\n", "-", "1", ",", "\n", "len", "(", "samples", ")", ",", "\n", "predictions", ",", "\n", "scores", ",", "\n", ")", "\n", "\n", "# prepare crossencoder data", "\n", "", "", "context_input", ",", "candidate_input", ",", "label_input", "=", "prepare_crossencoder_data", "(", "\n", "crossencoder", ".", "tokenizer", ",", "samples", ",", "labels", ",", "nns", ",", "id2title", ",", "id2text", ",", "keep_all", ",", "\n", ")", "\n", "\n", "context_input", "=", "modify", "(", "\n", "context_input", ",", "candidate_input", ",", "crossencoder_params", "[", "\"max_seq_length\"", "]", "\n", ")", "\n", "\n", "dataloader", "=", "_process_crossencoder_dataloader", "(", "\n", "context_input", ",", "label_input", ",", "crossencoder_params", "\n", ")", "\n", "\n", "# run crossencoder and get accuracy", "\n", "accuracy", ",", "index_array", ",", "unsorted_scores", "=", "_run_crossencoder", "(", "\n", "crossencoder", ",", "\n", "dataloader", ",", "\n", "logger", ",", "\n", "context_len", "=", "biencoder_params", "[", "\"max_context_length\"", "]", ",", "\n", ")", "\n", "\n", "if", "args", ".", "interactive", ":", "\n", "\n", "            ", "print", "(", "\"\\naccurate (crossencoder) predictions:\"", ")", "\n", "\n", "_print_colorful_text", "(", "text", ",", "samples", ")", "\n", "\n", "# print crossencoder prediction", "\n", "idx", "=", "0", "\n", "for", "entity_list", ",", "index_list", ",", "sample", "in", "zip", "(", "nns", ",", "index_array", ",", "samples", ")", ":", "\n", "                ", "e_id", "=", "entity_list", "[", "index_list", "[", "-", "1", "]", "]", "\n", "e_title", "=", "id2title", "[", "e_id", "]", "\n", "e_text", "=", "id2text", "[", "e_id", "]", "\n", "e_url", "=", "id2url", "[", "e_id", "]", "\n", "_print_colorful_prediction", "(", "\n", "idx", ",", "sample", ",", "e_id", ",", "e_title", ",", "e_text", ",", "e_url", ",", "args", ".", "show_url", "\n", ")", "\n", "idx", "+=", "1", "\n", "", "print", "(", ")", "\n", "", "else", ":", "\n", "\n", "            ", "scores", "=", "[", "]", "\n", "predictions", "=", "[", "]", "\n", "for", "entity_list", ",", "index_list", ",", "scores_list", "in", "zip", "(", "\n", "nns", ",", "index_array", ",", "unsorted_scores", "\n", ")", ":", "\n", "\n", "                ", "index_list", "=", "index_list", ".", "tolist", "(", ")", "\n", "\n", "# descending order", "\n", "index_list", ".", "reverse", "(", ")", "\n", "\n", "sample_prediction", "=", "[", "]", "\n", "sample_scores", "=", "[", "]", "\n", "for", "index", "in", "index_list", ":", "\n", "                    ", "e_id", "=", "entity_list", "[", "index", "]", "\n", "e_title", "=", "id2title", "[", "e_id", "]", "\n", "sample_prediction", ".", "append", "(", "e_title", ")", "\n", "sample_scores", ".", "append", "(", "scores_list", "[", "index", "]", ")", "\n", "", "predictions", ".", "append", "(", "sample_prediction", ")", "\n", "scores", ".", "append", "(", "sample_scores", ")", "\n", "\n", "", "crossencoder_normalized_accuracy", "=", "-", "1", "\n", "overall_unormalized_accuracy", "=", "-", "1", "\n", "if", "not", "keep_all", ":", "\n", "                ", "crossencoder_normalized_accuracy", "=", "accuracy", "\n", "print", "(", "\n", "\"crossencoder normalized accuracy: %.4f\"", "\n", "%", "crossencoder_normalized_accuracy", "\n", ")", "\n", "\n", "if", "len", "(", "samples", ")", ">", "0", ":", "\n", "                    ", "overall_unormalized_accuracy", "=", "(", "\n", "crossencoder_normalized_accuracy", "*", "len", "(", "label_input", ")", "/", "len", "(", "samples", ")", "\n", ")", "\n", "", "print", "(", "\n", "\"overall unnormalized accuracy: %.4f\"", "%", "overall_unormalized_accuracy", "\n", ")", "\n", "", "return", "(", "\n", "biencoder_accuracy", ",", "\n", "recall_at", ",", "\n", "crossencoder_normalized_accuracy", ",", "\n", "overall_unormalized_accuracy", ",", "\n", "len", "(", "samples", ")", ",", "\n", "predictions", ",", "\n", "scores", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.read_sentences_from_file": [[15, 31], ["io.open", "list", "line.strip.strip", "segtok.segmenter.split_multi", "lines.append", "line.strip.strip"], "function", ["None"], ["def", "read_sentences_from_file", "(", "path_to_file", ",", "one_sentence_per_line", "=", "True", ")", ":", "\n", "    ", "lines", "=", "[", "]", "\n", "with", "io", ".", "open", "(", "path_to_file", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "file", ":", "\n", "        ", "for", "line", "in", "file", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "!=", "\"\"", ":", "\n", "                ", "lines", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "", "if", "one_sentence_per_line", ":", "\n", "        ", "sentences", "=", "lines", "\n", "", "else", ":", "\n", "        ", "text", "=", "\" \"", ".", "join", "(", "lines", ")", "\n", "sentences", "=", "list", "(", "split_multi", "(", "text", ")", ")", "\n", "sentences", "=", "[", "sentence", "for", "sentence", "in", "sentences", "if", "sentence", "!=", "\"\"", "]", "\n", "\n", "", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.get_candidate_summary": [[34, 40], ["None"], "function", ["None"], ["", "def", "get_candidate_summary", "(", "candidate", ")", ":", "\n", "    ", "wikipedia_id", "=", "candidate", "[", "\"wikipedia_id\"", "]", "\n", "wikidata_id", "=", "candidate", "[", "\"wikidata_id\"", "]", "\n", "wikipedia_title", "=", "candidate", "[", "\"wikipedia_title\"", "]", "\n", "\n", "return", "\"{}, {}, {}\"", ".", "format", "(", "wikipedia_id", ",", "wikidata_id", ",", "wikipedia_title", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.present_sentence_mentions": [[42, 82], ["output", "output", "io.open", "mention_entity_pairs.append", "len", "output", "output", "io.open.write", "print", "len", "utils.get_candidate_summary"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.output", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.output", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.output", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.output", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.get_candidate_summary"], ["", "def", "present_sentence_mentions", "(", "sentence", ",", "mentions", ",", "output_file", ")", ":", "\n", "    ", "if", "output_file", "!=", "None", ":", "\n", "        ", "f", "=", "io", ".", "open", "(", "output_file", ",", "mode", "=", "\"a\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "output", "=", "lambda", "s", ":", "f", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "s", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "lambda", "s", ":", "print", "(", "s", ")", "\n", "", "output", "(", "\"Sentence: {}\"", ".", "format", "(", "sentence", ")", ")", "\n", "\n", "mention_entity_pairs", "=", "[", "]", "\n", "for", "mention", "in", "mentions", ":", "\n", "        ", "candidates", "=", "mention", "[", "\"candidates\"", "]", "\n", "# prediction = mention.get('predicted_candidate_idx', 0)", "\n", "prediction", "=", "mention", "[", "\"predicted_candidate_idx\"", "]", "\n", "\n", "if", "prediction", "<", "len", "(", "candidates", ")", ":", "\n", "# print(type(mention['prob_assigned_to_candidate']))", "\n", "# print(mention['prob_assigned_to_candidate'])", "\n", "            ", "mention_rep", "=", "\"{} ({}, {}) - {} (conf. {:.5f})\"", ".", "format", "(", "\n", "mention", "[", "\"text\"", "]", ",", "\n", "mention", "[", "\"start_pos\"", "]", ",", "\n", "mention", "[", "\"end_pos\"", "]", ",", "\n", "get_candidate_summary", "(", "candidates", "[", "prediction", "]", ")", ",", "\n", "mention", "[", "\"prob_assigned_to_candidate\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "mention_rep", "=", "\"{} ({}, {}) - {}\"", ".", "format", "(", "\n", "mention", "[", "\"text\"", "]", ",", "\n", "mention", "[", "\"start_pos\"", "]", ",", "\n", "mention", "[", "\"end_pos\"", "]", ",", "\n", "\"No candidate selected\"", ",", "\n", ")", "\n", "\n", "", "mention_entity_pairs", ".", "append", "(", "mention_rep", ")", "\n", "\n", "", "if", "len", "(", "mention_entity_pairs", ")", "!=", "0", ":", "\n", "        ", "output", "(", "\"Mention-Entity pairs: \\n{}\"", ".", "format", "(", "\"\\n\"", ".", "join", "(", "mention_entity_pairs", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "(", "\"No detected mentions\"", ")", "\n", "\n", "", "output", "(", "\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.sentence_mentions_pairs": [[84, 101], ["enumerate", "int", "mentions_per_sent.get", "mentions_per_sent.get.append", "pairs.append", "mentions_per_sent.get"], "function", ["None"], ["", "def", "sentence_mentions_pairs", "(", "sentences", ",", "mentions", ")", ":", "\n", "    ", "mentions_per_sent", "=", "{", "}", "\n", "\n", "for", "m", "in", "mentions", ":", "\n", "        ", "sent_idx", "=", "int", "(", "m", "[", "\"sent_idx\"", "]", ")", "\n", "\n", "curr_ments", "=", "mentions_per_sent", ".", "get", "(", "sent_idx", ",", "[", "]", ")", "\n", "curr_ments", ".", "append", "(", "m", ")", "\n", "\n", "mentions_per_sent", "[", "sent_idx", "]", "=", "curr_ments", "\n", "\n", "", "pairs", "=", "[", "]", "\n", "\n", "for", "idx", ",", "sent", "in", "enumerate", "(", "sentences", ")", ":", "\n", "        ", "pairs", ".", "append", "(", "(", "sent", ",", "mentions_per_sent", ".", "get", "(", "idx", ",", "[", "]", ")", ")", ")", "\n", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.present_annotated_sentences": [[103, 108], ["utils.sentence_mentions_pairs", "utils.present_sentence_mentions"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.sentence_mentions_pairs", "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.present_sentence_mentions"], ["", "def", "present_annotated_sentences", "(", "sentences", ",", "mentions", ",", "output_file", "=", "None", ")", ":", "\n", "    ", "pairs", "=", "sentence_mentions_pairs", "(", "sentences", ",", "mentions", ")", "\n", "\n", "for", "sent", ",", "ments", "in", "pairs", ":", "\n", "        ", "present_sentence_mentions", "(", "sent", ",", "ments", ",", "output_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.write_dicts_as_json_per_line": [[110, 118], ["io.open", "enumerate", "json.dumps", "file.write", "file.write", "len"], "function", ["None"], ["", "", "def", "write_dicts_as_json_per_line", "(", "list_of_dicts", ",", "txt_file_path", ")", ":", "\n", "    ", "with", "io", ".", "open", "(", "txt_file_path", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "file", ":", "\n", "        ", "for", "idx", ",", "mention", "in", "enumerate", "(", "list_of_dicts", ")", ":", "\n", "            ", "json_string", "=", "json", ".", "dumps", "(", "mention", ")", "\n", "file", ".", "write", "(", "json_string", ")", "\n", "\n", "if", "idx", "!=", "(", "len", "(", "list_of_dicts", ")", "-", "1", ")", ":", "\n", "                ", "file", ".", "write", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.get_mentions_txt_file_path": [[120, 126], ["os.makedirs", "os.path.join"], "function", ["None"], ["", "", "", "", "def", "get_mentions_txt_file_path", "(", "output_folder_path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_folder_path", ",", "exist_ok", "=", "True", ")", "\n", "file_name", "=", "\"mentions.jsonl\"", "\n", "path_to_file", "=", "os", ".", "path", ".", "join", "(", "output_folder_path", ",", "file_name", ")", "\n", "\n", "return", "path_to_file", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.get_sentences_txt_file_path": [[128, 134], ["os.makedirs", "os.path.join"], "function", ["None"], ["", "def", "get_sentences_txt_file_path", "(", "output_folder_path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_folder_path", ",", "exist_ok", "=", "True", ")", "\n", "file_name", "=", "\"sentences.jsonl\"", "\n", "path_to_file", "=", "os", ".", "path", ".", "join", "(", "output_folder_path", ",", "file_name", ")", "\n", "\n", "return", "path_to_file", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.get_end2end_pickle_output_file_path": [[136, 142], ["os.makedirs", "os.path.join"], "function", ["None"], ["", "def", "get_end2end_pickle_output_file_path", "(", "output_folder_path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_folder_path", ",", "exist_ok", "=", "True", ")", "\n", "file_name", "=", "\"mentions_and_sentences.pickle\"", "\n", "path_to_file", "=", "os", ".", "path", ".", "join", "(", "output_folder_path", ",", "file_name", ")", "\n", "\n", "return", "path_to_file", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.write_end2end_pickle_output": [[144, 148], ["open", "pickle.dump", "utils.get_end2end_pickle_output_file_path"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.get_end2end_pickle_output_file_path"], ["", "def", "write_end2end_pickle_output", "(", "sentences", ",", "mentions", ",", "output_file_id", ")", ":", "\n", "    ", "obj", "=", "{", "\"sentences\"", ":", "sentences", ",", "\"mentions\"", ":", "mentions", "}", "\n", "with", "open", "(", "get_end2end_pickle_output_file_path", "(", "output_file_id", ")", ",", "\"wb\"", ")", "as", "file", ":", "\n", "        ", "pickle", ".", "dump", "(", "obj", ",", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.utils.get_end2end_pretty_output_file_path": [[150, 155], ["os.makedirs", "os.path.join"], "function", ["None"], ["", "", "def", "get_end2end_pretty_output_file_path", "(", "output_folder_path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_folder_path", ",", "exist_ok", "=", "True", ")", "\n", "file_name", "=", "\"pretty.txt\"", "\n", "path_to_file", "=", "os", ".", "path", ".", "join", "(", "output_folder_path", ",", "file_name", ")", "\n", "return", "path_to_file", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.blink.build_faiss_index.main": [[19, 43], ["os.path.split", "blink.get_logger", "utils.get_logger.info", "torch.load", "torch.load.size", "utils.get_logger.info", "blink.indexer.faiss_indexer.DenseFlatIndexer.index_data", "utils.get_logger.info", "params.get", "os.path.exists", "os.makedirs", "utils.get_logger.info", "blink.indexer.faiss_indexer.DenseHNSWFlatIndexer", "utils.get_logger.info", "blink.indexer.faiss_indexer.DenseFlatIndexer", "torch.load.numpy", "blink.indexer.faiss_indexer.DenseFlatIndexer.serialize"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.get_logger", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseHNSWFlatIndexer.index_data", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanSerializer.serialize"], ["def", "main", "(", "params", ")", ":", "\n", "    ", "output_path", "=", "params", "[", "\"output_path\"", "]", "\n", "output_dir", ",", "_", "=", "os", ".", "path", ".", "split", "(", "output_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "logger", "=", "utils", ".", "get_logger", "(", "output_dir", ")", "\n", "\n", "logger", ".", "info", "(", "\"Loading candidate encoding from path: %s\"", "%", "params", "[", "\"candidate_encoding\"", "]", ")", "\n", "candidate_encoding", "=", "torch", ".", "load", "(", "params", "[", "\"candidate_encoding\"", "]", ")", "\n", "vector_size", "=", "candidate_encoding", ".", "size", "(", "1", ")", "\n", "index_buffer", "=", "params", "[", "\"index_buffer\"", "]", "\n", "if", "params", "[", "\"hnsw\"", "]", ":", "\n", "        ", "logger", ".", "info", "(", "\"Using HNSW index in FAISS\"", ")", "\n", "index", "=", "DenseHNSWFlatIndexer", "(", "vector_size", ",", "index_buffer", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Using Flat index in FAISS\"", ")", "\n", "index", "=", "DenseFlatIndexer", "(", "vector_size", ",", "index_buffer", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Building index.\"", ")", "\n", "index", ".", "index_data", "(", "candidate_encoding", ".", "numpy", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"Done indexing data.\"", ")", "\n", "\n", "if", "params", ".", "get", "(", "\"save_index\"", ",", "None", ")", ":", "\n", "        ", "index", ".", "serialize", "(", "output_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.__init__": [[223, 272], ["super().__init__", "pytorch_transformers.modeling_bert.BertModel.from_pretrained", "pytorch_transformers.modeling_bert.BertModel.from_pretrained", "elq.common.ranker_base.BertEncoder", "elq.common.ranker_base.BertEncoder", "params.get", "pytorch_transformers.modeling_bert.BertModel.from_pretrained.embeddings.word_embeddings.weight.size", "params.get", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "biencoder.BiEncoderModule.cand_encoder.parameters", "biencoder.MentionScoresHead", "torch.ModuleDict", "torch.ModuleDict", "torch.ModuleDict", "biencoder.GetContextEmbedsHead", "params.get", "pytorch_transformers.modeling_bert.BertModel.from_pretrained.embeddings.word_embeddings.weight.size", "torch.Linear", "torch.Linear", "torch.Linear", "pytorch_transformers.modeling_bert.BertModel.from_pretrained.embeddings.word_embeddings.weight.size", "pytorch_transformers.modeling_bert.BertModel.from_pretrained.embeddings.word_embeddings.weight.size"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.forward": [[480, 517], ["biencoder.BiEncoderModule.forward_ctxt", "biencoder.BiEncoderModule.forward_candidate"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.forward_ctxt", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.forward_candidate"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.__init__": [[550, 576], ["super().__init__", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "pytorch_transformers.tokenization_bert.BertTokenizer.from_pretrained", "biencoder.BiEncoderRanker.build_model", "params.get", "biencoder.BiEncoderRanker.model.to", "params.get", "biencoder.BiEncoderRanker.load_model", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "params.get"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.build_model", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.load_model"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.load_model": [[577, 588], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "biencoder.get_submodel_from_state_dict", "biencoder.BiEncoderRanker.model.cand_encoder.load_state_dict", "biencoder.BiEncoderRanker.model.upgrade_state_dict_named", "biencoder.BiEncoderRanker.model.load_state_dict", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.get_submodel_from_state_dict", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.upgrade_state_dict_named"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.build_model": [[589, 591], ["biencoder.BiEncoderModule"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.save_model": [[592, 600], ["elq.common.ranker_base.get_model_obj", "os.path.join", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "elq.common.ranker_base.get_model_obj.config.to_json_file", "os.path.exists", "os.makedirs", "elq.common.ranker_base.get_model_obj.state_dict"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.common.ranker_base.get_model_obj", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.get_optimizer": [[601, 607], ["blink.common.optimizer.get_bert_optimizer", "biencoder.BiEncoderRanker.params.get"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.common.optimizer.get_bert_optimizer"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.encode_context": [[609, 690], ["biencoder.to_bert_input", "biencoder.BiEncoderRanker.model", "cands.size", "[].max", "range", "context_outs[].size", "biencoder.BiEncoderRanker.encode_context.init_tensor"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.to_bert_input", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.encode_candidate": [[691, 700], ["biencoder.to_bert_input", "biencoder.BiEncoderRanker.model"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.to_bert_input"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.score_candidate": [[703, 787], ["biencoder.BiEncoderRanker.encode_context", "cand_vecs[].squeeze", "biencoder.BiEncoderRanker.encode_candidate", "embedding_ctxt.unsqueeze.unsqueeze.unsqueeze", "embedding_cands.unsqueeze.unsqueeze.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "torch.squeeze", "embedding_ctxt.unsqueeze.unsqueeze.mm", "embedding_cands.unsqueeze.unsqueeze.t"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.encode_context", "home.repos.pwc.inspect_result.chenllliang_atp.scripts.generate_candidates.encode_candidate"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.forward": [[791, 877], ["biencoder.BiEncoderRanker.score_candidate", "context_input.size", "gold_mention_bounds.size", "biencoder.BiEncoderRanker.get_span_loss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "target.to.to.to", "torch.BCEWithLogitsLoss.", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "label_input.float", "scores.size"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.score_candidate", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.get_span_loss", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.load_biencoder": [[29, 33], ["biencoder.BiEncoderRanker"], "function", ["None"], ["return", "biencoder", "\n", "\n", "\n", "", "class", "BiEncoderModule", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.to_bert_input": [[914, 923], ["mask.long"], "function", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.__init__": [[71, 79], ["len", "range", "zeshel_utils.Stats.hits.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "top_k", "=", "1000", ")", ":", "\n", "        ", "self", ".", "cnt", "=", "0", "\n", "self", ".", "hits", "=", "[", "]", "\n", "self", ".", "top_k", "=", "top_k", "\n", "self", ".", "rank", "=", "[", "1", ",", "4", ",", "8", ",", "16", ",", "32", ",", "64", ",", "100", ",", "128", ",", "256", ",", "512", "]", "\n", "self", ".", "LEN", "=", "len", "(", "self", ".", "rank", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "LEN", ")", ":", "\n", "            ", "self", ".", "hits", ".", "append", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add": [[80, 87], ["range"], "methods", ["None"], ["", "", "def", "add", "(", "self", ",", "idx", ")", ":", "\n", "        ", "self", ".", "cnt", "+=", "1", "\n", "if", "idx", "==", "-", "1", ":", "\n", "            ", "return", "\n", "", "for", "i", "in", "range", "(", "self", ".", "LEN", ")", ":", "\n", "            ", "if", "idx", "<", "self", ".", "rank", "[", "i", "]", ":", "\n", "                ", "self", ".", "hits", "[", "i", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend": [[88, 92], ["range"], "methods", ["None"], ["", "", "", "def", "extend", "(", "self", ",", "stats", ")", ":", "\n", "        ", "self", ".", "cnt", "+=", "stats", ".", "cnt", "\n", "for", "i", "in", "range", "(", "self", ".", "LEN", ")", ":", "\n", "            ", "self", ".", "hits", "[", "i", "]", "+=", "stats", ".", "hits", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.output": [[93, 100], ["range", "float"], "methods", ["None"], ["", "", "def", "output", "(", "self", ")", ":", "\n", "        ", "output_json", "=", "\"Total: %d examples.\"", "%", "self", ".", "cnt", "\n", "for", "i", "in", "range", "(", "self", ".", "LEN", ")", ":", "\n", "            ", "if", "self", ".", "top_k", "<", "self", ".", "rank", "[", "i", "]", ":", "\n", "                ", "break", "\n", "", "output_json", "+=", "\" r@%d: %.4f\"", "%", "(", "self", ".", "rank", "[", "i", "]", ",", "self", ".", "hits", "[", "i", "]", "/", "float", "(", "self", ".", "cnt", ")", ")", "\n", "", "return", "output_json", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.load_entity_dict_zeshel": [[36, 68], ["enumerate", "logger.info", "open", "line.rstrip.rstrip", "json.loads", "doc_list.append", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads"], ["def", "load_entity_dict_zeshel", "(", "logger", ",", "params", ")", ":", "\n", "    ", "entity_dict", "=", "{", "}", "\n", "# different worlds in train/valid/test", "\n", "if", "params", "[", "\"mode\"", "]", "==", "\"train\"", ":", "\n", "        ", "start_idx", "=", "0", "\n", "end_idx", "=", "8", "\n", "", "elif", "params", "[", "\"mode\"", "]", "==", "\"valid\"", ":", "\n", "        ", "start_idx", "=", "8", "\n", "end_idx", "=", "12", "\n", "", "else", ":", "\n", "        ", "start_idx", "=", "12", "\n", "end_idx", "=", "16", "\n", "# load data", "\n", "", "for", "i", ",", "src", "in", "enumerate", "(", "WORLDS", "[", "start_idx", ":", "end_idx", "]", ")", ":", "\n", "        ", "fname", "=", "DOC_PATH", "+", "src", "+", "\".json\"", "\n", "cur_dict", "=", "{", "}", "\n", "doc_list", "=", "[", "]", "\n", "src_id", "=", "world_to_id", "[", "src", "]", "\n", "with", "open", "(", "fname", ",", "'rt'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "item", "=", "json", ".", "loads", "(", "line", ")", "\n", "text", "=", "item", "[", "\"text\"", "]", "\n", "doc_list", ".", "append", "(", "text", "[", ":", "256", "]", ")", "\n", "\n", "if", "params", "[", "\"debug\"", "]", ":", "\n", "                    ", "if", "len", "(", "doc_list", ")", ">", "200", ":", "\n", "                        ", "break", "\n", "\n", "", "", "", "", "logger", ".", "info", "(", "\"Load for world %s.\"", "%", "src", ")", "\n", "entity_dict", "[", "src_id", "]", "=", "doc_list", "\n", "", "return", "entity_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.eval_biencoder.load_entity_dict": [[27, 46], ["params.get", "logger.info", "blink.biencoder.zeshel_utils.load_entity_dict_zeshel", "open", "json.loads", "json.loads.get().strip", "entity_list.append", "line.rstrip", "json.loads.get", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.load_entity_dict_zeshel", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads"], ["def", "load_entity_dict", "(", "logger", ",", "params", ",", "is_zeshel", ")", ":", "\n", "    ", "if", "is_zeshel", ":", "\n", "        ", "return", "load_entity_dict_zeshel", "(", "logger", ",", "params", ")", "\n", "\n", "", "path", "=", "params", ".", "get", "(", "\"entity_dict_path\"", ",", "None", ")", "\n", "assert", "path", "is", "not", "None", ",", "\"Error! entity_dict_path is empty.\"", "\n", "\n", "entity_list", "=", "[", "]", "\n", "logger", ".", "info", "(", "\"Loading entity description from path: \"", "+", "path", ")", "\n", "with", "open", "(", "path", ",", "'rt'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "sample", "=", "json", ".", "loads", "(", "line", ".", "rstrip", "(", ")", ")", "\n", "title", "=", "sample", "[", "'title'", "]", "\n", "text", "=", "sample", ".", "get", "(", "\"text\"", ",", "\"\"", ")", ".", "strip", "(", ")", "\n", "entity_list", ".", "append", "(", "(", "title", ",", "text", ")", ")", "\n", "if", "params", "[", "\"debug\"", "]", "and", "len", "(", "entity_list", ")", ">", "200", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "return", "entity_list", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.eval_biencoder.get_candidate_pool_tensor_zeshel": [[49, 68], ["range", "len", "logger.info", "eval_biencoder.get_candidate_pool_tensor", "entity_dict.get"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.eval_biencoder.get_candidate_pool_tensor"], ["", "def", "get_candidate_pool_tensor_zeshel", "(", "\n", "entity_dict", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "logger", ",", "\n", ")", ":", "\n", "    ", "candidate_pool", "=", "{", "}", "\n", "for", "src", "in", "range", "(", "len", "(", "WORLDS", ")", ")", ":", "\n", "        ", "if", "entity_dict", ".", "get", "(", "src", ",", "None", ")", "is", "None", ":", "\n", "            ", "continue", "\n", "", "logger", ".", "info", "(", "\"Get candidate desc to id for pool %s\"", "%", "WORLDS", "[", "src", "]", ")", "\n", "candidate_pool", "[", "src", "]", "=", "get_candidate_pool_tensor", "(", "\n", "entity_dict", "[", "src", "]", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "logger", ",", "\n", ")", "\n", "\n", "", "return", "candidate_pool", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.eval_biencoder.get_candidate_pool_tensor_helper": [[70, 90], ["eval_biencoder.get_candidate_pool_tensor_zeshel", "eval_biencoder.get_candidate_pool_tensor"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.eval_biencoder.get_candidate_pool_tensor_zeshel", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.eval_biencoder.get_candidate_pool_tensor"], ["", "def", "get_candidate_pool_tensor_helper", "(", "\n", "entity_desc_list", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "logger", ",", "\n", "is_zeshel", ",", "\n", ")", ":", "\n", "    ", "if", "is_zeshel", ":", "\n", "        ", "return", "get_candidate_pool_tensor_zeshel", "(", "\n", "entity_desc_list", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "logger", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "return", "get_candidate_pool_tensor", "(", "\n", "entity_desc_list", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "logger", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.eval_biencoder.get_candidate_pool_tensor": [[93, 119], ["logger.info", "tqdm.tqdm", "torch.LongTensor", "blink.get_candidate_representation", "torch.LongTensor.append", "type"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.get_candidate_representation"], ["", "", "def", "get_candidate_pool_tensor", "(", "\n", "entity_desc_list", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "logger", ",", "\n", ")", ":", "\n", "# TODO: add multiple thread process", "\n", "    ", "logger", ".", "info", "(", "\"Convert candidate text to id\"", ")", "\n", "cand_pool", "=", "[", "]", "\n", "for", "entity_desc", "in", "tqdm", "(", "entity_desc_list", ")", ":", "\n", "        ", "if", "type", "(", "entity_desc", ")", "is", "tuple", ":", "\n", "            ", "title", ",", "entity_text", "=", "entity_desc", "\n", "", "else", ":", "\n", "            ", "title", "=", "None", "\n", "entity_text", "=", "entity_desc", "\n", "\n", "", "rep", "=", "data", ".", "get_candidate_representation", "(", "\n", "entity_text", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "title", ",", "\n", ")", "\n", "cand_pool", ".", "append", "(", "rep", "[", "\"ids\"", "]", ")", "\n", "\n", "", "cand_pool", "=", "torch", ".", "LongTensor", "(", "cand_pool", ")", "\n", "return", "cand_pool", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.eval_biencoder.encode_candidate": [[121, 167], ["reranker.model.eval", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "enumerate", "candidate_pool.items", "tqdm.tqdm", "cands.to.to", "reranker.encode_candidate", "logger.info", "eval_biencoder.encode_candidate", "torch.cat"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.scripts.generate_candidates.encode_candidate", "home.repos.pwc.inspect_result.chenllliang_atp.scripts.generate_candidates.encode_candidate"], ["", "def", "encode_candidate", "(", "\n", "reranker", ",", "\n", "candidate_pool", ",", "\n", "encode_batch_size", ",", "\n", "silent", ",", "\n", "logger", ",", "\n", "is_zeshel", ",", "\n", ")", ":", "\n", "    ", "if", "is_zeshel", ":", "\n", "        ", "src", "=", "0", "\n", "cand_encode_dict", "=", "{", "}", "\n", "for", "src", ",", "cand_pool", "in", "candidate_pool", ".", "items", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Encoding candidate pool %s\"", "%", "WORLDS", "[", "src", "]", ")", "\n", "cand_pool_encode", "=", "encode_candidate", "(", "\n", "reranker", ",", "\n", "cand_pool", ",", "\n", "encode_batch_size", ",", "\n", "silent", ",", "\n", "logger", ",", "\n", "is_zeshel", "=", "False", ",", "\n", ")", "\n", "cand_encode_dict", "[", "src", "]", "=", "cand_pool_encode", "\n", "", "return", "cand_encode_dict", "\n", "\n", "", "reranker", ".", "model", ".", "eval", "(", ")", "\n", "device", "=", "reranker", ".", "device", "\n", "sampler", "=", "SequentialSampler", "(", "candidate_pool", ")", "\n", "data_loader", "=", "DataLoader", "(", "\n", "candidate_pool", ",", "sampler", "=", "sampler", ",", "batch_size", "=", "encode_batch_size", "\n", ")", "\n", "if", "silent", ":", "\n", "        ", "iter_", "=", "data_loader", "\n", "", "else", ":", "\n", "        ", "iter_", "=", "tqdm", "(", "data_loader", ")", "\n", "\n", "", "cand_encode_list", "=", "None", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_", ")", ":", "\n", "        ", "cands", "=", "batch", "\n", "cands", "=", "cands", ".", "to", "(", "device", ")", "\n", "cand_encode", "=", "reranker", ".", "encode_candidate", "(", "cands", ")", "\n", "if", "cand_encode_list", "is", "None", ":", "\n", "            ", "cand_encode_list", "=", "cand_encode", "\n", "", "else", ":", "\n", "            ", "cand_encode_list", "=", "torch", ".", "cat", "(", "(", "cand_encode_list", ",", "cand_encode", ")", ")", "\n", "\n", "", "", "return", "cand_encode_list", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.eval_biencoder.load_or_generate_candidate_pool": [[169, 202], ["params.get", "eval_biencoder.load_entity_dict", "eval_biencoder.get_candidate_pool_tensor_helper", "logger.info", "logger.info", "torch.load", "logger.info", "torch.save", "logger.info"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.zeshel.create_BLINK_zeshel_data.load_entity_dict", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.eval_biencoder.get_candidate_pool_tensor_helper", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save"], ["", "def", "load_or_generate_candidate_pool", "(", "\n", "tokenizer", ",", "\n", "params", ",", "\n", "logger", ",", "\n", "cand_pool_path", ",", "\n", ")", ":", "\n", "    ", "candidate_pool", "=", "None", "\n", "is_zeshel", "=", "params", ".", "get", "(", "\"zeshel\"", ",", "None", ")", "\n", "if", "cand_pool_path", "is", "not", "None", ":", "\n", "# try to load candidate pool from file", "\n", "        ", "try", ":", "\n", "            ", "logger", ".", "info", "(", "\"Loading pre-generated candidate pool from: \"", ")", "\n", "logger", ".", "info", "(", "cand_pool_path", ")", "\n", "candidate_pool", "=", "torch", ".", "load", "(", "cand_pool_path", ")", "\n", "", "except", ":", "\n", "            ", "logger", ".", "info", "(", "\"Loading failed. Generating candidate pool\"", ")", "\n", "\n", "", "", "if", "candidate_pool", "is", "None", ":", "\n", "# compute candidate pool from entity list", "\n", "        ", "entity_desc_list", "=", "load_entity_dict", "(", "logger", ",", "params", ",", "is_zeshel", ")", "\n", "candidate_pool", "=", "get_candidate_pool_tensor_helper", "(", "\n", "entity_desc_list", ",", "\n", "tokenizer", ",", "\n", "params", "[", "\"max_cand_length\"", "]", ",", "\n", "logger", ",", "\n", "is_zeshel", ",", "\n", ")", "\n", "\n", "if", "cand_pool_path", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving candidate pool.\"", ")", "\n", "torch", ".", "save", "(", "candidate_pool", ",", "cand_pool_path", ")", "\n", "\n", "", "", "return", "candidate_pool", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.eval_biencoder.main": [[204, 298], ["blink.get_logger", "blink.biencoder.biencoder.BiEncoderRanker", "params.get", "params.get", "eval_biencoder.load_or_generate_candidate_pool", "blink.read_dataset", "utils.get_logger.info", "blink.process_mention_data", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "params.get", "blink.get_topk_predictions", "os.path.exists", "os.makedirs", "eval_biencoder.encode_candidate", "params.get", "os.path.join", "os.path.join", "torch.save", "utils.get_logger.info", "torch.load", "utils.get_logger.info", "torch.save", "len", "os.path.exists", "os.makedirs", "utils.get_logger.info", "params.get"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.get_logger", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.eval_biencoder.load_or_generate_candidate_pool", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.read_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.process_mention_data", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.nn_prediction.get_topk_predictions", "home.repos.pwc.inspect_result.chenllliang_atp.scripts.generate_candidates.encode_candidate", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save"], ["", "def", "main", "(", "params", ")", ":", "\n", "    ", "output_path", "=", "params", "[", "\"output_path\"", "]", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_path", ")", "\n", "", "logger", "=", "utils", ".", "get_logger", "(", "params", "[", "\"output_path\"", "]", ")", "\n", "\n", "# Init model ", "\n", "reranker", "=", "BiEncoderRanker", "(", "params", ")", "\n", "tokenizer", "=", "reranker", ".", "tokenizer", "\n", "model", "=", "reranker", ".", "model", "\n", "\n", "device", "=", "reranker", ".", "device", "\n", "\n", "cand_encode_path", "=", "params", ".", "get", "(", "\"cand_encode_path\"", ",", "None", ")", "\n", "\n", "# candidate encoding is not pre-computed. ", "\n", "# load/generate candidate pool to compute candidate encoding.", "\n", "cand_pool_path", "=", "params", ".", "get", "(", "\"cand_pool_path\"", ",", "None", ")", "\n", "candidate_pool", "=", "load_or_generate_candidate_pool", "(", "\n", "tokenizer", ",", "\n", "params", ",", "\n", "logger", ",", "\n", "cand_pool_path", ",", "\n", ")", "\n", "\n", "candidate_encoding", "=", "None", "\n", "if", "cand_encode_path", "is", "not", "None", ":", "\n", "# try to load candidate encoding from path", "\n", "# if success, avoid computing candidate encoding", "\n", "        ", "try", ":", "\n", "            ", "logger", ".", "info", "(", "\"Loading pre-generated candidate encode path.\"", ")", "\n", "candidate_encoding", "=", "torch", ".", "load", "(", "cand_encode_path", ")", "\n", "", "except", ":", "\n", "            ", "logger", ".", "info", "(", "\"Loading failed. Generating candidate encoding.\"", ")", "\n", "\n", "", "", "if", "candidate_encoding", "is", "None", ":", "\n", "        ", "candidate_encoding", "=", "encode_candidate", "(", "\n", "reranker", ",", "\n", "candidate_pool", ",", "\n", "params", "[", "\"encode_batch_size\"", "]", ",", "\n", "silent", "=", "params", "[", "\"silent\"", "]", ",", "\n", "logger", "=", "logger", ",", "\n", "is_zeshel", "=", "params", ".", "get", "(", "\"zeshel\"", ",", "None", ")", "\n", "\n", ")", "\n", "\n", "if", "cand_encode_path", "is", "not", "None", ":", "\n", "# Save candidate encoding to avoid re-compute", "\n", "            ", "logger", ".", "info", "(", "\"Saving candidate encoding to file \"", "+", "cand_encode_path", ")", "\n", "torch", ".", "save", "(", "candidate_encoding", ",", "cand_encode_path", ")", "\n", "\n", "\n", "", "", "test_samples", "=", "utils", ".", "read_dataset", "(", "params", "[", "\"mode\"", "]", ",", "params", "[", "\"data_path\"", "]", ")", "\n", "logger", ".", "info", "(", "\"Read %d test samples.\"", "%", "len", "(", "test_samples", ")", ")", "\n", "\n", "test_data", ",", "test_tensor_data", "=", "data", ".", "process_mention_data", "(", "\n", "test_samples", ",", "\n", "tokenizer", ",", "\n", "params", "[", "\"max_context_length\"", "]", ",", "\n", "params", "[", "\"max_cand_length\"", "]", ",", "\n", "context_key", "=", "params", "[", "'context_key'", "]", ",", "\n", "silent", "=", "params", "[", "\"silent\"", "]", ",", "\n", "logger", "=", "logger", ",", "\n", "debug", "=", "params", "[", "\"debug\"", "]", ",", "\n", ")", "\n", "test_sampler", "=", "SequentialSampler", "(", "test_tensor_data", ")", "\n", "test_dataloader", "=", "DataLoader", "(", "\n", "test_tensor_data", ",", "\n", "sampler", "=", "test_sampler", ",", "\n", "batch_size", "=", "params", "[", "\"eval_batch_size\"", "]", "\n", ")", "\n", "\n", "save_results", "=", "params", ".", "get", "(", "\"save_topk_result\"", ")", "\n", "new_data", "=", "nnquery", ".", "get_topk_predictions", "(", "\n", "reranker", ",", "\n", "test_dataloader", ",", "\n", "candidate_pool", ",", "\n", "candidate_encoding", ",", "\n", "params", "[", "\"silent\"", "]", ",", "\n", "logger", ",", "\n", "params", "[", "\"top_k\"", "]", ",", "\n", "params", ".", "get", "(", "\"zeshel\"", ",", "None", ")", ",", "\n", "save_results", ",", "\n", ")", "\n", "\n", "if", "save_results", ":", "\n", "        ", "save_data_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "params", "[", "'output_path'", "]", ",", "\n", "\"top%d_candidates\"", "%", "params", "[", "'top_k'", "]", ",", "\n", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_data_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "save_data_dir", ")", "\n", "", "save_data_path", "=", "os", ".", "path", ".", "join", "(", "save_data_dir", ",", "\"%s.t7\"", "%", "params", "[", "'mode'", "]", ")", "\n", "torch", ".", "save", "(", "new_data", ",", "save_data_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.train_biencoder.evaluate": [[49, 168], ["reranker.model.eval", "enumerate", "logger.info", "logger.info", "logger.info", "tqdm.tqdm", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "cand_encs.to.to", "tuple", "batch[].cpu().numpy", "batch[].cpu().numpy", "cand_encs.to.to", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "logger.info", "batch[].cpu().numpy", "torch.no_grad", "torch.no_grad", "t.to", "batch[].cpu", "batch[].cpu", "reranker.encode_context", "context_outs[].cpu().numpy", "context_outs[].cpu().numpy", "context_outs[].cpu().numpy", "faiss_index.search_knn", "numpy.zeros", "numpy.zeros_like", "enumerate", "reranker", "logits.cpu().numpy.cpu().numpy", "torch.LongTensor", "torch.LongTensor", "label_ids.cpu().numpy.cpu().numpy", "elq.accuracy", "len", "len", "batch[].cpu", "elq.vcg_utils.measures.entity_linking_tp_with_overlap", "float", "float", "torch.arange", "torch.arange", "context_outs[].cpu", "context_outs[].cpu", "context_outs[].cpu", "numpy.log", "torch.sigmoid().log().cpu().numpy", "torch.sigmoid().log().cpu().numpy", "len", "len", "logits.cpu().numpy.cpu", "label_ids.cpu().numpy.cpu", "scipy.special.softmax", "str", "range", "str", "range", "torch.sigmoid().log().cpu", "torch.sigmoid().log().cpu", "len", "len", "torch.sigmoid().log", "torch.sigmoid().log", "torch.sigmoid", "torch.sigmoid", "context_outs[].unsqueeze"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.encode_context", "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseHNSWFlatIndexer.search_knn", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.accuracy", "home.repos.pwc.inspect_result.chenllliang_atp.vcg_utils.measures.entity_linking_tp_with_overlap"], ["if", "params", "[", "\"silent\"", "]", ":", "\n", "        ", "iter_", "=", "eval_dataloader", "\n", "", "else", ":", "\n", "        ", "iter_", "=", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluation\"", ")", "\n", "\n", "", "results", "=", "{", "}", "\n", "\n", "eval_accuracy", "=", "0.0", "\n", "nb_eval_examples", "=", "0", "\n", "nb_eval_steps", "=", "0", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_", ")", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "context_input", ",", "candidate_input", ",", "_", ",", "_", "=", "batch", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "eval_loss", ",", "logits", "=", "reranker", "(", "context_input", ",", "candidate_input", ")", "\n", "\n", "", "logits", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# Using in-batch negatives, the label ids are diagonal", "\n", "label_ids", "=", "torch", ".", "LongTensor", "(", "\n", "torch", ".", "arange", "(", "params", "[", "\"eval_batch_size\"", "]", ")", "\n", ")", ".", "numpy", "(", ")", "\n", "tmp_eval_accuracy", ",", "_", "=", "utils", ".", "accuracy", "(", "logits", ",", "label_ids", ")", "\n", "\n", "eval_accuracy", "+=", "tmp_eval_accuracy", "\n", "\n", "nb_eval_examples", "+=", "context_input", ".", "size", "(", "0", ")", "\n", "nb_eval_steps", "+=", "1", "\n", "\n", "", "normalized_eval_accuracy", "=", "eval_accuracy", "/", "nb_eval_examples", "\n", "logger", ".", "info", "(", "\"Eval accuracy: %.5f\"", "%", "normalized_eval_accuracy", ")", "\n", "results", "[", "\"normalized_accuracy\"", "]", "=", "normalized_eval_accuracy", "\n", "return", "results", "\n", "\n", "\n", "", "def", "get_optimizer", "(", "model", ",", "params", ")", ":", "\n", "    ", "return", "get_bert_optimizer", "(", "\n", "[", "model", "]", ",", "\n", "params", "[", "\"type_optimization\"", "]", ",", "\n", "params", "[", "\"learning_rate\"", "]", ",", "\n", "fp16", "=", "params", ".", "get", "(", "\"fp16\"", ")", ",", "\n", ")", "\n", "\n", "\n", "", "def", "get_scheduler", "(", "params", ",", "optimizer", ",", "len_train_data", ",", "logger", ")", ":", "\n", "    ", "batch_size", "=", "params", "[", "\"train_batch_size\"", "]", "\n", "grad_acc", "=", "params", "[", "\"gradient_accumulation_steps\"", "]", "\n", "epochs", "=", "params", "[", "\"num_train_epochs\"", "]", "\n", "\n", "num_train_steps", "=", "int", "(", "len_train_data", "/", "batch_size", "/", "grad_acc", ")", "*", "epochs", "\n", "num_warmup_steps", "=", "int", "(", "num_train_steps", "*", "params", "[", "\"warmup_proportion\"", "]", ")", "\n", "\n", "scheduler", "=", "WarmupLinearSchedule", "(", "\n", "optimizer", ",", "warmup_steps", "=", "num_warmup_steps", ",", "t_total", "=", "num_train_steps", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\" Num optimization steps = %d\"", "%", "num_train_steps", ")", "\n", "logger", ".", "info", "(", "\" Num warmup steps = %d\"", ",", "num_warmup_steps", ")", "\n", "return", "scheduler", "\n", "\n", "\n", "", "def", "main", "(", "params", ")", ":", "\n", "    ", "model_output_path", "=", "params", "[", "\"output_path\"", "]", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_output_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_output_path", ")", "\n", "", "logger", "=", "utils", ".", "get_logger", "(", "params", "[", "\"output_path\"", "]", ")", "\n", "\n", "# Init model", "\n", "reranker", "=", "BiEncoderRanker", "(", "params", ")", "\n", "tokenizer", "=", "reranker", ".", "tokenizer", "\n", "model", "=", "reranker", ".", "model", "\n", "\n", "device", "=", "reranker", ".", "device", "\n", "n_gpu", "=", "reranker", ".", "n_gpu", "\n", "\n", "if", "params", "[", "\"gradient_accumulation_steps\"", "]", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\"", ".", "format", "(", "\n", "params", "[", "\"gradient_accumulation_steps\"", "]", "\n", ")", "\n", ")", "\n", "\n", "# An effective batch size of `x`, when we are accumulating the gradient accross `y` batches will be achieved by having a batch size of `z = x / y`", "\n", "# args.gradient_accumulation_steps = args.gradient_accumulation_steps // n_gpu", "\n", "", "params", "[", "\"train_batch_size\"", "]", "=", "(", "\n", "params", "[", "\"train_batch_size\"", "]", "//", "params", "[", "\"gradient_accumulation_steps\"", "]", "\n", ")", "\n", "train_batch_size", "=", "params", "[", "\"train_batch_size\"", "]", "\n", "eval_batch_size", "=", "params", "[", "\"eval_batch_size\"", "]", "\n", "grad_acc_steps", "=", "params", "[", "\"gradient_accumulation_steps\"", "]", "\n", "\n", "# Fix the random seeds", "\n", "seed", "=", "params", "[", "\"seed\"", "]", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "reranker", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n", "# Load train data", "\n", "", "train_samples", "=", "utils", ".", "read_dataset", "(", "\"train\"", ",", "params", "[", "\"data_path\"", "]", ")", "\n", "logger", ".", "info", "(", "\"Read %d train samples.\"", "%", "len", "(", "train_samples", ")", ")", "\n", "\n", "train_data", ",", "train_tensor_data", "=", "data", ".", "process_mention_data", "(", "\n", "train_samples", ",", "\n", "tokenizer", ",", "\n", "params", "[", "\"max_context_length\"", "]", ",", "\n", "params", "[", "\"max_cand_length\"", "]", ",", "\n", "context_key", "=", "params", "[", "\"context_key\"", "]", ",", "\n", "silent", "=", "params", "[", "\"silent\"", "]", ",", "\n", "logger", "=", "logger", ",", "\n", "debug", "=", "params", "[", "\"debug\"", "]", ",", "\n", ")", "\n", "if", "params", "[", "\"shuffle\"", "]", ":", "\n", "        ", "train_sampler", "=", "RandomSampler", "(", "train_tensor_data", ")", "\n", "", "else", ":", "\n", "        ", "train_sampler", "=", "SequentialSampler", "(", "train_tensor_data", ")", "\n", "\n", "", "train_dataloader", "=", "DataLoader", "(", "\n", "train_tensor_data", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "train_batch_size", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.train_biencoder.get_optimizer": [[170, 176], ["blink.common.optimizer.get_bert_optimizer", "params.get"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.common.optimizer.get_bert_optimizer"], ["# Load eval data", "\n", "# TODO: reduce duplicated code here", "\n", "valid_samples", "=", "utils", ".", "read_dataset", "(", "\"valid\"", ",", "params", "[", "\"data_path\"", "]", ")", "\n", "logger", ".", "info", "(", "\"Read %d valid samples.\"", "%", "len", "(", "valid_samples", ")", ")", "\n", "\n", "valid_data", ",", "valid_tensor_data", "=", "data", ".", "process_mention_data", "(", "\n", "valid_samples", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.train_biencoder.get_scheduler": [[179, 193], ["int", "pytorch_transformers.optimization.WarmupLinearSchedule", "logger.info", "logger.info", "int"], "function", ["None"], ["params", "[", "\"max_cand_length\"", "]", ",", "\n", "context_key", "=", "params", "[", "\"context_key\"", "]", ",", "\n", "silent", "=", "params", "[", "\"silent\"", "]", ",", "\n", "logger", "=", "logger", ",", "\n", "debug", "=", "params", "[", "\"debug\"", "]", ",", "\n", ")", "\n", "valid_sampler", "=", "SequentialSampler", "(", "valid_tensor_data", ")", "\n", "valid_dataloader", "=", "DataLoader", "(", "\n", "valid_tensor_data", ",", "sampler", "=", "valid_sampler", ",", "batch_size", "=", "eval_batch_size", "\n", ")", "\n", "\n", "# evaluate before training", "\n", "results", "=", "evaluate", "(", "\n", "reranker", ",", "valid_dataloader", ",", "params", ",", "device", "=", "device", ",", "logger", "=", "logger", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.train_biencoder.main": [[195, 581], ["elq.get_logger", "elq.biencoder.biencoder.BiEncoderRanker", "random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "elq.read_dataset", "utils.get_logger.info", "utils.get_logger.info", "utils.get_logger.info", "elq.biencoder.data_process.process_mention_data", "torch.utils.data.TensorDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "train_biencoder.evaluate", "time.time", "elq.write_to_file", "utils.get_logger.info", "utils.get_logger.info", "params.get", "train_biencoder.get_optimizer", "train_biencoder.get_scheduler", "model.train", "utils.get_logger.info", "tqdm.trange", "elq.write_to_file", "utils.get_logger.info", "utils.get_logger.info", "os.path.join", "elq.save_model", "os.path.exists", "os.makedirs", "ValueError", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "elq.read_dataset", "len", "torch.load", "torch.load", "utils.get_logger.info", "elq.index.faiss_indexer.DenseHNSWFlatIndexer", "elq.index.faiss_indexer.DenseHNSWFlatIndexer.deserialize_from", "utils.get_logger.info", "os.path.join", "str", "len", "elq.biencoder.data_process.process_mention_data", "utils.get_logger.info", "os.path.exists", "torch.load", "torch.load", "get_optimizer.load_state_dict", "get_scheduler.load_state_dict", "utils.get_logger.info", "int", "torch.utils.data.TensorDataset", "torch.utils.data.DataLoader", "enumerate", "utils.get_logger.info", "os.path.join", "elq.save_model", "torch.save", "torch.save", "os.path.join", "utils.get_logger.info", "train_biencoder.evaluate", "utils.get_logger.info", "train_biencoder.evaluate", "utils.get_logger.info", "os.path.join", "train_biencoder.evaluate", "len", "elq.read_dataset", "len", "len", "elq.biencoder.data_process.process_mention_data", "utils.get_logger.info", "torch.utils.data.RandomSampler", "torch.utils.data.SequentialSampler", "tqdm.tqdm", "tuple", "elq.biencoder.biencoder.BiEncoderRanker.", "loss.item", "loss.backward", "os.path.join", "time.time", "len", "torch.cuda.device_count", "torch.cuda.device_count", "len", "list", "elq.biencoder.biencoder.BiEncoderRanker.encode_context", "elq.index.faiss_indexer.DenseHNSWFlatIndexer.search_knn", "torch.from_numpy", "torch.from_numpy", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "neg_example_idx.flatten.expand", "neg_example_idx.flatten.flatten", "neg_cand_encs_input_idxs.reshape.permute", "neg_cand_encs_input_idxs.reshape.reshape", "torch.cat", "torch.cat", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat", "torch.cat", "utils.get_logger.info", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "get_optimizer.step", "get_scheduler.step", "get_optimizer.zero_grad", "utils.get_logger.info", "train_biencoder.evaluate", "model.train", "utils.get_logger.info", "get_optimizer.state_dict", "get_scheduler.state_dict", "numpy.argmax", "numpy.argmax", "len", "t.to", "masked_mention_reps.detach().cpu().numpy", "label_ids.size", "label_ids.size", "neg_cand_encs_input_idxs.reshape.size", "neg_cand_encs_input_idxs.reshape.size", "neg_cand_encs_input_idxs.reshape.size", "neg_cand_encs_input_idxs.reshape.size", "mention_reps.size", "pos_cand_encs_input.size", "model.parameters", "label_ids.to", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "masked_mention_reps.detach().cpu", "neg_cand_encs_input_idxs.reshape.size", "masked_label_ids.to().unsqueeze", "neg_example_idx.flatten.to", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "masked_mention_reps.detach", "pos_cand_encs_input.size", "pos_cand_encs_input.size", "neg_cand_encs_input.size", "neg_cand_encs_input.size", "masked_label_ids.to"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.get_logger", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.read_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.process_mention_data", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.write_to_file", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.get_optimizer", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.train_cross.get_scheduler", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.write_to_file", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.save_model", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.read_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseHNSWFlatIndexer.deserialize_from", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.process_mention_data", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.save_model", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.read_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.process_mention_data", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.encode_context", "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseHNSWFlatIndexer.search_knn", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["number_of_samples_per_dataset", "=", "{", "}", "\n", "\n", "time_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "utils", ".", "write_to_file", "(", "\n", "os", ".", "path", ".", "join", "(", "model_output_path", ",", "\"training_params.txt\"", ")", ",", "str", "(", "params", ")", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\"Starting training\"", ")", "\n", "logger", ".", "info", "(", "\n", "\"device: {} n_gpu: {}, distributed training: {}\"", ".", "format", "(", "device", ",", "n_gpu", ",", "False", ")", "\n", ")", "\n", "\n", "optimizer", "=", "get_optimizer", "(", "model", ",", "params", ")", "\n", "scheduler", "=", "get_scheduler", "(", "params", ",", "optimizer", ",", "len", "(", "train_tensor_data", ")", ",", "logger", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "best_epoch_idx", "=", "-", "1", "\n", "best_score", "=", "-", "1", "\n", "\n", "num_train_epochs", "=", "params", "[", "\"num_train_epochs\"", "]", "\n", "for", "epoch_idx", "in", "trange", "(", "int", "(", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ")", ":", "\n", "        ", "tr_loss", "=", "0", "\n", "results", "=", "None", "\n", "\n", "if", "params", "[", "\"silent\"", "]", ":", "\n", "            ", "iter_", "=", "train_dataloader", "\n", "", "else", ":", "\n", "            ", "iter_", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Batch\"", ")", "\n", "\n", "", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_", ")", ":", "\n", "            ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "context_input", ",", "candidate_input", ",", "_", ",", "_", "=", "batch", "\n", "loss", ",", "_", "=", "reranker", "(", "context_input", ",", "candidate_input", ")", "\n", "\n", "# if n_gpu > 1:", "\n", "#     loss = loss.mean() # mean() to average on multi-gpu.", "\n", "\n", "if", "grad_acc_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "grad_acc_steps", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "(", "params", "[", "\"print_interval\"", "]", "*", "grad_acc_steps", ")", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Step {} - epoch {} average loss: {}\\n\"", ".", "format", "(", "\n", "step", ",", "\n", "epoch_idx", ",", "\n", "tr_loss", "/", "(", "params", "[", "\"print_interval\"", "]", "*", "grad_acc_steps", ")", ",", "\n", ")", "\n", ")", "\n", "tr_loss", "=", "0", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "grad_acc_steps", "==", "0", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "model", ".", "parameters", "(", ")", ",", "params", "[", "\"max_grad_norm\"", "]", "\n", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "if", "(", "step", "+", "1", ")", "%", "(", "params", "[", "\"eval_interval\"", "]", "*", "grad_acc_steps", ")", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Evaluation on the development dataset\"", ")", "\n", "evaluate", "(", "\n", "reranker", ",", "valid_dataloader", ",", "params", ",", "device", "=", "device", ",", "logger", "=", "logger", ",", "\n", ")", "\n", "model", ".", "train", "(", ")", "\n", "logger", ".", "info", "(", "\"\\n\"", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"***** Saving fine - tuned model *****\"", ")", "\n", "epoch_output_folder_path", "=", "os", ".", "path", ".", "join", "(", "\n", "model_output_path", ",", "\"epoch_{}\"", ".", "format", "(", "epoch_idx", ")", "\n", ")", "\n", "utils", ".", "save_model", "(", "model", ",", "tokenizer", ",", "epoch_output_folder_path", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "epoch_output_folder_path", ",", "\"eval_results.txt\"", ")", "\n", "results", "=", "evaluate", "(", "\n", "reranker", ",", "valid_dataloader", ",", "params", ",", "device", "=", "device", ",", "logger", "=", "logger", ",", "\n", ")", "\n", "\n", "ls", "=", "[", "best_score", ",", "results", "[", "\"normalized_accuracy\"", "]", "]", "\n", "li", "=", "[", "best_epoch_idx", ",", "epoch_idx", "]", "\n", "\n", "best_score", "=", "ls", "[", "np", ".", "argmax", "(", "ls", ")", "]", "\n", "best_epoch_idx", "=", "li", "[", "np", ".", "argmax", "(", "ls", ")", "]", "\n", "logger", ".", "info", "(", "\"\\n\"", ")", "\n", "\n", "", "execution_time", "=", "(", "time", ".", "time", "(", ")", "-", "time_start", ")", "/", "60", "\n", "utils", ".", "write_to_file", "(", "\n", "os", ".", "path", ".", "join", "(", "model_output_path", ",", "\"training_time.txt\"", ")", ",", "\n", "\"The training took {} minutes\\n\"", ".", "format", "(", "execution_time", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"The training took {} minutes\\n\"", ".", "format", "(", "execution_time", ")", ")", "\n", "\n", "# save the best model in the parent_dir", "\n", "logger", ".", "info", "(", "\"Best performance in epoch: {}\"", ".", "format", "(", "best_epoch_idx", ")", ")", "\n", "params", "[", "\"path_to_model\"", "]", "=", "os", ".", "path", ".", "join", "(", "\n", "model_output_path", ",", "\n", "\"epoch_{}\"", ".", "format", "(", "best_epoch_idx", ")", ",", "\n", "WEIGHTS_NAME", ",", "\n", ")", "\n", "reranker", "=", "load_biencoder", "(", "params", ")", "\n", "utils", ".", "save_model", "(", "reranker", ".", "model", ",", "tokenizer", ",", "model_output_path", ")", "\n", "\n", "if", "params", "[", "\"evaluate\"", "]", ":", "\n", "        ", "params", "[", "\"path_to_model\"", "]", "=", "model_output_path", "\n", "evaluate", "(", "params", ",", "logger", "=", "logger", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "parser", "=", "BlinkParser", "(", "add_model_args", "=", "True", ")", "\n", "parser", ".", "add_training_args", "(", ")", "\n", "parser", ".", "add_eval_args", "(", ")", "\n", "\n", "# args = argparse.Namespace(**params)", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "print", "(", "args", ")", "\n", "\n", "params", "=", "args", ".", "__dict__", "\n", "main", "(", "params", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.nn_prediction.get_topk_predictions": [[17, 127], ["reranker.model.eval", "logger.info", "logger.info", "range", "enumerate", "blink.biencoder.zeshel_utils.Stats", "range", "logger.info", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "tqdm.tqdm", "len", "blink.biencoder.zeshel_utils.Stats", "tuple", "srcs[].item", "reranker.score_candidate", "reranker.score_candidate.topk", "range", "stats[].output", "logger.info", "blink.biencoder.zeshel_utils.Stats.extend", "blink.biencoder.zeshel_utils.Stats.output", "torch.LongTensor", "context_input.size", "range", "stats[].add", "torch.LongTensor.append", "torch.LongTensor.append", "torch.LongTensor.append", "nn_worlds.append", "logger.info", "t.to", "cand_encode_list[].to", "srcs[].item", "reranker.score_candidate", "reranker.score_candidate.topk", "context_input[].cpu().tolist", "cur_candidates.cpu().tolist", "inds[].item", "label_ids[].item", "cand_encode_list[].to", "context_input[].cpu", "cur_candidates.cpu"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.score_candidate", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.output", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.output", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.score_candidate"], ["def", "get_topk_predictions", "(", "\n", "reranker", ",", "\n", "train_dataloader", ",", "\n", "candidate_pool", ",", "\n", "cand_encode_list", ",", "\n", "silent", ",", "\n", "logger", ",", "\n", "top_k", "=", "10", ",", "\n", "is_zeshel", "=", "False", ",", "\n", "save_predictions", "=", "False", ",", "\n", ")", ":", "\n", "    ", "reranker", ".", "model", ".", "eval", "(", ")", "\n", "device", "=", "reranker", ".", "device", "\n", "logger", ".", "info", "(", "\"Getting top %d predictions.\"", "%", "top_k", ")", "\n", "if", "silent", ":", "\n", "        ", "iter_", "=", "train_dataloader", "\n", "", "else", ":", "\n", "        ", "iter_", "=", "tqdm", "(", "train_dataloader", ")", "\n", "\n", "", "nn_context", "=", "[", "]", "\n", "nn_candidates", "=", "[", "]", "\n", "nn_labels", "=", "[", "]", "\n", "nn_worlds", "=", "[", "]", "\n", "stats", "=", "{", "}", "\n", "\n", "if", "is_zeshel", ":", "\n", "        ", "world_size", "=", "len", "(", "WORLDS", ")", "\n", "", "else", ":", "\n", "# only one domain", "\n", "        ", "world_size", "=", "1", "\n", "candidate_pool", "=", "[", "candidate_pool", "]", "\n", "cand_encode_list", "=", "[", "cand_encode_list", "]", "\n", "\n", "", "logger", ".", "info", "(", "\"World size : %d\"", "%", "world_size", ")", "\n", "\n", "for", "i", "in", "range", "(", "world_size", ")", ":", "\n", "        ", "stats", "[", "i", "]", "=", "Stats", "(", "top_k", ")", "\n", "\n", "", "oid", "=", "0", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_", ")", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "context_input", ",", "_", ",", "srcs", ",", "label_ids", "=", "batch", "\n", "src", "=", "srcs", "[", "0", "]", ".", "item", "(", ")", "\n", "scores", "=", "reranker", ".", "score_candidate", "(", "\n", "context_input", ",", "\n", "None", ",", "\n", "cand_encs", "=", "cand_encode_list", "[", "src", "]", ".", "to", "(", "device", ")", "\n", ")", "\n", "values", ",", "indicies", "=", "scores", ".", "topk", "(", "top_k", ")", "\n", "old_src", "=", "src", "\n", "for", "i", "in", "range", "(", "context_input", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "oid", "+=", "1", "\n", "inds", "=", "indicies", "[", "i", "]", "\n", "\n", "if", "srcs", "[", "i", "]", "!=", "old_src", ":", "\n", "                ", "src", "=", "srcs", "[", "i", "]", ".", "item", "(", ")", "\n", "# not the same domain, need to re-do", "\n", "new_scores", "=", "reranker", ".", "score_candidate", "(", "\n", "context_input", "[", "[", "i", "]", "]", ",", "\n", "None", ",", "\n", "cand_encs", "=", "cand_encode_list", "[", "src", "]", ".", "to", "(", "device", ")", "\n", ")", "\n", "_", ",", "inds", "=", "new_scores", ".", "topk", "(", "top_k", ")", "\n", "inds", "=", "inds", "[", "0", "]", "\n", "\n", "", "pointer", "=", "-", "1", "\n", "for", "j", "in", "range", "(", "top_k", ")", ":", "\n", "                ", "if", "inds", "[", "j", "]", ".", "item", "(", ")", "==", "label_ids", "[", "i", "]", ".", "item", "(", ")", ":", "\n", "                    ", "pointer", "=", "j", "\n", "break", "\n", "", "", "stats", "[", "src", "]", ".", "add", "(", "pointer", ")", "\n", "\n", "if", "pointer", "==", "-", "1", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "not", "save_predictions", ":", "\n", "                ", "continue", "\n", "\n", "# add examples in new_data", "\n", "", "cur_candidates", "=", "candidate_pool", "[", "src", "]", "[", "inds", "]", "\n", "nn_context", ".", "append", "(", "context_input", "[", "i", "]", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "\n", "nn_candidates", ".", "append", "(", "cur_candidates", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "\n", "nn_labels", ".", "append", "(", "pointer", ")", "\n", "nn_worlds", ".", "append", "(", "src", ")", "\n", "\n", "", "", "res", "=", "Stats", "(", "top_k", ")", "\n", "for", "src", "in", "range", "(", "world_size", ")", ":", "\n", "        ", "if", "stats", "[", "src", "]", ".", "cnt", "==", "0", ":", "\n", "            ", "continue", "\n", "", "if", "is_zeshel", ":", "\n", "            ", "logger", ".", "info", "(", "\"In world \"", "+", "WORLDS", "[", "src", "]", ")", "\n", "", "output", "=", "stats", "[", "src", "]", ".", "output", "(", ")", "\n", "logger", ".", "info", "(", "output", ")", "\n", "res", ".", "extend", "(", "stats", "[", "src", "]", ")", "\n", "\n", "", "logger", ".", "info", "(", "res", ".", "output", "(", ")", ")", "\n", "\n", "nn_context", "=", "torch", ".", "LongTensor", "(", "nn_context", ")", "\n", "nn_candidates", "=", "torch", ".", "LongTensor", "(", "nn_candidates", ")", "\n", "nn_labels", "=", "torch", ".", "LongTensor", "(", "nn_labels", ")", "\n", "nn_data", "=", "{", "\n", "'context_vecs'", ":", "nn_context", ",", "\n", "'candidate_vecs'", ":", "nn_candidates", ",", "\n", "'labels'", ":", "nn_labels", ",", "\n", "}", "\n", "\n", "if", "is_zeshel", ":", "\n", "        ", "nn_data", "[", "\"worlds\"", "]", "=", "torch", ".", "LongTensor", "(", "nn_worlds", ")", "\n", "\n", "", "return", "nn_data", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.select_field": [[42, 47], ["None"], "function", ["None"], ["context_left", "=", "tokenizer", ".", "tokenize", "(", "context_left", ")", "\n", "context_right", "=", "tokenizer", ".", "tokenize", "(", "context_right", ")", "\n", "\n", "left_quota", "=", "(", "max_seq_length", "-", "len", "(", "mention_tokens", ")", ")", "//", "2", "-", "1", "\n", "right_quota", "=", "max_seq_length", "-", "len", "(", "mention_tokens", ")", "-", "left_quota", "-", "2", "\n", "left_add", "=", "len", "(", "context_left", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.get_context_representation": [[26, 69], ["tokenizer.tokenize", "tokenizer.tokenize", "len", "len", "tokenizer.convert_tokens_to_ids", "tokenizer.tokenize", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize"], ["", "", "def", "get_context_representation", "(", "\n", "sample", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "mention_key", "=", "\"mention\"", ",", "\n", "context_key", "=", "\"context\"", ",", "\n", "ent_start_token", "=", "ENT_START_TAG", ",", "\n", "ent_end_token", "=", "ENT_END_TAG", ",", "\n", ")", ":", "\n", "    ", "mention_tokens", "=", "[", "]", "\n", "if", "sample", "[", "mention_key", "]", "and", "len", "(", "sample", "[", "mention_key", "]", ")", ">", "0", ":", "\n", "        ", "mention_tokens", "=", "tokenizer", ".", "tokenize", "(", "sample", "[", "mention_key", "]", ")", "\n", "mention_tokens", "=", "[", "ent_start_token", "]", "+", "mention_tokens", "+", "[", "ent_end_token", "]", "\n", "\n", "", "context_left", "=", "sample", "[", "context_key", "+", "\"_left\"", "]", "\n", "context_right", "=", "sample", "[", "context_key", "+", "\"_right\"", "]", "\n", "context_left", "=", "tokenizer", ".", "tokenize", "(", "context_left", ")", "\n", "context_right", "=", "tokenizer", ".", "tokenize", "(", "context_right", ")", "\n", "\n", "left_quota", "=", "(", "max_seq_length", "-", "len", "(", "mention_tokens", ")", ")", "//", "2", "-", "1", "\n", "right_quota", "=", "max_seq_length", "-", "len", "(", "mention_tokens", ")", "-", "left_quota", "-", "2", "\n", "left_add", "=", "len", "(", "context_left", ")", "\n", "right_add", "=", "len", "(", "context_right", ")", "\n", "if", "left_add", "<=", "left_quota", ":", "\n", "        ", "if", "right_add", ">", "right_quota", ":", "\n", "            ", "right_quota", "+=", "left_quota", "-", "left_add", "\n", "", "", "else", ":", "\n", "        ", "if", "right_add", "<=", "right_quota", ":", "\n", "            ", "left_quota", "+=", "right_quota", "-", "right_add", "\n", "\n", "", "", "context_tokens", "=", "(", "\n", "context_left", "[", "-", "left_quota", ":", "]", "+", "mention_tokens", "+", "context_right", "[", ":", "right_quota", "]", "\n", ")", "\n", "\n", "context_tokens", "=", "[", "\"[CLS]\"", "]", "+", "context_tokens", "+", "[", "\"[SEP]\"", "]", "\n", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "context_tokens", ")", "\n", "padding", "=", "[", "0", "]", "*", "(", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "input_ids", "+=", "padding", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "\n", "return", "{", "\n", "\"tokens\"", ":", "context_tokens", ",", "\n", "\"ids\"", ":", "input_ids", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.get_candidate_representation": [[320, 345], ["tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "tokenizer.tokenize", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.process_mention_data": [[348, 566], ["tokenizer.convert_tokens_to_ids", "tokenizer.convert_tokens_to_ids", "tokenizer.convert_tokens_to_ids", "tokenizer.convert_tokens_to_ids", "enumerate", "torch.tensor", "isinstance", "os.path.exists", "torch.load", "torch.load", "torch.load", "tqdm.tqdm", "range", "sample.get", "sample.get", "isinstance", "processed_samples.append", "logger.info", "data_process.select_field", "logger.info", "torch.tensor().unsqueeze", "torch.ones().unsqueeze", "torch.tensor().unsqueeze", "data_process.select_field_with_padding", "torch.tensor", "torch.tensor", "data_process.select_field_with_padding", "torch.tensor", "torch.tensor", "len", "torch.tensor", "os.makedirs", "torch.save", "torch.save", "os.path.join", "os.path.join", "os.path.join", "logger.info", "data_process.get_context_representation_multiple_mentions_left_right", "data_process.get_context_representation_multiple_mentions_idxs", "len", "len", "len", "int", "logger.info", "logger.info", "logger.info", "logger.info", "torch.tensor", "logger.info", "data_process.select_field_with_padding", "torch.tensor", "torch.tensor", "torch.Tensor", "torch.tensor.all", "logger.info", "torch.tensor.size", "data_process.select_field", "logger.info", "os.path.exists", "os.path.join", "os.path.join", "len", "len", "int", "isinstance", "isinstance", "logger.info", "logger.info", "logger.info", "torch.tensor", "torch.ones", "data_process.select_field", "logger.info", "torch.tensor", "torch.tensor.all", "logger.info", "torch.tensor.size", "os.path.join", "len", "len", "candidate_token_ids[].tolist", "data_process.get_candidate_representation", "data_process.select_field", "torch.tensor.size", "data_process.select_field", "enumerate", "len", "range", "str", "len", "str", "range"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.select_field", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.select_field_with_padding", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.select_field_with_padding", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.get_context_representation_multiple_mentions_left_right", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.get_context_representation_multiple_mentions_idxs", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.select_field_with_padding", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.select_field", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.select_field", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.get_candidate_representation", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.select_field", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.select_field"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.MentionScoresHead.__init__": [[46, 63], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "NotImplementedError", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["layer_pulled", "=", "params", "[", "\"pull_from_layer\"", "]", ",", "\n", "add_linear", "=", "params", "[", "\"add_linear\"", "]", ",", "\n", ")", "\n", "self", ".", "config", "=", "ctxt_bert", ".", "config", "\n", "\n", "", "def", "forward", "(", "\n", "self", ",", "\n", "token_idx_ctxt", ",", "\n", "segment_idx_ctxt", ",", "\n", "mask_ctxt", ",", "\n", "token_idx_cands", ",", "\n", "segment_idx_cands", ",", "\n", "mask_cands", ",", "\n", ")", ":", "\n", "        ", "embedding_ctxt", "=", "None", "\n", "if", "token_idx_ctxt", "is", "not", "None", ":", "\n", "            ", "embedding_ctxt", "=", "self", ".", "context_encoder", "(", "\n", "token_idx_ctxt", ",", "segment_idx_ctxt", ",", "mask_ctxt", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.MentionScoresHead.forward": [[64, 127], ["biencoder.MentionScoresHead.bound_classifier", "biencoder.MentionScoresHead.split", "start_logprobs.squeeze.squeeze.squeeze", "end_logprobs.squeeze.squeeze.squeeze", "mention_logprobs.squeeze.squeeze.squeeze", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "torch.stack().to", "mention_scores.view.view.view", "mention_bounds.unsqueeze().expand.unsqueeze().expand.view", "mention_bounds.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "biencoder.MentionScoresHead.filter_by_mention_size", "float", "float", "float", "start_logprobs.squeeze.squeeze.unsqueeze", "end_logprobs.squeeze.squeeze.unsqueeze", "mask_ctxt.size", "torch.zeros().to.unsqueeze", "torch.zeros().to.unsqueeze", "torch.zeros().to.unsqueeze", "torch.zeros().to.unsqueeze", "torch.zeros().to.unsqueeze", "torch.zeros().to.unsqueeze", "mask_ctxt.unsqueeze", "float", "mention_scores.view.view.size", "mention_scores.view.view.size", "mention_scores.view.view.size", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "mask_ctxt.size", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "mention_sizes.unsqueeze", "mention_bounds.unsqueeze().expand.unsqueeze().expand.unsqueeze", "mention_scores.view.view.size", "mask_ctxt.size", "mask_ctxt.size", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "torch.arange().unsqueeze().expand", "mention_scores.view.view.size", "mention_scores.view.view.size", "mention_scores.view.view.size", "mention_scores.view.view.size", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mention_scores.view.view.size", "mention_scores.view.view.size"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.MentionScoresHead.filter_by_mention_size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], [")", "\n", "", "embedding_cands", "=", "None", "\n", "if", "token_idx_cands", "is", "not", "None", ":", "\n", "            ", "embedding_cands", "=", "self", ".", "cand_encoder", "(", "\n", "token_idx_cands", ",", "segment_idx_cands", ",", "mask_cands", "\n", ")", "\n", "", "return", "embedding_ctxt", ",", "embedding_cands", "\n", "\n", "\n", "", "", "class", "BiEncoderRanker", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "params", ",", "shared", "=", "None", ")", ":", "\n", "        ", "super", "(", "BiEncoderRanker", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "params", "=", "params", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\n", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "params", "[", "\"no_cuda\"", "]", "else", "\"cpu\"", "\n", ")", "\n", "self", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "# init tokenizer", "\n", "self", ".", "NULL_IDX", "=", "0", "\n", "self", ".", "START_TOKEN", "=", "\"[CLS]\"", "\n", "self", ".", "END_TOKEN", "=", "\"[SEP]\"", "\n", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "\n", "params", "[", "\"bert_model\"", "]", ",", "do_lower_case", "=", "params", "[", "\"lowercase\"", "]", "\n", ")", "\n", "# init model", "\n", "self", ".", "build_model", "(", ")", "\n", "model_path", "=", "params", ".", "get", "(", "\"path_to_model\"", ",", "None", ")", "\n", "if", "model_path", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_model", "(", "model_path", ")", "\n", "\n", "", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "data_parallel", "=", "params", ".", "get", "(", "\"data_parallel\"", ")", "\n", "if", "self", ".", "data_parallel", ":", "\n", "            ", "self", ".", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "self", ".", "model", ")", "\n", "\n", "", "", "def", "load_model", "(", "self", ",", "fname", ",", "cpu", "=", "False", ")", ":", "\n", "        ", "if", "cpu", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "fname", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "\"cpu\"", ")", "\n", "", "else", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "fname", ")", "\n", "", "self", ".", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "", "def", "build_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", "=", "BiEncoderModule", "(", "self", ".", "params", ")", "\n", "\n", "", "def", "save_model", "(", "self", ",", "output_dir", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "get_model_obj", "(", "self", ".", "model", ")", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "WEIGHTS_NAME", ")", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "CONFIG_NAME", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_model_file", ")", "\n", "model_to_save", ".", "config", ".", "to_json_file", "(", "output_config_file", ")", "\n", "\n", "", "def", "get_optimizer", "(", "self", ",", "optim_states", "=", "None", ",", "saved_optim_type", "=", "None", ")", ":", "\n", "        ", "return", "get_bert_optimizer", "(", "\n", "[", "self", ".", "model", "]", ",", "\n", "self", ".", "params", "[", "\"type_optimization\"", "]", ",", "\n", "self", ".", "params", "[", "\"learning_rate\"", "]", ",", "\n", "fp16", "=", "self", ".", "params", ".", "get", "(", "\"fp16\"", ")", ",", "\n", ")", "\n", "\n", "", "def", "encode_context", "(", "self", ",", "cands", ")", ":", "\n", "        ", "token_idx_cands", ",", "segment_idx_cands", ",", "mask_cands", "=", "to_bert_input", "(", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.MentionScoresHead.filter_by_mention_size": [[128, 143], ["mention_scores.view.view.view", "mention_bounds.view.view.view", "mention_bounds_mask.size", "mention_bounds_mask.size"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["cands", ",", "self", ".", "NULL_IDX", "\n", ")", "\n", "embedding_context", ",", "_", "=", "self", ".", "model", "(", "\n", "token_idx_cands", ",", "segment_idx_cands", ",", "mask_cands", ",", "None", ",", "None", ",", "None", "\n", ")", "\n", "return", "embedding_context", ".", "cpu", "(", ")", ".", "detach", "(", ")", "\n", "\n", "", "def", "encode_candidate", "(", "self", ",", "cands", ")", ":", "\n", "        ", "token_idx_cands", ",", "segment_idx_cands", ",", "mask_cands", "=", "to_bert_input", "(", "\n", "cands", ",", "self", ".", "NULL_IDX", "\n", ")", "\n", "_", ",", "embedding_cands", "=", "self", ".", "model", "(", "\n", "None", ",", "None", ",", "None", ",", "token_idx_cands", ",", "segment_idx_cands", ",", "mask_cands", "\n", ")", "\n", "return", "embedding_cands", ".", "cpu", "(", ")", ".", "detach", "(", ")", "\n", "# TODO: why do we need cpu here?", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.GetContextEmbedsHead.__init__": [[146, 176], ["torch.Module.__init__", "mention_aggregation_type.split", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["# Score candidates given context input and label input", "\n", "# If cand_encs is provided (pre-computed), cand_ves is ignored", "\n", "", "def", "score_candidate", "(", "\n", "self", ",", "\n", "text_vecs", ",", "\n", "cand_vecs", ",", "\n", "random_negs", "=", "True", ",", "\n", "cand_encs", "=", "None", ",", "# pre-computed candidate encoding.", "\n", ")", ":", "\n", "# Encode contexts first", "\n", "        ", "token_idx_ctxt", ",", "segment_idx_ctxt", ",", "mask_ctxt", "=", "to_bert_input", "(", "\n", "text_vecs", ",", "self", ".", "NULL_IDX", "\n", ")", "\n", "embedding_ctxt", ",", "_", "=", "self", ".", "model", "(", "\n", "token_idx_ctxt", ",", "segment_idx_ctxt", ",", "mask_ctxt", ",", "None", ",", "None", ",", "None", "\n", ")", "\n", "\n", "# Candidate encoding is given, do not need to re-compute", "\n", "# Directly return the score of context encoding and candidate encoding", "\n", "if", "cand_encs", "is", "not", "None", ":", "\n", "            ", "return", "embedding_ctxt", ".", "mm", "(", "cand_encs", ".", "t", "(", ")", ")", "\n", "\n", "# Train time. We compare with all elements of the batch", "\n", "", "token_idx_cands", ",", "segment_idx_cands", ",", "mask_cands", "=", "to_bert_input", "(", "\n", "cand_vecs", ",", "self", ".", "NULL_IDX", "\n", ")", "\n", "_", ",", "embedding_cands", "=", "self", ".", "model", "(", "\n", "None", ",", "None", ",", "None", ",", "token_idx_cands", ",", "segment_idx_cands", ",", "mask_cands", "\n", ")", "\n", "if", "random_negs", ":", "\n", "# train on random negatives", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.GetContextEmbedsHead.forward": [[177, 220], ["mention_bounds.size", "elq.biencoder.allennlp_span_utils.batched_span_select", "biencoder.GetContextEmbedsHead.aggregate_method.startswith", "biencoder.GetContextEmbedsHead.mention_agg_linear", "elq.biencoder.allennlp_span_utils.batched_index_select", "elq.biencoder.allennlp_span_utils.batched_index_select", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "NotImplementedError", "biencoder.GetContextEmbedsHead.sum", "mask.sum().float().unsqueeze", "biencoder.GetContextEmbedsHead.mean", "elq.biencoder.allennlp_span_utils.batched_index_select.unsqueeze", "elq.biencoder.allennlp_span_utils.batched_index_select.unsqueeze", "biencoder.GetContextEmbedsHead.view", "biencoder.GetContextEmbedsHead.mention_agg_linear", "mask.sum().float", "biencoder.GetContextEmbedsHead.size", "biencoder.GetContextEmbedsHead.size", "mask.sum"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.allennlp_span_utils.batched_span_select", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.allennlp_span_utils.batched_index_select", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.allennlp_span_utils.batched_index_select", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["            ", "return", "embedding_ctxt", ".", "mm", "(", "embedding_cands", ".", "t", "(", ")", ")", "\n", "", "else", ":", "\n", "# train on hard negatives", "\n", "            ", "embedding_ctxt", "=", "embedding_ctxt", ".", "unsqueeze", "(", "1", ")", "# batchsize x 1 x embed_size", "\n", "embedding_cands", "=", "embedding_cands", ".", "unsqueeze", "(", "2", ")", "# batchsize x embed_size x 2", "\n", "scores", "=", "torch", ".", "bmm", "(", "embedding_ctxt", ",", "embedding_cands", ")", "# batchsize x 1 x 1", "\n", "scores", "=", "torch", ".", "squeeze", "(", "scores", ")", "\n", "return", "scores", "\n", "\n", "# label_input -- negatives provided", "\n", "# If label_input is None, train on in-batch negatives", "\n", "", "", "def", "forward", "(", "self", ",", "context_input", ",", "cand_input", ",", "label_input", "=", "None", ")", ":", "\n", "        ", "flag", "=", "label_input", "is", "None", "\n", "scores", "=", "self", ".", "score_candidate", "(", "context_input", ",", "cand_input", ",", "flag", ")", "\n", "bs", "=", "scores", ".", "size", "(", "0", ")", "\n", "if", "label_input", "is", "None", ":", "\n", "            ", "target", "=", "torch", ".", "LongTensor", "(", "torch", ".", "arange", "(", "bs", ")", ")", "\n", "target", "=", "target", ".", "to", "(", "self", ".", "device", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "scores", ",", "target", ",", "reduction", "=", "\"mean\"", ")", "\n", "", "else", ":", "\n", "            ", "loss_fct", "=", "nn", ".", "BCEWithLogitsLoss", "(", "reduction", "=", "\"mean\"", ")", "\n", "# TODO: add parameters?", "\n", "loss", "=", "loss_fct", "(", "scores", ",", "label_input", ")", "\n", "", "return", "loss", ",", "scores", "\n", "\n", "\n", "", "", "def", "to_bert_input", "(", "token_idx", ",", "null_idx", ")", ":", "\n", "    ", "\"\"\" token_idx is a 2D tensor int.\n        return token_idx, segment_idx and mask\n    \"\"\"", "\n", "segment_idx", "=", "token_idx", "*", "0", "\n", "mask", "=", "token_idx", "!=", "null_idx", "\n", "# nullify elements in case self.NULL_IDX was not 0", "\n", "token_idx", "=", "token_idx", "*", "mask", ".", "long", "(", ")", "\n", "return", "token_idx", ",", "segment_idx", ",", "mask", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.get_raw_ctxt_encoding": [[273, 290], ["biencoder.BiEncoderModule.context_encoder.bert_model"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.get_ctxt_mention_scores": [[291, 316], ["biencoder.BiEncoderModule.get_raw_ctxt_encoding"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.get_raw_ctxt_encoding"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.prune_ctxt_mentions": [[318, 364], ["mention_logits.topk", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "mention_pos.view.view.view", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "elq.biencoder.utils.batch_reshape_mask_left", "elq.biencoder.utils.batch_reshape_mask_left", "torch.sigmoid().log", "torch.sigmoid().log", "torch.sigmoid().log", "torch.sigmoid().log", "torch.sigmoid().log", "torch.sigmoid().log", "torch.sigmoid().log", "torch.sigmoid().log", "torch.sigmoid().log", "torch.arange().to().unsqueeze().expand_as", "torch.arange().to().unsqueeze().expand_as", "torch.arange().to().unsqueeze().expand_as", "torch.arange().to().unsqueeze().expand_as", "torch.arange().to().unsqueeze().expand_as", "torch.arange().to().unsqueeze().expand_as", "torch.arange().to().unsqueeze().expand_as", "torch.arange().to().unsqueeze().expand_as", "torch.arange().to().unsqueeze().expand_as", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "mention_logits.size", "float", "torch.arange().to().unsqueeze", "torch.arange().to().unsqueeze", "torch.arange().to().unsqueeze", "torch.arange().to().unsqueeze", "torch.arange().to().unsqueeze", "torch.arange().to().unsqueeze", "torch.arange().to().unsqueeze", "torch.arange().to().unsqueeze", "torch.arange().to().unsqueeze", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "torch.arange().to", "float", "top_mention_pos_mask.sum", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mention_pos.view.view.size"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.utils.batch_reshape_mask_left", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.utils.batch_reshape_mask_left", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.get_ctxt_embeds": [[365, 387], ["biencoder.BiEncoderModule.linear_compression"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.forward_ctxt": [[388, 462], ["biencoder.BiEncoderModule.context_encoder", "biencoder.BiEncoderModule.get_raw_ctxt_encoding", "biencoder.BiEncoderModule.get_ctxt_embeds", "biencoder.BiEncoderModule.linear_compression", "biencoder.BiEncoderModule.get_ctxt_mention_scores", "biencoder.BiEncoderModule.view", "top_mention_bounds.view", "top_mention_mask.view", "torch.tensor().unsqueeze().to", "torch.tensor().unsqueeze().to", "torch.tensor().unsqueeze().to", "torch.tensor().unsqueeze().to", "torch.tensor().unsqueeze().to", "torch.tensor().unsqueeze().to", "torch.tensor().unsqueeze().to", "torch.tensor().unsqueeze().to", "torch.tensor().unsqueeze().to", "biencoder.BiEncoderModule.prune_ctxt_mentions", "top_mention_logits.view", "biencoder.BiEncoderModule.size", "top_mention_bounds.size", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "top_mention_mask.size"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.get_raw_ctxt_encoding", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.get_ctxt_embeds", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.get_ctxt_mention_scores", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.prune_ctxt_mentions", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.forward_candidate": [[464, 479], ["biencoder.BiEncoderModule.cand_encoder", "print", "print", "print", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "torch.rand().to", "token_idx_cands.size", "segment_idx_cands.size", "mask_cands.size", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "token_idx_cands.size"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderModule.upgrade_state_dict_named": [[518, 547], ["state_dict.keys", "hasattr", "biencoder.BiEncoderModule.classification_heads.keys", "biencoder.BiEncoderModule.classification_heads.state_dict", "biencoder.BiEncoderModule.items", "hasattr", "k.startswith", "k[].split", "print", "keys_to_delete.append", "print", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.get_span_loss": [[878, 912], ["torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.BCEWithLogitsLoss.", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "float", "mention_logits.size", "mention_bounds.unsqueeze", "gold_mention_bounds.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.get_submodel_from_state_dict": [[35, 43], ["collections.OrderedDict", "state_dict.items", "key.startswith", "len"], "function", ["None"], ["ctxt_bert", "=", "BertModel", ".", "from_pretrained", "(", "params", "[", "\"bert_model\"", "]", ")", "\n", "cand_bert", "=", "BertModel", ".", "from_pretrained", "(", "params", "[", "'bert_model'", "]", ")", "\n", "self", ".", "context_encoder", "=", "BertEncoder", "(", "\n", "ctxt_bert", ",", "\n", "params", "[", "\"out_dim\"", "]", ",", "\n", "layer_pulled", "=", "params", "[", "\"pull_from_layer\"", "]", ",", "\n", "add_linear", "=", "params", "[", "\"add_linear\"", "]", ",", "\n", ")", "\n", "self", ".", "cand_encoder", "=", "BertEncoder", "(", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.select_field_with_padding": [[21, 40], ["enumerate", "padding_mask.append", "selected_list.append", "max", "selected_list.append", "max", "len", "len", "len", "len", "range", "range", "range", "len", "len", "len"], "function", ["None"], ["        ", "return", "[", "example", "[", "key1", "]", "for", "example", "in", "data", "]", "\n", "", "else", ":", "\n", "        ", "return", "[", "example", "[", "key1", "]", "[", "key2", "]", "for", "example", "in", "data", "]", "\n", "\n", "\n", "", "", "def", "get_context_representation", "(", "\n", "sample", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "mention_key", "=", "\"mention\"", ",", "\n", "context_key", "=", "\"context\"", ",", "\n", "ent_start_token", "=", "ENT_START_TAG", ",", "\n", "ent_end_token", "=", "ENT_END_TAG", ",", "\n", ")", ":", "\n", "    ", "mention_tokens", "=", "[", "]", "\n", "if", "sample", "[", "mention_key", "]", "and", "len", "(", "sample", "[", "mention_key", "]", ")", ">", "0", ":", "\n", "        ", "mention_tokens", "=", "tokenizer", ".", "tokenize", "(", "sample", "[", "mention_key", "]", ")", "\n", "mention_tokens", "=", "[", "ent_start_token", "]", "+", "mention_tokens", "+", "[", "ent_end_token", "]", "\n", "\n", "", "context_left", "=", "sample", "[", "context_key", "+", "\"_left\"", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.get_context_representation_single_mention": [[49, 107], ["tokenizer.tokenize", "tokenizer.tokenize", "len", "len", "tokenizer.convert_tokens_to_ids", "tokenizer.tokenize", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize"], ["if", "left_add", "<=", "left_quota", ":", "\n", "        ", "if", "right_add", ">", "right_quota", ":", "\n", "            ", "right_quota", "+=", "left_quota", "-", "left_add", "\n", "", "", "else", ":", "\n", "        ", "if", "right_add", "<=", "right_quota", ":", "\n", "            ", "left_quota", "+=", "right_quota", "-", "right_add", "\n", "\n", "", "", "context_tokens", "=", "(", "\n", "context_left", "[", "-", "left_quota", ":", "]", "+", "mention_tokens", "+", "context_right", "[", ":", "right_quota", "]", "\n", ")", "\n", "\n", "context_tokens", "=", "[", "\"[CLS]\"", "]", "+", "context_tokens", "+", "[", "\"[SEP]\"", "]", "\n", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "context_tokens", ")", "\n", "padding", "=", "[", "0", "]", "*", "(", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "input_ids", "+=", "padding", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "\n", "return", "{", "\n", "\"tokens\"", ":", "context_tokens", ",", "\n", "\"ids\"", ":", "input_ids", ",", "\n", "}", "\n", "\n", "\n", "", "def", "get_candidate_representation", "(", "\n", "candidate_desc", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "candidate_title", "=", "None", ",", "\n", "title_tag", "=", "ENT_TITLE_TAG", ",", "\n", ")", ":", "\n", "    ", "cls_token", "=", "tokenizer", ".", "cls_token", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", "\n", "cand_tokens", "=", "tokenizer", ".", "tokenize", "(", "candidate_desc", ")", "\n", "if", "candidate_title", "is", "not", "None", ":", "\n", "        ", "title_tokens", "=", "tokenizer", ".", "tokenize", "(", "candidate_title", ")", "\n", "cand_tokens", "=", "title_tokens", "+", "[", "title_tag", "]", "+", "cand_tokens", "\n", "\n", "", "cand_tokens", "=", "cand_tokens", "[", ":", "max_seq_length", "-", "2", "]", "\n", "cand_tokens", "=", "[", "cls_token", "]", "+", "cand_tokens", "+", "[", "sep_token", "]", "\n", "\n", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "cand_tokens", ")", "\n", "padding", "=", "[", "0", "]", "*", "(", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "input_ids", "+=", "padding", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "\n", "return", "{", "\n", "\"tokens\"", ":", "cand_tokens", ",", "\n", "\"ids\"", ":", "input_ids", ",", "\n", "}", "\n", "\n", "\n", "", "def", "process_mention_data", "(", "\n", "samples", ",", "\n", "tokenizer", ",", "\n", "max_context_length", ",", "\n", "max_cand_length", ",", "\n", "silent", ",", "\n", "mention_key", "=", "\"mention\"", ",", "\n", "context_key", "=", "\"context\"", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.get_context_representation_multiple_mentions_left_right": [[110, 199], ["range", "tokenizer.convert_tokens_to_ids", "tokenizer.convert_tokens_to_ids", "len", "len", "len", "len", "len", "tokenizer.tokenize", "tokenizer.tokenize", "len", "len", "mention_idxs.append", "len", "len", "len", "len", "len", "tokenizer.tokenize", "mention_tokens.append", "len", "len", "len", "len", "len", "len", "pdb.set_trace", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize"], ["ent_start_token", "=", "ENT_START_TAG", ",", "\n", "ent_end_token", "=", "ENT_END_TAG", ",", "\n", "title_token", "=", "ENT_TITLE_TAG", ",", "\n", "debug", "=", "False", ",", "\n", "logger", "=", "None", ",", "\n", ")", ":", "\n", "    ", "processed_samples", "=", "[", "]", "\n", "\n", "if", "debug", ":", "\n", "        ", "samples", "=", "samples", "[", ":", "200", "]", "\n", "\n", "", "if", "silent", ":", "\n", "        ", "iter_", "=", "samples", "\n", "", "else", ":", "\n", "        ", "iter_", "=", "tqdm", "(", "samples", ")", "\n", "\n", "", "use_world", "=", "True", "\n", "\n", "for", "idx", ",", "sample", "in", "enumerate", "(", "iter_", ")", ":", "\n", "        ", "context_tokens", "=", "get_context_representation", "(", "\n", "sample", ",", "\n", "tokenizer", ",", "\n", "max_context_length", ",", "\n", "mention_key", ",", "\n", "context_key", ",", "\n", "ent_start_token", ",", "\n", "ent_end_token", ",", "\n", ")", "\n", "\n", "label", "=", "sample", "[", "label_key", "]", "\n", "title", "=", "sample", ".", "get", "(", "title_key", ",", "None", ")", "\n", "label_tokens", "=", "get_candidate_representation", "(", "\n", "label", ",", "tokenizer", ",", "max_cand_length", ",", "title", ",", "\n", ")", "\n", "label_idx", "=", "int", "(", "sample", "[", "\"label_id\"", "]", ")", "\n", "\n", "record", "=", "{", "\n", "\"context\"", ":", "context_tokens", ",", "\n", "\"label\"", ":", "label_tokens", ",", "\n", "\"label_idx\"", ":", "[", "label_idx", "]", ",", "\n", "}", "\n", "\n", "if", "\"world\"", "in", "sample", ":", "\n", "            ", "src", "=", "sample", "[", "\"world\"", "]", "\n", "src", "=", "world_to_id", "[", "src", "]", "\n", "record", "[", "\"src\"", "]", "=", "[", "src", "]", "\n", "use_world", "=", "True", "\n", "", "else", ":", "\n", "            ", "use_world", "=", "False", "\n", "\n", "", "processed_samples", ".", "append", "(", "record", ")", "\n", "\n", "", "if", "debug", "and", "logger", ":", "\n", "        ", "logger", ".", "info", "(", "\"====Processed samples: ====\"", ")", "\n", "for", "sample", "in", "processed_samples", "[", ":", "5", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Context tokens : \"", "+", "\" \"", ".", "join", "(", "sample", "[", "\"context\"", "]", "[", "\"tokens\"", "]", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"Context ids : \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "v", ")", "for", "v", "in", "sample", "[", "\"context\"", "]", "[", "\"ids\"", "]", "]", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\"Label tokens : \"", "+", "\" \"", ".", "join", "(", "sample", "[", "\"label\"", "]", "[", "\"tokens\"", "]", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"Label ids : \"", "+", "\" \"", ".", "join", "(", "[", "str", "(", "v", ")", "for", "v", "in", "sample", "[", "\"label\"", "]", "[", "\"ids\"", "]", "]", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\"Src : %d\"", "%", "sample", "[", "\"src\"", "]", "[", "0", "]", ")", "\n", "logger", ".", "info", "(", "\"Label_id : %d\"", "%", "sample", "[", "\"label_idx\"", "]", "[", "0", "]", ")", "\n", "\n", "", "", "context_vecs", "=", "torch", ".", "tensor", "(", "\n", "select_field", "(", "processed_samples", ",", "\"context\"", ",", "\"ids\"", ")", ",", "dtype", "=", "torch", ".", "long", ",", "\n", ")", "\n", "cand_vecs", "=", "torch", ".", "tensor", "(", "\n", "select_field", "(", "processed_samples", ",", "\"label\"", ",", "\"ids\"", ")", ",", "dtype", "=", "torch", ".", "long", ",", "\n", ")", "\n", "if", "use_world", ":", "\n", "        ", "src_vecs", "=", "torch", ".", "tensor", "(", "\n", "select_field", "(", "processed_samples", ",", "\"src\"", ")", ",", "dtype", "=", "torch", ".", "long", ",", "\n", ")", "\n", "", "label_idx", "=", "torch", ".", "tensor", "(", "\n", "select_field", "(", "processed_samples", ",", "\"label_idx\"", ")", ",", "dtype", "=", "torch", ".", "long", ",", "\n", ")", "\n", "data", "=", "{", "\n", "\"context_vecs\"", ":", "context_vecs", ",", "\n", "\"cand_vecs\"", ":", "cand_vecs", ",", "\n", "\"label_idx\"", ":", "label_idx", ",", "\n", "}", "\n", "\n", "if", "use_world", ":", "\n", "        ", "data", "[", "\"src\"", "]", "=", "src_vecs", "\n", "tensor_data", "=", "TensorDataset", "(", "context_vecs", ",", "cand_vecs", ",", "src_vecs", ",", "label_idx", ")", "\n", "", "else", ":", "\n", "        ", "tensor_data", "=", "TensorDataset", "(", "context_vecs", ",", "cand_vecs", ",", "label_idx", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.sort_mentions": [[202, 212], ["range", "len", "range", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.do_sort": [[214, 222], ["data_process.sort_mentions", "data_process.sort_mentions", "data_process.sort_mentions", "data_process.sort_mentions", "data_process.sort_mentions"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.sort_mentions", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.sort_mentions", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.sort_mentions", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.sort_mentions", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.sort_mentions"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.get_context_representation_multiple_mentions_idxs": [[224, 317], ["len", "len", "tokenizer.convert_ids_to_tokens", "data_process.do_sort", "len", "len", "sorted", "data_process.sort_mentions", "len", "len", "len", "len", "range", "len", "enumerate", "enumerate", "len", "len", "pdb.set_trace", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.do_sort", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.sort_mentions"], []], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.utils.batch_reshape_mask_left": [[12, 51], ["selected.sum", "selected.sum.max", "torch.stack", "repeat_freqs.view.view", "torch.Tensor().to().fill_", "torch.zeros().to().bool", "left_align_mask.view.view", "left_align_mask.view.repeat_interleave", "left_align_mask.view.view", "torch.Tensor().to", "torch.zeros().to", "torch.Tensor", "torch.zeros", "input_t.size", "left_align_mask.view.size", "input_t.size"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["from", "segtok", ".", "segmenter", "import", "split_multi", "\n", "\n", "##### Reading helpers #####", "\n", "def", "read_sentences_from_file", "(", "path_to_file", ",", "one_sentence_per_line", "=", "True", ")", ":", "\n", "    ", "lines", "=", "[", "]", "\n", "with", "io", ".", "open", "(", "path_to_file", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "file", ":", "\n", "        ", "for", "line", "in", "file", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "!=", "\"\"", ":", "\n", "                ", "lines", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "", "if", "one_sentence_per_line", ":", "\n", "        ", "sentences", "=", "lines", "\n", "", "else", ":", "\n", "        ", "text", "=", "\" \"", ".", "join", "(", "lines", ")", "\n", "sentences", "=", "list", "(", "split_multi", "(", "text", ")", ")", "\n", "sentences", "=", "[", "sentence", "for", "sentence", "in", "sentences", "if", "sentence", "!=", "\"\"", "]", "\n", "\n", "", "return", "sentences", "\n", "\n", "\n", "##### Printing / writing  helpers #####", "\n", "", "def", "get_candidate_summary", "(", "candidate", ")", ":", "\n", "    ", "wikipedia_id", "=", "candidate", "[", "\"wikipedia_id\"", "]", "\n", "wikidata_id", "=", "candidate", "[", "\"wikidata_id\"", "]", "\n", "wikipedia_title", "=", "candidate", "[", "\"wikipedia_title\"", "]", "\n", "\n", "return", "\"{}, {}, {}\"", ".", "format", "(", "wikipedia_id", ",", "wikidata_id", ",", "wikipedia_title", ")", "\n", "\n", "\n", "", "def", "present_sentence_mentions", "(", "sentence", ",", "mentions", ",", "output_file", ")", ":", "\n", "    ", "if", "output_file", "!=", "None", ":", "\n", "        ", "f", "=", "io", ".", "open", "(", "output_file", ",", "mode", "=", "\"a\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "output", "=", "lambda", "s", ":", "f", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "s", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "lambda", "s", ":", "print", "(", "s", ")", "\n", "", "output", "(", "\"Sentence: {}\"", ".", "format", "(", "sentence", ")", ")", "\n", "\n", "mention_entity_pairs", "=", "[", "]", "\n", "for", "mention", "in", "mentions", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.allennlp_span_utils.get_device_of": [[14, 22], ["tensor.get_device"], "function", ["None"], ["def", "get_device_of", "(", "tensor", ":", "torch", ".", "Tensor", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Returns the device of the tensor.\n    \"\"\"", "\n", "if", "not", "tensor", ".", "is_cuda", ":", "\n", "        ", "return", "-", "1", "\n", "", "else", ":", "\n", "        ", "return", "tensor", ".", "get_device", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.allennlp_span_utils.get_range_vector": [[24, 33], ["torch.arange", "torch.cuda.LongTensor().fill_().cumsum", "torch.cuda.LongTensor().fill_", "torch.cuda.LongTensor"], "function", ["None"], ["", "", "def", "get_range_vector", "(", "size", ":", "int", ",", "device", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Returns a range vector with the desired size, starting at 0. The CUDA implementation\n    is meant to avoid copy data from CPU to GPU.\n    \"\"\"", "\n", "if", "device", ">", "-", "1", ":", "\n", "        ", "return", "torch", ".", "cuda", ".", "LongTensor", "(", "size", ",", "device", "=", "device", ")", ".", "fill_", "(", "1", ")", ".", "cumsum", "(", "0", ")", "-", "1", "\n", "", "else", ":", "\n", "        ", "return", "torch", ".", "arange", "(", "0", ",", "size", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.allennlp_span_utils.flatten_and_batch_shift_indices": [[35, 75], ["range", "offset_indices.view.view", "IndexError", "allennlp_span_utils.get_range_vector", "offsets.unsqueeze.unsqueeze", "torch.max", "torch.min", "indices.size", "allennlp_span_utils.get_device_of", "len", "indices.size"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.allennlp_span_utils.get_range_vector", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.allennlp_span_utils.get_device_of", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "", "def", "flatten_and_batch_shift_indices", "(", "indices", ":", "torch", ".", "Tensor", ",", "sequence_length", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    This is a subroutine for [`batched_index_select`](./util.md#batched_index_select).\n    The given `indices` of size `(batch_size, d_1, ..., d_n)` indexes into dimension 2 of a\n    target tensor, which has size `(batch_size, sequence_length, embedding_size)`. This\n    function returns a vector that correctly indexes into the flattened target. The sequence\n    length of the target must be provided to compute the appropriate offsets.\n    ```python\n        indices = torch.ones([2,3], dtype=torch.long)\n        # Sequence length of the target tensor.\n        sequence_length = 10\n        shifted_indices = flatten_and_batch_shift_indices(indices, sequence_length)\n        # Indices into the second element in the batch are correctly shifted\n        # to take into account that the target tensor will be flattened before\n        # the indices are applied.\n        assert shifted_indices == [1, 1, 1, 11, 11, 11]\n    ```\n    # Parameters\n    indices : `torch.LongTensor`, required.\n    sequence_length : `int`, required.\n        The length of the sequence the indices index into.\n        This must be the second dimension of the tensor.\n    # Returns\n    offset_indices : `torch.LongTensor`\n    \"\"\"", "\n", "# Shape: (batch_size)", "\n", "if", "torch", ".", "max", "(", "indices", ")", ">=", "sequence_length", "or", "torch", ".", "min", "(", "indices", ")", "<", "0", ":", "\n", "        ", "raise", "IndexError", "(", "\n", "f\"All elements in indices should be in range (0, {sequence_length - 1})\"", "\n", ")", "\n", "", "offsets", "=", "get_range_vector", "(", "indices", ".", "size", "(", "0", ")", ",", "get_device_of", "(", "indices", ")", ")", "*", "sequence_length", "\n", "for", "_", "in", "range", "(", "len", "(", "indices", ".", "size", "(", ")", ")", "-", "1", ")", ":", "\n", "        ", "offsets", "=", "offsets", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# Shape: (batch_size, d_1, ..., d_n)", "\n", "", "offset_indices", "=", "indices", "+", "offsets", "\n", "\n", "# Shape: (batch_size * d_1 * ... * d_n)", "\n", "offset_indices", "=", "offset_indices", ".", "view", "(", "-", "1", ")", "\n", "return", "offset_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.allennlp_span_utils.batched_index_select": [[77, 130], ["target.view", "target.view.index_select", "flattened_target.index_select.view", "target.size", "list", "allennlp_span_utils.flatten_and_batch_shift_indices", "indices.size", "target.size", "target.size", "print", "print", "allennlp_span_utils.flatten_and_batch_shift_indices", "target.size"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.allennlp_span_utils.flatten_and_batch_shift_indices", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.allennlp_span_utils.flatten_and_batch_shift_indices", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "batched_index_select", "(", "\n", "target", ":", "torch", ".", "Tensor", ",", "\n", "indices", ":", "torch", ".", "LongTensor", ",", "\n", "flattened_indices", ":", "Optional", "[", "torch", ".", "LongTensor", "]", "=", "None", ",", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    The given `indices` of size `(batch_size, d_1, ..., d_n)` indexes into the sequence\n    dimension (dimension 2) of the target, which has size `(batch_size, sequence_length,\n    embedding_size)`.\n    This function returns selected values in the target with respect to the provided indices, which\n    have size `(batch_size, d_1, ..., d_n, embedding_size)`. This can use the optionally\n    precomputed `flattened_indices` with size `(batch_size * d_1 * ... * d_n)` if given.\n    An example use case of this function is looking up the start and end indices of spans in a\n    sequence tensor. This is used in the\n    [CoreferenceResolver](../models/coreference_resolution/coref.md). Model to select\n    contextual word representations corresponding to the start and end indices of mentions. The key\n    reason this can't be done with basic torch functions is that we want to be able to use look-up\n    tensors with an arbitrary number of dimensions (for example, in the coref model, we don't know\n    a-priori how many spans we are looking up).\n    # Parameters\n    target : `torch.Tensor`, required.\n        A 3 dimensional tensor of shape (batch_size, sequence_length, embedding_size).\n        This is the tensor to be indexed.\n    indices : `torch.LongTensor`\n        A tensor of shape (batch_size, ...), where each element is an index into the\n        `sequence_length` dimension of the `target` tensor.\n    flattened_indices : Optional[torch.Tensor], optional (default = None)\n        An optional tensor representing the result of calling `flatten_and_batch_shift_indices`\n        on `indices`. This is helpful in the case that the indices can be flattened once and\n        cached for many batch lookups.\n    # Returns\n    selected_targets : `torch.Tensor`\n        A tensor with shape [indices.size(), target.size(-1)] representing the embedded indices\n        extracted from the batch flattened target tensor.\n    \"\"\"", "\n", "if", "flattened_indices", "is", "None", ":", "\n", "# Shape: (batch_size * d_1 * ... * d_n)", "\n", "        ", "try", ":", "\n", "            ", "flattened_indices", "=", "flatten_and_batch_shift_indices", "(", "indices", ",", "target", ".", "size", "(", "1", ")", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "\"indices: {}\"", ".", "format", "(", "indices", ")", ")", "\n", "print", "(", "\"target: {}\"", ".", "format", "(", "target", ")", ")", "\n", "flattened_indices", "=", "flatten_and_batch_shift_indices", "(", "indices", ",", "target", ".", "size", "(", "1", ")", ")", "\n", "\n", "# Shape: (batch_size * sequence_length, embedding_size)", "\n", "", "", "flattened_target", "=", "target", ".", "view", "(", "-", "1", ",", "target", ".", "size", "(", "-", "1", ")", ")", "\n", "\n", "# Shape: (batch_size * d_1 * ... * d_n, embedding_size)", "\n", "flattened_selected", "=", "flattened_target", ".", "index_select", "(", "0", ",", "flattened_indices", ")", "\n", "selected_shape", "=", "list", "(", "indices", ".", "size", "(", ")", ")", "+", "[", "target", ".", "size", "(", "-", "1", ")", "]", "\n", "# Shape: (batch_size, d_1, ..., d_n, embedding_size)", "\n", "selected_targets", "=", "flattened_selected", ".", "view", "(", "*", "selected_shape", ")", "\n", "return", "selected_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.allennlp_span_utils.batched_span_select": [[132, 192], ["spans.split", "get_range_vector().view", "torch.nn.functional.relu().long", "allennlp_span_utils.batched_index_select", "span_widths.max().item", "allennlp_span_utils.get_range_vector", "torch.nn.functional.relu", "span_widths.max", "allennlp_span_utils.get_device_of", "raw_span_indices.float"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.allennlp_span_utils.batched_index_select", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.allennlp_span_utils.get_range_vector", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.allennlp_span_utils.get_device_of"], ["", "def", "batched_span_select", "(", "target", ":", "torch", ".", "Tensor", ",", "spans", ":", "torch", ".", "LongTensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    The given `spans` of size `(batch_size, num_spans, 2)` indexes into the sequence\n    dimension (dimension 2) of the target, which has size `(batch_size, sequence_length,\n    embedding_size)`.\n    This function returns segmented spans in the target with respect to the provided span indices.\n    It does not guarantee element order within each span.\n    # Parameters\n    target : `torch.Tensor`, required.\n        A 3 dimensional tensor of shape (batch_size, sequence_length, embedding_size).\n        This is the tensor to be indexed.\n    indices : `torch.LongTensor`\n        A 3 dimensional tensor of shape (batch_size, num_spans, 2) representing start and end\n        indices (both inclusive) into the `sequence_length` dimension of the `target` tensor.\n    # Returns\n    span_embeddings : `torch.Tensor`\n        A tensor with shape (batch_size, num_spans, max_batch_span_width, embedding_size]\n        representing the embedded spans extracted from the batch flattened target tensor.\n    span_mask: `torch.BoolTensor`\n        A tensor with shape (batch_size, num_spans, max_batch_span_width) representing the mask on\n        the returned span embeddings.\n    \"\"\"", "\n", "# both of shape (batch_size, num_spans, 1)", "\n", "span_starts", ",", "span_ends", "=", "spans", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# shape (batch_size, num_spans, 1)", "\n", "# These span widths are off by 1, because the span ends are `inclusive`.", "\n", "span_widths", "=", "span_ends", "-", "span_starts", "\n", "\n", "# We need to know the maximum span width so we can", "\n", "# generate indices to extract the spans from the sequence tensor.", "\n", "# These indices will then get masked below, such that if the length", "\n", "# of a given span is smaller than the max, the rest of the values", "\n", "# are masked.", "\n", "max_batch_span_width", "=", "span_widths", ".", "max", "(", ")", ".", "item", "(", ")", "+", "1", "\n", "\n", "# Shape: (1, 1, max_batch_span_width)", "\n", "max_span_range_indices", "=", "get_range_vector", "(", "max_batch_span_width", ",", "get_device_of", "(", "target", ")", ")", ".", "view", "(", "\n", "1", ",", "1", ",", "-", "1", "\n", ")", "\n", "# Shape: (batch_size, num_spans, max_batch_span_width)", "\n", "# This is a broadcasted comparison - for each span we are considering,", "\n", "# we are creating a range vector of size max_span_width, but masking values", "\n", "# which are greater than the actual length of the span.", "\n", "#", "\n", "# We're using <= here (and for the mask below) because the span ends are", "\n", "# inclusive, so we want to include indices which are equal to span_widths rather", "\n", "# than using it as a non-inclusive upper bound.", "\n", "span_mask", "=", "max_span_range_indices", "<=", "span_widths", "\n", "raw_span_indices", "=", "span_ends", "-", "max_span_range_indices", "\n", "# We also don't want to include span indices which are less than zero,", "\n", "# which happens because some spans near the beginning of the sequence", "\n", "# have an end index < max_batch_span_width, so we add this to the mask here.", "\n", "span_mask", "=", "span_mask", "&", "(", "raw_span_indices", ">=", "0", ")", "\n", "span_indices", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "raw_span_indices", ".", "float", "(", ")", ")", ".", "long", "(", ")", "\n", "\n", "# Shape: (batch_size, num_spans, max_batch_span_width, embedding_dim)", "\n", "span_embeddings", "=", "batched_index_select", "(", "target", ",", "span_indices", ")", "\n", "\n", "return", "span_embeddings", ",", "span_mask", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.evaluate.evaluate_model_on_dataset": [[20, 102], ["model.eval", "tqdm.tqdm", "logger.info", "logger.info", "input_ids.to.to", "input_mask.to.to", "segment_ids.to.to", "label_ids.to().numpy.to", "entity_mask.to.to", "logits.detach().cpu().numpy.detach().cpu().numpy", "label_ids.to().numpy.to().numpy", "utils.accuracy", "utils.accuracy", "input_ids.to.size", "utils.eval_precision_bm45_dataloader", "utils.eval_precision_bm45_dataloader", "utils.eval_precision_bm45_dataloader", "utils.eval_precision_bm45_dataloader", "logger.info", "sorted", "torch.no_grad", "model", "result.keys", "logger.info", "open", "logger.info", "writer.write", "sorted", "writer.write", "logits.detach().cpu().numpy.detach().cpu", "label_ids.to().numpy.to", "str", "result.keys", "logger.info", "writer.write", "str", "logits.detach().cpu().numpy.detach", "str"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.accuracy", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.accuracy", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.eval_precision_bm45_dataloader", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.eval_precision_bm45_dataloader", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.eval_precision_bm45_dataloader", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.eval_precision_bm45_dataloader"], ["def", "evaluate_model_on_dataset", "(", "\n", "model", ",", "\n", "dataloader", ",", "\n", "dataset_name", ",", "\n", "device", ",", "\n", "logger", ",", "\n", "number_of_samples", ",", "\n", "eval_bm45_acc", "=", "False", ",", "\n", "path_to_file_to_write_results", "=", "None", ",", "\n", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "\n", "eval_accuracy", "=", "0", "\n", "nb_eval_steps", ",", "nb_eval_examples", "=", "0", ",", "0", "\n", "\n", "for", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", ",", "entity_mask", "in", "tqdm", "(", "\n", "dataloader", ",", "desc", "=", "\"Evaluating\"", "\n", ")", ":", "\n", "        ", "input_ids", "=", "input_ids", ".", "to", "(", "device", ")", "\n", "input_mask", "=", "input_mask", ".", "to", "(", "device", ")", "\n", "segment_ids", "=", "segment_ids", ".", "to", "(", "device", ")", "\n", "label_ids", "=", "label_ids", ".", "to", "(", "device", ")", "\n", "entity_mask", "=", "entity_mask", ".", "to", "(", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "tmp_eval_loss", ",", "logits", "=", "model", "(", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "label_ids", ",", "entity_mask", "=", "entity_mask", "\n", ")", "\n", "\n", "", "logits", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "label_ids", "=", "label_ids", ".", "to", "(", "\"cpu\"", ")", ".", "numpy", "(", ")", "\n", "tmp_eval_accuracy", "=", "utils", ".", "accuracy", "(", "logits", ",", "label_ids", ")", "\n", "\n", "eval_accuracy", "+=", "tmp_eval_accuracy", "\n", "\n", "nb_eval_examples", "+=", "input_ids", ".", "size", "(", "0", ")", "\n", "nb_eval_steps", "+=", "1", "\n", "\n", "", "logger", ".", "info", "(", "\"\\n\"", ")", "\n", "\n", "normalized_eval_accuracy", "=", "eval_accuracy", "/", "nb_eval_examples", "\n", "\n", "result", "=", "{", "\"normalized_accuracy\"", ":", "normalized_eval_accuracy", "}", "\n", "result", "[", "\"unnormalized_accuracy\"", "]", "=", "eval_accuracy", "/", "number_of_samples", "\n", "result", "[", "\"candidate_generation_recall\"", "]", "=", "nb_eval_examples", "/", "number_of_samples", "\n", "\n", "if", "eval_bm45_acc", ":", "\n", "        ", "result", "[", "\"normalized_bm45_recall_@\"", "]", "=", "utils", ".", "eval_precision_bm45_dataloader", "(", "\n", "dataloader", ",", "[", "1", ",", "5", ",", "10", ",", "20", ",", "40", ",", "60", ",", "80", ",", "100", "]", "\n", ")", "\n", "result", "[", "\"unnormalized_bm45_recall_@\"", "]", "=", "utils", ".", "eval_precision_bm45_dataloader", "(", "\n", "dataloader", ",", "[", "1", ",", "5", ",", "10", ",", "20", ",", "40", ",", "60", ",", "80", ",", "100", "]", ",", "number_of_samples", "\n", ")", "\n", "\n", "", "if", "path_to_file_to_write_results", "is", "None", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"***** Eval results - {} ({} / {} samples) *****\\n\"", ".", "format", "(", "\n", "dataset_name", ",", "nb_eval_examples", ",", "number_of_samples", "\n", ")", "\n", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "with", "open", "(", "path_to_file_to_write_results", ",", "\"a+\"", ")", "as", "writer", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"***** Eval results - {} ({} / {} samples) *****\\n\"", ".", "format", "(", "\n", "dataset_name", ",", "nb_eval_examples", ",", "number_of_samples", "\n", ")", "\n", ")", "\n", "writer", ".", "write", "(", "\n", "\"***** Eval results - {} ({} / {} samples) *****\\n\"", ".", "format", "(", "\n", "dataset_name", ",", "nb_eval_examples", ",", "number_of_samples", "\n", ")", "\n", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "", "writer", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"\\n\"", ")", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.evaluate.evaluate": [[104, 215], ["utils.get_reranker", "utils.get_reranker", "time.time", "logger.info", "utils.read_dataset", "utils.read_dataset", "utils.filter_samples", "utils.filter_samples", "logger.info", "len", "utils.get_reranker._process_mentions_for_model", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "evaluate.evaluate_model_on_dataset", "logger.info", "print", "os.path.join", "logger.info", "print", "len", "len", "time.time"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.get_reranker", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.get_reranker", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.read_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.read_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.filter_samples", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.filter_samples", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._process_mentions_for_model", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.evaluate.evaluate_model_on_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "evaluate", "(", "parameters", ",", "logger", "=", "None", ")", ":", "\n", "    ", "reranker", "=", "utils", ".", "get_reranker", "(", "parameters", ")", "\n", "\n", "if", "parameters", "[", "\"full_evaluation\"", "]", ":", "\n", "        ", "eval_datasets", "=", "[", "\n", "\"aida-A\"", ",", "\n", "\"aida-B\"", ",", "\n", "\"msnbc\"", ",", "\n", "\"aquaint\"", ",", "\n", "\"ace2004\"", ",", "\n", "\"clueweb\"", ",", "\n", "\"wikipedia\"", ",", "\n", "]", "\n", "", "else", ":", "\n", "        ", "eval_datasets", "=", "[", "\"aida-B\"", "]", "\n", "\n", "", "candidates_key", "=", "(", "\n", "\"pregenerated_candidates\"", "\n", "if", "parameters", "[", "\"evaluate_with_pregenerated_candidates\"", "]", "\n", "else", "\"candidates\"", "\n", ")", "\n", "gold_key", "=", "(", "\n", "\"pregenerated_gold_pos\"", "\n", "if", "parameters", "[", "\"evaluate_with_pregenerated_candidates\"", "]", "\n", "else", "\"gold_pos\"", "\n", ")", "\n", "\n", "number_of_samples_per_dataset", "=", "{", "}", "\n", "total_time", "=", "0", "\n", "\n", "for", "eval_dataset_name", "in", "eval_datasets", ":", "\n", "        ", "time_start", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "\"\\nEvaluating on the {} dataset\"", ".", "format", "(", "eval_dataset_name", ")", ")", "\n", "eval_samples", "=", "utils", ".", "read_dataset", "(", "\n", "eval_dataset_name", ",", "parameters", "[", "\"path_to_preprocessed_json_data\"", "]", "\n", ")", "\n", "eval_samples_filtered", "=", "utils", ".", "filter_samples", "(", "\n", "eval_samples", ",", "parameters", "[", "\"top_k\"", "]", ",", "gold_key", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"Retained {} out of {} samples\"", ".", "format", "(", "\n", "len", "(", "eval_samples_filtered", ")", ",", "len", "(", "eval_samples", ")", "\n", ")", "\n", ")", "\n", "number_of_samples_per_dataset", "[", "eval_dataset_name", "]", "=", "len", "(", "eval_samples", ")", "\n", "\n", "# if args.num_preprocessing_threads == -1:", "\n", "#     eval_data, eval_tensor_data = process_samples_for_model(args.context_key, eval_samples_filtered, tokenizer, args.max_seq_length, logger = logger, top_k = args.top_k, example = False, debug = args.debug, tagged = args.tag_mention, candidates_key = candidates_key, gold_key = gold_key)", "\n", "# else:", "\n", "#     eval_data, eval_tensor_data = preprocessing_multithreaded(eval_samples_filtered, logger, args, output_dir=True)", "\n", "\n", "eval_data", ",", "eval_tensor_data", "=", "reranker", ".", "_process_mentions_for_model", "(", "\n", "parameters", "[", "\"context_key\"", "]", ",", "\n", "eval_samples_filtered", ",", "\n", "reranker", ".", "tokenizer", ",", "\n", "parameters", "[", "\"max_seq_length\"", "]", ",", "\n", "parameters", "[", "\"top_k\"", "]", ",", "\n", "parameters", "[", "\"silent\"", "]", ",", "\n", "candidates_key", "=", "candidates_key", ",", "\n", "gold_key", "=", "gold_key", ",", "\n", "debug", "=", "parameters", "[", "\"debug\"", "]", ",", "\n", ")", "\n", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_tensor_data", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "eval_tensor_data", ",", "\n", "sampler", "=", "eval_sampler", ",", "\n", "batch_size", "=", "parameters", "[", "\"evaluation_batch_size\"", "]", ",", "\n", ")", "\n", "\n", "if", "parameters", "[", "\"output_eval_file\"", "]", "is", "None", ":", "\n", "            ", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "\n", "parameters", "[", "\"path_to_model\"", "]", ",", "\"eval_results.txt\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "output_eval_file", "=", "parameters", "[", "\"output_eval_file\"", "]", "\n", "\n", "", "result", "=", "evaluate_model_on_dataset", "(", "\n", "reranker", ".", "model", ",", "\n", "eval_dataloader", ",", "\n", "eval_dataset_name", ",", "\n", "eval_bm45_acc", "=", "True", ",", "\n", "device", "=", "reranker", ".", "device", ",", "\n", "logger", "=", "logger", ",", "\n", "path_to_file_to_write_results", "=", "output_eval_file", ",", "\n", "number_of_samples", "=", "number_of_samples_per_dataset", "[", "eval_dataset_name", "]", ",", "\n", ")", "\n", "\n", "execution_time", "=", "(", "time", ".", "time", "(", ")", "-", "time_start", ")", "/", "60", "\n", "total_time", "+=", "execution_time", "\n", "if", "logger", "!=", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"The execution for dataset {} took {} minutes\"", ".", "format", "(", "\n", "eval_dataset_name", ",", "execution_time", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\n", "\"The execution for dataset {} took {} minutes\"", ".", "format", "(", "\n", "eval_dataset_name", ",", "execution_time", "\n", ")", "\n", ")", "\n", "\n", "", "", "if", "logger", "!=", "None", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"The execution for dataset {} took {} minutes\"", ".", "format", "(", "\n", "eval_dataset_name", ",", "execution_time", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"The evaluation took:\"", ",", "total_time", ",", "\" minutes\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.train.main": [[41, 291], ["utils.get_reranker", "random.seed", "numpy.random.seed", "torch.manual_seed", "time.time", "utils.write_to_file", "utils.get_logger", "utils.get_logger.info", "utils.get_logger.info", "utils.read_dataset", "utils.filter_samples", "utils.get_logger.info", "len", "utils.get_reranker._process_mentions_for_model", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "utils.read_dataset", "utils.filter_samples", "utils.get_logger.info", "len", "utils.get_reranker._process_mentions_for_model", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "utils.get_logger.info", "utils.get_logger.info", "utils.get_logger.info", "utils.get_logger.info", "utils.get_reranker.get_scheduler_and_optimizer", "model.train", "tqdm.trange", "utils.write_to_file", "utils.get_logger.info", "utils.get_logger.info", "os.path.join", "utils.get_reranker", "utils.save_model", "ValueError", "torch.cuda.manual_seed_all", "os.path.exists", "os.listdir", "print", "input", "os.path.exists", "os.makedirs", "os.path.join", "str", "len", "int", "enumerate", "utils.get_logger.info", "os.path.join", "utils.save_model", "os.path.join", "evaluate.evaluate_model_on_dataset", "utils.get_logger.info", "os.path.join", "evaluate.evaluate", "input.strip", "print", "shutil.rmtree", "ValueError", "len", "len", "len", "len", "tqdm.tqdm", "tuple", "model", "loss.item", "loss.backward", "time.time", "utils.get_logger.info", "torch.nn.utils.clip_grad_norm_", "optimizer.step", "scheduler.step", "optimizer.zero_grad", "utils.get_logger.info", "evaluate.evaluate_model_on_dataset", "model.train", "utils.get_logger.info", "numpy.argmax", "numpy.argmax", "t.to", "model.parameters"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.get_reranker", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.write_to_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.get_logger", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.read_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.filter_samples", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._process_mentions_for_model", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.read_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.filter_samples", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._process_mentions_for_model", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker.get_scheduler_and_optimizer", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.write_to_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.get_reranker", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.save_model", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.save_model", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.evaluate.evaluate_model_on_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.evaluate.evaluate_model_on_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train"], ["def", "main", "(", "parameters", ")", ":", "\n", "# Read model", "\n", "    ", "reranker", "=", "utils", ".", "get_reranker", "(", "parameters", ")", "\n", "tokenizer", "=", "reranker", ".", "tokenizer", "\n", "model", "=", "reranker", ".", "model", "\n", "\n", "device", "=", "reranker", ".", "device", "\n", "n_gpu", "=", "reranker", ".", "n_gpu", "\n", "\n", "if", "parameters", "[", "\"gradient_accumulation_steps\"", "]", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\"", ".", "format", "(", "\n", "parameters", "[", "\"gradient_accumulation_steps\"", "]", "\n", ")", "\n", ")", "\n", "\n", "# An effective batch size of `x`, when we are accumulating the gradient accross `y` batches will be achieved by having a batch size of `z = x / y`", "\n", "# args.gradient_accumulation_steps = args.gradient_accumulation_steps // n_gpu", "\n", "", "parameters", "[", "\"train_batch_size\"", "]", "=", "(", "\n", "parameters", "[", "\"train_batch_size\"", "]", "//", "parameters", "[", "\"gradient_accumulation_steps\"", "]", "\n", ")", "\n", "train_batch_size", "=", "parameters", "[", "\"train_batch_size\"", "]", "\n", "evaluation_batch_size", "=", "parameters", "[", "\"evaluation_batch_size\"", "]", "\n", "gradient_accumulation_steps", "=", "parameters", "[", "\"gradient_accumulation_steps\"", "]", "\n", "\n", "# Fix the random seeds", "\n", "seed", "=", "parameters", "[", "\"seed\"", "]", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n", "logger", "=", "None", "\n", "number_of_samples_per_dataset", "=", "{", "}", "\n", "\n", "if", "reranker", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n", "", "time_start", "=", "time", ".", "time", "(", ")", "\n", "model_output_path", "=", "parameters", "[", "\"model_output_path\"", "]", "\n", "\n", "# Make sure everything is in order with the output directiory", "\n", "if", "os", ".", "path", ".", "exists", "(", "model_output_path", ")", "and", "os", ".", "listdir", "(", "model_output_path", ")", ":", "\n", "        ", "print", "(", "\n", "\"Output directory ({}) already exists and is not empty.\"", ".", "format", "(", "\n", "model_output_path", "\n", ")", "\n", ")", "\n", "answer", "=", "input", "(", "\"Would you like to empty the existing directory? [Y/N]\\n\"", ")", "\n", "if", "answer", ".", "strip", "(", ")", "==", "\"Y\"", ":", "\n", "            ", "print", "(", "\"Deleteing {}...\"", ".", "format", "(", "model_output_path", ")", ")", "\n", "shutil", ".", "rmtree", "(", "model_output_path", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty.\"", ".", "format", "(", "\n", "model_output_path", "\n", ")", "\n", ")", "\n", "\n", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "model_output_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_output_path", ")", "\n", "\n", "", "utils", ".", "write_to_file", "(", "\n", "os", ".", "path", ".", "join", "(", "model_output_path", ",", "\"training_parameters.txt\"", ")", ",", "str", "(", "parameters", ")", "\n", ")", "\n", "\n", "logger", "=", "utils", ".", "get_logger", "(", "model_output_path", ")", "\n", "logger", ".", "info", "(", "\"Starting training\"", ")", "\n", "logger", ".", "info", "(", "\n", "\"device: {} n_gpu: {}, distributed training: {}\"", ".", "format", "(", "device", ",", "n_gpu", ",", "False", ")", "\n", ")", "\n", "\n", "### Load training data", "\n", "train_dataset_name", "=", "\"aida-train\"", "\n", "train_samples", "=", "utils", ".", "read_dataset", "(", "\n", "train_dataset_name", ",", "parameters", "[", "\"path_to_preprocessed_json_data\"", "]", "\n", ")", "\n", "train_samples_filtered", "=", "utils", ".", "filter_samples", "(", "train_samples", ",", "parameters", "[", "\"top_k\"", "]", ")", "\n", "logger", ".", "info", "(", "\n", "\"Retained {} out of {} samples\"", ".", "format", "(", "\n", "len", "(", "train_samples_filtered", ")", ",", "len", "(", "train_samples", ")", "\n", ")", "\n", ")", "\n", "number_of_samples_per_dataset", "[", "train_dataset_name", "]", "=", "len", "(", "train_samples", ")", "\n", "\n", "train_data", ",", "train_tensor_data", "=", "reranker", ".", "_process_mentions_for_model", "(", "\n", "parameters", "[", "\"context_key\"", "]", ",", "\n", "train_samples_filtered", ",", "\n", "tokenizer", ",", "\n", "parameters", "[", "\"max_seq_length\"", "]", ",", "\n", "silent", "=", "parameters", "[", "\"silent\"", "]", ",", "\n", "logger", "=", "logger", ",", "\n", "top_k", "=", "parameters", "[", "\"top_k\"", "]", ",", "\n", "debug", "=", "parameters", "[", "\"debug\"", "]", ",", "\n", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_tensor_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_tensor_data", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "train_batch_size", "\n", ")", "\n", "###", "\n", "\n", "### Loading dev data", "\n", "dev_dataset_name", "=", "\"aida-A\"", "\n", "dev_samples", "=", "utils", ".", "read_dataset", "(", "\n", "dev_dataset_name", ",", "parameters", "[", "\"path_to_preprocessed_json_data\"", "]", "\n", ")", "\n", "dev_samples_filtered", "=", "utils", ".", "filter_samples", "(", "dev_samples", ",", "parameters", "[", "\"top_k\"", "]", ")", "\n", "logger", ".", "info", "(", "\n", "\"Retained {} out of {} samples\"", ".", "format", "(", "\n", "len", "(", "dev_samples_filtered", ")", ",", "len", "(", "dev_samples", ")", "\n", ")", "\n", ")", "\n", "number_of_samples_per_dataset", "[", "dev_dataset_name", "]", "=", "len", "(", "dev_samples", ")", "\n", "\n", "dev_data", ",", "dev_tensor_data", "=", "reranker", ".", "_process_mentions_for_model", "(", "\n", "parameters", "[", "\"context_key\"", "]", ",", "\n", "train_samples_filtered", ",", "\n", "tokenizer", ",", "\n", "parameters", "[", "\"max_seq_length\"", "]", ",", "\n", "silent", "=", "parameters", "[", "\"silent\"", "]", ",", "\n", "logger", "=", "logger", ",", "\n", "top_k", "=", "parameters", "[", "\"top_k\"", "]", ",", "\n", "debug", "=", "parameters", "[", "\"debug\"", "]", ",", "\n", ")", "\n", "dev_sampler", "=", "SequentialSampler", "(", "dev_tensor_data", ")", "\n", "dev_dataloader", "=", "DataLoader", "(", "\n", "dev_tensor_data", ",", "sampler", "=", "dev_sampler", ",", "batch_size", "=", "evaluation_batch_size", "\n", ")", "\n", "###", "\n", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_samples_filtered", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Gradient accumulation steps = %d\"", ",", "gradient_accumulation_steps", ")", "\n", "\n", "optimizer", ",", "scheduler", "=", "reranker", ".", "get_scheduler_and_optimizer", "(", "\n", "parameters", ",", "train_tensor_data", ",", "logger", "\n", ")", "\n", "\n", "best_epoch_idx", "=", "-", "1", "\n", "best_score", "=", "-", "1", "\n", "\n", "num_train_epochs", "=", "parameters", "[", "\"num_train_epochs\"", "]", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "for", "epoch_idx", "in", "trange", "(", "int", "(", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ")", ":", "\n", "        ", "tr_loss", "=", "0", "\n", "results", "=", "None", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Batch\"", ")", ")", ":", "\n", "            ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", ",", "entity_mask", "=", "batch", "\n", "loss", ",", "_", "=", "model", "(", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "label_ids", ",", "entity_mask", "=", "entity_mask", "\n", ")", "\n", "\n", "# if n_gpu > 1:", "\n", "#     loss = loss.mean() # mean() to average on multi-gpu.", "\n", "\n", "if", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "gradient_accumulation_steps", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "(", "\n", "parameters", "[", "\"print_tr_loss_opt_steps_interval\"", "]", "\n", "*", "parameters", "[", "\"gradient_accumulation_steps\"", "]", "\n", ")", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Step {} - epoch {} average loss: {}\\n\"", ".", "format", "(", "\n", "step", ",", "\n", "epoch_idx", ",", "\n", "tr_loss", "\n", "/", "(", "\n", "parameters", "[", "\"print_tr_loss_opt_steps_interval\"", "]", "\n", "*", "gradient_accumulation_steps", "\n", ")", ",", "\n", ")", "\n", ")", "\n", "tr_loss", "=", "0", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "model", ".", "parameters", "(", ")", ",", "parameters", "[", "\"max_grad_norm\"", "]", "\n", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "if", "(", "step", "+", "1", ")", "%", "(", "\n", "parameters", "[", "\"dev_evaluation_interval\"", "]", "\n", "*", "gradient_accumulation_steps", "\n", "*", "train_batch_size", "\n", ")", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Evaluation on the development dataset\"", ")", "\n", "evaluate_model_on_dataset", "(", "\n", "model", ",", "\n", "dev_dataloader", ",", "\n", "dev_dataset_name", ",", "\n", "device", "=", "device", ",", "\n", "logger", "=", "logger", ",", "\n", "number_of_samples", "=", "number_of_samples_per_dataset", "[", "dev_dataset_name", "]", ",", "\n", ")", "\n", "model", ".", "train", "(", ")", "\n", "logger", ".", "info", "(", "\"\\n\"", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"***** Saving fine - tuned model *****\"", ")", "\n", "epoch_output_folder_path", "=", "os", ".", "path", ".", "join", "(", "\n", "model_output_path", ",", "\"epoch_{}\"", ".", "format", "(", "epoch_idx", ")", "\n", ")", "\n", "utils", ".", "save_model", "(", "model", ",", "tokenizer", ",", "epoch_output_folder_path", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "epoch_output_folder_path", ",", "\"eval_results.txt\"", ")", "\n", "results", "=", "evaluate_model_on_dataset", "(", "\n", "model", ",", "\n", "dev_dataloader", ",", "\n", "dev_dataset_name", ",", "\n", "device", "=", "device", ",", "\n", "logger", "=", "logger", ",", "\n", "path_to_file_to_write_results", "=", "output_eval_file", ",", "\n", "number_of_samples", "=", "number_of_samples_per_dataset", "[", "dev_dataset_name", "]", ",", "\n", ")", "\n", "\n", "ls", "=", "[", "best_score", ",", "results", "[", "\"normalized_accuracy\"", "]", "]", "\n", "li", "=", "[", "best_epoch_idx", ",", "epoch_idx", "]", "\n", "\n", "best_score", "=", "ls", "[", "np", ".", "argmax", "(", "ls", ")", "]", "\n", "best_epoch_idx", "=", "li", "[", "np", ".", "argmax", "(", "ls", ")", "]", "\n", "logger", ".", "info", "(", "\"\\n\"", ")", "\n", "\n", "", "execution_time", "=", "(", "time", ".", "time", "(", ")", "-", "time_start", ")", "/", "60", "\n", "utils", ".", "write_to_file", "(", "\n", "os", ".", "path", ".", "join", "(", "model_output_path", ",", "\"training_time.txt\"", ")", ",", "\n", "\"The training took {} minutes\\n\"", ".", "format", "(", "execution_time", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"The training took {} minutes\\n\"", ".", "format", "(", "execution_time", ")", ")", "\n", "\n", "# save the best model in the parent_dir", "\n", "logger", ".", "info", "(", "\"Best performance in epoch: {}\"", ".", "format", "(", "best_epoch_idx", ")", ")", "\n", "parameters", "[", "\"path_to_model\"", "]", "=", "os", ".", "path", ".", "join", "(", "\n", "model_output_path", ",", "\"epoch_{}\"", ".", "format", "(", "best_epoch_idx", ")", "\n", ")", "\n", "reranker", "=", "utils", ".", "get_reranker", "(", "parameters", ")", "\n", "utils", ".", "save_model", "(", "reranker", ".", "model", ",", "tokenizer", ",", "model_output_path", ")", "\n", "\n", "if", "parameters", "[", "\"evaluate\"", "]", ":", "\n", "        ", "parameters", "[", "\"path_to_model\"", "]", "=", "model_output_path", "\n", "evaluate", "(", "parameters", ",", "logger", "=", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertForReranking.__init__": [[95, 102], ["pytorch_transformers.modeling_bert.BertPreTrainedModel.__init__", "pytorch_transformers.modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "bert_reranking.BertForReranking.init_weights"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForReranking", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertForReranking.forward": [[103, 158], ["input_ids.view", "bert_reranking.BertForReranking.bert", "bert_reranking.BertForReranking.dropout", "bert_reranking.BertForReranking.classifier", "bert_reranking.BertForReranking.view", "input_ids.size", "token_type_ids.view", "attention_mask.view", "position_ids.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "token_type_ids.size", "attention_mask.size", "position_ids.size"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "entity_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "\n", "# from batch_size x cands x tokens -> (batch_size x cands) x tokens", "\n", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_token_type_ids", "=", "(", "\n", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "if", "token_type_ids", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "flat_attention_mask", "=", "(", "\n", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "\n", "if", "attention_mask", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "flat_position_ids", "=", "(", "\n", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "if", "position_ids", "is", "not", "None", "\n", "else", "None", "\n", ")", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "flat_input_ids", ",", "\n", "position_ids", "=", "flat_position_ids", ",", "\n", "token_type_ids", "=", "flat_token_type_ids", ",", "\n", "attention_mask", "=", "flat_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", ")", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "num_choices", ")", "\n", "\n", "entity_mask", "=", "(", "1.0", "-", "entity_mask", ")", "*", "-", "1000.0", "\n", "reshaped_logits", "=", "reshaped_logits", "+", "entity_mask", "\n", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker.__init__": [[161, 178], ["torch.device", "torch.cuda.device_count", "bert_reranking.BertReranker.get_model", "bert_reranking.BertReranker.model.to", "bert_reranking.BertReranker.get_tokenizer", "print", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker.get_model", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker.get_tokenizer", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["    ", "def", "__init__", "(", "self", ",", "parameters", ")", ":", "\n", "        ", "if", "\"path_to_model\"", "not", "in", "parameters", ":", "\n", "            ", "parameters", "[", "\"path_to_model\"", "]", "=", "parameters", "[", "\"bert_model\"", "]", "\n", "\n", "", "self", ".", "parameters", "=", "parameters", "\n", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\n", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "parameters", "[", "\"no_cuda\"", "]", "else", "\"cpu\"", "\n", ")", "\n", "self", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "# Load the fine-tuned model and the tokenizer used by it", "\n", "self", ".", "model", "=", "BertReranker", ".", "get_model", "(", "parameters", ")", "\n", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "tokenizer", "=", "BertReranker", ".", "get_tokenizer", "(", "parameters", ")", "\n", "\n", "print", "(", "\"The reranking model is loaded\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker.rerank": [[179, 230], ["bert_reranking.BertReranker._process_mentions_for_model", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "torch.nn.Softmax", "tqdm.tqdm.tqdm", "input_ids.to.to.to", "input_mask.to.to.to", "segment_ids.to.to.to", "mention_ids.numpy.numpy.numpy", "entity_mask.to.to.to", "logits.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "torch.nn.Softmax.detach().cpu().numpy", "numpy.argmax", "enumerate", "torch.no_grad", "torch.nn.Softmax.", "predictions[].item", "[].item", "bert_reranking.BertReranker.model", "logits.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "torch.nn.Softmax.detach().cpu", "logits.detach().cpu().numpy.detach().cpu().numpy.detach", "torch.nn.Softmax.detach"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._process_mentions_for_model"], ["", "def", "rerank", "(", "self", ",", "mentions", ",", "sentences", ")", ":", "\n", "        ", "model", "=", "self", ".", "model", "\n", "tokenizer", "=", "self", ".", "tokenizer", "\n", "p", "=", "self", ".", "parameters", "\n", "device", "=", "self", ".", "device", "\n", "\n", "data", ",", "tensor_data", "=", "BertReranker", ".", "_process_mentions_for_model", "(", "\n", "p", "[", "\"context_key\"", "]", ",", "\n", "mentions", ",", "\n", "tokenizer", ",", "\n", "p", "[", "\"max_seq_length\"", "]", ",", "\n", "p", "[", "\"top_k\"", "]", ",", "\n", "p", "[", "\"silent\"", "]", ",", "\n", "sentences", "=", "sentences", ",", "\n", ")", "\n", "\n", "sampler", "=", "SequentialSampler", "(", "tensor_data", ")", "\n", "dataloader", "=", "DataLoader", "(", "\n", "tensor_data", ",", "sampler", "=", "sampler", ",", "batch_size", "=", "p", "[", "\"evaluation_batch_size\"", "]", "\n", ")", "\n", "\n", "softmax", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "\n", "for", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "mention_ids", ",", "entity_mask", "in", "tqdm", "(", "\n", "dataloader", ",", "desc", "=", "\"Inferring\"", "\n", ")", ":", "\n", "            ", "input_ids", "=", "input_ids", ".", "to", "(", "device", ")", "\n", "input_mask", "=", "input_mask", ".", "to", "(", "device", ")", "\n", "segment_ids", "=", "segment_ids", ".", "to", "(", "device", ")", "\n", "mention_ids", "=", "mention_ids", ".", "numpy", "(", ")", "\n", "entity_mask", "=", "entity_mask", ".", "to", "(", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "logits", "=", "self", ".", "model", "(", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "entity_mask", "=", "entity_mask", "\n", ")", "[", "0", "]", "\n", "probs", "=", "softmax", "(", "logits", ")", "\n", "\n", "", "logits", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "probs", "=", "probs", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "predictions", "=", "np", ".", "argmax", "(", "logits", ",", "axis", "=", "1", ")", "\n", "\n", "for", "idx", ",", "mention_idx", "in", "enumerate", "(", "mention_ids", ")", ":", "\n", "                ", "pred", "=", "predictions", "[", "idx", "]", ".", "item", "(", ")", "\n", "mentions", "[", "mention_idx", "]", "[", "\"predicted_candidate_idx\"", "]", "=", "pred", "\n", "mentions", "[", "mention_idx", "]", "[", "\"prob_assigned_to_candidate\"", "]", "=", "probs", "[", "idx", "]", "[", "\n", "pred", "\n", "]", ".", "item", "(", ")", "\n", "\n", "", "", "return", "mentions", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker.get_scheduler_and_optimizer": [[231, 280], ["int", "list", "pytorch_transformers.optimization.AdamW", "pytorch_transformers.optimization.WarmupLinearSchedule", "logger.info", "logger.info", "int", "model.named_parameters", "len", "any", "any"], "methods", ["None"], ["", "def", "get_scheduler_and_optimizer", "(", "self", ",", "parameters", ",", "train_tensor_data", ",", "logger", ")", ":", "\n", "        ", "model", "=", "self", ".", "model", "\n", "\n", "num_train_optimization_steps", "=", "(", "\n", "int", "(", "\n", "len", "(", "train_tensor_data", ")", "\n", "/", "parameters", "[", "\"train_batch_size\"", "]", "\n", "/", "parameters", "[", "\"gradient_accumulation_steps\"", "]", "\n", ")", "\n", "*", "parameters", "[", "\"num_train_epochs\"", "]", "\n", ")", "\n", "num_warmup_steps", "=", "int", "(", "\n", "num_train_optimization_steps", "*", "parameters", "[", "\"warmup_proportion\"", "]", "\n", ")", "\n", "param_optimizer", "=", "list", "(", "model", ".", "named_parameters", "(", ")", ")", "\n", "\n", "param_optimizer", "=", "[", "n", "for", "n", "in", "param_optimizer", "]", "\n", "\n", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "0.01", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "\n", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "\n", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "\n", "optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "parameters", "[", "\"learning_rate\"", "]", ",", "\n", "correct_bias", "=", "False", ",", "\n", ")", "\n", "\n", "scheduler", "=", "WarmupLinearSchedule", "(", "\n", "optimizer", ",", "\n", "warmup_steps", "=", "num_warmup_steps", ",", "\n", "t_total", "=", "num_train_optimization_steps", ",", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Num optimization steps = %d\"", ",", "num_train_optimization_steps", ")", "\n", "logger", ".", "info", "(", "\"  Num warmup steps = %d\"", ",", "num_warmup_steps", ")", "\n", "return", "optimizer", ",", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker.get_model": [[281, 294], ["BertForReranking.from_pretrained", "torch.nn.DataParallel", "print", "os.path.join", "str"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "@", "staticmethod", "\n", "def", "get_model", "(", "parameters", ")", ":", "\n", "        ", "model", "=", "BertForReranking", ".", "from_pretrained", "(", "\n", "parameters", "[", "\"path_to_model\"", "]", ",", "\n", "num_labels", "=", "parameters", "[", "\"top_k\"", "]", ",", "\n", "cache_dir", "=", "os", ".", "path", ".", "join", "(", "str", "(", "PYTORCH_PRETRAINED_BERT_CACHE", ")", ",", "\"local\"", ")", ",", "\n", ")", "\n", "\n", "if", "parameters", "[", "\"dataparallel_bert\"", "]", ":", "\n", "            ", "model", ".", "bert", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ".", "bert", ")", "\n", "print", "(", "\"Data parallel Bert\"", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker.get_tokenizer": [[295, 301], ["pytorch_transformers.tokenization_bert.BertTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained"], ["", "@", "staticmethod", "\n", "def", "get_tokenizer", "(", "parameters", ")", ":", "\n", "        ", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "\n", "parameters", "[", "\"path_to_model\"", "]", ",", "do_lower_case", "=", "parameters", "[", "\"lowercase_flag\"", "]", "\n", ")", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._get_candidate_representation": [[302, 334], ["tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize"], ["", "@", "staticmethod", "\n", "def", "_get_candidate_representation", "(", "\n", "context_tokens", ",", "candidate_desc", ",", "tokenizer", ",", "max_seq_length", ",", "max_sub_seq_length", "\n", ")", ":", "\n", "        ", "\"\"\"Tokenizes and truncates description; combines it with the tokenized context and generates one input sample for bert\"\"\"", "\n", "candidate_desc_tokens", "=", "tokenizer", ".", "tokenize", "(", "candidate_desc", ")", "\n", "candidate_desc_tokens", "=", "candidate_desc_tokens", "[", ":", "max_sub_seq_length", "]", "\n", "\n", "tokens", "=", "(", "\n", "[", "\"[CLS]\"", "]", "+", "context_tokens", "+", "[", "\"[SEP]\"", "]", "+", "candidate_desc_tokens", "+", "[", "\"[SEP]\"", "]", "\n", ")", "\n", "segment_ids", "=", "[", "0", "]", "*", "(", "len", "(", "context_tokens", ")", "+", "2", ")", "+", "[", "1", "]", "*", "(", "\n", "len", "(", "candidate_desc_tokens", ")", "+", "1", "\n", ")", "\n", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length", "\n", "padding", "=", "[", "0", "]", "*", "(", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "input_ids", "+=", "padding", "\n", "input_mask", "+=", "padding", "\n", "segment_ids", "+=", "padding", "\n", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "\n", "return", "{", "\n", "\"tokens\"", ":", "tokens", ",", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"input_mask\"", ":", "input_mask", ",", "\n", "\"segment_ids\"", ":", "segment_ids", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._get_mention_context_end2end": [[336, 354], ["sent[].strip", "sent[].strip", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_mention_context_end2end", "(", "mention", ",", "sentences", ")", ":", "\n", "        ", "\"\"\"Given a mention and a list of sentences that follow the blink conventions, it returns a left and right context for the mention\"\"\"", "\n", "sent_idx", "=", "mention", "[", "\"sent_idx\"", "]", "\n", "\n", "prev_sent", "=", "sentences", "[", "sent_idx", "-", "1", "]", "if", "sent_idx", ">", "0", "else", "\"\"", "\n", "next_sent", "=", "sentences", "[", "sent_idx", "+", "1", "]", "if", "sent_idx", "+", "1", "<", "len", "(", "sentences", ")", "else", "\"\"", "\n", "prev_sent", "=", "sentences", "[", "sent_idx", "-", "1", "]", "if", "False", "else", "\"\"", "\n", "next_sent", "=", "sentences", "[", "sent_idx", "+", "1", "]", "if", "False", "else", "\"\"", "\n", "sent", "=", "sentences", "[", "sent_idx", "]", "\n", "\n", "curr_sent_prev", "=", "sent", "[", ":", "mention", "[", "\"start_pos\"", "]", "]", ".", "strip", "(", ")", "\n", "curr_sent_next", "=", "sent", "[", "mention", "[", "\"end_pos\"", "]", ":", "]", ".", "strip", "(", ")", "\n", "\n", "left_context", "=", "\"{} {}\"", ".", "format", "(", "prev_sent", ",", "curr_sent_prev", ")", ".", "strip", "(", ")", "\n", "right_context", "=", "\"{} {}\"", ".", "format", "(", "curr_sent_next", ",", "next_sent", ")", ".", "strip", "(", ")", "\n", "\n", "return", "(", "left_context", ",", "right_context", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._select_field": [[355, 360], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_select_field", "(", "samples", ",", "field", ")", ":", "\n", "        ", "\"\"\"Helper function that returns a list of lists, each of which contains the information for all candidates for each sample\"\"\"", "\n", "return", "[", "\n", "[", "cand", "[", "field", "]", "for", "cand", "in", "sample", "[", "\"candidate_features\"", "]", "]", "for", "sample", "in", "samples", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._get_context_token_representation": [[362, 391], ["tokenizer.tokenize", "tokenizer.tokenize", "len", "len", "tokenizer.tokenize", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize"], ["", "@", "staticmethod", "\n", "def", "_get_context_token_representation", "(", "\n", "context_key", ",", "\n", "sample", ",", "\n", "tokenizer", ",", "\n", "max_sub_seq_length", ",", "\n", "start_token", ",", "\n", "end_token", ",", "\n", "mention_text_key", "=", "\"text\"", ",", "\n", "tagged", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Tags the mention, trims the context and concatenates everything to form the context representation\"\"\"", "\n", "mention_tokens", "=", "(", "\n", "[", "start_token", "]", "+", "tokenizer", ".", "tokenize", "(", "sample", "[", "mention_text_key", "]", ")", "+", "[", "end_token", "]", "\n", ")", "\n", "\n", "max_sub_seq_length", "=", "(", "max_sub_seq_length", "-", "len", "(", "mention_tokens", ")", ")", "//", "2", "\n", "\n", "context_left", ",", "context_right", "=", "sample", "[", "context_key", "]", "\n", "context_left", "=", "tokenizer", ".", "tokenize", "(", "context_left", ")", "\n", "context_right", "=", "tokenizer", ".", "tokenize", "(", "context_right", ")", "\n", "if", "len", "(", "context_left", ")", ">", "max_sub_seq_length", ":", "\n", "            ", "context_left", "=", "context_left", "[", "-", "max_sub_seq_length", ":", "]", "\n", "", "if", "len", "(", "context_right", ")", ">", "max_sub_seq_length", ":", "\n", "            ", "context_right", "=", "context_right", "[", ":", "max_sub_seq_length", "]", "\n", "\n", "", "context_tokens", "=", "context_left", "+", "mention_tokens", "+", "context_right", "\n", "\n", "return", "context_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._process_mentions_for_model": [[392, 550], ["enumerate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "tqdm.tqdm.tqdm", "bert_reranking.BertReranker._get_context_token_representation", "bert_reranking.BertReranker._select_field", "bert_reranking.BertReranker._select_field", "bert_reranking.BertReranker._select_field", "torch.tensor", "torch.utils.data.TensorDataset", "torch.tensor", "torch.utils.data.TensorDataset", "logger.info", "logger.info", "logger.info", "logger.info", "bert_reranking.BertReranker._get_mention_context_end2end", "bert_reranking.BertReranker._get_candidate_representation", "candidate_features.append", "len", "bert_reranking.BertReranker._get_candidate_representation", "range", "len", "len", "processed_mentions.append", "processed_mentions.append", "logger.info", "logger.info", "len", "candidate_features.append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._get_context_token_representation", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._select_field", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._select_field", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._select_field", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._get_mention_context_end2end", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._get_candidate_representation", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.bert_reranking.BertReranker._get_candidate_representation"], ["", "@", "staticmethod", "\n", "def", "_process_mentions_for_model", "(", "\n", "context_key", ",", "\n", "mentions", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "top_k", ",", "\n", "silent", ",", "\n", "start_token", "=", "\"[unused0]\"", ",", "\n", "end_token", "=", "\"[unused1]\"", ",", "\n", "debug", "=", "False", ",", "\n", "tagged", "=", "True", ",", "\n", "sentences", "=", "None", ",", "\n", "candidates_key", "=", "\"candidates\"", ",", "\n", "gold_key", "=", "\"gold_pos\"", ",", "\n", "logger", "=", "None", ",", "\n", ")", ":", "\n", "        ", "processed_mentions", "=", "[", "]", "\n", "\n", "if", "debug", ":", "\n", "            ", "mentions", "=", "mentions", "[", ":", "200", "]", "\n", "\n", "", "max_sub_seq_length", "=", "(", "max_seq_length", "-", "3", ")", "//", "2", "\n", "\n", "if", "silent", ":", "\n", "            ", "iter_", "=", "mentions", "\n", "", "else", ":", "\n", "            ", "iter_", "=", "tqdm", "(", "mentions", ")", "\n", "\n", "", "for", "idx", ",", "mention", "in", "enumerate", "(", "iter_", ")", ":", "\n", "# if sentences is not none that means that we are processing end2end data for inference", "\n", "            ", "if", "sentences", "is", "not", "None", ":", "\n", "                ", "mention", "[", "context_key", "]", "=", "BertReranker", ".", "_get_mention_context_end2end", "(", "\n", "mention", ",", "sentences", "\n", ")", "\n", "\n", "", "context_tokens", "=", "BertReranker", ".", "_get_context_token_representation", "(", "\n", "context_key", ",", "\n", "mention", ",", "\n", "tokenizer", ",", "\n", "max_sub_seq_length", ",", "\n", "start_token", ",", "\n", "end_token", ",", "\n", ")", "\n", "\n", "candidates", "=", "mention", "[", "candidates_key", "]", "\n", "candidate_features", "=", "[", "]", "\n", "\n", "for", "candidate", "in", "candidates", "[", ":", "top_k", "]", ":", "\n", "                ", "candidate_desc", "=", "\" \"", ".", "join", "(", "candidate", "[", "\"sentences\"", "]", ")", "\n", "\n", "candidate_obj", "=", "BertReranker", ".", "_get_candidate_representation", "(", "\n", "context_tokens", ",", "\n", "candidate_desc", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "max_sub_seq_length", ",", "\n", ")", "\n", "candidate_features", ".", "append", "(", "candidate_obj", ")", "\n", "\n", "", "entity_mask", "=", "[", "1", "]", "*", "len", "(", "candidate_features", ")", "+", "[", "0", "]", "*", "(", "\n", "top_k", "-", "len", "(", "candidate_features", ")", "\n", ")", "\n", "\n", "if", "len", "(", "candidates", ")", "<", "top_k", ":", "\n", "                ", "candidate_desc", "=", "\"\"", "\n", "padding_candidate_obj", "=", "BertReranker", ".", "_get_candidate_representation", "(", "\n", "context_tokens", ",", "\n", "candidate_desc", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "max_sub_seq_length", ",", "\n", ")", "\n", "for", "_", "in", "range", "(", "top_k", "-", "len", "(", "candidates", ")", ")", ":", "\n", "                    ", "candidate_features", ".", "append", "(", "padding_candidate_obj", ")", "\n", "\n", "", "", "assert", "len", "(", "candidate_features", ")", "==", "top_k", "\n", "assert", "len", "(", "entity_mask", ")", "==", "top_k", "\n", "\n", "if", "sentences", "is", "not", "None", ":", "\n", "                ", "processed_mentions", ".", "append", "(", "\n", "{", "\n", "\"candidate_features\"", ":", "candidate_features", ",", "\n", "\"mention_idx\"", ":", "idx", ",", "\n", "\"entity_mask\"", ":", "entity_mask", ",", "\n", "}", "\n", ")", "\n", "", "else", ":", "\n", "                ", "label", "=", "mention", "[", "gold_key", "]", "-", "1", "\n", "processed_mentions", ".", "append", "(", "\n", "{", "\n", "\"candidate_features\"", ":", "candidate_features", ",", "\n", "\"label\"", ":", "label", ",", "\n", "\"entity_mask\"", ":", "entity_mask", ",", "\n", "}", "\n", ")", "\n", "\n", "", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "\n", "BertReranker", ".", "_select_field", "(", "processed_mentions", ",", "\"input_ids\"", ")", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "\n", "BertReranker", ".", "_select_field", "(", "processed_mentions", ",", "\"input_mask\"", ")", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "\n", "BertReranker", ".", "_select_field", "(", "processed_mentions", ",", "\"segment_ids\"", ")", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", ")", "\n", "all_entity_masks", "=", "torch", ".", "tensor", "(", "\n", "[", "s", "[", "\"entity_mask\"", "]", "for", "s", "in", "processed_mentions", "]", ",", "dtype", "=", "torch", ".", "float", "\n", ")", "\n", "\n", "data", "=", "{", "\n", "\"all_input_ids\"", ":", "all_input_ids", ",", "\n", "\"all_input_mask\"", ":", "all_input_mask", ",", "\n", "\"all_segment_ids\"", ":", "all_segment_ids", ",", "\n", "\"all_entity_masks\"", ":", "all_entity_masks", ",", "\n", "}", "\n", "\n", "if", "sentences", "is", "not", "None", ":", "\n", "            ", "all_mention_indices", "=", "torch", ".", "tensor", "(", "\n", "[", "s", "[", "\"mention_idx\"", "]", "for", "s", "in", "processed_mentions", "]", ",", "dtype", "=", "torch", ".", "long", "\n", ")", "\n", "data", "[", "\"all_mention_indices\"", "]", "=", "all_mention_indices", "\n", "tensor_data", "=", "TensorDataset", "(", "\n", "all_input_ids", ",", "\n", "all_input_mask", ",", "\n", "all_segment_ids", ",", "\n", "all_mention_indices", ",", "\n", "all_entity_masks", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "all_label", "=", "torch", ".", "tensor", "(", "\n", "[", "s", "[", "\"label\"", "]", "for", "s", "in", "processed_mentions", "]", ",", "dtype", "=", "torch", ".", "long", "\n", ")", "\n", "data", "[", "\"all_label\"", "]", "=", "all_label", "\n", "tensor_data", "=", "TensorDataset", "(", "\n", "all_input_ids", ",", "\n", "all_input_mask", ",", "\n", "all_segment_ids", ",", "\n", "all_label", ",", "\n", "all_entity_masks", ",", "\n", ")", "\n", "\n", "", "if", "logger", "!=", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\"all_input_ids shape: {}\"", ".", "format", "(", "all_input_ids", ".", "shape", ")", ")", "\n", "logger", ".", "info", "(", "\"all_input_mask shape: {}\"", ".", "format", "(", "all_input_mask", ".", "shape", ")", ")", "\n", "logger", ".", "info", "(", "\"all_segment_ids shape: {}\"", ".", "format", "(", "all_segment_ids", ".", "shape", ")", ")", "\n", "logger", ".", "info", "(", "\"all_entity_masks shape: {}\"", ".", "format", "(", "all_entity_masks", ".", "shape", ")", ")", "\n", "if", "sentences", "is", "not", "None", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"all_mention_indices shape: {}\"", ".", "format", "(", "all_mention_indices", ".", "shape", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"all_label shape: {}\"", ".", "format", "(", "all_label", ".", "shape", ")", ")", "\n", "\n", "", "", "return", "data", ",", "tensor_data", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.read_dataset": [[23, 36], ["os.path.join", "io.open", "samples.append", "json.loads", "line.strip", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads"], ["", "", "", "if", "one_sentence_per_line", ":", "\n", "        ", "sentences", "=", "lines", "\n", "", "else", ":", "\n", "        ", "text", "=", "\" \"", ".", "join", "(", "lines", ")", "\n", "sentences", "=", "list", "(", "split_multi", "(", "text", ")", ")", "\n", "sentences", "=", "[", "sentence", "for", "sentence", "in", "sentences", "if", "sentence", "!=", "\"\"", "]", "\n", "\n", "", "return", "sentences", "\n", "\n", "\n", "##### Printing / writing  helpers #####", "\n", "", "def", "get_candidate_summary", "(", "candidate", ")", ":", "\n", "    ", "wikipedia_id", "=", "candidate", "[", "\"wikipedia_id\"", "]", "\n", "wikidata_id", "=", "candidate", "[", "\"wikidata_id\"", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.filter_samples": [[39, 49], ["None"], "function", ["None"], ["return", "\"{}, {}, {}\"", ".", "format", "(", "wikipedia_id", ",", "wikidata_id", ",", "wikipedia_title", ")", "\n", "\n", "\n", "", "def", "present_sentence_mentions", "(", "sentence", ",", "mentions", ",", "output_file", ")", ":", "\n", "    ", "if", "output_file", "!=", "None", ":", "\n", "        ", "f", "=", "io", ".", "open", "(", "output_file", ",", "mode", "=", "\"a\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "output", "=", "lambda", "s", ":", "f", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "s", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "lambda", "s", ":", "print", "(", "s", ")", "\n", "", "output", "(", "\"Sentence: {}\"", ".", "format", "(", "sentence", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils._truncate_seq_pair": [[51, 61], ["len", "len", "len", "len", "tokens_a.pop", "tokens_b.pop"], "function", ["None"], ["for", "mention", "in", "mentions", ":", "\n", "        ", "candidates", "=", "mention", "[", "\"candidates\"", "]", "\n", "# prediction = mention.get('predicted_candidate_idx', 0)", "\n", "prediction", "=", "mention", "[", "\"predicted_candidate_idx\"", "]", "\n", "\n", "if", "prediction", "<", "len", "(", "candidates", ")", ":", "\n", "# print(type(mention['prob_assigned_to_candidate']))", "\n", "# print(mention['prob_assigned_to_candidate'])", "\n", "            ", "mention_rep", "=", "\"{} ({}, {}) - {} (conf. {:.5f})\"", ".", "format", "(", "\n", "mention", "[", "\"text\"", "]", ",", "\n", "mention", "[", "\"start_pos\"", "]", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.eval_precision_bm45_dataloader": [[63, 84], ["torch.cat", "len"], "function", ["None"], ["get_candidate_summary", "(", "candidates", "[", "prediction", "]", ")", ",", "\n", "mention", "[", "\"prob_assigned_to_candidate\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "mention_rep", "=", "\"{} ({}, {}) - {}\"", ".", "format", "(", "\n", "mention", "[", "\"text\"", "]", ",", "\n", "mention", "[", "\"start_pos\"", "]", ",", "\n", "mention", "[", "\"end_pos\"", "]", ",", "\n", "\"No candidate selected\"", ",", "\n", ")", "\n", "\n", "", "mention_entity_pairs", ".", "append", "(", "mention_rep", ")", "\n", "\n", "", "if", "len", "(", "mention_entity_pairs", ")", "!=", "0", ":", "\n", "        ", "output", "(", "\"Mention-Entity pairs: \\n{}\"", ".", "format", "(", "\"\\n\"", ".", "join", "(", "mention_entity_pairs", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "(", "\"No detected mentions\"", ")", "\n", "\n", "", "output", "(", "\"\"", ")", "\n", "\n", "\n", "", "def", "sentence_mentions_pairs", "(", "sentences", ",", "mentions", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.accuracy": [[38, 41], ["numpy.argmax", "numpy.sum"], "function", ["None"], ["\n", "return", "\"{}, {}, {}\"", ".", "format", "(", "wikipedia_id", ",", "wikidata_id", ",", "wikipedia_title", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.remove_module_from_state_dict": [[43, 49], ["collections.OrderedDict", "state_dict.items", "key.split"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["    ", "if", "output_file", "!=", "None", ":", "\n", "        ", "f", "=", "io", ".", "open", "(", "output_file", ",", "mode", "=", "\"a\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "output", "=", "lambda", "s", ":", "f", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "s", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "lambda", "s", ":", "print", "(", "s", ")", "\n", "", "output", "(", "\"Sentence: {}\"", ".", "format", "(", "sentence", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.save_model": [[51, 62], ["os.path.join", "os.path.join", "torch.save", "model_to_save.config.to_json_file", "tokenizer.save_vocabulary", "os.path.exists", "os.makedirs", "hasattr", "model_to_save.state_dict"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save"], ["for", "mention", "in", "mentions", ":", "\n", "        ", "candidates", "=", "mention", "[", "\"candidates\"", "]", "\n", "# prediction = mention.get('predicted_candidate_idx', 0)", "\n", "prediction", "=", "mention", "[", "\"predicted_candidate_idx\"", "]", "\n", "\n", "if", "prediction", "<", "len", "(", "candidates", ")", ":", "\n", "# print(type(mention['prob_assigned_to_candidate']))", "\n", "# print(mention['prob_assigned_to_candidate'])", "\n", "            ", "mention_rep", "=", "\"{} ({}, {}) - {} (conf. {:.5f})\"", ".", "format", "(", "\n", "mention", "[", "\"text\"", "]", ",", "\n", "mention", "[", "\"start_pos\"", "]", ",", "\n", "mention", "[", "\"end_pos\"", "]", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.get_logger": [[64, 89], ["logging.getLogger", "logging.getLogger.setLevel", "os.makedirs", "logging.basicConfig", "logging.basicConfig", "logging.FileHandler", "logging.StreamHandler", "logging.StreamHandler"], "function", ["None"], ["mention", "[", "\"prob_assigned_to_candidate\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "mention_rep", "=", "\"{} ({}, {}) - {}\"", ".", "format", "(", "\n", "mention", "[", "\"text\"", "]", ",", "\n", "mention", "[", "\"start_pos\"", "]", ",", "\n", "mention", "[", "\"end_pos\"", "]", ",", "\n", "\"No candidate selected\"", ",", "\n", ")", "\n", "\n", "", "mention_entity_pairs", ".", "append", "(", "mention_rep", ")", "\n", "\n", "", "if", "len", "(", "mention_entity_pairs", ")", "!=", "0", ":", "\n", "        ", "output", "(", "\"Mention-Entity pairs: \\n{}\"", ".", "format", "(", "\"\\n\"", ".", "join", "(", "mention_entity_pairs", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "(", "\"No detected mentions\"", ")", "\n", "\n", "", "output", "(", "\"\"", ")", "\n", "\n", "\n", "", "def", "sentence_mentions_pairs", "(", "sentences", ",", "mentions", ")", ":", "\n", "    ", "mentions_per_sent", "=", "{", "}", "\n", "\n", "for", "m", "in", "mentions", ":", "\n", "        ", "sent_idx", "=", "int", "(", "m", "[", "\"sent_idx\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.write_to_file": [[91, 94], ["open", "writer.write"], "function", ["None"], ["curr_ments", ".", "append", "(", "m", ")", "\n", "\n", "mentions_per_sent", "[", "sent_idx", "]", "=", "curr_ments", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.get_reranker": [[144, 146], ["blink.candidate_ranking.bert_reranking.BertReranker"], "function", ["None"], ["", "def", "write_end2end_pickle_output", "(", "sentences", ",", "mentions", ",", "output_file_id", ")", ":", "\n", "    ", "obj", "=", "{", "\"sentences\"", ":", "sentences", ",", "\"mentions\"", ":", "mentions", "}", "\n", "with", "open", "(", "get_end2end_pickle_output_file_path", "(", "output_file_id", ")", ",", "\"wb\"", ")", "as", "file", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.get_biencoder": [[96, 98], ["elq.biencoder.biencoder.BiEncoderRanker"], "function", ["None"], ["\n", "for", "idx", ",", "sent", "in", "enumerate", "(", "sentences", ")", ":", "\n", "        ", "pairs", ".", "append", "(", "(", "sent", ",", "mentions_per_sent", ".", "get", "(", "idx", ",", "[", "]", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.data_ingestion.remove_all_docs": [[51, 53], ["solr.delete"], "function", ["None"], ["def", "remove_all_docs", "(", ")", ":", "\n", "    ", "solr", ".", "delete", "(", "q", "=", "\"*:*\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.data_ingestion.load_data": [[55, 57], ["pickle.load", "open"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["", "def", "load_data", "(", ")", ":", "\n", "    ", "return", "pickle", ".", "load", "(", "open", "(", "processed_data_path", ",", "\"rb\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.data_ingestion.get_data_for_key": [[59, 108], ["data[].get", "range", "data[].get"], "function", ["None"], ["", "def", "get_data_for_key", "(", "data", ",", "title", ")", ":", "\n", "    ", "obj", "=", "{", "}", "\n", "\n", "obj", "[", "\"id\"", "]", "=", "data", "[", "title", "]", "[", "\"wikipedia_id\"", "]", "\n", "obj", "[", "\"title\"", "]", "=", "title", "\n", "\n", "if", "(", "\"wikidata_info\"", "in", "data", "[", "title", "]", ")", "and", "(", "\n", "data", "[", "title", "]", "[", "\"wikidata_info\"", "]", "[", "\"wikidata_id\"", "]", "is", "not", "None", "\n", ")", ":", "\n", "        ", "obj", "[", "\"wikidata_id\"", "]", "=", "data", "[", "title", "]", "[", "\"wikidata_info\"", "]", "[", "\"wikidata_id\"", "]", "\n", "", "else", ":", "\n", "        ", "obj", "[", "\"wikidata_id\"", "]", "=", "data", "[", "title", "]", "[", "\"wikidata_id_from_index\"", "]", "\n", "\n", "", "description", "=", "data", "[", "title", "]", "[", "\"intro_concatenated\"", "]", "\n", "obj", "[", "\"desc\"", "]", "=", "description", "\n", "\n", "if", "\"wikidata_info\"", "in", "data", "[", "title", "]", ":", "\n", "        ", "if", "\"description\"", "in", "data", "[", "title", "]", "[", "\"wikidata_info\"", "]", ":", "\n", "            ", "wikidata_description", "=", "data", "[", "title", "]", "[", "\"wikidata_info\"", "]", "[", "\"description\"", "]", "\n", "", "else", ":", "\n", "            ", "wikidata_description", "=", "\"\"", "\n", "\n", "", "if", "(", "\"aliases\"", "in", "data", "[", "title", "]", "[", "\"wikidata_info\"", "]", ")", "and", "(", "\n", "data", "[", "title", "]", "[", "\"wikidata_info\"", "]", "[", "\"aliases\"", "]", "\n", ")", "is", "not", "None", ":", "\n", "            ", "aliases", "=", "\" \"", ".", "join", "(", "\n", "[", "\n", "'\"{}\"'", ".", "format", "(", "alias", ")", "\n", "for", "alias", "in", "data", "[", "title", "]", "[", "\"wikidata_info\"", "]", "[", "\"aliases\"", "]", "\n", "if", "alias", "not", "in", "emoji", ".", "UNICODE_EMOJI", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "            ", "aliases", "=", "\"\"", "\n", "", "", "else", ":", "\n", "        ", "aliases", "=", "\"\"", "\n", "wikidata_description", "=", "\"\"", "\n", "\n", "", "obj", "[", "\"aliases\"", "]", "=", "aliases", "\n", "obj", "[", "\"wikidata_desc\"", "]", "=", "wikidata_description", "\n", "obj", "[", "\"num_tokens\"", "]", "=", "data", "[", "title", "]", "[", "\"num_tokens\"", "]", "\n", "obj", "[", "\"num_incoming_links\"", "]", "=", "data", "[", "title", "]", ".", "get", "(", "\"num_incoming_links\"", ",", "0", ")", "\n", "\n", "if", "args", ".", "add_sentence_data", ":", "\n", "        ", "for", "k", "in", "range", "(", "0", ",", "10", ")", ":", "\n", "            ", "key", "=", "\"sent_desc_{}\"", ".", "format", "(", "k", "+", "1", ")", "\n", "obj", "[", "key", "]", "=", "data", "[", "title", "]", ".", "get", "(", "key", ",", "\"\"", ")", "\n", "\n", "", "", "return", "obj", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Simple_Candidate_Generator.__init__": [[17, 36], ["pysolr.Solr"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "collection_name", "=", "params", "[", "\"collection_name\"", "]", "\n", "self", ".", "solr_address", "=", "params", "[", "\"solr_address\"", "]", "\n", "self", ".", "solr", "=", "pysolr", ".", "Solr", "(", "\n", "\"{}/solr/{}\"", ".", "format", "(", "self", ".", "solr_address", ",", "self", ".", "collection_name", ")", ",", "\n", "always_commit", "=", "True", ",", "\n", "timeout", "=", "100", ",", "\n", ")", "\n", "self", ".", "rows", "=", "params", "[", "\"rows\"", "]", "\n", "self", ".", "query_data", "=", "params", "[", "\"query_data\"", "]", "\n", "self", ".", "c", "=", "0", "\n", "self", ".", "query_arguments", "=", "{", "\n", "\"fl\"", ":", "\"* score\"", ",", "\n", "\"rows\"", ":", "self", ".", "rows", ",", "\n", "\"defType\"", ":", "\"edismax\"", ",", "\n", "}", "\n", "\n", "if", "params", "[", "\"boosting\"", "]", "is", "not", "None", ":", "\n", "            ", "self", ".", "query_arguments", "[", "\"bf\"", "]", "=", "params", "[", "\"boosting\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Simple_Candidate_Generator._filter_result": [[37, 58], ["cand.get", "cand.get", "range", "cand.get", "sents.append", "cand.get"], "methods", ["None"], ["", "", "def", "_filter_result", "(", "self", ",", "cand", ")", ":", "\n", "        ", "wikidata_id", "=", "cand", ".", "get", "(", "\"wikidata_id\"", ",", "None", ")", "\n", "res", "=", "{", "\n", "\"wikidata_id\"", ":", "wikidata_id", ",", "\n", "\"wikipedia_id\"", ":", "cand", "[", "\"id\"", "]", ",", "\n", "\"wikipedia_title\"", ":", "cand", "[", "\"title\"", "]", ",", "\n", "}", "\n", "\n", "res", "[", "\"aliases\"", "]", "=", "cand", ".", "get", "(", "\"aliases\"", ",", "None", ")", "\n", "sents", "=", "[", "]", "\n", "\n", "for", "k", "in", "range", "(", "0", ",", "10", ")", ":", "\n", "            ", "key", "=", "\"sent_desc_{}\"", ".", "format", "(", "k", "+", "1", ")", "\n", "sents", ".", "append", "(", "cand", ".", "get", "(", "key", ",", "\"\"", ")", ")", "\n", "\n", "", "res", "[", "\"sentences\"", "]", "=", "sents", "\n", "\n", "res", "[", "\"num_incoming_links\"", "]", "=", "cand", ".", "get", "(", "\"num_incoming_links\"", ",", "0", ")", "\n", "res", "[", "\"score\"", "]", "=", "cand", "[", "\"score\"", "]", "\n", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Simple_Candidate_Generator.get_candidates": [[59, 117], ["query.format.format.format", "print", "solr.search", "print", "candidate_generators.Simple_Candidate_Generator._filter_result", "sys.exc_info", "print", "print", "repr", "print", "len", "utils.get_sent_context", "candidate_generators.mention_data_summary", "str"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.zeshel.create_BLINK_zeshel_data.LogFormatter.format", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Simple_Candidate_Generator._filter_result", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.get_sent_context", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.mention_data_summary"], ["", "def", "get_candidates", "(", "\n", "self", ",", "\n", "mention_data", ",", "\n", "verbose", "=", "False", ",", "\n", "print_number_of_docs_retrieved", "=", "False", ",", "\n", "print_query_flag", "=", "False", ",", "\n", ")", ":", "\n", "        ", "solr", "=", "self", ".", "solr", "\n", "query_data", "=", "self", ".", "query_data", "\n", "\n", "# Build query", "\n", "keys", "=", "query_data", "[", "\"keys\"", "]", "\n", "query", "=", "query_data", "[", "\"string\"", "]", "\n", "query", "=", "query", ".", "format", "(", "\n", "*", "[", "\n", "mention_data", "[", "key", "]", "\n", "if", "key", "in", "mention_data", "\n", "else", "utils", ".", "get_sent_context", "(", "mention_data", ",", "key", ")", "\n", "for", "key", "in", "keys", "\n", "]", "\n", ")", "\n", "\n", "if", "print_query_flag", ":", "\n", "            ", "print", "(", "\"Query: {}\"", ".", "format", "(", "query", ")", ")", "\n", "\n", "", "try", ":", "\n", "            ", "results", "=", "solr", ".", "search", "(", "query", ",", "**", "self", ".", "query_arguments", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "exc_type", ",", "exc_obj", ",", "exc_tb", "=", "sys", ".", "exc_info", "(", ")", "\n", "print", "(", "\"\\nException:\"", ",", "exc_type", ",", "\"- line\"", ",", "exc_tb", ".", "tb_lineno", ")", "\n", "print", "(", "repr", "(", "e", ")", ")", "\n", "\n", "c", "=", "self", ".", "c", "\n", "c", "+=", "1", "\n", "if", "c", "<", "10", ":", "\n", "                ", "print", "(", "\n", "\"Exception with: \\ncollection_name: {} \\nquery: {} \\nmention_data: {} \\ndataset_name: {}\\nquery_args: {}\\n\"", ".", "format", "(", "\n", "self", ".", "collection_name", ",", "\n", "query", ",", "\n", "mention_data_summary", "(", "mention_data", ")", ",", "\n", "mention_data", "[", "\"dataset_name\"", "]", ",", "\n", "str", "(", "self", ".", "query_arguments", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "", "return", "[", "]", "\n", "\n", "", "if", "print_number_of_docs_retrieved", ":", "\n", "            ", "print", "(", "\"Retrieved {0} result(s).\"", ".", "format", "(", "len", "(", "results", ")", ")", ")", "\n", "# Return the full retrieved objects (debuging purposes)", "\n", "", "if", "verbose", ":", "\n", "            ", "return", "results", "\n", "\n", "# Filter the data in the retrieved objects, while ignoring the ones without a wikidata_id (only a very small fraction in the dataset; they are noise)", "\n", "", "filtered_results", "=", "[", "\n", "self", ".", "_filter_result", "(", "cand", ")", "for", "cand", "in", "results", ".", "docs", "if", "\"wikidata_id\"", "in", "cand", "\n", "]", "\n", "return", "filtered_results", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Pregenerated_Candidates_Data_Fetcher.__init__": [[120, 131], ["pysolr.Solr"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "parameters", ")", ":", "\n", "        ", "solr_address", "=", "\"http://localhost:8983/solr/{}\"", ".", "format", "(", "\n", "parameters", "[", "\"collection_name\"", "]", "\n", ")", "\n", "\n", "query_arguments", "=", "{", "\"fl\"", ":", "\"* score\"", ",", "\"rows\"", ":", "1", ",", "\"defType\"", ":", "\"edismax\"", "}", "\n", "\n", "query_arguments", "[", "\"bf\"", "]", "=", "\"log(sum(num_incoming_links,1))\"", "\n", "\n", "self", ".", "solr", "=", "pysolr", ".", "Solr", "(", "solr_address", ",", "always_commit", "=", "True", ",", "timeout", "=", "100", ")", "\n", "self", ".", "query_arguments", "=", "query_arguments", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Pregenerated_Candidates_Data_Fetcher.get_candidates_data": [[132, 143], ["candidate_generators.Pregenerated_Candidates_Data_Fetcher.get_candidate_data_for_wikidata_id", "candidates_rich.append"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Pregenerated_Candidates_Data_Fetcher.get_candidate_data_for_wikidata_id"], ["", "def", "get_candidates_data", "(", "self", ",", "candidates_wikidata_ids", ")", ":", "\n", "        ", "candidates_rich", "=", "[", "]", "\n", "\n", "for", "candidate", "in", "candidates_wikidata_ids", ":", "\n", "            ", "candidate_data", "=", "self", ".", "get_candidate_data_for_wikidata_id", "(", "candidate", "[", "0", "]", ")", "\n", "\n", "if", "candidate_data", "!=", "None", ":", "\n", "                ", "candidate_data", "[", "\"p_e_m_score\"", "]", "=", "candidate", "[", "2", "]", "\n", "candidates_rich", ".", "append", "(", "candidate_data", ")", "\n", "\n", "", "", "return", "candidates_rich", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Pregenerated_Candidates_Data_Fetcher.filter_result": [[144, 164], ["cand.get", "cand.get", "range", "sents.append", "cand.get"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "filter_result", "(", "cand", ",", "detailed", "=", "True", ")", ":", "\n", "        ", "wikidata_id", "=", "cand", ".", "get", "(", "\"wikidata_id\"", ",", "None", ")", "\n", "res", "=", "{", "\n", "\"wikidata_id\"", ":", "wikidata_id", ",", "\n", "\"wikipedia_id\"", ":", "cand", "[", "\"id\"", "]", ",", "\n", "\"wikipedia_title\"", ":", "cand", "[", "\"title\"", "]", ",", "\n", "}", "\n", "\n", "if", "detailed", ":", "\n", "            ", "res", "[", "\"aliases\"", "]", "=", "cand", ".", "get", "(", "\"aliases\"", ",", "None", ")", "\n", "sents", "=", "[", "]", "\n", "\n", "for", "k", "in", "range", "(", "0", ",", "10", ")", ":", "\n", "                ", "key", "=", "\"sent_desc_{}\"", ".", "format", "(", "k", "+", "1", ")", "\n", "sents", ".", "append", "(", "cand", ".", "get", "(", "key", ",", "\"\"", ")", ")", "\n", "\n", "", "res", "[", "\"sentences\"", "]", "=", "sents", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Pregenerated_Candidates_Data_Fetcher.get_candidate_data_for_wikidata_id": [[165, 180], ["candidate_generators.Pregenerated_Candidates_Data_Fetcher.solr.search", "len", "candidate_generators.Pregenerated_Candidates_Data_Fetcher.filter_result"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Pregenerated_Candidates_Data_Fetcher.filter_result"], ["", "def", "get_candidate_data_for_wikidata_id", "(", "self", ",", "wikidata_id", ")", ":", "\n", "        ", "results", "=", "self", ".", "solr", ".", "search", "(", "\n", "\"wikidata_id:{}\"", ".", "format", "(", "wikidata_id", ")", ",", "**", "self", ".", "query_arguments", "\n", ")", "\n", "\n", "if", "len", "(", "results", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "\n", "", "filtered_results", "=", "[", "\n", "Pregenerated_Candidates_Data_Fetcher", ".", "filter_result", "(", "cand", ")", "\n", "for", "cand", "in", "results", ".", "docs", "\n", "if", "\"wikidata_id\"", "in", "cand", "\n", "]", "\n", "\n", "return", "filtered_results", "[", "0", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.mention_data_summary": [[12, 14], ["None"], "function", ["None"], ["def", "mention_data_summary", "(", "mention", ")", ":", "\n", "    ", "return", "(", "mention", "[", "\"mention\"", "]", ",", "mention", "[", "\"query_truncated_25_context\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.CoNLLDataset.__init__": [[240, 297], ["print", "print", "dataset.read_csv_file", "dataset.read_csv_file", "dataset.read_csv_file", "dataset.read_csv_file", "dataset.read_csv_file", "dataset.read_csv_file", "dataset.read_csv_file", "dataset.read_csv_file", "dataset.CoNLLDataset.wikipedia.pop", "print", "dataset.load_person_names", "dataset.with_coref", "dataset.with_coref", "dataset.with_coref", "dataset.with_coref", "dataset.with_coref", "dataset.with_coref", "dataset.with_coref", "dataset.with_coref", "print", "dataset.read_conll_file", "dataset.read_conll_file", "dataset.read_conll_file", "dataset.read_conll_file", "dataset.read_conll_file", "dataset.read_conll_file", "dataset.read_conll_file", "dataset.read_conll_file", "dataset.get_candidate_generator", "print", "print", "len", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_csv_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_csv_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_csv_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_csv_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_csv_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_csv_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_csv_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_csv_file", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.load_person_names", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.with_coref", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.with_coref", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.with_coref", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.with_coref", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.with_coref", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.with_coref", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.with_coref", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.with_coref", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_conll_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_conll_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_conll_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_conll_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_conll_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_conll_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_conll_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_conll_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.get_candidate_generator", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["def", "__init__", "(", "self", ",", "path", ",", "person_path", ",", "conll_path", ",", "added_params", ")", ":", "\n", "        ", "if", "added_params", "[", "\"generate_ments_and_cands\"", "]", ":", "\n", "            ", "added_params", "[", "\"generate_cands\"", "]", "=", "False", "\n", "\n", "", "if", "added_params", "[", "\"generate_cands\"", "]", "or", "added_params", "[", "\"generate_ments_and_cands\"", "]", ":", "\n", "            ", "added_params", "[", "\"cand_generator\"", "]", "=", "get_candidate_generator", "(", "added_params", ")", "\n", "\n", "", "print", "(", "added_params", ")", "\n", "\n", "print", "(", "\"load csv\"", ")", "\n", "self", ".", "train", "=", "read_csv_file", "(", "path", "+", "\"/aida_train.csv\"", ",", "added_params", ")", "\n", "self", ".", "testA", "=", "read_csv_file", "(", "path", "+", "\"/aida_testA.csv\"", ",", "added_params", ")", "\n", "self", ".", "testB", "=", "read_csv_file", "(", "path", "+", "\"/aida_testB.csv\"", ",", "added_params", ")", "\n", "self", ".", "ace2004", "=", "read_csv_file", "(", "path", "+", "\"/wned-ace2004.csv\"", ",", "added_params", ")", "\n", "self", ".", "aquaint", "=", "read_csv_file", "(", "path", "+", "\"/wned-aquaint.csv\"", ",", "added_params", ")", "\n", "self", ".", "clueweb", "=", "read_csv_file", "(", "path", "+", "\"/wned-clueweb.csv\"", ",", "added_params", ")", "\n", "self", ".", "msnbc", "=", "read_csv_file", "(", "path", "+", "\"/wned-msnbc.csv\"", ",", "added_params", ")", "\n", "self", ".", "wikipedia", "=", "read_csv_file", "(", "path", "+", "\"/wned-wikipedia.csv\"", ",", "added_params", ")", "\n", "self", ".", "wikipedia", ".", "pop", "(", "\"Ji\u0159\u00ed_T\u0159anovsk\u00fd Ji\u0159\u00ed_T\u0159anovsk\u00fd\"", ",", "None", ")", "\n", "\n", "print", "(", "\"process coref\"", ")", "\n", "person_names", "=", "load_person_names", "(", "person_path", ")", "\n", "with_coref", "(", "self", ".", "train", ",", "person_names", ")", "\n", "with_coref", "(", "self", ".", "testA", ",", "person_names", ")", "\n", "with_coref", "(", "self", ".", "testB", ",", "person_names", ")", "\n", "with_coref", "(", "self", ".", "ace2004", ",", "person_names", ")", "\n", "with_coref", "(", "self", ".", "aquaint", ",", "person_names", ")", "\n", "with_coref", "(", "self", ".", "clueweb", ",", "person_names", ")", "\n", "with_coref", "(", "self", ".", "msnbc", ",", "person_names", ")", "\n", "with_coref", "(", "self", ".", "wikipedia", ",", "person_names", ")", "\n", "\n", "print", "(", "\"load conll\"", ")", "\n", "read_conll_file", "(", "self", ".", "train", ",", "conll_path", "+", "\"/AIDA/aida_train.txt\"", ")", "\n", "read_conll_file", "(", "self", ".", "testA", ",", "conll_path", "+", "\"/AIDA/testa_testb_aggregate_original\"", ")", "\n", "read_conll_file", "(", "self", ".", "testB", ",", "conll_path", "+", "\"/AIDA/testa_testb_aggregate_original\"", ")", "\n", "read_conll_file", "(", "\n", "self", ".", "ace2004", ",", "conll_path", "+", "\"/wned-datasets/ace2004/ace2004.conll\"", "\n", ")", "\n", "read_conll_file", "(", "\n", "self", ".", "aquaint", ",", "conll_path", "+", "\"/wned-datasets/aquaint/aquaint.conll\"", "\n", ")", "\n", "read_conll_file", "(", "self", ".", "msnbc", ",", "conll_path", "+", "\"/wned-datasets/msnbc/msnbc.conll\"", ")", "\n", "read_conll_file", "(", "\n", "self", ".", "clueweb", ",", "conll_path", "+", "\"/wned-datasets/clueweb/clueweb.conll\"", "\n", ")", "\n", "read_conll_file", "(", "\n", "self", ".", "wikipedia", ",", "conll_path", "+", "\"/wned-datasets/wikipedia/wikipedia.conll\"", "\n", ")", "\n", "\n", "if", "added_params", "[", "\"generate_cands\"", "]", ":", "\n", "            ", "print", "(", "\n", "\"Number of candidates not present in p_e_m originally, but present when lowercased\"", ",", "\n", "len", "(", "added_params", "[", "\"cand_generator\"", "]", ".", "lower_org", ")", ",", "\n", ")", "\n", "print", "(", "\n", "\"Number of candidates not present in p_e_m originally, but present in p_e_m_lower when lowercased \"", ",", "\n", "len", "(", "added_params", "[", "\"cand_generator\"", "]", ".", "lower_lower", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.FetchCandidateEntities.__init__": [[305, 321], ["print", "time.time", "pickle.load", "pickle.load", "pickle.load", "print", "open", "open", "open", "os.path.join", "os.path.join", "os.path.join", "time.time"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["def", "__init__", "(", "self", ",", "p_e_m_data_path", "=", "\"data/basic_data/p_e_m_data/\"", ")", ":", "\n", "        ", "print", "(", "\"Reading p_e_m dictionaries\"", ")", "\n", "# return", "\n", "wall_start", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "lower_org", "=", "[", "]", "\n", "self", ".", "lower_lower", "=", "[", "]", "\n", "self", ".", "p_e_m", "=", "pickle", ".", "load", "(", "\n", "open", "(", "os", ".", "path", ".", "join", "(", "p_e_m_data_path", ",", "\"p_e_m_dict.pickle\"", ")", ",", "\"rb\"", ")", "\n", ")", "\n", "self", ".", "p_e_m_lower", "=", "pickle", ".", "load", "(", "\n", "open", "(", "os", ".", "path", ".", "join", "(", "p_e_m_data_path", ",", "\"p_e_m_lower_dict.pickle\"", ")", ",", "\"rb\"", ")", "\n", ")", "\n", "self", ".", "mention_total_freq", "=", "pickle", ".", "load", "(", "\n", "open", "(", "os", ".", "path", ".", "join", "(", "p_e_m_data_path", ",", "\"mention_total_freq.pickle\"", ")", ",", "\"rb\"", ")", "\n", ")", "\n", "print", "(", "\"The reading took:\"", ",", "(", "time", ".", "time", "(", ")", "-", "wall_start", ")", "/", "60", ",", "\" minutes\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.FetchCandidateEntities.process": [[322, 348], ["span.title", "span.lower", "dataset.FetchCandidateEntities.lower_org.append", "span.lower", "dataset.FetchCandidateEntities.lower_lower.append", "span.lower", "span.lower"], "methods", ["None"], ["", "def", "process", "(", "self", ",", "span", ")", ":", "\n", "        ", "\"\"\"span can be either a string or a list of words\"\"\"", "\n", "\n", "title", "=", "span", ".", "title", "(", ")", "\n", "# 'obama 44th president of united states'.title() # 'Obama 44Th President Of United States'", "\n", "title_freq", "=", "(", "\n", "self", ".", "mention_total_freq", "[", "title", "]", "if", "title", "in", "self", ".", "mention_total_freq", "else", "0", "\n", ")", "\n", "span_freq", "=", "(", "\n", "self", ".", "mention_total_freq", "[", "span", "]", "if", "span", "in", "self", ".", "mention_total_freq", "else", "0", "\n", ")", "\n", "\n", "if", "title_freq", "==", "0", "and", "span_freq", "==", "0", ":", "\n", "            ", "if", "span", ".", "lower", "(", ")", "in", "self", ".", "p_e_m", ":", "\n", "                ", "self", ".", "lower_org", ".", "append", "(", "span", ")", "\n", "return", "self", ".", "p_e_m", "[", "span", ".", "lower", "(", ")", "]", "\n", "", "elif", "span", ".", "lower", "(", ")", "in", "self", ".", "p_e_m_lower", ":", "\n", "                ", "self", ".", "lower_lower", ".", "append", "(", "span", ")", "\n", "return", "self", ".", "p_e_m_lower", "[", "span", ".", "lower", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "return", "[", "]", "\n", "", "", "else", ":", "\n", "            ", "if", "span_freq", ">", "title_freq", ":", "\n", "                ", "return", "self", ".", "p_e_m", "[", "span", "]", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "p_e_m", "[", "title", "]", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_csv_file": [[18, 70], ["open", "line.strip().split", "comps[].split", "data[].append", "added_params[].process", "line.strip", "c.split", "print", "float"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.FetchCandidateEntities.process", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["def", "read_csv_file", "(", "path", ",", "added_params", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "info", "=", "True", "\n", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "comps", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "doc_name", "=", "comps", "[", "0", "]", "+", "\" \"", "+", "comps", "[", "1", "]", "\n", "mention", "=", "comps", "[", "2", "]", "\n", "lctx", "=", "comps", "[", "3", "]", "\n", "rctx", "=", "comps", "[", "4", "]", "\n", "\n", "if", "comps", "[", "6", "]", "!=", "\"EMPTYCAND\"", ":", "\n", "                ", "cands", "=", "[", "c", ".", "split", "(", "\",\"", ")", "for", "c", "in", "comps", "[", "6", ":", "-", "2", "]", "]", "\n", "cands", "=", "[", "\n", "(", "\",\"", ".", "join", "(", "c", "[", "2", ":", "]", ")", ".", "replace", "(", "'\"'", ",", "\"%22\"", ")", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ",", "float", "(", "c", "[", "1", "]", ")", ")", "\n", "for", "c", "in", "cands", "\n", "]", "\n", "", "else", ":", "\n", "                ", "cands", "=", "[", "]", "\n", "\n", "", "gold", "=", "comps", "[", "-", "1", "]", ".", "split", "(", "\",\"", ")", "\n", "if", "gold", "[", "0", "]", "==", "\"-1\"", ":", "\n", "                ", "gold", "=", "(", "\n", "\",\"", ".", "join", "(", "gold", "[", "2", ":", "]", ")", ".", "replace", "(", "'\"'", ",", "\"%22\"", ")", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ",", "\n", "1e-5", ",", "\n", "-", "1", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "gold", "=", "(", "\n", "\",\"", ".", "join", "(", "gold", "[", "3", ":", "]", ")", ".", "replace", "(", "'\"'", ",", "\"%22\"", ")", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ",", "\n", "1e-5", ",", "\n", "-", "1", ",", "\n", ")", "\n", "\n", "", "if", "added_params", "[", "\"generate_cands\"", "]", ":", "\n", "                ", "if", "info", ":", "\n", "                    ", "print", "(", "\"Generating candidates\"", ")", "\n", "info", "=", "False", "\n", "", "cands", "=", "added_params", "[", "\"cand_generator\"", "]", ".", "process", "(", "mention", ")", "\n", "\n", "", "if", "doc_name", "not", "in", "data", ":", "\n", "                ", "data", "[", "doc_name", "]", "=", "[", "]", "\n", "\n", "", "data", "[", "doc_name", "]", ".", "append", "(", "\n", "{", "\n", "\"mention\"", ":", "mention", ",", "\n", "\"context\"", ":", "(", "lctx", ",", "rctx", ")", ",", "\n", "\"candidates\"", ":", "cands", ",", "\n", "\"gold\"", ":", "gold", ",", "\n", "}", "\n", ")", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.read_conll_file": [[73, 139], ["re.compile", "data.items", "open", "line.strip.strip", "line.strip.startswith", "cur_doc[].append", "line.strip.split", "cur_sent.append", "doc_name.split", "re.compile.sub", "re.compile.sub", "line.strip.split", "len", "cur_conll_mention.lower", "mention.lower", "cur_doc[].append", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "read_conll_file", "(", "data", ",", "path", ")", ":", "\n", "    ", "conll", "=", "{", "}", "\n", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "        ", "cur_sent", "=", "None", "\n", "cur_doc", "=", "None", "\n", "\n", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ".", "startswith", "(", "\"-DOCSTART-\"", ")", ":", "\n", "                ", "docname", "=", "line", ".", "split", "(", ")", "[", "1", "]", "[", "1", ":", "]", "\n", "conll", "[", "docname", "]", "=", "{", "\"sentences\"", ":", "[", "]", ",", "\"mentions\"", ":", "[", "]", "}", "\n", "cur_doc", "=", "conll", "[", "docname", "]", "\n", "cur_sent", "=", "[", "]", "\n", "\n", "", "else", ":", "\n", "                ", "if", "line", "==", "\"\"", ":", "\n", "                    ", "cur_doc", "[", "\"sentences\"", "]", ".", "append", "(", "cur_sent", ")", "\n", "cur_sent", "=", "[", "]", "\n", "\n", "", "else", ":", "\n", "                    ", "comps", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "tok", "=", "comps", "[", "0", "]", "\n", "cur_sent", ".", "append", "(", "tok", ")", "\n", "\n", "if", "len", "(", "comps", ")", ">=", "6", ":", "\n", "                        ", "bi", "=", "comps", "[", "1", "]", "\n", "wikilink", "=", "comps", "[", "4", "]", "\n", "if", "bi", "==", "\"I\"", ":", "\n", "                            ", "cur_doc", "[", "\"mentions\"", "]", "[", "-", "1", "]", "[", "\"end\"", "]", "+=", "1", "\n", "", "else", ":", "\n", "                            ", "new_ment", "=", "{", "\n", "\"sent_id\"", ":", "len", "(", "cur_doc", "[", "\"sentences\"", "]", ")", ",", "\n", "\"start\"", ":", "len", "(", "cur_sent", ")", "-", "1", ",", "\n", "\"end\"", ":", "len", "(", "cur_sent", ")", ",", "\n", "\"wikilink\"", ":", "wikilink", ",", "\n", "}", "\n", "cur_doc", "[", "\"mentions\"", "]", ".", "append", "(", "new_ment", ")", "\n", "\n", "# merge with data", "\n", "", "", "", "", "", "", "rmpunc", "=", "re", ".", "compile", "(", "\"[\\W]+\"", ")", "\n", "for", "doc_name", ",", "content", "in", "data", ".", "items", "(", ")", ":", "\n", "        ", "conll_doc", "=", "conll", "[", "doc_name", ".", "split", "(", ")", "[", "0", "]", "]", "\n", "content", "[", "0", "]", "[", "\"conll_doc\"", "]", "=", "conll_doc", "\n", "\n", "cur_conll_m_id", "=", "0", "\n", "for", "m", "in", "content", ":", "\n", "            ", "mention", "=", "m", "[", "\"mention\"", "]", "\n", "gold", "=", "m", "[", "\"gold\"", "]", "\n", "\n", "while", "True", ":", "\n", "                ", "cur_conll_m", "=", "conll_doc", "[", "\"mentions\"", "]", "[", "cur_conll_m_id", "]", "\n", "cur_conll_mention", "=", "\" \"", ".", "join", "(", "\n", "conll_doc", "[", "\"sentences\"", "]", "[", "cur_conll_m", "[", "\"sent_id\"", "]", "]", "[", "\n", "cur_conll_m", "[", "\"start\"", "]", ":", "cur_conll_m", "[", "\"end\"", "]", "\n", "]", "\n", ")", "\n", "if", "rmpunc", ".", "sub", "(", "\"\"", ",", "cur_conll_mention", ".", "lower", "(", ")", ")", "==", "rmpunc", ".", "sub", "(", "\n", "\"\"", ",", "mention", ".", "lower", "(", ")", "\n", ")", ":", "\n", "                    ", "m", "[", "\"conll_m\"", "]", "=", "cur_conll_m", "\n", "cur_conll_m_id", "+=", "1", "\n", "break", "\n", "", "else", ":", "\n", "                    ", "cur_conll_m_id", "+=", "1", "\n", "\n", "", "", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.load_person_names": [[145, 151], ["set", "open", "data.append", "line.strip().replace", "line.strip"], "function", ["None"], ["", "def", "load_person_names", "(", "path", ")", ":", "\n", "    ", "data", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "data", ".", "append", "(", "line", ".", "strip", "(", ")", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ")", "\n", "", "", "return", "set", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.find_coref": [[153, 172], ["ment[].lower", "m[].lower", "m[].lower.find", "coref.append", "len", "len", "len"], "function", ["None"], ["", "def", "find_coref", "(", "ment", ",", "mentlist", ",", "person_names", ")", ":", "\n", "    ", "cur_m", "=", "ment", "[", "\"mention\"", "]", ".", "lower", "(", ")", "\n", "coref", "=", "[", "]", "\n", "for", "m", "in", "mentlist", ":", "\n", "        ", "if", "len", "(", "m", "[", "\"candidates\"", "]", ")", "==", "0", "or", "m", "[", "\"candidates\"", "]", "[", "0", "]", "[", "0", "]", "not", "in", "person_names", ":", "\n", "            ", "continue", "\n", "\n", "", "mention", "=", "m", "[", "\"mention\"", "]", ".", "lower", "(", ")", "\n", "start_pos", "=", "mention", ".", "find", "(", "cur_m", ")", "\n", "if", "start_pos", "==", "-", "1", "or", "mention", "==", "cur_m", ":", "\n", "            ", "continue", "\n", "\n", "", "end_pos", "=", "start_pos", "+", "len", "(", "cur_m", ")", "-", "1", "\n", "if", "(", "start_pos", "==", "0", "or", "mention", "[", "start_pos", "-", "1", "]", "==", "\" \"", ")", "and", "(", "\n", "end_pos", "==", "len", "(", "mention", ")", "-", "1", "or", "mention", "[", "end_pos", "+", "1", "]", "==", "\" \"", "\n", ")", ":", "\n", "            ", "coref", ".", "append", "(", "m", ")", "\n", "\n", "", "", "return", "coref", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.with_coref": [[174, 188], ["dataset.items", "dataset.find_coref", "cur_cands.keys", "len", "len", "sorted", "list", "cur_cands.get", "cur_cands.items"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.find_coref"], ["", "def", "with_coref", "(", "dataset", ",", "person_names", ")", ":", "\n", "    ", "for", "data_name", ",", "content", "in", "dataset", ".", "items", "(", ")", ":", "\n", "        ", "for", "cur_m", "in", "content", ":", "\n", "            ", "coref", "=", "find_coref", "(", "cur_m", ",", "content", ",", "person_names", ")", "\n", "if", "coref", "is", "not", "None", "and", "len", "(", "coref", ")", ">", "0", ":", "\n", "                ", "cur_cands", "=", "{", "}", "\n", "for", "m", "in", "coref", ":", "\n", "                    ", "for", "c", ",", "p", "in", "m", "[", "\"candidates\"", "]", ":", "\n", "                        ", "cur_cands", "[", "c", "]", "=", "cur_cands", ".", "get", "(", "c", ",", "0", ")", "+", "p", "\n", "", "", "for", "c", "in", "cur_cands", ".", "keys", "(", ")", ":", "\n", "                    ", "cur_cands", "[", "c", "]", "/=", "len", "(", "coref", ")", "\n", "", "cur_m", "[", "\"candidates\"", "]", "=", "sorted", "(", "\n", "list", "(", "cur_cands", ".", "items", "(", ")", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", "\n", ")", "[", ":", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval": [[193, 223], ["testset.items", "zip", "len", "testset.items", "len", "numpy.sum", "len", "len"], "function", ["None"], ["", "", "", "", "def", "eval", "(", "testset", ",", "system_pred", ",", "nel", "=", "False", ")", ":", "\n", "    ", "gold", "=", "[", "]", "\n", "pred", "=", "[", "]", "\n", "\n", "for", "doc_name", ",", "content", "in", "testset", ".", "items", "(", ")", ":", "\n", "        ", "gold", "+=", "[", "c", "[", "\"gold\"", "]", "[", "0", "]", "for", "c", "in", "content", "]", "# the gold named entity", "\n", "pred", "+=", "[", "\n", "c", "[", "\"pred\"", "]", "[", "0", "]", "for", "c", "in", "system_pred", "[", "doc_name", "]", "\n", "]", "# the predicted named entity", "\n", "\n", "", "true_pos", "=", "0", "\n", "for", "g", ",", "p", "in", "zip", "(", "gold", ",", "pred", ")", ":", "\n", "        ", "if", "g", "==", "p", "and", "p", "!=", "\"NIL\"", ":", "\n", "            ", "true_pos", "+=", "1", "\n", "\n", "", "", "if", "nel", ":", "\n", "        ", "NIL_preds", "=", "len", "(", "[", "p", "for", "p", "in", "pred", "if", "p", "==", "\"NIL\"", "]", ")", "\n", "total_discovered_mentions", "=", "0", "\n", "for", "doc_name", ",", "content", "in", "testset", ".", "items", "(", ")", ":", "\n", "            ", "total_discovered_mentions", "+=", "np", ".", "sum", "(", "\n", "len", "(", "ment", ")", "for", "ment", "in", "content", "[", "0", "]", "[", "\"ments_per_sent_flair\"", "]", "\n", ")", "\n", "\n", "", "precision", "=", "true_pos", "/", "(", "total_discovered_mentions", "-", "NIL_preds", ")", "\n", "", "else", ":", "\n", "        ", "precision", "=", "true_pos", "/", "len", "(", "[", "p", "for", "p", "in", "pred", "if", "p", "!=", "\"NIL\"", "]", ")", "\n", "\n", "", "recall", "=", "true_pos", "/", "len", "(", "gold", ")", "\n", "f1", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "return", "precision", ",", "recall", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.get_candidate_generator": [[225, 233], ["dataset.FetchCandidateEntities", "dataset.FetchCandidateEntities"], "function", ["None"], ["", "def", "get_candidate_generator", "(", "added_params", ")", ":", "\n", "    ", "if", "added_params", "[", "\"candidate_generator_type\"", "]", "==", "\"p_e_m\"", ":", "\n", "        ", "if", "\"p_e_m_data_path\"", "in", "added_params", ":", "\n", "            ", "return", "FetchCandidateEntities", "(", "added_params", "[", "\"p_e_m_data_path\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "FetchCandidateEntities", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.run_thread": [[26, 59], ["print", "tqdm.tqdm", "candidate_generator.get_candidates", "candidate_generator.get_candidates", "data_fetcher.get_candidates_data", "data_fetcher.get_candidates_data"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Simple_Candidate_Generator.get_candidates", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Simple_Candidate_Generator.get_candidates", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Pregenerated_Candidates_Data_Fetcher.get_candidates_data", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.candidate_generators.Pregenerated_Candidates_Data_Fetcher.get_candidates_data"], ["def", "run_thread", "(", "arguments", ")", ":", "\n", "    ", "mentions", "=", "arguments", "[", "\"data\"", "]", "\n", "candidate_generator", "=", "arguments", "[", "\"candidate_generator\"", "]", "\n", "args", "=", "arguments", "[", "\"args\"", "]", "\n", "if", "args", ".", "keep_pregenerated_candidates", ":", "\n", "        ", "data_fetcher", "=", "arguments", "[", "\"pregenereted_cands_data_fetcher\"", "]", "\n", "\n", "", "if", "arguments", "[", "\"id\"", "]", "==", "0", ":", "\n", "        ", "print", "(", "\"Query args: \"", ",", "candidate_generator", ".", "query_arguments", ")", "\n", "print_query_flag", "=", "True", "\n", "for", "mention", "in", "tqdm", "(", "mentions", ")", ":", "\n", "            ", "mention", "[", "\"generated_candidates\"", "]", "=", "candidate_generator", ".", "get_candidates", "(", "\n", "mention", ",", "print_query_flag", "=", "print_query_flag", "\n", ")", "\n", "print_query_flag", "=", "False", "\n", "\n", "if", "args", ".", "keep_pregenerated_candidates", ":", "\n", "                ", "wikidata_ids", "=", "mention", "[", "\"candidates_wikidata_ids\"", "]", "\n", "mention", "[", "\"candidates_data\"", "]", "=", "data_fetcher", ".", "get_candidates_data", "(", "\n", "wikidata_ids", "\n", ")", "\n", "", "", "", "else", ":", "\n", "        ", "for", "mention", "in", "mentions", ":", "\n", "            ", "mention", "[", "\"generated_candidates\"", "]", "=", "candidate_generator", ".", "get_candidates", "(", "\n", "mention", "\n", ")", "\n", "if", "args", ".", "keep_pregenerated_candidates", ":", "\n", "                ", "wikidata_ids", "=", "mention", "[", "\"candidates_wikidata_ids\"", "]", "\n", "mention", "[", "\"candidates_data\"", "]", "=", "data_fetcher", ".", "get_candidates_data", "(", "\n", "wikidata_ids", "\n", ")", "\n", "\n", "", "", "", "return", "arguments", "[", "\"id\"", "]", ",", "mentions", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split": [[61, 64], ["divmod", "len", "range", "min", "min"], "function", ["None"], ["", "def", "split", "(", "a", ",", "n", ")", ":", "\n", "    ", "k", ",", "m", "=", "divmod", "(", "len", "(", "a", ")", ",", "n", ")", "\n", "return", "(", "a", "[", "i", "*", "k", "+", "min", "(", "i", ",", "m", ")", ":", "(", "i", "+", "1", ")", "*", "k", "+", "min", "(", "i", "+", "1", ",", "m", ")", "]", "for", "i", "in", "range", "(", "n", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.main": [[66, 155], ["time.time", "perform_and_evaluate_candidate_retrieval_multithreaded.get_parameters", "print", "utils.get_datasets", "utils.get_list_of_mentions", "multiprocessing.pool.ThreadPool", "perform_and_evaluate_candidate_retrieval_multithreaded.split", "multiprocessing.pool.ThreadPool.map", "multiprocessing.pool.ThreadPool.terminate", "multiprocessing.pool.ThreadPool.join", "print", "evaluator.Evaluator", "evaluator.Evaluator.candidate_generation", "print", "os.makedirs", "pickle.dump", "time.time", "open", "candidate_generators.Simple_Candidate_Generator", "candidate_generators.Pregenerated_Candidates_Data_Fetcher", "enumerate", "candidate_generators.Simple_Candidate_Generator", "enumerate", "os.path.join"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.get_parameters", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.get_datasets", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.get_list_of_mentions", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.evaluator.Evaluator.candidate_generation", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "wall_start", "=", "time", ".", "time", "(", ")", "\n", "parameters", "=", "get_parameters", "(", "args", ")", "\n", "\n", "print", "(", "\"Candidate generator parameters:\"", ",", "parameters", ")", "\n", "\n", "datasets", "=", "utils", ".", "get_datasets", "(", "\n", "args", ".", "include_aida_train", ",", "args", ".", "keep_pregenerated_candidates", "\n", ")", "\n", "\n", "if", "args", ".", "single_dataset", ":", "\n", "        ", "datasets", "=", "[", "datasets", "[", "0", "]", "]", "\n", "\n", "", "mentions", "=", "utils", ".", "get_list_of_mentions", "(", "datasets", ")", "\n", "\n", "# NUM_TREADS = multiprocessing.cpu_count()", "\n", "NUM_THREADS", "=", "args", ".", "num_threads", "\n", "pool", "=", "ThreadPool", "(", "NUM_THREADS", ")", "\n", "\n", "# Split the data into approximately equal parts and give one block to each thread", "\n", "data_per_thread", "=", "split", "(", "mentions", ",", "NUM_THREADS", ")", "\n", "\n", "if", "args", ".", "keep_pregenerated_candidates", ":", "\n", "        ", "arguments", "=", "[", "\n", "{", "\n", "\"id\"", ":", "idx", ",", "\n", "\"data\"", ":", "data_bloc", ",", "\n", "\"args\"", ":", "args", ",", "\n", "\"candidate_generator\"", ":", "Simple_Candidate_Generator", "(", "parameters", ")", ",", "\n", "\"pregenereted_cands_data_fetcher\"", ":", "Pregenerated_Candidates_Data_Fetcher", "(", "\n", "parameters", "\n", ")", ",", "\n", "}", "\n", "for", "idx", ",", "data_bloc", "in", "enumerate", "(", "data_per_thread", ")", "\n", "]", "\n", "", "else", ":", "\n", "        ", "arguments", "=", "[", "\n", "{", "\n", "\"id\"", ":", "idx", ",", "\n", "\"data\"", ":", "data_bloc", ",", "\n", "\"args\"", ":", "args", ",", "\n", "\"candidate_generator\"", ":", "Simple_Candidate_Generator", "(", "parameters", ")", ",", "\n", "}", "\n", "for", "idx", ",", "data_bloc", "in", "enumerate", "(", "data_per_thread", ")", "\n", "]", "\n", "\n", "", "results", "=", "pool", ".", "map", "(", "run_thread", ",", "arguments", ")", "\n", "\n", "# Merge the results", "\n", "processed_mentions", "=", "[", "]", "\n", "for", "_id", ",", "mentions", "in", "results", ":", "\n", "        ", "processed_mentions", "=", "processed_mentions", "+", "mentions", "\n", "\n", "", "has_gold", "=", "0", "\n", "\n", "pool", ".", "terminate", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "execution_time", "=", "(", "time", ".", "time", "(", ")", "-", "wall_start", ")", "/", "60", "\n", "print", "(", "\"The execution took:\"", ",", "execution_time", ",", "\" minutes\"", ")", "\n", "\n", "# Evaluate the generation", "\n", "evaluator", "=", "Evaluator", "(", "processed_mentions", ")", "\n", "evaluator", ".", "candidate_generation", "(", "\n", "save_gold_pos", "=", "True", ",", "save_pregenerated_gold_pos", "=", "args", ".", "keep_pregenerated_candidates", "\n", ")", "\n", "\n", "# Dump the data if the dump_mentions flag was set", "\n", "if", "args", ".", "dump_mentions", ":", "\n", "        ", "print", "(", "\"Dumping processed mentions\"", ")", "\n", "# Create the directory for the mention dumps if it does not exist", "\n", "dump_folder", "=", "args", ".", "dump_mentions_folder", "\n", "os", ".", "makedirs", "(", "dump_folder", ",", "exist_ok", "=", "True", ")", "\n", "\n", "dump_object", "=", "{", "}", "\n", "dump_object", "[", "\"mentions\"", "]", "=", "processed_mentions", "\n", "dump_object", "[", "\"total_per_dataset\"", "]", "=", "evaluator", ".", "total_per_dataset", "\n", "dump_object", "[", "\"has_gold_per_dataset\"", "]", "=", "evaluator", ".", "has_gold_per_dataset", "\n", "dump_object", "[", "\"parameters\"", "]", "=", "parameters", "\n", "dump_object", "[", "\"args\"", "]", "=", "args", "\n", "dump_object", "[", "\"execution_time\"", "]", "=", "execution_time", "\n", "\n", "pickle", ".", "dump", "(", "\n", "dump_object", ",", "\n", "open", "(", "os", ".", "path", ".", "join", "(", "dump_folder", ",", "args", ".", "dump_file_id", ")", ",", "\"wb\"", ")", ",", "\n", "protocol", "=", "4", ",", "\n", ")", "\n", "\n", "# evaluator.candidate_generation(max_rank=100)", "\n", "", "return", "evaluator", ".", "recall", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.get_parameters": [[157, 170], ["k.strip", "args.keys.split"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "get_parameters", "(", "args", ")", ":", "\n", "    ", "parameters", "=", "{", "\n", "\"collection_name\"", ":", "args", ".", "collection_name", ",", "\n", "\"rows\"", ":", "args", ".", "rows", ",", "\n", "\"solr_address\"", ":", "args", ".", "solr_address", ",", "\n", "}", "\n", "\n", "parameters", "[", "\"query_data\"", "]", "=", "{", "}", "\n", "parameters", "[", "\"query_data\"", "]", "[", "\"string\"", "]", "=", "args", ".", "query", "\n", "parameters", "[", "\"query_data\"", "]", "[", "\"keys\"", "]", "=", "[", "k", ".", "strip", "(", ")", "for", "k", "in", "args", ".", "keys", ".", "split", "(", "\",\"", ")", "]", "\n", "parameters", "[", "\"boosting\"", "]", "=", "args", ".", "boosting", "\n", "\n", "return", "parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.evaluator.Evaluator.__init__": [[13, 15], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ")", ":", "\n", "        ", "self", ".", "data", "=", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.evaluator.Evaluator.candidate_generation": [[16, 91], ["print", "print", "print", "enumerate", "has_gold_per_dataset.get", "print", "print", "enumerate", "total_per_dataset.get", "has_gold_per_dataset.get"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "candidate_generation", "(", "\n", "self", ",", "max_rank", "=", "None", ",", "save_gold_pos", "=", "False", ",", "save_pregenerated_gold_pos", "=", "False", "\n", ")", ":", "\n", "        ", "has_gold_per_dataset", "=", "{", "}", "\n", "total_per_dataset", "=", "{", "}", "\n", "recall", "=", "{", "}", "\n", "processed_mentions", "=", "self", ".", "data", "\n", "\n", "if", "max_rank", "is", "None", ":", "\n", "            ", "print", "(", "\"Max rank: None\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Max rank\"", ",", "max_rank", ")", "\n", "\n", "", "for", "mention", "in", "processed_mentions", ":", "\n", "            ", "dataset_name", "=", "mention", "[", "\"dataset_name\"", "]", "\n", "gold_wikidata_id", "=", "mention", "[", "\"gold_wikidata_id\"", "]", "\n", "gold_pos", "=", "-", "1", "\n", "\n", "for", "idx", ",", "cand", "in", "enumerate", "(", "mention", "[", "\"generated_candidates\"", "]", ")", ":", "\n", "                ", "cand_wikidata_id", "=", "cand", "[", "\"wikidata_id\"", "]", "\n", "if", "gold_wikidata_id", "==", "cand_wikidata_id", ":", "\n", "                    ", "gold_pos", "=", "idx", "+", "1", "# Because idx starts at 0", "\n", "break", "\n", "\n", "", "", "if", "save_gold_pos", ":", "\n", "                ", "mention", "[", "\"gold_pos\"", "]", "=", "gold_pos", "\n", "\n", "", "if", "gold_pos", ">", "0", "and", "(", "(", "max_rank", "is", "None", ")", "or", "gold_pos", "<=", "max_rank", ")", ":", "\n", "                ", "has_gold", "=", "has_gold_per_dataset", ".", "get", "(", "dataset_name", ",", "0", ")", "+", "1", "\n", "has_gold_per_dataset", "[", "dataset_name", "]", "=", "has_gold", "\n", "\n", "", "if", "save_pregenerated_gold_pos", ":", "\n", "                ", "pre_gen_gold_pos", "=", "-", "1", "\n", "\n", "for", "idx", ",", "cand", "in", "enumerate", "(", "mention", "[", "\"candidates_data\"", "]", ")", ":", "\n", "                    ", "cand_wikidata_id", "=", "cand", "[", "\"wikidata_id\"", "]", "\n", "if", "gold_wikidata_id", "==", "cand_wikidata_id", ":", "\n", "                        ", "pre_gen_gold_pos", "=", "idx", "+", "1", "# Because idx starts at 0", "\n", "break", "\n", "\n", "", "", "mention", "[", "\"pre_gen_candidates_gold_pos\"", "]", "=", "pre_gen_gold_pos", "\n", "\n", "", "total", "=", "total_per_dataset", ".", "get", "(", "dataset_name", ",", "0", ")", "+", "1", "\n", "total_per_dataset", "[", "dataset_name", "]", "=", "total", "\n", "\n", "", "total", "=", "0", "\n", "has_gold", "=", "0", "\n", "\n", "for", "dataset_name", "in", "total_per_dataset", ":", "\n", "            ", "has_gold_ds", "=", "has_gold_per_dataset", ".", "get", "(", "dataset_name", ",", "0", ")", "\n", "total_ds", "=", "total_per_dataset", "[", "dataset_name", "]", "\n", "\n", "has_gold", "+=", "has_gold_ds", "\n", "total", "+=", "total_ds", "\n", "\n", "recall", "[", "dataset_name", "]", "=", "has_gold_ds", "/", "total_ds", "\n", "print", "(", "\"Dataset:\"", ",", "dataset_name", ")", "\n", "print", "(", "\n", "\"Recall (w.r.t candidate generation): {:.3f}\"", ".", "format", "(", "\n", "recall", "[", "dataset_name", "]", "\n", ")", "\n", ")", "\n", "\n", "", "recall", "[", "\"overall\"", "]", "=", "has_gold", "/", "total", "\n", "print", "(", "\n", "\"Overal recall (w.r.t candidate generation): {:.3f}\"", ".", "format", "(", "\n", "recall", "[", "\"overall\"", "]", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "has_gold_per_dataset", "=", "has_gold_per_dataset", "\n", "self", ".", "total_per_dataset", "=", "total_per_dataset", "\n", "self", ".", "total", "=", "total", "\n", "self", ".", "has_gold", "=", "has_gold", "\n", "self", ".", "recall", "=", "recall", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.evaluator.Evaluator.candidate_generation_recall_at": [[92, 125], ["len", "numpy.array", "sorted", "matplotlib.subplot.plot", "matplotlib.figure", "matplotlib.subplot", "matplotlib.subplot.set_ylabel", "matplotlib.subplot.set_xlabel", "collections.Counter().items", "enumerate", "str", "str", "numpy.cumsum", "collections.Counter"], "methods", ["None"], ["", "def", "candidate_generation_recall_at", "(", "self", ",", "ax", "=", "None", ",", "max_rank", "=", "None", ")", ":", "\n", "        ", "processed_mentions", "=", "self", ".", "data", "\n", "total_num_of_docs", "=", "len", "(", "processed_mentions", ")", "\n", "\n", "gold_positions", "=", "np", ".", "array", "(", "\n", "[", "\n", "mention", "[", "\"gold_pos\"", "]", "\n", "for", "mention", "in", "processed_mentions", "\n", "if", "mention", "[", "\"gold_pos\"", "]", ">=", "0", "\n", "]", "\n", ")", "\n", "if", "ax", "==", "None", ":", "\n", "            ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "7", ",", "7", ")", ")", "\n", "ax", "=", "plt", ".", "subplot", "(", "111", ")", "\n", "ax", ".", "set_ylabel", "(", "str", "(", "\"Recall\"", ")", ")", "\n", "ax", ".", "set_xlabel", "(", "str", "(", "\"True entity rank\"", ")", ")", "\n", "\n", "", "rank_count_pairs", "=", "sorted", "(", "Counter", "(", "gold_positions", ")", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "\n", "# rank_count_pairs = rank_count_pairs[:k]", "\n", "\n", "counts", "=", "[", "i", "[", "1", "]", "for", "i", "in", "rank_count_pairs", "]", "\n", "recall", "=", "np", ".", "cumsum", "(", "counts", ")", "/", "total_num_of_docs", "*", "100", "\n", "rankings", "=", "[", "i", "[", "0", "]", "for", "i", "in", "rank_count_pairs", "]", "\n", "\n", "if", "max_rank", "is", "not", "None", ":", "\n", "            ", "for", "idx", ",", "rank", "in", "enumerate", "(", "rankings", ")", ":", "\n", "                ", "if", "rank", ">", "max_rank", ":", "\n", "                    ", "rankings", "=", "rankings", "[", ":", "idx", "]", "\n", "recall", "=", "recall", "[", ":", "idx", "]", "\n", "break", "\n", "\n", "", "", "", "ax", ".", "plot", "(", "rankings", ",", "recall", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.solr_escape": [[18, 31], ["re.sub", "re.sub", "re.sub", "ESCAPE_CHARS_RE.sub", "re.sub.lower", "x.group().lower", "x.group().lower", "x.group().lower", "x.group", "x.group", "x.group"], "function", ["None"], ["        ", "for", "line", "in", "file", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "!=", "\"\"", ":", "\n", "                ", "lines", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "", "if", "one_sentence_per_line", ":", "\n", "        ", "sentences", "=", "lines", "\n", "", "else", ":", "\n", "        ", "text", "=", "\" \"", ".", "join", "(", "lines", ")", "\n", "sentences", "=", "list", "(", "split_multi", "(", "text", ")", ")", "\n", "sentences", "=", "[", "sentence", "for", "sentence", "in", "sentences", "if", "sentence", "!=", "\"\"", "]", "\n", "\n", "", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.get_wikidata_id_from_link_name": [[36, 50], ["pickle.load.get", "os.path.isfile", "pickle.load", "subprocess.call", "pickle.load", "open", "open"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["wikidata_id", "=", "candidate", "[", "\"wikidata_id\"", "]", "\n", "wikipedia_title", "=", "candidate", "[", "\"wikipedia_title\"", "]", "\n", "\n", "return", "\"{}, {}, {}\"", ".", "format", "(", "wikipedia_id", ",", "wikidata_id", ",", "wikipedia_title", ")", "\n", "\n", "\n", "", "def", "present_sentence_mentions", "(", "sentence", ",", "mentions", ",", "output_file", ")", ":", "\n", "    ", "if", "output_file", "!=", "None", ":", "\n", "        ", "f", "=", "io", ".", "open", "(", "output_file", ",", "mode", "=", "\"a\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "output", "=", "lambda", "s", ":", "f", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "s", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "lambda", "s", ":", "print", "(", "s", ")", "\n", "", "output", "(", "\"Sentence: {}\"", ".", "format", "(", "sentence", ")", ")", "\n", "\n", "mention_entity_pairs", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.get_datasets": [[52, 117], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "blink.CoNLLDataset", "print", "print", "dev_datasets.append", "print", "dataset.items", "len", "utils.get_wikidata_id_from_link_name", "not_found.append", "len", "utils.get_wikidata_id_from_link_name", "cands.append"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.get_wikidata_id_from_link_name", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.get_wikidata_id_from_link_name"], ["        ", "candidates", "=", "mention", "[", "\"candidates\"", "]", "\n", "# prediction = mention.get('predicted_candidate_idx', 0)", "\n", "prediction", "=", "mention", "[", "\"predicted_candidate_idx\"", "]", "\n", "\n", "if", "prediction", "<", "len", "(", "candidates", ")", ":", "\n", "# print(type(mention['prob_assigned_to_candidate']))", "\n", "# print(mention['prob_assigned_to_candidate'])", "\n", "            ", "mention_rep", "=", "\"{} ({}, {}) - {} (conf. {:.5f})\"", ".", "format", "(", "\n", "mention", "[", "\"text\"", "]", ",", "\n", "mention", "[", "\"start_pos\"", "]", ",", "\n", "mention", "[", "\"end_pos\"", "]", ",", "\n", "get_candidate_summary", "(", "candidates", "[", "prediction", "]", ")", ",", "\n", "mention", "[", "\"prob_assigned_to_candidate\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "mention_rep", "=", "\"{} ({}, {}) - {}\"", ".", "format", "(", "\n", "mention", "[", "\"text\"", "]", ",", "\n", "mention", "[", "\"start_pos\"", "]", ",", "\n", "mention", "[", "\"end_pos\"", "]", ",", "\n", "\"No candidate selected\"", ",", "\n", ")", "\n", "\n", "", "mention_entity_pairs", ".", "append", "(", "mention_rep", ")", "\n", "\n", "", "if", "len", "(", "mention_entity_pairs", ")", "!=", "0", ":", "\n", "        ", "output", "(", "\"Mention-Entity pairs: \\n{}\"", ".", "format", "(", "\"\\n\"", ".", "join", "(", "mention_entity_pairs", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "(", "\"No detected mentions\"", ")", "\n", "\n", "", "output", "(", "\"\"", ")", "\n", "\n", "\n", "", "def", "sentence_mentions_pairs", "(", "sentences", ",", "mentions", ")", ":", "\n", "    ", "mentions_per_sent", "=", "{", "}", "\n", "\n", "for", "m", "in", "mentions", ":", "\n", "        ", "sent_idx", "=", "int", "(", "m", "[", "\"sent_idx\"", "]", ")", "\n", "\n", "curr_ments", "=", "mentions_per_sent", ".", "get", "(", "sent_idx", ",", "[", "]", ")", "\n", "curr_ments", ".", "append", "(", "m", ")", "\n", "\n", "mentions_per_sent", "[", "sent_idx", "]", "=", "curr_ments", "\n", "\n", "", "pairs", "=", "[", "]", "\n", "\n", "for", "idx", ",", "sent", "in", "enumerate", "(", "sentences", ")", ":", "\n", "        ", "pairs", ".", "append", "(", "(", "sent", ",", "mentions_per_sent", ".", "get", "(", "idx", ",", "[", "]", ")", ")", ")", "\n", "\n", "", "return", "pairs", "\n", "\n", "\n", "", "def", "present_annotated_sentences", "(", "sentences", ",", "mentions", ",", "output_file", "=", "None", ")", ":", "\n", "    ", "pairs", "=", "sentence_mentions_pairs", "(", "sentences", ",", "mentions", ")", "\n", "\n", "for", "sent", ",", "ments", "in", "pairs", ":", "\n", "        ", "present_sentence_mentions", "(", "sent", ",", "ments", ",", "output_file", ")", "\n", "\n", "\n", "", "", "def", "write_dicts_as_json_per_line", "(", "list_of_dicts", ",", "txt_file_path", ")", ":", "\n", "    ", "with", "io", ".", "open", "(", "txt_file_path", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "file", ":", "\n", "        ", "for", "idx", ",", "mention", "in", "enumerate", "(", "list_of_dicts", ")", ":", "\n", "            ", "json_string", "=", "json", ".", "dumps", "(", "mention", ")", "\n", "file", ".", "write", "(", "json_string", ")", "\n", "\n", "if", "idx", "!=", "(", "len", "(", "list_of_dicts", ")", "-", "1", ")", ":", "\n", "                ", "file", ".", "write", "(", "\"\\n\"", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.get_sent_context": [[119, 154], ["key.endswith", "res.strip", "key.endswith", "key.endswith"], "function", ["None"], ["\n", "", "", "", "", "def", "get_mentions_txt_file_path", "(", "output_folder_path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_folder_path", ",", "exist_ok", "=", "True", ")", "\n", "file_name", "=", "\"mentions.jsonl\"", "\n", "path_to_file", "=", "os", ".", "path", ".", "join", "(", "output_folder_path", ",", "file_name", ")", "\n", "\n", "return", "path_to_file", "\n", "\n", "\n", "", "def", "get_sentences_txt_file_path", "(", "output_folder_path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_folder_path", ",", "exist_ok", "=", "True", ")", "\n", "file_name", "=", "\"sentences.jsonl\"", "\n", "path_to_file", "=", "os", ".", "path", ".", "join", "(", "output_folder_path", ",", "file_name", ")", "\n", "\n", "return", "path_to_file", "\n", "\n", "\n", "", "def", "get_end2end_pickle_output_file_path", "(", "output_folder_path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_folder_path", ",", "exist_ok", "=", "True", ")", "\n", "file_name", "=", "\"mentions_and_sentences.pickle\"", "\n", "path_to_file", "=", "os", ".", "path", ".", "join", "(", "output_folder_path", ",", "file_name", ")", "\n", "\n", "return", "path_to_file", "\n", "\n", "\n", "", "def", "write_end2end_pickle_output", "(", "sentences", ",", "mentions", ",", "output_file_id", ")", ":", "\n", "    ", "obj", "=", "{", "\"sentences\"", ":", "sentences", ",", "\"mentions\"", ":", "mentions", "}", "\n", "with", "open", "(", "get_end2end_pickle_output_file_path", "(", "output_file_id", ")", ",", "\"wb\"", ")", "as", "file", ":", "\n", "        ", "pickle", ".", "dump", "(", "obj", ",", "file", ")", "\n", "\n", "\n", "", "", "def", "get_end2end_pretty_output_file_path", "(", "output_folder_path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_folder_path", ",", "exist_ok", "=", "True", ")", "\n", "file_name", "=", "\"pretty.txt\"", "\n", "path_to_file", "=", "os", ".", "path", ".", "join", "(", "output_folder_path", ",", "file_name", ")", "\n", "return", "path_to_file", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.get_list_of_mentions": [[156, 270], ["print", "dataset.items", "print", "print", "utils.solr_escape", "utils.solr_escape", "mentions.append", "utils.solr_escape", "utils.solr_escape", "utils.solr_escape", "len", "utils.solr_escape", "solr_escape.split", "solr_escape.split", "solr_escape.split", "solr_escape.split"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.solr_escape", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.solr_escape", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.solr_escape", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.solr_escape", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.solr_escape", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.solr_escape", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], []], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.write_candidate_generation_results_for_a_run_to_file": [[272, 283], ["open", "file.write", "sorted", "run[].keys"], "function", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.write_candidate_generation_execution_time_to_file": [[285, 292], ["open", "file.write"], "function", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.write_candidate_generation_results_to_file": [[294, 307], ["runs.sort", "utils.write_candidate_generation_results_for_a_run_to_file", "utils.write_candidate_generation_execution_time_to_file"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.write_candidate_generation_results_for_a_run_to_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.utils.write_candidate_generation_execution_time_to_file"], []], "home.repos.pwc.inspect_result.chenllliang_atp.indexer.faiss_indexer.DenseIndexer.__init__": [[23, 27], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "buffer_size", ":", "int", "=", "50000", ")", ":", "\n", "        ", "self", ".", "buffer_size", "=", "buffer_size", "\n", "self", ".", "index_id_to_db_id", "=", "[", "]", "\n", "self", ".", "index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.indexer.faiss_indexer.DenseIndexer.index_data": [[28, 30], ["None"], "methods", ["None"], ["", "def", "index_data", "(", "self", ",", "data", ":", "np", ".", "array", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.indexer.faiss_indexer.DenseIndexer.search_knn": [[31, 33], ["None"], "methods", ["None"], ["", "def", "search_knn", "(", "self", ",", "query_vectors", ":", "np", ".", "array", ",", "top_docs", ":", "int", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.indexer.faiss_indexer.DenseIndexer.serialize": [[34, 37], ["logger.info", "faiss.write_index"], "methods", ["None"], ["", "def", "serialize", "(", "self", ",", "index_file", ":", "str", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Serializing index to %s\"", ",", "index_file", ")", "\n", "faiss", ".", "write_index", "(", "self", ".", "index", ",", "index_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.indexer.faiss_indexer.DenseIndexer.deserialize_from": [[38, 43], ["logger.info", "faiss.read_index", "logger.info", "type"], "methods", ["None"], ["", "def", "deserialize_from", "(", "self", ",", "index_file", ":", "str", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading index from %s\"", ",", "index_file", ")", "\n", "self", ".", "index", "=", "faiss", ".", "read_index", "(", "index_file", ")", "\n", "logger", ".", "info", "(", "\n", "\"Loaded index of type %s and size %d\"", ",", "type", "(", "self", ".", "index", ")", ",", "self", ".", "index", ".", "ntotal", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.indexer.faiss_indexer.DenseFlatIndexer.__init__": [[48, 51], ["faiss_indexer.DenseIndexer.__init__", "faiss.IndexFlatIP"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vector_sz", ":", "int", "=", "1", ",", "buffer_size", ":", "int", "=", "50000", ")", ":", "\n", "        ", "super", "(", "DenseFlatIndexer", ",", "self", ")", ".", "__init__", "(", "buffer_size", "=", "buffer_size", ")", "\n", "self", ".", "index", "=", "faiss", ".", "IndexFlatIP", "(", "vector_sz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.indexer.faiss_indexer.DenseFlatIndexer.index_data": [[52, 64], ["len", "logger.info", "range", "logger.info", "numpy.concatenate", "faiss_indexer.DenseFlatIndexer.index.add", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["", "def", "index_data", "(", "self", ",", "data", ":", "np", ".", "array", ")", ":", "\n", "        ", "n", "=", "len", "(", "data", ")", "\n", "# indexing in batches is beneficial for many faiss index types", "\n", "logger", ".", "info", "(", "\"Indexing data, this may take a while.\"", ")", "\n", "cnt", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "n", ",", "self", ".", "buffer_size", ")", ":", "\n", "            ", "vectors", "=", "[", "np", ".", "reshape", "(", "t", ",", "(", "1", ",", "-", "1", ")", ")", "for", "t", "in", "data", "[", "i", ":", "i", "+", "self", ".", "buffer_size", "]", "]", "\n", "vectors", "=", "np", ".", "concatenate", "(", "vectors", ",", "axis", "=", "0", ")", "\n", "self", ".", "index", ".", "add", "(", "vectors", ")", "\n", "cnt", "+=", "self", ".", "buffer_size", "\n", "\n", "", "logger", ".", "info", "(", "\"Total data indexed %d\"", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.indexer.faiss_indexer.DenseFlatIndexer.search_knn": [[65, 68], ["faiss_indexer.DenseFlatIndexer.index.search"], "methods", ["None"], ["", "def", "search_knn", "(", "self", ",", "query_vectors", ",", "top_k", ")", ":", "\n", "        ", "scores", ",", "indexes", "=", "self", ".", "index", ".", "search", "(", "query_vectors", ",", "top_k", ")", "\n", "return", "scores", ",", "indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.indexer.faiss_indexer.DenseHNSWFlatIndexer.__init__": [[76, 93], ["faiss_indexer.DenseIndexer.__init__", "faiss.IndexHNSWFlat"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vector_sz", ":", "int", ",", "\n", "buffer_size", ":", "int", "=", "50000", ",", "\n", "store_n", ":", "int", "=", "128", ",", "\n", "ef_search", ":", "int", "=", "256", ",", "\n", "ef_construction", ":", "int", "=", "200", ",", "\n", ")", ":", "\n", "        ", "super", "(", "DenseHNSWFlatIndexer", ",", "self", ")", ".", "__init__", "(", "buffer_size", "=", "buffer_size", ")", "\n", "\n", "# IndexHNSWFlat supports L2 similarity only", "\n", "# so we have to apply DOT -> L2 similairy space conversion with the help of an extra dimension", "\n", "index", "=", "faiss", ".", "IndexHNSWFlat", "(", "vector_sz", "+", "1", ",", "store_n", ")", "\n", "index", ".", "hnsw", ".", "efSearch", "=", "ef_search", "\n", "index", ".", "hnsw", ".", "efConstruction", "=", "ef_construction", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "phi", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.indexer.faiss_indexer.DenseHNSWFlatIndexer.index_data": [[94, 130], ["len", "enumerate", "logger.info", "logger.info", "range", "logger.info", "RuntimeError", "max", "numpy.concatenate", "faiss_indexer.DenseHNSWFlatIndexer.index.add", "logger.info", "numpy.reshape", "numpy.sqrt", "numpy.hstack", "enumerate", "aux_dims[].reshape"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["", "def", "index_data", "(", "self", ",", "data", ":", "np", ".", "array", ")", ":", "\n", "        ", "n", "=", "len", "(", "data", ")", "\n", "\n", "# max norm is required before putting all vectors in the index to convert inner product similarity to L2", "\n", "if", "self", ".", "phi", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"DPR HNSWF index needs to index all data at once,\"", "\n", "\"results will be unpredictable otherwise.\"", "\n", ")", "\n", "", "phi", "=", "0", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "doc_vector", "=", "item", "\n", "norms", "=", "(", "doc_vector", "**", "2", ")", ".", "sum", "(", ")", "\n", "phi", "=", "max", "(", "phi", ",", "norms", ")", "\n", "", "logger", ".", "info", "(", "\"HNSWF DotProduct -> L2 space phi={}\"", ".", "format", "(", "phi", ")", ")", "\n", "self", ".", "phi", "=", "0", "\n", "\n", "# indexing in batches is beneficial for many faiss index types", "\n", "logger", ".", "info", "(", "\"Indexing data, this may take a while.\"", ")", "\n", "cnt", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "n", ",", "self", ".", "buffer_size", ")", ":", "\n", "            ", "vectors", "=", "[", "np", ".", "reshape", "(", "t", ",", "(", "1", ",", "-", "1", ")", ")", "for", "t", "in", "data", "[", "i", ":", "i", "+", "self", ".", "buffer_size", "]", "]", "\n", "\n", "norms", "=", "[", "(", "doc_vector", "**", "2", ")", ".", "sum", "(", ")", "for", "doc_vector", "in", "vectors", "]", "\n", "aux_dims", "=", "[", "np", ".", "sqrt", "(", "phi", "-", "norm", ")", "for", "norm", "in", "norms", "]", "\n", "hnsw_vectors", "=", "[", "\n", "np", ".", "hstack", "(", "(", "doc_vector", ",", "aux_dims", "[", "i", "]", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ")", "\n", "for", "i", ",", "doc_vector", "in", "enumerate", "(", "vectors", ")", "\n", "]", "\n", "hnsw_vectors", "=", "np", ".", "concatenate", "(", "hnsw_vectors", ",", "axis", "=", "0", ")", "\n", "\n", "self", ".", "index", ".", "add", "(", "hnsw_vectors", ")", "\n", "cnt", "+=", "self", ".", "buffer_size", "\n", "logger", ".", "info", "(", "\"Indexed data %d\"", "%", "cnt", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Total data indexed %d\"", "%", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.indexer.faiss_indexer.DenseHNSWFlatIndexer.search_knn": [[131, 137], ["numpy.zeros", "numpy.hstack", "logger.info", "faiss_indexer.DenseHNSWFlatIndexer.index.search", "len", "numpy.zeros.reshape"], "methods", ["None"], ["", "def", "search_knn", "(", "self", ",", "query_vectors", ",", "top_k", ")", ":", "\n", "        ", "aux_dim", "=", "np", ".", "zeros", "(", "len", "(", "query_vectors", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "query_nhsw_vectors", "=", "np", ".", "hstack", "(", "(", "query_vectors", ",", "aux_dim", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"query_hnsw_vectors %s\"", ",", "query_nhsw_vectors", ".", "shape", ")", "\n", "scores", ",", "indexes", "=", "self", ".", "index", ".", "search", "(", "query_nhsw_vectors", ",", "top_k", ")", "\n", "return", "scores", ",", "indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.indexer.faiss_indexer.DenseHNSWFlatIndexer.deserialize_from": [[138, 142], ["faiss_indexer.DenseIndexer.deserialize_from"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseHNSWFlatIndexer.deserialize_from"], ["", "def", "deserialize_from", "(", "self", ",", "file", ":", "str", ")", ":", "\n", "        ", "super", "(", "DenseHNSWFlatIndexer", ",", "self", ")", ".", "deserialize_from", "(", "file", ")", "\n", "# to trigger warning on subsequent indexing", "\n", "self", ".", "phi", "=", "1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.train_cross.modify": [[43, 61], ["context_input.tolist.tolist", "candidate_input.tolist.tolist", "range", "torch.LongTensor", "len", "range", "new_input.append", "len", "mod_input.append"], "function", ["None"], ["def", "modify", "(", "context_input", ",", "candidate_input", ",", "max_seq_length", ")", ":", "\n", "    ", "new_input", "=", "[", "]", "\n", "context_input", "=", "context_input", ".", "tolist", "(", ")", "\n", "candidate_input", "=", "candidate_input", ".", "tolist", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "context_input", ")", ")", ":", "\n", "        ", "cur_input", "=", "context_input", "[", "i", "]", "\n", "cur_candidate", "=", "candidate_input", "[", "i", "]", "\n", "mod_input", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "cur_candidate", ")", ")", ":", "\n", "# remove [CLS] token from candidate", "\n", "            ", "sample", "=", "cur_input", "+", "cur_candidate", "[", "j", "]", "[", "1", ":", "]", "\n", "sample", "=", "sample", "[", ":", "max_seq_length", "]", "\n", "mod_input", ".", "append", "(", "sample", ")", "\n", "\n", "", "new_input", ".", "append", "(", "mod_input", ")", "\n", "\n", "", "return", "torch", ".", "LongTensor", "(", "new_input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.train_cross.evaluate": [[63, 132], ["reranker.model.eval", "len", "range", "enumerate", "tqdm.tqdm", "tuple", "logits.detach().cpu().numpy.detach().cpu().numpy", "label_input.cpu().numpy", "blink.accuracy", "all_logits.extend", "context_input.size", "range", "torch.no_grad", "reranker", "range", "len", "logger.info", "logger.info", "logger.info", "t.to", "logits.detach().cpu().numpy.detach().cpu", "label_input.cpu", "context_input.size", "src[].item", "logits.detach().cpu().numpy.detach"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.accuracy", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "evaluate", "(", "reranker", ",", "eval_dataloader", ",", "device", ",", "logger", ",", "context_length", ",", "zeshel", "=", "False", ",", "silent", "=", "True", ")", ":", "\n", "    ", "reranker", ".", "model", ".", "eval", "(", ")", "\n", "if", "silent", ":", "\n", "        ", "iter_", "=", "eval_dataloader", "\n", "", "else", ":", "\n", "        ", "iter_", "=", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluation\"", ")", "\n", "\n", "", "results", "=", "{", "}", "\n", "\n", "eval_accuracy", "=", "0.0", "\n", "nb_eval_examples", "=", "0", "\n", "nb_eval_steps", "=", "0", "\n", "\n", "acc", "=", "{", "}", "\n", "tot", "=", "{", "}", "\n", "world_size", "=", "len", "(", "WORLDS", ")", "\n", "for", "i", "in", "range", "(", "world_size", ")", ":", "\n", "        ", "acc", "[", "i", "]", "=", "0.0", "\n", "tot", "[", "i", "]", "=", "0.0", "\n", "\n", "", "all_logits", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_", ")", ":", "\n", "        ", "if", "zeshel", ":", "\n", "            ", "src", "=", "batch", "[", "2", "]", "\n", "cnt", "+=", "1", "\n", "", "batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "context_input", "=", "batch", "[", "0", "]", "\n", "label_input", "=", "batch", "[", "1", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "eval_loss", ",", "logits", "=", "reranker", "(", "context_input", ",", "label_input", ",", "context_length", ")", "\n", "\n", "", "logits", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "label_ids", "=", "label_input", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "tmp_eval_accuracy", ",", "eval_result", "=", "utils", ".", "accuracy", "(", "logits", ",", "label_ids", ")", "\n", "\n", "eval_accuracy", "+=", "tmp_eval_accuracy", "\n", "all_logits", ".", "extend", "(", "logits", ")", "\n", "\n", "nb_eval_examples", "+=", "context_input", ".", "size", "(", "0", ")", "\n", "if", "zeshel", ":", "\n", "            ", "for", "i", "in", "range", "(", "context_input", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "src_w", "=", "src", "[", "i", "]", ".", "item", "(", ")", "\n", "acc", "[", "src_w", "]", "+=", "eval_result", "[", "i", "]", "\n", "tot", "[", "src_w", "]", "+=", "1", "\n", "", "", "nb_eval_steps", "+=", "1", "\n", "\n", "", "normalized_eval_accuracy", "=", "-", "1", "\n", "if", "nb_eval_examples", ">", "0", ":", "\n", "        ", "normalized_eval_accuracy", "=", "eval_accuracy", "/", "nb_eval_examples", "\n", "", "if", "zeshel", ":", "\n", "        ", "macro", "=", "0.0", "\n", "num", "=", "0.0", "\n", "for", "i", "in", "range", "(", "len", "(", "WORLDS", ")", ")", ":", "\n", "            ", "if", "acc", "[", "i", "]", ">", "0", ":", "\n", "                ", "acc", "[", "i", "]", "/=", "tot", "[", "i", "]", "\n", "macro", "+=", "acc", "[", "i", "]", "\n", "num", "+=", "1", "\n", "", "", "if", "num", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Macro accuracy: %.5f\"", "%", "(", "macro", "/", "num", ")", ")", "\n", "logger", ".", "info", "(", "\"Micro accuracy: %.5f\"", "%", "normalized_eval_accuracy", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "logger", ":", "\n", "            ", "logger", ".", "info", "(", "\"Eval accuracy: %.5f\"", "%", "normalized_eval_accuracy", ")", "\n", "\n", "", "", "results", "[", "\"normalized_accuracy\"", "]", "=", "normalized_eval_accuracy", "\n", "results", "[", "\"logits\"", "]", "=", "all_logits", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.train_cross.get_optimizer": [[134, 140], ["blink.common.optimizer.get_bert_optimizer", "params.get"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.common.optimizer.get_bert_optimizer"], ["", "def", "get_optimizer", "(", "model", ",", "params", ")", ":", "\n", "    ", "return", "get_bert_optimizer", "(", "\n", "[", "model", "]", ",", "\n", "params", "[", "\"type_optimization\"", "]", ",", "\n", "params", "[", "\"learning_rate\"", "]", ",", "\n", "fp16", "=", "params", ".", "get", "(", "\"fp16\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.train_cross.get_scheduler": [[143, 157], ["int", "pytorch_transformers.optimization.WarmupLinearSchedule", "logger.info", "logger.info", "int"], "function", ["None"], ["", "def", "get_scheduler", "(", "params", ",", "optimizer", ",", "len_train_data", ",", "logger", ")", ":", "\n", "    ", "batch_size", "=", "params", "[", "\"train_batch_size\"", "]", "\n", "grad_acc", "=", "params", "[", "\"gradient_accumulation_steps\"", "]", "\n", "epochs", "=", "params", "[", "\"num_train_epochs\"", "]", "\n", "\n", "num_train_steps", "=", "int", "(", "len_train_data", "/", "batch_size", "/", "grad_acc", ")", "*", "epochs", "\n", "num_warmup_steps", "=", "int", "(", "num_train_steps", "*", "params", "[", "\"warmup_proportion\"", "]", ")", "\n", "\n", "scheduler", "=", "WarmupLinearSchedule", "(", "\n", "optimizer", ",", "warmup_steps", "=", "num_warmup_steps", ",", "t_total", "=", "num_train_steps", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\" Num optimization steps = %d\"", "%", "num_train_steps", ")", "\n", "logger", ".", "info", "(", "\" Num warmup steps = %d\"", ",", "num_warmup_steps", ")", "\n", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.train_cross.main": [[159, 386], ["blink.get_logger", "blink.crossencoder.crossencoder.CrossEncoderRanker", "random.seed", "numpy.random.seed", "torch.manual_seed", "os.path.join", "torch.load", "train_cross.modify", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "os.path.join", "torch.load", "train_cross.modify", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "train_cross.evaluate", "time.time", "blink.write_to_file", "utils.get_logger.info", "utils.get_logger.info", "train_cross.get_optimizer", "train_cross.get_scheduler", "model.train", "tqdm.trange", "blink.write_to_file", "utils.get_logger.info", "utils.get_logger.info", "os.path.join", "os.path.exists", "os.makedirs", "ValueError", "torch.cuda.manual_seed_all", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "os.path.join", "str", "len", "int", "enumerate", "utils.get_logger.info", "os.path.join", "blink.save_model", "os.path.join", "train_cross.evaluate", "utils.get_logger.info", "os.path.join", "tqdm.tqdm", "tuple", "blink.crossencoder.crossencoder.CrossEncoderRanker.", "loss.item", "loss.backward", "time.time", "len", "len", "utils.get_logger.info", "torch.nn.utils.clip_grad_norm_", "get_optimizer.step", "get_scheduler.step", "get_optimizer.zero_grad", "utils.get_logger.info", "train_cross.evaluate", "utils.get_logger.info", "os.path.join", "blink.save_model", "model.train", "utils.get_logger.info", "numpy.argmax", "numpy.argmax", "t.to", "model.parameters"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_ranking.utils.get_logger", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.train_cross.modify", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.train_cross.modify", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.write_to_file", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.get_optimizer", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.train_cross.get_scheduler", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.write_to_file", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.save_model", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.save_model", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train"], ["", "def", "main", "(", "params", ")", ":", "\n", "    ", "model_output_path", "=", "params", "[", "\"output_path\"", "]", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_output_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_output_path", ")", "\n", "", "logger", "=", "utils", ".", "get_logger", "(", "params", "[", "\"output_path\"", "]", ")", "\n", "\n", "# Init model", "\n", "reranker", "=", "CrossEncoderRanker", "(", "params", ")", "\n", "tokenizer", "=", "reranker", ".", "tokenizer", "\n", "model", "=", "reranker", ".", "model", "\n", "\n", "# utils.save_model(model, tokenizer, model_output_path)", "\n", "\n", "device", "=", "reranker", ".", "device", "\n", "n_gpu", "=", "reranker", ".", "n_gpu", "\n", "\n", "if", "params", "[", "\"gradient_accumulation_steps\"", "]", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\"", ".", "format", "(", "\n", "params", "[", "\"gradient_accumulation_steps\"", "]", "\n", ")", "\n", ")", "\n", "\n", "# An effective batch size of `x`, when we are accumulating the gradient accross `y` batches will be achieved by having a batch size of `z = x / y`", "\n", "# args.gradient_accumulation_steps = args.gradient_accumulation_steps // n_gpu", "\n", "", "params", "[", "\"train_batch_size\"", "]", "=", "(", "\n", "params", "[", "\"train_batch_size\"", "]", "//", "params", "[", "\"gradient_accumulation_steps\"", "]", "\n", ")", "\n", "train_batch_size", "=", "params", "[", "\"train_batch_size\"", "]", "\n", "eval_batch_size", "=", "params", "[", "\"eval_batch_size\"", "]", "\n", "grad_acc_steps", "=", "params", "[", "\"gradient_accumulation_steps\"", "]", "\n", "\n", "# Fix the random seeds", "\n", "seed", "=", "params", "[", "\"seed\"", "]", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "reranker", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n", "", "max_seq_length", "=", "params", "[", "\"max_seq_length\"", "]", "\n", "context_length", "=", "params", "[", "\"max_context_length\"", "]", "\n", "\n", "fname", "=", "os", ".", "path", ".", "join", "(", "params", "[", "\"data_path\"", "]", ",", "\"train.t7\"", ")", "\n", "train_data", "=", "torch", ".", "load", "(", "fname", ")", "\n", "context_input", "=", "train_data", "[", "\"context_vecs\"", "]", "\n", "candidate_input", "=", "train_data", "[", "\"candidate_vecs\"", "]", "\n", "label_input", "=", "train_data", "[", "\"labels\"", "]", "\n", "if", "params", "[", "\"debug\"", "]", ":", "\n", "        ", "max_n", "=", "200", "\n", "context_input", "=", "context_input", "[", ":", "max_n", "]", "\n", "candidate_input", "=", "candidate_input", "[", ":", "max_n", "]", "\n", "label_input", "=", "label_input", "[", ":", "max_n", "]", "\n", "\n", "", "context_input", "=", "modify", "(", "context_input", ",", "candidate_input", ",", "max_seq_length", ")", "\n", "if", "params", "[", "\"zeshel\"", "]", ":", "\n", "        ", "src_input", "=", "train_data", "[", "'worlds'", "]", "[", ":", "len", "(", "context_input", ")", "]", "\n", "train_tensor_data", "=", "TensorDataset", "(", "context_input", ",", "label_input", ",", "src_input", ")", "\n", "", "else", ":", "\n", "        ", "train_tensor_data", "=", "TensorDataset", "(", "context_input", ",", "label_input", ")", "\n", "", "train_sampler", "=", "RandomSampler", "(", "train_tensor_data", ")", "\n", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_tensor_data", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "params", "[", "\"train_batch_size\"", "]", "\n", ")", "\n", "\n", "fname", "=", "os", ".", "path", ".", "join", "(", "params", "[", "\"data_path\"", "]", ",", "\"valid.t7\"", ")", "\n", "valid_data", "=", "torch", ".", "load", "(", "fname", ")", "\n", "context_input", "=", "valid_data", "[", "\"context_vecs\"", "]", "\n", "candidate_input", "=", "valid_data", "[", "\"candidate_vecs\"", "]", "\n", "label_input", "=", "valid_data", "[", "\"labels\"", "]", "\n", "if", "params", "[", "\"debug\"", "]", ":", "\n", "        ", "max_n", "=", "200", "\n", "context_input", "=", "context_input", "[", ":", "max_n", "]", "\n", "candidate_input", "=", "candidate_input", "[", ":", "max_n", "]", "\n", "label_input", "=", "label_input", "[", ":", "max_n", "]", "\n", "\n", "", "context_input", "=", "modify", "(", "context_input", ",", "candidate_input", ",", "max_seq_length", ")", "\n", "if", "params", "[", "\"zeshel\"", "]", ":", "\n", "        ", "src_input", "=", "valid_data", "[", "\"worlds\"", "]", "[", ":", "len", "(", "context_input", ")", "]", "\n", "valid_tensor_data", "=", "TensorDataset", "(", "context_input", ",", "label_input", ",", "src_input", ")", "\n", "", "else", ":", "\n", "        ", "valid_tensor_data", "=", "TensorDataset", "(", "context_input", ",", "label_input", ")", "\n", "", "valid_sampler", "=", "SequentialSampler", "(", "valid_tensor_data", ")", "\n", "\n", "valid_dataloader", "=", "DataLoader", "(", "\n", "valid_tensor_data", ",", "\n", "sampler", "=", "valid_sampler", ",", "\n", "batch_size", "=", "params", "[", "\"eval_batch_size\"", "]", "\n", ")", "\n", "\n", "# evaluate before training", "\n", "results", "=", "evaluate", "(", "\n", "reranker", ",", "\n", "valid_dataloader", ",", "\n", "device", "=", "device", ",", "\n", "logger", "=", "logger", ",", "\n", "context_length", "=", "context_length", ",", "\n", "zeshel", "=", "params", "[", "\"zeshel\"", "]", ",", "\n", "silent", "=", "params", "[", "\"silent\"", "]", ",", "\n", ")", "\n", "\n", "number_of_samples_per_dataset", "=", "{", "}", "\n", "\n", "time_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "utils", ".", "write_to_file", "(", "\n", "os", ".", "path", ".", "join", "(", "model_output_path", ",", "\"training_params.txt\"", ")", ",", "str", "(", "params", ")", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\"Starting training\"", ")", "\n", "logger", ".", "info", "(", "\n", "\"device: {} n_gpu: {}, distributed training: {}\"", ".", "format", "(", "device", ",", "n_gpu", ",", "False", ")", "\n", ")", "\n", "\n", "optimizer", "=", "get_optimizer", "(", "model", ",", "params", ")", "\n", "scheduler", "=", "get_scheduler", "(", "params", ",", "optimizer", ",", "len", "(", "train_tensor_data", ")", ",", "logger", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "best_epoch_idx", "=", "-", "1", "\n", "best_score", "=", "-", "1", "\n", "\n", "num_train_epochs", "=", "params", "[", "\"num_train_epochs\"", "]", "\n", "\n", "for", "epoch_idx", "in", "trange", "(", "int", "(", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ")", ":", "\n", "        ", "tr_loss", "=", "0", "\n", "results", "=", "None", "\n", "\n", "if", "params", "[", "\"silent\"", "]", ":", "\n", "            ", "iter_", "=", "train_dataloader", "\n", "", "else", ":", "\n", "            ", "iter_", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Batch\"", ")", "\n", "\n", "", "part", "=", "0", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_", ")", ":", "\n", "            ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "context_input", "=", "batch", "[", "0", "]", "\n", "label_input", "=", "batch", "[", "1", "]", "\n", "loss", ",", "_", "=", "reranker", "(", "context_input", ",", "label_input", ",", "context_length", ")", "\n", "\n", "# if n_gpu > 1:", "\n", "#     loss = loss.mean() # mean() to average on multi-gpu.", "\n", "\n", "if", "grad_acc_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "grad_acc_steps", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "(", "params", "[", "\"print_interval\"", "]", "*", "grad_acc_steps", ")", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Step {} - epoch {} average loss: {}\\n\"", ".", "format", "(", "\n", "step", ",", "\n", "epoch_idx", ",", "\n", "tr_loss", "/", "(", "params", "[", "\"print_interval\"", "]", "*", "grad_acc_steps", ")", ",", "\n", ")", "\n", ")", "\n", "tr_loss", "=", "0", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "grad_acc_steps", "==", "0", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "model", ".", "parameters", "(", ")", ",", "params", "[", "\"max_grad_norm\"", "]", "\n", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "if", "(", "step", "+", "1", ")", "%", "(", "params", "[", "\"eval_interval\"", "]", "*", "grad_acc_steps", ")", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Evaluation on the development dataset\"", ")", "\n", "evaluate", "(", "\n", "reranker", ",", "\n", "valid_dataloader", ",", "\n", "device", "=", "device", ",", "\n", "logger", "=", "logger", ",", "\n", "context_length", "=", "context_length", ",", "\n", "zeshel", "=", "params", "[", "\"zeshel\"", "]", ",", "\n", "silent", "=", "params", "[", "\"silent\"", "]", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"***** Saving fine - tuned model *****\"", ")", "\n", "epoch_output_folder_path", "=", "os", ".", "path", ".", "join", "(", "\n", "model_output_path", ",", "\"epoch_{}_{}\"", ".", "format", "(", "epoch_idx", ",", "part", ")", "\n", ")", "\n", "part", "+=", "1", "\n", "utils", ".", "save_model", "(", "model", ",", "tokenizer", ",", "epoch_output_folder_path", ")", "\n", "model", ".", "train", "(", ")", "\n", "logger", ".", "info", "(", "\"\\n\"", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"***** Saving fine - tuned model *****\"", ")", "\n", "epoch_output_folder_path", "=", "os", ".", "path", ".", "join", "(", "\n", "model_output_path", ",", "\"epoch_{}\"", ".", "format", "(", "epoch_idx", ")", "\n", ")", "\n", "utils", ".", "save_model", "(", "model", ",", "tokenizer", ",", "epoch_output_folder_path", ")", "\n", "# reranker.save(epoch_output_folder_path)", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "epoch_output_folder_path", ",", "\"eval_results.txt\"", ")", "\n", "results", "=", "evaluate", "(", "\n", "reranker", ",", "\n", "valid_dataloader", ",", "\n", "device", "=", "device", ",", "\n", "logger", "=", "logger", ",", "\n", "context_length", "=", "context_length", ",", "\n", "zeshel", "=", "params", "[", "\"zeshel\"", "]", ",", "\n", "silent", "=", "params", "[", "\"silent\"", "]", ",", "\n", ")", "\n", "\n", "ls", "=", "[", "best_score", ",", "results", "[", "\"normalized_accuracy\"", "]", "]", "\n", "li", "=", "[", "best_epoch_idx", ",", "epoch_idx", "]", "\n", "\n", "best_score", "=", "ls", "[", "np", ".", "argmax", "(", "ls", ")", "]", "\n", "best_epoch_idx", "=", "li", "[", "np", ".", "argmax", "(", "ls", ")", "]", "\n", "logger", ".", "info", "(", "\"\\n\"", ")", "\n", "\n", "", "execution_time", "=", "(", "time", ".", "time", "(", ")", "-", "time_start", ")", "/", "60", "\n", "utils", ".", "write_to_file", "(", "\n", "os", ".", "path", ".", "join", "(", "model_output_path", ",", "\"training_time.txt\"", ")", ",", "\n", "\"The training took {} minutes\\n\"", ".", "format", "(", "execution_time", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"The training took {} minutes\\n\"", ".", "format", "(", "execution_time", ")", ")", "\n", "\n", "# save the best model in the parent_dir", "\n", "logger", ".", "info", "(", "\"Best performance in epoch: {}\"", ".", "format", "(", "best_epoch_idx", ")", ")", "\n", "params", "[", "\"path_to_model\"", "]", "=", "os", ".", "path", ".", "join", "(", "\n", "model_output_path", ",", "\"epoch_{}\"", ".", "format", "(", "best_epoch_idx", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.data_process.prepare_crossencoder_mentions": [[17, 44], ["tqdm.tqdm", "numpy.asarray", "blink.get_context_representation", "np.asarray.append"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.get_context_representation"], ["\n", "\n", "def", "select_field", "(", "data", ",", "key1", ",", "key2", "=", "None", ")", ":", "\n", "    ", "if", "key2", "is", "None", ":", "\n", "        ", "return", "[", "example", "[", "key1", "]", "for", "example", "in", "data", "]", "\n", "", "else", ":", "\n", "        ", "return", "[", "example", "[", "key1", "]", "[", "key2", "]", "for", "example", "in", "data", "]", "\n", "\n", "\n", "", "", "def", "get_context_representation", "(", "\n", "sample", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "mention_key", "=", "\"mention\"", ",", "\n", "context_key", "=", "\"context\"", ",", "\n", "ent_start_token", "=", "ENT_START_TAG", ",", "\n", "ent_end_token", "=", "ENT_END_TAG", ",", "\n", ")", ":", "\n", "    ", "mention_tokens", "=", "[", "]", "\n", "if", "sample", "[", "mention_key", "]", "and", "len", "(", "sample", "[", "mention_key", "]", ")", ">", "0", ":", "\n", "        ", "mention_tokens", "=", "tokenizer", ".", "tokenize", "(", "sample", "[", "mention_key", "]", ")", "\n", "mention_tokens", "=", "[", "ent_start_token", "]", "+", "mention_tokens", "+", "[", "ent_end_token", "]", "\n", "\n", "", "context_left", "=", "sample", "[", "context_key", "+", "\"_left\"", "]", "\n", "context_right", "=", "sample", "[", "context_key", "+", "\"_right\"", "]", "\n", "context_left", "=", "tokenizer", ".", "tokenize", "(", "context_left", ")", "\n", "context_right", "=", "tokenizer", ".", "tokenize", "(", "context_right", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.data_process.prepare_crossencoder_candidates": [[46, 87], ["zip", "numpy.asarray", "numpy.asarray", "enumerate", "np.asarray.append", "np.asarray.append", "sys.stdout.write", "sys.stdout.flush", "blink.get_candidate_representation", "candidates.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.get_candidate_representation"], ["right_quota", "=", "max_seq_length", "-", "len", "(", "mention_tokens", ")", "-", "left_quota", "-", "2", "\n", "left_add", "=", "len", "(", "context_left", ")", "\n", "right_add", "=", "len", "(", "context_right", ")", "\n", "if", "left_add", "<=", "left_quota", ":", "\n", "        ", "if", "right_add", ">", "right_quota", ":", "\n", "            ", "right_quota", "+=", "left_quota", "-", "left_add", "\n", "", "", "else", ":", "\n", "        ", "if", "right_add", "<=", "right_quota", ":", "\n", "            ", "left_quota", "+=", "right_quota", "-", "right_add", "\n", "\n", "", "", "context_tokens", "=", "(", "\n", "context_left", "[", "-", "left_quota", ":", "]", "+", "mention_tokens", "+", "context_right", "[", ":", "right_quota", "]", "\n", ")", "\n", "\n", "context_tokens", "=", "[", "\"[CLS]\"", "]", "+", "context_tokens", "+", "[", "\"[SEP]\"", "]", "\n", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "context_tokens", ")", "\n", "padding", "=", "[", "0", "]", "*", "(", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "input_ids", "+=", "padding", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "\n", "return", "{", "\n", "\"tokens\"", ":", "context_tokens", ",", "\n", "\"ids\"", ":", "input_ids", ",", "\n", "}", "\n", "\n", "\n", "", "def", "get_candidate_representation", "(", "\n", "candidate_desc", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "candidate_title", "=", "None", ",", "\n", "title_tag", "=", "ENT_TITLE_TAG", ",", "\n", ")", ":", "\n", "    ", "cls_token", "=", "tokenizer", ".", "cls_token", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", "\n", "cand_tokens", "=", "tokenizer", ".", "tokenize", "(", "candidate_desc", ")", "\n", "if", "candidate_title", "is", "not", "None", ":", "\n", "        ", "title_tokens", "=", "tokenizer", ".", "tokenize", "(", "candidate_title", ")", "\n", "cand_tokens", "=", "title_tokens", "+", "[", "title_tag", "]", "+", "cand_tokens", "\n", "\n", "", "cand_tokens", "=", "cand_tokens", "[", ":", "max_seq_length", "-", "2", "]", "\n", "cand_tokens", "=", "[", "cls_token", "]", "+", "cand_tokens", "+", "[", "sep_token", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.data_process.filter_crossencoder_tensor_input": [[89, 112], ["zip", "zip", "zip"], "function", ["None"], ["input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "cand_tokens", ")", "\n", "padding", "=", "[", "0", "]", "*", "(", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "input_ids", "+=", "padding", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "\n", "return", "{", "\n", "\"tokens\"", ":", "cand_tokens", ",", "\n", "\"ids\"", ":", "input_ids", ",", "\n", "}", "\n", "\n", "\n", "", "def", "process_mention_data", "(", "\n", "samples", ",", "\n", "tokenizer", ",", "\n", "max_context_length", ",", "\n", "max_cand_length", ",", "\n", "silent", ",", "\n", "mention_key", "=", "\"mention\"", ",", "\n", "context_key", "=", "\"context\"", ",", "\n", "label_key", "=", "\"label\"", ",", "\n", "title_key", "=", "'label_title'", ",", "\n", "ent_start_token", "=", "ENT_START_TAG", ",", "\n", "ent_end_token", "=", "ENT_END_TAG", ",", "\n", "title_token", "=", "ENT_TITLE_TAG", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.data_process.prepare_crossencoder_data": [[115, 147], ["data_process.prepare_crossencoder_mentions", "data_process.prepare_crossencoder_candidates", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "data_process.filter_crossencoder_tensor_input", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.data_process.prepare_crossencoder_mentions", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.data_process.prepare_crossencoder_candidates", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.data_process.filter_crossencoder_tensor_input"], [")", ":", "\n", "    ", "processed_samples", "=", "[", "]", "\n", "\n", "if", "debug", ":", "\n", "        ", "samples", "=", "samples", "[", ":", "200", "]", "\n", "\n", "", "if", "silent", ":", "\n", "        ", "iter_", "=", "samples", "\n", "", "else", ":", "\n", "        ", "iter_", "=", "tqdm", "(", "samples", ")", "\n", "\n", "", "use_world", "=", "True", "\n", "\n", "for", "idx", ",", "sample", "in", "enumerate", "(", "iter_", ")", ":", "\n", "        ", "context_tokens", "=", "get_context_representation", "(", "\n", "sample", ",", "\n", "tokenizer", ",", "\n", "max_context_length", ",", "\n", "mention_key", ",", "\n", "context_key", ",", "\n", "ent_start_token", ",", "\n", "ent_end_token", ",", "\n", ")", "\n", "\n", "label", "=", "sample", "[", "label_key", "]", "\n", "title", "=", "sample", ".", "get", "(", "title_key", ",", "None", ")", "\n", "label_tokens", "=", "get_candidate_representation", "(", "\n", "label", ",", "tokenizer", ",", "max_cand_length", ",", "title", ",", "\n", ")", "\n", "label_idx", "=", "int", "(", "sample", "[", "\"label_id\"", "]", ")", "\n", "\n", "record", "=", "{", "\n", "\"context\"", ":", "context_tokens", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderModule.__init__": [[43, 58], ["super().__init__", "params.get", "pytorch_transformers.modeling_bert.BertModel.from_pretrained.resize_token_embeddings", "blink.common.ranker_base.BertEncoder", "pytorch_transformers.modeling_roberta.RobertaModel.from_pretrained", "pytorch_transformers.modeling_bert.BertModel.from_pretrained", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.resize_token_embeddings", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "tokenizer", ")", ":", "\n", "        ", "super", "(", "CrossEncoderModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "model_path", "=", "params", "[", "\"bert_model\"", "]", "\n", "if", "params", ".", "get", "(", "\"roberta\"", ")", ":", "\n", "            ", "encoder_model", "=", "RobertaModel", ".", "from_pretrained", "(", "model_path", ")", "\n", "", "else", ":", "\n", "            ", "encoder_model", "=", "BertModel", ".", "from_pretrained", "(", "model_path", ")", "\n", "", "encoder_model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "\n", "encoder_model", ",", "\n", "params", "[", "\"out_dim\"", "]", ",", "\n", "layer_pulled", "=", "params", "[", "\"pull_from_layer\"", "]", ",", "\n", "add_linear", "=", "params", "[", "\"add_linear\"", "]", ",", "\n", ")", "\n", "self", ".", "config", "=", "self", ".", "encoder", ".", "bert_model", ".", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderModule.forward": [[59, 64], ["crossencoder.CrossEncoderModule.encoder", "crossencoder.CrossEncoderModule.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "token_idx_ctxt", ",", "segment_idx_ctxt", ",", "mask_ctxt", ",", "\n", ")", ":", "\n", "        ", "embedding_ctxt", "=", "self", ".", "encoder", "(", "token_idx_ctxt", ",", "segment_idx_ctxt", ",", "mask_ctxt", ")", "\n", "return", "embedding_ctxt", ".", "squeeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.__init__": [[67, 103], ["super().__init__", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "params.get", "crossencoder.CrossEncoderRanker.tokenizer.add_special_tokens", "crossencoder.CrossEncoderRanker.build_model", "crossencoder.CrossEncoderRanker.model.to", "params.get", "pytorch_transformers.tokenization_roberta.RobertaTokenizer.from_pretrained", "pytorch_transformers.tokenization_bert.BertTokenizer.from_pretrained", "crossencoder.CrossEncoderRanker.load_model", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.build_model", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.load_model"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "shared", "=", "None", ")", ":", "\n", "        ", "super", "(", "CrossEncoderRanker", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "params", "=", "params", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\n", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "params", "[", "\"no_cuda\"", "]", "else", "\"cpu\"", "\n", ")", "\n", "self", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "if", "params", ".", "get", "(", "\"roberta\"", ")", ":", "\n", "            ", "self", ".", "tokenizer", "=", "RobertaTokenizer", ".", "from_pretrained", "(", "params", "[", "\"bert_model\"", "]", ",", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tokenizer", "=", "BertTokenizer", ".", "from_pretrained", "(", "\n", "params", "[", "\"bert_model\"", "]", ",", "do_lower_case", "=", "params", "[", "\"lowercase\"", "]", "\n", ")", "\n", "\n", "", "special_tokens_dict", "=", "{", "\n", "\"additional_special_tokens\"", ":", "[", "\n", "ENT_START_TAG", ",", "\n", "ENT_END_TAG", ",", "\n", "ENT_TITLE_TAG", ",", "\n", "]", ",", "\n", "}", "\n", "self", ".", "tokenizer", ".", "add_special_tokens", "(", "special_tokens_dict", ")", "\n", "self", ".", "NULL_IDX", "=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "self", ".", "START_TOKEN", "=", "self", ".", "tokenizer", ".", "cls_token", "\n", "self", ".", "END_TOKEN", "=", "self", ".", "tokenizer", ".", "sep_token", "\n", "\n", "# init model", "\n", "self", ".", "build_model", "(", ")", "\n", "if", "params", "[", "\"path_to_model\"", "]", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_model", "(", "params", "[", "\"path_to_model\"", "]", ")", "\n", "\n", "", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "data_parallel", "=", "params", ".", "get", "(", "\"data_parallel\"", ")", "\n", "if", "self", ".", "data_parallel", ":", "\n", "            ", "self", ".", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "self", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.load_model": [[104, 110], ["crossencoder.CrossEncoderRanker.model.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["", "", "def", "load_model", "(", "self", ",", "fname", ",", "cpu", "=", "False", ")", ":", "\n", "        ", "if", "cpu", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "fname", ",", "map_location", "=", "lambda", "storage", ",", "location", ":", "\"cpu\"", ")", "\n", "", "else", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "fname", ")", "\n", "", "self", ".", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.save": [[111, 114], ["crossencoder.CrossEncoderRanker.save_model", "crossencoder.CrossEncoderRanker.tokenizer.save_vocabulary"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.save_model"], ["", "def", "save", "(", "self", ",", "output_dir", ")", ":", "\n", "        ", "self", ".", "save_model", "(", "output_dir", ")", "\n", "self", ".", "tokenizer", ".", "save_vocabulary", "(", "output_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.build_model": [[115, 117], ["crossencoder.CrossEncoderModule"], "methods", ["None"], ["", "def", "build_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", "=", "CrossEncoderModule", "(", "self", ".", "params", ",", "self", ".", "tokenizer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.save_model": [[118, 126], ["blink.common.ranker_base.get_model_obj", "os.path.join", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "blink.common.ranker_base.get_model_obj.config.to_json_file", "os.path.exists", "os.makedirs", "blink.common.ranker_base.get_model_obj.state_dict"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.common.ranker_base.get_model_obj", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save"], ["", "def", "save_model", "(", "self", ",", "output_dir", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "get_model_obj", "(", "self", ".", "model", ")", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "WEIGHTS_NAME", ")", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "CONFIG_NAME", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_model_file", ")", "\n", "model_to_save", ".", "config", ".", "to_json_file", "(", "output_config_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.get_optimizer": [[127, 133], ["blink.common.optimizer.get_bert_optimizer", "crossencoder.CrossEncoderRanker.params.get"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.common.optimizer.get_bert_optimizer"], ["", "def", "get_optimizer", "(", "self", ",", "optim_states", "=", "None", ",", "saved_optim_type", "=", "None", ")", ":", "\n", "        ", "return", "get_bert_optimizer", "(", "\n", "[", "self", ".", "model", "]", ",", "\n", "self", ".", "params", "[", "\"type_optimization\"", "]", ",", "\n", "self", ".", "params", "[", "\"learning_rate\"", "]", ",", "\n", "fp16", "=", "self", ".", "params", ".", "get", "(", "\"fp16\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.score_candidate": [[135, 145], ["text_vecs.view.view.size", "text_vecs.view.view.view", "crossencoder.to_bert_input", "crossencoder.CrossEncoderRanker.model", "crossencoder.CrossEncoderRanker.view", "text_vecs.view.view.size"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.to_bert_input", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "score_candidate", "(", "self", ",", "text_vecs", ",", "context_len", ")", ":", "\n", "# Encode contexts first", "\n", "        ", "num_cand", "=", "text_vecs", ".", "size", "(", "1", ")", "\n", "text_vecs", "=", "text_vecs", ".", "view", "(", "-", "1", ",", "text_vecs", ".", "size", "(", "-", "1", ")", ")", "\n", "token_idx_ctxt", ",", "segment_idx_ctxt", ",", "mask_ctxt", "=", "to_bert_input", "(", "\n", "text_vecs", ",", "self", ".", "NULL_IDX", ",", "context_len", ",", "\n", ")", "\n", "embedding_ctxt", "=", "self", ".", "model", "(", "token_idx_ctxt", ",", "segment_idx_ctxt", ",", "mask_ctxt", ",", ")", "\n", "\n", "return", "embedding_ctxt", ".", "view", "(", "-", "1", ",", "num_cand", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.forward": [[146, 150], ["crossencoder.CrossEncoderRanker.score_candidate", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.score_candidate"], ["", "def", "forward", "(", "self", ",", "input_idx", ",", "label_input", ",", "context_len", ")", ":", "\n", "        ", "scores", "=", "self", ".", "score_candidate", "(", "input_idx", ",", "context_len", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "scores", ",", "label_input", ",", "reduction", "=", "\"mean\"", ")", "\n", "return", "loss", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.load_crossencoder": [[36, 40], ["crossencoder.CrossEncoderRanker"], "function", ["None"], ["def", "load_crossencoder", "(", "params", ")", ":", "\n", "# Init model", "\n", "    ", "crossencoder", "=", "CrossEncoderRanker", "(", "params", ")", "\n", "return", "crossencoder", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.to_bert_input": [[152, 164], ["None"], "function", ["None"], ["", "", "def", "to_bert_input", "(", "token_idx", ",", "null_idx", ",", "segment_pos", ")", ":", "\n", "    ", "\"\"\" token_idx is a 2D tensor int.\n        return token_idx, segment_idx and mask\n    \"\"\"", "\n", "segment_idx", "=", "token_idx", "*", "0", "\n", "if", "segment_pos", ">", "0", ":", "\n", "        ", "segment_idx", "[", ":", ",", "segment_pos", ":", "]", "=", "token_idx", "[", ":", ",", "segment_pos", ":", "]", ">", "0", "\n", "\n", "", "mask", "=", "token_idx", "!=", "null_idx", "\n", "# nullify elements in case self.NULL_IDX was not 0", "\n", "# token_idx = token_idx * mask.long()", "\n", "return", "token_idx", ",", "segment_idx", ",", "mask", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.common.ranker_base.BertEncoder.__init__": [[16, 29], ["torch.nn.Module.__init__", "bert_model.embeddings.word_embeddings.weight.size", "torch.nn.Dropout", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["self", ",", "bert_model", ",", "output_dim", ",", "layer_pulled", "=", "-", "1", ",", "add_linear", "=", "None", ")", ":", "\n", "        ", "super", "(", "BertEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer_pulled", "=", "layer_pulled", "\n", "bert_output_dim", "=", "bert_model", ".", "embeddings", ".", "word_embeddings", ".", "weight", ".", "size", "(", "1", ")", "\n", "\n", "self", ".", "bert_model", "=", "bert_model", "\n", "if", "add_linear", ":", "\n", "            ", "self", ".", "additional_linear", "=", "nn", ".", "Linear", "(", "bert_output_dim", ",", "output_dim", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "additional_linear", "=", "None", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "token_ids", ",", "segment_ids", ",", "attention_mask", ")", ":", "\n", "        ", "output_bert", ",", "output_pooler", "=", "self", ".", "bert_model", "(", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.common.ranker_base.BertEncoder.forward": [[30, 63], ["pdb.set_trace", "ranker_base.BertEncoder.bert_model", "ranker_base.BertEncoder.additional_linear", "print", "print", "print", "print", "pdb.set_trace", "ranker_base.BertEncoder.bert_model", "ranker_base.BertEncoder.dropout", "token_ids.size", "segment_ids.size", "attention_mask.size"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["token_ids", ",", "segment_ids", ",", "attention_mask", "\n", ")", "\n", "# get embedding of [CLS] token", "\n", "if", "self", ".", "additional_linear", "is", "not", "None", ":", "\n", "            ", "embeddings", "=", "output_pooler", "\n", "", "else", ":", "\n", "            ", "embeddings", "=", "output_bert", "[", ":", ",", "0", ",", ":", "]", "\n", "\n", "# in case of dimensionality reduction", "\n", "", "if", "self", ".", "additional_linear", "is", "not", "None", ":", "\n", "            ", "result", "=", "self", ".", "additional_linear", "(", "self", ".", "dropout", "(", "embeddings", ")", ")", "\n", "", "else", ":", "\n", "            ", "result", "=", "embeddings", "\n", "\n", "", "return", "result", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.common.ranker_base.get_model_obj": [[11, 14], ["hasattr"], "function", ["None"], ["    ", "model", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", "return", "model", "\n", "\n", "", "class", "BertEncoder", "(", "nn", ".", "Module", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.common.params.BlinkParser.__init__": [[35, 59], ["argparse.ArgumentParser.__init__", "os.path.dirname", "os.path.dirname", "params.BlinkParser.add_blink_args", "params.BlinkParser.add_model_args", "os.path.dirname", "os.path.realpath"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.common.params.BlinkParser.add_blink_args", "home.repos.pwc.inspect_result.chenllliang_atp.common.params.ElqParser.add_model_args"], ["def", "__init__", "(", "\n", "self", ",", "add_blink_args", "=", "True", ",", "add_model_args", "=", "False", ",", "\n", "description", "=", "'BLINK parser'", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "description", "=", "description", ",", "\n", "allow_abbrev", "=", "False", ",", "\n", "conflict_handler", "=", "'resolve'", ",", "\n", "formatter_class", "=", "argparse", ".", "HelpFormatter", ",", "\n", "add_help", "=", "add_blink_args", ",", "\n", ")", "\n", "self", ".", "blink_home", "=", "os", ".", "path", ".", "dirname", "(", "\n", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", ")", "\n", ")", "\n", "os", ".", "environ", "[", "'BLINK_HOME'", "]", "=", "self", ".", "blink_home", "\n", "\n", "self", ".", "add_arg", "=", "self", ".", "add_argument", "\n", "\n", "self", ".", "overridable", "=", "{", "}", "\n", "\n", "if", "add_blink_args", ":", "\n", "            ", "self", ".", "add_blink_args", "(", ")", "\n", "", "if", "add_model_args", ":", "\n", "            ", "self", ".", "add_model_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.common.params.BlinkParser.add_blink_args": [[60, 91], ["params.BlinkParser.add_argument_group", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument"], "methods", ["None"], ["", "", "def", "add_blink_args", "(", "self", ",", "args", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Add common BLINK args across all scripts.\n        \"\"\"", "\n", "parser", "=", "self", ".", "add_argument_group", "(", "\"Common Arguments\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--silent\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to print progress bars.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--debug\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run in debug mode with only 200 samples.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_parallel\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to distributed the candidate generation process.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether not to use CUDA when available\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--top_k\"", ",", "default", "=", "10", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "52313", ",", "help", "=", "\"random seed for initialization\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--zeshel\"", ",", "\n", "default", "=", "True", ",", "\n", "type", "=", "bool", ",", "\n", "help", "=", "\"Whether the dataset is from zeroshot.\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.common.params.BlinkParser.add_model_args": [[93, 165], ["params.BlinkParser.add_argument_group", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument"], "methods", ["None"], ["", "def", "add_model_args", "(", "self", ",", "args", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Add model args.\n        \"\"\"", "\n", "parser", "=", "self", ".", "add_argument_group", "(", "\"Model Arguments\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "256", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after WordPiece tokenization. \\n\"", "\n", "\"Sequences longer than this will be truncated, and sequences shorter \\n\"", "\n", "\"than this will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_context_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total context input sequence length after WordPiece tokenization. \\n\"", "\n", "\"Sequences longer than this will be truncated, and sequences shorter \\n\"", "\n", "\"than this will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_cand_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total label input sequence length after WordPiece tokenization. \\n\"", "\n", "\"Sequences longer than this will be truncated, and sequences shorter \\n\"", "\n", "\"than this will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--path_to_model\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "False", ",", "\n", "help", "=", "\"The full path to the model to load.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--bert_model\"", ",", "\n", "default", "=", "\"bert-base-uncased\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Bert pre-trained model selected in the list: bert-base-uncased, \"", "\n", "\"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pull_from_layer\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"Layers to pull from BERT\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lowercase\"", ",", "\n", "action", "=", "\"store_false\"", ",", "\n", "help", "=", "\"Whether to lower case the input text. True for uncased models, False for cased models.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--context_key\"", ",", "default", "=", "\"context\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--out_dim\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"Output dimention of bi-encoders.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--add_linear\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to add an additonal linear projection on top of BERT.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_path\"", ",", "\n", "default", "=", "\"data/zeshel\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The path to the train data.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where generated output file (model, etc.) is to be dumped.\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.common.params.BlinkParser.add_training_args": [[168, 235], ["params.BlinkParser.add_argument_group", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument"], "methods", ["None"], ["", "def", "add_training_args", "(", "self", ",", "args", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Add model training args.\n        \"\"\"", "\n", "parser", "=", "self", ".", "add_argument_group", "(", "\"Model Training Arguments\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_eval_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The txt file where the the evaluation results will be written.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Total batch size for training.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--learning_rate\"", ",", "\n", "default", "=", "3e-5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Number of training epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--print_interval\"", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "\"Interval of loss printing\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_interval\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "100", ",", "\n", "help", "=", "\"Interval for evaluation during training\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_interval\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Interval for model saving\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--warmup_proportion\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Proportion of training to perform linear learning rate warmup for. \"", "\n", "\"E.g., 0.1 = 10% of training.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumualte before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--type_optimization\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"all_encoder_layers\"", ",", "\n", "help", "=", "\"Which type of layers to optimize in BERT\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shuffle\"", ",", "type", "=", "bool", ",", "default", "=", "False", ",", "\n", "help", "=", "\"Whether to shuffle train data\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.common.params.BlinkParser.add_eval_args": [[237, 274], ["params.BlinkParser.add_argument_group", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument", "params.BlinkParser.add_argument"], "methods", ["None"], ["", "def", "add_eval_args", "(", "self", ",", "args", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Add model evaluation args.\n        \"\"\"", "\n", "parser", "=", "self", ".", "add_argument_group", "(", "\"Model Evaluation Arguments\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Total batch size for evaluation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mode\"", ",", "\n", "default", "=", "\"valid\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Train / validation / test\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_topk_result\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to save prediction results.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encode_batch_size\"", ",", "\n", "default", "=", "8", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size for encoding.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cand_pool_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path for cached candidate pool (id tokenization of candidates)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cand_encode_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path for cached candidate encoding\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.common.optimizer.get_bert_optimizer": [[37, 80], ["print", "print", "print", "print", "pytorch_transformers.optimization.AdamW", "print", "model.named_parameters", "optimizer.ellipse", "optimizer.ellipse", "fp16_optimizer_wrapper", "any", "str", "any", "patterns_optimizer.keys", "parameters_without_decay.append", "parameters_without_decay_names.append", "parameters_with_decay.append", "parameters_with_decay_names.append"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.common.optimizer.ellipse", "home.repos.pwc.inspect_result.chenllliang_atp.common.optimizer.ellipse"], ["def", "get_bert_optimizer", "(", "models", ",", "type_optimization", ",", "learning_rate", ",", "fp16", "=", "False", ")", ":", "\n", "    ", "\"\"\" Optimizes the network with AdamWithDecay\n    \"\"\"", "\n", "if", "type_optimization", "not", "in", "patterns_optimizer", ":", "\n", "        ", "print", "(", "\n", "'Error. Type optimizer must be one of %s'", "%", "(", "str", "(", "patterns_optimizer", ".", "keys", "(", ")", ")", ")", "\n", ")", "\n", "", "parameters_with_decay", "=", "[", "]", "\n", "parameters_with_decay_names", "=", "[", "]", "\n", "parameters_without_decay", "=", "[", "]", "\n", "parameters_without_decay_names", "=", "[", "]", "\n", "no_decay", "=", "[", "'bias'", ",", "'gamma'", ",", "'beta'", "]", "\n", "patterns", "=", "patterns_optimizer", "[", "type_optimization", "]", "\n", "\n", "for", "model", "in", "models", ":", "\n", "        ", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "any", "(", "t", "in", "n", "for", "t", "in", "patterns", ")", ":", "\n", "                ", "if", "any", "(", "t", "in", "n", "for", "t", "in", "no_decay", ")", ":", "\n", "                    ", "parameters_without_decay", ".", "append", "(", "p", ")", "\n", "parameters_without_decay_names", ".", "append", "(", "n", ")", "\n", "", "else", ":", "\n", "                    ", "parameters_with_decay", ".", "append", "(", "p", ")", "\n", "parameters_with_decay_names", ".", "append", "(", "n", ")", "\n", "\n", "", "", "", "", "print", "(", "'The following parameters will be optimized WITH decay:'", ")", "\n", "print", "(", "ellipse", "(", "parameters_with_decay_names", ",", "5", ",", "' , '", ")", ")", "\n", "print", "(", "'The following parameters will be optimized WITHOUT decay:'", ")", "\n", "print", "(", "ellipse", "(", "parameters_without_decay_names", ",", "5", ",", "' , '", ")", ")", "\n", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "parameters_with_decay", ",", "'weight_decay'", ":", "0.01", "}", ",", "\n", "{", "'params'", ":", "parameters_without_decay", ",", "'weight_decay'", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "learning_rate", ",", "\n", "correct_bias", "=", "False", "\n", ")", "\n", "\n", "if", "fp16", ":", "\n", "        ", "optimizer", "=", "fp16_optimizer_wrapper", "(", "optimizer", ")", "\n", "\n", "", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.common.optimizer.ellipse": [[82, 97], ["list", "sep.join", "len", "str", "len"], "function", ["None"], ["", "def", "ellipse", "(", "lst", ",", "max_display", "=", "5", ",", "sep", "=", "'|'", ")", ":", "\n", "    ", "\"\"\"\n    Like join, but possibly inserts an ellipsis.\n    :param lst: The list to join on\n    :param int max_display: the number of items to display for ellipsing.\n        If -1, shows all items\n    :param string sep: the delimiter to join on\n    \"\"\"", "\n", "# copy the list (or force it to a list if it's a set)", "\n", "choices", "=", "list", "(", "lst", ")", "\n", "# insert the ellipsis if necessary", "\n", "if", "max_display", ">", "0", "and", "len", "(", "choices", ")", ">", "max_display", ":", "\n", "        ", "ellipsis", "=", "'...and {} more'", ".", "format", "(", "len", "(", "choices", ")", "-", "max_display", ")", "\n", "choices", "=", "choices", "[", ":", "max_display", "]", "+", "[", "ellipsis", "]", "\n", "", "return", "sep", ".", "join", "(", "str", "(", "c", ")", "for", "c", "in", "choices", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.common.params.ElqParser.__init__": [[35, 59], ["argparse.ArgumentParser.__init__", "os.path.dirname", "os.path.dirname", "params.ElqParser.add_elq_args", "params.ElqParser.add_model_args", "os.path.dirname", "os.path.realpath"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.common.params.ElqParser.add_elq_args", "home.repos.pwc.inspect_result.chenllliang_atp.common.params.ElqParser.add_model_args"], ["def", "__init__", "(", "\n", "self", ",", "add_blink_args", "=", "True", ",", "add_model_args", "=", "False", ",", "\n", "description", "=", "'BLINK parser'", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "description", "=", "description", ",", "\n", "allow_abbrev", "=", "False", ",", "\n", "conflict_handler", "=", "'resolve'", ",", "\n", "formatter_class", "=", "argparse", ".", "HelpFormatter", ",", "\n", "add_help", "=", "add_blink_args", ",", "\n", ")", "\n", "self", ".", "blink_home", "=", "os", ".", "path", ".", "dirname", "(", "\n", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", ")", "\n", ")", "\n", "os", ".", "environ", "[", "'BLINK_HOME'", "]", "=", "self", ".", "blink_home", "\n", "\n", "self", ".", "add_arg", "=", "self", ".", "add_argument", "\n", "\n", "self", ".", "overridable", "=", "{", "}", "\n", "\n", "if", "add_blink_args", ":", "\n", "            ", "self", ".", "add_blink_args", "(", ")", "\n", "", "if", "add_model_args", ":", "\n", "            ", "self", ".", "add_model_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.common.params.ElqParser.add_elq_args": [[60, 91], ["params.ElqParser.add_argument_group", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument"], "methods", ["None"], ["", "", "def", "add_blink_args", "(", "self", ",", "args", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Add common BLINK args across all scripts.\n        \"\"\"", "\n", "parser", "=", "self", ".", "add_argument_group", "(", "\"Common Arguments\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--silent\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to print progress bars.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--debug\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run in debug mode with only 200 samples.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_parallel\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to distributed the candidate generation process.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether not to use CUDA when available\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--top_k\"", ",", "default", "=", "10", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "52313", ",", "help", "=", "\"random seed for initialization\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--zeshel\"", ",", "\n", "default", "=", "True", ",", "\n", "type", "=", "bool", ",", "\n", "help", "=", "\"Whether the dataset is from zeroshot.\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.common.params.ElqParser.add_model_args": [[93, 195], ["params.ElqParser.add_argument_group", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument"], "methods", ["None"], ["", "def", "add_model_args", "(", "self", ",", "args", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Add model args.\n        \"\"\"", "\n", "parser", "=", "self", ".", "add_argument_group", "(", "\"Model Arguments\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "256", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after WordPiece tokenization. \\n\"", "\n", "\"Sequences longer than this will be truncated, and sequences shorter \\n\"", "\n", "\"than this will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_context_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total context input sequence length after WordPiece tokenization. \\n\"", "\n", "\"Sequences longer than this will be truncated, and sequences shorter \\n\"", "\n", "\"than this will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_cand_length\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total label input sequence length after WordPiece tokenization. \\n\"", "\n", "\"Sequences longer than this will be truncated, and sequences shorter \\n\"", "\n", "\"than this will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--path_to_model\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "False", ",", "\n", "help", "=", "\"The full path to the model to load.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--bert_model\"", ",", "\n", "default", "=", "\"bert-base-uncased\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Bert pre-trained model selected in the list: bert-base-uncased, \"", "\n", "\"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--pull_from_layer\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"Layers to pull from BERT\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lowercase\"", ",", "\n", "action", "=", "\"store_false\"", ",", "\n", "help", "=", "\"Whether to lower case the input text. True for uncased models, False for cased models.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--context_key\"", ",", "default", "=", "\"context\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--out_dim\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"Output dimention of bi-encoders.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--add_linear\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to add an additonal linear projection on top of BERT.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_path\"", ",", "\n", "default", "=", "\"data/zeshel\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The path to the train data.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where generated output file (model, etc.) is to be dumped.\"", ",", "\n", ")", "\n", "\n", "\n", "", "def", "add_training_args", "(", "self", ",", "args", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Add model training args.\n        \"\"\"", "\n", "parser", "=", "self", ".", "add_argument_group", "(", "\"Model Training Arguments\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_eval_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The txt file where the the evaluation results will be written.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Total batch size for training.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--learning_rate\"", ",", "\n", "default", "=", "3e-5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "\n", "default", "=", "1", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.common.params.ElqParser.add_training_args": [[197, 343], ["params.ElqParser.add_argument_group", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument"], "methods", ["None"], ["help", "=", "\"Number of training epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--print_interval\"", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "\"Interval of loss printing\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_interval\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "100", ",", "\n", "help", "=", "\"Interval for evaluation during training\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_interval\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Interval for model saving\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--warmup_proportion\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Proportion of training to perform linear learning rate warmup for. \"", "\n", "\"E.g., 0.1 = 10% of training.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumualte before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--type_optimization\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"all_encoder_layers\"", ",", "\n", "help", "=", "\"Which type of layers to optimize in BERT\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shuffle\"", ",", "type", "=", "bool", ",", "default", "=", "False", ",", "\n", "help", "=", "\"Whether to shuffle train data\"", ",", "\n", ")", "\n", "\n", "", "def", "add_eval_args", "(", "self", ",", "args", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Add model evaluation args.\n        \"\"\"", "\n", "parser", "=", "self", ".", "add_argument_group", "(", "\"Model Evaluation Arguments\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Total batch size for evaluation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--mode\"", ",", "\n", "default", "=", "\"valid\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Train / validation / test\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_topk_result\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to save prediction results.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encode_batch_size\"", ",", "\n", "default", "=", "8", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size for encoding.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cand_pool_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path for cached candidate pool (id tokenization of candidates)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cand_encode_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path for cached candidate encoding\"", ",", "\n", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.common.params.ElqParser.add_eval_args": [[345, 378], ["params.ElqParser.add_argument_group", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument", "params.ElqParser.add_argument"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.zeshel.create_BLINK_zeshel_data.LogFormatter.__init__": [[37, 39], ["time.time"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.zeshel.create_BLINK_zeshel_data.LogFormatter.format": [[40, 51], ["round", "record.getMessage", "message.replace.replace.replace", "time.strftime", "datetime.timedelta", "len"], "methods", ["None"], ["", "def", "format", "(", "self", ",", "record", ")", ":", "\n", "        ", "elapsed_seconds", "=", "round", "(", "record", ".", "created", "-", "self", ".", "start_time", ")", "\n", "\n", "prefix", "=", "\"%s - %s - %s\"", "%", "(", "\n", "record", ".", "levelname", ",", "\n", "time", ".", "strftime", "(", "\"%x %X\"", ")", ",", "\n", "timedelta", "(", "seconds", "=", "elapsed_seconds", ")", "\n", ")", "\n", "message", "=", "record", ".", "getMessage", "(", ")", "\n", "message", "=", "message", ".", "replace", "(", "'\\n'", ",", "'\\n'", "+", "' '", "*", "(", "len", "(", "prefix", ")", "+", "3", ")", ")", "\n", "return", "\"%s - %s\"", "%", "(", "prefix", ",", "message", ")", "if", "message", "else", "''", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.zeshel.create_BLINK_zeshel_data.load_entity_dict": [[65, 89], ["os.path.join", "os.path.isfile", "logger.info", "open", "line.rstrip.rstrip", "json.loads", "len", "doc_list.append"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads"], ["def", "load_entity_dict", "(", "params", ")", ":", "\n", "    ", "entity_dict", "=", "{", "}", "\n", "entity_map", "=", "{", "}", "\n", "for", "src", "in", "WORLDS", ":", "\n", "        ", "fname", "=", "os", ".", "path", ".", "join", "(", "params", ".", "document_path", ",", "src", "+", "\".json\"", ")", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "fname", ")", ",", "\"File not found! %s\"", "%", "fname", "\n", "cur_dict", "=", "{", "}", "\n", "doc_map", "=", "{", "}", "\n", "doc_list", "=", "[", "]", "\n", "with", "open", "(", "fname", ",", "'rt'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "item", "=", "json", ".", "loads", "(", "line", ")", "\n", "doc_id", "=", "item", "[", "\"document_id\"", "]", "\n", "title", "=", "item", "[", "\"title\"", "]", "\n", "text", "=", "item", "[", "\"text\"", "]", "\n", "doc_map", "[", "doc_id", "]", "=", "len", "(", "doc_list", ")", "\n", "doc_list", ".", "append", "(", "item", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"Load for world %s.\"", "%", "src", ")", "\n", "entity_dict", "[", "src", "]", "=", "doc_list", "\n", "entity_map", "[", "src", "]", "=", "doc_map", "\n", "\n", "", "return", "entity_dict", ",", "entity_map", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.zeshel.create_BLINK_zeshel_data.convert_data": [[91, 140], ["open", "open.close", "os.path.join", "os.path.join", "os.path.join", "open", "line.rstrip.rstrip", "json.loads", "item[].lower", "[].lower", "[].lower.split", "open.write", "open.write", "json.dumps", "max", "min", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "convert_data", "(", "params", ",", "entity_dict", ",", "entity_map", ",", "mode", ")", ":", "\n", "    ", "if", "mode", "==", "\"valid\"", ":", "\n", "        ", "fname", "=", "os", ".", "path", ".", "join", "(", "params", ".", "mention_path", ",", "\"val.json\"", ")", "\n", "", "else", ":", "\n", "        ", "fname", "=", "os", ".", "path", ".", "join", "(", "params", ".", "mention_path", ",", "mode", "+", "\".json\"", ")", "\n", "\n", "", "fout", "=", "open", "(", "os", ".", "path", ".", "join", "(", "params", ".", "output_path", ",", "mode", "+", "\".jsonl\"", ")", ",", "'wt'", ")", "\n", "cnt", "=", "0", "\n", "max_tok", "=", "128", "\n", "with", "open", "(", "fname", ",", "'rt'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "cnt", "+=", "1", "\n", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "item", "=", "json", ".", "loads", "(", "line", ")", "\n", "mention", "=", "item", "[", "\"text\"", "]", ".", "lower", "(", ")", "\n", "src", "=", "item", "[", "\"corpus\"", "]", "\n", "label_doc_id", "=", "item", "[", "\"label_document_id\"", "]", "\n", "orig_doc_id", "=", "item", "[", "\"context_document_id\"", "]", "\n", "start", "=", "item", "[", "\"start_index\"", "]", "\n", "end", "=", "item", "[", "\"end_index\"", "]", "\n", "\n", "# add context around the mention as well", "\n", "orig_id", "=", "entity_map", "[", "src", "]", "[", "orig_doc_id", "]", "\n", "text", "=", "entity_dict", "[", "src", "]", "[", "orig_id", "]", "[", "\"text\"", "]", ".", "lower", "(", ")", "\n", "tokens", "=", "text", ".", "split", "(", "\" \"", ")", "\n", "\n", "assert", "mention", "==", "' '", ".", "join", "(", "tokens", "[", "start", ":", "end", "+", "1", "]", ")", "\n", "tokenized_query", "=", "mention", "\n", "\n", "mention_context_left", "=", "tokens", "[", "max", "(", "0", ",", "start", "-", "max_tok", ")", ":", "start", "]", "\n", "mention_context_right", "=", "tokens", "[", "end", "+", "1", ":", "min", "(", "len", "(", "tokens", ")", ",", "end", "+", "max_tok", "+", "1", ")", "]", "\n", "\n", "# entity info", "\n", "k", "=", "entity_map", "[", "src", "]", "[", "label_doc_id", "]", "\n", "ent_title", "=", "entity_dict", "[", "src", "]", "[", "k", "]", "[", "'title'", "]", "\n", "ent_text", "=", "entity_dict", "[", "src", "]", "[", "k", "]", "[", "\"text\"", "]", "\n", "\n", "example", "=", "{", "}", "\n", "example", "[", "\"context_left\"", "]", "=", "' '", ".", "join", "(", "mention_context_left", ")", "\n", "example", "[", "'context_right'", "]", "=", "' '", ".", "join", "(", "mention_context_right", ")", "\n", "example", "[", "\"mention\"", "]", "=", "mention", "\n", "example", "[", "\"label\"", "]", "=", "ent_text", "\n", "example", "[", "\"label_id\"", "]", "=", "k", "\n", "example", "[", "'label_title'", "]", "=", "ent_title", "\n", "example", "[", "'world'", "]", "=", "src", "\n", "fout", ".", "write", "(", "json", ".", "dumps", "(", "example", ")", ")", "\n", "fout", ".", "write", "(", "'\\n'", ")", "\n", "\n", "", "", "fout", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.scripts.tune_hyperparams_new.load_dists": [[20, 41], ["numpy.load", "numpy.load", "os.path.exists", "numpy.load", "os.path.exists", "os.path.exists", "open", "f.readlines", "os.path.join", "os.path.join", "os.path.join", "numpy.load", "numpy.load", "os.path.join", "os.path.join", "numpy.load", "os.path.join", "json.loads", "os.path.join", "os.path.join", "os.path.join", "numpy.log", "torch.log_softmax().numpy", "range", "len", "torch.log_softmax", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads"], ["def", "load_dists", "(", "all_save_dir", ",", "data", ",", "split", ",", "model", ",", "joint_threshold", ")", ":", "\n", "    ", "save_dir", "=", "\"{}/{}_{}_{}_joint{}_top50cands_final_joint\"", ".", "format", "(", "all_save_dir", ",", "data", ",", "split", ",", "model", ",", "joint_threshold", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_dir", ")", ":", "\n", "        ", "save_dir", "+=", "\"_0\"", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"biencoder_outs.jsonl\"", ")", ")", "as", "f", ":", "\n", "        ", "examples", "=", "f", ".", "readlines", "(", ")", "\n", "examples", "=", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "examples", "]", "\n", "", "biencoder_indices", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"biencoder_nns.npy\"", ")", ",", "allow_pickle", "=", "True", ")", "# corresponds to biencoder_dists", "\n", "biencoder_dists", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"biencoder_dists.npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"biencoder_cand_scores.npy\"", ")", ")", ":", "\n", "        ", "cand_dists", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"biencoder_cand_scores.npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "cand_dists", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"biencoder_cand_dists.npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "", "pred_mention_bounds", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"biencoder_mention_bounds.npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"biencoder_mention_scores.npy\"", ")", ")", ":", "\n", "        ", "mention_dists", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"biencoder_mention_scores.npy\"", ")", ",", "allow_pickle", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "mention_dists", "=", "[", "biencoder_dists", "[", "i", "]", "-", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "cand_dists", "[", "i", "]", ")", ",", "1", ")", ".", "numpy", "(", ")", "for", "i", "in", "range", "(", "len", "(", "biencoder_dists", ")", ")", "]", "\n", "# inverse sigmoid", "\n", "mention_dists", "=", "[", "np", ".", "log", "(", "md", "/", "(", "1", "-", "md", ")", ")", "for", "md", "in", "mention_dists", "]", "\n", "", "return", "examples", ",", "biencoder_indices", ",", "biencoder_dists", ",", "cand_dists", ",", "pred_mention_bounds", ",", "mention_dists", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.scripts.tune_hyperparams_new.filter_repeats": [[43, 58], ["sorted", "enumerate", "enumerate", "all_pred_entities_pruned.append", "all_pred_scores_pruned.append"], "function", ["None"], ["", "def", "filter_repeats", "(", "pred_triples", ",", "pred_scores", ")", ":", "\n", "# sort pred_triples and pred_scores by pred_scores", "\n", "    ", "score_sort_ids", "=", "sorted", "(", "enumerate", "(", "pred_scores", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "pred_triples", "=", "[", "pred_triples", "[", "si", "[", "0", "]", "]", "for", "si", "in", "score_sort_ids", "]", "\n", "pred_scores", "=", "[", "score_sort_id", "[", "1", "]", "for", "score_sort_id", "in", "score_sort_ids", "]", "\n", "all_pred_entities", "=", "{", "}", "\n", "all_pred_entities_pruned", "=", "[", "]", "\n", "all_pred_scores_pruned", "=", "[", "]", "\n", "for", "idx", ",", "ent", "in", "enumerate", "(", "pred_triples", ")", ":", "\n", "        ", "if", "ent", "[", "0", "]", "in", "all_pred_entities", ":", "\n", "            ", "continue", "\n", "", "all_pred_entities_pruned", ".", "append", "(", "ent", ")", "\n", "all_pred_scores_pruned", ".", "append", "(", "pred_scores", "[", "idx", "]", ")", "\n", "all_pred_entities", "[", "ent", "[", "0", "]", "]", "=", "0", "\n", "", "return", "all_pred_entities_pruned", ",", "all_pred_scores_pruned", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.scripts.tune_hyperparams_new.filter_overlaps": [[60, 73], ["numpy.zeros", "enumerate", "len", "all_pred_entities_pruned.append", "all_pred_scores_pruned.append", "sum"], "function", ["None"], ["", "def", "filter_overlaps", "(", "tokens", ",", "pred_triples", ",", "pred_scores", ")", ":", "\n", "    ", "all_pred_entities_pruned", "=", "[", "]", "\n", "all_pred_scores_pruned", "=", "[", "]", "\n", "mention_masked_utterance", "=", "np", ".", "zeros", "(", "len", "(", "tokens", ")", ")", "\n", "# ensure well-formed-ness, prune overlaps", "\n", "# greedily pick highest scoring, then prune all overlapping", "\n", "for", "idx", ",", "mb", "in", "enumerate", "(", "pred_triples", ")", ":", "\n", "        ", "if", "sum", "(", "mention_masked_utterance", "[", "mb", "[", "1", "]", ":", "mb", "[", "2", "]", "]", ")", ">", "0", ":", "\n", "            ", "continue", "\n", "", "all_pred_entities_pruned", ".", "append", "(", "mb", ")", "\n", "all_pred_scores_pruned", ".", "append", "(", "pred_scores", "[", "idx", "]", ")", "\n", "mention_masked_utterance", "[", "mb", "[", "1", "]", ":", "mb", "[", "2", "]", "]", "=", "1", "\n", "", "return", "all_pred_entities_pruned", ",", "all_pred_scores_pruned", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.scripts.tune_hyperparams_new.filter_repeat_overlaps": [[75, 88], ["enumerate", "numpy.zeros", "all_pred_entities_pruned.append", "all_pred_scores_pruned.append", "len", "sum"], "function", ["None"], ["", "def", "filter_repeat_overlaps", "(", "tokens", ",", "pred_triples", ",", "pred_scores", ")", ":", "\n", "    ", "all_pred_entities_pruned", "=", "[", "]", "\n", "all_pred_scores_pruned", "=", "[", "]", "\n", "mention_masked_utterance", "=", "{", "triple", "[", "0", "]", ":", "np", ".", "zeros", "(", "len", "(", "tokens", ")", ")", "for", "triple", "in", "pred_triples", "}", "\n", "# ensure well-formed-ness, prune overlaps", "\n", "# greedily pick highest scoring, then prune all overlapping", "\n", "for", "idx", ",", "mb", "in", "enumerate", "(", "pred_triples", ")", ":", "\n", "        ", "if", "sum", "(", "mention_masked_utterance", "[", "mb", "[", "0", "]", "]", "[", "mb", "[", "1", "]", ":", "mb", "[", "2", "]", "]", ")", ">", "0", ":", "\n", "            ", "continue", "\n", "", "all_pred_entities_pruned", ".", "append", "(", "mb", ")", "\n", "all_pred_scores_pruned", ".", "append", "(", "pred_scores", "[", "idx", "]", ")", "\n", "mention_masked_utterance", "[", "mb", "[", "0", "]", "]", "[", "mb", "[", "1", "]", ":", "mb", "[", "2", "]", "]", "=", "1", "\n", "", "return", "all_pred_entities_pruned", ",", "all_pred_scores_pruned", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.scripts.tune_hyperparams_new.get_threshold_mask_and_sort": [[91, 112], ["len", "torch.log_softmax", "torch.sigmoid().log().unsqueeze", "[].sort", "scores[].sort", "scores_mask.numpy", "sorted_idxs.numpy", "sorted_filtered_scores.numpy", "torch.tensor", "torch.sigmoid().log", "torch.sigmoid", "torch.tensor"], "function", ["None"], ["", "def", "get_threshold_mask_and_sort", "(", "mention_dists", ",", "cand_dists", ",", "biencoder_dists", ",", "valid_cands_mask", ",", "threshold", ",", "top_mention_sort", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n        top_mention_sort:\n            True: sort top candidates per mention only\n                scores_mask and sorted_idxs has dim (#_valid_examples,)\n            False: sort ALL candidates (assumes multiple candidates per mention)\n                scores_mask and sorted_idxs has dim (#_valid_examples, #_cands)\n    \"\"\"", "\n", "mention_scores", "=", "mention_dists", "[", "valid_cands_mask", "]", "\n", "if", "len", "(", "mention_scores", ".", "shape", ")", ">", "1", ":", "\n", "        ", "mention_scores", "=", "mention_scores", "[", ":", ",", "0", "]", "\n", "", "scores", "=", "torch", ".", "log_softmax", "(", "torch", ".", "tensor", "(", "cand_dists", "[", "valid_cands_mask", "]", ")", ",", "1", ")", "+", "torch", ".", "sigmoid", "(", "torch", ".", "tensor", "(", "mention_scores", ")", ")", ".", "log", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "if", "top_mention_sort", ":", "\n", "        ", "scores_mask", "=", "(", "scores", "[", ":", ",", "0", "]", ">", "threshold", ")", "\n", "# sort...", "\n", "_", ",", "sorted_idxs", "=", "scores", "[", ":", ",", "0", "]", "[", "scores_mask", "]", ".", "sort", "(", "descending", "=", "True", ")", "\n", "sorted_filtered_scores", "=", "scores", "[", "scores_mask", "]", "[", "sorted_idxs", "]", "\n", "", "else", ":", "\n", "        ", "scores_mask", "=", "(", "scores", ">", "threshold", ")", "# GRAPHQUESTIONS BEST", "\n", "sorted_filtered_scores", ",", "sorted_idxs", "=", "scores", "[", "scores_mask", "]", ".", "sort", "(", "descending", "=", "True", ")", "\n", "", "return", "scores_mask", ".", "numpy", "(", ")", ",", "sorted_idxs", ".", "numpy", "(", ")", ",", "sorted_filtered_scores", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.scripts.generate_candidates.encode_candidate": [[19, 50], ["reranker.model.eval", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "enumerate", "tqdm.tqdm", "cands.to.to", "reranker.encode_candidate", "torch.cat"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.scripts.generate_candidates.encode_candidate"], ["def", "encode_candidate", "(", "\n", "reranker", ",", "\n", "candidate_pool", ",", "\n", "encode_batch_size", ",", "\n", "silent", ",", "\n", "logger", ",", "\n", ")", ":", "\n", "    ", "reranker", ".", "model", ".", "eval", "(", ")", "\n", "device", "=", "reranker", ".", "device", "\n", "#for cand_pool in candidate_pool:", "\n", "#logger.info(\"Encoding candidate pool %s\" % src)", "\n", "sampler", "=", "SequentialSampler", "(", "candidate_pool", ")", "\n", "data_loader", "=", "DataLoader", "(", "\n", "candidate_pool", ",", "sampler", "=", "sampler", ",", "batch_size", "=", "encode_batch_size", "\n", ")", "\n", "if", "silent", ":", "\n", "        ", "iter_", "=", "data_loader", "\n", "", "else", ":", "\n", "        ", "iter_", "=", "tqdm", "(", "data_loader", ")", "\n", "\n", "", "cand_encode_list", "=", "None", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "iter_", ")", ":", "\n", "        ", "cands", "=", "batch", "\n", "cands", "=", "cands", ".", "to", "(", "device", ")", "\n", "cand_encode", "=", "reranker", ".", "encode_candidate", "(", "cands", ")", "\n", "if", "cand_encode_list", "is", "None", ":", "\n", "            ", "cand_encode_list", "=", "cand_encode", "\n", "", "else", ":", "\n", "            ", "cand_encode_list", "=", "torch", ".", "cat", "(", "(", "cand_encode_list", ",", "cand_encode", ")", ")", "\n", "\n", "", "", "return", "cand_encode_list", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.scripts.generate_candidates.load_candidate_pool": [[52, 69], ["logger.info", "logger.info", "torch.load", "logger.info"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["", "def", "load_candidate_pool", "(", "\n", "tokenizer", ",", "\n", "params", ",", "\n", "logger", ",", "\n", "cand_pool_path", ",", "\n", ")", ":", "\n", "    ", "candidate_pool", "=", "None", "\n", "# try to load candidate pool from file", "\n", "try", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading pre-generated candidate pool from: \"", ")", "\n", "logger", ".", "info", "(", "cand_pool_path", ")", "\n", "candidate_pool", "=", "torch", ".", "load", "(", "cand_pool_path", ")", "\n", "", "except", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading failed.\"", ")", "\n", "", "assert", "candidate_pool", "is", "not", "None", "\n", "\n", "return", "candidate_pool", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.scripts.create_BLINK_benchmark_data._read_url": [[19, 25], ["urllib.request.urlopen", "response.read", "bs4.BeautifulSoup", "bs4.BeautifulSoup.title.string.replace().strip", "bs4.BeautifulSoup.title.string.replace"], "function", ["None"], ["def", "_read_url", "(", "url", ")", ":", "\n", "    ", "with", "urllib", ".", "request", ".", "urlopen", "(", "url", ")", "as", "response", ":", "\n", "        ", "html", "=", "response", ".", "read", "(", ")", "\n", "soup", "=", "BeautifulSoup", "(", "html", ",", "features", "=", "\"html.parser\"", ")", "\n", "title", "=", "soup", ".", "title", ".", "string", ".", "replace", "(", "\" - Wikipedia\"", ",", "\"\"", ")", ".", "strip", "(", ")", "\n", "", "return", "title", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.scripts.create_BLINK_benchmark_data._get_pageid_from_api": [[27, 51], ["title.strip().replace", "requests.get", "requests.get.json", "[].items", "title.strip", "len", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "_get_pageid_from_api", "(", "title", ",", "client", "=", "None", ")", ":", "\n", "    ", "pageid", "=", "None", "\n", "\n", "title_html", "=", "title", ".", "strip", "(", ")", ".", "replace", "(", "\" \"", ",", "\"%20\"", ")", "\n", "url", "=", "\"https://en.wikipedia.org/w/api.php?action=query&titles={}&format=json\"", ".", "format", "(", "\n", "title_html", "\n", ")", "\n", "\n", "try", ":", "\n", "# Package the request, send the request and catch the response: r", "\n", "        ", "r", "=", "requests", ".", "get", "(", "url", ")", "\n", "\n", "# Decode the JSON data into a dictionary: json_data", "\n", "json_data", "=", "r", ".", "json", "(", ")", "\n", "\n", "if", "len", "(", "json_data", "[", "\"query\"", "]", "[", "\"pages\"", "]", ")", ">", "1", ":", "\n", "            ", "print", "(", "\"WARNING: more than one result returned from wikipedia api\"", ")", "\n", "\n", "", "for", "_", ",", "v", "in", "json_data", "[", "\"query\"", "]", "[", "\"pages\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "pageid", "=", "v", "[", "\"pageid\"", "]", "\n", "", "", "except", ":", "\n", "        ", "pass", "\n", "\n", "", "return", "pageid", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.scripts.create_BLINK_benchmark_data.extract_questions": [[53, 174], ["global_questions.extend", "open", "fin.readlines", "tqdm.tqdm", "[].append", "global_questions.extend", "line.split", "split[].strip", "left_context.append", "[].append", "len", "q[].append", "q[].append", "[].append", "line.split", "[].append", "len", "[].replace", "document_questions.append", "print", "sys.exit", "left_context.copy", "format", "create_BLINK_benchmark_data._get_pageid_from_api", "left_context.copy", "Wikipedia_URL.split"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.zeshel.create_BLINK_zeshel_data.LogFormatter.format", "home.repos.pwc.inspect_result.chenllliang_atp.scripts.create_BLINK_benchmark_data._get_pageid_from_api", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "extract_questions", "(", "filename", ")", ":", "\n", "\n", "# all the datapoints", "\n", "    ", "global_questions", "=", "[", "]", "\n", "\n", "# left context so far in the document", "\n", "left_context", "=", "[", "]", "\n", "\n", "# working datapoints for the document", "\n", "document_questions", "=", "[", "]", "\n", "\n", "# is the entity open", "\n", "open_entity", "=", "False", "\n", "\n", "# question id in the document", "\n", "question_i", "=", "0", "\n", "\n", "with", "open", "(", "filename", ")", "as", "fin", ":", "\n", "        ", "lines", "=", "fin", ".", "readlines", "(", ")", "\n", "\n", "for", "line", "in", "tqdm", "(", "lines", ")", ":", "\n", "\n", "            ", "if", "\"-DOCSTART-\"", "in", "line", ":", "\n", "# new document is starting", "\n", "\n", "                ", "doc_id", "=", "line", ".", "split", "(", "\"(\"", ")", "[", "-", "1", "]", "[", ":", "-", "2", "]", "\n", "\n", "# END DOCUMENT", "\n", "\n", "# check end of entity", "\n", "if", "open_entity", ":", "\n", "                    ", "document_questions", "[", "-", "1", "]", "[", "\"input\"", "]", ".", "append", "(", "END_ENT_TOKEN", ")", "\n", "open_entity", "=", "False", "\n", "\n", "", "\"\"\"\n                #DEBUG\n                for q in document_questions:\n                    pp.pprint(q)\n                    input(\"...\")\n                \"\"\"", "\n", "\n", "# add sentence_questions to global_questions", "\n", "global_questions", ".", "extend", "(", "document_questions", ")", "\n", "\n", "# reset", "\n", "left_context", "=", "[", "]", "\n", "document_questions", "=", "[", "]", "\n", "question_i", "=", "0", "\n", "\n", "", "else", ":", "\n", "                ", "split", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "token", "=", "split", "[", "0", "]", ".", "strip", "(", ")", "\n", "\n", "if", "len", "(", "split", ")", ">=", "5", ":", "\n", "                    ", "B_I", "=", "split", "[", "1", "]", "\n", "mention", "=", "split", "[", "2", "]", "\n", "# \u00a0YAGO2_entity = split[3]", "\n", "Wikipedia_URL", "=", "split", "[", "4", "]", "\n", "Wikipedia_ID", "=", "split", "[", "5", "]", "\n", "# Freee_base_id = split[6]", "\n", "\n", "if", "B_I", "==", "\"I\"", ":", "\n", "                        ", "pass", "\n", "\n", "", "elif", "B_I", "==", "\"B\"", ":", "\n", "\n", "                        ", "title", "=", "Wikipedia_URL", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", "\n", "\n", "if", "Wikipedia_ID", "==", "\"000\"", ":", "\n", "\n", "                            ", "if", "Wikipedia_URL", "in", "url2id_cache", ":", "\n", "                                ", "pageid", "=", "url2id_cache", "[", "Wikipedia_URL", "]", "\n", "", "else", ":", "\n", "\n", "                                ", "pageid", "=", "_get_pageid_from_api", "(", "title", ")", "\n", "url2id_cache", "[", "Wikipedia_URL", "]", "=", "pageid", "\n", "", "Wikipedia_ID", "=", "pageid", "\n", "\n", "", "q", "=", "{", "\n", "\"id\"", ":", "\"{}:{}\"", ".", "format", "(", "doc_id", ",", "question_i", ")", ",", "\n", "\"input\"", ":", "left_context", ".", "copy", "(", ")", "+", "[", "BEGIN_ENT_TOKEN", "]", ",", "\n", "\"mention\"", ":", "mention", ",", "\n", "\"Wikipedia_title\"", ":", "title", ",", "\n", "\"Wikipedia_URL\"", ":", "Wikipedia_URL", ",", "\n", "\"Wikipedia_ID\"", ":", "Wikipedia_ID", ",", "\n", "\"left_context\"", ":", "left_context", ".", "copy", "(", ")", ",", "\n", "\"right_context\"", ":", "[", "]", ",", "\n", "}", "\n", "document_questions", ".", "append", "(", "q", ")", "\n", "open_entity", "=", "True", "\n", "question_i", "+=", "1", "\n", "\n", "", "else", ":", "\n", "                        ", "print", "(", "\"Invalid B_I {}\"", ",", "format", "(", "B_I", ")", ")", "\n", "sys", ".", "exit", "(", "-", "1", ")", "\n", "\n", "# print(token,B_I,mention,Wikipedia_URL,Wikipedia_ID)", "\n", "", "", "else", ":", "\n", "                    ", "if", "open_entity", ":", "\n", "                        ", "document_questions", "[", "-", "1", "]", "[", "\"input\"", "]", ".", "append", "(", "END_ENT_TOKEN", ")", "\n", "open_entity", "=", "False", "\n", "\n", "", "", "left_context", ".", "append", "(", "token", ")", "\n", "for", "q", "in", "document_questions", ":", "\n", "                    ", "q", "[", "\"input\"", "]", ".", "append", "(", "token", ")", "\n", "\n", "", "for", "q", "in", "document_questions", "[", ":", "-", "1", "]", ":", "\n", "                    ", "q", "[", "\"right_context\"", "]", ".", "append", "(", "token", ")", "\n", "\n", "", "if", "len", "(", "document_questions", ")", ">", "0", "and", "not", "open_entity", ":", "\n", "                    ", "document_questions", "[", "-", "1", "]", "[", "\"right_context\"", "]", ".", "append", "(", "token", ")", "\n", "\n", "# FINAL SENTENCE", "\n", "", "", "", "", "if", "open_entity", ":", "\n", "        ", "document_questions", "[", "-", "1", "]", "[", "\"input\"", "]", ".", "append", "(", "END_ENT_TOKEN", ")", "\n", "open_entity", "=", "False", "\n", "\n", "# add sentence_questions to global_questions", "\n", "", "global_questions", ".", "extend", "(", "document_questions", ")", "\n", "\n", "return", "global_questions", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.scripts.create_BLINK_benchmark_data.store_questions": [[177, 190], ["os.path.exists", "open", "os.path.dirname", "os.makedirs", "json.dump", "fout.write", "os.path.dirname"], "function", ["None"], ["", "def", "store_questions", "(", "questions", ",", "OUT_FILENAME", ")", ":", "\n", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "dirname", "(", "OUT_FILENAME", ")", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "OUT_FILENAME", ")", ")", "\n", "", "except", "OSError", "as", "exc", ":", "# Guard against race condition", "\n", "            ", "if", "exc", ".", "errno", "!=", "errno", ".", "EEXIST", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "with", "open", "(", "OUT_FILENAME", ",", "\"w+\"", ")", "as", "fout", ":", "\n", "        ", "for", "q", "in", "questions", ":", "\n", "            ", "json", ".", "dump", "(", "q", ",", "fout", ")", "\n", "fout", ".", "write", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.scripts.create_BLINK_benchmark_data.convert_to_BLINK_format": [[192, 207], ["data.append"], "function", ["None"], ["", "", "", "def", "convert_to_BLINK_format", "(", "questions", ")", ":", "\n", "    ", "data", "=", "[", "]", "\n", "for", "q", "in", "questions", ":", "\n", "        ", "datapoint", "=", "{", "\n", "\"context_left\"", ":", "\" \"", ".", "join", "(", "q", "[", "\"left_context\"", "]", ")", ".", "strip", "(", ")", ",", "\n", "\"mention\"", ":", "q", "[", "\"mention\"", "]", ",", "\n", "\"context_right\"", ":", "\" \"", ".", "join", "(", "q", "[", "\"right_context\"", "]", ")", ".", "strip", "(", ")", ",", "\n", "\"query_id\"", ":", "q", "[", "\"id\"", "]", ",", "\n", "\"label_id\"", ":", "q", "[", "\"Wikipedia_ID\"", "]", ",", "\n", "\"Wikipedia_ID\"", ":", "q", "[", "\"Wikipedia_ID\"", "]", ",", "\n", "\"Wikipedia_URL\"", ":", "q", "[", "\"Wikipedia_URL\"", "]", ",", "\n", "\"Wikipedia_title\"", ":", "q", "[", "\"Wikipedia_title\"", "]", ",", "\n", "}", "\n", "data", ".", "append", "(", "datapoint", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._print_colorful_text": [[52, 79], ["sorted", "colorama.init", "print", "range", "tokenizer.decode", "enumerate", "tokenizer.decode", "len", "len", "termcolor.colored", "str", "int", "tokenizer.decode", "len", "tokenizer.decode", "tokenizer.decode", "int", "int", "len", "int", "int", "int"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], [")", "\n", "if", "idx", "<", "len", "(", "samples", ")", "-", "1", ":", "\n", "                ", "msg", "+=", "input_sentence", "[", "\n", "int", "(", "sample", "[", "\"end_pos\"", "]", ")", ":", "int", "(", "samples", "[", "idx", "+", "1", "]", "[", "\"start_pos\"", "]", ")", "\n", "]", "\n", "", "else", ":", "\n", "                ", "msg", "+=", "input_sentence", "[", "int", "(", "sample", "[", "\"end_pos\"", "]", ")", ":", "]", "\n", "", "", "", "else", ":", "\n", "        ", "msg", "=", "input_sentence", "\n", "print", "(", "\"Failed to identify entity from text:\"", ")", "\n", "", "print", "(", "\"\\n\"", "+", "str", "(", "msg", ")", "+", "\"\\n\"", ")", "\n", "\n", "\n", "", "def", "_print_colorful_prediction", "(", "\n", "idx", ",", "sample", ",", "e_id", ",", "e_title", ",", "e_text", ",", "e_url", ",", "show_url", "=", "False", "\n", ")", ":", "\n", "    ", "print", "(", "colored", "(", "sample", "[", "\"mention\"", "]", ",", "\"grey\"", ",", "HIGHLIGHTS", "[", "idx", "%", "len", "(", "HIGHLIGHTS", ")", "]", ")", ")", "\n", "to_print", "=", "\"id:{}\\ntitle:{}\\ntext:{}\\n\"", ".", "format", "(", "e_id", ",", "e_title", ",", "e_text", "[", ":", "256", "]", ")", "\n", "if", "show_url", ":", "\n", "        ", "to_print", "+=", "\"url:{}\\n\"", ".", "format", "(", "e_url", ")", "\n", "", "print", "(", "to_print", ")", "\n", "\n", "\n", "", "def", "_annotate", "(", "ner_model", ",", "input_sentences", ")", ":", "\n", "    ", "ner_output_data", "=", "ner_model", ".", "predict", "(", "input_sentences", ")", "\n", "sentences", "=", "ner_output_data", "[", "\"sentences\"", "]", "\n", "mentions", "=", "ner_output_data", "[", "\"mentions\"", "]", "\n", "samples", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._print_colorful_prediction": [[81, 91], ["sorted", "range", "print", "print", "print", "print", "print", "len", "termcolor.colored", "print", "str", "str", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["        ", "record", "=", "{", "}", "\n", "record", "[", "\"label\"", "]", "=", "\"unknown\"", "\n", "record", "[", "\"label_id\"", "]", "=", "-", "1", "\n", "# LOWERCASE EVERYTHING !", "\n", "record", "[", "\"context_left\"", "]", "=", "sentences", "[", "mention", "[", "\"sent_idx\"", "]", "]", "[", "\n", ":", "mention", "[", "\"start_pos\"", "]", "\n", "]", ".", "lower", "(", ")", "\n", "record", "[", "\"context_right\"", "]", "=", "sentences", "[", "mention", "[", "\"sent_idx\"", "]", "]", "[", "\n", "mention", "[", "\"end_pos\"", "]", ":", "\n", "]", ".", "lower", "(", ")", "\n", "record", "[", "\"mention\"", "]", "=", "mention", "[", "\"text\"", "]", ".", "lower", "(", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._load_candidates": [[93, 144], ["torch.load", "torch.load", "torch.load", "torch.load", "elq.index.faiss_indexer.DenseIVFFlatIndexer.deserialize_from", "os.path.exists", "json.dump", "json.dump", "json.dump", "json.load", "json.load", "json.load", "elq.index.faiss_indexer.DenseFlatIndexer", "open", "fin.readlines", "open", "open", "open", "logger.info", "open", "logger.info", "open", "logger.info", "open", "elq.index.faiss_indexer.DenseHNSWFlatIndexer", "json.loads", "elq.index.faiss_indexer.DenseIVFFlatIndexer", "ValueError", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseHNSWFlatIndexer.deserialize_from", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads"], ["record", "[", "\"end_pos\"", "]", "=", "int", "(", "mention", "[", "\"end_pos\"", "]", ")", "\n", "record", "[", "\"sent_idx\"", "]", "=", "mention", "[", "\"sent_idx\"", "]", "\n", "samples", ".", "append", "(", "record", ")", "\n", "", "return", "samples", "\n", "\n", "\n", "", "def", "_load_candidates", "(", "\n", "entity_catalogue", ",", "entity_encoding", ",", "faiss_index", "=", "None", ",", "index_path", "=", "None", ",", "logger", "=", "None", "\n", ")", ":", "\n", "# only load candidate encoding if not using faiss index", "\n", "    ", "if", "faiss_index", "is", "None", ":", "\n", "        ", "candidate_encoding", "=", "torch", ".", "load", "(", "entity_encoding", ")", "\n", "indexer", "=", "None", "\n", "", "else", ":", "\n", "        ", "if", "logger", ":", "\n", "            ", "logger", ".", "info", "(", "\"Using faiss index to retrieve entities.\"", ")", "\n", "", "candidate_encoding", "=", "None", "\n", "assert", "index_path", "is", "not", "None", ",", "\"Error! Empty indexer path.\"", "\n", "if", "faiss_index", "==", "\"flat\"", ":", "\n", "            ", "indexer", "=", "DenseFlatIndexer", "(", "1", ")", "\n", "", "elif", "faiss_index", "==", "\"hnsw\"", ":", "\n", "            ", "indexer", "=", "DenseHNSWFlatIndexer", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Error! Unsupported indexer type! Choose from flat,hnsw.\"", ")", "\n", "", "indexer", ".", "deserialize_from", "(", "index_path", ")", "\n", "\n", "# load all the 5903527 entities", "\n", "", "title2id", "=", "{", "}", "\n", "id2title", "=", "{", "}", "\n", "id2text", "=", "{", "}", "\n", "wikipedia_id2local_id", "=", "{", "}", "\n", "local_idx", "=", "0", "\n", "with", "open", "(", "entity_catalogue", ",", "\"r\"", ")", "as", "fin", ":", "\n", "        ", "lines", "=", "fin", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "entity", "=", "json", ".", "loads", "(", "line", ")", "\n", "\n", "if", "\"idx\"", "in", "entity", ":", "\n", "                ", "split", "=", "entity", "[", "\"idx\"", "]", ".", "split", "(", "\"curid=\"", ")", "\n", "if", "len", "(", "split", ")", ">", "1", ":", "\n", "                    ", "wikipedia_id", "=", "int", "(", "split", "[", "-", "1", "]", ".", "strip", "(", ")", ")", "\n", "", "else", ":", "\n", "                    ", "wikipedia_id", "=", "entity", "[", "\"idx\"", "]", ".", "strip", "(", ")", "\n", "\n", "", "assert", "wikipedia_id", "not", "in", "wikipedia_id2local_id", "\n", "wikipedia_id2local_id", "[", "wikipedia_id", "]", "=", "local_idx", "\n", "\n", "", "title2id", "[", "entity", "[", "\"title\"", "]", "]", "=", "local_idx", "\n", "id2title", "[", "local_idx", "]", "=", "entity", "[", "\"title\"", "]", "\n", "id2text", "[", "local_idx", "]", "=", "entity", "[", "\"text\"", "]", "\n", "local_idx", "+=", "1", "\n", "", "", "return", "(", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._get_test_samples": [[147, 189], ["logger.info", "open", "fin.readlines", "enumerate", "json.loads", "test_samples.append"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads"], ["id2title", ",", "\n", "id2text", ",", "\n", "wikipedia_id2local_id", ",", "\n", "indexer", ",", "\n", ")", "\n", "\n", "\n", "", "def", "__map_test_entities", "(", "test_entities_path", ",", "title2id", ",", "logger", ")", ":", "\n", "# load the 732859 tac_kbp_ref_know_base entities", "\n", "    ", "kb2id", "=", "{", "}", "\n", "missing_pages", "=", "0", "\n", "n", "=", "0", "\n", "with", "open", "(", "test_entities_path", ",", "\"r\"", ")", "as", "fin", ":", "\n", "        ", "lines", "=", "fin", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "entity", "=", "json", ".", "loads", "(", "line", ")", "\n", "if", "entity", "[", "\"title\"", "]", "not", "in", "title2id", ":", "\n", "                ", "missing_pages", "+=", "1", "\n", "", "else", ":", "\n", "                ", "kb2id", "[", "entity", "[", "\"entity_id\"", "]", "]", "=", "title2id", "[", "entity", "[", "\"title\"", "]", "]", "\n", "", "n", "+=", "1", "\n", "", "", "if", "logger", ":", "\n", "        ", "logger", ".", "info", "(", "\"missing {}/{} pages\"", ".", "format", "(", "missing_pages", ",", "n", ")", ")", "\n", "", "return", "kb2id", "\n", "\n", "\n", "", "def", "__load_test", "(", "test_filename", ",", "kb2id", ",", "wikipedia_id2local_id", ",", "logger", ")", ":", "\n", "    ", "test_samples", "=", "[", "]", "\n", "with", "open", "(", "test_filename", ",", "\"r\"", ")", "as", "fin", ":", "\n", "        ", "lines", "=", "fin", ".", "readlines", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "record", "=", "json", ".", "loads", "(", "line", ")", "\n", "record", "[", "\"label\"", "]", "=", "str", "(", "record", "[", "\"label_id\"", "]", ")", "\n", "\n", "# for tac kbp we should use a separate knowledge source to get the entity id (label_id)", "\n", "if", "kb2id", "and", "len", "(", "kb2id", ")", ">", "0", ":", "\n", "                ", "if", "record", "[", "\"label\"", "]", "in", "kb2id", ":", "\n", "                    ", "record", "[", "\"label_id\"", "]", "=", "kb2id", "[", "record", "[", "\"label\"", "]", "]", "\n", "", "else", ":", "\n", "                    ", "continue", "\n", "\n", "# check that each entity id (label_id) is in the entity collection", "\n", "", "", "elif", "wikipedia_id2local_id", "and", "len", "(", "wikipedia_id2local_id", ")", ">", "0", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._process_biencoder_dataloader": [[191, 246], ["torch.utils.data.TensorDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "elq.biencoder.data_process.process_mention_data", "max", "samples_text_tuple.append", "torch.tensor", "torch.tensor", "len", "biencoder_params.get", "tokenizer.encode", "range", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.data_process.process_mention_data", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode"], ["                    ", "key", "=", "int", "(", "record", "[", "\"label\"", "]", ".", "strip", "(", ")", ")", "\n", "if", "key", "in", "wikipedia_id2local_id", ":", "\n", "                        ", "record", "[", "\"label_id\"", "]", "=", "wikipedia_id2local_id", "[", "key", "]", "\n", "", "else", ":", "\n", "                        ", "continue", "\n", "", "", "except", ":", "\n", "                    ", "continue", "\n", "\n", "# LOWERCASE EVERYTHING !", "\n", "", "", "record", "[", "\"context_left\"", "]", "=", "record", "[", "\"context_left\"", "]", ".", "lower", "(", ")", "\n", "record", "[", "\"context_right\"", "]", "=", "record", "[", "\"context_right\"", "]", ".", "lower", "(", ")", "\n", "record", "[", "\"mention\"", "]", "=", "record", "[", "\"mention\"", "]", ".", "lower", "(", ")", "\n", "test_samples", ".", "append", "(", "record", ")", "\n", "\n", "", "", "if", "logger", ":", "\n", "        ", "logger", ".", "info", "(", "\"{}/{} samples considered\"", ".", "format", "(", "len", "(", "test_samples", ")", ",", "len", "(", "lines", ")", ")", ")", "\n", "", "return", "test_samples", "\n", "\n", "\n", "", "def", "_get_test_samples", "(", "\n", "test_filename", ",", "test_entities_path", ",", "title2id", ",", "wikipedia_id2local_id", ",", "logger", "\n", ")", ":", "\n", "    ", "kb2id", "=", "None", "\n", "if", "test_entities_path", ":", "\n", "        ", "kb2id", "=", "__map_test_entities", "(", "test_entities_path", ",", "title2id", ",", "logger", ")", "\n", "", "test_samples", "=", "__load_test", "(", "test_filename", ",", "kb2id", ",", "wikipedia_id2local_id", ",", "logger", ")", "\n", "return", "test_samples", "\n", "\n", "\n", "", "def", "_process_biencoder_dataloader", "(", "samples", ",", "tokenizer", ",", "biencoder_params", ")", ":", "\n", "    ", "_", ",", "tensor_data", "=", "process_mention_data", "(", "\n", "samples", ",", "\n", "tokenizer", ",", "\n", "biencoder_params", "[", "\"max_context_length\"", "]", ",", "\n", "biencoder_params", "[", "\"max_cand_length\"", "]", ",", "\n", "silent", "=", "True", ",", "\n", "logger", "=", "None", ",", "\n", "debug", "=", "biencoder_params", "[", "\"debug\"", "]", ",", "\n", ")", "\n", "sampler", "=", "SequentialSampler", "(", "tensor_data", ")", "\n", "dataloader", "=", "DataLoader", "(", "\n", "tensor_data", ",", "sampler", "=", "sampler", ",", "batch_size", "=", "biencoder_params", "[", "\"eval_batch_size\"", "]", "\n", ")", "\n", "return", "dataloader", "\n", "\n", "\n", "", "def", "_run_biencoder", "(", "biencoder", ",", "dataloader", ",", "candidate_encoding", ",", "top_k", "=", "100", ",", "indexer", "=", "None", ")", ":", "\n", "    ", "biencoder", ".", "model", ".", "eval", "(", ")", "\n", "labels", "=", "[", "]", "\n", "nns", "=", "[", "]", "\n", "all_scores", "=", "[", "]", "\n", "for", "batch", "in", "tqdm", "(", "dataloader", ")", ":", "\n", "        ", "context_input", ",", "_", ",", "label_ids", "=", "batch", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "indexer", "is", "not", "None", ":", "\n", "                ", "context_encoding", "=", "biencoder", ".", "encode_context", "(", "context_input", ")", ".", "numpy", "(", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._run_biencoder": [[248, 376], ["biencoder.model.eval", "hasattr", "enumerate", "tqdm.tqdm", "batch[].to", "torch.no_grad", "torch.no_grad", "biencoder.encode_context", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "indexer.search_knn", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.log_softmax", "torch.log_softmax", "torch.sigmoid().log", "torch.sigmoid().log", "len", "context_inputs.append", "nns.append", "dists.append", "pred_mention_bounds.append", "mention_scores.append", "cand_scores.append", "biencoder.score_candidate", "cand_logits.topk", "embedding_ctxt.cpu().numpy", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "[].data.cpu().numpy", "[].data.cpu().numpy", "[].data.cpu().numpy", "[].data.cpu().numpy", "[].data.cpu().numpy", "[].data.cpu().numpy", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "chosen_mention_logits.size", "chosen_mention_logits.size", "torch.tensor().to.size", "chosen_mention_logits.size", "chosen_mention_logits.size", "all_top_cand_indices.gather.size", "torch.sigmoid", "torch.sigmoid", "candidate_encoding.to", "int", "range", "embedding_ctxt.cpu", "chosen_mention_logits.unsqueeze", "[].data.cpu", "[].data.cpu", "[].data.cpu", "[].data.cpu", "[].data.cpu", "[].data.cpu", "len", "torch.cat().topk", "torch.cat().topk", "torch.cat", "torch.cat", "torch.cat.gather", "len", "embedding_ctxt.mm().topk", "top_cand_logits_list.append", "top_cand_indices_list.append", "len", "pdb.set_trace", "int", "torch.cat", "torch.cat", "embedding_ctxt.mm", "candidate_encoding[].to().t().contiguous", "candidate_encoding[].to().t", "candidate_encoding[].to"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.BiEncoderRanker.encode_context", "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseHNSWFlatIndexer.search_knn", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.score_candidate", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["scores", ",", "indicies", "=", "indexer", ".", "search_knn", "(", "context_encoding", ",", "top_k", ")", "\n", "", "else", ":", "\n", "                ", "scores", "=", "biencoder", ".", "score_candidate", "(", "\n", "context_input", ",", "None", ",", "cand_encs", "=", "candidate_encoding", "# .to(device)", "\n", ")", "\n", "scores", ",", "indicies", "=", "scores", ".", "topk", "(", "top_k", ")", "\n", "scores", "=", "scores", ".", "data", ".", "numpy", "(", ")", "\n", "indicies", "=", "indicies", ".", "data", ".", "numpy", "(", ")", "\n", "\n", "", "", "labels", ".", "extend", "(", "label_ids", ".", "data", ".", "numpy", "(", ")", ")", "\n", "nns", ".", "extend", "(", "indicies", ")", "\n", "all_scores", ".", "extend", "(", "scores", ")", "\n", "", "return", "labels", ",", "nns", ",", "all_scores", "\n", "\n", "\n", "", "def", "_process_crossencoder_dataloader", "(", "context_input", ",", "label_input", ",", "crossencoder_params", ")", ":", "\n", "    ", "tensor_data", "=", "TensorDataset", "(", "context_input", ",", "label_input", ")", "\n", "sampler", "=", "SequentialSampler", "(", "tensor_data", ")", "\n", "dataloader", "=", "DataLoader", "(", "\n", "tensor_data", ",", "sampler", "=", "sampler", ",", "batch_size", "=", "crossencoder_params", "[", "\"eval_batch_size\"", "]", "\n", ")", "\n", "return", "dataloader", "\n", "\n", "\n", "", "def", "_run_crossencoder", "(", "crossencoder", ",", "dataloader", ",", "logger", ",", "context_len", ",", "device", "=", "\"cuda\"", ")", ":", "\n", "    ", "crossencoder", ".", "model", ".", "eval", "(", ")", "\n", "accuracy", "=", "0.0", "\n", "crossencoder", ".", "to", "(", "device", ")", "\n", "\n", "res", "=", "evaluate", "(", "crossencoder", ",", "dataloader", ",", "device", ",", "logger", ",", "context_len", ",", "zeshel", "=", "False", ",", "silent", "=", "False", ")", "\n", "accuracy", "=", "res", "[", "\"normalized_accuracy\"", "]", "\n", "logits", "=", "res", "[", "\"logits\"", "]", "\n", "\n", "if", "accuracy", ">", "-", "1", ":", "\n", "        ", "predictions", "=", "np", ".", "argsort", "(", "logits", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "predictions", "=", "[", "]", "\n", "\n", "", "return", "accuracy", ",", "predictions", ",", "logits", "\n", "\n", "\n", "", "def", "load_models", "(", "args", ",", "logger", "=", "None", ")", ":", "\n", "\n", "# load biencoder model", "\n", "    ", "if", "logger", ":", "\n", "        ", "logger", ".", "info", "(", "\"loading biencoder model\"", ")", "\n", "", "with", "open", "(", "args", ".", "biencoder_config", ")", "as", "json_file", ":", "\n", "        ", "biencoder_params", "=", "json", ".", "load", "(", "json_file", ")", "\n", "biencoder_params", "[", "\"path_to_model\"", "]", "=", "args", ".", "biencoder_model", "\n", "", "biencoder", "=", "load_biencoder", "(", "biencoder_params", ")", "\n", "\n", "crossencoder", "=", "None", "\n", "crossencoder_params", "=", "None", "\n", "if", "not", "args", ".", "fast", ":", "\n", "# load crossencoder model", "\n", "        ", "if", "logger", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading crossencoder model\"", ")", "\n", "", "with", "open", "(", "args", ".", "crossencoder_config", ")", "as", "json_file", ":", "\n", "            ", "crossencoder_params", "=", "json", ".", "load", "(", "json_file", ")", "\n", "crossencoder_params", "[", "\"path_to_model\"", "]", "=", "args", ".", "crossencoder_model", "\n", "", "crossencoder", "=", "load_crossencoder", "(", "crossencoder_params", ")", "\n", "\n", "# load candidate entities", "\n", "", "if", "logger", ":", "\n", "        ", "logger", ".", "info", "(", "\"loading candidate entities\"", ")", "\n", "", "(", "\n", "candidate_encoding", ",", "\n", "title2id", ",", "\n", "id2title", ",", "\n", "id2text", ",", "\n", "wikipedia_id2local_id", ",", "\n", "faiss_indexer", ",", "\n", ")", "=", "_load_candidates", "(", "\n", "args", ".", "entity_catalogue", ",", "\n", "args", ".", "entity_encoding", ",", "\n", "faiss_index", "=", "getattr", "(", "args", ",", "'faiss_index'", ",", "None", ")", ",", "\n", "index_path", "=", "getattr", "(", "args", ",", "'index_path'", ",", "None", ")", ",", "\n", "logger", "=", "logger", ",", "\n", ")", "\n", "\n", "return", "(", "\n", "biencoder", ",", "\n", "biencoder_params", ",", "\n", "crossencoder", ",", "\n", "crossencoder_params", ",", "\n", "candidate_encoding", ",", "\n", "title2id", ",", "\n", "id2title", ",", "\n", "id2text", ",", "\n", "wikipedia_id2local_id", ",", "\n", "faiss_indexer", ",", "\n", ")", "\n", "\n", "\n", "", "def", "run", "(", "\n", "args", ",", "\n", "logger", ",", "\n", "biencoder", ",", "\n", "biencoder_params", ",", "\n", "crossencoder", ",", "\n", "crossencoder_params", ",", "\n", "candidate_encoding", ",", "\n", "title2id", ",", "\n", "id2title", ",", "\n", "id2text", ",", "\n", "wikipedia_id2local_id", ",", "\n", "faiss_indexer", "=", "None", ",", "\n", "test_data", "=", "None", ",", "\n", ")", ":", "\n", "\n", "    ", "if", "not", "test_data", "and", "not", "args", ".", "test_mentions", "and", "not", "args", ".", "interactive", ":", "\n", "        ", "msg", "=", "(", "\n", "\"ERROR: either you start BLINK with the \"", "\n", "\"interactive option (-i) or you pass in input test mentions (--test_mentions)\"", "\n", "\"and test entitied (--test_entities)\"", "\n", ")", "\n", "raise", "ValueError", "(", "msg", ")", "\n", "\n", "", "id2url", "=", "{", "\n", "v", ":", "\"https://en.wikipedia.org/wiki?curid=%s\"", "%", "k", "\n", "for", "k", ",", "v", "in", "wikipedia_id2local_id", ".", "items", "(", ")", "\n", "}", "\n", "\n", "stopping_condition", "=", "False", "\n", "while", "not", "stopping_condition", ":", "\n", "\n", "        ", "samples", "=", "None", "\n", "\n", "if", "args", ".", "interactive", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense.get_predictions": [[378, 568], ["enumerate", "getattr", "os.path.join", "open", "open", "range", "open.close", "open.close", "os.path.join", "len", "len", "[].tolist", "torch.tensor().sort", "torch.tensor().sort", "numpy.zeros", "enumerate", "all_entity_preds.append", "len", "len", "len", "e_mention_bounds_pruned.append", "all_pred_entities_pruned.append", "chosen_distances_pruned.append", "[].tolist", "[].tolist", "range", "elq.vcg_utils.measures.entity_linking_tp_with_overlap", "len", "len", "elq.vcg_utils.measures.entity_linking_tp_with_overlap", "len", "entity_results.update", "entity_results.update", "open.write", "torch.tensor", "torch.tensor", "float", "str", "range", "len", "len", "len", "open.write", "mention_masked_utterance[].sum", "int", "int", "len", "str", "range", "str", "int", "int", "range", "str", "range", "json.dumps", "len", "len", "len", "len", "len", "json.dumps", "tokenizer.decode", "tokenizer.decode", "tokenizer.decode", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.vcg_utils.measures.entity_linking_tp_with_overlap", "home.repos.pwc.inspect_result.chenllliang_atp.vcg_utils.measures.entity_linking_tp_with_overlap", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update"], ["\n", "# biencoder_params[\"eval_batch_size\"] = 1", "\n", "\n", "# Load NER model", "\n", "ner_model", "=", "NER", ".", "get_model", "(", ")", "\n", "\n", "# Interactive", "\n", "text", "=", "input", "(", "\"insert text:\"", ")", "\n", "\n", "# Identify mentions", "\n", "samples", "=", "_annotate", "(", "ner_model", ",", "[", "text", "]", ")", "\n", "\n", "_print_colorful_text", "(", "text", ",", "samples", ")", "\n", "\n", "", "else", ":", "\n", "            ", "if", "logger", ":", "\n", "                ", "logger", ".", "info", "(", "\"test dataset mode\"", ")", "\n", "\n", "", "if", "test_data", ":", "\n", "                ", "samples", "=", "test_data", "\n", "", "else", ":", "\n", "# Load test mentions", "\n", "                ", "samples", "=", "_get_test_samples", "(", "\n", "args", ".", "test_mentions", ",", "\n", "args", ".", "test_entities", ",", "\n", "title2id", ",", "\n", "wikipedia_id2local_id", ",", "\n", "logger", ",", "\n", ")", "\n", "\n", "", "stopping_condition", "=", "True", "\n", "\n", "# don't look at labels", "\n", "", "keep_all", "=", "(", "\n", "args", ".", "interactive", "\n", "or", "samples", "[", "0", "]", "[", "\"label\"", "]", "==", "\"unknown\"", "\n", "or", "samples", "[", "0", "]", "[", "\"label_id\"", "]", "<", "0", "\n", ")", "\n", "\n", "# prepare the data for biencoder", "\n", "if", "logger", ":", "\n", "            ", "logger", ".", "info", "(", "\"preparing data for biencoder\"", ")", "\n", "", "dataloader", "=", "_process_biencoder_dataloader", "(", "\n", "samples", ",", "biencoder", ".", "tokenizer", ",", "biencoder_params", "\n", ")", "\n", "\n", "# run biencoder", "\n", "if", "logger", ":", "\n", "            ", "logger", ".", "info", "(", "\"run biencoder\"", ")", "\n", "", "top_k", "=", "args", ".", "top_k", "\n", "labels", ",", "nns", ",", "scores", "=", "_run_biencoder", "(", "\n", "biencoder", ",", "dataloader", ",", "candidate_encoding", ",", "top_k", ",", "faiss_indexer", "\n", ")", "\n", "\n", "if", "args", ".", "interactive", ":", "\n", "\n", "            ", "print", "(", "\"\\nfast (biencoder) predictions:\"", ")", "\n", "\n", "_print_colorful_text", "(", "text", ",", "samples", ")", "\n", "\n", "# print biencoder prediction", "\n", "idx", "=", "0", "\n", "for", "entity_list", ",", "sample", "in", "zip", "(", "nns", ",", "samples", ")", ":", "\n", "                ", "e_id", "=", "entity_list", "[", "0", "]", "\n", "e_title", "=", "id2title", "[", "e_id", "]", "\n", "e_text", "=", "id2text", "[", "e_id", "]", "\n", "e_url", "=", "id2url", "[", "e_id", "]", "\n", "_print_colorful_prediction", "(", "\n", "idx", ",", "sample", ",", "e_id", ",", "e_title", ",", "e_text", ",", "e_url", ",", "args", ".", "show_url", "\n", ")", "\n", "idx", "+=", "1", "\n", "", "print", "(", ")", "\n", "\n", "if", "args", ".", "fast", ":", "\n", "# use only biencoder", "\n", "                ", "continue", "\n", "\n", "", "", "else", ":", "\n", "\n", "            ", "biencoder_accuracy", "=", "-", "1", "\n", "recall_at", "=", "-", "1", "\n", "if", "not", "keep_all", ":", "\n", "# get recall values", "\n", "                ", "top_k", "=", "args", ".", "top_k", "\n", "x", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "top_k", ")", ":", "\n", "                    ", "temp_y", "=", "0.0", "\n", "for", "label", ",", "top", "in", "zip", "(", "labels", ",", "nns", ")", ":", "\n", "                        ", "if", "label", "in", "top", "[", ":", "i", "]", ":", "\n", "                            ", "temp_y", "+=", "1", "\n", "", "", "if", "len", "(", "labels", ")", ">", "0", ":", "\n", "                        ", "temp_y", "/=", "len", "(", "labels", ")", "\n", "", "x", ".", "append", "(", "i", ")", "\n", "y", ".", "append", "(", "temp_y", ")", "\n", "# plt.plot(x, y)", "\n", "", "biencoder_accuracy", "=", "y", "[", "0", "]", "\n", "recall_at", "=", "y", "[", "-", "1", "]", "\n", "print", "(", "\"biencoder accuracy: %.4f\"", "%", "biencoder_accuracy", ")", "\n", "print", "(", "\"biencoder recall@%d: %.4f\"", "%", "(", "top_k", ",", "y", "[", "-", "1", "]", ")", ")", "\n", "\n", "", "if", "args", ".", "fast", ":", "\n", "\n", "                ", "predictions", "=", "[", "]", "\n", "for", "entity_list", "in", "nns", ":", "\n", "                    ", "sample_prediction", "=", "[", "]", "\n", "for", "e_id", "in", "entity_list", ":", "\n", "                        ", "e_title", "=", "id2title", "[", "e_id", "]", "\n", "sample_prediction", ".", "append", "(", "e_title", ")", "\n", "", "predictions", ".", "append", "(", "sample_prediction", ")", "\n", "\n", "# use only biencoder", "\n", "", "return", "(", "\n", "biencoder_accuracy", ",", "\n", "recall_at", ",", "\n", "-", "1", ",", "\n", "-", "1", ",", "\n", "len", "(", "samples", ")", ",", "\n", "predictions", ",", "\n", "scores", ",", "\n", ")", "\n", "\n", "# prepare crossencoder data", "\n", "", "", "context_input", ",", "candidate_input", ",", "label_input", "=", "prepare_crossencoder_data", "(", "\n", "crossencoder", ".", "tokenizer", ",", "samples", ",", "labels", ",", "nns", ",", "id2title", ",", "id2text", ",", "keep_all", ",", "\n", ")", "\n", "\n", "context_input", "=", "modify", "(", "\n", "context_input", ",", "candidate_input", ",", "crossencoder_params", "[", "\"max_seq_length\"", "]", "\n", ")", "\n", "\n", "dataloader", "=", "_process_crossencoder_dataloader", "(", "\n", "context_input", ",", "label_input", ",", "crossencoder_params", "\n", ")", "\n", "\n", "# run crossencoder and get accuracy", "\n", "accuracy", ",", "index_array", ",", "unsorted_scores", "=", "_run_crossencoder", "(", "\n", "crossencoder", ",", "\n", "dataloader", ",", "\n", "logger", ",", "\n", "context_len", "=", "biencoder_params", "[", "\"max_context_length\"", "]", ",", "\n", ")", "\n", "\n", "if", "args", ".", "interactive", ":", "\n", "\n", "            ", "print", "(", "\"\\naccurate (crossencoder) predictions:\"", ")", "\n", "\n", "_print_colorful_text", "(", "text", ",", "samples", ")", "\n", "\n", "# print crossencoder prediction", "\n", "idx", "=", "0", "\n", "for", "entity_list", ",", "index_list", ",", "sample", "in", "zip", "(", "nns", ",", "index_array", ",", "samples", ")", ":", "\n", "                ", "e_id", "=", "entity_list", "[", "index_list", "[", "-", "1", "]", "]", "\n", "e_title", "=", "id2title", "[", "e_id", "]", "\n", "e_text", "=", "id2text", "[", "e_id", "]", "\n", "e_url", "=", "id2url", "[", "e_id", "]", "\n", "_print_colorful_prediction", "(", "\n", "idx", ",", "sample", ",", "e_id", ",", "e_title", ",", "e_text", ",", "e_url", ",", "args", ".", "show_url", "\n", ")", "\n", "idx", "+=", "1", "\n", "", "print", "(", ")", "\n", "", "else", ":", "\n", "\n", "            ", "scores", "=", "[", "]", "\n", "predictions", "=", "[", "]", "\n", "for", "entity_list", ",", "index_list", ",", "scores_list", "in", "zip", "(", "\n", "nns", ",", "index_array", ",", "unsorted_scores", "\n", ")", ":", "\n", "\n", "                ", "index_list", "=", "index_list", ".", "tolist", "(", ")", "\n", "\n", "# descending order", "\n", "index_list", ".", "reverse", "(", ")", "\n", "\n", "sample_prediction", "=", "[", "]", "\n", "sample_scores", "=", "[", "]", "\n", "for", "index", "in", "index_list", ":", "\n", "                    ", "e_id", "=", "entity_list", "[", "index", "]", "\n", "e_title", "=", "id2title", "[", "e_id", "]", "\n", "sample_prediction", ".", "append", "(", "e_title", ")", "\n", "sample_scores", ".", "append", "(", "scores_list", "[", "index", "]", ")", "\n", "", "predictions", ".", "append", "(", "sample_prediction", ")", "\n", "scores", ".", "append", "(", "sample_scores", ")", "\n", "\n", "", "crossencoder_normalized_accuracy", "=", "-", "1", "\n", "overall_unormalized_accuracy", "=", "-", "1", "\n", "if", "not", "keep_all", ":", "\n", "                ", "crossencoder_normalized_accuracy", "=", "accuracy", "\n", "print", "(", "\n", "\"crossencoder normalized accuracy: %.4f\"", "\n", "%", "crossencoder_normalized_accuracy", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._save_biencoder_outs": [[571, 579], ["numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "wf.write", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save"], ["if", "len", "(", "samples", ")", ">", "0", ":", "\n", "                    ", "overall_unormalized_accuracy", "=", "(", "\n", "crossencoder_normalized_accuracy", "*", "len", "(", "label_input", ")", "/", "len", "(", "samples", ")", "\n", ")", "\n", "", "print", "(", "\n", "\"overall unnormalized accuracy: %.4f\"", "%", "overall_unormalized_accuracy", "\n", ")", "\n", "", "return", "(", "\n", "biencoder_accuracy", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._load_biencoder_outs": [[581, 589], ["numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "float", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open().read", "open", "os.path.join"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["crossencoder_normalized_accuracy", ",", "\n", "overall_unormalized_accuracy", ",", "\n", "len", "(", "samples", ")", ",", "\n", "predictions", ",", "\n", "scores", ",", "\n", ")", "\n", "\n", "\n", "", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense.display_metrics": [[591, 603], ["print", "print", "print", "float", "float", "float", "float"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["\n", "parser", ".", "add_argument", "(", "\n", "\"--interactive\"", ",", "\"-i\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Interactive mode.\"", "\n", ")", "\n", "\n", "# test_data", "\n", "parser", ".", "add_argument", "(", "\n", "\"--test_mentions\"", ",", "dest", "=", "\"test_mentions\"", ",", "type", "=", "str", ",", "help", "=", "\"Test Dataset.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--test_entities\"", ",", "dest", "=", "\"test_entities\"", ",", "type", "=", "str", ",", "help", "=", "\"Test Entities.\"", "\n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense.load_models": [[605, 657], ["getattr", "elq.biencoder.biencoder.load_biencoder", "main_dense._load_candidates", "logger.info", "getattr", "logger.info", "open", "json.load", "getattr", "torch.cuda.is_available", "torch.cuda.is_available", "torch.nn.DataParallel", "torch.nn.DataParallel", "open", "type", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "json.loads", "type"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.biencoder.load_biencoder", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._load_candidates", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads"], ["parser", ".", "add_argument", "(", "\n", "\"--biencoder_model\"", ",", "\n", "dest", "=", "\"biencoder_model\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"models/biencoder_wiki_large.bin\"", ",", "\n", "help", "=", "\"Path to the biencoder model.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--biencoder_config\"", ",", "\n", "dest", "=", "\"biencoder_config\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"models/biencoder_wiki_large.json\"", ",", "\n", "help", "=", "\"Path to the biencoder configuration.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--entity_catalogue\"", ",", "\n", "dest", "=", "\"entity_catalogue\"", ",", "\n", "type", "=", "str", ",", "\n", "# default=\"models/tac_entity.jsonl\",  # TAC-KBP", "\n", "default", "=", "\"models/entity.jsonl\"", ",", "# ALL WIKIPEDIA!", "\n", "help", "=", "\"Path to the entity catalogue.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--entity_encoding\"", ",", "\n", "dest", "=", "\"entity_encoding\"", ",", "\n", "type", "=", "str", ",", "\n", "# default=\"models/tac_candidate_encode_large.t7\",  # TAC-KBP", "\n", "default", "=", "\"models/all_entities_large.t7\"", ",", "# ALL WIKIPEDIA!", "\n", "help", "=", "\"Path to the entity catalogue.\"", ",", "\n", ")", "\n", "\n", "# crossencoder", "\n", "parser", ".", "add_argument", "(", "\n", "\"--crossencoder_model\"", ",", "\n", "dest", "=", "\"crossencoder_model\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"models/crossencoder_wiki_large.bin\"", ",", "\n", "help", "=", "\"Path to the crossencoder model.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--crossencoder_config\"", ",", "\n", "dest", "=", "\"crossencoder_config\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"models/crossencoder_wiki_large.json\"", ",", "\n", "help", "=", "\"Path to the crossencoder configuration.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--top_k\"", ",", "\n", "dest", "=", "\"top_k\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "10", ",", "\n", "help", "=", "\"Number of candidates retrieved by biencoder.\"", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense.run": [[660, 809], ["float", "ValueError", "os.makedirs", "print", "float", "main_dense._process_biencoder_dataloader", "main_dense.get_predictions", "print", "getattr", "getattr", "getattr", "os.path.exists", "input", "main_dense._process_biencoder_dataloader", "main_dense._run_biencoder", "main_dense._get_test_samples", "logger.info", "time.time", "main_dense._run_biencoder", "time.time", "getattr", "main_dense._load_biencoder_outs", "len", "len", "len", "len", "len", "len", "print", "main_dense.display_metrics", "print", "main_dense.display_metrics", "print", "print", "main_dense.display_metrics", "print", "main_dense.display_metrics", "print", "print", "print", "logger.info", "main_dense._print_colorful_text", "main_dense._print_colorful_prediction", "input", "getattr", "os.path.exists", "logger.info", "logger.info", "main_dense._save_biencoder_outs", "main_dense.get_predictions", "input", "print", "os.path.join", "input", "float", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._process_biencoder_dataloader", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense.get_predictions", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._process_biencoder_dataloader", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._run_biencoder", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._get_test_samples", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._run_biencoder", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._load_biencoder_outs", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense.display_metrics", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense.display_metrics", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense.display_metrics", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense.display_metrics", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._print_colorful_text", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._print_colorful_prediction", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense._save_biencoder_outs", "home.repos.pwc.inspect_result.chenllliang_atp.elq.main_dense.get_predictions", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["# output folder", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_path\"", ",", "\n", "dest", "=", "\"output_path\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"output\"", ",", "\n", "help", "=", "\"Path to the output.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fast\"", ",", "dest", "=", "\"fast\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"only biencoder mode\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--show_url\"", ",", "\n", "dest", "=", "\"show_url\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"whether to show entity url in interactive mode\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--faiss_index\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"whether to use faiss index\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--index_path\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"path to load indexer\"", ",", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "logger", "=", "utils", ".", "get_logger", "(", "args", ".", "output_path", ")", "\n", "\n", "models", "=", "load_models", "(", "args", ",", "logger", ")", "\n", "run", "(", "args", ",", "logger", ",", "*", "models", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.elq.build_faiss_index.main": [[19, 42], ["logger.info", "torch.load", "torch.load.size", "logger.info", "elq.index.faiss_indexer.DenseFlatIndexer.index_data", "logger.info", "params.get", "logger.info", "elq.index.faiss_indexer.DenseHNSWFlatIndexer", "torch.load.numpy", "elq.index.faiss_indexer.DenseFlatIndexer.serialize", "logger.info", "elq.index.faiss_indexer.DenseIVFFlatIndexer", "logger.info", "elq.index.faiss_indexer.DenseFlatIndexer"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseHNSWFlatIndexer.index_data", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanSerializer.serialize"], ["def", "main", "(", "params", ")", ":", "\n", "    ", "output_path", "=", "params", "[", "\"output_path\"", "]", "\n", "output_dir", ",", "_", "=", "os", ".", "path", ".", "split", "(", "output_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "logger", "=", "utils", ".", "get_logger", "(", "output_dir", ")", "\n", "\n", "logger", ".", "info", "(", "\"Loading candidate encoding from path: %s\"", "%", "params", "[", "\"candidate_encoding\"", "]", ")", "\n", "candidate_encoding", "=", "torch", ".", "load", "(", "params", "[", "\"candidate_encoding\"", "]", ")", "\n", "vector_size", "=", "candidate_encoding", ".", "size", "(", "1", ")", "\n", "index_buffer", "=", "params", "[", "\"index_buffer\"", "]", "\n", "if", "params", "[", "\"hnsw\"", "]", ":", "\n", "        ", "logger", ".", "info", "(", "\"Using HNSW index in FAISS\"", ")", "\n", "index", "=", "DenseHNSWFlatIndexer", "(", "vector_size", ",", "index_buffer", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Using Flat index in FAISS\"", ")", "\n", "index", "=", "DenseFlatIndexer", "(", "vector_size", ",", "index_buffer", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Building index.\"", ")", "\n", "index", ".", "index_data", "(", "candidate_encoding", ".", "numpy", "(", ")", ")", "\n", "logger", ".", "info", "(", "\"Done indexing data.\"", ")", "\n", "\n", "if", "params", ".", "get", "(", "\"save_index\"", ",", "None", ")", ":", "\n", "        ", "index", ".", "serialize", "(", "output_path", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseIndexer.__init__": [[23, 27], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "buffer_size", ":", "int", "=", "50000", ")", ":", "\n", "        ", "self", ".", "buffer_size", "=", "buffer_size", "\n", "self", ".", "index_id_to_db_id", "=", "[", "]", "\n", "self", ".", "index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseIndexer.index_data": [[28, 30], ["None"], "methods", ["None"], ["", "def", "index_data", "(", "self", ",", "data", ":", "np", ".", "array", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseIndexer.search_knn": [[31, 33], ["None"], "methods", ["None"], ["", "def", "search_knn", "(", "self", ",", "query_vectors", ":", "np", ".", "array", ",", "top_docs", ":", "int", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseIndexer.serialize": [[34, 37], ["logger.info", "faiss.write_index"], "methods", ["None"], ["", "def", "serialize", "(", "self", ",", "index_file", ":", "str", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Serializing index to %s\"", ",", "index_file", ")", "\n", "faiss", ".", "write_index", "(", "self", ".", "index", ",", "index_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseIndexer.deserialize_from": [[38, 43], ["logger.info", "faiss.read_index", "logger.info", "type"], "methods", ["None"], ["", "def", "deserialize_from", "(", "self", ",", "index_file", ":", "str", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading index from %s\"", ",", "index_file", ")", "\n", "self", ".", "index", "=", "faiss", ".", "read_index", "(", "index_file", ")", "\n", "logger", ".", "info", "(", "\n", "\"Loaded index of type %s and size %d\"", ",", "type", "(", "self", ".", "index", ")", ",", "self", ".", "index", ".", "ntotal", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseFlatIndexer.__init__": [[48, 51], ["faiss_indexer.DenseIndexer.__init__", "faiss.IndexFlatIP"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vector_sz", ":", "int", "=", "1", ",", "buffer_size", ":", "int", "=", "50000", ")", ":", "\n", "        ", "super", "(", "DenseFlatIndexer", ",", "self", ")", ".", "__init__", "(", "buffer_size", "=", "buffer_size", ")", "\n", "self", ".", "index", "=", "faiss", ".", "IndexFlatIP", "(", "vector_sz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseFlatIndexer.index_data": [[52, 64], ["len", "logger.info", "range", "logger.info", "numpy.concatenate", "faiss_indexer.DenseFlatIndexer.index.add", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["", "def", "index_data", "(", "self", ",", "data", ":", "np", ".", "array", ")", ":", "\n", "        ", "n", "=", "len", "(", "data", ")", "\n", "# indexing in batches is beneficial for many faiss index types", "\n", "logger", ".", "info", "(", "\"Indexing data, this may take a while.\"", ")", "\n", "cnt", "=", "0", "\n", "for", "i", "in", "range", "(", "0", ",", "n", ",", "self", ".", "buffer_size", ")", ":", "\n", "            ", "vectors", "=", "[", "np", ".", "reshape", "(", "t", ",", "(", "1", ",", "-", "1", ")", ")", "for", "t", "in", "data", "[", "i", ":", "i", "+", "self", ".", "buffer_size", "]", "]", "\n", "vectors", "=", "np", ".", "concatenate", "(", "vectors", ",", "axis", "=", "0", ")", "\n", "self", ".", "index", ".", "add", "(", "vectors", ")", "\n", "cnt", "+=", "self", ".", "buffer_size", "\n", "\n", "", "logger", ".", "info", "(", "\"Total data indexed %d\"", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseFlatIndexer.search_knn": [[65, 68], ["faiss_indexer.DenseFlatIndexer.index.search"], "methods", ["None"], ["", "def", "search_knn", "(", "self", ",", "query_vectors", ",", "top_k", ")", ":", "\n", "        ", "scores", ",", "indexes", "=", "self", ".", "index", ".", "search", "(", "query_vectors", ",", "top_k", ")", "\n", "return", "scores", ",", "indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseIVFFlatIndexer.__init__": [[72, 79], ["faiss_indexer.DenseIndexer.__init__", "faiss.IndexFlatL2", "faiss.IndexIVFFlat"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["    ", "\"\"\"\n     Efficient index for retrieval. Note: default settings are for hugh accuracy but also high RAM usage\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "vector_sz", ":", "int", ",", "\n", "buffer_size", ":", "int", "=", "50000", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseIVFFlatIndexer.index_data": [[80, 87], ["len", "logger.info", "faiss_indexer.DenseIVFFlatIndexer.index.train", "faiss_indexer.DenseIVFFlatIndexer.index.add", "logger.info"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["store_n", ":", "int", "=", "128", ",", "\n", "ef_search", ":", "int", "=", "256", ",", "\n", "ef_construction", ":", "int", "=", "200", ",", "\n", ")", ":", "\n", "        ", "super", "(", "DenseHNSWFlatIndexer", ",", "self", ")", ".", "__init__", "(", "buffer_size", "=", "buffer_size", ")", "\n", "\n", "# IndexHNSWFlat supports L2 similarity only", "\n", "# so we have to apply DOT -> L2 similairy space conversion with the help of an extra dimension", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseIVFFlatIndexer.search_knn": [[88, 91], ["faiss_indexer.DenseIVFFlatIndexer.index.search"], "methods", ["None"], ["index", "=", "faiss", ".", "IndexHNSWFlat", "(", "vector_sz", "+", "1", ",", "store_n", ")", "\n", "index", ".", "hnsw", ".", "efSearch", "=", "ef_search", "\n", "index", ".", "hnsw", ".", "efConstruction", "=", "ef_construction", "\n", "self", ".", "index", "=", "index", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseHNSWFlatIndexer.__init__": [[99, 113], ["faiss_indexer.DenseIndexer.__init__", "faiss.IndexHNSWFlat"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["            ", "raise", "RuntimeError", "(", "\n", "\"DPR HNSWF index needs to index all data at once,\"", "\n", "\"results will be unpredictable otherwise.\"", "\n", ")", "\n", "", "phi", "=", "0", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "data", ")", ":", "\n", "            ", "doc_vector", "=", "item", "\n", "norms", "=", "(", "doc_vector", "**", "2", ")", ".", "sum", "(", ")", "\n", "phi", "=", "max", "(", "phi", ",", "norms", ")", "\n", "", "logger", ".", "info", "(", "\"HNSWF DotProduct -> L2 space phi={}\"", ".", "format", "(", "phi", ")", ")", "\n", "self", ".", "phi", "=", "0", "\n", "\n", "# indexing in batches is beneficial for many faiss index types", "\n", "logger", ".", "info", "(", "\"Indexing data, this may take a while.\"", ")", "\n", "cnt", "=", "0", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseHNSWFlatIndexer.index_data": [[114, 121], ["len", "logger.info", "faiss_indexer.DenseHNSWFlatIndexer.index.add", "logger.info"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["for", "i", "in", "range", "(", "0", ",", "n", ",", "self", ".", "buffer_size", ")", ":", "\n", "            ", "vectors", "=", "[", "np", ".", "reshape", "(", "t", ",", "(", "1", ",", "-", "1", ")", ")", "for", "t", "in", "data", "[", "i", ":", "i", "+", "self", ".", "buffer_size", "]", "]", "\n", "\n", "norms", "=", "[", "(", "doc_vector", "**", "2", ")", ".", "sum", "(", ")", "for", "doc_vector", "in", "vectors", "]", "\n", "aux_dims", "=", "[", "np", ".", "sqrt", "(", "phi", "-", "norm", ")", "for", "norm", "in", "norms", "]", "\n", "hnsw_vectors", "=", "[", "\n", "np", ".", "hstack", "(", "(", "doc_vector", ",", "aux_dims", "[", "i", "]", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ")", "\n", "for", "i", ",", "doc_vector", "in", "enumerate", "(", "vectors", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseHNSWFlatIndexer.search_knn": [[122, 125], ["faiss_indexer.DenseHNSWFlatIndexer.index.search"], "methods", ["None"], ["]", "\n", "hnsw_vectors", "=", "np", ".", "concatenate", "(", "hnsw_vectors", ",", "axis", "=", "0", ")", "\n", "\n", "self", ".", "index", ".", "add", "(", "hnsw_vectors", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseHNSWFlatIndexer.deserialize_from": [[126, 130], ["faiss_indexer.DenseIndexer.deserialize_from"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.index.faiss_indexer.DenseHNSWFlatIndexer.deserialize_from"], ["cnt", "+=", "self", ".", "buffer_size", "\n", "logger", ".", "info", "(", "\"Indexed data %d\"", "%", "cnt", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Total data indexed %d\"", "%", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.vcg_utils.measures.entity_linking_tp_with_overlap": [[9, 89], ["any", "sorted", "sorted", "numpy.zeros", "numpy.zeros", "range", "len", "range", "len", "len", "len", "len", "len", "len", "gm[].lower", "pm[].lower", "gm[].lower", "pm[].lower", "len", "len", "len", "len", "max", "max", "max", "max", "max", "max"], "function", ["None"], ["def", "entity_linking_tp_with_overlap", "(", "gold", ",", "predicted", ")", ":", "\n", "    ", "\"\"\"\n\n    Partially adopted from: https://github.com/UKPLab/starsem2018-entity-linking\n\n    Counts weak and strong matches\n\n    :param gold:\n    :param predicted:\n    :return:\n    >>> entity_linking_tp_with_overlap([('Q7366', 14, 18), ('Q780394', 19, 35)], [('Q7366', 14, 16), ('Q780394', 19, 35)])\n    2, 1\n    >>> entity_linking_tp_with_overlap([('Q7366', 14, 18), ('Q780394', 19, 35)], [('Q7366', 14, 16)])\n    1, 0\n    >>> entity_linking_tp_with_overlap([(None, 14, 18), ('Q780394', 19, 35)], [('Q7366', 14, 16)])\n    0, 0\n    >>> entity_linking_tp_with_overlap([(None, 14, 18), (None, )], [(None,)])\n    1, 0\n    >>> entity_linking_tp_with_overlap([('Q7366', ), ('Q780394', )], [('Q7366', 14, 16)])\n    1, 0\n    >>> entity_linking_tp_with_overlap([], [('Q7366', 14, 16)])\n    0, 0\n    \"\"\"", "\n", "if", "not", "gold", "or", "not", "predicted", ":", "\n", "        ", "return", "0", ",", "0", "\n", "# Add dummy spans, if no spans are given, everything is overlapping per default", "\n", "", "if", "any", "(", "len", "(", "e", ")", "!=", "3", "for", "e", "in", "gold", ")", ":", "\n", "        ", "gold", "=", "[", "(", "e", "[", "0", "]", ",", "0", ",", "1", ")", "for", "e", "in", "gold", "]", "\n", "predicted", "=", "[", "(", "e", "[", "0", "]", ",", "0", ",", "1", ")", "for", "e", "in", "predicted", "]", "\n", "# Replace None KB ids with empty strings", "\n", "", "gold", "=", "[", "(", "\"\"", ",", ")", "+", "e", "[", "1", ":", "]", "if", "e", "[", "0", "]", "is", "None", "else", "e", "for", "e", "in", "gold", "]", "\n", "predicted", "=", "[", "(", "\"\"", ",", ")", "+", "e", "[", "1", ":", "]", "if", "e", "[", "0", "]", "is", "None", "else", "e", "for", "e", "in", "predicted", "]", "\n", "\n", "gold", "=", "sorted", "(", "gold", ",", "key", "=", "lambda", "x", ":", "x", "[", "2", "]", ")", "\n", "predicted", "=", "sorted", "(", "predicted", ",", "key", "=", "lambda", "x", ":", "x", "[", "2", "]", ")", "\n", "\n", "# tracks weak matches", "\n", "lcs_matrix_weak", "=", "np", ".", "zeros", "(", "(", "len", "(", "gold", ")", ",", "len", "(", "predicted", ")", ")", ",", "dtype", "=", "np", ".", "int16", ")", "\n", "# tracks strong matches", "\n", "lcs_matrix_strong", "=", "np", ".", "zeros", "(", "(", "len", "(", "gold", ")", ",", "len", "(", "predicted", ")", ")", ",", "dtype", "=", "np", ".", "int16", ")", "\n", "for", "g_i", "in", "range", "(", "len", "(", "gold", ")", ")", ":", "\n", "        ", "for", "p_i", "in", "range", "(", "len", "(", "predicted", ")", ")", ":", "\n", "            ", "gm", "=", "gold", "[", "g_i", "]", "\n", "pm", "=", "predicted", "[", "p_i", "]", "\n", "\n", "# increment lcs_matrix_weak", "\n", "if", "not", "(", "gm", "[", "1", "]", ">=", "pm", "[", "2", "]", "or", "pm", "[", "1", "]", ">=", "gm", "[", "2", "]", ")", "and", "(", "gm", "[", "0", "]", ".", "lower", "(", ")", "==", "pm", "[", "0", "]", ".", "lower", "(", ")", ")", ":", "\n", "                ", "if", "g_i", "==", "0", "or", "p_i", "==", "0", ":", "\n", "                    ", "lcs_matrix_weak", "[", "g_i", ",", "p_i", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "lcs_matrix_weak", "[", "g_i", ",", "p_i", "]", "=", "1", "+", "lcs_matrix_weak", "[", "g_i", "-", "1", ",", "p_i", "-", "1", "]", "\n", "", "", "else", ":", "\n", "                ", "if", "g_i", "==", "0", "and", "p_i", "==", "0", ":", "\n", "                    ", "lcs_matrix_weak", "[", "g_i", ",", "p_i", "]", "=", "0", "\n", "", "elif", "g_i", "==", "0", "and", "p_i", "!=", "0", ":", "\n", "                    ", "lcs_matrix_weak", "[", "g_i", ",", "p_i", "]", "=", "max", "(", "0", ",", "lcs_matrix_weak", "[", "g_i", ",", "p_i", "-", "1", "]", ")", "\n", "", "elif", "g_i", "!=", "0", "and", "p_i", "==", "0", ":", "\n", "                    ", "lcs_matrix_weak", "[", "g_i", ",", "p_i", "]", "=", "max", "(", "lcs_matrix_weak", "[", "g_i", "-", "1", ",", "p_i", "]", ",", "0", ")", "\n", "", "elif", "g_i", "!=", "0", "and", "p_i", "!=", "0", ":", "\n", "                    ", "lcs_matrix_weak", "[", "g_i", ",", "p_i", "]", "=", "max", "(", "lcs_matrix_weak", "[", "g_i", "-", "1", ",", "p_i", "]", ",", "lcs_matrix_weak", "[", "g_i", ",", "p_i", "-", "1", "]", ")", "\n", "\n", "# increment lcs_matrix_strong", "\n", "", "", "if", "(", "gm", "[", "1", "]", "==", "pm", "[", "1", "]", "and", "pm", "[", "2", "]", "==", "gm", "[", "2", "]", ")", "and", "(", "gm", "[", "0", "]", ".", "lower", "(", ")", "==", "pm", "[", "0", "]", ".", "lower", "(", ")", ")", ":", "\n", "                ", "if", "g_i", "==", "0", "or", "p_i", "==", "0", ":", "\n", "                    ", "lcs_matrix_strong", "[", "g_i", ",", "p_i", "]", "=", "1", "\n", "", "else", ":", "\n", "                    ", "lcs_matrix_strong", "[", "g_i", ",", "p_i", "]", "=", "1", "+", "lcs_matrix_strong", "[", "g_i", "-", "1", ",", "p_i", "-", "1", "]", "\n", "", "", "else", ":", "\n", "                ", "if", "g_i", "==", "0", "and", "p_i", "==", "0", ":", "\n", "                    ", "lcs_matrix_strong", "[", "g_i", ",", "p_i", "]", "=", "0", "\n", "", "elif", "g_i", "==", "0", "and", "p_i", "!=", "0", ":", "\n", "                    ", "lcs_matrix_strong", "[", "g_i", ",", "p_i", "]", "=", "max", "(", "0", ",", "lcs_matrix_strong", "[", "g_i", ",", "p_i", "-", "1", "]", ")", "\n", "", "elif", "g_i", "!=", "0", "and", "p_i", "==", "0", ":", "\n", "                    ", "lcs_matrix_strong", "[", "g_i", ",", "p_i", "]", "=", "max", "(", "lcs_matrix_strong", "[", "g_i", "-", "1", ",", "p_i", "]", ",", "0", ")", "\n", "", "elif", "g_i", "!=", "0", "and", "p_i", "!=", "0", ":", "\n", "                    ", "lcs_matrix_strong", "[", "g_i", ",", "p_i", "]", "=", "max", "(", "lcs_matrix_strong", "[", "g_i", "-", "1", ",", "p_i", "]", ",", "lcs_matrix_strong", "[", "g_i", ",", "p_i", "-", "1", "]", ")", "\n", "\n", "", "", "", "", "weak_match_count", "=", "lcs_matrix_weak", "[", "len", "(", "gold", ")", "-", "1", ",", "len", "(", "predicted", ")", "-", "1", "]", "\n", "strong_match_count", "=", "lcs_matrix_strong", "[", "len", "(", "gold", ")", "-", "1", ",", "len", "(", "predicted", ")", "-", "1", "]", "\n", "return", "weak_match_count", ",", "strong_match_count", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.alignments.Alignments._traverse": [[17, 46], ["parsed_amr.get_triples3", "range", "queue.append", "len", "len", "queue.pop", "triples2.append", "visited.append", "triples2.append", "str", "queue.append", "str", "str"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amr.AMR.get_triples3"], ["\t", "def", "_traverse", "(", "self", ",", "parsed_amr", ",", "amr", ")", ":", "\n", "\t\t", "triples", "=", "parsed_amr", ".", "get_triples3", "(", ")", "\n", "triples2", "=", "[", "]", "\n", "root", "=", "None", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "triples", ")", ")", ":", "\n", "\t\t\t", "rel", "=", "triples", "[", "i", "]", "\n", "if", "rel", "[", "1", "]", "==", "\"TOP\"", ":", "\n", "\t\t\t\t", "triples2", ".", "append", "(", "(", "\"TOP\"", ",", "\":top\"", ",", "rel", "[", "0", "]", ")", ")", "\n", "root", "=", "rel", "[", "0", "]", "\n", "", "elif", "rel", "not", "in", "[", "r", "for", "r", "in", "parsed_amr", ".", "reent", "if", "r", "[", "2", "]", "in", "parsed_amr", ".", "nodes", "]", ":", "\n", "\t\t\t\t", "triples2", ".", "append", "(", "(", "rel", "[", "0", "]", ",", "\":\"", "+", "rel", "[", "1", "]", ",", "rel", "[", "2", "]", ")", ")", "\n", "", "", "indexes", "=", "{", "}", "\n", "queue", "=", "[", "]", "\n", "visited", "=", "[", "]", "\n", "queue", ".", "append", "(", "(", "root", ",", "\"0\"", ")", ")", "\n", "while", "len", "(", "queue", ")", ">", "0", ":", "\n", "\t\t\t", "(", "node", ",", "prefix", ")", "=", "queue", ".", "pop", "(", "0", ")", "\n", "if", "node", "in", "visited", ":", "\n", "\t\t\t\t", "continue", "\n", "", "indexes", "[", "prefix", "]", "=", "node", "\n", "if", "node", "in", "parsed_amr", ".", "nodes", ":", "\n", "\t\t\t\t", "visited", ".", "append", "(", "node", ")", "\n", "children", "=", "[", "t", "for", "t", "in", "triples2", "if", "str", "(", "t", "[", "0", "]", ")", "==", "node", "]", "\n", "i", "=", "0", "\n", "for", "c", "in", "children", ":", "\n", "\t\t\t\t\t", "v", "=", "str", "(", "c", "[", "2", "]", ")", "\n", "queue", ".", "append", "(", "(", "v", ",", "prefix", "+", "\".\"", "+", "str", "(", "i", ")", ")", ")", "\n", "i", "+=", "1", "\n", "", "", "", "return", "indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.alignments.Alignments.__init__": [[48, 68], ["zip", "open", "g.strip", "g.strip.AMR.parse_AMR_line", "line.strip.strip.strip", "alignments.Alignments._traverse", "collections.defaultdict", "alignments.Alignments.alignments.append", "g.strip.replace", "line.strip.strip.split", "range", "a.strip", "[].split", "[].split", "int", "int", "[].split", "al[].append", "a.split", "a.split", "a.split"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.parse_AMR_line", "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.alignments.Alignments._traverse", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "__init__", "(", "self", ",", "alignments_filename", ",", "graphs", ")", ":", "\n", "\t\t", "self", ".", "alignments", "=", "[", "]", "\n", "for", "g", ",", "line", "in", "zip", "(", "graphs", ",", "open", "(", "alignments_filename", ")", ")", ":", "\n", "\t\t\t", "amr", "=", "g", ".", "strip", "(", ")", "\n", "parsed_amr", "=", "amr_annot", ".", "AMR", ".", "parse_AMR_line", "(", "amr", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ",", "False", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "indexes", "=", "self", ".", "_traverse", "(", "parsed_amr", ",", "amr", ")", "\n", "al", "=", "defaultdict", "(", "list", ")", "\n", "if", "line", "!=", "\"\"", ":", "\n", "\t\t\t\t", "for", "a", "in", "line", ".", "split", "(", "\" \"", ")", ":", "\n", "\t\t\t\t\t", "if", "a", ".", "strip", "(", ")", "==", "\"\"", ":", "\n", "\t\t\t\t\t\t", "continue", "\n", "", "start", "=", "a", ".", "split", "(", "\"|\"", ")", "[", "0", "]", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "\n", "if", "start", "[", "0", "]", "==", "\"*\"", ":", "\n", "\t\t\t\t\t\t", "start", "=", "start", "[", "1", ":", "]", "\n", "", "end", "=", "a", ".", "split", "(", "\"|\"", ")", "[", "0", "]", ".", "split", "(", "\"-\"", ")", "[", "1", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "start", ")", ",", "int", "(", "end", ")", ")", ":", "\n", "\t\t\t\t\t\t", "for", "segment", "in", "a", ".", "split", "(", "\"|\"", ")", "[", "1", "]", ".", "split", "(", "\"+\"", ")", ":", "\n", "\t\t\t\t\t\t\t", "al", "[", "i", "]", ".", "append", "(", "indexes", "[", "segment", "]", ")", "\n", "", "", "", "", "self", ".", "alignments", ".", "append", "(", "al", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.extract_np._to_string": [[8, 45], ["enumerate", "indexes[].append", "seen.append", "len", "root.split", "len", "str", "range", "copy.deepcopy", "str", "root.split", "root.split", "root.split", "extract_np._to_string", "str", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.extract_np._to_string"], ["def", "_to_string", "(", "triples", ",", "root", ",", "level", ",", "last_child", ",", "seen", ",", "prefix", ",", "indexes", ")", ":", "\n", "    ", "children", "=", "[", "t", "for", "t", "in", "triples", "if", "str", "(", "t", "[", "0", "]", ")", "==", "root", ".", "split", "(", ")", "[", "0", "]", "]", "\n", "if", "root", "in", "seen", ":", "\n", "        ", "root", "=", "root", ".", "split", "(", ")", "[", "0", "]", "\n", "children", "=", "[", "]", "\n", "", "else", ":", "\n", "        ", "var", "=", "root", "\n", "if", "\" / \"", "in", "root", ":", "\n", "            ", "var", "=", "root", ".", "split", "(", ")", "[", "0", "]", "\n", "", "indexes", "[", "var", "]", ".", "append", "(", "prefix", ")", "\n", "", "if", "\" / \"", "in", "root", ":", "\n", "        ", "seen", ".", "append", "(", "root", ")", "\n", "graph", "=", "\"(\"", "+", "root", "\n", "if", "len", "(", "children", ")", ">", "0", ":", "\n", "            ", "graph", "+=", "\"\\n\"", "\n", "", "else", ":", "\n", "            ", "graph", "+=", "\")\"", "\n", "", "", "else", ":", "\n", "        ", "graph", "=", "root", "\n", "", "j", "=", "0", "\n", "for", "k", ",", "t", "in", "enumerate", "(", "children", ")", ":", "\n", "        ", "if", "str", "(", "t", "[", "0", "]", ")", "==", "root", ".", "split", "(", ")", "[", "0", "]", ":", "\n", "            ", "next_r", "=", "t", "[", "3", "]", "\n", "if", "t", "[", "4", "]", "!=", "\"\"", ":", "\n", "                ", "next_r", "+=", "\" / \"", "+", "t", "[", "4", "]", "\n", "", "for", "i", "in", "range", "(", "0", ",", "level", ")", ":", "\n", "                ", "graph", "+=", "\"    \"", "\n", "", "seen2", "=", "copy", ".", "deepcopy", "(", "seen", ")", "\n", "graph", "+=", "t", "[", "2", "]", "+", "\" \"", "+", "_to_string", "(", "triples", ",", "next_r", ",", "level", "+", "1", ",", "k", "==", "len", "(", "children", ")", "-", "1", ",", "seen", ",", "prefix", "+", "\".\"", "+", "str", "(", "j", ")", ",", "indexes", ")", "[", "0", "]", "\n", "if", "next_r", "not", "in", "seen2", "or", "\" / \"", "not", "in", "next_r", ":", "\n", "                ", "j", "+=", "1", "\n", "", "", "", "if", "len", "(", "children", ")", ">", "0", ":", "\n", "        ", "graph", "+=", "\")\"", "\n", "", "if", "not", "last_child", ":", "\n", "        ", "graph", "+=", "\"\\n\"", "\n", "\n", "", "return", "graph", ",", "indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.extract_np.to_string": [[46, 64], ["extract_np._to_string", "len", "len", "collections.defaultdict", "collections.defaultdict", "str", "triples2.append", "triples2.append", "str", "str"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.extract_np._to_string"], ["", "def", "to_string", "(", "triples", ",", "root", ")", ":", "\n", "    ", "children", "=", "[", "t", "for", "t", "in", "triples", "if", "str", "(", "t", "[", "0", "]", ")", "==", "root", "]", "\n", "if", "len", "(", "children", ")", ">", "1", ":", "\n", "        ", "counter", "=", "1", "\n", "triples2", "=", "[", "(", "\"TOP\"", ",", "\"\"", ",", "\":top\"", ",", "\"mu\"", ",", "\"multi-sentence\"", ")", "]", "\n", "for", "t", "in", "triples", ":", "\n", "            ", "if", "t", "[", "0", "]", "==", "\"TOP\"", ":", "\n", "                ", "triples2", ".", "append", "(", "(", "\"mu\"", ",", "\"multi-sentence\"", ",", "\":snt\"", "+", "str", "(", "counter", ")", ",", "t", "[", "3", "]", ",", "t", "[", "4", "]", ")", ")", "\n", "counter", "+=", "1", "\n", "", "else", ":", "\n", "                ", "triples2", ".", "append", "(", "t", ")", "\n", "", "", "", "else", ":", "\n", "        ", "triples2", "=", "triples", "\n", "", "children", "=", "[", "t", "for", "t", "in", "triples2", "if", "str", "(", "t", "[", "0", "]", ")", "==", "root", "]", "\n", "assert", "(", "len", "(", "children", ")", "==", "1", ")", "\n", "if", "children", "[", "0", "]", "[", "4", "]", "==", "\"\"", ":", "\n", "        ", "return", "\"(e / emptygraph)\\n\"", ",", "defaultdict", "(", "list", ")", "\n", "", "return", "_to_string", "(", "triples2", ",", "children", "[", "0", "]", "[", "3", "]", "+", "\" / \"", "+", "children", "[", "0", "]", "[", "4", "]", ",", "1", ",", "False", ",", "[", "]", ",", "\"0\"", ",", "defaultdict", "(", "list", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.extract_np.var2concept": [[65, 70], ["zip"], "function", ["None"], ["", "def", "var2concept", "(", "amr", ")", ":", "\n", "    ", "v2c", "=", "{", "}", "\n", "for", "n", ",", "v", "in", "zip", "(", "amr", ".", "nodes", ",", "amr", ".", "node_values", ")", ":", "\n", "            ", "v2c", "[", "n", "]", "=", "v", "\n", "", "return", "v2c", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.extract_np.preprocess_constituency_tree": [[71, 83], ["enumerate", "snt.split", "syntax.split", "new_syntax.append", "new_syntax.append", "tok.startswith", "str"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "preprocess_constituency_tree", "(", "snt", ",", "syntax", ")", ":", "\n", "    ", "for", "idx", ",", "word", "in", "enumerate", "(", "snt", ".", "split", "(", ")", ")", ":", "\n", "        ", "new_syntax", "=", "[", "]", "\n", "done", "=", "False", "\n", "for", "tok", "in", "syntax", ".", "split", "(", ")", ":", "\n", "            ", "if", "not", "done", "and", "word", "==", "tok", "and", "not", "tok", ".", "startswith", "(", "'<<'", ")", ":", "\n", "                ", "new_syntax", ".", "append", "(", "'<<'", "+", "str", "(", "idx", ")", "+", "'>>'", "+", "tok", ")", "\n", "done", "=", "True", "\n", "", "else", ":", "\n", "                ", "new_syntax", ".", "append", "(", "tok", ")", "\n", "", "", "syntax", "=", "' '", ".", "join", "(", "new_syntax", ")", "\n", "", "return", "syntax", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.extract_np.run": [[84, 180], ["open().read().split", "amrdata.AMRDataset().getAllSents", "open", "open", "open().read().split.pop().strip", "blocks.pop().strip.split", "blocks[].startswith", "snt.replace.replace", "snt.replace.replace", "extract_np.preprocess_constituency_tree", "preprocess_constituency_tree.split", "zip", "open().read", "amrdata.AMRDataset", "len", "open().read().split.pop", "[].replace().split", "tok.split", "int", "int", "range", "collections.defaultdict", "smatch.AMR.parse_AMR_line", "extract_np.var2concept", "open.write", "open.write", "open().read().split.pop", "len", "nodes.extend", "sents[].graph.replace", "str", "len", "rels2.insert", "extract_np.to_string", "open", "[].replace", "tok.split", "new_np_idxs.append", "rels2.insert", "tok.split", "len", "nps.append", "nps_idxs.append", "new_np_idxs.append", "str", "extract_np.var2concept", "new_np.split", "x.startswith", "re.sub().split", "len", "len", "const.split", "re.sub"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amrdata.AMRDataset.getAllSents", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.extract_np.preprocess_constituency_tree", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.parse_AMR_line", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.var2concept", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.extract_np.to_string", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.var2concept", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "run", "(", "prefix", ")", ":", "\n", "    ", "blocks", "=", "open", "(", "prefix", "+", "\".sentences.nopars.out\"", ")", ".", "read", "(", ")", ".", "split", "(", "\"\\n\\n\"", ")", "\n", "nps", "=", "[", "]", "\n", "npstart", "=", "False", "\n", "par", "=", "0", "\n", "k", "=", "-", "1", "\n", "sents", "=", "AMRDataset", "(", "prefix", ",", "True", ",", "False", ")", ".", "getAllSents", "(", ")", "\n", "famr", "=", "open", "(", "\"np_graphs.txt\"", ",", "\"w\"", ")", "\n", "fsent", "=", "open", "(", "\"np_sents.txt\"", ",", "\"w\"", ")", "\n", "while", "True", ":", "\n", "        ", "k", "+=", "1", "\n", "if", "len", "(", "blocks", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "block_txt", "=", "blocks", ".", "pop", "(", "0", ")", ".", "strip", "(", ")", "\n", "block", "=", "block_txt", ".", "split", "(", "\"\\n\"", ")", "\n", "const", "=", "\"\"", ".", "join", "(", "block", "[", "3", ":", "]", ")", "\n", "if", "blocks", "[", "0", "]", ".", "startswith", "(", "\"\\n\"", ")", ":", "\n", "                ", "b", "=", "\"\"", "\n", "", "else", ":", "\n", "                ", "b", "=", "blocks", ".", "pop", "(", "0", ")", "\n", "\n", "", "snt", "=", "' '", ".", "join", "(", "sents", "[", "k", "]", ".", "tokens", ")", "\n", "snt", "=", "snt", ".", "replace", "(", "'('", ",", "'<OP>'", ")", "\n", "snt", "=", "snt", ".", "replace", "(", "')'", ",", "'<CP>'", ")", "\n", "\n", "syntax", "=", "\" \"", ".", "join", "(", "const", ".", "split", "(", "']'", ")", "[", "-", "1", "]", ".", "replace", "(", "')'", ",", "' )'", ")", ".", "split", "(", ")", ")", "\n", "syntax", "=", "preprocess_constituency_tree", "(", "snt", ",", "syntax", ")", "\n", "\n", "nps", "=", "[", "]", "\n", "nps_idxs", "=", "[", "]", "\n", "np_flag", "=", "False", "\n", "new_np", "=", "\"\"", "\n", "new_np_idxs", "=", "[", "]", "\n", "pars", "=", "0", "\n", "\n", "# find all NPs", "\n", "for", "tok", "in", "syntax", ".", "split", "(", ")", ":", "\n", "            ", "fields", "=", "tok", ".", "split", "(", "'>>'", ")", "\n", "if", "len", "(", "fields", ")", ">", "1", ":", "\n", "                ", "i", "=", "tok", ".", "split", "(", "'>>'", ")", "[", "0", "]", "[", "2", ":", "]", "\n", "tok", "=", "tok", ".", "split", "(", "'>>'", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "                ", "i", "=", "-", "1", "\n", "", "if", "'('", "in", "tok", ":", "\n", "                ", "pars", "+=", "1", "\n", "", "elif", "')'", "in", "tok", ":", "\n", "                ", "pars", "-=", "1", "\n", "", "if", "np_flag", ":", "\n", "                ", "if", "tok", "==", "')'", "and", "pars", "==", "0", ":", "\n", "                    ", "np_flag", "=", "False", "\n", "new_np", "+=", "tok", "\n", "new_np_idxs", ".", "append", "(", "i", ")", "\n", "nouns", "=", "[", "x", "for", "x", "in", "new_np", ".", "split", "(", ")", "if", "x", ".", "startswith", "(", "'(N'", ")", "]", "\n", "if", "len", "(", "nouns", ")", ">", "1", ":", "\n", "                        ", "nps", ".", "append", "(", "re", ".", "sub", "(", "r'\\([A-Z:\\-\\,\\.\\$\\'\\`][A-Z:\\-\\,\\.\\$\\'\\`]*|\\)'", ",", "''", ",", "new_np", ")", ".", "split", "(", ")", ")", "\n", "nps_idxs", ".", "append", "(", "new_np_idxs", "[", "0", ":", "-", "1", "]", ")", "\n", "assert", "(", "len", "(", "nps", "[", "-", "1", "]", ")", "==", "len", "(", "nps_idxs", "[", "-", "1", "]", ")", ")", "\n", "", "", "else", ":", "\n", "                    ", "new_np", "+=", "' '", "+", "tok", "\n", "if", "i", "!=", "-", "1", ":", "\n", "                        ", "new_np_idxs", ".", "append", "(", "i", ")", "\n", "", "", "", "else", ":", "\n", "                ", "if", "tok", "==", "'(NP'", ":", "\n", "                    ", "pars", "=", "1", "\n", "np_flag", "=", "True", "\n", "new_np", "=", "tok", "\n", "new_np_idxs", "=", "[", "]", "\n", "\n", "# align NPs with tokens in text and write to file", "\n", "", "", "", "for", "n", ",", "i", "in", "zip", "(", "nps", ",", "nps_idxs", ")", ":", "\n", "            ", "nodes", "=", "[", "]", "\n", "if", "n", "==", "[", "]", ":", "\n", "                ", "continue", "\n", "", "a", "=", "int", "(", "i", "[", "0", "]", ")", "\n", "b", "=", "int", "(", "i", "[", "-", "1", "]", ")", "\n", "for", "index", "in", "range", "(", "a", ",", "b", "+", "1", ")", ":", "\n", "                ", "nodes", ".", "extend", "(", "sents", "[", "k", "]", ".", "alignments", "[", "index", "]", ")", "\n", "", "if", "nodes", "==", "[", "]", ":", "\n", "                ", "continue", "\n", "\n", "", "v2c", "=", "defaultdict", "(", "str", ")", "\n", "amr_annot", "=", "amr", ".", "AMR", ".", "parse_AMR_line", "(", "sents", "[", "k", "]", ".", "graph", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", "\n", "for", "key", "in", "var2concept", "(", "amr_annot", ")", ":", "\n", "                ", "v2c", "[", "str", "(", "key", ")", "]", "=", "str", "(", "var2concept", "(", "amr_annot", ")", "[", "key", "]", ")", "\n", "\n", "", "rels", "=", "[", "r", "for", "r", "in", "sents", "[", "k", "]", ".", "relations", "if", "r", "[", "0", "]", "in", "nodes", "and", "r", "[", "2", "]", "in", "nodes", "]", "\n", "rels2", "=", "[", "(", "r", "[", "0", "]", ",", "v2c", "[", "r", "[", "0", "]", "]", ",", "r", "[", "1", "]", ",", "r", "[", "2", "]", ",", "v2c", "[", "r", "[", "2", "]", "]", ")", "for", "r", "in", "rels", "]", "\n", "if", "len", "(", "rels2", ")", ">", "0", ":", "\n", "                ", "rels2", ".", "insert", "(", "0", ",", "(", "\"TOP\"", ",", "\"\"", ",", "\":top\"", ",", "rels2", "[", "0", "]", "[", "0", "]", ",", "v2c", "[", "rels2", "[", "0", "]", "[", "0", "]", "]", ")", ")", "\n", "", "for", "node", "in", "nodes", ":", "\n", "                ", "if", "node", "not", "in", "[", "r", "[", "0", "]", "for", "r", "in", "rels2", "]", "and", "node", "not", "in", "[", "r", "[", "3", "]", "for", "r", "in", "rels2", "]", ":", "\n", "                    ", "rels2", ".", "insert", "(", "0", ",", "(", "\"TOP\"", ",", "\"\"", ",", "\":top\"", ",", "node", ",", "v2c", "[", "node", "]", ")", ")", "\n", "", "", "amr_str", "=", "to_string", "(", "rels2", ",", "rels2", "[", "0", "]", "[", "0", "]", ")", "[", "0", "]", "\n", "\n", "famr", ".", "write", "(", "amr_str", "+", "\"\\n\"", ")", "\n", "fsent", ".", "write", "(", "\" \"", ".", "join", "(", "n", ")", ".", "replace", "(", "'<OP>'", ",", "'('", ")", ".", "replace", "(", "'<CP>'", ",", "')'", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amr.AMR.__init__": [[37, 91], ["collections.OrderedDict", "attribute_list2.append", "r[].endswith", "reent2.append", "reent2.append", "r[].endswith", "allrelations2.append", "allrelations2.append", "len", "dct[].endswith", "len", "len", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "node_list", "=", "None", ",", "node_value_list", "=", "None", ",", "relation_list", "=", "None", ",", "attribute_list", "=", "None", ",", "reent", "=", "None", ",", "allrelations", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        node_list: names of nodes in AMR graph, e.g. \"a11\", \"n\"\n        node_value_list: values of nodes in AMR graph, e.g. \"group\" for a node named \"g\"\n        relation_list: list of relations between two nodes\n        attribute_list: list of attributes (links between one node and one constant value)\n\n        \"\"\"", "\n", "# initialize AMR graph nodes using list of nodes name", "\n", "# root, by default, is the first in var_list", "\n", "attribute_list2", "=", "[", "]", "\n", "for", "dct", "in", "attribute_list", ":", "\n", "            ", "dct2", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "item", "in", "dct", ":", "\n", "                ", "if", "len", "(", "dct", "[", "item", "]", ")", ">", "1", "and", "dct", "[", "item", "]", ".", "endswith", "(", "\"_\"", ")", ":", "\n", "                    ", "dct", "[", "item", "]", "=", "'\"'", "+", "dct", "[", "item", "]", "[", "0", ":", "-", "1", "]", "+", "'\"'", "\n", "", "dct2", "[", "item", "]", "=", "dct", "[", "item", "]", "\n", "", "attribute_list2", ".", "append", "(", "dct2", ")", "\n", "", "reent2", "=", "[", "]", "\n", "for", "r", "in", "reent", ":", "\n", "            ", "if", "len", "(", "r", "[", "2", "]", ")", ">", "1", "and", "r", "[", "2", "]", ".", "endswith", "(", "\"_\"", ")", ":", "\n", "                ", "reent2", ".", "append", "(", "(", "r", "[", "0", "]", ",", "r", "[", "1", "]", ",", "'\"'", "+", "r", "[", "2", "]", "[", "0", ":", "-", "1", "]", "+", "'\"'", ")", ")", "\n", "", "else", ":", "\n", "                ", "reent2", ".", "append", "(", "r", ")", "\n", "", "", "allrelations2", "=", "[", "]", "\n", "for", "r", "in", "allrelations", ":", "\n", "            ", "if", "len", "(", "r", "[", "2", "]", ")", ">", "1", "and", "r", "[", "2", "]", ".", "endswith", "(", "\"_\"", ")", ":", "\n", "                ", "allrelations2", ".", "append", "(", "(", "r", "[", "0", "]", ",", "r", "[", "1", "]", ",", "'\"'", "+", "r", "[", "2", "]", "[", "0", ":", "-", "1", "]", "+", "'\"'", ")", ")", "\n", "", "else", ":", "\n", "                ", "allrelations2", ".", "append", "(", "r", ")", "\n", "", "", "if", "node_list", "is", "None", ":", "\n", "            ", "self", ".", "nodes", "=", "[", "]", "\n", "self", ".", "root", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "nodes", "=", "node_list", "[", ":", "]", "\n", "if", "len", "(", "node_list", ")", "!=", "0", ":", "\n", "                ", "self", ".", "root", "=", "node_list", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "root", "=", "None", "\n", "", "", "if", "node_value_list", "is", "None", ":", "\n", "            ", "self", ".", "node_values", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "node_values", "=", "node_value_list", "[", ":", "]", "\n", "", "if", "relation_list", "is", "None", ":", "\n", "            ", "self", ".", "relations", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "relations", "=", "relation_list", "[", ":", "]", "\n", "", "if", "attribute_list2", "is", "None", ":", "\n", "            ", "self", ".", "attributes", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "attributes", "=", "attribute_list2", "[", ":", "]", "\n", "\n", "", "self", ".", "reent", "=", "reent2", "\n", "self", ".", "allrelations", "=", "allrelations2", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amr.AMR.rename_node": [[92, 114], ["range", "enumerate", "enumerate", "len", "d.items", "str", "new_dict[].append"], "methods", ["None"], ["", "def", "rename_node", "(", "self", ",", "prefix", ")", ":", "\n", "        ", "\"\"\"\n        Rename AMR graph nodes to prefix + node_index to avoid nodes with the same name in two different AMRs.\n\n        \"\"\"", "\n", "node_map_dict", "=", "{", "}", "\n", "# map each node to its new name (e.g. \"a1\")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "node_map_dict", "[", "self", ".", "nodes", "[", "i", "]", "]", "=", "prefix", "+", "str", "(", "i", ")", "\n", "# update node name", "\n", "", "for", "i", ",", "v", "in", "enumerate", "(", "self", ".", "nodes", ")", ":", "\n", "            ", "self", ".", "nodes", "[", "i", "]", "=", "node_map_dict", "[", "v", "]", "\n", "# update node name in relations", "\n", "", "for", "i", ",", "d", "in", "enumerate", "(", "self", ".", "relations", ")", ":", "\n", "            ", "new_dict", "=", "{", "}", "\n", "for", "k", ",", "v_lst", "in", "d", ".", "items", "(", ")", ":", "\n", "                ", "for", "v", "in", "v_lst", ":", "\n", "                    ", "if", "node_map_dict", "[", "k", "]", "not", "in", "new_dict", ":", "\n", "                        ", "new_dict", "[", "node_map_dict", "[", "k", "]", "]", "=", "[", "v", "]", "\n", "", "else", ":", "\n", "                        ", "new_dict", "[", "node_map_dict", "[", "k", "]", "]", ".", "append", "(", "v", ")", "\n", "", "", "", "self", ".", "relations", "[", "i", "]", "=", "new_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amr.AMR.get_triples": [[115, 138], ["range", "len", "instance_triple.append", "amr.AMR.relations[].items", "amr.AMR.attributes[].items", "attribute_triple.append", "relation_triple.append"], "methods", ["None"], ["", "", "def", "get_triples", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the triples in three lists.\n        instance_triple: a triple representing an instance. E.g. instance(w, want-01)\n        attribute triple: relation of attributes, e.g. polarity(w, - )\n        and relation triple, e.g. arg0 (w, b)\n\n        \"\"\"", "\n", "instance_triple", "=", "[", "]", "\n", "relation_triple", "=", "[", "]", "\n", "attribute_triple", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "instance_triple", ".", "append", "(", "(", "\"instance\"", ",", "self", ".", "nodes", "[", "i", "]", ",", "self", ".", "node_values", "[", "i", "]", ")", ")", "\n", "# k is the other node this node has relation with", "\n", "# v is relation name", "\n", "for", "k", ",", "v_lst", "in", "self", ".", "relations", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "for", "v", "in", "v_lst", ":", "\n", "                    ", "relation_triple", ".", "append", "(", "(", "v", ",", "self", ".", "nodes", "[", "i", "]", ",", "k", ")", ")", "\n", "# k2 is the attribute name", "\n", "# v2 is the attribute value", "\n", "", "", "for", "k2", ",", "v2", "in", "self", ".", "attributes", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "attribute_triple", ".", "append", "(", "(", "k2", ",", "self", ".", "nodes", "[", "i", "]", ",", "v2", ")", ")", "\n", "", "", "return", "instance_triple", ",", "attribute_triple", ",", "relation_triple", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amr.AMR.get_triples2": [[140, 166], ["range", "len", "instance_triple.append", "amr.AMR.relations[].items", "amr.AMR.attributes[].items", "relation_triple.append", "relation_triple.append"], "methods", ["None"], ["", "def", "get_triples2", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the triples in two lists:\n        instance_triple: a triple representing an instance. E.g. instance(w, want-01)\n        relation_triple: a triple representing all relations. E.g arg0 (w, b) or E.g. polarity(w, - )\n        Note that we do not differentiate between attribute triple and relation triple. Both are considered as relation\n        triples.\n        All triples are represented by (triple_type, argument 1 of the triple, argument 2 of the triple)\n\n        \"\"\"", "\n", "instance_triple", "=", "[", "]", "\n", "relation_triple", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "# an instance triple is instance(node name, node value).", "\n", "# For example, instance(b, boy).", "\n", "            ", "instance_triple", ".", "append", "(", "(", "\"instance\"", ",", "self", ".", "nodes", "[", "i", "]", ",", "self", ".", "node_values", "[", "i", "]", ")", ")", "\n", "# k is the other node this node has relation with", "\n", "# v is relation name", "\n", "for", "k", ",", "v_lst", "in", "self", ".", "relations", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "for", "v", "in", "v_lst", ":", "\n", "                    ", "relation_triple", ".", "append", "(", "(", "v", ",", "self", ".", "nodes", "[", "i", "]", ",", "k", ")", ")", "\n", "# k2 is the attribute name", "\n", "# v2 is the attribute value", "\n", "", "", "for", "k2", ",", "v2", "in", "self", ".", "attributes", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "relation_triple", ".", "append", "(", "(", "k2", ",", "self", ".", "nodes", "[", "i", "]", ",", "v2", ")", ")", "\n", "", "", "return", "instance_triple", ",", "relation_triple", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amr.AMR.get_triples3": [[167, 171], ["relation_triple.extend"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend"], ["", "def", "get_triples3", "(", "self", ")", ":", "\n", "        ", "relation_triple", "=", "[", "(", "self", ".", "nodes", "[", "0", "]", ",", "\"TOP\"", ",", "self", ".", "node_values", "[", "0", "]", ")", "]", "\n", "relation_triple", ".", "extend", "(", "self", ".", "allrelations", ")", "\n", "return", "relation_triple", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amr.AMR.__str__": [[172, 188], ["range", "len", "lines.append", "lines.append", "lines.append", "amr.AMR.relations[].items", "amr.AMR.attributes[].items", "lines.append", "lines.append", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Generate AMR string for better readability\n\n        \"\"\"", "\n", "lines", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "lines", ".", "append", "(", "\"Node \"", "+", "str", "(", "i", ")", "+", "\" \"", "+", "self", ".", "nodes", "[", "i", "]", ")", "\n", "lines", ".", "append", "(", "\"Value: \"", "+", "self", ".", "node_values", "[", "i", "]", ")", "\n", "lines", ".", "append", "(", "\"Relations:\"", ")", "\n", "for", "k", ",", "v_lst", "in", "self", ".", "relations", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "for", "v", "in", "v_lst", ":", "\n", "                    ", "lines", ".", "append", "(", "\"Node \"", "+", "k", "+", "\" via \"", "+", "v", ")", "\n", "", "", "for", "k2", ",", "v2", "in", "self", ".", "attributes", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "lines", ".", "append", "(", "\"Attribute: \"", "+", "k2", "+", "\" value \"", "+", "v2", ")", "\n", "", "", "return", "\"\\n\"", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amr.AMR.__repr__": [[189, 191], ["amr.AMR.__str__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.ATP.generate_amrized_srl.SRL.__str__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__str__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amr.AMR.output_amr": [[192, 198], ["amr.AMR.__str__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.ATP.generate_amrized_srl.SRL.__str__"], ["", "def", "output_amr", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Output AMR string\n\n        \"\"\"", "\n", "print", ">>", "DEBUG_LOG", ",", "self", ".", "__str__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amr.AMR.parse_AMR_line": [[200, 460], ["collections.OrderedDict", "collections.defaultdict", "collections.defaultdict", "enumerate", "amr.AMR", "line.strip", "collections.OrderedDict", "collections.OrderedDict", "relation_list.append", "attribute_list.append", "node_value_list.append", "cur_charseq.append", "cur_charseq.append", "cur_charseq.append", "relation_dict[].append", "cur_charseq.append", "temp_attr_value.split", "parts[].strip", "parts[].strip", "cur_charseq.append", "stack.append", "node_name_list.append", "stack.pop", "cur_charseq.append", "relation_dict[].append", "len", "len", "parts[].strip.endswith", "allrelations.append", "reent.append", "allrelations.append", "reent.append", "cur_charseq.append", "len", "temp_attr_value.split", "parts[].strip", "parts[].strip", "reent.append", "node_relation_dict2[].append", "node_relation_dict1[].append", "node_relation_dict2[].append", "node_relation_dict1[].append", "node_relation_dict1[].append", "allrelations.append", "node_relation_dict1[].append", "allrelations.append", "len", "parts[].strip.endswith", "allrelations.append", "node_relation_dict1[].append", "allrelations.append", "node_relation_dict2[].append", "node_relation_dict1[].append", "cur_relation_name.endswith"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "@", "staticmethod", "\n", "def", "parse_AMR_line", "(", "line", ",", "normalize_inv", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Parse a AMR from line representation to an AMR object.\n        This parsing algorithm scans the line once and process each character, in a shift-reduce style.\n\n        \"\"\"", "\n", "# Current state. It denotes the last significant symbol encountered. 1 for (, 2 for :, 3 for /,", "\n", "# and 0 for start state or ')'", "\n", "# Last significant symbol is ( --- start processing node name", "\n", "# Last significant symbol is : --- start processing relation name", "\n", "# Last significant symbol is / --- start processing node value (concept name)", "\n", "# Last significant symbol is ) --- current node processing is complete", "\n", "# Note that if these symbols are inside parenthesis, they are not significant symbols.", "\n", "state", "=", "0", "\n", "stack", "=", "[", "]", "\n", "# current not-yet-reduced character sequence", "\n", "cur_charseq", "=", "[", "]", "\n", "# key: node name value: node value", "\n", "node_dict", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "# node name list (order: occurrence of the node)", "\n", "node_name_list", "=", "[", "]", "\n", "# key: node name:  value: list of (relation name, the other node name)", "\n", "node_relation_dict1", "=", "defaultdict", "(", "list", ")", "\n", "# key: node name, value: list of (attribute name, const value) or (relation name, unseen node name)", "\n", "node_relation_dict2", "=", "defaultdict", "(", "list", ")", "\n", "allrelations", "=", "[", "]", "\n", "reent", "=", "[", "]", "\n", "# current relation name", "\n", "cur_relation_name", "=", "\"\"", "\n", "# having unmatched quote string", "\n", "in_quote", "=", "False", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "line", ".", "strip", "(", ")", ")", ":", "\n", "            ", "if", "c", "==", "\" \"", ":", "\n", "# allow space in relation name", "\n", "                ", "if", "state", "==", "2", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "", "continue", "\n", "", "if", "c", "==", "\"\\\"\"", ":", "\n", "# flip in_quote value when a quote symbol is encountered", "\n", "# insert placeholder if in_quote from last symbol", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "'_'", ")", "\n", "", "in_quote", "=", "not", "in_quote", "\n", "", "elif", "c", "==", "\"(\"", ":", "\n", "# not significant symbol if inside quote", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# get the attribute name", "\n", "# e.g :arg0 (x ...", "\n", "# at this point we get \"arg0\"", "\n", "", "if", "state", "==", "2", ":", "\n", "# in this state, current relation name should be empty", "\n", "                    ", "if", "cur_relation_name", "!=", "\"\"", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "\"Format error when processing \"", ",", "line", "[", "0", ":", "i", "+", "1", "]", "\n", "return", "None", "\n", "# update current relation name for future use", "\n", "", "cur_relation_name", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", ".", "strip", "(", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "", "state", "=", "1", "\n", "", "elif", "c", "==", "\":\"", ":", "\n", "# not significant symbol if inside quote", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# Last significant symbol is \"/\". Now we encounter \":\"", "\n", "# Example:", "\n", "# :OR (o2 / *OR*", "\n", "#    :mod (o3 / official)", "\n", "#  gets node value \"*OR*\" at this point", "\n", "", "if", "state", "==", "3", ":", "\n", "                    ", "node_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "# clear current char sequence", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "# pop node name (\"o2\" in the above example)", "\n", "cur_node_name", "=", "stack", "[", "-", "1", "]", "\n", "# update node name/value map", "\n", "node_dict", "[", "cur_node_name", "]", "=", "node_value", "\n", "# Last significant symbol is \":\". Now we encounter \":\"", "\n", "# Example:", "\n", "# :op1 w :quant 30", "\n", "# or :day 14 :month 3", "\n", "# the problem is that we cannot decide if node value is attribute value (constant)", "\n", "# or node value (variable) at this moment", "\n", "", "elif", "state", "==", "2", ":", "\n", "                    ", "temp_attr_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "parts", "=", "temp_attr_value", ".", "split", "(", ")", "\n", "if", "len", "(", "parts", ")", "<", "2", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "\"Error in processing; part len < 2\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", "\n", "return", "None", "\n", "# For the above example, node name is \"op1\", and node value is \"w\"", "\n", "# Note that this node name might not be encountered before", "\n", "", "relation_name", "=", "parts", "[", "0", "]", ".", "strip", "(", ")", "\n", "relation_value", "=", "parts", "[", "1", "]", ".", "strip", "(", ")", "\n", "# We need to link upper level node to the current", "\n", "# top of stack is upper level node", "\n", "if", "len", "(", "stack", ")", "==", "0", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "\"Error in processing\"", ",", "line", "[", ":", "i", "]", ",", "relation_name", ",", "relation_value", "\n", "return", "None", "\n", "# if we have not seen this node name before", "\n", "", "if", "relation_name", ".", "endswith", "(", "\"-of\"", ")", "and", "normalize_inv", ":", "\n", "                        ", "allrelations", ".", "append", "(", "(", "relation_value", ",", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "if", "relation_value", "not", "in", "node_dict", ":", "\n", "                            ", "node_relation_dict2", "[", "relation_value", "]", ".", "append", "(", "(", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                            ", "node_relation_dict1", "[", "relation_value", "]", ".", "append", "(", "(", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "", "reent", ".", "append", "(", "(", "relation_value", ",", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                        ", "allrelations", ".", "append", "(", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "if", "relation_value", "not", "in", "node_dict", ":", "\n", "                            ", "node_relation_dict2", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "", "else", ":", "\n", "                            ", "node_relation_dict1", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "", "reent", ".", "append", "(", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "", "", "state", "=", "2", "\n", "", "elif", "c", "==", "\"/\"", ":", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# Last significant symbol is \"(\". Now we encounter \"/\"", "\n", "# Example:", "\n", "# (d / default-01", "\n", "# get \"d\" here", "\n", "", "if", "state", "==", "1", ":", "\n", "                    ", "node_name", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "# if this node name is already in node_dict, it is duplicate", "\n", "if", "node_name", "in", "node_dict", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "\"Duplicate node name \"", ",", "node_name", ",", "\" in parsing AMR\"", "\n", "return", "None", "\n", "# push the node name to stack", "\n", "", "stack", ".", "append", "(", "node_name", ")", "\n", "# add it to node name list", "\n", "node_name_list", ".", "append", "(", "node_name", ")", "\n", "# if this node is part of the relation", "\n", "# Example:", "\n", "# :arg1 (n / nation)", "\n", "# cur_relation_name is arg1", "\n", "# node name is n", "\n", "# we have a relation arg1(upper level node, n)", "\n", "if", "cur_relation_name", "!=", "\"\"", ":", "\n", "# if relation name ends with \"-of\", e.g.\"arg0-of\",", "\n", "# it is reverse of some relation. For example, if a is \"arg0-of\" b,", "\n", "# we can also say b is \"arg0\" a.", "\n", "# If the relation name ends with \"-of\", we store the reverse relation.", "\n", "                        ", "if", "(", "not", "cur_relation_name", ".", "endswith", "(", "\"-of\"", ")", ")", "or", "normalize_inv", "==", "False", ":", "\n", "# stack[-2] is upper_level node we encountered, as we just add node_name to stack", "\n", "                            ", "node_relation_dict1", "[", "stack", "[", "-", "2", "]", "]", ".", "append", "(", "(", "cur_relation_name", ",", "node_name", ")", ")", "\n", "allrelations", ".", "append", "(", "(", "stack", "[", "-", "2", "]", ",", "cur_relation_name", ",", "node_name", ")", ")", "\n", "#if node_name in node_name_list:", "\n", "#\treent.append((stack[-2],cur_relation_name,node_name))", "\n", "", "else", ":", "\n", "# cur_relation_name[:-3] is to delete \"-of\"", "\n", "                            ", "node_relation_dict1", "[", "node_name", "]", ".", "append", "(", "(", "cur_relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "2", "]", ")", ")", "\n", "allrelations", ".", "append", "(", "(", "node_name", ",", "cur_relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "2", "]", ")", ")", "\n", "# clear current_relation_name", "\n", "", "cur_relation_name", "=", "\"\"", "\n", "", "", "else", ":", "\n", "# error if in other state", "\n", "                    ", "print", ">>", "ERROR_LOG", ",", "\"Error in parsing AMR\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", "\n", "return", "None", "\n", "", "state", "=", "3", "\n", "", "elif", "c", "==", "\")\"", ":", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# stack should be non-empty to find upper level node", "\n", "", "if", "len", "(", "stack", ")", "==", "0", ":", "\n", "                    ", "print", ">>", "ERROR_LOG", ",", "\"Unmatched parenthesis at position\"", ",", "i", ",", "\"in processing\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", "\n", "return", "None", "\n", "# Last significant symbol is \":\". Now we encounter \")\"", "\n", "# Example:", "\n", "# :op2 \"Brown\") or :op2 w)", "\n", "# get \\\"Brown\\\" or w here", "\n", "", "if", "state", "==", "2", ":", "\n", "                    ", "temp_attr_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "parts", "=", "temp_attr_value", ".", "split", "(", ")", "\n", "if", "len", "(", "parts", ")", "<", "2", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "\"Error processing\"", ",", "line", "[", ":", "i", "+", "1", "]", ",", "temp_attr_value", "\n", "return", "None", "\n", "", "relation_name", "=", "parts", "[", "0", "]", ".", "strip", "(", ")", "\n", "relation_value", "=", "parts", "[", "1", "]", ".", "strip", "(", ")", "\n", "# store reverse of the relation", "\n", "# we are sure relation_value is a node here, as \"-of\" relation is only between two nodes", "\n", "if", "relation_name", ".", "endswith", "(", "\"-of\"", ")", "and", "normalize_inv", ":", "\n", "                        ", "allrelations", ".", "append", "(", "(", "relation_value", ",", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "node_relation_dict1", "[", "relation_value", "]", ".", "append", "(", "(", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "# attribute value not seen before", "\n", "# Note that it might be a constant attribute value, or an unseen node", "\n", "# process this after we have seen all the node names", "\n", "", "else", ":", "\n", "                        ", "allrelations", ".", "append", "(", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "", "if", "relation_value", "not", "in", "node_dict", ":", "\n", "                        ", "node_relation_dict2", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "", "else", ":", "\n", "                        ", "node_relation_dict1", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "#if relation_value in node_name_list:", "\n", "", "reent", ".", "append", "(", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "# Last significant symbol is \"/\". Now we encounter \")\"", "\n", "# Example:", "\n", "# :arg1 (n / nation)", "\n", "# we get \"nation\" here", "\n", "", "elif", "state", "==", "3", ":", "\n", "                    ", "node_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "cur_node_name", "=", "stack", "[", "-", "1", "]", "\n", "# map node name to its value", "\n", "node_dict", "[", "cur_node_name", "]", "=", "node_value", "\n", "#if node_value in node_name_list:", "\n", "#    reent.append((stack[-1],relation_name,relation_value))", "\n", "# pop from stack, as the current node has been processed", "\n", "", "stack", ".", "pop", "(", ")", "\n", "cur_relation_name", "=", "\"\"", "\n", "state", "=", "0", "\n", "", "else", ":", "\n", "# not significant symbols, so we just shift.", "\n", "                ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "#create data structures to initialize an AMR", "\n", "", "", "node_value_list", "=", "[", "]", "\n", "relation_list", "=", "[", "]", "\n", "attribute_list", "=", "[", "]", "\n", "for", "v", "in", "node_name_list", ":", "\n", "            ", "if", "v", "not", "in", "node_dict", ":", "\n", "                ", "print", ">>", "ERROR_LOG", ",", "\"Error: Node name not found\"", ",", "v", "\n", "return", "None", "\n", "", "else", ":", "\n", "                ", "node_value_list", ".", "append", "(", "node_dict", "[", "v", "]", ")", "\n", "# build relation map and attribute map for this node", "\n", "", "relation_dict", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "attribute_dict", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "if", "v", "in", "node_relation_dict1", ":", "\n", "                ", "for", "v1", "in", "node_relation_dict1", "[", "v", "]", ":", "\n", "                    ", "if", "v1", "[", "1", "]", "not", "in", "relation_dict", ":", "\n", "                        ", "relation_dict", "[", "v1", "[", "1", "]", "]", "=", "[", "v1", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "                        ", "relation_dict", "[", "v1", "[", "1", "]", "]", ".", "append", "(", "v1", "[", "0", "]", ")", "\n", "", "", "", "if", "v", "in", "node_relation_dict2", ":", "\n", "                ", "for", "v2", "in", "node_relation_dict2", "[", "v", "]", ":", "\n", "# if value is in quote, it is a constant value", "\n", "# strip the quote and put it in attribute map", "\n", "                    ", "if", "v2", "[", "1", "]", "[", "0", "]", "==", "\"\\\"\"", "and", "v2", "[", "1", "]", "[", "-", "1", "]", "==", "\"\\\"\"", ":", "\n", "                        ", "attribute_dict", "[", "v2", "[", "0", "]", "]", "=", "v2", "[", "1", "]", "[", "1", ":", "-", "1", "]", "\n", "# if value is a node name", "\n", "", "elif", "v2", "[", "1", "]", "in", "node_dict", ":", "\n", "                        ", "if", "v2", "[", "1", "]", "not", "in", "relation_dict", ":", "\n", "                            ", "relation_dict", "[", "v2", "[", "1", "]", "]", "=", "[", "v2", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "                            ", "relation_dict", "[", "v2", "[", "1", "]", "]", ".", "append", "(", "v2", "[", "0", "]", ")", "\n", "", "", "else", ":", "\n", "                        ", "attribute_dict", "[", "v2", "[", "0", "]", "]", "=", "v2", "[", "1", "]", "\n", "# each node has a relation map and attribute map", "\n", "", "", "", "relation_list", ".", "append", "(", "relation_dict", ")", "\n", "attribute_list", ".", "append", "(", "attribute_dict", ")", "\n", "# add TOP as an attribute. The attribute value is the top node value", "\n", "", "attribute_list", "[", "0", "]", "[", "\"TOP\"", "]", "=", "node_value_list", "[", "0", "]", "\n", "result_amr", "=", "AMR", "(", "node_name_list", ",", "node_value_list", ",", "relation_list", ",", "attribute_list", ",", "reent", ",", "allrelations", ")", "\n", "return", "result_amr", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amrdata.AMRSentence.__init__": [[17, 29], ["str", "str"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokens", ",", "pos", ",", "lemmas", ",", "nes", ",", "dependencies", ",", "variables", "=", "None", ",", "relations", "=", "None", ",", "graph", "=", "None", ",", "alignments", "=", "None", ")", ":", "\n", "        ", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "pos", "=", "pos", "\n", "self", ".", "lemmas", "=", "lemmas", "\n", "self", ".", "nes", "=", "nes", "\n", "self", ".", "dependencies", "=", "dependencies", "\n", "if", "variables", "is", "not", "None", ":", "\n", "            ", "self", ".", "variables", "=", "[", "(", "str", "(", "k", ")", ",", "str", "(", "variables", "[", "k", "]", ")", ")", "for", "k", "in", "variables", "]", "\n", "", "if", "relations", "is", "not", "None", ":", "\n", "            ", "self", ".", "relations", "=", "[", "r", "for", "r", "in", "relations", "if", "r", "[", "0", "]", "!=", "r", "[", "2", "]", "]", "\n", "", "self", ".", "graph", "=", "graph", "\n", "self", ".", "alignments", "=", "alignments", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amrdata.AMRDataset._var2concept": [[31, 36], ["zip"], "methods", ["None"], ["    ", "def", "_var2concept", "(", "self", ",", "amr", ")", ":", "\n", "        ", "v2c", "=", "{", "}", "\n", "for", "n", ",", "v", "in", "zip", "(", "amr", ".", "nodes", ",", "amr", ".", "node_values", ")", ":", "\n", "            ", "v2c", "[", "n", "]", "=", "v", "\n", "", "return", "v2c", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amrdata.AMRDataset.__init__": [[37, 88], ["amrdata.AMRDataset._loadFromFile", "open().read().split", "alignments.Alignments", "zip", "zip", "graph.strip.strip.strip", "amrannot.AMR.parse_AMR_line.AMR.parse_AMR_line", "zip", "amr.AMR.parse_AMR_line.get_triples3", "depslines.split", "amrdata.AMRDataset.sentences.append", "depslines.split", "amrdata.AMRDataset.sentences.append", "open().read", "graph.strip.strip.replace", "re.match", "amrdata.AMRSentence", "re.match", "amrdata.AMRSentence", "relations.append", "relations.append", "re.match.group", "re.match.group", "open", "int", "int", "dependencies.append", "int", "int", "dependencies.append", "str", "str", "re.match.group", "re.match.group", "dependencies.append", "re.match.group", "re.match.group", "dependencies.append", "str"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amrdata.AMRDataset._loadFromFile", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.parse_AMR_line", "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amr.AMR.get_triples3", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "__init__", "(", "self", ",", "prefix", ",", "amrs", ",", "normalize", "=", "True", ")", ":", "\n", "        ", "self", ".", "normalize", "=", "normalize", "\n", "self", ".", "sentences", "=", "[", "]", "\n", "\n", "alltokens", ",", "allpos", ",", "alllemmas", ",", "allnes", ",", "alldepslines", "=", "self", ".", "_loadFromFile", "(", "prefix", "+", "\".out\"", ")", "\n", "if", "amrs", ":", "\n", "            ", "allgraphs", "=", "open", "(", "prefix", "+", "\".graphs\"", ")", ".", "read", "(", ")", ".", "split", "(", "\"\\n\\n\"", ")", "\n", "a", "=", "Alignments", "(", "prefix", "+", "\".alignments\"", ",", "allgraphs", ")", "\n", "allalignments", "=", "a", ".", "alignments", "\n", "\n", "for", "graph", ",", "alignments", ",", "depslines", ",", "tokens", ",", "pos", ",", "lemmas", ",", "nes", "in", "zip", "(", "allgraphs", ",", "allalignments", ",", "alldepslines", ",", "alltokens", ",", "allpos", ",", "alllemmas", ",", "allnes", ")", ":", "\n", "                ", "graph", "=", "graph", ".", "strip", "(", ")", "\n", "amr", "=", "amrannot", ".", "AMR", ".", "parse_AMR_line", "(", "graph", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ",", "False", ")", "\n", "variables", "=", "{", "}", "\n", "for", "n", ",", "v", "in", "zip", "(", "amr", ".", "nodes", ",", "amr", ".", "node_values", ")", ":", "\n", "                    ", "variables", "[", "n", "]", "=", "v", "\n", "", "role_triples", "=", "amr", ".", "get_triples3", "(", ")", "\n", "relations", "=", "[", "]", "\n", "for", "(", "var1", ",", "label", ",", "var2", ")", "in", "role_triples", ":", "\n", "                    ", "if", "label", "==", "\"TOP\"", ":", "\n", "                        ", "relations", ".", "append", "(", "(", "\"TOP\"", ",", "\":top\"", ",", "var1", ")", ")", "\n", "", "else", ":", "\n", "                        ", "relations", ".", "append", "(", "(", "str", "(", "var1", ")", ",", "\":\"", "+", "str", "(", "label", ")", ",", "str", "(", "var2", ")", ")", ")", "\n", "", "", "dependencies", "=", "[", "]", "\n", "for", "line", "in", "depslines", ".", "split", "(", "\"\\n\"", ")", ":", "\n", "                    ", "pattern", "=", "\"^(.+)\\(.+-([0-9]+), .+-([0-9]+)\\)\"", "\n", "regex", "=", "re", ".", "match", "(", "pattern", ",", "line", ")", "\n", "if", "regex", "is", "not", "None", ":", "\n", "                        ", "label", "=", "regex", ".", "group", "(", "1", ")", "\n", "a", "=", "int", "(", "regex", ".", "group", "(", "2", ")", ")", "-", "1", "\n", "b", "=", "int", "(", "regex", ".", "group", "(", "3", ")", ")", "-", "1", "\n", "if", "a", "==", "-", "1", ":", "\n", "                            ", "dependencies", ".", "append", "(", "(", "b", ",", "'ROOT'", ",", "b", ")", ")", "\n", "", "elif", "a", "!=", "b", ":", "\n", "                            ", "dependencies", ".", "append", "(", "(", "a", ",", "label", ",", "b", ")", ")", "\n", "", "", "", "self", ".", "sentences", ".", "append", "(", "AMRSentence", "(", "tokens", ",", "pos", ",", "lemmas", ",", "nes", ",", "dependencies", ",", "variables", ",", "relations", ",", "graph", ",", "alignments", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "depslines", ",", "tokens", ",", "pos", ",", "lemmas", ",", "nes", "in", "zip", "(", "alldepslines", ",", "alltokens", ",", "allpos", ",", "alllemmas", ",", "allnes", ")", ":", "\n", "                ", "dependencies", "=", "[", "]", "\n", "for", "line", "in", "depslines", ".", "split", "(", "\"\\n\"", ")", ":", "\n", "                    ", "pattern", "=", "\"^(.+)\\(.+-([0-9]+), .+-([0-9]+)\\)\"", "\n", "regex", "=", "re", ".", "match", "(", "pattern", ",", "line", ")", "\n", "if", "regex", "is", "not", "None", ":", "\n", "                        ", "label", "=", "regex", ".", "group", "(", "1", ")", "\n", "a", "=", "int", "(", "regex", ".", "group", "(", "2", ")", ")", "-", "1", "\n", "b", "=", "int", "(", "regex", ".", "group", "(", "3", ")", ")", "-", "1", "\n", "if", "a", "==", "-", "1", ":", "\n", "                            ", "dependencies", ".", "append", "(", "(", "b", ",", "'ROOT'", ",", "b", ")", ")", "\n", "", "elif", "a", "!=", "b", ":", "\n", "                            ", "dependencies", ".", "append", "(", "(", "a", ",", "label", ",", "b", ")", ")", "\n", "", "", "", "self", ".", "sentences", ".", "append", "(", "AMRSentence", "(", "tokens", ",", "pos", ",", "lemmas", ",", "nes", ",", "dependencies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amrdata.AMRDataset.getSent": [[90, 92], ["None"], "methods", ["None"], ["", "", "", "def", "getSent", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "sentences", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amrdata.AMRDataset.getAllSents": [[93, 95], ["None"], "methods", ["None"], ["", "def", "getAllSents", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.amrdata.AMRDataset._loadFromFile": [[96, 216], ["open().read().split", "open().read().split.pop().strip().split", "block[].startswith", "allpos.append", "blocks[].startswith", "alltokens.append", "alllemmas.append", "allnes.append", "alldepslines.append", "zip", "alltokens.append", "alllemmas.append", "allnes.append", "alldepslines.append", "open().read", "len", "tokens.extend", "pos.extend", "lemmas.extend", "nes.extend", "open().read().split.pop", "ne.split", "open().read().split.pop().strip", "len", "re.match", "tokens2.append", "lemmas2.append", "nes2.append", "open", "[].encode", "re.match", "curr.replace().replace().replace().replace.replace().replace().replace().replace.replace().replace().replace().replace", "re.match", "lemmas2.append", "nes2.append", "open().read().split.pop", "re.findall", "re.findall", "re.findall", "re.findall", "len", "re.match.groups", "re.match.groups", "[].replace().replace().replace().replace", "[].replace().replace().replace().replace.startswith", "format", "re.sub", "token.endswith", "re.sub", "tokens2.append", "tokens2.append", "re.match", "tokens2.append", "lemmas2.append", "nes2.append", "tokens2.append", "lemmas2.append", "nes2.append", "curr.replace().replace().replace().replace.replace().replace().replace().replace.replace().replace().replace", "[].replace().replace().replace().replace.startswith", "re.match.groups", "token.replace().replace().isdigit", "len", "re.match", "str", "token.endswith", "re.sub", "[].replace().replace().replace", "[].replace().replace().replace().replace.startswith", "int", "float", "float", "re.match.groups", "token.replace().replace().isdigit", "curr.replace().replace().replace().replace.replace().replace().replace().replace.replace().replace", "[].replace().replace().replace().replace.startswith", "token.replace().replace", "int", "float", "int", "[].replace().replace", "re.match.groups", "token.replace().replace", "curr.replace().replace().replace().replace.replace().replace().replace().replace.replace", "token.replace", "re.match.groups", "[].replace", "token.replace"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode", "home.repos.pwc.inspect_result.chenllliang_atp.zeshel.create_BLINK_zeshel_data.LogFormatter.format"], ["", "def", "_loadFromFile", "(", "self", ",", "stanfordOutput", ",", "norm", "=", "True", ")", ":", "\n", "        ", "alltokens", "=", "[", "]", "\n", "allpos", "=", "[", "]", "\n", "alllemmas", "=", "[", "]", "\n", "allnes", "=", "[", "]", "\n", "alldepslines", "=", "[", "]", "\n", "blocks", "=", "open", "(", "stanfordOutput", ",", "'r'", ")", ".", "read", "(", ")", ".", "split", "(", "\"\\n\\n\"", ")", "\n", "while", "True", ":", "\n", "            ", "if", "len", "(", "blocks", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "block", "=", "blocks", ".", "pop", "(", "0", ")", ".", "strip", "(", ")", ".", "split", "(", "\"\\n\"", ")", "\n", "tokens", "=", "[", "]", "\n", "lemmas", "=", "[", "]", "\n", "nes", "=", "[", "]", "\n", "pos", "=", "[", "]", "\n", "i", "=", "2", "\n", "while", "block", "[", "i", "]", ".", "startswith", "(", "\"[Text\"", ")", ":", "\n", "                ", "tokens", ".", "extend", "(", "[", "t", "[", "5", ":", "-", "1", "]", "for", "t", "in", "re", ".", "findall", "(", "'Text=[^\\s]* '", ",", "block", "[", "i", "]", ")", "]", ")", "\n", "pos", ".", "extend", "(", "[", "t", "[", "13", ":", "-", "1", "]", "for", "t", "in", "re", ".", "findall", "(", "'PartOfSpeech=[^\\s]* '", ",", "block", "[", "i", "]", ")", "]", ")", "\n", "lemmas", ".", "extend", "(", "[", "t", "[", "6", ":", "-", "1", "]", "for", "t", "in", "re", ".", "findall", "(", "'Lemma=[^\\s]* '", ",", "block", "[", "i", "]", ")", "]", ")", "\n", "nes", ".", "extend", "(", "[", "t", "[", "15", ":", "]", "for", "t", "in", "re", ".", "findall", "(", "'NamedEntityTag=[^\\]]*'", ",", "block", "[", "i", "]", ")", "]", ")", "\n", "i", "+=", "1", "\n", "", "allpos", ".", "append", "(", "pos", ")", "\n", "if", "blocks", "[", "0", "]", ".", "startswith", "(", "\"\\n\"", ")", ":", "\n", "                ", "b", "=", "\"\"", "\n", "", "else", ":", "\n", "                ", "b", "=", "blocks", ".", "pop", "(", "0", ")", "\n", "", "depslines", "=", "b", "\n", "alltokens", ".", "append", "(", "tokens", ")", "\n", "alllemmas", ".", "append", "(", "lemmas", ")", "\n", "allnes", ".", "append", "(", "nes", ")", "\n", "alldepslines", ".", "append", "(", "depslines", ")", "\n", "continue", "# don't need this part of evaluation....", "\n", "\n", "#very messy piece of code to handle corenlp normalization (for dates, currencies, etc)", "\n", "tokens2", "=", "[", "]", "\n", "lemmas2", "=", "[", "]", "\n", "nes2", "=", "[", "]", "\n", "lastnorm", "=", "None", "\n", "for", "token", ",", "lemma", ",", "ne", "in", "zip", "(", "tokens", ",", "lemmas", ",", "nes", ")", ":", "\n", "                ", "nesplit", "=", "ne", ".", "split", "(", ")", "\n", "if", "len", "(", "nesplit", ")", ">", "1", ":", "\n", "                    ", "mne", "=", "re", ".", "match", "(", "\"^([a-zA-Z\\%\\>\\<\\$\\~\\=]*)([0-9\\.]*.*)\"", ",", "nesplit", "[", "1", "]", "[", "25", ":", "]", ".", "encode", "(", "'ascii'", ",", "'ignore'", ")", ")", "\n", "", "else", ":", "\n", "                    ", "mne", "=", "None", "\n", "\n", "", "if", "nesplit", "[", "0", "]", "==", "\"DATE\"", "and", "re", ".", "match", "(", "\"^(\\d{4}|XXXX)(-\\d{2})?(-\\d{2})?$\"", ",", "nesplit", "[", "1", "]", "[", "25", ":", "]", ")", "is", "not", "None", ":", "\n", "                    ", "norm", "=", "nesplit", "[", "1", "]", "[", "25", ":", "]", "\n", "lastnorm", "=", "norm", "\n", "tokens2", ".", "append", "(", "norm", ")", "\n", "lemmas2", ".", "append", "(", "norm", ")", "\n", "nes2", ".", "append", "(", "nesplit", "[", "0", "]", ")", "\n", "\n", "", "elif", "(", "nesplit", "[", "0", "]", "==", "\"MONEY\"", "or", "nesplit", "[", "0", "]", "==", "\"PERCENT\"", ")", "and", "self", ".", "normalize", "and", "len", "(", "nesplit", ")", "==", "2", "and", "mne", "is", "not", "None", ":", "\n", "                    ", "[", "name", ",", "norm", "]", "=", "nesplit", "\n", "curr", "=", "mne", ".", "groups", "(", ")", "[", "0", "]", "\n", "norm", "=", "mne", ".", "groups", "(", ")", "[", "1", "]", "\n", "curr", "=", "curr", ".", "replace", "(", "\"<\"", ",", "\"\"", ")", ".", "replace", "(", "\">\"", ",", "\"\"", ")", ".", "replace", "(", "\"~\"", ",", "\"\"", ")", ".", "replace", "(", "\"=\"", ",", "\"\"", ")", "\n", "if", "curr", "==", "\"$\"", ":", "\n", "                        ", "curr", "=", "\"dollar\"", "\n", "", "if", "curr", "==", "\"\"", ":", "\n", "                        ", "w", "=", "nesplit", "[", "1", "]", "[", "25", ":", "]", ".", "replace", "(", "\"<\"", ",", "\"\"", ")", ".", "replace", "(", "\">\"", ",", "\"\"", ")", ".", "replace", "(", "\"~\"", ",", "\"\"", ")", ".", "replace", "(", "\"=\"", ",", "\"\"", ")", "\n", "if", "w", ".", "startswith", "(", "u\"\\u00A5\"", ")", ":", "\n", "                            ", "curr", "=", "\"yen\"", "\n", "", "elif", "w", ".", "startswith", "(", "u\"\\u5143\"", ")", ":", "\n", "                            ", "curr", "=", "\"yuan\"", "\n", "", "elif", "w", ".", "startswith", "(", "u\"\\u00A3\"", ")", ":", "\n", "                            ", "curr", "=", "\"pound\"", "\n", "", "elif", "w", ".", "startswith", "(", "u\"\\u20AC\"", ")", ":", "\n", "                            ", "curr", "=", "\"euro\"", "\n", "", "else", ":", "\n", "                            ", "curr", "=", "\"NULL\"", "\n", "\n", "", "", "m", "=", "re", ".", "match", "(", "\"([0-9\\.][0-9\\.]*)E([0-9][0-9]*)$\"", ",", "norm", ")", "\n", "if", "m", "is", "not", "None", ":", "\n", "                        ", "n", "=", "m", ".", "groups", "(", ")", "[", "0", "]", "\n", "z", "=", "\"\"", ".", "join", "(", "[", "\"0\"", "]", "*", "int", "(", "m", ".", "groups", "(", ")", "[", "1", "]", ")", ")", "\n", "norm", "=", "format", "(", "float", "(", "n", ")", "*", "float", "(", "\"1\"", "+", "z", ")", ",", "\".32f\"", ")", "\n", "norm", "=", "re", ".", "sub", "(", "\"\\.00*$\"", ",", "\"\"", ",", "norm", ")", "\n", "", "if", "token", ".", "endswith", "(", "\".0\"", ")", "==", "False", ":", "\n", "                        ", "norm", "=", "re", ".", "sub", "(", "\"\\.0$\"", ",", "\"\"", ",", "norm", ")", "\n", "", "if", "token", ".", "replace", "(", "\",\"", ",", "\"\"", ")", ".", "replace", "(", "\".\"", ",", "\"\"", ")", ".", "isdigit", "(", ")", "==", "False", "and", "lastnorm", "is", "not", "None", ":", "\n", "                        ", "norm", "=", "\",\"", "\n", "token", "=", "\",\"", "\n", "name", "=", "\"O\"", "\n", "", "lastnorm", "=", "norm", "\n", "if", "norm", "==", "\",\"", ":", "\n", "                        ", "tokens2", ".", "append", "(", "norm", ")", "\n", "", "else", ":", "\n", "                        ", "tokens2", ".", "append", "(", "norm", "+", "\"_\"", "+", "curr", ")", "\n", "", "lemmas2", ".", "append", "(", "token", ")", "\n", "nes2", ".", "append", "(", "name", ")", "\n", "", "elif", "self", ".", "normalize", "and", "len", "(", "nesplit", ")", "==", "2", "and", "re", ".", "match", "(", "\"^[0-9].*\"", ",", "nesplit", "[", "1", "]", "[", "25", ":", "]", ")", "is", "not", "None", ":", "#numbers", "\n", "                    ", "[", "name", ",", "norm", "]", "=", "nesplit", "\n", "norm", "=", "norm", "[", "25", ":", "]", "\n", "m", "=", "re", ".", "match", "(", "\"([0-9\\.][0-9\\.]*)E([0-9][0-9]*)$\"", ",", "norm", ")", "\n", "if", "m", "is", "not", "None", ":", "\n", "                        ", "n", "=", "m", ".", "groups", "(", ")", "[", "0", "]", "\n", "z", "=", "\"\"", ".", "join", "(", "[", "\"0\"", "]", "*", "int", "(", "m", ".", "groups", "(", ")", "[", "1", "]", ")", ")", "\n", "norm", "=", "str", "(", "float", "(", "n", ")", "*", "int", "(", "\"1\"", "+", "z", ")", ")", "\n", "", "if", "token", ".", "endswith", "(", "\".0\"", ")", "==", "False", ":", "\n", "                        ", "norm", "=", "re", ".", "sub", "(", "\"\\.0$\"", ",", "\"\"", ",", "norm", ")", "\n", "", "if", "token", ".", "replace", "(", "\",\"", ",", "\"\"", ")", ".", "replace", "(", "\".\"", ",", "\"\"", ")", ".", "isdigit", "(", ")", "==", "False", "and", "lastnorm", "is", "not", "None", ":", "\n", "                        ", "norm", "=", "\",\"", "\n", "token", "=", "\",\"", "\n", "name", "=", "\"O\"", "\n", "", "lastnorm", "=", "norm", "\n", "tokens2", ".", "append", "(", "norm", ")", "\n", "lemmas2", ".", "append", "(", "token", ")", "\n", "nes2", ".", "append", "(", "name", ")", "\n", "", "else", ":", "\n", "                    ", "lastnorm", "=", "None", "\n", "tokens2", ".", "append", "(", "token", ")", "\n", "lemmas2", ".", "append", "(", "lemma", ")", "\n", "nes2", ".", "append", "(", "nesplit", "[", "0", "]", ")", "\n", "", "", "alltokens", ".", "append", "(", "tokens2", ")", "\n", "alllemmas", ".", "append", "(", "lemmas2", ")", "\n", "allnes", ".", "append", "(", "nes2", ")", "\n", "alldepslines", ".", "append", "(", "depslines", ")", "\n", "", "return", "(", "alltokens", ",", "allpos", ",", "alllemmas", ",", "allnes", ",", "alldepslines", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.utils.disambig": [[8, 18], ["lst2.append", "str", "str", "str"], "function", ["None"], ["import", "json", "\n", "import", "os", "\n", "import", "pickle", "\n", "\n", "from", "segtok", ".", "segmenter", "import", "split_multi", "\n", "\n", "##### Reading helpers #####", "\n", "def", "read_sentences_from_file", "(", "path_to_file", ",", "one_sentence_per_line", "=", "True", ")", ":", "\n", "    ", "lines", "=", "[", "]", "\n", "with", "io", ".", "open", "(", "path_to_file", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "file", ":", "\n", "        ", "for", "line", "in", "file", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.utils.concepts": [[19, 21], ["str", "v2c_dict.values"], "function", ["None"], ["            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "!=", "\"\"", ":", "\n", "                ", "lines", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.utils.namedent": [[22, 24], ["str"], "function", ["None"], ["\n", "", "", "", "if", "one_sentence_per_line", ":", "\n", "        ", "sentences", "=", "lines", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.utils.negations": [[25, 27], ["None"], "function", ["None"], ["", "else", ":", "\n", "        ", "text", "=", "\" \"", ".", "join", "(", "lines", ")", "\n", "sentences", "=", "list", "(", "split_multi", "(", "text", ")", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.utils.wikification": [[28, 30], ["None"], "function", ["None"], ["sentences", "=", "[", "sentence", "for", "sentence", "in", "sentences", "if", "sentence", "!=", "\"\"", "]", "\n", "\n", "", "return", "sentences", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.utils.reentrancies": [[31, 47], ["v2c_dict.keys", "len", "lst.append", "vrs.extend"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend"], ["\n", "\n", "##### Printing / writing  helpers #####", "\n", "", "def", "get_candidate_summary", "(", "candidate", ")", ":", "\n", "    ", "wikipedia_id", "=", "candidate", "[", "\"wikipedia_id\"", "]", "\n", "wikidata_id", "=", "candidate", "[", "\"wikidata_id\"", "]", "\n", "wikipedia_title", "=", "candidate", "[", "\"wikipedia_title\"", "]", "\n", "\n", "return", "\"{}, {}, {}\"", ".", "format", "(", "wikipedia_id", ",", "wikidata_id", ",", "wikipedia_title", ")", "\n", "\n", "\n", "", "def", "present_sentence_mentions", "(", "sentence", ",", "mentions", ",", "output_file", ")", ":", "\n", "    ", "if", "output_file", "!=", "None", ":", "\n", "        ", "f", "=", "io", ".", "open", "(", "output_file", ",", "mode", "=", "\"a\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "output", "=", "lambda", "s", ":", "f", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "s", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "lambda", "s", ":", "print", "(", "s", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.utils.srl": [[48, 69], ["t[].startswith", "t[].endswith", "lst.append", "vrs.extend", "lst.append", "vrs.extend"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend"], ["", "output", "(", "\"Sentence: {}\"", ".", "format", "(", "sentence", ")", ")", "\n", "\n", "mention_entity_pairs", "=", "[", "]", "\n", "for", "mention", "in", "mentions", ":", "\n", "        ", "candidates", "=", "mention", "[", "\"candidates\"", "]", "\n", "# prediction = mention.get('predicted_candidate_idx', 0)", "\n", "prediction", "=", "mention", "[", "\"predicted_candidate_idx\"", "]", "\n", "\n", "if", "prediction", "<", "len", "(", "candidates", ")", ":", "\n", "# print(type(mention['prob_assigned_to_candidate']))", "\n", "# print(mention['prob_assigned_to_candidate'])", "\n", "            ", "mention_rep", "=", "\"{} ({}, {}) - {} (conf. {:.5f})\"", ".", "format", "(", "\n", "mention", "[", "\"text\"", "]", ",", "\n", "mention", "[", "\"start_pos\"", "]", ",", "\n", "mention", "[", "\"end_pos\"", "]", ",", "\n", "get_candidate_summary", "(", "candidates", "[", "prediction", "]", ")", ",", "\n", "mention", "[", "\"prob_assigned_to_candidate\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "mention_rep", "=", "\"{} ({}, {}) - {}\"", ".", "format", "(", "\n", "mention", "[", "\"text\"", "]", ",", "\n", "mention", "[", "\"start_pos\"", "]", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr-evaluation.utils.var2concept": [[70, 75], ["zip"], "function", ["None"], ["mention", "[", "\"end_pos\"", "]", ",", "\n", "\"No candidate selected\"", ",", "\n", ")", "\n", "\n", "", "mention_entity_pairs", ".", "append", "(", "mention_rep", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.parse_relations": [[43, 86], ["collections.defaultdict", "collections.defaultdict", "amr.AMR", "relation_list.append", "attribute_list.append", "len", "attribute_list[].append", "var_list.append", "conc_list.append", "var_list.append", "conc_list.append", "node_relation_dict1[].append", "str", "str", "str", "str", "str", "str", "str", "node_relation_dict2[].append", "node_rel_list.append", "str", "str", "node_attr_list.append", "str", "str", "node_rel_list.append", "node_attr_list.append", "str", "str"], "function", ["None"], ["def", "parse_relations", "(", "rels", ",", "v2c", ")", ":", "\n", "    ", "var_list", "=", "[", "]", "\n", "conc_list", "=", "[", "]", "\n", "node_relation_dict1", "=", "defaultdict", "(", "list", ")", "\n", "node_relation_dict2", "=", "defaultdict", "(", "list", ")", "\n", "for", "r", "in", "rels", ":", "\n", "        ", "if", "str", "(", "r", "[", "1", "]", ")", "not", "in", "var_list", "and", "str", "(", "r", "[", "1", "]", ")", "!=", "\"TOP\"", "and", "r", "[", "1", "]", "in", "v2c", ":", "\n", "            ", "var_list", ".", "append", "(", "str", "(", "r", "[", "1", "]", ")", ")", "\n", "conc_list", ".", "append", "(", "str", "(", "v2c", "[", "r", "[", "1", "]", "]", ")", ")", "\n", "", "if", "str", "(", "r", "[", "2", "]", ")", "not", "in", "var_list", "and", "r", "[", "2", "]", "in", "v2c", ":", "\n", "            ", "var_list", ".", "append", "(", "str", "(", "r", "[", "2", "]", ")", ")", "\n", "conc_list", ".", "append", "(", "str", "(", "v2c", "[", "r", "[", "2", "]", "]", ")", ")", "\n", "", "if", "r", "[", "2", "]", "in", "v2c", "and", "r", "[", "1", "]", "!=", "\"TOP\"", ":", "\n", "            ", "node_relation_dict1", "[", "str", "(", "r", "[", "1", "]", ")", "]", ".", "append", "(", "(", "str", "(", "r", "[", "0", "]", ")", ",", "str", "(", "r", "[", "2", "]", ")", ")", ")", "\n", "", "elif", "r", "[", "2", "]", "not", "in", "v2c", ":", "\n", "            ", "node_relation_dict2", "[", "str", "(", "r", "[", "1", "]", ")", "]", ".", "append", "(", "(", "str", "(", "r", "[", "0", "]", ")", ",", "str", "(", "r", "[", "2", "]", ")", ")", ")", "\n", "", "", "relation_list", "=", "[", "]", "\n", "attribute_list", "=", "[", "]", "\n", "for", "v", "in", "var_list", ":", "\n", "        ", "node_rel_list", "=", "[", "]", "\n", "node_attr_list", "=", "[", "]", "\n", "if", "v", "in", "node_relation_dict1", ":", "\n", "            ", "for", "v1", "in", "node_relation_dict1", "[", "v", "]", ":", "\n", "                ", "node_rel_list", ".", "append", "(", "[", "v1", "[", "0", "]", ",", "v1", "[", "1", "]", "]", ")", "\n", "", "", "if", "v", "in", "node_relation_dict2", ":", "\n", "            ", "for", "v2", "in", "node_relation_dict2", "[", "v", "]", ":", "\n", "# if value is in quote, it is a constant value", "\n", "# strip the quote and put it in attribute map", "\n", "                ", "if", "v2", "[", "1", "]", "[", "0", "]", "==", "\"\\\"\"", "and", "v2", "[", "1", "]", "[", "-", "1", "]", "==", "\"\\\"\"", ":", "\n", "                    ", "node_attr_list", ".", "append", "(", "[", "[", "v2", "[", "0", "]", "]", ",", "v2", "[", "1", "]", "[", "1", ":", "-", "1", "]", "]", ")", "\n", "# if value is a node name", "\n", "", "elif", "v2", "[", "1", "]", "in", "v2c", ":", "\n", "                    ", "node_rel_list", ".", "append", "(", "[", "v2", "[", "0", "]", ",", "v2", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "                    ", "node_attr_list", ".", "append", "(", "[", "v2", "[", "0", "]", ",", "v2", "[", "1", "]", "]", ")", "\n", "# each node has a relation list and attribute list", "\n", "", "", "", "relation_list", ".", "append", "(", "node_rel_list", ")", "\n", "attribute_list", ".", "append", "(", "node_attr_list", ")", "\n", "# add TOP as an attribute. The attribute value is the top node value", "\n", "", "if", "len", "(", "conc_list", ")", ">", "0", ":", "\n", "        ", "attribute_list", "[", "0", "]", ".", "append", "(", "[", "\"TOP\"", ",", "conc_list", "[", "0", "]", "]", ")", "\n", "", "result_amr", "=", "amr", ".", "AMR", "(", "var_list", ",", "conc_list", ",", "relation_list", ",", "attribute_list", ")", "\n", "return", "result_amr", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.get_best_match": [[87, 156], ["smatch_fromlists.compute_pool", "range", "print", "print", "print", "print", "len", "smatch_fromlists.compute_match", "print", "smatch_fromlists.smart_init_mapping", "smatch_fromlists.random_init_mapping", "print", "print", "smatch_fromlists.get_best_gain", "len", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_pool", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.smart_init_mapping", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.random_init_mapping", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_gain", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "get_best_match", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "True", ",", "doattribute", "=", "True", ",", "dorelation", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Get the highest triple match number between two sets of triples via hill-climbing.\n    Arguments:\n        instance1: instance triples of AMR 1 (\"instance\", node name, node value)\n        attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n        relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n        instance2: instance triples of AMR 2 (\"instance\", node name, node value)\n        attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n        relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name)\n        prefix1: prefix label for AMR 1\n        prefix2: prefix label for AMR 2\n    Returns:\n        best_match: the node mapping that results in the highest triple matching number\n        best_match_num: the highest triple matching number\n\n    \"\"\"", "\n", "# Compute candidate pool - all possible node match candidates.", "\n", "# In the hill-climbing, we only consider candidate in this pool to save computing time.", "\n", "# weight_dict is a dictionary that maps a pair of node", "\n", "(", "candidate_mappings", ",", "weight_dict", ")", "=", "compute_pool", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "doinstance", ",", "doattribute", "=", "doattribute", ",", "\n", "dorelation", "=", "dorelation", ")", "\n", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Candidate mappings:\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "candidate_mappings", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Weight dictionary\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "weight_dict", ",", "file", "=", "DEBUG_LOG", ")", "\n", "\n", "", "best_match_num", "=", "0", "\n", "# initialize best match mapping", "\n", "# the ith entry is the node index in AMR 2 which maps to the ith node in AMR 1", "\n", "best_mapping", "=", "[", "-", "1", "]", "*", "len", "(", "instance1", ")", "\n", "for", "i", "in", "range", "(", "iteration_num", ")", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"Iteration\"", ",", "i", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "i", "==", "0", ":", "\n", "# smart initialization used for the first round", "\n", "            ", "cur_mapping", "=", "smart_init_mapping", "(", "candidate_mappings", ",", "instance1", ",", "instance2", ")", "\n", "", "else", ":", "\n", "# random initialization for the other round", "\n", "            ", "cur_mapping", "=", "random_init_mapping", "(", "candidate_mappings", ")", "\n", "# compute current triple match number", "\n", "", "match_num", "=", "compute_match", "(", "cur_mapping", ",", "weight_dict", ")", "\n", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"Node mapping at start\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Triple match number at start:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "while", "True", ":", "\n", "# get best gain", "\n", "            ", "(", "gain", ",", "new_mapping", ")", "=", "get_best_gain", "(", "cur_mapping", ",", "candidate_mappings", ",", "weight_dict", ",", "\n", "len", "(", "instance2", ")", ",", "match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Gain after the hill-climbing\"", ",", "gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# hill-climbing until there will be no gain for new node mapping", "\n", "", "if", "gain", "<=", "0", ":", "\n", "                ", "break", "\n", "# otherwise update match_num and mapping", "\n", "", "match_num", "+=", "gain", "\n", "cur_mapping", "=", "new_mapping", "[", ":", "]", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Update triple match number to:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Current mapping:\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "if", "match_num", ">", "best_match_num", ":", "\n", "            ", "best_mapping", "=", "cur_mapping", "[", ":", "]", "\n", "best_match_num", "=", "match_num", "\n", "", "", "return", "best_mapping", ",", "best_match_num", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.normalize": [[158, 163], ["item.lower().rstrip", "item.lower"], "function", ["None"], ["", "def", "normalize", "(", "item", ")", ":", "\n", "    ", "\"\"\"\n    lowercase and remove quote signifiers from items that are about to be compared\n    \"\"\"", "\n", "return", "item", ".", "lower", "(", ")", ".", "rstrip", "(", "'_'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.compute_pool": [[165, 273], ["candidate_mapping.append", "set", "int", "int", "candidate_mapping[].add", "int", "int", "candidate_mapping[].add", "smatch_fromlists.normalize", "smatch_fromlists.normalize", "int", "int", "int", "int", "candidate_mapping[].add", "candidate_mapping[].add", "smatch_fromlists.normalize", "smatch_fromlists.normalize", "smatch_fromlists.normalize", "smatch_fromlists.normalize", "smatch_fromlists.normalize", "smatch_fromlists.normalize", "smatch_fromlists.normalize", "smatch_fromlists.normalize", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize"], ["", "def", "compute_pool", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "True", ",", "doattribute", "=", "True", ",", "dorelation", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    compute all possible node mapping candidates and their weights (the triple matching number gain resulting from\n    mapping one node in AMR 1 to another node in AMR2)\n\n    Arguments:\n        instance1: instance triples of AMR 1\n        attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n        relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n        instance2: instance triples of AMR 2\n        attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n        relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name\n        prefix1: prefix label for AMR 1\n        prefix2: prefix label for AMR 2\n    Returns:\n      candidate_mapping: a list of candidate nodes.\n                       The ith element contains the node indices (in AMR 2) the ith node (in AMR 1) can map to.\n                       (resulting in non-zero triple match)\n      weight_dict: a dictionary which contains the matching triple number for every pair of node mapping. The key\n                   is a node pair. The value is another dictionary. key {-1} is triple match resulting from this node\n                   pair alone (instance triples and attribute triples), and other keys are node pairs that can result\n                   in relation triple match together with the first node pair.\n\n\n    \"\"\"", "\n", "candidate_mapping", "=", "[", "]", "\n", "weight_dict", "=", "{", "}", "\n", "for", "instance1_item", "in", "instance1", ":", "\n", "# each candidate mapping is a set of node indices", "\n", "        ", "candidate_mapping", ".", "append", "(", "set", "(", ")", ")", "\n", "if", "doinstance", ":", "\n", "            ", "for", "instance2_item", "in", "instance2", ":", "\n", "# if both triples are instance triples and have the same value", "\n", "                ", "if", "normalize", "(", "instance1_item", "[", "0", "]", ")", "==", "normalize", "(", "instance2_item", "[", "0", "]", ")", "and", "normalize", "(", "instance1_item", "[", "2", "]", ")", "==", "normalize", "(", "instance2_item", "[", "2", "]", ")", ":", "\n", "# get node index by stripping the prefix", "\n", "                    ", "node1_index", "=", "int", "(", "instance1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index", "=", "int", "(", "instance2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "candidate_mapping", "[", "node1_index", "]", ".", "add", "(", "node2_index", ")", "\n", "node_pair", "=", "(", "node1_index", ",", "node2_index", ")", "\n", "# use -1 as key in weight_dict for instance triples and attribute triples", "\n", "if", "node_pair", "in", "weight_dict", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "=", "1", "\n", "", "", "", "", "", "if", "doattribute", ":", "\n", "        ", "for", "attribute1_item", "in", "attribute1", ":", "\n", "            ", "for", "attribute2_item", "in", "attribute2", ":", "\n", "# if both attribute relation triple have the same relation name and value", "\n", "                ", "if", "normalize", "(", "attribute1_item", "[", "0", "]", ")", "==", "normalize", "(", "attribute2_item", "[", "0", "]", ")", "and", "normalize", "(", "attribute1_item", "[", "2", "]", ")", "==", "normalize", "(", "attribute2_item", "[", "2", "]", ")", ":", "\n", "                    ", "node1_index", "=", "int", "(", "attribute1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index", "=", "int", "(", "attribute2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "candidate_mapping", "[", "node1_index", "]", ".", "add", "(", "node2_index", ")", "\n", "node_pair", "=", "(", "node1_index", ",", "node2_index", ")", "\n", "# use -1 as key in weight_dict for instance triples and attribute triples", "\n", "if", "node_pair", "in", "weight_dict", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "=", "1", "\n", "", "", "", "", "", "if", "dorelation", ":", "\n", "        ", "for", "relation1_item", "in", "relation1", ":", "\n", "            ", "for", "relation2_item", "in", "relation2", ":", "\n", "# if both relation share the same name", "\n", "                ", "if", "normalize", "(", "relation1_item", "[", "0", "]", ")", "==", "normalize", "(", "relation2_item", "[", "0", "]", ")", ":", "\n", "                    ", "node1_index_amr1", "=", "int", "(", "relation1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node1_index_amr2", "=", "int", "(", "relation2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "node2_index_amr1", "=", "int", "(", "relation1_item", "[", "2", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index_amr2", "=", "int", "(", "relation2_item", "[", "2", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "# add mapping between two nodes", "\n", "candidate_mapping", "[", "node1_index_amr1", "]", ".", "add", "(", "node1_index_amr2", ")", "\n", "candidate_mapping", "[", "node2_index_amr1", "]", ".", "add", "(", "node2_index_amr2", ")", "\n", "node_pair1", "=", "(", "node1_index_amr1", ",", "node1_index_amr2", ")", "\n", "node_pair2", "=", "(", "node2_index_amr1", ",", "node2_index_amr2", ")", "\n", "if", "node_pair2", "!=", "node_pair1", ":", "\n", "# update weight_dict weight. Note that we need to update both entries for future search", "\n", "# i.e weight_dict[node_pair1][node_pair2]", "\n", "#     weight_dict[node_pair2][node_pair1]", "\n", "                        ", "if", "node1_index_amr1", ">", "node2_index_amr1", ":", "\n", "# swap node_pair1 and node_pair2", "\n", "                            ", "node_pair1", "=", "(", "node2_index_amr1", ",", "node2_index_amr2", ")", "\n", "node_pair2", "=", "(", "node1_index_amr1", ",", "node1_index_amr2", ")", "\n", "", "if", "node_pair1", "in", "weight_dict", ":", "\n", "                            ", "if", "node_pair2", "in", "weight_dict", "[", "node_pair1", "]", ":", "\n", "                                ", "weight_dict", "[", "node_pair1", "]", "[", "node_pair2", "]", "+=", "1", "\n", "", "else", ":", "\n", "                                ", "weight_dict", "[", "node_pair1", "]", "[", "node_pair2", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "=", "{", "-", "1", ":", "0", ",", "node_pair2", ":", "1", "}", "\n", "", "if", "node_pair2", "in", "weight_dict", ":", "\n", "                            ", "if", "node_pair1", "in", "weight_dict", "[", "node_pair2", "]", ":", "\n", "                                ", "weight_dict", "[", "node_pair2", "]", "[", "node_pair1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                                ", "weight_dict", "[", "node_pair2", "]", "[", "node_pair1", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair2", "]", "=", "{", "-", "1", ":", "0", ",", "node_pair1", ":", "1", "}", "\n", "", "", "else", ":", "\n", "# two node pairs are the same. So we only update weight_dict once.", "\n", "# this generally should not happen.", "\n", "                        ", "if", "node_pair1", "in", "weight_dict", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "=", "{", "-", "1", ":", "1", "}", "\n", "", "", "", "", "", "", "return", "candidate_mapping", ",", "weight_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.smart_init_mapping": [[275, 324], ["random.seed", "enumerate", "list", "result.append", "len", "no_word_match.append", "result.append", "random.randint", "list.pop", "result.append", "len"], "function", ["None"], ["", "def", "smart_init_mapping", "(", "candidate_mapping", ",", "instance1", ",", "instance2", ")", ":", "\n", "    ", "\"\"\"\n    Initialize mapping based on the concept mapping (smart initialization)\n    Arguments:\n        candidate_mapping: candidate node match list\n        instance1: instance triples of AMR 1\n        instance2: instance triples of AMR 2\n    Returns:\n        initialized node mapping between two AMRs\n\n    \"\"\"", "\n", "random", ".", "seed", "(", ")", "\n", "matched_dict", "=", "{", "}", "\n", "result", "=", "[", "]", "\n", "# list to store node indices that have no concept match", "\n", "no_word_match", "=", "[", "]", "\n", "for", "i", ",", "candidates", "in", "enumerate", "(", "candidate_mapping", ")", ":", "\n", "        ", "if", "not", "candidates", ":", "\n", "# no possible mapping", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "continue", "\n", "# node value in instance triples of AMR 1", "\n", "", "value1", "=", "instance1", "[", "i", "]", "[", "2", "]", "\n", "for", "node_index", "in", "candidates", ":", "\n", "            ", "value2", "=", "instance2", "[", "node_index", "]", "[", "2", "]", "\n", "# find the first instance triple match in the candidates", "\n", "# instance triple match is having the same concept value", "\n", "if", "value1", "==", "value2", ":", "\n", "                ", "if", "node_index", "not", "in", "matched_dict", ":", "\n", "                    ", "result", ".", "append", "(", "node_index", ")", "\n", "matched_dict", "[", "node_index", "]", "=", "1", "\n", "break", "\n", "", "", "", "if", "len", "(", "result", ")", "==", "i", ":", "\n", "            ", "no_word_match", ".", "append", "(", "i", ")", "\n", "result", ".", "append", "(", "-", "1", ")", "\n", "# if no concept match, generate a random mapping", "\n", "", "", "for", "i", "in", "no_word_match", ":", "\n", "        ", "candidates", "=", "list", "(", "candidate_mapping", "[", "i", "]", ")", "\n", "while", "candidates", ":", "\n", "# get a random node index from candidates", "\n", "            ", "rid", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "candidates", ")", "-", "1", ")", "\n", "candidate", "=", "candidates", "[", "rid", "]", "\n", "if", "candidate", "in", "matched_dict", ":", "\n", "                ", "candidates", ".", "pop", "(", "rid", ")", "\n", "", "else", ":", "\n", "                ", "matched_dict", "[", "candidate", "]", "=", "1", "\n", "result", "[", "i", "]", "=", "candidate", "\n", "break", "\n", "", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.random_init_mapping": [[326, 361], ["random.seed", "list", "result.append", "random.randint", "result.append", "list.pop", "result.append", "len"], "function", ["None"], ["", "def", "random_init_mapping", "(", "candidate_mapping", ")", ":", "\n", "    ", "\"\"\"\n    Generate a random node mapping.\n    Args:\n        candidate_mapping: candidate_mapping: candidate node match list\n    Returns:\n        randomly-generated node mapping between two AMRs\n\n    \"\"\"", "\n", "# if needed, a fixed seed could be passed here to generate same random (to help debugging)", "\n", "random", ".", "seed", "(", ")", "\n", "matched_dict", "=", "{", "}", "\n", "result", "=", "[", "]", "\n", "for", "c", "in", "candidate_mapping", ":", "\n", "        ", "candidates", "=", "list", "(", "c", ")", "\n", "if", "not", "candidates", ":", "\n", "# -1 indicates no possible mapping", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "continue", "\n", "", "found", "=", "False", "\n", "while", "candidates", ":", "\n", "# randomly generate an index in [0, length of candidates)", "\n", "            ", "rid", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "candidates", ")", "-", "1", ")", "\n", "candidate", "=", "candidates", "[", "rid", "]", "\n", "# check if it has already been matched", "\n", "if", "candidate", "in", "matched_dict", ":", "\n", "                ", "candidates", ".", "pop", "(", "rid", ")", "\n", "", "else", ":", "\n", "                ", "matched_dict", "[", "candidate", "]", "=", "1", "\n", "result", ".", "append", "(", "candidate", ")", "\n", "found", "=", "True", "\n", "break", "\n", "", "", "if", "not", "found", ":", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.compute_match": [[363, 413], ["enumerate", "print", "print", "tuple", "print", "print", "print", "tuple", "tuple", "print", "tuple", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "compute_match", "(", "mapping", ",", "weight_dict", ")", ":", "\n", "    ", "\"\"\"\n    Given a node mapping, compute match number based on weight_dict.\n    Args:\n    mappings: a list of node index in AMR 2. The ith element (value j) means node i in AMR 1 maps to node j in AMR 2.\n    Returns:\n    matching triple number\n    Complexity: O(m*n) , m is the node number of AMR 1, n is the node number of AMR 2\n\n    \"\"\"", "\n", "# If this mapping has been investigated before, retrieve the value instead of re-computing.", "\n", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Computing match for mapping\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "tuple", "(", "mapping", ")", "in", "match_triple_dict", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"saved value\"", ",", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", "\n", "", "match_num", "=", "0", "\n", "# i is node index in AMR 1, m is node index in AMR 2", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "mapping", ")", ":", "\n", "        ", "if", "m", "==", "-", "1", ":", "\n", "# no node maps to this node", "\n", "            ", "continue", "\n", "# node i in AMR 1 maps to node m in AMR 2", "\n", "", "current_node_pair", "=", "(", "i", ",", "m", ")", "\n", "if", "current_node_pair", "not", "in", "weight_dict", ":", "\n", "            ", "continue", "\n", "", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"node_pair\"", ",", "current_node_pair", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "for", "key", "in", "weight_dict", "[", "current_node_pair", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "# matching triple resulting from instance/attribute triples", "\n", "                ", "match_num", "+=", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"instance/attribute match\"", ",", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# only consider node index larger than i to avoid duplicates", "\n", "# as we store both weight_dict[node_pair1][node_pair2] and", "\n", "#     weight_dict[node_pair2][node_pair1] for a relation", "\n", "", "", "elif", "key", "[", "0", "]", "<", "i", ":", "\n", "                ", "continue", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "match_num", "+=", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"relation match with\"", ",", "key", ",", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "", "", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"match computing complete, result:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# update match_triple_dict", "\n", "", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", "=", "match_num", "\n", "return", "match_num", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.move_gain": [[415, 459], ["tuple", "tuple", "tuple"], "function", ["None"], ["", "def", "move_gain", "(", "mapping", ",", "node_id", ",", "old_id", ",", "new_id", ",", "weight_dict", ",", "match_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the triple match number gain from the move operation\n    Arguments:\n        mapping: current node mapping\n        node_id: remapped node in AMR 1\n        old_id: original node id in AMR 2 to which node_id is mapped\n        new_id: new node in to which node_id is mapped\n        weight_dict: weight dictionary\n        match_num: the original triple matching number\n    Returns:\n        the triple match gain number (might be negative)\n\n    \"\"\"", "\n", "# new node mapping after moving", "\n", "new_mapping", "=", "(", "node_id", ",", "new_id", ")", "\n", "# node mapping before moving", "\n", "old_mapping", "=", "(", "node_id", ",", "old_id", ")", "\n", "# new nodes mapping list (all node pairs)", "\n", "new_mapping_list", "=", "mapping", "[", ":", "]", "\n", "new_mapping_list", "[", "node_id", "]", "=", "new_id", "\n", "# if this mapping is already been investigated, use saved one to avoid duplicate computing", "\n", "if", "tuple", "(", "new_mapping_list", ")", "in", "match_triple_dict", ":", "\n", "        ", "return", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "-", "match_num", "\n", "", "gain", "=", "0", "\n", "# add the triple match incurred by new_mapping to gain", "\n", "if", "new_mapping", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "# instance/attribute triple match", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping", "]", "[", "-", "1", "]", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "# relation gain incurred by new_mapping and another node pair in new_mapping_list", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping", "]", "[", "key", "]", "\n", "# deduct the triple match incurred by old_mapping from gain", "\n", "", "", "", "if", "old_mapping", "in", "weight_dict", ":", "\n", "        ", "for", "k", "in", "weight_dict", "[", "old_mapping", "]", ":", "\n", "            ", "if", "k", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping", "]", "[", "-", "1", "]", "\n", "", "elif", "mapping", "[", "k", "[", "0", "]", "]", "==", "k", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping", "]", "[", "k", "]", "\n", "# update match number dictionary", "\n", "", "", "", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "=", "match_num", "+", "gain", "\n", "return", "gain", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.swap_gain": [[461, 525], ["tuple", "tuple", "tuple"], "function", ["None"], ["", "def", "swap_gain", "(", "mapping", ",", "node_id1", ",", "mapping_id1", ",", "node_id2", ",", "mapping_id2", ",", "weight_dict", ",", "match_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the triple match number gain from the swapping\n    Arguments:\n    mapping: current node mapping list\n    node_id1: node 1 index in AMR 1\n    mapping_id1: the node index in AMR 2 node 1 maps to (in the current mapping)\n    node_id2: node 2 index in AMR 1\n    mapping_id2: the node index in AMR 2 node 2 maps to (in the current mapping)\n    weight_dict: weight dictionary\n    match_num: the original matching triple number\n    Returns:\n    the gain number (might be negative)\n\n    \"\"\"", "\n", "new_mapping_list", "=", "mapping", "[", ":", "]", "\n", "# Before swapping, node_id1 maps to mapping_id1, and node_id2 maps to mapping_id2", "\n", "# After swapping, node_id1 maps to mapping_id2 and node_id2 maps to mapping_id1", "\n", "new_mapping_list", "[", "node_id1", "]", "=", "mapping_id2", "\n", "new_mapping_list", "[", "node_id2", "]", "=", "mapping_id1", "\n", "if", "tuple", "(", "new_mapping_list", ")", "in", "match_triple_dict", ":", "\n", "        ", "return", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "-", "match_num", "\n", "", "gain", "=", "0", "\n", "new_mapping1", "=", "(", "node_id1", ",", "mapping_id2", ")", "\n", "new_mapping2", "=", "(", "node_id2", ",", "mapping_id1", ")", "\n", "old_mapping1", "=", "(", "node_id1", ",", "mapping_id1", ")", "\n", "old_mapping2", "=", "(", "node_id2", ",", "mapping_id2", ")", "\n", "if", "node_id1", ">", "node_id2", ":", "\n", "        ", "new_mapping2", "=", "(", "node_id1", ",", "mapping_id2", ")", "\n", "new_mapping1", "=", "(", "node_id2", ",", "mapping_id1", ")", "\n", "old_mapping1", "=", "(", "node_id2", ",", "mapping_id2", ")", "\n", "old_mapping2", "=", "(", "node_id1", ",", "mapping_id1", ")", "\n", "", "if", "new_mapping1", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping1", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping1", "]", "[", "-", "1", "]", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping1", "]", "[", "key", "]", "\n", "", "", "", "if", "new_mapping2", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping2", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping2", "]", "[", "-", "1", "]", "\n", "# to avoid duplicate", "\n", "", "elif", "key", "[", "0", "]", "==", "node_id1", ":", "\n", "                ", "continue", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping2", "]", "[", "key", "]", "\n", "", "", "", "if", "old_mapping1", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "old_mapping1", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping1", "]", "[", "-", "1", "]", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping1", "]", "[", "key", "]", "\n", "", "", "", "if", "old_mapping2", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "old_mapping2", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping2", "]", "[", "-", "1", "]", "\n", "# to avoid duplicate", "\n", "", "elif", "key", "[", "0", "]", "==", "node_id1", ":", "\n", "                ", "continue", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping2", "]", "[", "key", "]", "\n", "", "", "", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "=", "match_num", "+", "gain", "\n", "return", "gain", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.get_best_gain": [[527, 626], ["set", "enumerate", "enumerate", "range", "range", "print", "print", "set.remove", "len", "smatch_fromlists.swap_gain", "print", "smatch_fromlists.move_gain", "print", "print", "print", "print", "print", "print", "smatch_fromlists.compute_match", "print", "print", "print", "print", "smatch_fromlists.compute_match", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.swap_gain", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.move_gain", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "get_best_gain", "(", "mapping", ",", "candidate_mappings", ",", "weight_dict", ",", "instance_len", ",", "cur_match_num", ")", ":", "\n", "    ", "\"\"\"\n    Hill-climbing method to return the best gain swap/move can get\n    Arguments:\n    mapping: current node mapping\n    candidate_mappings: the candidates mapping list\n    weight_dict: the weight dictionary\n    instance_len: the number of the nodes in AMR 2\n    cur_match_num: current triple match number\n    Returns:\n    the best gain we can get via swap/move operation\n\n    \"\"\"", "\n", "largest_gain", "=", "0", "\n", "# True: using swap; False: using move", "\n", "use_swap", "=", "True", "\n", "# the node to be moved/swapped", "\n", "node1", "=", "None", "\n", "# store the other node affected. In swap, this other node is the node swapping with node1. In move, this other", "\n", "# node is the node node1 will move to.", "\n", "node2", "=", "None", "\n", "# unmatched nodes in AMR 2", "\n", "unmatched", "=", "set", "(", "range", "(", "instance_len", ")", ")", "\n", "# exclude nodes in current mapping", "\n", "# get unmatched nodes", "\n", "for", "nid", "in", "mapping", ":", "\n", "        ", "if", "nid", "in", "unmatched", ":", "\n", "            ", "unmatched", ".", "remove", "(", "nid", ")", "\n", "", "", "for", "i", ",", "nid", "in", "enumerate", "(", "mapping", ")", ":", "\n", "# current node i in AMR 1 maps to node nid in AMR 2", "\n", "        ", "for", "nm", "in", "unmatched", ":", "\n", "            ", "if", "nm", "in", "candidate_mappings", "[", "i", "]", ":", "\n", "# remap i to another unmatched node (move)", "\n", "# (i, m) -> (i, nm)", "\n", "                ", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"Remap node\"", ",", "i", ",", "\"from \"", ",", "nid", ",", "\"to\"", ",", "nm", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "mv_gain", "=", "move_gain", "(", "mapping", ",", "i", ",", "nid", ",", "nm", ",", "weight_dict", ",", "cur_match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"Move gain:\"", ",", "mv_gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_mapping", "=", "mapping", "[", ":", "]", "\n", "new_mapping", "[", "i", "]", "=", "nm", "\n", "new_match_num", "=", "compute_match", "(", "new_mapping", ",", "weight_dict", ")", "\n", "if", "new_match_num", "!=", "cur_match_num", "+", "mv_gain", ":", "\n", "                        ", "print", "(", "mapping", ",", "new_mapping", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Inconsistency in computing: move gain\"", ",", "cur_match_num", ",", "mv_gain", ",", "new_match_num", ",", "\n", "file", "=", "ERROR_LOG", ")", "\n", "", "", "if", "mv_gain", ">", "largest_gain", ":", "\n", "                    ", "largest_gain", "=", "mv_gain", "\n", "node1", "=", "i", "\n", "node2", "=", "nm", "\n", "use_swap", "=", "False", "\n", "# compute swap gain", "\n", "", "", "", "", "for", "i", ",", "m", "in", "enumerate", "(", "mapping", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "mapping", ")", ")", ":", "\n", "            ", "m2", "=", "mapping", "[", "j", "]", "\n", "# swap operation (i, m) (j, m2) -> (i, m2) (j, m)", "\n", "# j starts from i+1, to avoid duplicate swap", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Swap node\"", ",", "i", ",", "\"and\"", ",", "j", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Before swapping:\"", ",", "i", ",", "\"-\"", ",", "m", ",", "\",\"", ",", "j", ",", "\"-\"", ",", "m2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"After swapping:\"", ",", "i", ",", "\"-\"", ",", "m2", ",", "\",\"", ",", "j", ",", "\"-\"", ",", "m", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "sw_gain", "=", "swap_gain", "(", "mapping", ",", "i", ",", "m", ",", "j", ",", "m2", ",", "weight_dict", ",", "cur_match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Swap gain:\"", ",", "sw_gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_mapping", "=", "mapping", "[", ":", "]", "\n", "new_mapping", "[", "i", "]", "=", "m2", "\n", "new_mapping", "[", "j", "]", "=", "m", "\n", "print", "(", "new_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_match_num", "=", "compute_match", "(", "new_mapping", ",", "weight_dict", ")", "\n", "if", "new_match_num", "!=", "cur_match_num", "+", "sw_gain", ":", "\n", "                    ", "print", "(", "mapping", ",", "new_mapping", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Inconsistency in computing: swap gain\"", ",", "cur_match_num", ",", "sw_gain", ",", "new_match_num", ",", "\n", "file", "=", "ERROR_LOG", ")", "\n", "", "", "if", "sw_gain", ">", "largest_gain", ":", "\n", "                ", "largest_gain", "=", "sw_gain", "\n", "node1", "=", "i", "\n", "node2", "=", "j", "\n", "use_swap", "=", "True", "\n", "# generate a new mapping based on swap/move", "\n", "", "", "", "cur_mapping", "=", "mapping", "[", ":", "]", "\n", "if", "node1", "is", "not", "None", ":", "\n", "        ", "if", "use_swap", ":", "\n", "            ", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Use swap gain\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "temp", "=", "cur_mapping", "[", "node1", "]", "\n", "cur_mapping", "[", "node1", "]", "=", "cur_mapping", "[", "node2", "]", "\n", "cur_mapping", "[", "node2", "]", "=", "temp", "\n", "", "else", ":", "\n", "            ", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Use move gain\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "cur_mapping", "[", "node1", "]", "=", "node2", "\n", "", "", "else", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"no move/swap gain found\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Original mapping\"", ",", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Current mapping\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "largest_gain", ",", "cur_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.print_alignment": [[628, 647], ["zip", "result.append"], "function", ["None"], ["", "def", "print_alignment", "(", "mapping", ",", "instance1", ",", "instance2", ")", ":", "\n", "    ", "\"\"\"\n    print the alignment based on a node mapping\n    Args:\n        mapping: current node mapping list\n        instance1: nodes of AMR 1\n        instance2: nodes of AMR 2\n\n    \"\"\"", "\n", "result", "=", "[", "]", "\n", "for", "instance1_item", ",", "m", "in", "zip", "(", "instance1", ",", "mapping", ")", ":", "\n", "        ", "r", "=", "instance1_item", "[", "1", "]", "+", "\"(\"", "+", "instance1_item", "[", "2", "]", "+", "\")\"", "\n", "if", "m", "==", "-", "1", ":", "\n", "            ", "r", "+=", "\"-Null\"", "\n", "", "else", ":", "\n", "            ", "instance2_item", "=", "instance2", "[", "m", "]", "\n", "r", "+=", "\"-\"", "+", "instance2_item", "[", "1", "]", "+", "\"(\"", "+", "instance2_item", "[", "2", "]", "+", "\")\"", "\n", "", "result", ".", "append", "(", "r", ")", "\n", "", "return", "\" \"", ".", "join", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.compute_f": [[649, 676], ["float", "float", "float", "float", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "compute_f", "(", "match_num", ",", "test_num", ",", "gold_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the f-score based on the matching triple number,\n                                 triple number of AMR set 1,\n                                 triple number of AMR set 2\n    Args:\n        match_num: matching triple number\n        test_num:  triple number of AMR 1 (test file)\n        gold_num:  triple number of AMR 2 (gold file)\n    Returns:\n        precision: match_num/test_num\n        recall: match_num/gold_num\n        f_score: 2*precision*recall/(precision+recall)\n    \"\"\"", "\n", "if", "test_num", "==", "0", "or", "gold_num", "==", "0", ":", "\n", "        ", "return", "0.00", ",", "0.00", ",", "0.00", "\n", "", "precision", "=", "float", "(", "match_num", ")", "/", "float", "(", "test_num", ")", "\n", "recall", "=", "float", "(", "match_num", ")", "/", "float", "(", "gold_num", ")", "\n", "if", "(", "precision", "+", "recall", ")", "!=", "0", ":", "\n", "        ", "f_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"F-score:\"", ",", "f_score", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "precision", ",", "recall", ",", "f_score", "\n", "", "else", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"F-score:\"", ",", "\"0.0\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "precision", ",", "recall", ",", "0.00", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.generate_amr_lines": [[678, 691], ["zip", "smatch_fromlists.parse_relations", "smatch_fromlists.parse_relations"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.parse_relations", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.parse_relations"], ["", "", "def", "generate_amr_lines", "(", "list1", ",", "list2", ")", ":", "\n", "    ", "\"\"\"\n    Read one AMR line at a time from each file handle\n    :param f1: file handle (or any iterable of strings) to read AMR 1 lines from\n    :param f2: file handle (or any iterable of strings) to read AMR 2 lines from\n    :return: generator of cur_amr1, cur_amr2 pairs: one-line AMR strings\n    \"\"\"", "\n", "for", "l1", ",", "l2", "in", "zip", "(", "list1", ",", "list2", ")", ":", "\n", "        ", "lst_amr1", ",", "dic_amr1", "=", "l1", "\n", "lst_amr2", ",", "dic_amr2", "=", "l2", "\n", "amr1", "=", "parse_relations", "(", "lst_amr1", ",", "dic_amr1", ")", "\n", "amr2", "=", "parse_relations", "(", "lst_amr2", ",", "dic_amr2", ")", "\n", "yield", "amr1", ",", "amr2", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.get_amr_match": [[693, 750], ["amr1.get_triples", "amr2.get_triples", "smatch_fromlists.get_best_match", "str", "amr1.rename_node", "str", "amr2.rename_node", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "len", "len", "len", "len", "len", "len", "len", "len", "smatch_fromlists.print_alignment", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_match", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.print_alignment"], ["", "", "def", "get_amr_match", "(", "amr1", ",", "amr2", ",", "sent_num", "=", "1", ",", "justinstance", "=", "False", ",", "justattribute", "=", "False", ",", "justrelation", "=", "False", ")", ":", "\n", "    ", "prefix1", "=", "\"a\"", "\n", "prefix2", "=", "\"b\"", "\n", "# Rename node to \"a1\", \"a2\", .etc", "\n", "if", "str", "(", "amr1", ")", "!=", "''", ":", "\n", "        ", "amr1", ".", "rename_node", "(", "prefix1", ")", "\n", "# Renaming node to \"b1\", \"b2\", .etc", "\n", "", "if", "str", "(", "amr2", ")", "!=", "''", ":", "\n", "        ", "amr2", ".", "rename_node", "(", "prefix2", ")", "\n", "", "(", "instance1", ",", "attributes1", ",", "relation1", ")", "=", "amr1", ".", "get_triples", "(", ")", "\n", "(", "instance2", ",", "attributes2", ",", "relation2", ")", "=", "amr2", ".", "get_triples", "(", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"AMR pair\"", ",", "sent_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"============================================\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"AMR 1 (one-line):\"", ",", "cur_amr1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"AMR 2 (one-line):\"", ",", "cur_amr2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Instance triples of AMR 1:\"", ",", "len", "(", "instance1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "instance1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of AMR 1:\"", ",", "len", "(", "attributes1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "attributes1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of AMR 1:\"", ",", "len", "(", "relation1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "relation1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Instance triples of AMR 2:\"", ",", "len", "(", "instance2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "instance2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of AMR 2:\"", ",", "len", "(", "attributes2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "attributes2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of AMR 2:\"", ",", "len", "(", "relation2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "relation2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# optionally turn off some of the node comparison", "\n", "", "doinstance", "=", "doattribute", "=", "dorelation", "=", "True", "\n", "if", "justinstance", ":", "\n", "        ", "doattribute", "=", "dorelation", "=", "False", "\n", "", "if", "justattribute", ":", "\n", "        ", "doinstance", "=", "dorelation", "=", "False", "\n", "", "if", "justrelation", ":", "\n", "        ", "doinstance", "=", "doattribute", "=", "False", "\n", "", "(", "best_mapping", ",", "best_match_num", ")", "=", "get_best_match", "(", "instance1", ",", "attributes1", ",", "relation1", ",", "\n", "instance2", ",", "attributes2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "doinstance", ",", "\n", "doattribute", "=", "doattribute", ",", "dorelation", "=", "dorelation", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"best match number\"", ",", "best_match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"best node mapping\"", ",", "best_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Best node mapping alignment:\"", ",", "print_alignment", "(", "best_mapping", ",", "instance1", ",", "instance2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "justinstance", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "instance1", ")", "\n", "gold_triple_num", "=", "len", "(", "instance2", ")", "\n", "", "elif", "justattribute", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "attributes1", ")", "\n", "gold_triple_num", "=", "len", "(", "attributes2", ")", "\n", "", "elif", "justrelation", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "relation1", ")", "\n", "gold_triple_num", "=", "len", "(", "relation2", ")", "\n", "", "else", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "instance1", ")", "+", "len", "(", "attributes1", ")", "+", "len", "(", "relation1", ")", "\n", "gold_triple_num", "=", "len", "(", "instance2", ")", "+", "len", "(", "attributes2", ")", "+", "len", "(", "relation2", ")", "\n", "", "return", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.score_amr_pairs": [[752, 784], ["enumerate", "smatch_fromlists.generate_amr_lines", "smatch_fromlists.get_amr_match", "match_triple_dict.clear", "print", "print", "print", "smatch_fromlists.compute_f", "smatch_fromlists.compute_f"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.generate_amr_lines", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.get_amr_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f"], ["", "def", "score_amr_pairs", "(", "f1", ",", "f2", ",", "justinstance", "=", "False", ",", "justattribute", "=", "False", ",", "justrelation", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Score one pair of AMR lines at a time from each file handle\n    :param f1: file handle (or any iterable of strings) to read AMR 1 lines from\n    :param f2: file handle (or any iterable of strings) to read AMR 2 lines from\n    :param justinstance: just pay attention to matching instances\n    :param justattribute: just pay attention to matching attributes\n    :param justrelation: just pay attention to matching relations\n    :return: generator of cur_amr1, cur_amr2 pairs: one-line AMR strings\n    \"\"\"", "\n", "# matching triple number, triple number in test file, triple number in gold file", "\n", "total_match_num", "=", "total_test_num", "=", "total_gold_num", "=", "0", "\n", "# Read amr pairs from two files", "\n", "for", "sent_num", ",", "(", "cur_amr1", ",", "cur_amr2", ")", "in", "enumerate", "(", "generate_amr_lines", "(", "f1", ",", "f2", ")", ",", "start", "=", "1", ")", ":", "\n", "        ", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", "=", "get_amr_match", "(", "cur_amr1", ",", "cur_amr2", ",", "\n", "sent_num", "=", "sent_num", ",", "# sentence number", "\n", "justinstance", "=", "justinstance", ",", "\n", "justattribute", "=", "justattribute", ",", "\n", "justrelation", "=", "justrelation", ")", "\n", "total_match_num", "+=", "best_match_num", "\n", "total_test_num", "+=", "test_triple_num", "\n", "total_gold_num", "+=", "gold_triple_num", "\n", "# clear the matching triple dictionary for the next AMR pair", "\n", "match_triple_dict", ".", "clear", "(", ")", "\n", "if", "not", "single_score", ":", "# if each AMR pair should have a score, compute and output it here", "\n", "            ", "yield", "compute_f", "(", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", ")", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\"Total match number, total triple number in AMR 1, and total triple number in AMR 2:\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "total_match_num", ",", "total_test_num", ",", "total_gold_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"---------------------------------------------------------------------------------\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "single_score", ":", "# output document-level smatch score (a single f-score for all AMR pairs in two files)", "\n", "        ", "yield", "compute_f", "(", "total_match_num", ",", "total_test_num", ",", "total_gold_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.run": [[786, 805], ["smatch_fromlists.score_amr_pairs"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.score_amr_pairs"], ["", "", "def", "run", "(", "list1", ",", "list2", ",", "pr_flag", ")", ":", "\n", "    ", "\"\"\"\n    Main function of smatch score calculation\n    \"\"\"", "\n", "global", "verbose", "\n", "global", "veryVerbose", "\n", "global", "iteration_num", "\n", "global", "single_score", "\n", "global", "match_triple_dict", "\n", "# set the iteration number", "\n", "# total iteration number = restart number + 1", "\n", "iteration_num", "=", "5", "\n", "# significant digits to print out", "\n", "floatdisplay", "=", "\"%%.%df\"", "%", "2", "\n", "for", "(", "precision", ",", "recall", ",", "best_f_score", ")", "in", "score_amr_pairs", "(", "list1", ",", "list2", ",", "\n", "justinstance", "=", "False", ",", "\n", "justattribute", "=", "False", ",", "\n", "justrelation", "=", "False", ")", ":", "\n", "        ", "return", "precision", ",", "recall", ",", "best_f_score", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_fromlists.main": [[806, 808], ["smatch_fromlists.run"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run"], ["", "", "def", "main", "(", "list1", ",", "list2", ",", "pr_flag", "=", "False", ")", ":", "\n", "    ", "return", "run", "(", "list1", ",", "list2", ",", "pr_flag", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.build_arg_parser": [[49, 74], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType"], "function", ["None"], ["def", "build_arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Build an argument parser using argparse. Use it when python version is 2.7 or later.\n\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Smatch calculator -- arguments\"", ")", "\n", "parser", ".", "add_argument", "(", "'-f'", ",", "nargs", "=", "2", ",", "required", "=", "True", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "\n", "help", "=", "'Two files containing AMR pairs. AMRs in each file are separated by a single blank line'", ")", "\n", "parser", ".", "add_argument", "(", "'-r'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'Restart number (Default:4)'", ")", "\n", "parser", ".", "add_argument", "(", "'--significant'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "'significant digits to output (default: 2)'", ")", "\n", "parser", ".", "add_argument", "(", "'-v'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Verbose output (Default:false)'", ")", "\n", "parser", ".", "add_argument", "(", "'--vv'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Very Verbose output (Default:false)'", ")", "\n", "parser", ".", "add_argument", "(", "'--ms'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Output multiple scores (one AMR pair a score)'", "\n", "'instead of a single document-level smatch score (Default: false)'", ")", "\n", "parser", ".", "add_argument", "(", "'--pr'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"Output precision and recall as well as the f-score. Default: false\"", ")", "\n", "parser", ".", "add_argument", "(", "'--justinstance'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching instances\"", ")", "\n", "parser", ".", "add_argument", "(", "'--justattribute'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching attributes\"", ")", "\n", "parser", ".", "add_argument", "(", "'--justrelation'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching relations\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.build_arg_parser2": [[76, 105], ["optparse.OptionParser", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.set_defaults"], "function", ["None"], ["", "def", "build_arg_parser2", "(", ")", ":", "\n", "    ", "\"\"\"\n    Build an argument parser using optparse. Use it when python version is 2.5 or 2.6.\n\n    \"\"\"", "\n", "usage_str", "=", "\"Smatch calculator -- arguments\"", "\n", "parser", "=", "optparse", ".", "OptionParser", "(", "usage", "=", "usage_str", ")", "\n", "parser", ".", "add_option", "(", "\"-f\"", ",", "\"--files\"", ",", "nargs", "=", "2", ",", "dest", "=", "\"f\"", ",", "type", "=", "\"string\"", ",", "\n", "help", "=", "'Two files containing AMR pairs. AMRs in each file are '", "'separated by a single blank line. This option is required.'", ")", "\n", "parser", ".", "add_option", "(", "\"-r\"", ",", "\"--restart\"", ",", "dest", "=", "\"r\"", ",", "type", "=", "\"int\"", ",", "help", "=", "'Restart number (Default: 4)'", ")", "\n", "parser", ".", "add_option", "(", "'--significant'", ",", "dest", "=", "\"significant\"", ",", "type", "=", "\"int\"", ",", "default", "=", "2", ",", "\n", "help", "=", "'significant digits to output (default: 2)'", ")", "\n", "parser", ".", "add_option", "(", "\"-v\"", ",", "\"--verbose\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"v\"", ",", "help", "=", "'Verbose output (Default:False)'", ")", "\n", "parser", ".", "add_option", "(", "\"--vv\"", ",", "\"--veryverbose\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"vv\"", ",", "\n", "help", "=", "'Very Verbose output (Default:False)'", ")", "\n", "parser", ".", "add_option", "(", "\"--ms\"", ",", "\"--multiple_score\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"ms\"", ",", "\n", "help", "=", "'Output multiple scores (one AMR pair a score) instead of '", "'a single document-level smatch score (Default: False)'", ")", "\n", "parser", ".", "add_option", "(", "'--pr'", ",", "\"--precision_recall\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"pr\"", ",", "\n", "help", "=", "\"Output precision and recall as well as the f-score. Default: false\"", ")", "\n", "parser", ".", "add_option", "(", "'--justinstance'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching instances\"", ")", "\n", "parser", ".", "add_option", "(", "'--justattribute'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching attributes\"", ")", "\n", "parser", ".", "add_option", "(", "'--justrelation'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching relations\"", ")", "\n", "parser", ".", "set_defaults", "(", "r", "=", "4", ",", "v", "=", "False", ",", "ms", "=", "False", ",", "pr", "=", "False", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.get_best_match": [[107, 176], ["smatch.compute_pool", "range", "print", "print", "print", "print", "len", "smatch.compute_match", "print", "smatch.smart_init_mapping", "smatch.random_init_mapping", "print", "print", "smatch.get_best_gain", "len", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_pool", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.smart_init_mapping", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.random_init_mapping", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_gain", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "get_best_match", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "True", ",", "doattribute", "=", "True", ",", "dorelation", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Get the highest triple match number between two sets of triples via hill-climbing.\n    Arguments:\n        instance1: instance triples of AMR 1 (\"instance\", node name, node value)\n        attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n        relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n        instance2: instance triples of AMR 2 (\"instance\", node name, node value)\n        attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n        relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name)\n        prefix1: prefix label for AMR 1\n        prefix2: prefix label for AMR 2\n    Returns:\n        best_match: the node mapping that results in the highest triple matching number\n        best_match_num: the highest triple matching number\n\n    \"\"\"", "\n", "# Compute candidate pool - all possible node match candidates.", "\n", "# In the hill-climbing, we only consider candidate in this pool to save computing time.", "\n", "# weight_dict is a dictionary that maps a pair of node", "\n", "(", "candidate_mappings", ",", "weight_dict", ")", "=", "compute_pool", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "doinstance", ",", "doattribute", "=", "doattribute", ",", "\n", "dorelation", "=", "dorelation", ")", "\n", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Candidate mappings:\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "candidate_mappings", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Weight dictionary\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "weight_dict", ",", "file", "=", "DEBUG_LOG", ")", "\n", "\n", "", "best_match_num", "=", "0", "\n", "# initialize best match mapping", "\n", "# the ith entry is the node index in AMR 2 which maps to the ith node in AMR 1", "\n", "best_mapping", "=", "[", "-", "1", "]", "*", "len", "(", "instance1", ")", "\n", "for", "i", "in", "range", "(", "iteration_num", ")", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"Iteration\"", ",", "i", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "i", "==", "0", ":", "\n", "# smart initialization used for the first round", "\n", "            ", "cur_mapping", "=", "smart_init_mapping", "(", "candidate_mappings", ",", "instance1", ",", "instance2", ")", "\n", "", "else", ":", "\n", "# random initialization for the other round", "\n", "            ", "cur_mapping", "=", "random_init_mapping", "(", "candidate_mappings", ")", "\n", "# compute current triple match number", "\n", "", "match_num", "=", "compute_match", "(", "cur_mapping", ",", "weight_dict", ")", "\n", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"Node mapping at start\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Triple match number at start:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "while", "True", ":", "\n", "# get best gain", "\n", "            ", "(", "gain", ",", "new_mapping", ")", "=", "get_best_gain", "(", "cur_mapping", ",", "candidate_mappings", ",", "weight_dict", ",", "\n", "len", "(", "instance2", ")", ",", "match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Gain after the hill-climbing\"", ",", "gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# hill-climbing until there will be no gain for new node mapping", "\n", "", "if", "gain", "<=", "0", ":", "\n", "                ", "break", "\n", "# otherwise update match_num and mapping", "\n", "", "match_num", "+=", "gain", "\n", "cur_mapping", "=", "new_mapping", "[", ":", "]", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Update triple match number to:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Current mapping:\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "if", "match_num", ">", "best_match_num", ":", "\n", "            ", "best_mapping", "=", "cur_mapping", "[", ":", "]", "\n", "best_match_num", "=", "match_num", "\n", "", "", "return", "best_mapping", ",", "best_match_num", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.normalize": [[178, 183], ["item.lower().rstrip", "item.lower"], "function", ["None"], ["", "def", "normalize", "(", "item", ")", ":", "\n", "    ", "\"\"\"\n    lowercase and remove quote signifiers from items that are about to be compared\n    \"\"\"", "\n", "return", "item", ".", "lower", "(", ")", ".", "rstrip", "(", "'_'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.compute_pool": [[185, 293], ["candidate_mapping.append", "set", "int", "int", "candidate_mapping[].add", "int", "int", "candidate_mapping[].add", "smatch.normalize", "smatch.normalize", "int", "int", "int", "int", "candidate_mapping[].add", "candidate_mapping[].add", "smatch.normalize", "smatch.normalize", "smatch.normalize", "smatch.normalize", "smatch.normalize", "smatch.normalize", "smatch.normalize", "smatch.normalize", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize"], ["", "def", "compute_pool", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "True", ",", "doattribute", "=", "True", ",", "dorelation", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    compute all possible node mapping candidates and their weights (the triple matching number gain resulting from\n    mapping one node in AMR 1 to another node in AMR2)\n\n    Arguments:\n        instance1: instance triples of AMR 1\n        attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n        relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n        instance2: instance triples of AMR 2\n        attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n        relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name\n        prefix1: prefix label for AMR 1\n        prefix2: prefix label for AMR 2\n    Returns:\n      candidate_mapping: a list of candidate nodes.\n                       The ith element contains the node indices (in AMR 2) the ith node (in AMR 1) can map to.\n                       (resulting in non-zero triple match)\n      weight_dict: a dictionary which contains the matching triple number for every pair of node mapping. The key\n                   is a node pair. The value is another dictionary. key {-1} is triple match resulting from this node\n                   pair alone (instance triples and attribute triples), and other keys are node pairs that can result\n                   in relation triple match together with the first node pair.\n\n\n    \"\"\"", "\n", "candidate_mapping", "=", "[", "]", "\n", "weight_dict", "=", "{", "}", "\n", "for", "instance1_item", "in", "instance1", ":", "\n", "# each candidate mapping is a set of node indices", "\n", "        ", "candidate_mapping", ".", "append", "(", "set", "(", ")", ")", "\n", "if", "doinstance", ":", "\n", "            ", "for", "instance2_item", "in", "instance2", ":", "\n", "# if both triples are instance triples and have the same value", "\n", "                ", "if", "normalize", "(", "instance1_item", "[", "0", "]", ")", "==", "normalize", "(", "instance2_item", "[", "0", "]", ")", "and", "normalize", "(", "instance1_item", "[", "2", "]", ")", "==", "normalize", "(", "instance2_item", "[", "2", "]", ")", ":", "\n", "# get node index by stripping the prefix", "\n", "                    ", "node1_index", "=", "int", "(", "instance1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index", "=", "int", "(", "instance2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "candidate_mapping", "[", "node1_index", "]", ".", "add", "(", "node2_index", ")", "\n", "node_pair", "=", "(", "node1_index", ",", "node2_index", ")", "\n", "# use -1 as key in weight_dict for instance triples and attribute triples", "\n", "if", "node_pair", "in", "weight_dict", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "=", "1", "\n", "", "", "", "", "", "if", "doattribute", ":", "\n", "        ", "for", "attribute1_item", "in", "attribute1", ":", "\n", "            ", "for", "attribute2_item", "in", "attribute2", ":", "\n", "# if both attribute relation triple have the same relation name and value", "\n", "                ", "if", "normalize", "(", "attribute1_item", "[", "0", "]", ")", "==", "normalize", "(", "attribute2_item", "[", "0", "]", ")", "and", "normalize", "(", "attribute1_item", "[", "2", "]", ")", "==", "normalize", "(", "attribute2_item", "[", "2", "]", ")", ":", "\n", "                    ", "node1_index", "=", "int", "(", "attribute1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index", "=", "int", "(", "attribute2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "candidate_mapping", "[", "node1_index", "]", ".", "add", "(", "node2_index", ")", "\n", "node_pair", "=", "(", "node1_index", ",", "node2_index", ")", "\n", "# use -1 as key in weight_dict for instance triples and attribute triples", "\n", "if", "node_pair", "in", "weight_dict", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "=", "1", "\n", "", "", "", "", "", "if", "dorelation", ":", "\n", "        ", "for", "relation1_item", "in", "relation1", ":", "\n", "            ", "for", "relation2_item", "in", "relation2", ":", "\n", "# if both relation share the same name", "\n", "                ", "if", "normalize", "(", "relation1_item", "[", "0", "]", ")", "==", "normalize", "(", "relation2_item", "[", "0", "]", ")", ":", "\n", "                    ", "node1_index_amr1", "=", "int", "(", "relation1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node1_index_amr2", "=", "int", "(", "relation2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "node2_index_amr1", "=", "int", "(", "relation1_item", "[", "2", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index_amr2", "=", "int", "(", "relation2_item", "[", "2", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "# add mapping between two nodes", "\n", "candidate_mapping", "[", "node1_index_amr1", "]", ".", "add", "(", "node1_index_amr2", ")", "\n", "candidate_mapping", "[", "node2_index_amr1", "]", ".", "add", "(", "node2_index_amr2", ")", "\n", "node_pair1", "=", "(", "node1_index_amr1", ",", "node1_index_amr2", ")", "\n", "node_pair2", "=", "(", "node2_index_amr1", ",", "node2_index_amr2", ")", "\n", "if", "node_pair2", "!=", "node_pair1", ":", "\n", "# update weight_dict weight. Note that we need to update both entries for future search", "\n", "# i.e weight_dict[node_pair1][node_pair2]", "\n", "#     weight_dict[node_pair2][node_pair1]", "\n", "                        ", "if", "node1_index_amr1", ">", "node2_index_amr1", ":", "\n", "# swap node_pair1 and node_pair2", "\n", "                            ", "node_pair1", "=", "(", "node2_index_amr1", ",", "node2_index_amr2", ")", "\n", "node_pair2", "=", "(", "node1_index_amr1", ",", "node1_index_amr2", ")", "\n", "", "if", "node_pair1", "in", "weight_dict", ":", "\n", "                            ", "if", "node_pair2", "in", "weight_dict", "[", "node_pair1", "]", ":", "\n", "                                ", "weight_dict", "[", "node_pair1", "]", "[", "node_pair2", "]", "+=", "1", "\n", "", "else", ":", "\n", "                                ", "weight_dict", "[", "node_pair1", "]", "[", "node_pair2", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "=", "{", "-", "1", ":", "0", ",", "node_pair2", ":", "1", "}", "\n", "", "if", "node_pair2", "in", "weight_dict", ":", "\n", "                            ", "if", "node_pair1", "in", "weight_dict", "[", "node_pair2", "]", ":", "\n", "                                ", "weight_dict", "[", "node_pair2", "]", "[", "node_pair1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                                ", "weight_dict", "[", "node_pair2", "]", "[", "node_pair1", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair2", "]", "=", "{", "-", "1", ":", "0", ",", "node_pair1", ":", "1", "}", "\n", "", "", "else", ":", "\n", "# two node pairs are the same. So we only update weight_dict once.", "\n", "# this generally should not happen.", "\n", "                        ", "if", "node_pair1", "in", "weight_dict", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "=", "{", "-", "1", ":", "1", "}", "\n", "", "", "", "", "", "", "return", "candidate_mapping", ",", "weight_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.smart_init_mapping": [[295, 344], ["random.seed", "enumerate", "list", "result.append", "len", "no_word_match.append", "result.append", "random.randint", "list.pop", "result.append", "len"], "function", ["None"], ["", "def", "smart_init_mapping", "(", "candidate_mapping", ",", "instance1", ",", "instance2", ")", ":", "\n", "    ", "\"\"\"\n    Initialize mapping based on the concept mapping (smart initialization)\n    Arguments:\n        candidate_mapping: candidate node match list\n        instance1: instance triples of AMR 1\n        instance2: instance triples of AMR 2\n    Returns:\n        initialized node mapping between two AMRs\n\n    \"\"\"", "\n", "random", ".", "seed", "(", ")", "\n", "matched_dict", "=", "{", "}", "\n", "result", "=", "[", "]", "\n", "# list to store node indices that have no concept match", "\n", "no_word_match", "=", "[", "]", "\n", "for", "i", ",", "candidates", "in", "enumerate", "(", "candidate_mapping", ")", ":", "\n", "        ", "if", "not", "candidates", ":", "\n", "# no possible mapping", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "continue", "\n", "# node value in instance triples of AMR 1", "\n", "", "value1", "=", "instance1", "[", "i", "]", "[", "2", "]", "\n", "for", "node_index", "in", "candidates", ":", "\n", "            ", "value2", "=", "instance2", "[", "node_index", "]", "[", "2", "]", "\n", "# find the first instance triple match in the candidates", "\n", "# instance triple match is having the same concept value", "\n", "if", "value1", "==", "value2", ":", "\n", "                ", "if", "node_index", "not", "in", "matched_dict", ":", "\n", "                    ", "result", ".", "append", "(", "node_index", ")", "\n", "matched_dict", "[", "node_index", "]", "=", "1", "\n", "break", "\n", "", "", "", "if", "len", "(", "result", ")", "==", "i", ":", "\n", "            ", "no_word_match", ".", "append", "(", "i", ")", "\n", "result", ".", "append", "(", "-", "1", ")", "\n", "# if no concept match, generate a random mapping", "\n", "", "", "for", "i", "in", "no_word_match", ":", "\n", "        ", "candidates", "=", "list", "(", "candidate_mapping", "[", "i", "]", ")", "\n", "while", "candidates", ":", "\n", "# get a random node index from candidates", "\n", "            ", "rid", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "candidates", ")", "-", "1", ")", "\n", "candidate", "=", "candidates", "[", "rid", "]", "\n", "if", "candidate", "in", "matched_dict", ":", "\n", "                ", "candidates", ".", "pop", "(", "rid", ")", "\n", "", "else", ":", "\n", "                ", "matched_dict", "[", "candidate", "]", "=", "1", "\n", "result", "[", "i", "]", "=", "candidate", "\n", "break", "\n", "", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.random_init_mapping": [[346, 381], ["random.seed", "list", "result.append", "random.randint", "result.append", "list.pop", "result.append", "len"], "function", ["None"], ["", "def", "random_init_mapping", "(", "candidate_mapping", ")", ":", "\n", "    ", "\"\"\"\n    Generate a random node mapping.\n    Args:\n        candidate_mapping: candidate_mapping: candidate node match list\n    Returns:\n        randomly-generated node mapping between two AMRs\n\n    \"\"\"", "\n", "# if needed, a fixed seed could be passed here to generate same random (to help debugging)", "\n", "random", ".", "seed", "(", ")", "\n", "matched_dict", "=", "{", "}", "\n", "result", "=", "[", "]", "\n", "for", "c", "in", "candidate_mapping", ":", "\n", "        ", "candidates", "=", "list", "(", "c", ")", "\n", "if", "not", "candidates", ":", "\n", "# -1 indicates no possible mapping", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "continue", "\n", "", "found", "=", "False", "\n", "while", "candidates", ":", "\n", "# randomly generate an index in [0, length of candidates)", "\n", "            ", "rid", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "candidates", ")", "-", "1", ")", "\n", "candidate", "=", "candidates", "[", "rid", "]", "\n", "# check if it has already been matched", "\n", "if", "candidate", "in", "matched_dict", ":", "\n", "                ", "candidates", ".", "pop", "(", "rid", ")", "\n", "", "else", ":", "\n", "                ", "matched_dict", "[", "candidate", "]", "=", "1", "\n", "result", ".", "append", "(", "candidate", ")", "\n", "found", "=", "True", "\n", "break", "\n", "", "", "if", "not", "found", ":", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.compute_match": [[383, 433], ["enumerate", "print", "print", "tuple", "print", "print", "print", "tuple", "tuple", "print", "tuple", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "compute_match", "(", "mapping", ",", "weight_dict", ")", ":", "\n", "    ", "\"\"\"\n    Given a node mapping, compute match number based on weight_dict.\n    Args:\n    mappings: a list of node index in AMR 2. The ith element (value j) means node i in AMR 1 maps to node j in AMR 2.\n    Returns:\n    matching triple number\n    Complexity: O(m*n) , m is the node number of AMR 1, n is the node number of AMR 2\n\n    \"\"\"", "\n", "# If this mapping has been investigated before, retrieve the value instead of re-computing.", "\n", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Computing match for mapping\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "tuple", "(", "mapping", ")", "in", "match_triple_dict", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"saved value\"", ",", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", "\n", "", "match_num", "=", "0", "\n", "# i is node index in AMR 1, m is node index in AMR 2", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "mapping", ")", ":", "\n", "        ", "if", "m", "==", "-", "1", ":", "\n", "# no node maps to this node", "\n", "            ", "continue", "\n", "# node i in AMR 1 maps to node m in AMR 2", "\n", "", "current_node_pair", "=", "(", "i", ",", "m", ")", "\n", "if", "current_node_pair", "not", "in", "weight_dict", ":", "\n", "            ", "continue", "\n", "", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"node_pair\"", ",", "current_node_pair", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "for", "key", "in", "weight_dict", "[", "current_node_pair", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "# matching triple resulting from instance/attribute triples", "\n", "                ", "match_num", "+=", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"instance/attribute match\"", ",", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# only consider node index larger than i to avoid duplicates", "\n", "# as we store both weight_dict[node_pair1][node_pair2] and", "\n", "#     weight_dict[node_pair2][node_pair1] for a relation", "\n", "", "", "elif", "key", "[", "0", "]", "<", "i", ":", "\n", "                ", "continue", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "match_num", "+=", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"relation match with\"", ",", "key", ",", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "", "", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"match computing complete, result:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# update match_triple_dict", "\n", "", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", "=", "match_num", "\n", "return", "match_num", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.move_gain": [[435, 479], ["tuple", "tuple", "tuple"], "function", ["None"], ["", "def", "move_gain", "(", "mapping", ",", "node_id", ",", "old_id", ",", "new_id", ",", "weight_dict", ",", "match_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the triple match number gain from the move operation\n    Arguments:\n        mapping: current node mapping\n        node_id: remapped node in AMR 1\n        old_id: original node id in AMR 2 to which node_id is mapped\n        new_id: new node in to which node_id is mapped\n        weight_dict: weight dictionary\n        match_num: the original triple matching number\n    Returns:\n        the triple match gain number (might be negative)\n\n    \"\"\"", "\n", "# new node mapping after moving", "\n", "new_mapping", "=", "(", "node_id", ",", "new_id", ")", "\n", "# node mapping before moving", "\n", "old_mapping", "=", "(", "node_id", ",", "old_id", ")", "\n", "# new nodes mapping list (all node pairs)", "\n", "new_mapping_list", "=", "mapping", "[", ":", "]", "\n", "new_mapping_list", "[", "node_id", "]", "=", "new_id", "\n", "# if this mapping is already been investigated, use saved one to avoid duplicate computing", "\n", "if", "tuple", "(", "new_mapping_list", ")", "in", "match_triple_dict", ":", "\n", "        ", "return", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "-", "match_num", "\n", "", "gain", "=", "0", "\n", "# add the triple match incurred by new_mapping to gain", "\n", "if", "new_mapping", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "# instance/attribute triple match", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping", "]", "[", "-", "1", "]", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "# relation gain incurred by new_mapping and another node pair in new_mapping_list", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping", "]", "[", "key", "]", "\n", "# deduct the triple match incurred by old_mapping from gain", "\n", "", "", "", "if", "old_mapping", "in", "weight_dict", ":", "\n", "        ", "for", "k", "in", "weight_dict", "[", "old_mapping", "]", ":", "\n", "            ", "if", "k", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping", "]", "[", "-", "1", "]", "\n", "", "elif", "mapping", "[", "k", "[", "0", "]", "]", "==", "k", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping", "]", "[", "k", "]", "\n", "# update match number dictionary", "\n", "", "", "", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "=", "match_num", "+", "gain", "\n", "return", "gain", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.swap_gain": [[481, 545], ["tuple", "tuple", "tuple"], "function", ["None"], ["", "def", "swap_gain", "(", "mapping", ",", "node_id1", ",", "mapping_id1", ",", "node_id2", ",", "mapping_id2", ",", "weight_dict", ",", "match_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the triple match number gain from the swapping\n    Arguments:\n    mapping: current node mapping list\n    node_id1: node 1 index in AMR 1\n    mapping_id1: the node index in AMR 2 node 1 maps to (in the current mapping)\n    node_id2: node 2 index in AMR 1\n    mapping_id2: the node index in AMR 2 node 2 maps to (in the current mapping)\n    weight_dict: weight dictionary\n    match_num: the original matching triple number\n    Returns:\n    the gain number (might be negative)\n\n    \"\"\"", "\n", "new_mapping_list", "=", "mapping", "[", ":", "]", "\n", "# Before swapping, node_id1 maps to mapping_id1, and node_id2 maps to mapping_id2", "\n", "# After swapping, node_id1 maps to mapping_id2 and node_id2 maps to mapping_id1", "\n", "new_mapping_list", "[", "node_id1", "]", "=", "mapping_id2", "\n", "new_mapping_list", "[", "node_id2", "]", "=", "mapping_id1", "\n", "if", "tuple", "(", "new_mapping_list", ")", "in", "match_triple_dict", ":", "\n", "        ", "return", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "-", "match_num", "\n", "", "gain", "=", "0", "\n", "new_mapping1", "=", "(", "node_id1", ",", "mapping_id2", ")", "\n", "new_mapping2", "=", "(", "node_id2", ",", "mapping_id1", ")", "\n", "old_mapping1", "=", "(", "node_id1", ",", "mapping_id1", ")", "\n", "old_mapping2", "=", "(", "node_id2", ",", "mapping_id2", ")", "\n", "if", "node_id1", ">", "node_id2", ":", "\n", "        ", "new_mapping2", "=", "(", "node_id1", ",", "mapping_id2", ")", "\n", "new_mapping1", "=", "(", "node_id2", ",", "mapping_id1", ")", "\n", "old_mapping1", "=", "(", "node_id2", ",", "mapping_id2", ")", "\n", "old_mapping2", "=", "(", "node_id1", ",", "mapping_id1", ")", "\n", "", "if", "new_mapping1", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping1", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping1", "]", "[", "-", "1", "]", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping1", "]", "[", "key", "]", "\n", "", "", "", "if", "new_mapping2", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping2", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping2", "]", "[", "-", "1", "]", "\n", "# to avoid duplicate", "\n", "", "elif", "key", "[", "0", "]", "==", "node_id1", ":", "\n", "                ", "continue", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping2", "]", "[", "key", "]", "\n", "", "", "", "if", "old_mapping1", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "old_mapping1", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping1", "]", "[", "-", "1", "]", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping1", "]", "[", "key", "]", "\n", "", "", "", "if", "old_mapping2", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "old_mapping2", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping2", "]", "[", "-", "1", "]", "\n", "# to avoid duplicate", "\n", "", "elif", "key", "[", "0", "]", "==", "node_id1", ":", "\n", "                ", "continue", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping2", "]", "[", "key", "]", "\n", "", "", "", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "=", "match_num", "+", "gain", "\n", "return", "gain", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.get_best_gain": [[547, 646], ["set", "enumerate", "enumerate", "range", "range", "print", "print", "set.remove", "len", "smatch.swap_gain", "print", "smatch.move_gain", "print", "print", "print", "print", "print", "print", "smatch.compute_match", "print", "print", "print", "print", "smatch.compute_match", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.swap_gain", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.move_gain", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "get_best_gain", "(", "mapping", ",", "candidate_mappings", ",", "weight_dict", ",", "instance_len", ",", "cur_match_num", ")", ":", "\n", "    ", "\"\"\"\n    Hill-climbing method to return the best gain swap/move can get\n    Arguments:\n    mapping: current node mapping\n    candidate_mappings: the candidates mapping list\n    weight_dict: the weight dictionary\n    instance_len: the number of the nodes in AMR 2\n    cur_match_num: current triple match number\n    Returns:\n    the best gain we can get via swap/move operation\n\n    \"\"\"", "\n", "largest_gain", "=", "0", "\n", "# True: using swap; False: using move", "\n", "use_swap", "=", "True", "\n", "# the node to be moved/swapped", "\n", "node1", "=", "None", "\n", "# store the other node affected. In swap, this other node is the node swapping with node1. In move, this other", "\n", "# node is the node node1 will move to.", "\n", "node2", "=", "None", "\n", "# unmatched nodes in AMR 2", "\n", "unmatched", "=", "set", "(", "range", "(", "instance_len", ")", ")", "\n", "# exclude nodes in current mapping", "\n", "# get unmatched nodes", "\n", "for", "nid", "in", "mapping", ":", "\n", "        ", "if", "nid", "in", "unmatched", ":", "\n", "            ", "unmatched", ".", "remove", "(", "nid", ")", "\n", "", "", "for", "i", ",", "nid", "in", "enumerate", "(", "mapping", ")", ":", "\n", "# current node i in AMR 1 maps to node nid in AMR 2", "\n", "        ", "for", "nm", "in", "unmatched", ":", "\n", "            ", "if", "nm", "in", "candidate_mappings", "[", "i", "]", ":", "\n", "# remap i to another unmatched node (move)", "\n", "# (i, m) -> (i, nm)", "\n", "                ", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"Remap node\"", ",", "i", ",", "\"from \"", ",", "nid", ",", "\"to\"", ",", "nm", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "mv_gain", "=", "move_gain", "(", "mapping", ",", "i", ",", "nid", ",", "nm", ",", "weight_dict", ",", "cur_match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"Move gain:\"", ",", "mv_gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_mapping", "=", "mapping", "[", ":", "]", "\n", "new_mapping", "[", "i", "]", "=", "nm", "\n", "new_match_num", "=", "compute_match", "(", "new_mapping", ",", "weight_dict", ")", "\n", "if", "new_match_num", "!=", "cur_match_num", "+", "mv_gain", ":", "\n", "                        ", "print", "(", "mapping", ",", "new_mapping", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Inconsistency in computing: move gain\"", ",", "cur_match_num", ",", "mv_gain", ",", "new_match_num", ",", "\n", "file", "=", "ERROR_LOG", ")", "\n", "", "", "if", "mv_gain", ">", "largest_gain", ":", "\n", "                    ", "largest_gain", "=", "mv_gain", "\n", "node1", "=", "i", "\n", "node2", "=", "nm", "\n", "use_swap", "=", "False", "\n", "# compute swap gain", "\n", "", "", "", "", "for", "i", ",", "m", "in", "enumerate", "(", "mapping", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "mapping", ")", ")", ":", "\n", "            ", "m2", "=", "mapping", "[", "j", "]", "\n", "# swap operation (i, m) (j, m2) -> (i, m2) (j, m)", "\n", "# j starts from i+1, to avoid duplicate swap", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Swap node\"", ",", "i", ",", "\"and\"", ",", "j", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Before swapping:\"", ",", "i", ",", "\"-\"", ",", "m", ",", "\",\"", ",", "j", ",", "\"-\"", ",", "m2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"After swapping:\"", ",", "i", ",", "\"-\"", ",", "m2", ",", "\",\"", ",", "j", ",", "\"-\"", ",", "m", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "sw_gain", "=", "swap_gain", "(", "mapping", ",", "i", ",", "m", ",", "j", ",", "m2", ",", "weight_dict", ",", "cur_match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Swap gain:\"", ",", "sw_gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_mapping", "=", "mapping", "[", ":", "]", "\n", "new_mapping", "[", "i", "]", "=", "m2", "\n", "new_mapping", "[", "j", "]", "=", "m", "\n", "print", "(", "new_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_match_num", "=", "compute_match", "(", "new_mapping", ",", "weight_dict", ")", "\n", "if", "new_match_num", "!=", "cur_match_num", "+", "sw_gain", ":", "\n", "                    ", "print", "(", "mapping", ",", "new_mapping", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Inconsistency in computing: swap gain\"", ",", "cur_match_num", ",", "sw_gain", ",", "new_match_num", ",", "\n", "file", "=", "ERROR_LOG", ")", "\n", "", "", "if", "sw_gain", ">", "largest_gain", ":", "\n", "                ", "largest_gain", "=", "sw_gain", "\n", "node1", "=", "i", "\n", "node2", "=", "j", "\n", "use_swap", "=", "True", "\n", "# generate a new mapping based on swap/move", "\n", "", "", "", "cur_mapping", "=", "mapping", "[", ":", "]", "\n", "if", "node1", "is", "not", "None", ":", "\n", "        ", "if", "use_swap", ":", "\n", "            ", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Use swap gain\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "temp", "=", "cur_mapping", "[", "node1", "]", "\n", "cur_mapping", "[", "node1", "]", "=", "cur_mapping", "[", "node2", "]", "\n", "cur_mapping", "[", "node2", "]", "=", "temp", "\n", "", "else", ":", "\n", "            ", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Use move gain\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "cur_mapping", "[", "node1", "]", "=", "node2", "\n", "", "", "else", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"no move/swap gain found\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Original mapping\"", ",", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Current mapping\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "largest_gain", ",", "cur_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.print_alignment": [[648, 667], ["zip", "result.append"], "function", ["None"], ["", "def", "print_alignment", "(", "mapping", ",", "instance1", ",", "instance2", ")", ":", "\n", "    ", "\"\"\"\n    print the alignment based on a node mapping\n    Args:\n        mapping: current node mapping list\n        instance1: nodes of AMR 1\n        instance2: nodes of AMR 2\n\n    \"\"\"", "\n", "result", "=", "[", "]", "\n", "for", "instance1_item", ",", "m", "in", "zip", "(", "instance1", ",", "mapping", ")", ":", "\n", "        ", "r", "=", "instance1_item", "[", "1", "]", "+", "\"(\"", "+", "instance1_item", "[", "2", "]", "+", "\")\"", "\n", "if", "m", "==", "-", "1", ":", "\n", "            ", "r", "+=", "\"-Null\"", "\n", "", "else", ":", "\n", "            ", "instance2_item", "=", "instance2", "[", "m", "]", "\n", "r", "+=", "\"-\"", "+", "instance2_item", "[", "1", "]", "+", "\"(\"", "+", "instance2_item", "[", "2", "]", "+", "\")\"", "\n", "", "result", ".", "append", "(", "r", ")", "\n", "", "return", "\" \"", ".", "join", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.compute_f": [[669, 696], ["float", "float", "float", "float", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "compute_f", "(", "match_num", ",", "test_num", ",", "gold_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the f-score based on the matching triple number,\n                                 triple number of AMR set 1,\n                                 triple number of AMR set 2\n    Args:\n        match_num: matching triple number\n        test_num:  triple number of AMR 1 (test file)\n        gold_num:  triple number of AMR 2 (gold file)\n    Returns:\n        precision: match_num/test_num\n        recall: match_num/gold_num\n        f_score: 2*precision*recall/(precision+recall)\n    \"\"\"", "\n", "if", "test_num", "==", "0", "or", "gold_num", "==", "0", ":", "\n", "        ", "return", "0.00", ",", "0.00", ",", "0.00", "\n", "", "precision", "=", "float", "(", "match_num", ")", "/", "float", "(", "test_num", ")", "\n", "recall", "=", "float", "(", "match_num", ")", "/", "float", "(", "gold_num", ")", "\n", "if", "(", "precision", "+", "recall", ")", "!=", "0", ":", "\n", "        ", "f_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"F-score:\"", ",", "f_score", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "precision", ",", "recall", ",", "f_score", "\n", "", "else", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"F-score:\"", ",", "\"0.0\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "precision", ",", "recall", ",", "0.00", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.generate_amr_lines": [[698, 720], ["amr.AMR.get_amr_line", "amr.AMR.get_amr_line", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_amr_line", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_amr_line", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "", "def", "generate_amr_lines", "(", "f1", ",", "f2", ")", ":", "\n", "    ", "\"\"\"\n    Read one AMR line at a time from each file handle\n    :param f1: file handle (or any iterable of strings) to read AMR 1 lines from\n    :param f2: file handle (or any iterable of strings) to read AMR 2 lines from\n    :return: generator of cur_amr1, cur_amr2 pairs: one-line AMR strings\n    \"\"\"", "\n", "while", "True", ":", "\n", "        ", "cur_amr1", "=", "amr", ".", "AMR", ".", "get_amr_line", "(", "f1", ")", "\n", "cur_amr2", "=", "amr", ".", "AMR", ".", "get_amr_line", "(", "f2", ")", "\n", "if", "not", "cur_amr1", "and", "not", "cur_amr2", ":", "\n", "            ", "pass", "\n", "", "elif", "not", "cur_amr1", ":", "\n", "            ", "print", "(", "\"Error: File 1 has less AMRs than file 2\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Ignoring remaining AMRs\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "", "elif", "not", "cur_amr2", ":", "\n", "            ", "print", "(", "\"Error: File 2 has less AMRs than file 1\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Ignoring remaining AMRs\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "", "else", ":", "\n", "            ", "yield", "cur_amr1", ",", "cur_amr2", "\n", "continue", "\n", "", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.get_amr_match": [[722, 786], ["amr1.rename_node", "amr2.rename_node", "amr1.get_triples", "amr2.get_triples", "smatch.get_best_match", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "len", "len", "amr_pair.append", "len", "len", "len", "len", "len", "len", "smatch.print_alignment", "len", "len", "amr.AMR.parse_AMR_line", "print", "print", "print", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.print_alignment", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.parse_AMR_line", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "", "def", "get_amr_match", "(", "cur_amr1", ",", "cur_amr2", ",", "sent_num", "=", "1", ",", "justinstance", "=", "False", ",", "justattribute", "=", "False", ",", "justrelation", "=", "False", ")", ":", "\n", "    ", "amr_pair", "=", "[", "]", "\n", "for", "i", ",", "cur_amr", "in", "(", "1", ",", "cur_amr1", ")", ",", "(", "2", ",", "cur_amr2", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "amr_pair", ".", "append", "(", "amr", ".", "AMR", ".", "parse_AMR_line", "(", "cur_amr", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"Error in parsing amr %d: %s\"", "%", "(", "i", ",", "cur_amr", ")", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Please check if the AMR is ill-formatted. Ignoring remaining AMRs\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Error message: %s\"", "%", "e", ",", "file", "=", "ERROR_LOG", ")", "\n", "", "", "amr1", ",", "amr2", "=", "amr_pair", "\n", "prefix1", "=", "\"a\"", "\n", "prefix2", "=", "\"b\"", "\n", "# Rename node to \"a1\", \"a2\", .etc", "\n", "amr1", ".", "rename_node", "(", "prefix1", ")", "\n", "# Renaming node to \"b1\", \"b2\", .etc", "\n", "amr2", ".", "rename_node", "(", "prefix2", ")", "\n", "(", "instance1", ",", "attributes1", ",", "relation1", ")", "=", "amr1", ".", "get_triples", "(", ")", "\n", "(", "instance2", ",", "attributes2", ",", "relation2", ")", "=", "amr2", ".", "get_triples", "(", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"AMR pair\"", ",", "sent_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"============================================\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"AMR 1 (one-line):\"", ",", "cur_amr1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"AMR 2 (one-line):\"", ",", "cur_amr2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Instance triples of AMR 1:\"", ",", "len", "(", "instance1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "instance1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of AMR 1:\"", ",", "len", "(", "attributes1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "attributes1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of AMR 1:\"", ",", "len", "(", "relation1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "relation1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Instance triples of AMR 2:\"", ",", "len", "(", "instance2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "instance2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of AMR 2:\"", ",", "len", "(", "attributes2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "attributes2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of AMR 2:\"", ",", "len", "(", "relation2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "relation2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# optionally turn off some of the node comparison", "\n", "", "doinstance", "=", "doattribute", "=", "dorelation", "=", "True", "\n", "if", "justinstance", ":", "\n", "        ", "doattribute", "=", "dorelation", "=", "False", "\n", "", "if", "justattribute", ":", "\n", "        ", "doinstance", "=", "dorelation", "=", "False", "\n", "", "if", "justrelation", ":", "\n", "        ", "doinstance", "=", "doattribute", "=", "False", "\n", "", "(", "best_mapping", ",", "best_match_num", ")", "=", "get_best_match", "(", "instance1", ",", "attributes1", ",", "relation1", ",", "\n", "instance2", ",", "attributes2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "doinstance", ",", "\n", "doattribute", "=", "doattribute", ",", "dorelation", "=", "dorelation", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"best match number\"", ",", "best_match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"best node mapping\"", ",", "best_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Best node mapping alignment:\"", ",", "print_alignment", "(", "best_mapping", ",", "instance1", ",", "instance2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "justinstance", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "instance1", ")", "\n", "gold_triple_num", "=", "len", "(", "instance2", ")", "\n", "", "elif", "justattribute", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "attributes1", ")", "\n", "gold_triple_num", "=", "len", "(", "attributes2", ")", "\n", "", "elif", "justrelation", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "relation1", ")", "\n", "gold_triple_num", "=", "len", "(", "relation2", ")", "\n", "", "else", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "instance1", ")", "+", "len", "(", "attributes1", ")", "+", "len", "(", "relation1", ")", "\n", "gold_triple_num", "=", "len", "(", "instance2", ")", "+", "len", "(", "attributes2", ")", "+", "len", "(", "relation2", ")", "\n", "", "return", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.score_amr_pairs": [[788, 820], ["enumerate", "smatch.generate_amr_lines", "smatch.get_amr_match", "match_triple_dict.clear", "print", "print", "print", "smatch.compute_f", "smatch.compute_f"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.generate_amr_lines", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.get_amr_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f"], ["", "def", "score_amr_pairs", "(", "f1", ",", "f2", ",", "justinstance", "=", "False", ",", "justattribute", "=", "False", ",", "justrelation", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Score one pair of AMR lines at a time from each file handle\n    :param f1: file handle (or any iterable of strings) to read AMR 1 lines from\n    :param f2: file handle (or any iterable of strings) to read AMR 2 lines from\n    :param justinstance: just pay attention to matching instances\n    :param justattribute: just pay attention to matching attributes\n    :param justrelation: just pay attention to matching relations\n    :return: generator of cur_amr1, cur_amr2 pairs: one-line AMR strings\n    \"\"\"", "\n", "# matching triple number, triple number in test file, triple number in gold file", "\n", "total_match_num", "=", "total_test_num", "=", "total_gold_num", "=", "0", "\n", "# Read amr pairs from two files", "\n", "for", "sent_num", ",", "(", "cur_amr1", ",", "cur_amr2", ")", "in", "enumerate", "(", "generate_amr_lines", "(", "f1", ",", "f2", ")", ",", "start", "=", "1", ")", ":", "\n", "        ", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", "=", "get_amr_match", "(", "cur_amr1", ",", "cur_amr2", ",", "\n", "sent_num", "=", "sent_num", ",", "# sentence number", "\n", "justinstance", "=", "justinstance", ",", "\n", "justattribute", "=", "justattribute", ",", "\n", "justrelation", "=", "justrelation", ")", "\n", "total_match_num", "+=", "best_match_num", "\n", "total_test_num", "+=", "test_triple_num", "\n", "total_gold_num", "+=", "gold_triple_num", "\n", "# clear the matching triple dictionary for the next AMR pair", "\n", "match_triple_dict", ".", "clear", "(", ")", "\n", "if", "not", "single_score", ":", "# if each AMR pair should have a score, compute and output it here", "\n", "            ", "yield", "compute_f", "(", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", ")", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\"Total match number, total triple number in AMR 1, and total triple number in AMR 2:\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "total_match_num", ",", "total_test_num", ",", "total_gold_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"---------------------------------------------------------------------------------\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "single_score", ":", "# output document-level smatch score (a single f-score for all AMR pairs in two files)", "\n", "        ", "yield", "compute_f", "(", "total_match_num", ",", "total_test_num", ",", "total_gold_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch.main": [[822, 857], ["smatch.score_amr_pairs", "args.f[].close", "args.f[].close", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.score_amr_pairs", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "", "def", "main", "(", "arguments", ")", ":", "\n", "    ", "\"\"\"\n    Main function of smatch score calculation\n    \"\"\"", "\n", "global", "verbose", "\n", "global", "veryVerbose", "\n", "global", "iteration_num", "\n", "global", "single_score", "\n", "global", "pr_flag", "\n", "global", "match_triple_dict", "\n", "# set the iteration number", "\n", "# total iteration number = restart number + 1", "\n", "iteration_num", "=", "arguments", ".", "r", "+", "1", "\n", "if", "arguments", ".", "ms", ":", "\n", "        ", "single_score", "=", "False", "\n", "", "if", "arguments", ".", "v", ":", "\n", "        ", "verbose", "=", "True", "\n", "", "if", "arguments", ".", "vv", ":", "\n", "        ", "veryVerbose", "=", "True", "\n", "", "if", "arguments", ".", "pr", ":", "\n", "        ", "pr_flag", "=", "True", "\n", "# significant digits to print out", "\n", "", "arguments", ".", "significant", "=", "4", "\n", "floatdisplay", "=", "\"%%.%df\"", "%", "arguments", ".", "significant", "\n", "for", "(", "precision", ",", "recall", ",", "best_f_score", ")", "in", "score_amr_pairs", "(", "args", ".", "f", "[", "0", "]", ",", "args", ".", "f", "[", "1", "]", ",", "\n", "justinstance", "=", "arguments", ".", "justinstance", ",", "\n", "justattribute", "=", "arguments", ".", "justattribute", ",", "\n", "justrelation", "=", "arguments", ".", "justrelation", ")", ":", "\n", "# print(\"Sentence\", sent_num)", "\n", "        ", "if", "pr_flag", ":", "\n", "            ", "print", "(", "\"Precision: \"", "+", "floatdisplay", "%", "precision", ")", "\n", "print", "(", "\"Recall: \"", "+", "floatdisplay", "%", "recall", ")", "\n", "", "print", "(", "\"F-score: \"", "+", "floatdisplay", "%", "best_f_score", ")", "\n", "", "args", ".", "f", "[", "0", "]", ".", "close", "(", ")", "\n", "args", ".", "f", "[", "1", "]", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch-table.get_names": [[22, 55], ["os.walk", "len", "print", "name_list.append", "os.path.exists"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["def", "get_names", "(", "file_dir", ",", "files", ")", ":", "\n", "    ", "\"\"\"\n    Get the annotator name list based on a list of files\n    Args:\n    file_dir: AMR file folder\n    files: a list of AMR names, e.g. nw_wsj_0001_1\n\n    Returns:\n   a list of user names who annotate all the files\n    \"\"\"", "\n", "# for each user, check if they have files available", "\n", "# return user name list", "\n", "total_list", "=", "[", "]", "\n", "name_list", "=", "[", "]", "\n", "get_sub", "=", "False", "\n", "for", "path", ",", "subdir", ",", "dir_files", "in", "os", ".", "walk", "(", "file_dir", ")", ":", "\n", "        ", "if", "not", "get_sub", ":", "\n", "            ", "total_list", "=", "subdir", "[", ":", "]", "\n", "get_sub", "=", "True", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "for", "user", "in", "total_list", ":", "\n", "        ", "has_file", "=", "True", "\n", "for", "f", "in", "files", ":", "\n", "            ", "file_path", "=", "file_dir", "+", "user", "+", "\"/\"", "+", "f", "+", "\".txt\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "file_path", ")", ":", "\n", "                ", "has_file", "=", "False", "\n", "break", "\n", "", "", "if", "has_file", ":", "\n", "            ", "name_list", ".", "append", "(", "user", ")", "\n", "", "", "if", "len", "(", "name_list", ")", "==", "0", ":", "\n", "        ", "print", "(", "\"********Error: Cannot find any user who completes the files*************\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "", "return", "name_list", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch-table.compute_files": [[57, 130], ["smatch.compute_f", "smatch.get_amr_line", "smatch.get_amr_line", "amr.AMR.parse_AMR_line", "amr.AMR.parse_AMR_line", "amr.AMR.parse_AMR_line.rename_node", "amr.AMR.parse_AMR_line.rename_node", "amr.AMR.parse_AMR_line.get_triples", "amr.AMR.parse_AMR_line.get_triples", "smatch.get_best_match", "smatch.match_triple_dict.clear", "os.path.exists", "print", "os.path.exists", "print", "open", "open", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "len", "len", "print", "len", "len", "len", "len", "len", "len", "smatch.print_alignment", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_amr_line", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_amr_line", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.parse_AMR_line", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.parse_AMR_line", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.print_alignment"], ["", "def", "compute_files", "(", "user1", ",", "user2", ",", "file_list", ",", "dir_pre", ",", "start_num", ")", ":", "\n", "\n", "    ", "\"\"\"\n    Compute the smatch scores for a file list between two users\n    Args:\n    user1: user 1 name\n    user2: user 2 name\n    file_list: file list\n    dir_pre: the file location prefix\n    start_num: the number of restarts in smatch\n    Returns:\n    smatch f score.\n\n    \"\"\"", "\n", "match_total", "=", "0", "\n", "test_total", "=", "0", "\n", "gold_total", "=", "0", "\n", "for", "fi", "in", "file_list", ":", "\n", "        ", "file1", "=", "dir_pre", "+", "user1", "+", "\"/\"", "+", "fi", "+", "\".txt\"", "\n", "file2", "=", "dir_pre", "+", "user2", "+", "\"/\"", "+", "fi", "+", "\".txt\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "file1", ")", ":", "\n", "            ", "print", "(", "\"*********Error: \"", ",", "file1", ",", "\"does not exist*********\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "-", "1.00", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "file2", ")", ":", "\n", "            ", "print", "(", "\"*********Error: \"", ",", "file2", ",", "\"does not exist*********\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "-", "1.00", "\n", "", "try", ":", "\n", "            ", "file1_h", "=", "open", "(", "file1", ",", "\"r\"", ")", "\n", "file2_h", "=", "open", "(", "file2", ",", "\"r\"", ")", "\n", "", "except", "IOError", ":", "\n", "            ", "print", "(", "\"Cannot open the files\"", ",", "file1", ",", "file2", ",", "file", "=", "ERROR_LOG", ")", "\n", "break", "\n", "", "cur_amr1", "=", "smatch", ".", "get_amr_line", "(", "file1_h", ")", "\n", "cur_amr2", "=", "smatch", ".", "get_amr_line", "(", "file2_h", ")", "\n", "if", "cur_amr1", "==", "\"\"", ":", "\n", "            ", "print", "(", "\"AMR 1 is empty\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "continue", "\n", "", "if", "cur_amr2", "==", "\"\"", ":", "\n", "            ", "print", "(", "\"AMR 2 is empty\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "continue", "\n", "", "amr1", "=", "amr", ".", "AMR", ".", "parse_AMR_line", "(", "cur_amr1", ")", "\n", "amr2", "=", "amr", ".", "AMR", ".", "parse_AMR_line", "(", "cur_amr2", ")", "\n", "test_label", "=", "\"a\"", "\n", "gold_label", "=", "\"b\"", "\n", "amr1", ".", "rename_node", "(", "test_label", ")", "\n", "amr2", ".", "rename_node", "(", "gold_label", ")", "\n", "(", "test_inst", ",", "test_rel1", ",", "test_rel2", ")", "=", "amr1", ".", "get_triples", "(", ")", "\n", "(", "gold_inst", ",", "gold_rel1", ",", "gold_rel2", ")", "=", "amr2", ".", "get_triples", "(", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"Instance triples of file 1:\"", ",", "len", "(", "test_inst", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "test_inst", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of file 1:\"", ",", "len", "(", "test_rel1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "test_rel1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of file 1:\"", ",", "len", "(", "test_rel2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "test_rel2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Instance triples of file 2:\"", ",", "len", "(", "gold_inst", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "gold_inst", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of file 2:\"", ",", "len", "(", "gold_rel1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "gold_rel1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of file 2:\"", ",", "len", "(", "gold_rel2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "gold_rel2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "(", "best_match", ",", "best_match_num", ")", "=", "smatch", ".", "get_best_match", "(", "test_inst", ",", "test_rel1", ",", "test_rel2", ",", "\n", "gold_inst", ",", "gold_rel1", ",", "gold_rel2", ",", "\n", "test_label", ",", "gold_label", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"best match number\"", ",", "best_match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Best Match:\"", ",", "smatch", ".", "print_alignment", "(", "best_match", ",", "test_inst", ",", "gold_inst", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "match_total", "+=", "best_match_num", "\n", "test_total", "+=", "(", "len", "(", "test_inst", ")", "+", "len", "(", "test_rel1", ")", "+", "len", "(", "test_rel2", ")", ")", "\n", "gold_total", "+=", "(", "len", "(", "gold_inst", ")", "+", "len", "(", "gold_rel1", ")", "+", "len", "(", "gold_rel2", ")", ")", "\n", "smatch", ".", "match_triple_dict", ".", "clear", "(", ")", "\n", "", "(", "precision", ",", "recall", ",", "f_score", ")", "=", "smatch", ".", "compute_f", "(", "match_total", ",", "test_total", ",", "gold_total", ")", "\n", "return", "\"%.2f\"", "%", "f_score", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch-table.get_max_width": [[132, 134], ["max", "len", "str"], "function", ["None"], ["", "def", "get_max_width", "(", "table", ",", "index", ")", ":", "\n", "    ", "return", "max", "(", "[", "len", "(", "str", "(", "row", "[", "index", "]", ")", ")", "for", "row", "in", "table", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch-table.pprint_table": [[136, 150], ["range", "len", "col_paddings.append", "print", "range", "print", "smatch-table.get_max_width", "row[].ljust", "len", "str().rjust", "print", "str"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch-table.get_max_width", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "pprint_table", "(", "table", ")", ":", "\n", "    ", "\"\"\"\n    Print a table in pretty format\n\n    \"\"\"", "\n", "col_paddings", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "table", "[", "0", "]", ")", ")", ":", "\n", "        ", "col_paddings", ".", "append", "(", "get_max_width", "(", "table", ",", "i", ")", ")", "\n", "", "for", "row", "in", "table", ":", "\n", "        ", "print", "(", "row", "[", "0", "]", ".", "ljust", "(", "col_paddings", "[", "0", "]", "+", "1", ")", ",", "end", "=", "\"\"", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "row", ")", ")", ":", "\n", "            ", "col", "=", "str", "(", "row", "[", "i", "]", ")", ".", "rjust", "(", "col_paddings", "[", "i", "]", "+", "2", ")", "\n", "print", "(", "col", ",", "end", "=", "''", ")", "\n", "", "print", "(", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch-table.build_arg_parser": [[152, 165], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType"], "function", ["None"], ["", "", "def", "build_arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Build an argument parser using argparse. Use it when python version is 2.7 or later.\n\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Smatch table calculator -- arguments\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--fl\"", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "help", "=", "'AMR ID list file'", ")", "\n", "parser", ".", "add_argument", "(", "'-f'", ",", "nargs", "=", "'+'", ",", "help", "=", "'AMR IDs (at least one)'", ")", "\n", "parser", ".", "add_argument", "(", "\"-p\"", ",", "nargs", "=", "'*'", ",", "help", "=", "\"User list (can be none)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--fd\"", ",", "default", "=", "isi_dir_pre", ",", "help", "=", "\"AMR File directory. Default=location on isi machine\"", ")", "\n", "parser", ".", "add_argument", "(", "'-r'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'Restart number (Default:4)'", ")", "\n", "parser", ".", "add_argument", "(", "'-v'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Verbose output (Default:False)'", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch-table.build_arg_parser2": [[167, 182], ["optparse.OptionParser", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.set_defaults"], "function", ["None"], ["", "def", "build_arg_parser2", "(", ")", ":", "\n", "    ", "\"\"\"\n    Build an argument parser using optparse. Use it when python version is 2.5 or 2.6.\n\n    \"\"\"", "\n", "usage_str", "=", "\"Smatch table calculator -- arguments\"", "\n", "parser", "=", "optparse", ".", "OptionParser", "(", "usage", "=", "usage_str", ")", "\n", "parser", ".", "add_option", "(", "\"--fl\"", ",", "dest", "=", "\"fl\"", ",", "type", "=", "\"string\"", ",", "help", "=", "'AMR ID list file'", ")", "\n", "parser", ".", "add_option", "(", "\"-f\"", ",", "dest", "=", "\"f\"", ",", "type", "=", "\"string\"", ",", "action", "=", "\"callback\"", ",", "callback", "=", "cb", ",", "help", "=", "\"AMR IDs (at least one)\"", ")", "\n", "parser", ".", "add_option", "(", "\"-p\"", ",", "dest", "=", "\"p\"", ",", "type", "=", "\"string\"", ",", "action", "=", "\"callback\"", ",", "callback", "=", "cb", ",", "help", "=", "\"User list\"", ")", "\n", "parser", ".", "add_option", "(", "\"--fd\"", ",", "dest", "=", "\"fd\"", ",", "type", "=", "\"string\"", ",", "help", "=", "\"file directory\"", ")", "\n", "parser", ".", "add_option", "(", "\"-r\"", ",", "\"--restart\"", ",", "dest", "=", "\"r\"", ",", "type", "=", "\"int\"", ",", "help", "=", "'Restart number (Default: 4)'", ")", "\n", "parser", ".", "add_option", "(", "\"-v\"", ",", "\"--verbose\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"v\"", ",", "help", "=", "'Verbose output (Default:False)'", ")", "\n", "parser", ".", "set_defaults", "(", "r", "=", "4", ",", "v", "=", "False", ",", "ms", "=", "False", ",", "fd", "=", "isi_dir_pre", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch-table.cb": [[184, 199], ["getattr", "setattr", "arguments.extend", "arguments.append", "getattr", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend"], ["", "def", "cb", "(", "option", ",", "value", ",", "parser", ")", ":", "\n", "    ", "\"\"\"\n    Callback function to handle variable number of arguments in optparse\n\n    \"\"\"", "\n", "arguments", "=", "[", "value", "]", "\n", "for", "arg", "in", "parser", ".", "rargs", ":", "\n", "        ", "if", "arg", "[", "0", "]", "!=", "\"-\"", ":", "\n", "            ", "arguments", ".", "append", "(", "arg", ")", "\n", "", "else", ":", "\n", "            ", "del", "parser", ".", "rargs", "[", ":", "len", "(", "arguments", ")", "]", "\n", "break", "\n", "", "", "if", "getattr", "(", "parser", ".", "values", ",", "option", ".", "dest", ")", ":", "\n", "        ", "arguments", ".", "extend", "(", "getattr", "(", "parser", ".", "values", ",", "option", ".", "dest", ")", ")", "\n", "", "setattr", "(", "parser", ".", "values", ",", "option", ".", "dest", ",", "arguments", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch-table.check_args": [[201, 259], ["os.path.exists", "print", "args.fl.readline", "args.fl.readline.strip().split", "smatch-table.get_names", "len", "print", "len", "print", "get_names.index", "get_names.pop", "get_names.append", "enumerate", "print", "len", "print", "len", "len", "print", "args.fl.readline.strip", "print", "get_names.pop", "os.path.exists", "print", "pop_name.append"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch-table.get_names", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "check_args", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Parse arguments and check if the arguments are valid\n\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "fd", ")", ":", "\n", "        ", "print", "(", "\"Not a valid path\"", ",", "args", ".", "fd", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "[", "]", ",", "[", "]", ",", "False", "\n", "", "if", "args", ".", "fl", "is", "not", "None", ":", "\n", "# we already ensure the file can be opened and opened the file", "\n", "        ", "file_line", "=", "args", ".", "fl", ".", "readline", "(", ")", "\n", "amr_ids", "=", "file_line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "", "elif", "args", ".", "f", "is", "None", ":", "\n", "        ", "print", "(", "\"No AMR ID was given\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "[", "]", ",", "[", "]", ",", "False", "\n", "", "else", ":", "\n", "        ", "amr_ids", "=", "args", ".", "f", "\n", "", "names", "=", "[", "]", "\n", "check_name", "=", "True", "\n", "if", "args", ".", "p", "is", "None", ":", "\n", "        ", "names", "=", "get_names", "(", "args", ".", "fd", ",", "amr_ids", ")", "\n", "# no need to check names", "\n", "check_name", "=", "False", "\n", "if", "len", "(", "names", ")", "==", "0", ":", "\n", "            ", "print", "(", "\"Cannot find any user who tagged these AMR\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "[", "]", ",", "[", "]", ",", "False", "\n", "", "else", ":", "\n", "            ", "names", "=", "args", ".", "p", "\n", "", "", "if", "len", "(", "names", ")", "==", "0", ":", "\n", "        ", "print", "(", "\"No user was given\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "[", "]", ",", "[", "]", ",", "False", "\n", "", "if", "len", "(", "names", ")", "==", "1", ":", "\n", "        ", "print", "(", "\"Only one user is given. Smatch calculation requires at least two users.\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "[", "]", ",", "[", "]", ",", "False", "\n", "", "if", "\"consensus\"", "in", "names", ":", "\n", "        ", "con_index", "=", "names", ".", "index", "(", "\"consensus\"", ")", "\n", "names", ".", "pop", "(", "con_index", ")", "\n", "names", ".", "append", "(", "\"consensus\"", ")", "\n", "# check if all the AMR_id and user combinations are valid", "\n", "", "if", "check_name", ":", "\n", "        ", "pop_name", "=", "[", "]", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "names", ")", ":", "\n", "            ", "for", "amr", "in", "amr_ids", ":", "\n", "                ", "amr_path", "=", "args", ".", "fd", "+", "name", "+", "\"/\"", "+", "amr", "+", "\".txt\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "amr_path", ")", ":", "\n", "                    ", "print", "(", "\"User\"", ",", "name", ",", "\"fails to tag AMR\"", ",", "amr", ",", "file", "=", "ERROR_LOG", ")", "\n", "pop_name", ".", "append", "(", "i", ")", "\n", "break", "\n", "", "", "", "if", "len", "(", "pop_name", ")", "!=", "0", ":", "\n", "            ", "pop_num", "=", "0", "\n", "for", "p", "in", "pop_name", ":", "\n", "                ", "print", "(", "\"Deleting user\"", ",", "names", "[", "p", "-", "pop_num", "]", ",", "\"from the name list\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "names", ".", "pop", "(", "p", "-", "pop_num", ")", "\n", "pop_num", "+=", "1", "\n", "", "", "if", "len", "(", "names", ")", "<", "2", ":", "\n", "            ", "print", "(", "\"Not enough users to evaluate. Smatch requires >2 users who tag all the AMRs\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "\"\"", ",", "\"\"", ",", "False", "\n", "", "", "return", "amr_ids", ",", "names", ",", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch-table.main": [[261, 298], ["smatch-table.check_args", "len", "range", "table[].append", "range", "range", "range", "smatch-table.pprint_table", "table.append", "table[].append", "table[].append", "range", "range", "time.clock", "table[].append", "time.clock", "table[].append", "smatch-table.compute_files"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch-table.check_args", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch-table.pprint_table", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch-table.compute_files"], ["", "def", "main", "(", "arguments", ")", ":", "\n", "    ", "global", "verbose", "\n", "(", "ids", ",", "names", ",", "result", ")", "=", "check_args", "(", "arguments", ")", "\n", "if", "arguments", ".", "v", ":", "\n", "        ", "verbose", "=", "True", "\n", "", "if", "not", "result", ":", "\n", "        ", "return", "0", "\n", "", "acc_time", "=", "0", "\n", "len_name", "=", "len", "(", "names", ")", "\n", "table", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len_name", "+", "1", ")", ":", "\n", "        ", "table", ".", "append", "(", "[", "]", ")", "\n", "", "table", "[", "0", "]", ".", "append", "(", "\"\"", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "len_name", ")", ":", "\n", "        ", "table", "[", "0", "]", ".", "append", "(", "names", "[", "i", "]", ")", "\n", "", "for", "i", "in", "range", "(", "0", ",", "len_name", ")", ":", "\n", "        ", "table", "[", "i", "+", "1", "]", ".", "append", "(", "names", "[", "i", "]", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "len_name", ")", ":", "\n", "            ", "if", "i", "!=", "j", ":", "\n", "                ", "start", "=", "time", ".", "clock", "(", ")", "\n", "table", "[", "i", "+", "1", "]", ".", "append", "(", "compute_files", "(", "names", "[", "i", "]", ",", "names", "[", "j", "]", ",", "ids", ",", "args", ".", "fd", ",", "args", ".", "r", ")", ")", "\n", "end", "=", "time", ".", "clock", "(", ")", "\n", "if", "table", "[", "i", "+", "1", "]", "[", "-", "1", "]", "!=", "-", "1.0", ":", "\n", "                    ", "acc_time", "+=", "end", "-", "start", "\n", "", "", "else", ":", "\n", "                ", "table", "[", "i", "+", "1", "]", ".", "append", "(", "\"\"", ")", "\n", "# check table", "\n", "", "", "", "for", "i", "in", "range", "(", "0", ",", "len_name", "+", "1", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "0", ",", "len_name", "+", "1", ")", ":", "\n", "            ", "if", "i", "!=", "j", ":", "\n", "                ", "if", "table", "[", "i", "]", "[", "j", "]", "!=", "table", "[", "j", "]", "[", "i", "]", ":", "\n", "                    ", "if", "table", "[", "i", "]", "[", "j", "]", ">", "table", "[", "j", "]", "[", "i", "]", ":", "\n", "                        ", "table", "[", "j", "]", "[", "i", "]", "=", "table", "[", "i", "]", "[", "j", "]", "\n", "", "else", ":", "\n", "                        ", "table", "[", "i", "]", "[", "j", "]", "=", "table", "[", "j", "]", "[", "i", "]", "\n", "", "", "", "", "", "pprint_table", "(", "table", ")", "\n", "return", "acc_time", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.amr.AMR.__init__": [[38, 70], ["len"], "methods", ["None"], ["        ", "\"\"\"\n        node_list: names of nodes in AMR graph, e.g. \"a11\", \"n\"\n        node_value_list: values of nodes in AMR graph, e.g. \"group\" for a node named \"g\"\n        relation_list: list of relations between two nodes\n        attribute_list: list of attributes (links between one node and one constant value)\n\n        \"\"\"", "\n", "# initialize AMR graph nodes using list of nodes name", "\n", "# root, by default, is the first in var_list", "\n", "attribute_list2", "=", "[", "]", "\n", "for", "dct", "in", "attribute_list", ":", "\n", "            ", "dct2", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "item", "in", "dct", ":", "\n", "                ", "if", "len", "(", "dct", "[", "item", "]", ")", ">", "1", "and", "dct", "[", "item", "]", ".", "endswith", "(", "\"_\"", ")", ":", "\n", "                    ", "dct", "[", "item", "]", "=", "'\"'", "+", "dct", "[", "item", "]", "[", "0", ":", "-", "1", "]", "+", "'\"'", "\n", "", "dct2", "[", "item", "]", "=", "dct", "[", "item", "]", "\n", "", "attribute_list2", ".", "append", "(", "dct2", ")", "\n", "", "reent2", "=", "[", "]", "\n", "for", "r", "in", "reent", ":", "\n", "            ", "if", "len", "(", "r", "[", "2", "]", ")", ">", "1", "and", "r", "[", "2", "]", ".", "endswith", "(", "\"_\"", ")", ":", "\n", "                ", "reent2", ".", "append", "(", "(", "r", "[", "0", "]", ",", "r", "[", "1", "]", ",", "'\"'", "+", "r", "[", "2", "]", "[", "0", ":", "-", "1", "]", "+", "'\"'", ")", ")", "\n", "", "else", ":", "\n", "                ", "reent2", ".", "append", "(", "r", ")", "\n", "", "", "allrelations2", "=", "[", "]", "\n", "for", "r", "in", "allrelations", ":", "\n", "            ", "if", "len", "(", "r", "[", "2", "]", ")", ">", "1", "and", "r", "[", "2", "]", ".", "endswith", "(", "\"_\"", ")", ":", "\n", "                ", "allrelations2", ".", "append", "(", "(", "r", "[", "0", "]", ",", "r", "[", "1", "]", ",", "'\"'", "+", "r", "[", "2", "]", "[", "0", ":", "-", "1", "]", "+", "'\"'", ")", ")", "\n", "", "else", ":", "\n", "                ", "allrelations2", ".", "append", "(", "r", ")", "\n", "", "", "if", "node_list", "is", "None", ":", "\n", "            ", "self", ".", "nodes", "=", "[", "]", "\n", "self", ".", "root", "=", "None", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.amr.AMR.rename_node": [[71, 87], ["range", "enumerate", "len", "enumerate", "str"], "methods", ["None"], ["            ", "self", ".", "nodes", "=", "node_list", "[", ":", "]", "\n", "if", "len", "(", "node_list", ")", "!=", "0", ":", "\n", "                ", "self", ".", "root", "=", "node_list", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "root", "=", "None", "\n", "", "", "if", "node_value_list", "is", "None", ":", "\n", "            ", "self", ".", "node_values", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "node_values", "=", "node_value_list", "[", ":", "]", "\n", "", "if", "relation_list", "is", "None", ":", "\n", "            ", "self", ".", "relations", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "relations", "=", "relation_list", "[", ":", "]", "\n", "", "if", "attribute_list2", "is", "None", ":", "\n", "            ", "self", ".", "attributes", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "attributes", "=", "attribute_list2", "[", ":", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.amr.AMR.get_triples": [[88, 110], ["range", "len", "instance_triple.append", "relation_triple.append", "attribute_triple.append"], "methods", ["None"], ["\n", "", "self", ".", "reent", "=", "reent2", "\n", "self", ".", "allrelations", "=", "allrelations2", "\n", "\n", "", "def", "rename_node", "(", "self", ",", "prefix", ")", ":", "\n", "        ", "\"\"\"\n        Rename AMR graph nodes to prefix + node_index to avoid nodes with the same name in two different AMRs.\n\n        \"\"\"", "\n", "node_map_dict", "=", "{", "}", "\n", "# map each node to its new name (e.g. \"a1\")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "node_map_dict", "[", "self", ".", "nodes", "[", "i", "]", "]", "=", "prefix", "+", "str", "(", "i", ")", "\n", "# update node name", "\n", "", "for", "i", ",", "v", "in", "enumerate", "(", "self", ".", "nodes", ")", ":", "\n", "            ", "self", ".", "nodes", "[", "i", "]", "=", "node_map_dict", "[", "v", "]", "\n", "# update node name in relations", "\n", "", "for", "i", ",", "d", "in", "enumerate", "(", "self", ".", "relations", ")", ":", "\n", "            ", "new_dict", "=", "{", "}", "\n", "for", "k", ",", "v_lst", "in", "d", ".", "items", "(", ")", ":", "\n", "                ", "for", "v", "in", "v_lst", ":", "\n", "                    ", "if", "node_map_dict", "[", "k", "]", "not", "in", "new_dict", ":", "\n", "                        ", "new_dict", "[", "node_map_dict", "[", "k", "]", "]", "=", "[", "v", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.amr.AMR.get_triples2": [[112, 137], ["range", "len", "instance_triple.append", "relation_triple.append", "relation_triple.append"], "methods", ["None"], ["                        ", "new_dict", "[", "node_map_dict", "[", "k", "]", "]", ".", "append", "(", "v", ")", "\n", "", "", "", "self", ".", "relations", "[", "i", "]", "=", "new_dict", "\n", "\n", "", "", "def", "get_triples", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the triples in three lists.\n        instance_triple: a triple representing an instance. E.g. instance(w, want-01)\n        attribute triple: relation of attributes, e.g. polarity(w, - )\n        and relation triple, e.g. arg0 (w, b)\n\n        \"\"\"", "\n", "instance_triple", "=", "[", "]", "\n", "relation_triple", "=", "[", "]", "\n", "attribute_triple", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "instance_triple", ".", "append", "(", "(", "\"instance\"", ",", "self", ".", "nodes", "[", "i", "]", ",", "self", ".", "node_values", "[", "i", "]", ")", ")", "\n", "# k is the other node this node has relation with", "\n", "# v is relation name", "\n", "for", "k", ",", "v_lst", "in", "self", ".", "relations", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "for", "v", "in", "v_lst", ":", "\n", "                    ", "relation_triple", ".", "append", "(", "(", "v", ",", "self", ".", "nodes", "[", "i", "]", ",", "k", ")", ")", "\n", "# k2 is the attribute name", "\n", "# v2 is the attribute value", "\n", "", "", "for", "k2", ",", "v2", "in", "self", ".", "attributes", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "attribute_triple", ".", "append", "(", "(", "k2", ",", "self", ".", "nodes", "[", "i", "]", ",", "v2", ")", ")", "\n", "", "", "return", "instance_triple", ",", "attribute_triple", ",", "relation_triple", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.amr.AMR.__str__": [[139, 154], ["range", "len", "lines.append", "lines.append", "lines.append", "lines.append", "lines.append", "str"], "methods", ["None"], ["\n", "", "def", "get_triples2", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the triples in two lists:\n        instance_triple: a triple representing an instance. E.g. instance(w, want-01)\n        relation_triple: a triple representing all relations. E.g arg0 (w, b) or E.g. polarity(w, - )\n        Note that we do not differentiate between attribute triple and relation triple. Both are considered as relation\n        triples.\n        All triples are represented by (triple_type, argument 1 of the triple, argument 2 of the triple)\n\n        \"\"\"", "\n", "instance_triple", "=", "[", "]", "\n", "relation_triple", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "# an instance triple is instance(node name, node value).", "\n", "# For example, instance(b, boy).", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.amr.AMR.__repr__": [[155, 157], ["amr.AMR.__str__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.ATP.generate_amrized_srl.SRL.__str__"], ["            ", "instance_triple", ".", "append", "(", "(", "\"instance\"", ",", "self", ".", "nodes", "[", "i", "]", ",", "self", ".", "node_values", "[", "i", "]", ")", ")", "\n", "# k is the other node this node has relation with", "\n", "# v is relation name", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.amr.AMR.output_amr": [[158, 164], ["print", "amr.AMR.__str__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.ATP.generate_amrized_srl.SRL.__str__"], ["for", "k", ",", "v_lst", "in", "self", ".", "relations", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "for", "v", "in", "v_lst", ":", "\n", "                    ", "relation_triple", ".", "append", "(", "(", "v", ",", "self", ".", "nodes", "[", "i", "]", ",", "k", ")", ")", "\n", "# k2 is the attribute name", "\n", "# v2 is the attribute value", "\n", "", "", "for", "k2", ",", "v2", "in", "self", ".", "attributes", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "relation_triple", ".", "append", "(", "(", "k2", ",", "self", ".", "nodes", "[", "i", "]", ",", "v2", ")", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.amr.AMR.get_amr_line": [[165, 191], ["line.strip.strip.strip", "line.strip.strip.strip().startswith", "cur_amr.append", "line.strip.strip.strip", "line.strip.strip.strip"], "methods", ["None"], ["", "", "return", "instance_triple", ",", "relation_triple", "\n", "\n", "", "def", "get_triples3", "(", "self", ")", ":", "\n", "        ", "relation_triple", "=", "[", "(", "self", ".", "nodes", "[", "0", "]", ",", "\"TOP\"", ",", "self", ".", "node_values", "[", "0", "]", ")", "]", "\n", "relation_triple", ".", "extend", "(", "self", ".", "allrelations", ")", "\n", "return", "relation_triple", "\n", "\n", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Generate AMR string for better readability\n\n        \"\"\"", "\n", "lines", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "lines", ".", "append", "(", "\"Node \"", "+", "str", "(", "i", ")", "+", "\" \"", "+", "self", ".", "nodes", "[", "i", "]", ")", "\n", "lines", ".", "append", "(", "\"Value: \"", "+", "self", ".", "node_values", "[", "i", "]", ")", "\n", "lines", ".", "append", "(", "\"Relations:\"", ")", "\n", "for", "k", ",", "v_lst", "in", "self", ".", "relations", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "for", "v", "in", "v_lst", ":", "\n", "                    ", "lines", ".", "append", "(", "\"Node \"", "+", "k", "+", "\" via \"", "+", "v", ")", "\n", "", "", "for", "k2", ",", "v2", "in", "self", ".", "attributes", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "lines", ".", "append", "(", "\"Attribute: \"", "+", "k2", "+", "\" value \"", "+", "v2", ")", "\n", "", "", "return", "\"\\n\"", ".", "join", "(", "lines", ")", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__str__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.amr.AMR.parse_AMR_line": [[192, 426], ["collections.defaultdict", "collections.defaultdict", "enumerate", "attribute_list[].append", "amr.AMR", "line.strip", "relation_list.append", "attribute_list.append", "print", "node_value_list.append", "cur_charseq.append", "cur_charseq.append", "node_rel_list.append", "cur_charseq.append", "node_attr_list.append", "print", "cur_charseq.append", "node_rel_list.append", "node_attr_list.append", "temp_attr_value.split", "parts[].strip", "parts[].strip", "cur_charseq.append", "stack.append", "node_name_list.append", "print", "stack.pop", "cur_charseq.append", "len", "print", "len", "print", "node_relation_dict2[].append", "node_relation_dict1[].append", "print", "cur_charseq.append", "len", "print", "temp_attr_value.split", "parts[].strip", "parts[].strip", "parts[].strip.endswith", "cur_relation_name.endswith", "node_relation_dict1[].append", "node_relation_dict1[].append", "len", "print", "node_relation_dict1[].append", "node_relation_dict2[].append", "node_relation_dict1[].append"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "output_amr", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Output AMR string\n\n        \"\"\"", "\n", "print", ">>", "DEBUG_LOG", ",", "self", ".", "__str__", "(", ")", "\n", "\n", "\n", "", "@", "staticmethod", "\n", "def", "parse_AMR_line", "(", "line", ",", "normalize_inv", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Parse a AMR from line representation to an AMR object.\n        This parsing algorithm scans the line once and process each character, in a shift-reduce style.\n\n        \"\"\"", "\n", "# Current state. It denotes the last significant symbol encountered. 1 for (, 2 for :, 3 for /,", "\n", "# and 0 for start state or ')'", "\n", "# Last significant symbol is ( --- start processing node name", "\n", "# Last significant symbol is : --- start processing relation name", "\n", "# Last significant symbol is / --- start processing node value (concept name)", "\n", "# Last significant symbol is ) --- current node processing is complete", "\n", "# Note that if these symbols are inside parenthesis, they are not significant symbols.", "\n", "state", "=", "0", "\n", "stack", "=", "[", "]", "\n", "# current not-yet-reduced character sequence", "\n", "cur_charseq", "=", "[", "]", "\n", "# key: node name value: node value", "\n", "node_dict", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "# node name list (order: occurrence of the node)", "\n", "node_name_list", "=", "[", "]", "\n", "# key: node name:  value: list of (relation name, the other node name)", "\n", "node_relation_dict1", "=", "defaultdict", "(", "list", ")", "\n", "# key: node name, value: list of (attribute name, const value) or (relation name, unseen node name)", "\n", "node_relation_dict2", "=", "defaultdict", "(", "list", ")", "\n", "allrelations", "=", "[", "]", "\n", "reent", "=", "[", "]", "\n", "# current relation name", "\n", "cur_relation_name", "=", "\"\"", "\n", "# having unmatched quote string", "\n", "in_quote", "=", "False", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "line", ".", "strip", "(", ")", ")", ":", "\n", "            ", "if", "c", "==", "\" \"", ":", "\n", "# allow space in relation name", "\n", "                ", "if", "state", "==", "2", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "", "continue", "\n", "", "if", "c", "==", "\"\\\"\"", ":", "\n", "# flip in_quote value when a quote symbol is encountered", "\n", "# insert placeholder if in_quote from last symbol", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "'_'", ")", "\n", "", "in_quote", "=", "not", "in_quote", "\n", "", "elif", "c", "==", "\"(\"", ":", "\n", "# not significant symbol if inside quote", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# get the attribute name", "\n", "# e.g :arg0 (x ...", "\n", "# at this point we get \"arg0\"", "\n", "", "if", "state", "==", "2", ":", "\n", "# in this state, current relation name should be empty", "\n", "                    ", "if", "cur_relation_name", "!=", "\"\"", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "\"Format error when processing \"", ",", "line", "[", "0", ":", "i", "+", "1", "]", "\n", "return", "None", "\n", "# update current relation name for future use", "\n", "", "cur_relation_name", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", ".", "strip", "(", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "", "state", "=", "1", "\n", "", "elif", "c", "==", "\":\"", ":", "\n", "# not significant symbol if inside quote", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# Last significant symbol is \"/\". Now we encounter \":\"", "\n", "# Example:", "\n", "# :OR (o2 / *OR*", "\n", "#    :mod (o3 / official)", "\n", "#  gets node value \"*OR*\" at this point", "\n", "", "if", "state", "==", "3", ":", "\n", "                    ", "node_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "# clear current char sequence", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "# pop node name (\"o2\" in the above example)", "\n", "cur_node_name", "=", "stack", "[", "-", "1", "]", "\n", "# update node name/value map", "\n", "node_dict", "[", "cur_node_name", "]", "=", "node_value", "\n", "# Last significant symbol is \":\". Now we encounter \":\"", "\n", "# Example:", "\n", "# :op1 w :quant 30", "\n", "# or :day 14 :month 3", "\n", "# the problem is that we cannot decide if node value is attribute value (constant)", "\n", "# or node value (variable) at this moment", "\n", "", "elif", "state", "==", "2", ":", "\n", "                    ", "temp_attr_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "parts", "=", "temp_attr_value", ".", "split", "(", ")", "\n", "if", "len", "(", "parts", ")", "<", "2", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "\"Error in processing; part len < 2\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", "\n", "return", "None", "\n", "# For the above example, node name is \"op1\", and node value is \"w\"", "\n", "# Note that this node name might not be encountered before", "\n", "", "relation_name", "=", "parts", "[", "0", "]", ".", "strip", "(", ")", "\n", "relation_value", "=", "parts", "[", "1", "]", ".", "strip", "(", ")", "\n", "# We need to link upper level node to the current", "\n", "# top of stack is upper level node", "\n", "if", "len", "(", "stack", ")", "==", "0", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "\"Error in processing\"", ",", "line", "[", ":", "i", "]", ",", "relation_name", ",", "relation_value", "\n", "return", "None", "\n", "# if we have not seen this node name before", "\n", "", "if", "relation_name", ".", "endswith", "(", "\"-of\"", ")", "and", "normalize_inv", ":", "\n", "                        ", "allrelations", ".", "append", "(", "(", "relation_value", ",", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "if", "relation_value", "not", "in", "node_dict", ":", "\n", "                            ", "node_relation_dict2", "[", "relation_value", "]", ".", "append", "(", "(", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                            ", "node_relation_dict1", "[", "relation_value", "]", ".", "append", "(", "(", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "", "reent", ".", "append", "(", "(", "relation_value", ",", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                        ", "allrelations", ".", "append", "(", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "if", "relation_value", "not", "in", "node_dict", ":", "\n", "                            ", "node_relation_dict2", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "", "else", ":", "\n", "                            ", "node_relation_dict1", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "", "reent", ".", "append", "(", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "", "", "state", "=", "2", "\n", "", "elif", "c", "==", "\"/\"", ":", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# Last significant symbol is \"(\". Now we encounter \"/\"", "\n", "# Example:", "\n", "# (d / default-01", "\n", "# get \"d\" here", "\n", "", "if", "state", "==", "1", ":", "\n", "                    ", "node_name", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "# if this node name is already in node_dict, it is duplicate", "\n", "if", "node_name", "in", "node_dict", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "\"Duplicate node name \"", ",", "node_name", ",", "\" in parsing AMR\"", "\n", "return", "None", "\n", "# push the node name to stack", "\n", "", "stack", ".", "append", "(", "node_name", ")", "\n", "# add it to node name list", "\n", "node_name_list", ".", "append", "(", "node_name", ")", "\n", "# if this node is part of the relation", "\n", "# Example:", "\n", "# :arg1 (n / nation)", "\n", "# cur_relation_name is arg1", "\n", "# node name is n", "\n", "# we have a relation arg1(upper level node, n)", "\n", "if", "cur_relation_name", "!=", "\"\"", ":", "\n", "# if relation name ends with \"-of\", e.g.\"arg0-of\",", "\n", "# it is reverse of some relation. For example, if a is \"arg0-of\" b,", "\n", "# we can also say b is \"arg0\" a.", "\n", "# If the relation name ends with \"-of\", we store the reverse relation.", "\n", "                        ", "if", "(", "not", "cur_relation_name", ".", "endswith", "(", "\"-of\"", ")", ")", "or", "normalize_inv", "==", "False", ":", "\n", "# stack[-2] is upper_level node we encountered, as we just add node_name to stack", "\n", "                            ", "node_relation_dict1", "[", "stack", "[", "-", "2", "]", "]", ".", "append", "(", "(", "cur_relation_name", ",", "node_name", ")", ")", "\n", "allrelations", ".", "append", "(", "(", "stack", "[", "-", "2", "]", ",", "cur_relation_name", ",", "node_name", ")", ")", "\n", "#if node_name in node_name_list:", "\n", "#\treent.append((stack[-2],cur_relation_name,node_name))", "\n", "", "else", ":", "\n", "# cur_relation_name[:-3] is to delete \"-of\"", "\n", "                            ", "node_relation_dict1", "[", "node_name", "]", ".", "append", "(", "(", "cur_relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "2", "]", ")", ")", "\n", "allrelations", ".", "append", "(", "(", "node_name", ",", "cur_relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "2", "]", ")", ")", "\n", "# clear current_relation_name", "\n", "", "cur_relation_name", "=", "\"\"", "\n", "", "", "else", ":", "\n", "# error if in other state", "\n", "                    ", "print", ">>", "ERROR_LOG", ",", "\"Error in parsing AMR\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", "\n", "return", "None", "\n", "", "state", "=", "3", "\n", "", "elif", "c", "==", "\")\"", ":", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# stack should be non-empty to find upper level node", "\n", "", "if", "len", "(", "stack", ")", "==", "0", ":", "\n", "                    ", "print", ">>", "ERROR_LOG", ",", "\"Unmatched parenthesis at position\"", ",", "i", ",", "\"in processing\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", "\n", "return", "None", "\n", "# Last significant symbol is \":\". Now we encounter \")\"", "\n", "# Example:", "\n", "# :op2 \"Brown\") or :op2 w)", "\n", "# get \\\"Brown\\\" or w here", "\n", "", "if", "state", "==", "2", ":", "\n", "                    ", "temp_attr_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "parts", "=", "temp_attr_value", ".", "split", "(", ")", "\n", "if", "len", "(", "parts", ")", "<", "2", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "\"Error processing\"", ",", "line", "[", ":", "i", "+", "1", "]", ",", "temp_attr_value", "\n", "return", "None", "\n", "", "relation_name", "=", "parts", "[", "0", "]", ".", "strip", "(", ")", "\n", "relation_value", "=", "parts", "[", "1", "]", ".", "strip", "(", ")", "\n", "# store reverse of the relation", "\n", "# we are sure relation_value is a node here, as \"-of\" relation is only between two nodes", "\n", "if", "relation_name", ".", "endswith", "(", "\"-of\"", ")", "and", "normalize_inv", ":", "\n", "                        ", "allrelations", ".", "append", "(", "(", "relation_value", ",", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "node_relation_dict1", "[", "relation_value", "]", ".", "append", "(", "(", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "# attribute value not seen before", "\n", "# Note that it might be a constant attribute value, or an unseen node", "\n", "# process this after we have seen all the node names", "\n", "", "else", ":", "\n", "                        ", "allrelations", ".", "append", "(", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "", "if", "relation_value", "not", "in", "node_dict", ":", "\n", "                        ", "node_relation_dict2", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "", "else", ":", "\n", "                        ", "node_relation_dict1", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "#if relation_value in node_name_list:", "\n", "", "reent", ".", "append", "(", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "# Last significant symbol is \"/\". Now we encounter \")\"", "\n", "# Example:", "\n", "# :arg1 (n / nation)", "\n", "# we get \"nation\" here", "\n", "", "elif", "state", "==", "3", ":", "\n", "                    ", "node_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "cur_node_name", "=", "stack", "[", "-", "1", "]", "\n", "# map node name to its value", "\n", "node_dict", "[", "cur_node_name", "]", "=", "node_value", "\n", "#if node_value in node_name_list:", "\n", "#    reent.append((stack[-1],relation_name,relation_value))", "\n", "# pop from stack, as the current node has been processed", "\n", "", "stack", ".", "pop", "(", ")", "\n", "cur_relation_name", "=", "\"\"", "\n", "state", "=", "0", "\n", "", "else", ":", "\n", "# not significant symbols, so we just shift.", "\n", "                ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "#create data structures to initialize an AMR", "\n", "", "", "node_value_list", "=", "[", "]", "\n", "relation_list", "=", "[", "]", "\n", "attribute_list", "=", "[", "]", "\n", "for", "v", "in", "node_name_list", ":", "\n", "            ", "if", "v", "not", "in", "node_dict", ":", "\n", "                ", "print", ">>", "ERROR_LOG", ",", "\"Error: Node name not found\"", ",", "v", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.build_arg_parser": [[47, 72], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType"], "function", ["None"], ["def", "build_arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Build an argument parser using argparse. Use it when python version is 2.7 or later.\n\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Smatch calculator -- arguments\"", ")", "\n", "parser", ".", "add_argument", "(", "'-f'", ",", "nargs", "=", "2", ",", "required", "=", "True", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "\n", "help", "=", "'Two files containing AMR pairs. AMRs in each file are separated by a single blank line'", ")", "\n", "parser", ".", "add_argument", "(", "'-r'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'Restart number (Default:4)'", ")", "\n", "parser", ".", "add_argument", "(", "'--significant'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "'significant digits to output (default: 2)'", ")", "\n", "parser", ".", "add_argument", "(", "'-v'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Verbose output (Default:false)'", ")", "\n", "parser", ".", "add_argument", "(", "'--vv'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Very Verbose output (Default:false)'", ")", "\n", "parser", ".", "add_argument", "(", "'--ms'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Output multiple scores (one AMR pair a score)'", "\n", "'instead of a single document-level smatch score (Default: false)'", ")", "\n", "parser", ".", "add_argument", "(", "'--pr'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"Output precision and recall as well as the f-score. Default: false\"", ")", "\n", "parser", ".", "add_argument", "(", "'--justinstance'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching instances\"", ")", "\n", "parser", ".", "add_argument", "(", "'--justattribute'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching attributes\"", ")", "\n", "parser", ".", "add_argument", "(", "'--justrelation'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching relations\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.build_arg_parser2": [[74, 103], ["optparse.OptionParser", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.set_defaults"], "function", ["None"], ["", "def", "build_arg_parser2", "(", ")", ":", "\n", "    ", "\"\"\"\n    Build an argument parser using optparse. Use it when python version is 2.5 or 2.6.\n\n    \"\"\"", "\n", "usage_str", "=", "\"Smatch calculator -- arguments\"", "\n", "parser", "=", "optparse", ".", "OptionParser", "(", "usage", "=", "usage_str", ")", "\n", "parser", ".", "add_option", "(", "\"-f\"", ",", "\"--files\"", ",", "nargs", "=", "2", ",", "dest", "=", "\"f\"", ",", "type", "=", "\"string\"", ",", "\n", "help", "=", "'Two files containing AMR pairs. AMRs in each file are '", "'separated by a single blank line. This option is required.'", ")", "\n", "parser", ".", "add_option", "(", "\"-r\"", ",", "\"--restart\"", ",", "dest", "=", "\"r\"", ",", "type", "=", "\"int\"", ",", "help", "=", "'Restart number (Default: 4)'", ")", "\n", "parser", ".", "add_option", "(", "'--significant'", ",", "dest", "=", "\"significant\"", ",", "type", "=", "\"int\"", ",", "default", "=", "2", ",", "\n", "help", "=", "'significant digits to output (default: 2)'", ")", "\n", "parser", ".", "add_option", "(", "\"-v\"", ",", "\"--verbose\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"v\"", ",", "help", "=", "'Verbose output (Default:False)'", ")", "\n", "parser", ".", "add_option", "(", "\"--vv\"", ",", "\"--veryverbose\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"vv\"", ",", "\n", "help", "=", "'Very Verbose output (Default:False)'", ")", "\n", "parser", ".", "add_option", "(", "\"--ms\"", ",", "\"--multiple_score\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"ms\"", ",", "\n", "help", "=", "'Output multiple scores (one AMR pair a score) instead of '", "'a single document-level smatch score (Default: False)'", ")", "\n", "parser", ".", "add_option", "(", "'--pr'", ",", "\"--precision_recall\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"pr\"", ",", "\n", "help", "=", "\"Output precision and recall as well as the f-score. Default: false\"", ")", "\n", "parser", ".", "add_option", "(", "'--justinstance'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching instances\"", ")", "\n", "parser", ".", "add_option", "(", "'--justattribute'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching attributes\"", ")", "\n", "parser", ".", "add_option", "(", "'--justrelation'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching relations\"", ")", "\n", "parser", ".", "set_defaults", "(", "r", "=", "4", ",", "v", "=", "False", ",", "ms", "=", "False", ",", "pr", "=", "False", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.get_best_match": [[105, 174], ["smatch_all.compute_pool", "range", "print", "print", "print", "print", "len", "smatch_all.compute_match", "print", "smatch_all.smart_init_mapping", "smatch_all.random_init_mapping", "print", "print", "smatch_all.get_best_gain", "len", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_pool", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.smart_init_mapping", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.random_init_mapping", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_gain", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "get_best_match", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "True", ",", "doattribute", "=", "True", ",", "dorelation", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Get the highest triple match number between two sets of triples via hill-climbing.\n    Arguments:\n        instance1: instance triples of AMR 1 (\"instance\", node name, node value)\n        attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n        relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n        instance2: instance triples of AMR 2 (\"instance\", node name, node value)\n        attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n        relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name)\n        prefix1: prefix label for AMR 1\n        prefix2: prefix label for AMR 2\n    Returns:\n        best_match: the node mapping that results in the highest triple matching number\n        best_match_num: the highest triple matching number\n\n    \"\"\"", "\n", "# Compute candidate pool - all possible node match candidates.", "\n", "# In the hill-climbing, we only consider candidate in this pool to save computing time.", "\n", "# weight_dict is a dictionary that maps a pair of node", "\n", "(", "candidate_mappings", ",", "weight_dict", ")", "=", "compute_pool", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "doinstance", ",", "doattribute", "=", "doattribute", ",", "\n", "dorelation", "=", "dorelation", ")", "\n", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Candidate mappings:\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "candidate_mappings", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Weight dictionary\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "weight_dict", ",", "file", "=", "DEBUG_LOG", ")", "\n", "\n", "", "best_match_num", "=", "0", "\n", "# initialize best match mapping", "\n", "# the ith entry is the node index in AMR 2 which maps to the ith node in AMR 1", "\n", "best_mapping", "=", "[", "-", "1", "]", "*", "len", "(", "instance1", ")", "\n", "for", "i", "in", "range", "(", "iteration_num", ")", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"Iteration\"", ",", "i", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "i", "==", "0", ":", "\n", "# smart initialization used for the first round", "\n", "            ", "cur_mapping", "=", "smart_init_mapping", "(", "candidate_mappings", ",", "instance1", ",", "instance2", ")", "\n", "", "else", ":", "\n", "# random initialization for the other round", "\n", "            ", "cur_mapping", "=", "random_init_mapping", "(", "candidate_mappings", ")", "\n", "# compute current triple match number", "\n", "", "match_num", "=", "compute_match", "(", "cur_mapping", ",", "weight_dict", ")", "\n", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"Node mapping at start\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Triple match number at start:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "while", "True", ":", "\n", "# get best gain", "\n", "            ", "(", "gain", ",", "new_mapping", ")", "=", "get_best_gain", "(", "cur_mapping", ",", "candidate_mappings", ",", "weight_dict", ",", "\n", "len", "(", "instance2", ")", ",", "match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Gain after the hill-climbing\"", ",", "gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# hill-climbing until there will be no gain for new node mapping", "\n", "", "if", "gain", "<=", "0", ":", "\n", "                ", "break", "\n", "# otherwise update match_num and mapping", "\n", "", "match_num", "+=", "gain", "\n", "cur_mapping", "=", "new_mapping", "[", ":", "]", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Update triple match number to:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Current mapping:\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "if", "match_num", ">", "best_match_num", ":", "\n", "            ", "best_mapping", "=", "cur_mapping", "[", ":", "]", "\n", "best_match_num", "=", "match_num", "\n", "", "", "return", "best_mapping", ",", "best_match_num", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.normalize": [[176, 181], ["item.lower().rstrip", "item.lower"], "function", ["None"], ["", "def", "normalize", "(", "item", ")", ":", "\n", "    ", "\"\"\"\n    lowercase and remove quote signifiers from items that are about to be compared\n    \"\"\"", "\n", "return", "item", ".", "lower", "(", ")", ".", "rstrip", "(", "'_'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.compute_pool": [[183, 291], ["candidate_mapping.append", "set", "int", "int", "candidate_mapping[].add", "int", "int", "candidate_mapping[].add", "smatch_all.normalize", "smatch_all.normalize", "int", "int", "int", "int", "candidate_mapping[].add", "candidate_mapping[].add", "smatch_all.normalize", "smatch_all.normalize", "smatch_all.normalize", "smatch_all.normalize", "smatch_all.normalize", "smatch_all.normalize", "smatch_all.normalize", "smatch_all.normalize", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize"], ["", "def", "compute_pool", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "True", ",", "doattribute", "=", "True", ",", "dorelation", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    compute all possible node mapping candidates and their weights (the triple matching number gain resulting from\n    mapping one node in AMR 1 to another node in AMR2)\n\n    Arguments:\n        instance1: instance triples of AMR 1\n        attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n        relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n        instance2: instance triples of AMR 2\n        attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n        relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name\n        prefix1: prefix label for AMR 1\n        prefix2: prefix label for AMR 2\n    Returns:\n      candidate_mapping: a list of candidate nodes.\n                       The ith element contains the node indices (in AMR 2) the ith node (in AMR 1) can map to.\n                       (resulting in non-zero triple match)\n      weight_dict: a dictionary which contains the matching triple number for every pair of node mapping. The key\n                   is a node pair. The value is another dictionary. key {-1} is triple match resulting from this node\n                   pair alone (instance triples and attribute triples), and other keys are node pairs that can result\n                   in relation triple match together with the first node pair.\n\n\n    \"\"\"", "\n", "candidate_mapping", "=", "[", "]", "\n", "weight_dict", "=", "{", "}", "\n", "for", "instance1_item", "in", "instance1", ":", "\n", "# each candidate mapping is a set of node indices", "\n", "        ", "candidate_mapping", ".", "append", "(", "set", "(", ")", ")", "\n", "if", "doinstance", ":", "\n", "            ", "for", "instance2_item", "in", "instance2", ":", "\n", "# if both triples are instance triples and have the same value", "\n", "                ", "if", "normalize", "(", "instance1_item", "[", "0", "]", ")", "==", "normalize", "(", "instance2_item", "[", "0", "]", ")", "and", "normalize", "(", "instance1_item", "[", "2", "]", ")", "==", "normalize", "(", "instance2_item", "[", "2", "]", ")", ":", "\n", "# get node index by stripping the prefix", "\n", "                    ", "node1_index", "=", "int", "(", "instance1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index", "=", "int", "(", "instance2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "candidate_mapping", "[", "node1_index", "]", ".", "add", "(", "node2_index", ")", "\n", "node_pair", "=", "(", "node1_index", ",", "node2_index", ")", "\n", "# use -1 as key in weight_dict for instance triples and attribute triples", "\n", "if", "node_pair", "in", "weight_dict", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "=", "1", "\n", "", "", "", "", "", "if", "doattribute", ":", "\n", "        ", "for", "attribute1_item", "in", "attribute1", ":", "\n", "            ", "for", "attribute2_item", "in", "attribute2", ":", "\n", "# if both attribute relation triple have the same relation name and value", "\n", "                ", "if", "normalize", "(", "attribute1_item", "[", "0", "]", ")", "==", "normalize", "(", "attribute2_item", "[", "0", "]", ")", "and", "normalize", "(", "attribute1_item", "[", "2", "]", ")", "==", "normalize", "(", "attribute2_item", "[", "2", "]", ")", ":", "\n", "                    ", "node1_index", "=", "int", "(", "attribute1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index", "=", "int", "(", "attribute2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "candidate_mapping", "[", "node1_index", "]", ".", "add", "(", "node2_index", ")", "\n", "node_pair", "=", "(", "node1_index", ",", "node2_index", ")", "\n", "# use -1 as key in weight_dict for instance triples and attribute triples", "\n", "if", "node_pair", "in", "weight_dict", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "=", "1", "\n", "", "", "", "", "", "if", "dorelation", ":", "\n", "        ", "for", "relation1_item", "in", "relation1", ":", "\n", "            ", "for", "relation2_item", "in", "relation2", ":", "\n", "# if both relation share the same name", "\n", "                ", "if", "normalize", "(", "relation1_item", "[", "0", "]", ")", "==", "normalize", "(", "relation2_item", "[", "0", "]", ")", ":", "\n", "                    ", "node1_index_amr1", "=", "int", "(", "relation1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node1_index_amr2", "=", "int", "(", "relation2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "node2_index_amr1", "=", "int", "(", "relation1_item", "[", "2", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index_amr2", "=", "int", "(", "relation2_item", "[", "2", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "# add mapping between two nodes", "\n", "candidate_mapping", "[", "node1_index_amr1", "]", ".", "add", "(", "node1_index_amr2", ")", "\n", "candidate_mapping", "[", "node2_index_amr1", "]", ".", "add", "(", "node2_index_amr2", ")", "\n", "node_pair1", "=", "(", "node1_index_amr1", ",", "node1_index_amr2", ")", "\n", "node_pair2", "=", "(", "node2_index_amr1", ",", "node2_index_amr2", ")", "\n", "if", "node_pair2", "!=", "node_pair1", ":", "\n", "# update weight_dict weight. Note that we need to update both entries for future search", "\n", "# i.e weight_dict[node_pair1][node_pair2]", "\n", "#     weight_dict[node_pair2][node_pair1]", "\n", "                        ", "if", "node1_index_amr1", ">", "node2_index_amr1", ":", "\n", "# swap node_pair1 and node_pair2", "\n", "                            ", "node_pair1", "=", "(", "node2_index_amr1", ",", "node2_index_amr2", ")", "\n", "node_pair2", "=", "(", "node1_index_amr1", ",", "node1_index_amr2", ")", "\n", "", "if", "node_pair1", "in", "weight_dict", ":", "\n", "                            ", "if", "node_pair2", "in", "weight_dict", "[", "node_pair1", "]", ":", "\n", "                                ", "weight_dict", "[", "node_pair1", "]", "[", "node_pair2", "]", "+=", "1", "\n", "", "else", ":", "\n", "                                ", "weight_dict", "[", "node_pair1", "]", "[", "node_pair2", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "=", "{", "-", "1", ":", "0", ",", "node_pair2", ":", "1", "}", "\n", "", "if", "node_pair2", "in", "weight_dict", ":", "\n", "                            ", "if", "node_pair1", "in", "weight_dict", "[", "node_pair2", "]", ":", "\n", "                                ", "weight_dict", "[", "node_pair2", "]", "[", "node_pair1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                                ", "weight_dict", "[", "node_pair2", "]", "[", "node_pair1", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair2", "]", "=", "{", "-", "1", ":", "0", ",", "node_pair1", ":", "1", "}", "\n", "", "", "else", ":", "\n", "# two node pairs are the same. So we only update weight_dict once.", "\n", "# this generally should not happen.", "\n", "                        ", "if", "node_pair1", "in", "weight_dict", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "=", "{", "-", "1", ":", "1", "}", "\n", "", "", "", "", "", "", "return", "candidate_mapping", ",", "weight_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.smart_init_mapping": [[293, 342], ["random.seed", "enumerate", "list", "result.append", "len", "no_word_match.append", "result.append", "random.randint", "list.pop", "result.append", "len"], "function", ["None"], ["", "def", "smart_init_mapping", "(", "candidate_mapping", ",", "instance1", ",", "instance2", ")", ":", "\n", "    ", "\"\"\"\n    Initialize mapping based on the concept mapping (smart initialization)\n    Arguments:\n        candidate_mapping: candidate node match list\n        instance1: instance triples of AMR 1\n        instance2: instance triples of AMR 2\n    Returns:\n        initialized node mapping between two AMRs\n\n    \"\"\"", "\n", "random", ".", "seed", "(", ")", "\n", "matched_dict", "=", "{", "}", "\n", "result", "=", "[", "]", "\n", "# list to store node indices that have no concept match", "\n", "no_word_match", "=", "[", "]", "\n", "for", "i", ",", "candidates", "in", "enumerate", "(", "candidate_mapping", ")", ":", "\n", "        ", "if", "not", "candidates", ":", "\n", "# no possible mapping", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "continue", "\n", "# node value in instance triples of AMR 1", "\n", "", "value1", "=", "instance1", "[", "i", "]", "[", "2", "]", "\n", "for", "node_index", "in", "candidates", ":", "\n", "            ", "value2", "=", "instance2", "[", "node_index", "]", "[", "2", "]", "\n", "# find the first instance triple match in the candidates", "\n", "# instance triple match is having the same concept value", "\n", "if", "value1", "==", "value2", ":", "\n", "                ", "if", "node_index", "not", "in", "matched_dict", ":", "\n", "                    ", "result", ".", "append", "(", "node_index", ")", "\n", "matched_dict", "[", "node_index", "]", "=", "1", "\n", "break", "\n", "", "", "", "if", "len", "(", "result", ")", "==", "i", ":", "\n", "            ", "no_word_match", ".", "append", "(", "i", ")", "\n", "result", ".", "append", "(", "-", "1", ")", "\n", "# if no concept match, generate a random mapping", "\n", "", "", "for", "i", "in", "no_word_match", ":", "\n", "        ", "candidates", "=", "list", "(", "candidate_mapping", "[", "i", "]", ")", "\n", "while", "candidates", ":", "\n", "# get a random node index from candidates", "\n", "            ", "rid", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "candidates", ")", "-", "1", ")", "\n", "candidate", "=", "candidates", "[", "rid", "]", "\n", "if", "candidate", "in", "matched_dict", ":", "\n", "                ", "candidates", ".", "pop", "(", "rid", ")", "\n", "", "else", ":", "\n", "                ", "matched_dict", "[", "candidate", "]", "=", "1", "\n", "result", "[", "i", "]", "=", "candidate", "\n", "break", "\n", "", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.random_init_mapping": [[344, 379], ["random.seed", "list", "result.append", "random.randint", "result.append", "list.pop", "result.append", "len"], "function", ["None"], ["", "def", "random_init_mapping", "(", "candidate_mapping", ")", ":", "\n", "    ", "\"\"\"\n    Generate a random node mapping.\n    Args:\n        candidate_mapping: candidate_mapping: candidate node match list\n    Returns:\n        randomly-generated node mapping between two AMRs\n\n    \"\"\"", "\n", "# if needed, a fixed seed could be passed here to generate same random (to help debugging)", "\n", "random", ".", "seed", "(", ")", "\n", "matched_dict", "=", "{", "}", "\n", "result", "=", "[", "]", "\n", "for", "c", "in", "candidate_mapping", ":", "\n", "        ", "candidates", "=", "list", "(", "c", ")", "\n", "if", "not", "candidates", ":", "\n", "# -1 indicates no possible mapping", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "continue", "\n", "", "found", "=", "False", "\n", "while", "candidates", ":", "\n", "# randomly generate an index in [0, length of candidates)", "\n", "            ", "rid", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "candidates", ")", "-", "1", ")", "\n", "candidate", "=", "candidates", "[", "rid", "]", "\n", "# check if it has already been matched", "\n", "if", "candidate", "in", "matched_dict", ":", "\n", "                ", "candidates", ".", "pop", "(", "rid", ")", "\n", "", "else", ":", "\n", "                ", "matched_dict", "[", "candidate", "]", "=", "1", "\n", "result", ".", "append", "(", "candidate", ")", "\n", "found", "=", "True", "\n", "break", "\n", "", "", "if", "not", "found", ":", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.compute_match": [[381, 431], ["enumerate", "print", "print", "tuple", "print", "print", "print", "tuple", "tuple", "print", "tuple", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "compute_match", "(", "mapping", ",", "weight_dict", ")", ":", "\n", "    ", "\"\"\"\n    Given a node mapping, compute match number based on weight_dict.\n    Args:\n    mappings: a list of node index in AMR 2. The ith element (value j) means node i in AMR 1 maps to node j in AMR 2.\n    Returns:\n    matching triple number\n    Complexity: O(m*n) , m is the node number of AMR 1, n is the node number of AMR 2\n\n    \"\"\"", "\n", "# If this mapping has been investigated before, retrieve the value instead of re-computing.", "\n", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Computing match for mapping\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "tuple", "(", "mapping", ")", "in", "match_triple_dict", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"saved value\"", ",", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", "\n", "", "match_num", "=", "0", "\n", "# i is node index in AMR 1, m is node index in AMR 2", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "mapping", ")", ":", "\n", "        ", "if", "m", "==", "-", "1", ":", "\n", "# no node maps to this node", "\n", "            ", "continue", "\n", "# node i in AMR 1 maps to node m in AMR 2", "\n", "", "current_node_pair", "=", "(", "i", ",", "m", ")", "\n", "if", "current_node_pair", "not", "in", "weight_dict", ":", "\n", "            ", "continue", "\n", "", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"node_pair\"", ",", "current_node_pair", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "for", "key", "in", "weight_dict", "[", "current_node_pair", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "# matching triple resulting from instance/attribute triples", "\n", "                ", "match_num", "+=", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"instance/attribute match\"", ",", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# only consider node index larger than i to avoid duplicates", "\n", "# as we store both weight_dict[node_pair1][node_pair2] and", "\n", "#     weight_dict[node_pair2][node_pair1] for a relation", "\n", "", "", "elif", "key", "[", "0", "]", "<", "i", ":", "\n", "                ", "continue", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "match_num", "+=", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"relation match with\"", ",", "key", ",", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "", "", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"match computing complete, result:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# update match_triple_dict", "\n", "", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", "=", "match_num", "\n", "return", "match_num", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.move_gain": [[433, 477], ["tuple", "tuple", "tuple"], "function", ["None"], ["", "def", "move_gain", "(", "mapping", ",", "node_id", ",", "old_id", ",", "new_id", ",", "weight_dict", ",", "match_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the triple match number gain from the move operation\n    Arguments:\n        mapping: current node mapping\n        node_id: remapped node in AMR 1\n        old_id: original node id in AMR 2 to which node_id is mapped\n        new_id: new node in to which node_id is mapped\n        weight_dict: weight dictionary\n        match_num: the original triple matching number\n    Returns:\n        the triple match gain number (might be negative)\n\n    \"\"\"", "\n", "# new node mapping after moving", "\n", "new_mapping", "=", "(", "node_id", ",", "new_id", ")", "\n", "# node mapping before moving", "\n", "old_mapping", "=", "(", "node_id", ",", "old_id", ")", "\n", "# new nodes mapping list (all node pairs)", "\n", "new_mapping_list", "=", "mapping", "[", ":", "]", "\n", "new_mapping_list", "[", "node_id", "]", "=", "new_id", "\n", "# if this mapping is already been investigated, use saved one to avoid duplicate computing", "\n", "if", "tuple", "(", "new_mapping_list", ")", "in", "match_triple_dict", ":", "\n", "        ", "return", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "-", "match_num", "\n", "", "gain", "=", "0", "\n", "# add the triple match incurred by new_mapping to gain", "\n", "if", "new_mapping", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "# instance/attribute triple match", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping", "]", "[", "-", "1", "]", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "# relation gain incurred by new_mapping and another node pair in new_mapping_list", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping", "]", "[", "key", "]", "\n", "# deduct the triple match incurred by old_mapping from gain", "\n", "", "", "", "if", "old_mapping", "in", "weight_dict", ":", "\n", "        ", "for", "k", "in", "weight_dict", "[", "old_mapping", "]", ":", "\n", "            ", "if", "k", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping", "]", "[", "-", "1", "]", "\n", "", "elif", "mapping", "[", "k", "[", "0", "]", "]", "==", "k", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping", "]", "[", "k", "]", "\n", "# update match number dictionary", "\n", "", "", "", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "=", "match_num", "+", "gain", "\n", "return", "gain", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.swap_gain": [[479, 543], ["tuple", "tuple", "tuple"], "function", ["None"], ["", "def", "swap_gain", "(", "mapping", ",", "node_id1", ",", "mapping_id1", ",", "node_id2", ",", "mapping_id2", ",", "weight_dict", ",", "match_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the triple match number gain from the swapping\n    Arguments:\n    mapping: current node mapping list\n    node_id1: node 1 index in AMR 1\n    mapping_id1: the node index in AMR 2 node 1 maps to (in the current mapping)\n    node_id2: node 2 index in AMR 1\n    mapping_id2: the node index in AMR 2 node 2 maps to (in the current mapping)\n    weight_dict: weight dictionary\n    match_num: the original matching triple number\n    Returns:\n    the gain number (might be negative)\n\n    \"\"\"", "\n", "new_mapping_list", "=", "mapping", "[", ":", "]", "\n", "# Before swapping, node_id1 maps to mapping_id1, and node_id2 maps to mapping_id2", "\n", "# After swapping, node_id1 maps to mapping_id2 and node_id2 maps to mapping_id1", "\n", "new_mapping_list", "[", "node_id1", "]", "=", "mapping_id2", "\n", "new_mapping_list", "[", "node_id2", "]", "=", "mapping_id1", "\n", "if", "tuple", "(", "new_mapping_list", ")", "in", "match_triple_dict", ":", "\n", "        ", "return", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "-", "match_num", "\n", "", "gain", "=", "0", "\n", "new_mapping1", "=", "(", "node_id1", ",", "mapping_id2", ")", "\n", "new_mapping2", "=", "(", "node_id2", ",", "mapping_id1", ")", "\n", "old_mapping1", "=", "(", "node_id1", ",", "mapping_id1", ")", "\n", "old_mapping2", "=", "(", "node_id2", ",", "mapping_id2", ")", "\n", "if", "node_id1", ">", "node_id2", ":", "\n", "        ", "new_mapping2", "=", "(", "node_id1", ",", "mapping_id2", ")", "\n", "new_mapping1", "=", "(", "node_id2", ",", "mapping_id1", ")", "\n", "old_mapping1", "=", "(", "node_id2", ",", "mapping_id2", ")", "\n", "old_mapping2", "=", "(", "node_id1", ",", "mapping_id1", ")", "\n", "", "if", "new_mapping1", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping1", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping1", "]", "[", "-", "1", "]", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping1", "]", "[", "key", "]", "\n", "", "", "", "if", "new_mapping2", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping2", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping2", "]", "[", "-", "1", "]", "\n", "# to avoid duplicate", "\n", "", "elif", "key", "[", "0", "]", "==", "node_id1", ":", "\n", "                ", "continue", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping2", "]", "[", "key", "]", "\n", "", "", "", "if", "old_mapping1", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "old_mapping1", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping1", "]", "[", "-", "1", "]", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping1", "]", "[", "key", "]", "\n", "", "", "", "if", "old_mapping2", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "old_mapping2", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping2", "]", "[", "-", "1", "]", "\n", "# to avoid duplicate", "\n", "", "elif", "key", "[", "0", "]", "==", "node_id1", ":", "\n", "                ", "continue", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping2", "]", "[", "key", "]", "\n", "", "", "", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "=", "match_num", "+", "gain", "\n", "return", "gain", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.get_best_gain": [[545, 644], ["set", "enumerate", "enumerate", "range", "range", "print", "print", "set.remove", "len", "smatch_all.swap_gain", "print", "smatch_all.move_gain", "print", "print", "print", "print", "print", "print", "smatch_all.compute_match", "print", "print", "print", "print", "smatch_all.compute_match", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.swap_gain", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.move_gain", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "get_best_gain", "(", "mapping", ",", "candidate_mappings", ",", "weight_dict", ",", "instance_len", ",", "cur_match_num", ")", ":", "\n", "    ", "\"\"\"\n    Hill-climbing method to return the best gain swap/move can get\n    Arguments:\n    mapping: current node mapping\n    candidate_mappings: the candidates mapping list\n    weight_dict: the weight dictionary\n    instance_len: the number of the nodes in AMR 2\n    cur_match_num: current triple match number\n    Returns:\n    the best gain we can get via swap/move operation\n\n    \"\"\"", "\n", "largest_gain", "=", "0", "\n", "# True: using swap; False: using move", "\n", "use_swap", "=", "True", "\n", "# the node to be moved/swapped", "\n", "node1", "=", "None", "\n", "# store the other node affected. In swap, this other node is the node swapping with node1. In move, this other", "\n", "# node is the node node1 will move to.", "\n", "node2", "=", "None", "\n", "# unmatched nodes in AMR 2", "\n", "unmatched", "=", "set", "(", "range", "(", "instance_len", ")", ")", "\n", "# exclude nodes in current mapping", "\n", "# get unmatched nodes", "\n", "for", "nid", "in", "mapping", ":", "\n", "        ", "if", "nid", "in", "unmatched", ":", "\n", "            ", "unmatched", ".", "remove", "(", "nid", ")", "\n", "", "", "for", "i", ",", "nid", "in", "enumerate", "(", "mapping", ")", ":", "\n", "# current node i in AMR 1 maps to node nid in AMR 2", "\n", "        ", "for", "nm", "in", "unmatched", ":", "\n", "            ", "if", "nm", "in", "candidate_mappings", "[", "i", "]", ":", "\n", "# remap i to another unmatched node (move)", "\n", "# (i, m) -> (i, nm)", "\n", "                ", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"Remap node\"", ",", "i", ",", "\"from \"", ",", "nid", ",", "\"to\"", ",", "nm", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "mv_gain", "=", "move_gain", "(", "mapping", ",", "i", ",", "nid", ",", "nm", ",", "weight_dict", ",", "cur_match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"Move gain:\"", ",", "mv_gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_mapping", "=", "mapping", "[", ":", "]", "\n", "new_mapping", "[", "i", "]", "=", "nm", "\n", "new_match_num", "=", "compute_match", "(", "new_mapping", ",", "weight_dict", ")", "\n", "if", "new_match_num", "!=", "cur_match_num", "+", "mv_gain", ":", "\n", "                        ", "print", "(", "mapping", ",", "new_mapping", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Inconsistency in computing: move gain\"", ",", "cur_match_num", ",", "mv_gain", ",", "new_match_num", ",", "\n", "file", "=", "ERROR_LOG", ")", "\n", "", "", "if", "mv_gain", ">", "largest_gain", ":", "\n", "                    ", "largest_gain", "=", "mv_gain", "\n", "node1", "=", "i", "\n", "node2", "=", "nm", "\n", "use_swap", "=", "False", "\n", "# compute swap gain", "\n", "", "", "", "", "for", "i", ",", "m", "in", "enumerate", "(", "mapping", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "mapping", ")", ")", ":", "\n", "            ", "m2", "=", "mapping", "[", "j", "]", "\n", "# swap operation (i, m) (j, m2) -> (i, m2) (j, m)", "\n", "# j starts from i+1, to avoid duplicate swap", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Swap node\"", ",", "i", ",", "\"and\"", ",", "j", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Before swapping:\"", ",", "i", ",", "\"-\"", ",", "m", ",", "\",\"", ",", "j", ",", "\"-\"", ",", "m2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"After swapping:\"", ",", "i", ",", "\"-\"", ",", "m2", ",", "\",\"", ",", "j", ",", "\"-\"", ",", "m", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "sw_gain", "=", "swap_gain", "(", "mapping", ",", "i", ",", "m", ",", "j", ",", "m2", ",", "weight_dict", ",", "cur_match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Swap gain:\"", ",", "sw_gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_mapping", "=", "mapping", "[", ":", "]", "\n", "new_mapping", "[", "i", "]", "=", "m2", "\n", "new_mapping", "[", "j", "]", "=", "m", "\n", "print", "(", "new_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_match_num", "=", "compute_match", "(", "new_mapping", ",", "weight_dict", ")", "\n", "if", "new_match_num", "!=", "cur_match_num", "+", "sw_gain", ":", "\n", "                    ", "print", "(", "mapping", ",", "new_mapping", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Inconsistency in computing: swap gain\"", ",", "cur_match_num", ",", "sw_gain", ",", "new_match_num", ",", "\n", "file", "=", "ERROR_LOG", ")", "\n", "", "", "if", "sw_gain", ">", "largest_gain", ":", "\n", "                ", "largest_gain", "=", "sw_gain", "\n", "node1", "=", "i", "\n", "node2", "=", "j", "\n", "use_swap", "=", "True", "\n", "# generate a new mapping based on swap/move", "\n", "", "", "", "cur_mapping", "=", "mapping", "[", ":", "]", "\n", "if", "node1", "is", "not", "None", ":", "\n", "        ", "if", "use_swap", ":", "\n", "            ", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Use swap gain\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "temp", "=", "cur_mapping", "[", "node1", "]", "\n", "cur_mapping", "[", "node1", "]", "=", "cur_mapping", "[", "node2", "]", "\n", "cur_mapping", "[", "node2", "]", "=", "temp", "\n", "", "else", ":", "\n", "            ", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Use move gain\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "cur_mapping", "[", "node1", "]", "=", "node2", "\n", "", "", "else", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"no move/swap gain found\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Original mapping\"", ",", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Current mapping\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "largest_gain", ",", "cur_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.print_alignment": [[646, 665], ["zip", "result.append"], "function", ["None"], ["", "def", "print_alignment", "(", "mapping", ",", "instance1", ",", "instance2", ")", ":", "\n", "    ", "\"\"\"\n    print the alignment based on a node mapping\n    Args:\n        mapping: current node mapping list\n        instance1: nodes of AMR 1\n        instance2: nodes of AMR 2\n\n    \"\"\"", "\n", "result", "=", "[", "]", "\n", "for", "instance1_item", ",", "m", "in", "zip", "(", "instance1", ",", "mapping", ")", ":", "\n", "        ", "r", "=", "instance1_item", "[", "1", "]", "+", "\"(\"", "+", "instance1_item", "[", "2", "]", "+", "\")\"", "\n", "if", "m", "==", "-", "1", ":", "\n", "            ", "r", "+=", "\"-Null\"", "\n", "", "else", ":", "\n", "            ", "instance2_item", "=", "instance2", "[", "m", "]", "\n", "r", "+=", "\"-\"", "+", "instance2_item", "[", "1", "]", "+", "\"(\"", "+", "instance2_item", "[", "2", "]", "+", "\")\"", "\n", "", "result", ".", "append", "(", "r", ")", "\n", "", "return", "\" \"", ".", "join", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.compute_f": [[667, 694], ["float", "float", "float", "float", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "compute_f", "(", "match_num", ",", "test_num", ",", "gold_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the f-score based on the matching triple number,\n                                 triple number of AMR set 1,\n                                 triple number of AMR set 2\n    Args:\n        match_num: matching triple number\n        test_num:  triple number of AMR 1 (test file)\n        gold_num:  triple number of AMR 2 (gold file)\n    Returns:\n        precision: match_num/test_num\n        recall: match_num/gold_num\n        f_score: 2*precision*recall/(precision+recall)\n    \"\"\"", "\n", "if", "test_num", "==", "0", "or", "gold_num", "==", "0", ":", "\n", "        ", "return", "0.00", ",", "0.00", ",", "0.00", "\n", "", "precision", "=", "float", "(", "match_num", ")", "/", "float", "(", "test_num", ")", "\n", "recall", "=", "float", "(", "match_num", ")", "/", "float", "(", "gold_num", ")", "\n", "if", "(", "precision", "+", "recall", ")", "!=", "0", ":", "\n", "        ", "f_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"F-score:\"", ",", "f_score", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "precision", ",", "recall", ",", "f_score", "\n", "", "else", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"F-score:\"", ",", "\"0.0\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "precision", ",", "recall", ",", "0.00", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.generate_amr_lines": [[696, 718], ["amr.AMR.get_amr_line", "amr.AMR.get_amr_line", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_amr_line", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_amr_line", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "", "def", "generate_amr_lines", "(", "f1", ",", "f2", ")", ":", "\n", "    ", "\"\"\"\n    Read one AMR line at a time from each file handle\n    :param f1: file handle (or any iterable of strings) to read AMR 1 lines from\n    :param f2: file handle (or any iterable of strings) to read AMR 2 lines from\n    :return: generator of cur_amr1, cur_amr2 pairs: one-line AMR strings\n    \"\"\"", "\n", "while", "True", ":", "\n", "        ", "cur_amr1", "=", "amr", ".", "AMR", ".", "get_amr_line", "(", "f1", ")", "\n", "cur_amr2", "=", "amr", ".", "AMR", ".", "get_amr_line", "(", "f2", ")", "\n", "if", "not", "cur_amr1", "and", "not", "cur_amr2", ":", "\n", "            ", "pass", "\n", "", "elif", "not", "cur_amr1", ":", "\n", "            ", "print", "(", "\"Error: File 1 has less AMRs than file 2\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Ignoring remaining AMRs\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "", "elif", "not", "cur_amr2", ":", "\n", "            ", "print", "(", "\"Error: File 2 has less AMRs than file 1\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Ignoring remaining AMRs\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "", "else", ":", "\n", "            ", "yield", "cur_amr1", ",", "cur_amr2", "\n", "continue", "\n", "", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.get_amr_match": [[720, 784], ["amr1.rename_node", "amr2.rename_node", "amr1.get_triples", "amr2.get_triples", "smatch_all.get_best_match", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "len", "len", "amr_pair.append", "len", "len", "len", "len", "len", "len", "smatch_all.print_alignment", "len", "len", "amr.AMR.parse_AMR_line", "print", "print", "print", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.print_alignment", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.parse_AMR_line", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "", "def", "get_amr_match", "(", "cur_amr1", ",", "cur_amr2", ",", "sent_num", "=", "1", ",", "justinstance", "=", "False", ",", "justattribute", "=", "False", ",", "justrelation", "=", "False", ")", ":", "\n", "    ", "amr_pair", "=", "[", "]", "\n", "for", "i", ",", "cur_amr", "in", "(", "1", ",", "cur_amr1", ")", ",", "(", "2", ",", "cur_amr2", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "amr_pair", ".", "append", "(", "amr", ".", "AMR", ".", "parse_AMR_line", "(", "cur_amr", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"Error in parsing amr %d: %s\"", "%", "(", "i", ",", "cur_amr", ")", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Please check if the AMR is ill-formatted. Ignoring remaining AMRs\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Error message: %s\"", "%", "e", ",", "file", "=", "ERROR_LOG", ")", "\n", "", "", "amr1", ",", "amr2", "=", "amr_pair", "\n", "prefix1", "=", "\"a\"", "\n", "prefix2", "=", "\"b\"", "\n", "# Rename node to \"a1\", \"a2\", .etc", "\n", "amr1", ".", "rename_node", "(", "prefix1", ")", "\n", "# Renaming node to \"b1\", \"b2\", .etc", "\n", "amr2", ".", "rename_node", "(", "prefix2", ")", "\n", "(", "instance1", ",", "attributes1", ",", "relation1", ")", "=", "amr1", ".", "get_triples", "(", ")", "\n", "(", "instance2", ",", "attributes2", ",", "relation2", ")", "=", "amr2", ".", "get_triples", "(", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"AMR pair\"", ",", "sent_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"============================================\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"AMR 1 (one-line):\"", ",", "cur_amr1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"AMR 2 (one-line):\"", ",", "cur_amr2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Instance triples of AMR 1:\"", ",", "len", "(", "instance1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "instance1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of AMR 1:\"", ",", "len", "(", "attributes1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "attributes1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of AMR 1:\"", ",", "len", "(", "relation1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "relation1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Instance triples of AMR 2:\"", ",", "len", "(", "instance2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "instance2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of AMR 2:\"", ",", "len", "(", "attributes2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "attributes2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of AMR 2:\"", ",", "len", "(", "relation2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "relation2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# optionally turn off some of the node comparison", "\n", "", "doinstance", "=", "doattribute", "=", "dorelation", "=", "True", "\n", "if", "justinstance", ":", "\n", "        ", "doattribute", "=", "dorelation", "=", "False", "\n", "", "if", "justattribute", ":", "\n", "        ", "doinstance", "=", "dorelation", "=", "False", "\n", "", "if", "justrelation", ":", "\n", "        ", "doinstance", "=", "doattribute", "=", "False", "\n", "", "(", "best_mapping", ",", "best_match_num", ")", "=", "get_best_match", "(", "instance1", ",", "attributes1", ",", "relation1", ",", "\n", "instance2", ",", "attributes2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "doinstance", ",", "\n", "doattribute", "=", "doattribute", ",", "dorelation", "=", "dorelation", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"best match number\"", ",", "best_match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"best node mapping\"", ",", "best_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Best node mapping alignment:\"", ",", "print_alignment", "(", "best_mapping", ",", "instance1", ",", "instance2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "justinstance", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "instance1", ")", "\n", "gold_triple_num", "=", "len", "(", "instance2", ")", "\n", "", "elif", "justattribute", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "attributes1", ")", "\n", "gold_triple_num", "=", "len", "(", "attributes2", ")", "\n", "", "elif", "justrelation", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "relation1", ")", "\n", "gold_triple_num", "=", "len", "(", "relation2", ")", "\n", "", "else", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "instance1", ")", "+", "len", "(", "attributes1", ")", "+", "len", "(", "relation1", ")", "\n", "gold_triple_num", "=", "len", "(", "instance2", ")", "+", "len", "(", "attributes2", ")", "+", "len", "(", "relation2", ")", "\n", "", "return", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.score_amr_pairs": [[786, 818], ["enumerate", "smatch_all.generate_amr_lines", "smatch_all.get_amr_match", "match_triple_dict.clear", "print", "print", "print", "smatch_all.compute_f", "smatch_all.compute_f"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.generate_amr_lines", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.get_amr_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f"], ["", "def", "score_amr_pairs", "(", "f1", ",", "f2", ",", "justinstance", "=", "False", ",", "justattribute", "=", "False", ",", "justrelation", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Score one pair of AMR lines at a time from each file handle\n    :param f1: file handle (or any iterable of strings) to read AMR 1 lines from\n    :param f2: file handle (or any iterable of strings) to read AMR 2 lines from\n    :param justinstance: just pay attention to matching instances\n    :param justattribute: just pay attention to matching attributes\n    :param justrelation: just pay attention to matching relations\n    :return: generator of cur_amr1, cur_amr2 pairs: one-line AMR strings\n    \"\"\"", "\n", "# matching triple number, triple number in test file, triple number in gold file", "\n", "total_match_num", "=", "total_test_num", "=", "total_gold_num", "=", "0", "\n", "# Read amr pairs from two files", "\n", "for", "sent_num", ",", "(", "cur_amr1", ",", "cur_amr2", ")", "in", "enumerate", "(", "generate_amr_lines", "(", "f1", ",", "f2", ")", ",", "start", "=", "1", ")", ":", "\n", "        ", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", "=", "get_amr_match", "(", "cur_amr1", ",", "cur_amr2", ",", "\n", "sent_num", "=", "sent_num", ",", "# sentence number", "\n", "justinstance", "=", "justinstance", ",", "\n", "justattribute", "=", "justattribute", ",", "\n", "justrelation", "=", "justrelation", ")", "\n", "total_match_num", "+=", "best_match_num", "\n", "total_test_num", "+=", "test_triple_num", "\n", "total_gold_num", "+=", "gold_triple_num", "\n", "# clear the matching triple dictionary for the next AMR pair", "\n", "match_triple_dict", ".", "clear", "(", ")", "\n", "if", "not", "single_score", ":", "# if each AMR pair should have a score, compute and output it here", "\n", "            ", "yield", "compute_f", "(", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", ")", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\"Total match number, total triple number in AMR 1, and total triple number in AMR 2:\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "total_match_num", ",", "total_test_num", ",", "total_gold_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"---------------------------------------------------------------------------------\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "single_score", ":", "# output document-level smatch score (a single f-score for all AMR pairs in two files)", "\n", "        ", "yield", "compute_f", "(", "total_match_num", ",", "total_test_num", ",", "total_gold_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_all.main": [[820, 855], ["smatch_all.score_amr_pairs", "args.f[].close", "args.f[].close", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.score_amr_pairs", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "", "def", "main", "(", "arguments", ")", ":", "\n", "    ", "\"\"\"\n    Main function of smatch score calculation\n    \"\"\"", "\n", "global", "verbose", "\n", "global", "veryVerbose", "\n", "global", "iteration_num", "\n", "global", "single_score", "\n", "global", "pr_flag", "\n", "global", "match_triple_dict", "\n", "# set the iteration number", "\n", "# total iteration number = restart number + 1", "\n", "iteration_num", "=", "arguments", ".", "r", "+", "1", "\n", "if", "arguments", ".", "ms", ":", "\n", "        ", "single_score", "=", "False", "\n", "", "if", "arguments", ".", "v", ":", "\n", "        ", "verbose", "=", "True", "\n", "", "if", "arguments", ".", "vv", ":", "\n", "        ", "veryVerbose", "=", "True", "\n", "", "if", "arguments", ".", "pr", ":", "\n", "        ", "pr_flag", "=", "True", "\n", "# significant digits to print out", "\n", "", "arguments", ".", "significant", "=", "4", "\n", "floatdisplay", "=", "\"%%.%df\"", "%", "arguments", ".", "significant", "\n", "for", "(", "precision", ",", "recall", ",", "best_f_score", ")", "in", "score_amr_pairs", "(", "args", ".", "f", "[", "0", "]", ",", "args", ".", "f", "[", "1", "]", ",", "\n", "justinstance", "=", "arguments", ".", "justinstance", ",", "\n", "justattribute", "=", "arguments", ".", "justattribute", ",", "\n", "justrelation", "=", "arguments", ".", "justrelation", ")", ":", "\n", "# print(\"Sentence\", sent_num)", "\n", "        ", "if", "pr_flag", ":", "\n", "            ", "print", "(", "\"Precision: \"", "+", "floatdisplay", "%", "precision", ")", "\n", "print", "(", "\"Recall: \"", "+", "floatdisplay", "%", "recall", ")", "\n", "", "print", "(", "\"F-score: \"", "+", "floatdisplay", "%", "best_f_score", ")", "\n", "", "args", ".", "f", "[", "0", "]", ".", "close", "(", ")", "\n", "args", ".", "f", "[", "1", "]", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.build_arg_parser": [[50, 75], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType"], "function", ["None"], ["def", "build_arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Build an argument parser using argparse. Use it when python version is 2.7 or later.\n\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Smatch calculator -- arguments\"", ")", "\n", "parser", ".", "add_argument", "(", "'-f'", ",", "nargs", "=", "2", ",", "required", "=", "True", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "\n", "help", "=", "'Two files containing AMR pairs. AMRs in each file are separated by a single blank line'", ")", "\n", "parser", ".", "add_argument", "(", "'-r'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'Restart number (Default:4)'", ")", "\n", "parser", ".", "add_argument", "(", "'--significant'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "'significant digits to output (default: 2)'", ")", "\n", "parser", ".", "add_argument", "(", "'-v'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Verbose output (Default:false)'", ")", "\n", "parser", ".", "add_argument", "(", "'--vv'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Very Verbose output (Default:false)'", ")", "\n", "parser", ".", "add_argument", "(", "'--ms'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Output multiple scores (one AMR pair a score)'", "\n", "'instead of a single document-level smatch score (Default: false)'", ")", "\n", "parser", ".", "add_argument", "(", "'--pr'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"Output precision and recall as well as the f-score. Default: false\"", ")", "\n", "parser", ".", "add_argument", "(", "'--justinstance'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching instances\"", ")", "\n", "parser", ".", "add_argument", "(", "'--justattribute'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching attributes\"", ")", "\n", "parser", ".", "add_argument", "(", "'--justrelation'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching relations\"", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.build_arg_parser2": [[77, 106], ["optparse.OptionParser", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.set_defaults"], "function", ["None"], ["", "def", "build_arg_parser2", "(", ")", ":", "\n", "    ", "\"\"\"\n    Build an argument parser using optparse. Use it when python version is 2.5 or 2.6.\n\n    \"\"\"", "\n", "usage_str", "=", "\"Smatch calculator -- arguments\"", "\n", "parser", "=", "optparse", ".", "OptionParser", "(", "usage", "=", "usage_str", ")", "\n", "parser", ".", "add_option", "(", "\"-f\"", ",", "\"--files\"", ",", "nargs", "=", "2", ",", "dest", "=", "\"f\"", ",", "type", "=", "\"string\"", ",", "\n", "help", "=", "'Two files containing AMR pairs. AMRs in each file are '", "'separated by a single blank line. This option is required.'", ")", "\n", "parser", ".", "add_option", "(", "\"-r\"", ",", "\"--restart\"", ",", "dest", "=", "\"r\"", ",", "type", "=", "\"int\"", ",", "help", "=", "'Restart number (Default: 4)'", ")", "\n", "parser", ".", "add_option", "(", "'--significant'", ",", "dest", "=", "\"significant\"", ",", "type", "=", "\"int\"", ",", "default", "=", "2", ",", "\n", "help", "=", "'significant digits to output (default: 2)'", ")", "\n", "parser", ".", "add_option", "(", "\"-v\"", ",", "\"--verbose\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"v\"", ",", "help", "=", "'Verbose output (Default:False)'", ")", "\n", "parser", ".", "add_option", "(", "\"--vv\"", ",", "\"--veryverbose\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"vv\"", ",", "\n", "help", "=", "'Very Verbose output (Default:False)'", ")", "\n", "parser", ".", "add_option", "(", "\"--ms\"", ",", "\"--multiple_score\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"ms\"", ",", "\n", "help", "=", "'Output multiple scores (one AMR pair a score) instead of '", "'a single document-level smatch score (Default: False)'", ")", "\n", "parser", ".", "add_option", "(", "'--pr'", ",", "\"--precision_recall\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"pr\"", ",", "\n", "help", "=", "\"Output precision and recall as well as the f-score. Default: false\"", ")", "\n", "parser", ".", "add_option", "(", "'--justinstance'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching instances\"", ")", "\n", "parser", ".", "add_option", "(", "'--justattribute'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching attributes\"", ")", "\n", "parser", ".", "add_option", "(", "'--justrelation'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"just pay attention to matching relations\"", ")", "\n", "parser", ".", "set_defaults", "(", "r", "=", "4", ",", "v", "=", "False", ",", "ms", "=", "False", ",", "pr", "=", "False", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.check_match": [[110, 112], ["None"], "function", ["None"], ["", "def", "check_match", "(", "tri1", ",", "tri2", ")", ":", "\n", "    ", "return", "tri1", "[", "0", "]", "==", "tri2", "[", "0", "]", "and", "tri1", "[", "1", "]", "==", "tri2", "[", "1", "]", "and", "tri1", "[", "2", "]", "==", "tri2", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.get_doc_level_smatch": [[114, 126], ["set", "zip", "len", "len", "set.update", "len", "len", "smatch_amrFC.get_match_tributes"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.get_match_tributes"], ["", "def", "get_doc_level_smatch", "(", "tributes_parse", ",", "tributes_gold_list", ",", "best_mapping_list", ")", ":", "\n", "    ", "matched_pred", "=", "set", "(", ")", "\n", "assert", "len", "(", "tributes_gold_list", ")", "==", "len", "(", "best_mapping_list", ")", "\n", "for", "i", ",", "j", "in", "zip", "(", "tributes_gold_list", ",", "best_mapping_list", ")", ":", "\n", "\n", "\n", "        ", "matched_pred", ".", "update", "(", "get_match_tributes", "(", "tributes_parse", ",", "i", ",", "j", ")", ")", "\n", "\n", "\n", "", "precision", "=", "len", "(", "matched_pred", ")", "/", "len", "(", "tributes_parse", ")", "\n", "\n", "return", "precision", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.get_match_tributes": [[131, 147], ["set", "str", "str", "enumerate", "smatch_amrFC.check_match", "mapping_dict.keys", "temp.append", "temp.append", "set.add"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.check_match", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["", "def", "get_match_tributes", "(", "tributes_parse", ",", "tributes_gold", ",", "best_mapping", ")", ":", "\n", "    ", "mapping_dict", "=", "{", "\"a\"", "+", "str", "(", "j", ")", ":", "\"b\"", "+", "str", "(", "i", ")", "for", "j", ",", "i", "in", "enumerate", "(", "best_mapping", ")", "}", "\n", "tributes", "=", "set", "(", ")", "\n", "for", "i", "in", "tributes_parse", ":", "\n", "        ", "temp", "=", "[", "]", "\n", "for", "name", "in", "i", ":", "\n", "            ", "if", "name", "not", "in", "mapping_dict", ".", "keys", "(", ")", ":", "\n", "                ", "temp", ".", "append", "(", "name", ")", "\n", "", "else", ":", "\n", "                ", "temp", ".", "append", "(", "mapping_dict", "[", "name", "]", ")", "\n", "\n", "", "", "for", "j", "in", "tributes_gold", ":", "\n", "            ", "if", "check_match", "(", "temp", ",", "j", ")", ":", "\n", "                ", "tributes", ".", "add", "(", "i", ")", "\n", "break", "\n", "", "", "", "return", "tributes", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.get_best_match_tributes": [[150, 222], ["smatch_amrFC.compute_pool", "range", "print", "print", "print", "print", "len", "smatch_amrFC.compute_match", "print", "smatch_amrFC.smart_init_mapping", "smatch_amrFC.random_init_mapping", "print", "print", "smatch_amrFC.get_best_gain", "len", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_pool", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.smart_init_mapping", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.random_init_mapping", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_gain", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "get_best_match_tributes", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "True", ",", "doattribute", "=", "True", ",", "dorelation", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Get the highest triple match number between two sets of triples via hill-climbing.\n    Arguments:\n        instance1: instance triples of AMR 1 (\"instance\", node name, node value)\n        attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n        relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n        instance2: instance triples of AMR 2 (\"instance\", node name, node value)\n        attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n        relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name)\n        prefix1: prefix label for AMR 1\n        prefix2: prefix label for AMR 2\n    Returns:\n        best_match: the node mapping that results in the highest triple matching number\n        best_match_num: the highest triple matching number\n\n    \"\"\"", "\n", "# Compute candidate pool - all possible node match candidates.", "\n", "# In the hill-climbing, we only consider candidate in this pool to save computing time.", "\n", "# weight_dict is a dictionary that maps a pair of node", "\n", "(", "candidate_mappings", ",", "weight_dict", ")", "=", "compute_pool", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "doinstance", ",", "doattribute", "=", "doattribute", ",", "\n", "dorelation", "=", "dorelation", ")", "\n", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Candidate mappings:\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "candidate_mappings", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Weight dictionary\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "weight_dict", ",", "file", "=", "DEBUG_LOG", ")", "\n", "\n", "", "best_match_num", "=", "0", "\n", "# initialize best match mapping", "\n", "# the ith entry is the node index in AMR 2 which maps to the ith node in AMR 1", "\n", "best_mapping", "=", "[", "-", "1", "]", "*", "len", "(", "instance1", ")", "\n", "for", "i", "in", "range", "(", "iteration_num", ")", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"Iteration\"", ",", "i", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "i", "==", "0", ":", "\n", "# smart initialization used for the first round", "\n", "            ", "cur_mapping", "=", "smart_init_mapping", "(", "candidate_mappings", ",", "instance1", ",", "instance2", ")", "\n", "", "else", ":", "\n", "# random initialization for the other round", "\n", "            ", "cur_mapping", "=", "random_init_mapping", "(", "candidate_mappings", ")", "\n", "# compute current triple match number", "\n", "", "match_num", "=", "compute_match", "(", "cur_mapping", ",", "weight_dict", ")", "\n", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"Node mapping at start\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Triple match number at start:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "while", "True", ":", "\n", "# get best gain", "\n", "            ", "(", "gain", ",", "new_mapping", ")", "=", "get_best_gain", "(", "cur_mapping", ",", "candidate_mappings", ",", "weight_dict", ",", "\n", "len", "(", "instance2", ")", ",", "match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Gain after the hill-climbing\"", ",", "gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# hill-climbing until there will be no gain for new node mapping", "\n", "", "if", "gain", "<=", "0", ":", "\n", "                ", "break", "\n", "# otherwise update match_num and mapping", "\n", "", "match_num", "+=", "gain", "\n", "cur_mapping", "=", "new_mapping", "[", ":", "]", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Update triple match number to:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Current mapping:\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "if", "match_num", ">", "best_match_num", ":", "\n", "            ", "best_mapping", "=", "cur_mapping", "[", ":", "]", "\n", "best_match_num", "=", "match_num", "\n", "\n", "\n", "\n", "", "", "return", "best_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.get_best_match": [[224, 295], ["smatch_amrFC.compute_pool", "range", "pdb.set_trace", "print", "print", "print", "print", "len", "smatch_amrFC.compute_match", "print", "smatch_amrFC.smart_init_mapping", "smatch_amrFC.random_init_mapping", "print", "print", "smatch_amrFC.get_best_gain", "len", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_pool", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.smart_init_mapping", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.random_init_mapping", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_gain", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "get_best_match", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "True", ",", "doattribute", "=", "True", ",", "dorelation", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Get the highest triple match number between two sets of triples via hill-climbing.\n    Arguments:\n        instance1: instance triples of AMR 1 (\"instance\", node name, node value)\n        attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n        relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n        instance2: instance triples of AMR 2 (\"instance\", node name, node value)\n        attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n        relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name)\n        prefix1: prefix label for AMR 1\n        prefix2: prefix label for AMR 2\n    Returns:\n        best_match: the node mapping that results in the highest triple matching number\n        best_match_num: the highest triple matching number\n\n    \"\"\"", "\n", "# Compute candidate pool - all possible node match candidates.", "\n", "# In the hill-climbing, we only consider candidate in this pool to save computing time.", "\n", "# weight_dict is a dictionary that maps a pair of node", "\n", "(", "candidate_mappings", ",", "weight_dict", ")", "=", "compute_pool", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "doinstance", ",", "doattribute", "=", "doattribute", ",", "\n", "dorelation", "=", "dorelation", ")", "\n", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Candidate mappings:\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "candidate_mappings", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Weight dictionary\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "weight_dict", ",", "file", "=", "DEBUG_LOG", ")", "\n", "\n", "", "best_match_num", "=", "0", "\n", "# initialize best match mapping", "\n", "# the ith entry is the node index in AMR 2 which maps to the ith node in AMR 1", "\n", "best_mapping", "=", "[", "-", "1", "]", "*", "len", "(", "instance1", ")", "\n", "for", "i", "in", "range", "(", "iteration_num", ")", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"Iteration\"", ",", "i", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "i", "==", "0", ":", "\n", "# smart initialization used for the first round", "\n", "            ", "cur_mapping", "=", "smart_init_mapping", "(", "candidate_mappings", ",", "instance1", ",", "instance2", ")", "\n", "", "else", ":", "\n", "# random initialization for the other round", "\n", "            ", "cur_mapping", "=", "random_init_mapping", "(", "candidate_mappings", ")", "\n", "# compute current triple match number", "\n", "", "match_num", "=", "compute_match", "(", "cur_mapping", ",", "weight_dict", ")", "\n", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"Node mapping at start\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Triple match number at start:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "while", "True", ":", "\n", "# get best gain", "\n", "            ", "(", "gain", ",", "new_mapping", ")", "=", "get_best_gain", "(", "cur_mapping", ",", "candidate_mappings", ",", "weight_dict", ",", "\n", "len", "(", "instance2", ")", ",", "match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Gain after the hill-climbing\"", ",", "gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# hill-climbing until there will be no gain for new node mapping", "\n", "", "if", "gain", "<=", "0", ":", "\n", "                ", "break", "\n", "# otherwise update match_num and mapping", "\n", "", "match_num", "+=", "gain", "\n", "cur_mapping", "=", "new_mapping", "[", ":", "]", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Update triple match number to:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Current mapping:\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "if", "match_num", ">", "best_match_num", ":", "\n", "            ", "best_mapping", "=", "cur_mapping", "[", ":", "]", "\n", "best_match_num", "=", "match_num", "\n", "\n", "", "", "pdb", ".", "set_trace", "(", ")", "\n", "return", "best_mapping", ",", "best_match_num", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize": [[297, 302], ["item.lower().rstrip", "item.lower"], "function", ["None"], ["", "def", "normalize", "(", "item", ")", ":", "\n", "    ", "\"\"\"\n    lowercase and remove quote signifiers from items that are about to be compared\n    \"\"\"", "\n", "return", "item", ".", "lower", "(", ")", ".", "rstrip", "(", "'_'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.compute_pool": [[304, 412], ["candidate_mapping.append", "set", "int", "int", "candidate_mapping[].add", "int", "int", "candidate_mapping[].add", "smatch_amrFC.normalize", "smatch_amrFC.normalize", "int", "int", "int", "int", "candidate_mapping[].add", "candidate_mapping[].add", "smatch_amrFC.normalize", "smatch_amrFC.normalize", "smatch_amrFC.normalize", "smatch_amrFC.normalize", "smatch_amrFC.normalize", "smatch_amrFC.normalize", "smatch_amrFC.normalize", "smatch_amrFC.normalize", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.normalize"], ["", "def", "compute_pool", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "True", ",", "doattribute", "=", "True", ",", "dorelation", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    compute all possible node mapping candidates and their weights (the triple matching number gain resulting from\n    mapping one node in AMR 1 to another node in AMR2)\n\n    Arguments:\n        instance1: instance triples of AMR 1\n        attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n        relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n        instance2: instance triples of AMR 2\n        attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n        relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name\n        prefix1: prefix label for AMR 1\n        prefix2: prefix label for AMR 2\n    Returns:\n      candidate_mapping: a list of candidate nodes.\n                       The ith element contains the node indices (in AMR 2) the ith node (in AMR 1) can map to.\n                       (resulting in non-zero triple match)\n      weight_dict: a dictionary which contains the matching triple number for every pair of node mapping. The key\n                   is a node pair. The value is another dictionary. key {-1} is triple match resulting from this node\n                   pair alone (instance triples and attribute triples), and other keys are node pairs that can result\n                   in relation triple match together with the first node pair.\n\n\n    \"\"\"", "\n", "candidate_mapping", "=", "[", "]", "\n", "weight_dict", "=", "{", "}", "\n", "for", "instance1_item", "in", "instance1", ":", "\n", "# each candidate mapping is a set of node indices", "\n", "        ", "candidate_mapping", ".", "append", "(", "set", "(", ")", ")", "\n", "if", "doinstance", ":", "\n", "            ", "for", "instance2_item", "in", "instance2", ":", "\n", "# if both triples are instance triples and have the same value", "\n", "                ", "if", "normalize", "(", "instance1_item", "[", "0", "]", ")", "==", "normalize", "(", "instance2_item", "[", "0", "]", ")", "and", "normalize", "(", "instance1_item", "[", "2", "]", ")", "==", "normalize", "(", "instance2_item", "[", "2", "]", ")", ":", "\n", "# get node index by stripping the prefix", "\n", "                    ", "node1_index", "=", "int", "(", "instance1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index", "=", "int", "(", "instance2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "candidate_mapping", "[", "node1_index", "]", ".", "add", "(", "node2_index", ")", "\n", "node_pair", "=", "(", "node1_index", ",", "node2_index", ")", "\n", "# use -1 as key in weight_dict for instance triples and attribute triples", "\n", "if", "node_pair", "in", "weight_dict", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "=", "1", "\n", "", "", "", "", "", "if", "doattribute", ":", "\n", "        ", "for", "attribute1_item", "in", "attribute1", ":", "\n", "            ", "for", "attribute2_item", "in", "attribute2", ":", "\n", "# if both attribute relation triple have the same relation name and value", "\n", "                ", "if", "normalize", "(", "attribute1_item", "[", "0", "]", ")", "==", "normalize", "(", "attribute2_item", "[", "0", "]", ")", "and", "normalize", "(", "attribute1_item", "[", "2", "]", ")", "==", "normalize", "(", "attribute2_item", "[", "2", "]", ")", ":", "\n", "                    ", "node1_index", "=", "int", "(", "attribute1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index", "=", "int", "(", "attribute2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "candidate_mapping", "[", "node1_index", "]", ".", "add", "(", "node2_index", ")", "\n", "node_pair", "=", "(", "node1_index", ",", "node2_index", ")", "\n", "# use -1 as key in weight_dict for instance triples and attribute triples", "\n", "if", "node_pair", "in", "weight_dict", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "=", "1", "\n", "", "", "", "", "", "if", "dorelation", ":", "\n", "        ", "for", "relation1_item", "in", "relation1", ":", "\n", "            ", "for", "relation2_item", "in", "relation2", ":", "\n", "# if both relation share the same name", "\n", "                ", "if", "normalize", "(", "relation1_item", "[", "0", "]", ")", "==", "normalize", "(", "relation2_item", "[", "0", "]", ")", ":", "\n", "                    ", "node1_index_amr1", "=", "int", "(", "relation1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node1_index_amr2", "=", "int", "(", "relation2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "node2_index_amr1", "=", "int", "(", "relation1_item", "[", "2", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index_amr2", "=", "int", "(", "relation2_item", "[", "2", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "# add mapping between two nodes", "\n", "candidate_mapping", "[", "node1_index_amr1", "]", ".", "add", "(", "node1_index_amr2", ")", "\n", "candidate_mapping", "[", "node2_index_amr1", "]", ".", "add", "(", "node2_index_amr2", ")", "\n", "node_pair1", "=", "(", "node1_index_amr1", ",", "node1_index_amr2", ")", "\n", "node_pair2", "=", "(", "node2_index_amr1", ",", "node2_index_amr2", ")", "\n", "if", "node_pair2", "!=", "node_pair1", ":", "\n", "# update weight_dict weight. Note that we need to update both entries for future search", "\n", "# i.e weight_dict[node_pair1][node_pair2]", "\n", "#     weight_dict[node_pair2][node_pair1]", "\n", "                        ", "if", "node1_index_amr1", ">", "node2_index_amr1", ":", "\n", "# swap node_pair1 and node_pair2", "\n", "                            ", "node_pair1", "=", "(", "node2_index_amr1", ",", "node2_index_amr2", ")", "\n", "node_pair2", "=", "(", "node1_index_amr1", ",", "node1_index_amr2", ")", "\n", "", "if", "node_pair1", "in", "weight_dict", ":", "\n", "                            ", "if", "node_pair2", "in", "weight_dict", "[", "node_pair1", "]", ":", "\n", "                                ", "weight_dict", "[", "node_pair1", "]", "[", "node_pair2", "]", "+=", "1", "\n", "", "else", ":", "\n", "                                ", "weight_dict", "[", "node_pair1", "]", "[", "node_pair2", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "=", "{", "-", "1", ":", "0", ",", "node_pair2", ":", "1", "}", "\n", "", "if", "node_pair2", "in", "weight_dict", ":", "\n", "                            ", "if", "node_pair1", "in", "weight_dict", "[", "node_pair2", "]", ":", "\n", "                                ", "weight_dict", "[", "node_pair2", "]", "[", "node_pair1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                                ", "weight_dict", "[", "node_pair2", "]", "[", "node_pair1", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair2", "]", "=", "{", "-", "1", ":", "0", ",", "node_pair1", ":", "1", "}", "\n", "", "", "else", ":", "\n", "# two node pairs are the same. So we only update weight_dict once.", "\n", "# this generally should not happen.", "\n", "                        ", "if", "node_pair1", "in", "weight_dict", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "=", "{", "-", "1", ":", "1", "}", "\n", "", "", "", "", "", "", "return", "candidate_mapping", ",", "weight_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.smart_init_mapping": [[414, 463], ["random.seed", "enumerate", "list", "result.append", "len", "no_word_match.append", "result.append", "random.randint", "list.pop", "result.append", "len"], "function", ["None"], ["", "def", "smart_init_mapping", "(", "candidate_mapping", ",", "instance1", ",", "instance2", ")", ":", "\n", "    ", "\"\"\"\n    Initialize mapping based on the concept mapping (smart initialization)\n    Arguments:\n        candidate_mapping: candidate node match list\n        instance1: instance triples of AMR 1\n        instance2: instance triples of AMR 2\n    Returns:\n        initialized node mapping between two AMRs\n\n    \"\"\"", "\n", "random", ".", "seed", "(", ")", "\n", "matched_dict", "=", "{", "}", "\n", "result", "=", "[", "]", "\n", "# list to store node indices that have no concept match", "\n", "no_word_match", "=", "[", "]", "\n", "for", "i", ",", "candidates", "in", "enumerate", "(", "candidate_mapping", ")", ":", "\n", "        ", "if", "not", "candidates", ":", "\n", "# no possible mapping", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "continue", "\n", "# node value in instance triples of AMR 1", "\n", "", "value1", "=", "instance1", "[", "i", "]", "[", "2", "]", "\n", "for", "node_index", "in", "candidates", ":", "\n", "            ", "value2", "=", "instance2", "[", "node_index", "]", "[", "2", "]", "\n", "# find the first instance triple match in the candidates", "\n", "# instance triple match is having the same concept value", "\n", "if", "value1", "==", "value2", ":", "\n", "                ", "if", "node_index", "not", "in", "matched_dict", ":", "\n", "                    ", "result", ".", "append", "(", "node_index", ")", "\n", "matched_dict", "[", "node_index", "]", "=", "1", "\n", "break", "\n", "", "", "", "if", "len", "(", "result", ")", "==", "i", ":", "\n", "            ", "no_word_match", ".", "append", "(", "i", ")", "\n", "result", ".", "append", "(", "-", "1", ")", "\n", "# if no concept match, generate a random mapping", "\n", "", "", "for", "i", "in", "no_word_match", ":", "\n", "        ", "candidates", "=", "list", "(", "candidate_mapping", "[", "i", "]", ")", "\n", "while", "candidates", ":", "\n", "# get a random node index from candidates", "\n", "            ", "rid", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "candidates", ")", "-", "1", ")", "\n", "candidate", "=", "candidates", "[", "rid", "]", "\n", "if", "candidate", "in", "matched_dict", ":", "\n", "                ", "candidates", ".", "pop", "(", "rid", ")", "\n", "", "else", ":", "\n", "                ", "matched_dict", "[", "candidate", "]", "=", "1", "\n", "result", "[", "i", "]", "=", "candidate", "\n", "break", "\n", "", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.random_init_mapping": [[465, 500], ["random.seed", "list", "result.append", "random.randint", "result.append", "list.pop", "result.append", "len"], "function", ["None"], ["", "def", "random_init_mapping", "(", "candidate_mapping", ")", ":", "\n", "    ", "\"\"\"\n    Generate a random node mapping.\n    Args:\n        candidate_mapping: candidate_mapping: candidate node match list\n    Returns:\n        randomly-generated node mapping between two AMRs\n\n    \"\"\"", "\n", "# if needed, a fixed seed could be passed here to generate same random (to help debugging)", "\n", "random", ".", "seed", "(", ")", "\n", "matched_dict", "=", "{", "}", "\n", "result", "=", "[", "]", "\n", "for", "c", "in", "candidate_mapping", ":", "\n", "        ", "candidates", "=", "list", "(", "c", ")", "\n", "if", "not", "candidates", ":", "\n", "# -1 indicates no possible mapping", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "continue", "\n", "", "found", "=", "False", "\n", "while", "candidates", ":", "\n", "# randomly generate an index in [0, length of candidates)", "\n", "            ", "rid", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "candidates", ")", "-", "1", ")", "\n", "candidate", "=", "candidates", "[", "rid", "]", "\n", "# check if it has already been matched", "\n", "if", "candidate", "in", "matched_dict", ":", "\n", "                ", "candidates", ".", "pop", "(", "rid", ")", "\n", "", "else", ":", "\n", "                ", "matched_dict", "[", "candidate", "]", "=", "1", "\n", "result", ".", "append", "(", "candidate", ")", "\n", "found", "=", "True", "\n", "break", "\n", "", "", "if", "not", "found", ":", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.compute_match": [[502, 552], ["enumerate", "print", "print", "tuple", "print", "print", "print", "tuple", "tuple", "print", "tuple", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "compute_match", "(", "mapping", ",", "weight_dict", ")", ":", "\n", "    ", "\"\"\"\n    Given a node mapping, compute match number based on weight_dict.\n    Args:\n    mappings: a list of node index in AMR 2. The ith element (value j) means node i in AMR 1 maps to node j in AMR 2.\n    Returns:\n    matching triple number\n    Complexity: O(m*n) , m is the node number of AMR 1, n is the node number of AMR 2\n\n    \"\"\"", "\n", "# If this mapping has been investigated before, retrieve the value instead of re-computing.", "\n", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Computing match for mapping\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "tuple", "(", "mapping", ")", "in", "match_triple_dict", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"saved value\"", ",", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", "\n", "", "match_num", "=", "0", "\n", "# i is node index in AMR 1, m is node index in AMR 2", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "mapping", ")", ":", "\n", "        ", "if", "m", "==", "-", "1", ":", "\n", "# no node maps to this node", "\n", "            ", "continue", "\n", "# node i in AMR 1 maps to node m in AMR 2", "\n", "", "current_node_pair", "=", "(", "i", ",", "m", ")", "\n", "if", "current_node_pair", "not", "in", "weight_dict", ":", "\n", "            ", "continue", "\n", "", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"node_pair\"", ",", "current_node_pair", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "for", "key", "in", "weight_dict", "[", "current_node_pair", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "# matching triple resulting from instance/attribute triples", "\n", "                ", "match_num", "+=", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"instance/attribute match\"", ",", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# only consider node index larger than i to avoid duplicates", "\n", "# as we store both weight_dict[node_pair1][node_pair2] and", "\n", "#     weight_dict[node_pair2][node_pair1] for a relation", "\n", "", "", "elif", "key", "[", "0", "]", "<", "i", ":", "\n", "                ", "continue", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "match_num", "+=", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"relation match with\"", ",", "key", ",", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "", "", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"match computing complete, result:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# update match_triple_dict", "\n", "", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", "=", "match_num", "\n", "return", "match_num", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.move_gain": [[554, 598], ["tuple", "tuple", "tuple"], "function", ["None"], ["", "def", "move_gain", "(", "mapping", ",", "node_id", ",", "old_id", ",", "new_id", ",", "weight_dict", ",", "match_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the triple match number gain from the move operation\n    Arguments:\n        mapping: current node mapping\n        node_id: remapped node in AMR 1\n        old_id: original node id in AMR 2 to which node_id is mapped\n        new_id: new node in to which node_id is mapped\n        weight_dict: weight dictionary\n        match_num: the original triple matching number\n    Returns:\n        the triple match gain number (might be negative)\n\n    \"\"\"", "\n", "# new node mapping after moving", "\n", "new_mapping", "=", "(", "node_id", ",", "new_id", ")", "\n", "# node mapping before moving", "\n", "old_mapping", "=", "(", "node_id", ",", "old_id", ")", "\n", "# new nodes mapping list (all node pairs)", "\n", "new_mapping_list", "=", "mapping", "[", ":", "]", "\n", "new_mapping_list", "[", "node_id", "]", "=", "new_id", "\n", "# if this mapping is already been investigated, use saved one to avoid duplicate computing", "\n", "if", "tuple", "(", "new_mapping_list", ")", "in", "match_triple_dict", ":", "\n", "        ", "return", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "-", "match_num", "\n", "", "gain", "=", "0", "\n", "# add the triple match incurred by new_mapping to gain", "\n", "if", "new_mapping", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "# instance/attribute triple match", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping", "]", "[", "-", "1", "]", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "# relation gain incurred by new_mapping and another node pair in new_mapping_list", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping", "]", "[", "key", "]", "\n", "# deduct the triple match incurred by old_mapping from gain", "\n", "", "", "", "if", "old_mapping", "in", "weight_dict", ":", "\n", "        ", "for", "k", "in", "weight_dict", "[", "old_mapping", "]", ":", "\n", "            ", "if", "k", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping", "]", "[", "-", "1", "]", "\n", "", "elif", "mapping", "[", "k", "[", "0", "]", "]", "==", "k", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping", "]", "[", "k", "]", "\n", "# update match number dictionary", "\n", "", "", "", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "=", "match_num", "+", "gain", "\n", "return", "gain", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.swap_gain": [[600, 664], ["tuple", "tuple", "tuple"], "function", ["None"], ["", "def", "swap_gain", "(", "mapping", ",", "node_id1", ",", "mapping_id1", ",", "node_id2", ",", "mapping_id2", ",", "weight_dict", ",", "match_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the triple match number gain from the swapping\n    Arguments:\n    mapping: current node mapping list\n    node_id1: node 1 index in AMR 1\n    mapping_id1: the node index in AMR 2 node 1 maps to (in the current mapping)\n    node_id2: node 2 index in AMR 1\n    mapping_id2: the node index in AMR 2 node 2 maps to (in the current mapping)\n    weight_dict: weight dictionary\n    match_num: the original matching triple number\n    Returns:\n    the gain number (might be negative)\n\n    \"\"\"", "\n", "new_mapping_list", "=", "mapping", "[", ":", "]", "\n", "# Before swapping, node_id1 maps to mapping_id1, and node_id2 maps to mapping_id2", "\n", "# After swapping, node_id1 maps to mapping_id2 and node_id2 maps to mapping_id1", "\n", "new_mapping_list", "[", "node_id1", "]", "=", "mapping_id2", "\n", "new_mapping_list", "[", "node_id2", "]", "=", "mapping_id1", "\n", "if", "tuple", "(", "new_mapping_list", ")", "in", "match_triple_dict", ":", "\n", "        ", "return", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "-", "match_num", "\n", "", "gain", "=", "0", "\n", "new_mapping1", "=", "(", "node_id1", ",", "mapping_id2", ")", "\n", "new_mapping2", "=", "(", "node_id2", ",", "mapping_id1", ")", "\n", "old_mapping1", "=", "(", "node_id1", ",", "mapping_id1", ")", "\n", "old_mapping2", "=", "(", "node_id2", ",", "mapping_id2", ")", "\n", "if", "node_id1", ">", "node_id2", ":", "\n", "        ", "new_mapping2", "=", "(", "node_id1", ",", "mapping_id2", ")", "\n", "new_mapping1", "=", "(", "node_id2", ",", "mapping_id1", ")", "\n", "old_mapping1", "=", "(", "node_id2", ",", "mapping_id2", ")", "\n", "old_mapping2", "=", "(", "node_id1", ",", "mapping_id1", ")", "\n", "", "if", "new_mapping1", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping1", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping1", "]", "[", "-", "1", "]", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping1", "]", "[", "key", "]", "\n", "", "", "", "if", "new_mapping2", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping2", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping2", "]", "[", "-", "1", "]", "\n", "# to avoid duplicate", "\n", "", "elif", "key", "[", "0", "]", "==", "node_id1", ":", "\n", "                ", "continue", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping2", "]", "[", "key", "]", "\n", "", "", "", "if", "old_mapping1", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "old_mapping1", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping1", "]", "[", "-", "1", "]", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping1", "]", "[", "key", "]", "\n", "", "", "", "if", "old_mapping2", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "old_mapping2", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping2", "]", "[", "-", "1", "]", "\n", "# to avoid duplicate", "\n", "", "elif", "key", "[", "0", "]", "==", "node_id1", ":", "\n", "                ", "continue", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping2", "]", "[", "key", "]", "\n", "", "", "", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "=", "match_num", "+", "gain", "\n", "return", "gain", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.get_best_gain": [[666, 765], ["set", "enumerate", "enumerate", "range", "range", "print", "print", "set.remove", "len", "smatch_amrFC.swap_gain", "print", "smatch_amrFC.move_gain", "print", "print", "print", "print", "print", "print", "smatch_amrFC.compute_match", "print", "print", "print", "print", "smatch_amrFC.compute_match", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.swap_gain", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.move_gain", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "get_best_gain", "(", "mapping", ",", "candidate_mappings", ",", "weight_dict", ",", "instance_len", ",", "cur_match_num", ")", ":", "\n", "    ", "\"\"\"\n    Hill-climbing method to return the best gain swap/move can get\n    Arguments:\n    mapping: current node mapping\n    candidate_mappings: the candidates mapping list\n    weight_dict: the weight dictionary\n    instance_len: the number of the nodes in AMR 2\n    cur_match_num: current triple match number\n    Returns:\n    the best gain we can get via swap/move operation\n\n    \"\"\"", "\n", "largest_gain", "=", "0", "\n", "# True: using swap; False: using move", "\n", "use_swap", "=", "True", "\n", "# the node to be moved/swapped", "\n", "node1", "=", "None", "\n", "# store the other node affected. In swap, this other node is the node swapping with node1. In move, this other", "\n", "# node is the node node1 will move to.", "\n", "node2", "=", "None", "\n", "# unmatched nodes in AMR 2", "\n", "unmatched", "=", "set", "(", "range", "(", "instance_len", ")", ")", "\n", "# exclude nodes in current mapping", "\n", "# get unmatched nodes", "\n", "for", "nid", "in", "mapping", ":", "\n", "        ", "if", "nid", "in", "unmatched", ":", "\n", "            ", "unmatched", ".", "remove", "(", "nid", ")", "\n", "", "", "for", "i", ",", "nid", "in", "enumerate", "(", "mapping", ")", ":", "\n", "# current node i in AMR 1 maps to node nid in AMR 2", "\n", "        ", "for", "nm", "in", "unmatched", ":", "\n", "            ", "if", "nm", "in", "candidate_mappings", "[", "i", "]", ":", "\n", "# remap i to another unmatched node (move)", "\n", "# (i, m) -> (i, nm)", "\n", "                ", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"Remap node\"", ",", "i", ",", "\"from \"", ",", "nid", ",", "\"to\"", ",", "nm", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "mv_gain", "=", "move_gain", "(", "mapping", ",", "i", ",", "nid", ",", "nm", ",", "weight_dict", ",", "cur_match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"Move gain:\"", ",", "mv_gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_mapping", "=", "mapping", "[", ":", "]", "\n", "new_mapping", "[", "i", "]", "=", "nm", "\n", "new_match_num", "=", "compute_match", "(", "new_mapping", ",", "weight_dict", ")", "\n", "if", "new_match_num", "!=", "cur_match_num", "+", "mv_gain", ":", "\n", "                        ", "print", "(", "mapping", ",", "new_mapping", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Inconsistency in computing: move gain\"", ",", "cur_match_num", ",", "mv_gain", ",", "new_match_num", ",", "\n", "file", "=", "ERROR_LOG", ")", "\n", "", "", "if", "mv_gain", ">", "largest_gain", ":", "\n", "                    ", "largest_gain", "=", "mv_gain", "\n", "node1", "=", "i", "\n", "node2", "=", "nm", "\n", "use_swap", "=", "False", "\n", "# compute swap gain", "\n", "", "", "", "", "for", "i", ",", "m", "in", "enumerate", "(", "mapping", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "mapping", ")", ")", ":", "\n", "            ", "m2", "=", "mapping", "[", "j", "]", "\n", "# swap operation (i, m) (j, m2) -> (i, m2) (j, m)", "\n", "# j starts from i+1, to avoid duplicate swap", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Swap node\"", ",", "i", ",", "\"and\"", ",", "j", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Before swapping:\"", ",", "i", ",", "\"-\"", ",", "m", ",", "\",\"", ",", "j", ",", "\"-\"", ",", "m2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"After swapping:\"", ",", "i", ",", "\"-\"", ",", "m2", ",", "\",\"", ",", "j", ",", "\"-\"", ",", "m", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "sw_gain", "=", "swap_gain", "(", "mapping", ",", "i", ",", "m", ",", "j", ",", "m2", ",", "weight_dict", ",", "cur_match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Swap gain:\"", ",", "sw_gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_mapping", "=", "mapping", "[", ":", "]", "\n", "new_mapping", "[", "i", "]", "=", "m2", "\n", "new_mapping", "[", "j", "]", "=", "m", "\n", "print", "(", "new_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_match_num", "=", "compute_match", "(", "new_mapping", ",", "weight_dict", ")", "\n", "if", "new_match_num", "!=", "cur_match_num", "+", "sw_gain", ":", "\n", "                    ", "print", "(", "mapping", ",", "new_mapping", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Inconsistency in computing: swap gain\"", ",", "cur_match_num", ",", "sw_gain", ",", "new_match_num", ",", "\n", "file", "=", "ERROR_LOG", ")", "\n", "", "", "if", "sw_gain", ">", "largest_gain", ":", "\n", "                ", "largest_gain", "=", "sw_gain", "\n", "node1", "=", "i", "\n", "node2", "=", "j", "\n", "use_swap", "=", "True", "\n", "# generate a new mapping based on swap/move", "\n", "", "", "", "cur_mapping", "=", "mapping", "[", ":", "]", "\n", "if", "node1", "is", "not", "None", ":", "\n", "        ", "if", "use_swap", ":", "\n", "            ", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Use swap gain\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "temp", "=", "cur_mapping", "[", "node1", "]", "\n", "cur_mapping", "[", "node1", "]", "=", "cur_mapping", "[", "node2", "]", "\n", "cur_mapping", "[", "node2", "]", "=", "temp", "\n", "", "else", ":", "\n", "            ", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Use move gain\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "cur_mapping", "[", "node1", "]", "=", "node2", "\n", "", "", "else", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"no move/swap gain found\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Original mapping\"", ",", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Current mapping\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "largest_gain", ",", "cur_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.print_alignment": [[767, 786], ["zip", "result.append"], "function", ["None"], ["", "def", "print_alignment", "(", "mapping", ",", "instance1", ",", "instance2", ")", ":", "\n", "    ", "\"\"\"\n    print the alignment based on a node mapping\n    Args:\n        mapping: current node mapping list\n        instance1: nodes of AMR 1\n        instance2: nodes of AMR 2\n\n    \"\"\"", "\n", "result", "=", "[", "]", "\n", "for", "instance1_item", ",", "m", "in", "zip", "(", "instance1", ",", "mapping", ")", ":", "\n", "        ", "r", "=", "instance1_item", "[", "1", "]", "+", "\"(\"", "+", "instance1_item", "[", "2", "]", "+", "\")\"", "\n", "if", "m", "==", "-", "1", ":", "\n", "            ", "r", "+=", "\"-Null\"", "\n", "", "else", ":", "\n", "            ", "instance2_item", "=", "instance2", "[", "m", "]", "\n", "r", "+=", "\"-\"", "+", "instance2_item", "[", "1", "]", "+", "\"(\"", "+", "instance2_item", "[", "2", "]", "+", "\")\"", "\n", "", "result", ".", "append", "(", "r", ")", "\n", "", "return", "\" \"", ".", "join", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.compute_f": [[788, 815], ["float", "float", "float", "float", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "compute_f", "(", "match_num", ",", "test_num", ",", "gold_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the f-score based on the matching triple number,\n                                 triple number of AMR set 1,\n                                 triple number of AMR set 2\n    Args:\n        match_num: matching triple number\n        test_num:  triple number of AMR 1 (test file)\n        gold_num:  triple number of AMR 2 (gold file)\n    Returns:\n        precision: match_num/test_num\n        recall: match_num/gold_num\n        f_score: 2*precision*recall/(precision+recall)\n    \"\"\"", "\n", "if", "test_num", "==", "0", "or", "gold_num", "==", "0", ":", "\n", "        ", "return", "0.00", ",", "0.00", ",", "0.00", "\n", "", "precision", "=", "float", "(", "match_num", ")", "/", "float", "(", "test_num", ")", "\n", "recall", "=", "float", "(", "match_num", ")", "/", "float", "(", "gold_num", ")", "\n", "if", "(", "precision", "+", "recall", ")", "!=", "0", ":", "\n", "        ", "f_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"F-score:\"", ",", "f_score", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "precision", ",", "recall", ",", "f_score", "\n", "", "else", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"F-score:\"", ",", "\"0.0\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "precision", ",", "recall", ",", "0.00", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.generate_amr_lines": [[817, 839], ["amr.AMR.get_amr_line", "amr.AMR.get_amr_line", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_amr_line", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_amr_line", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "", "def", "generate_amr_lines", "(", "f1", ",", "f2", ")", ":", "\n", "    ", "\"\"\"\n    Read one AMR line at a time from each file handle\n    :param f1: file handle (or any iterable of strings) to read AMR 1 lines from\n    :param f2: file handle (or any iterable of strings) to read AMR 2 lines from\n    :return: generator of cur_amr1, cur_amr2 pairs: one-line AMR strings\n    \"\"\"", "\n", "while", "True", ":", "\n", "        ", "cur_amr1", "=", "amr", ".", "AMR", ".", "get_amr_line", "(", "f1", ")", "\n", "cur_amr2", "=", "amr", ".", "AMR", ".", "get_amr_line", "(", "f2", ")", "\n", "if", "not", "cur_amr1", "and", "not", "cur_amr2", ":", "\n", "            ", "pass", "\n", "", "elif", "not", "cur_amr1", ":", "\n", "            ", "print", "(", "\"Error: File 1 has less AMRs than file 2\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Ignoring remaining AMRs\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "", "elif", "not", "cur_amr2", ":", "\n", "            ", "print", "(", "\"Error: File 2 has less AMRs than file 1\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Ignoring remaining AMRs\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "", "else", ":", "\n", "            ", "yield", "cur_amr1", ",", "cur_amr2", "\n", "continue", "\n", "", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.get_amr_match": [[841, 905], ["amr1.rename_node", "amr2.rename_node", "amr1.get_triples", "amr2.get_triples", "smatch_amrFC.get_best_match_tributes", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "len", "len", "amr_pair.append", "len", "len", "len", "len", "len", "len", "smatch_amrFC.print_alignment", "len", "len", "amr.AMR.parse_AMR_line", "print", "print", "print", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.get_best_match_tributes", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.print_alignment", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.parse_AMR_line", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "", "def", "get_amr_match", "(", "cur_amr1", ",", "cur_amr2", ",", "sent_num", "=", "1", ",", "justinstance", "=", "False", ",", "justattribute", "=", "False", ",", "justrelation", "=", "False", ")", ":", "\n", "    ", "amr_pair", "=", "[", "]", "\n", "for", "i", ",", "cur_amr", "in", "(", "1", ",", "cur_amr1", ")", ",", "(", "2", ",", "cur_amr2", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "amr_pair", ".", "append", "(", "amr", ".", "AMR", ".", "parse_AMR_line", "(", "cur_amr", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"Error in parsing amr %d: %s\"", "%", "(", "i", ",", "cur_amr", ")", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Please check if the AMR is ill-formatted. Ignoring remaining AMRs\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Error message: %s\"", "%", "e", ",", "file", "=", "ERROR_LOG", ")", "\n", "", "", "amr1", ",", "amr2", "=", "amr_pair", "\n", "prefix1", "=", "\"a\"", "\n", "prefix2", "=", "\"b\"", "\n", "# Rename node to \"a1\", \"a2\", .etc", "\n", "amr1", ".", "rename_node", "(", "prefix1", ")", "\n", "# Renaming node to \"b1\", \"b2\", .etc", "\n", "amr2", ".", "rename_node", "(", "prefix2", ")", "\n", "(", "instance1", ",", "attributes1", ",", "relation1", ")", "=", "amr1", ".", "get_triples", "(", ")", "\n", "(", "instance2", ",", "attributes2", ",", "relation2", ")", "=", "amr2", ".", "get_triples", "(", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"AMR pair\"", ",", "sent_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"============================================\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"AMR 1 (one-line):\"", ",", "cur_amr1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"AMR 2 (one-line):\"", ",", "cur_amr2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Instance triples of AMR 1:\"", ",", "len", "(", "instance1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "instance1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of AMR 1:\"", ",", "len", "(", "attributes1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "attributes1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of AMR 1:\"", ",", "len", "(", "relation1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "relation1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Instance triples of AMR 2:\"", ",", "len", "(", "instance2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "instance2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of AMR 2:\"", ",", "len", "(", "attributes2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "attributes2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of AMR 2:\"", ",", "len", "(", "relation2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "relation2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# optionally turn off some of the node comparison", "\n", "", "doinstance", "=", "doattribute", "=", "dorelation", "=", "True", "\n", "if", "justinstance", ":", "\n", "        ", "doattribute", "=", "dorelation", "=", "False", "\n", "", "if", "justattribute", ":", "\n", "        ", "doinstance", "=", "dorelation", "=", "False", "\n", "", "if", "justrelation", ":", "\n", "        ", "doinstance", "=", "doattribute", "=", "False", "\n", "", "(", "best_mapping", ",", "best_match_num", ")", "=", "get_best_match_tributes", "(", "instance1", ",", "attributes1", ",", "relation1", ",", "\n", "instance2", ",", "attributes2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "doinstance", ",", "\n", "doattribute", "=", "doattribute", ",", "dorelation", "=", "dorelation", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"best match number\"", ",", "best_match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"best node mapping\"", ",", "best_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Best node mapping alignment:\"", ",", "print_alignment", "(", "best_mapping", ",", "instance1", ",", "instance2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "justinstance", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "instance1", ")", "\n", "gold_triple_num", "=", "len", "(", "instance2", ")", "\n", "", "elif", "justattribute", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "attributes1", ")", "\n", "gold_triple_num", "=", "len", "(", "attributes2", ")", "\n", "", "elif", "justrelation", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "relation1", ")", "\n", "gold_triple_num", "=", "len", "(", "relation2", ")", "\n", "", "else", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "instance1", ")", "+", "len", "(", "attributes1", ")", "+", "len", "(", "relation1", ")", "\n", "gold_triple_num", "=", "len", "(", "instance2", ")", "+", "len", "(", "attributes2", ")", "+", "len", "(", "relation2", ")", "\n", "", "return", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.score_doc_level_amr_pairs": [[907, 958], ["amr.AMR.get_amr_line", "smatch_amrFC.get_doc_level_smatch", "amr.AMR.get_amr_line", "amr1.rename_node", "amr2.rename_node", "amr1.get_triples", "amr2.get_triples", "tributes_gold_list.append", "smatch_amrFC.get_best_match_tributes", "mapping_list.append", "gold_amr_list.append", "amr_pair.append", "amr.AMR.parse_AMR_line", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_amr_line", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.get_doc_level_smatch", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_amr_line", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.get_best_match_tributes", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.parse_AMR_line", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "score_doc_level_amr_pairs", "(", "f1", ",", "f2", ",", "justinstance", "=", "False", ",", "justattribute", "=", "False", ",", "justrelation", "=", "False", ")", ":", "\n", "    ", "total_match_num", "=", "total_test_num", "=", "total_gold_num", "=", "0", "\n", "pred", "=", "amr", ".", "AMR", ".", "get_amr_line", "(", "f1", ")", "\n", "gold_amr_list", "=", "[", "]", "\n", "mapping_list", "=", "[", "]", "\n", "\n", "tributes_gold_list", "=", "[", "]", "\n", "tributes_pred", "=", "None", "\n", "\n", "while", "True", ":", "\n", "        ", "temp_amr", "=", "amr", ".", "AMR", ".", "get_amr_line", "(", "f2", ")", "\n", "if", "not", "temp_amr", ":", "\n", "            ", "break", "\n", "", "else", ":", "\n", "            ", "gold_amr_list", ".", "append", "(", "temp_amr", ")", "\n", "\n", "# get best mapping for each sentence in article", "\n", "\n", "", "", "for", "cur_amr2", "in", "gold_amr_list", ":", "\n", "        ", "amr_pair", "=", "[", "]", "\n", "for", "i", ",", "cur_amr", "in", "(", "1", ",", "pred", ")", ",", "(", "2", ",", "cur_amr2", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "amr_pair", ".", "append", "(", "amr", ".", "AMR", ".", "parse_AMR_line", "(", "cur_amr", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "\"Error in parsing amr %d: %s\"", "%", "(", "i", ",", "cur_amr", ")", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Please check if the AMR is ill-formatted. Ignoring remaining AMRs\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Error message: %s\"", "%", "e", ",", "file", "=", "ERROR_LOG", ")", "\n", "", "", "amr1", ",", "amr2", "=", "amr_pair", "\n", "prefix1", "=", "\"a\"", "\n", "prefix2", "=", "\"b\"", "\n", "# Rename node to \"a1\", \"a2\", .etc", "\n", "amr1", ".", "rename_node", "(", "prefix1", ")", "\n", "# Renaming node to \"b1\", \"b2\", .etc", "\n", "amr2", ".", "rename_node", "(", "prefix2", ")", "\n", "(", "instance1", ",", "attributes1", ",", "relation1", ")", "=", "amr1", ".", "get_triples", "(", ")", "\n", "(", "instance2", ",", "attributes2", ",", "relation2", ")", "=", "amr2", ".", "get_triples", "(", ")", "\n", "\n", "if", "tributes_pred", "==", "None", ":", "\n", "            ", "tributes_pred", "=", "instance1", "+", "attributes1", "+", "relation1", "\n", "\n", "", "tributes_gold_list", ".", "append", "(", "instance2", "+", "attributes2", "+", "relation2", ")", "\n", "\n", "best_mapping", "=", "get_best_match_tributes", "(", "instance1", ",", "attributes1", ",", "relation1", ",", "instance2", ",", "attributes2", ",", "relation2", ",", "prefix1", ",", "prefix2", ")", "\n", "mapping_list", ".", "append", "(", "best_mapping", ")", "\n", "\n", "", "result", "=", "get_doc_level_smatch", "(", "tributes_pred", ",", "tributes_gold_list", ",", "mapping_list", ")", "\n", "\n", "\n", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.score_amr_pairs": [[962, 994], ["enumerate", "smatch_amrFC.generate_amr_lines", "smatch_amrFC.get_amr_match", "match_triple_dict.clear", "print", "print", "print", "smatch_amrFC.compute_f", "smatch_amrFC.compute_f"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.generate_amr_lines", "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.get_amr_match", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f"], ["", "def", "score_amr_pairs", "(", "f1", ",", "f2", ",", "justinstance", "=", "False", ",", "justattribute", "=", "False", ",", "justrelation", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Score one pair of AMR lines at a time from each file handle\n    :param f1: file handle (or any iterable of strings) to read AMR 1 lines from\n    :param f2: file handle (or any iterable of strings) to read AMR 2 lines from\n    :param justinstance: just pay attention to matching instances\n    :param justattribute: just pay attention to matching attributes\n    :param justrelation: just pay attention to matching relations\n    :return: generator of cur_amr1, cur_amr2 pairs: one-line AMR strings\n    \"\"\"", "\n", "# matching triple number, triple number in test file, triple number in gold file", "\n", "total_match_num", "=", "total_test_num", "=", "total_gold_num", "=", "0", "\n", "# Read amr pairs from two files", "\n", "for", "sent_num", ",", "(", "cur_amr1", ",", "cur_amr2", ")", "in", "enumerate", "(", "generate_amr_lines", "(", "f1", ",", "f2", ")", ",", "start", "=", "1", ")", ":", "\n", "        ", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", "=", "get_amr_match", "(", "cur_amr1", ",", "cur_amr2", ",", "\n", "sent_num", "=", "sent_num", ",", "# sentence number", "\n", "justinstance", "=", "justinstance", ",", "\n", "justattribute", "=", "justattribute", ",", "\n", "justrelation", "=", "justrelation", ")", "\n", "total_match_num", "+=", "best_match_num", "\n", "total_test_num", "+=", "test_triple_num", "\n", "total_gold_num", "+=", "gold_triple_num", "\n", "# clear the matching triple dictionary for the next AMR pair", "\n", "match_triple_dict", ".", "clear", "(", ")", "\n", "if", "not", "single_score", ":", "# if each AMR pair should have a score, compute and output it here", "\n", "            ", "yield", "compute_f", "(", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", ")", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\"Total match number, total triple number in AMR 1, and total triple number in AMR 2:\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "total_match_num", ",", "total_test_num", ",", "total_gold_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"---------------------------------------------------------------------------------\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "single_score", ":", "# output document-level smatch score (a single f-score for all AMR pairs in two files)", "\n", "        ", "yield", "compute_f", "(", "total_match_num", ",", "total_test_num", ",", "total_gold_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.main": [[996, 1027], ["smatch_amrFC.score_doc_level_amr_pairs", "print", "args.f[].close", "args.f[].close"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.score_doc_level_amr_pairs", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close"], ["", "", "def", "main", "(", "arguments", ")", ":", "\n", "    ", "\"\"\"\n    Main function of smatch score calculation\n    \"\"\"", "\n", "global", "verbose", "\n", "global", "veryVerbose", "\n", "global", "iteration_num", "\n", "global", "single_score", "\n", "global", "pr_flag", "\n", "global", "match_triple_dict", "\n", "# set the iteration number", "\n", "# total iteration number = restart number + 1", "\n", "iteration_num", "=", "arguments", ".", "r", "+", "1", "\n", "if", "arguments", ".", "ms", ":", "\n", "        ", "single_score", "=", "False", "\n", "", "if", "arguments", ".", "v", ":", "\n", "        ", "verbose", "=", "True", "\n", "", "if", "arguments", ".", "vv", ":", "\n", "        ", "veryVerbose", "=", "True", "\n", "", "if", "arguments", ".", "pr", ":", "\n", "        ", "pr_flag", "=", "True", "\n", "# significant digits to print out", "\n", "", "arguments", ".", "significant", "=", "4", "\n", "floatdisplay", "=", "\"%%.%df\"", "%", "arguments", ".", "significant", "\n", "result", "=", "score_doc_level_amr_pairs", "(", "args", ".", "f", "[", "0", "]", ",", "args", ".", "f", "[", "1", "]", ",", "\n", "justinstance", "=", "arguments", ".", "justinstance", ",", "\n", "justattribute", "=", "arguments", ".", "justattribute", ",", "\n", "justrelation", "=", "arguments", ".", "justrelation", ")", "\n", "print", "(", "\"doc level smatch is: \"", ",", "result", ")", "\n", "args", ".", "f", "[", "0", "]", ".", "close", "(", ")", "\n", "args", ".", "f", "[", "1", "]", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.parse_relations": [[17, 47], ["range", "enumerate", "amr.AMR", "len", "len", "len", "rel_dict.append", "att_dict.append", "len", "var_list.append", "conc_list.append", "var_list.append", "conc_list.append", "len", "str", "str", "str", "str", "str", "str", "str", "v2c.keys", "len", "att_dict.append", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["import", "sys", "\n", "from", "collections", "import", "defaultdict", "\n", "\n", "# total number of iteration in smatch computation", "\n", "iteration_num", "=", "5", "\n", "\n", "# verbose output switch.", "\n", "# Default false (no verbose output)", "\n", "verbose", "=", "False", "\n", "veryVerbose", "=", "False", "\n", "\n", "# single score output switch.", "\n", "# Default true (compute a single score for all AMRs in two files)", "\n", "single_score", "=", "True", "\n", "\n", "# Error log location", "\n", "ERROR_LOG", "=", "sys", ".", "stderr", "\n", "\n", "# Debug log location", "\n", "DEBUG_LOG", "=", "sys", ".", "stderr", "\n", "\n", "# dictionary to save pre-computed node mapping and its resulting triple match count", "\n", "# key: tuples of node mapping", "\n", "# value: the matching triple count", "\n", "match_triple_dict", "=", "{", "}", "\n", "\n", "def", "parse_relations", "(", "rels", ",", "v2c", ")", ":", "\n", "    ", "var_list", "=", "[", "]", "\n", "conc_list", "=", "[", "]", "\n", "node_relation_dict1", "=", "defaultdict", "(", "list", ")", "\n", "node_relation_dict2", "=", "defaultdict", "(", "list", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.get_amr_line": [[75, 100], ["line.strip.strip", "line.strip.strip().startswith", "cur_amr.append", "line.strip.strip", "line.strip.strip"], "function", ["None"], ["                    ", "node_rel_list", ".", "append", "(", "[", "v2", "[", "0", "]", ",", "v2", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "                    ", "node_attr_list", ".", "append", "(", "[", "v2", "[", "0", "]", ",", "v2", "[", "1", "]", "]", ")", "\n", "# each node has a relation list and attribute list", "\n", "", "", "", "relation_list", ".", "append", "(", "node_rel_list", ")", "\n", "attribute_list", ".", "append", "(", "node_attr_list", ")", "\n", "# add TOP as an attribute. The attribute value is the top node value", "\n", "", "if", "len", "(", "conc_list", ")", ">", "0", ":", "\n", "        ", "attribute_list", "[", "0", "]", ".", "append", "(", "[", "\"TOP\"", ",", "conc_list", "[", "0", "]", "]", ")", "\n", "", "result_amr", "=", "amr", ".", "AMR", "(", "var_list", ",", "conc_list", ",", "relation_list", ",", "attribute_list", ")", "\n", "return", "result_amr", "\n", "\n", "", "def", "get_best_match", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "True", ",", "doattribute", "=", "True", ",", "dorelation", "=", "True", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.build_arg_parser": [[102, 119], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType"], "function", ["None"], ["\n", "# Compute candidate pool - all possible node match candidates.", "\n", "# In the hill-climbing, we only consider candidate in this pool to save computing time.", "\n", "# weight_dict is a dictionary that maps a pair of node", "\n", "(", "candidate_mappings", ",", "weight_dict", ")", "=", "compute_pool", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "doinstance", ",", "doattribute", "=", "doattribute", ",", "\n", "dorelation", "=", "dorelation", ")", "\n", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Candidate mappings:\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "candidate_mappings", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Weight dictionary\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "weight_dict", ",", "file", "=", "DEBUG_LOG", ")", "\n", "\n", "", "best_match_num", "=", "0", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.build_arg_parser2": [[121, 140], ["optparse.OptionParser", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.set_defaults"], "function", ["None"], ["# the ith entry is the node index in AMR 2 which maps to the ith node in AMR 1", "\n", "best_mapping", "=", "[", "-", "1", "]", "*", "len", "(", "instance1", ")", "\n", "for", "i", "in", "range", "(", "iteration_num", ")", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"Iteration\"", ",", "i", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "i", "==", "0", ":", "\n", "# smart initialization used for the first round", "\n", "            ", "cur_mapping", "=", "smart_init_mapping", "(", "candidate_mappings", ",", "instance1", ",", "instance2", ")", "\n", "", "else", ":", "\n", "# random initialization for the other round", "\n", "            ", "cur_mapping", "=", "random_init_mapping", "(", "candidate_mappings", ")", "\n", "# compute current triple match number", "\n", "", "match_num", "=", "compute_match", "(", "cur_mapping", ",", "weight_dict", ")", "\n", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"Node mapping at start\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Triple match number at start:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "while", "True", ":", "\n", "# get best gain", "\n", "            ", "(", "gain", ",", "new_mapping", ")", "=", "get_best_gain", "(", "cur_mapping", ",", "candidate_mappings", ",", "weight_dict", ",", "\n", "len", "(", "instance2", ")", ",", "match_num", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.get_best_match": [[142, 210], ["smatch_fromlists.compute_pool", "range", "len", "smatch_fromlists.compute_match", "smatch_fromlists.smart_init_mapping", "smatch_fromlists.random_init_mapping", "smatch_fromlists.get_best_gain", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_pool", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.smart_init_mapping", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.random_init_mapping", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_gain"], ["                ", "print", "(", "\"Gain after the hill-climbing\"", ",", "gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# hill-climbing until there will be no gain for new node mapping", "\n", "", "if", "gain", "<=", "0", ":", "\n", "                ", "break", "\n", "# otherwise update match_num and mapping", "\n", "", "match_num", "+=", "gain", "\n", "cur_mapping", "=", "new_mapping", "[", ":", "]", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Update triple match number to:\"", ",", "match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Current mapping:\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "if", "match_num", ">", "best_match_num", ":", "\n", "            ", "best_mapping", "=", "cur_mapping", "[", ":", "]", "\n", "best_match_num", "=", "match_num", "\n", "", "", "return", "best_mapping", ",", "best_match_num", "\n", "\n", "\n", "", "def", "normalize", "(", "item", ")", ":", "\n", "    ", "\"\"\"\n    lowercase and remove quote signifiers from items that are about to be compared\n    \"\"\"", "\n", "return", "item", ".", "lower", "(", ")", ".", "rstrip", "(", "'_'", ")", "\n", "\n", "\n", "", "def", "compute_pool", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "True", ",", "doattribute", "=", "True", ",", "dorelation", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    compute all possible node mapping candidates and their weights (the triple matching number gain resulting from\n    mapping one node in AMR 1 to another node in AMR2)\n\n    Arguments:\n        instance1: instance triples of AMR 1\n        attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n        relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n        instance2: instance triples of AMR 2\n        attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n        relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name\n        prefix1: prefix label for AMR 1\n        prefix2: prefix label for AMR 2\n    Returns:\n      candidate_mapping: a list of candidate nodes.\n                       The ith element contains the node indices (in AMR 2) the ith node (in AMR 1) can map to.\n                       (resulting in non-zero triple match)\n      weight_dict: a dictionary which contains the matching triple number for every pair of node mapping. The key\n                   is a node pair. The value is another dictionary. key {-1} is triple match resulting from this node\n                   pair alone (instance triples and attribute triples), and other keys are node pairs that can result\n                   in relation triple match together with the first node pair.\n\n\n    \"\"\"", "\n", "candidate_mapping", "=", "[", "]", "\n", "weight_dict", "=", "{", "}", "\n", "for", "instance1_item", "in", "instance1", ":", "\n", "# each candidate mapping is a set of node indices", "\n", "        ", "candidate_mapping", ".", "append", "(", "set", "(", ")", ")", "\n", "if", "doinstance", ":", "\n", "            ", "for", "instance2_item", "in", "instance2", ":", "\n", "# if both triples are instance triples and have the same value", "\n", "                ", "if", "normalize", "(", "instance1_item", "[", "0", "]", ")", "==", "normalize", "(", "instance2_item", "[", "0", "]", ")", "and", "normalize", "(", "instance1_item", "[", "2", "]", ")", "==", "normalize", "(", "instance2_item", "[", "2", "]", ")", ":", "\n", "# get node index by stripping the prefix", "\n", "                    ", "node1_index", "=", "int", "(", "instance1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index", "=", "int", "(", "instance2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "candidate_mapping", "[", "node1_index", "]", ".", "add", "(", "node2_index", ")", "\n", "node_pair", "=", "(", "node1_index", ",", "node2_index", ")", "\n", "# use -1 as key in weight_dict for instance triples and attribute triples", "\n", "if", "node_pair", "in", "weight_dict", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.compute_pool": [[212, 322], ["range", "range", "range", "len", "candidate_mapping.append", "range", "len", "range", "len", "range", "set", "len", "len", "len", "int", "int", "candidate_mapping[].add", "int", "int", "candidate_mapping[].add", "[].lower", "[].lower", "int", "int", "int", "int", "candidate_mapping[].add", "candidate_mapping[].add", "[].lower", "[].lower", "[].lower", "[].lower", "[].lower", "[].lower", "[].lower", "[].lower", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "=", "1", "\n", "", "", "", "", "", "if", "doattribute", ":", "\n", "        ", "for", "attribute1_item", "in", "attribute1", ":", "\n", "            ", "for", "attribute2_item", "in", "attribute2", ":", "\n", "# if both attribute relation triple have the same relation name and value", "\n", "                ", "if", "normalize", "(", "attribute1_item", "[", "0", "]", ")", "==", "normalize", "(", "attribute2_item", "[", "0", "]", ")", "and", "normalize", "(", "attribute1_item", "[", "2", "]", ")", "==", "normalize", "(", "attribute2_item", "[", "2", "]", ")", ":", "\n", "                    ", "node1_index", "=", "int", "(", "attribute1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index", "=", "int", "(", "attribute2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "candidate_mapping", "[", "node1_index", "]", ".", "add", "(", "node2_index", ")", "\n", "node_pair", "=", "(", "node1_index", ",", "node2_index", ")", "\n", "# use -1 as key in weight_dict for instance triples and attribute triples", "\n", "if", "node_pair", "in", "weight_dict", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "weight_dict", "[", "node_pair", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "=", "1", "\n", "", "", "", "", "", "if", "dorelation", ":", "\n", "        ", "for", "relation1_item", "in", "relation1", ":", "\n", "            ", "for", "relation2_item", "in", "relation2", ":", "\n", "# if both relation share the same name", "\n", "                ", "if", "normalize", "(", "relation1_item", "[", "0", "]", ")", "==", "normalize", "(", "relation2_item", "[", "0", "]", ")", ":", "\n", "                    ", "node1_index_amr1", "=", "int", "(", "relation1_item", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node1_index_amr2", "=", "int", "(", "relation2_item", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "node2_index_amr1", "=", "int", "(", "relation1_item", "[", "2", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index_amr2", "=", "int", "(", "relation2_item", "[", "2", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "# add mapping between two nodes", "\n", "candidate_mapping", "[", "node1_index_amr1", "]", ".", "add", "(", "node1_index_amr2", ")", "\n", "candidate_mapping", "[", "node2_index_amr1", "]", ".", "add", "(", "node2_index_amr2", ")", "\n", "node_pair1", "=", "(", "node1_index_amr1", ",", "node1_index_amr2", ")", "\n", "node_pair2", "=", "(", "node2_index_amr1", ",", "node2_index_amr2", ")", "\n", "if", "node_pair2", "!=", "node_pair1", ":", "\n", "# update weight_dict weight. Note that we need to update both entries for future search", "\n", "# i.e weight_dict[node_pair1][node_pair2]", "\n", "#     weight_dict[node_pair2][node_pair1]", "\n", "                        ", "if", "node1_index_amr1", ">", "node2_index_amr1", ":", "\n", "# swap node_pair1 and node_pair2", "\n", "                            ", "node_pair1", "=", "(", "node2_index_amr1", ",", "node2_index_amr2", ")", "\n", "node_pair2", "=", "(", "node1_index_amr1", ",", "node1_index_amr2", ")", "\n", "", "if", "node_pair1", "in", "weight_dict", ":", "\n", "                            ", "if", "node_pair2", "in", "weight_dict", "[", "node_pair1", "]", ":", "\n", "                                ", "weight_dict", "[", "node_pair1", "]", "[", "node_pair2", "]", "+=", "1", "\n", "", "else", ":", "\n", "                                ", "weight_dict", "[", "node_pair1", "]", "[", "node_pair2", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "=", "{", "-", "1", ":", "0", ",", "node_pair2", ":", "1", "}", "\n", "", "if", "node_pair2", "in", "weight_dict", ":", "\n", "                            ", "if", "node_pair1", "in", "weight_dict", "[", "node_pair2", "]", ":", "\n", "                                ", "weight_dict", "[", "node_pair2", "]", "[", "node_pair1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                                ", "weight_dict", "[", "node_pair2", "]", "[", "node_pair1", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair2", "]", "=", "{", "-", "1", ":", "0", ",", "node_pair1", ":", "1", "}", "\n", "", "", "else", ":", "\n", "# two node pairs are the same. So we only update weight_dict once.", "\n", "# this generally should not happen.", "\n", "                        ", "if", "node_pair1", "in", "weight_dict", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "=", "{", "-", "1", ":", "1", "}", "\n", "", "", "", "", "", "", "return", "candidate_mapping", ",", "weight_dict", "\n", "\n", "\n", "", "def", "smart_init_mapping", "(", "candidate_mapping", ",", "instance1", ",", "instance2", ")", ":", "\n", "    ", "\"\"\"\n    Initialize mapping based on the concept mapping (smart initialization)\n    Arguments:\n        candidate_mapping: candidate node match list\n        instance1: instance triples of AMR 1\n        instance2: instance triples of AMR 2\n    Returns:\n        initialized node mapping between two AMRs\n\n    \"\"\"", "\n", "random", ".", "seed", "(", ")", "\n", "matched_dict", "=", "{", "}", "\n", "result", "=", "[", "]", "\n", "# list to store node indices that have no concept match", "\n", "no_word_match", "=", "[", "]", "\n", "for", "i", ",", "candidates", "in", "enumerate", "(", "candidate_mapping", ")", ":", "\n", "        ", "if", "not", "candidates", ":", "\n", "# no possible mapping", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "continue", "\n", "# node value in instance triples of AMR 1", "\n", "", "value1", "=", "instance1", "[", "i", "]", "[", "2", "]", "\n", "for", "node_index", "in", "candidates", ":", "\n", "            ", "value2", "=", "instance2", "[", "node_index", "]", "[", "2", "]", "\n", "# find the first instance triple match in the candidates", "\n", "# instance triple match is having the same concept value", "\n", "if", "value1", "==", "value2", ":", "\n", "                ", "if", "node_index", "not", "in", "matched_dict", ":", "\n", "                    ", "result", ".", "append", "(", "node_index", ")", "\n", "matched_dict", "[", "node_index", "]", "=", "1", "\n", "break", "\n", "", "", "", "if", "len", "(", "result", ")", "==", "i", ":", "\n", "            ", "no_word_match", ".", "append", "(", "i", ")", "\n", "result", ".", "append", "(", "-", "1", ")", "\n", "# if no concept match, generate a random mapping", "\n", "", "", "for", "i", "in", "no_word_match", ":", "\n", "        ", "candidates", "=", "list", "(", "candidate_mapping", "[", "i", "]", ")", "\n", "while", "candidates", ":", "\n", "# get a random node index from candidates", "\n", "            ", "rid", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "candidates", ")", "-", "1", ")", "\n", "candidate", "=", "candidates", "[", "rid", "]", "\n", "if", "candidate", "in", "matched_dict", ":", "\n", "                ", "candidates", ".", "pop", "(", "rid", ")", "\n", "", "else", ":", "\n", "                ", "matched_dict", "[", "candidate", "]", "=", "1", "\n", "result", "[", "i", "]", "=", "candidate", "\n", "break", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.smart_init_mapping": [[324, 372], ["random.seed", "enumerate", "list", "len", "result.append", "len", "no_word_match.append", "result.append", "len", "random.randint", "list.pop", "result.append", "len"], "function", ["None"], ["\n", "\n", "", "def", "random_init_mapping", "(", "candidate_mapping", ")", ":", "\n", "    ", "\"\"\"\n    Generate a random node mapping.\n    Args:\n        candidate_mapping: candidate_mapping: candidate node match list\n    Returns:\n        randomly-generated node mapping between two AMRs\n\n    \"\"\"", "\n", "# if needed, a fixed seed could be passed here to generate same random (to help debugging)", "\n", "random", ".", "seed", "(", ")", "\n", "matched_dict", "=", "{", "}", "\n", "result", "=", "[", "]", "\n", "for", "c", "in", "candidate_mapping", ":", "\n", "        ", "candidates", "=", "list", "(", "c", ")", "\n", "if", "not", "candidates", ":", "\n", "# -1 indicates no possible mapping", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "continue", "\n", "", "found", "=", "False", "\n", "while", "candidates", ":", "\n", "# randomly generate an index in [0, length of candidates)", "\n", "            ", "rid", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "candidates", ")", "-", "1", ")", "\n", "candidate", "=", "candidates", "[", "rid", "]", "\n", "# check if it has already been matched", "\n", "if", "candidate", "in", "matched_dict", ":", "\n", "                ", "candidates", ".", "pop", "(", "rid", ")", "\n", "", "else", ":", "\n", "                ", "matched_dict", "[", "candidate", "]", "=", "1", "\n", "result", ".", "append", "(", "candidate", ")", "\n", "found", "=", "True", "\n", "break", "\n", "", "", "if", "not", "found", ":", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "", "", "return", "result", "\n", "\n", "\n", "", "def", "compute_match", "(", "mapping", ",", "weight_dict", ")", ":", "\n", "    ", "\"\"\"\n    Given a node mapping, compute match number based on weight_dict.\n    Args:\n    mappings: a list of node index in AMR 2. The ith element (value j) means node i in AMR 1 maps to node j in AMR 2.\n    Returns:\n    matching triple number\n    Complexity: O(m*n) , m is the node number of AMR 1, n is the node number of AMR 2\n\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.random_init_mapping": [[374, 408], ["random.seed", "list", "len", "result.append", "len", "random.randint", "result.append", "list.pop", "result.append", "len"], "function", ["None"], ["if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Computing match for mapping\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "tuple", "(", "mapping", ")", "in", "match_triple_dict", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"saved value\"", ",", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", "\n", "", "match_num", "=", "0", "\n", "# i is node index in AMR 1, m is node index in AMR 2", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "mapping", ")", ":", "\n", "        ", "if", "m", "==", "-", "1", ":", "\n", "# no node maps to this node", "\n", "            ", "continue", "\n", "# node i in AMR 1 maps to node m in AMR 2", "\n", "", "current_node_pair", "=", "(", "i", ",", "m", ")", "\n", "if", "current_node_pair", "not", "in", "weight_dict", ":", "\n", "            ", "continue", "\n", "", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"node_pair\"", ",", "current_node_pair", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "for", "key", "in", "weight_dict", "[", "current_node_pair", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "# matching triple resulting from instance/attribute triples", "\n", "                ", "match_num", "+=", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"instance/attribute match\"", ",", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# only consider node index larger than i to avoid duplicates", "\n", "# as we store both weight_dict[node_pair1][node_pair2] and", "\n", "#     weight_dict[node_pair2][node_pair1] for a relation", "\n", "", "", "elif", "key", "[", "0", "]", "<", "i", ":", "\n", "                ", "continue", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "match_num", "+=", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"relation match with\"", ",", "key", ",", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "", "", "if", "veryVerbose", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.compute_match": [[410, 460], ["enumerate", "tuple", "tuple", "tuple", "tuple"], "function", ["None"], ["# update match_triple_dict", "\n", "", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", "=", "match_num", "\n", "return", "match_num", "\n", "\n", "\n", "", "def", "move_gain", "(", "mapping", ",", "node_id", ",", "old_id", ",", "new_id", ",", "weight_dict", ",", "match_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the triple match number gain from the move operation\n    Arguments:\n        mapping: current node mapping\n        node_id: remapped node in AMR 1\n        old_id: original node id in AMR 2 to which node_id is mapped\n        new_id: new node in to which node_id is mapped\n        weight_dict: weight dictionary\n        match_num: the original triple matching number\n    Returns:\n        the triple match gain number (might be negative)\n\n    \"\"\"", "\n", "# new node mapping after moving", "\n", "new_mapping", "=", "(", "node_id", ",", "new_id", ")", "\n", "# node mapping before moving", "\n", "old_mapping", "=", "(", "node_id", ",", "old_id", ")", "\n", "# new nodes mapping list (all node pairs)", "\n", "new_mapping_list", "=", "mapping", "[", ":", "]", "\n", "new_mapping_list", "[", "node_id", "]", "=", "new_id", "\n", "# if this mapping is already been investigated, use saved one to avoid duplicate computing", "\n", "if", "tuple", "(", "new_mapping_list", ")", "in", "match_triple_dict", ":", "\n", "        ", "return", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "-", "match_num", "\n", "", "gain", "=", "0", "\n", "# add the triple match incurred by new_mapping to gain", "\n", "if", "new_mapping", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "# instance/attribute triple match", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping", "]", "[", "-", "1", "]", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "# relation gain incurred by new_mapping and another node pair in new_mapping_list", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping", "]", "[", "key", "]", "\n", "# deduct the triple match incurred by old_mapping from gain", "\n", "", "", "", "if", "old_mapping", "in", "weight_dict", ":", "\n", "        ", "for", "k", "in", "weight_dict", "[", "old_mapping", "]", ":", "\n", "            ", "if", "k", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping", "]", "[", "-", "1", "]", "\n", "", "elif", "mapping", "[", "k", "[", "0", "]", "]", "==", "k", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping", "]", "[", "k", "]", "\n", "# update match number dictionary", "\n", "", "", "", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "=", "match_num", "+", "gain", "\n", "return", "gain", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.move_gain": [[462, 506], ["tuple", "tuple", "tuple"], "function", ["None"], ["    ", "\"\"\"\n    Compute the triple match number gain from the swapping\n    Arguments:\n    mapping: current node mapping list\n    node_id1: node 1 index in AMR 1\n    mapping_id1: the node index in AMR 2 node 1 maps to (in the current mapping)\n    node_id2: node 2 index in AMR 1\n    mapping_id2: the node index in AMR 2 node 2 maps to (in the current mapping)\n    weight_dict: weight dictionary\n    match_num: the original matching triple number\n    Returns:\n    the gain number (might be negative)\n\n    \"\"\"", "\n", "new_mapping_list", "=", "mapping", "[", ":", "]", "\n", "# Before swapping, node_id1 maps to mapping_id1, and node_id2 maps to mapping_id2", "\n", "# After swapping, node_id1 maps to mapping_id2 and node_id2 maps to mapping_id1", "\n", "new_mapping_list", "[", "node_id1", "]", "=", "mapping_id2", "\n", "new_mapping_list", "[", "node_id2", "]", "=", "mapping_id1", "\n", "if", "tuple", "(", "new_mapping_list", ")", "in", "match_triple_dict", ":", "\n", "        ", "return", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "-", "match_num", "\n", "", "gain", "=", "0", "\n", "new_mapping1", "=", "(", "node_id1", ",", "mapping_id2", ")", "\n", "new_mapping2", "=", "(", "node_id2", ",", "mapping_id1", ")", "\n", "old_mapping1", "=", "(", "node_id1", ",", "mapping_id1", ")", "\n", "old_mapping2", "=", "(", "node_id2", ",", "mapping_id2", ")", "\n", "if", "node_id1", ">", "node_id2", ":", "\n", "        ", "new_mapping2", "=", "(", "node_id1", ",", "mapping_id2", ")", "\n", "new_mapping1", "=", "(", "node_id2", ",", "mapping_id1", ")", "\n", "old_mapping1", "=", "(", "node_id2", ",", "mapping_id2", ")", "\n", "old_mapping2", "=", "(", "node_id1", ",", "mapping_id1", ")", "\n", "", "if", "new_mapping1", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping1", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping1", "]", "[", "-", "1", "]", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping1", "]", "[", "key", "]", "\n", "", "", "", "if", "new_mapping2", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping2", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping2", "]", "[", "-", "1", "]", "\n", "# to avoid duplicate", "\n", "", "elif", "key", "[", "0", "]", "==", "node_id1", ":", "\n", "                ", "continue", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.swap_gain": [[508, 572], ["tuple", "tuple", "tuple"], "function", ["None"], ["", "", "", "if", "old_mapping1", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "old_mapping1", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping1", "]", "[", "-", "1", "]", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping1", "]", "[", "key", "]", "\n", "", "", "", "if", "old_mapping2", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "old_mapping2", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping2", "]", "[", "-", "1", "]", "\n", "# to avoid duplicate", "\n", "", "elif", "key", "[", "0", "]", "==", "node_id1", ":", "\n", "                ", "continue", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping2", "]", "[", "key", "]", "\n", "", "", "", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "=", "match_num", "+", "gain", "\n", "return", "gain", "\n", "\n", "\n", "", "def", "get_best_gain", "(", "mapping", ",", "candidate_mappings", ",", "weight_dict", ",", "instance_len", ",", "cur_match_num", ")", ":", "\n", "    ", "\"\"\"\n    Hill-climbing method to return the best gain swap/move can get\n    Arguments:\n    mapping: current node mapping\n    candidate_mappings: the candidates mapping list\n    weight_dict: the weight dictionary\n    instance_len: the number of the nodes in AMR 2\n    cur_match_num: current triple match number\n    Returns:\n    the best gain we can get via swap/move operation\n\n    \"\"\"", "\n", "largest_gain", "=", "0", "\n", "# True: using swap; False: using move", "\n", "use_swap", "=", "True", "\n", "# the node to be moved/swapped", "\n", "node1", "=", "None", "\n", "# store the other node affected. In swap, this other node is the node swapping with node1. In move, this other", "\n", "# node is the node node1 will move to.", "\n", "node2", "=", "None", "\n", "# unmatched nodes in AMR 2", "\n", "unmatched", "=", "set", "(", "range", "(", "instance_len", ")", ")", "\n", "# exclude nodes in current mapping", "\n", "# get unmatched nodes", "\n", "for", "nid", "in", "mapping", ":", "\n", "        ", "if", "nid", "in", "unmatched", ":", "\n", "            ", "unmatched", ".", "remove", "(", "nid", ")", "\n", "", "", "for", "i", ",", "nid", "in", "enumerate", "(", "mapping", ")", ":", "\n", "# current node i in AMR 1 maps to node nid in AMR 2", "\n", "        ", "for", "nm", "in", "unmatched", ":", "\n", "            ", "if", "nm", "in", "candidate_mappings", "[", "i", "]", ":", "\n", "# remap i to another unmatched node (move)", "\n", "# (i, m) -> (i, nm)", "\n", "                ", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"Remap node\"", ",", "i", ",", "\"from \"", ",", "nid", ",", "\"to\"", ",", "nm", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "mv_gain", "=", "move_gain", "(", "mapping", ",", "i", ",", "nid", ",", "nm", ",", "weight_dict", ",", "cur_match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                    ", "print", "(", "\"Move gain:\"", ",", "mv_gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_mapping", "=", "mapping", "[", ":", "]", "\n", "new_mapping", "[", "i", "]", "=", "nm", "\n", "new_match_num", "=", "compute_match", "(", "new_mapping", ",", "weight_dict", ")", "\n", "if", "new_match_num", "!=", "cur_match_num", "+", "mv_gain", ":", "\n", "                        ", "print", "(", "mapping", ",", "new_mapping", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Inconsistency in computing: move gain\"", ",", "cur_match_num", ",", "mv_gain", ",", "new_match_num", ",", "\n", "file", "=", "ERROR_LOG", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.get_best_gain": [[574, 672], ["set", "enumerate", "enumerate", "range", "range", "set.remove", "len", "smatch_fromlists.swap_gain", "smatch_fromlists.move_gain", "smatch_fromlists.compute_match", "smatch_fromlists.compute_match"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.swap_gain", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.move_gain", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match"], ["                    ", "largest_gain", "=", "mv_gain", "\n", "node1", "=", "i", "\n", "node2", "=", "nm", "\n", "use_swap", "=", "False", "\n", "# compute swap gain", "\n", "", "", "", "", "for", "i", ",", "m", "in", "enumerate", "(", "mapping", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "mapping", ")", ")", ":", "\n", "            ", "m2", "=", "mapping", "[", "j", "]", "\n", "# swap operation (i, m) (j, m2) -> (i, m2) (j, m)", "\n", "# j starts from i+1, to avoid duplicate swap", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Swap node\"", ",", "i", ",", "\"and\"", ",", "j", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Before swapping:\"", ",", "i", ",", "\"-\"", ",", "m", ",", "\",\"", ",", "j", ",", "\"-\"", ",", "m2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"After swapping:\"", ",", "i", ",", "\"-\"", ",", "m2", ",", "\",\"", ",", "j", ",", "\"-\"", ",", "m", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "sw_gain", "=", "swap_gain", "(", "mapping", ",", "i", ",", "m", ",", "j", ",", "m2", ",", "weight_dict", ",", "cur_match_num", ")", "\n", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Swap gain:\"", ",", "sw_gain", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_mapping", "=", "mapping", "[", ":", "]", "\n", "new_mapping", "[", "i", "]", "=", "m2", "\n", "new_mapping", "[", "j", "]", "=", "m", "\n", "print", "(", "new_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "new_match_num", "=", "compute_match", "(", "new_mapping", ",", "weight_dict", ")", "\n", "if", "new_match_num", "!=", "cur_match_num", "+", "sw_gain", ":", "\n", "                    ", "print", "(", "mapping", ",", "new_mapping", ",", "file", "=", "ERROR_LOG", ")", "\n", "print", "(", "\"Inconsistency in computing: swap gain\"", ",", "cur_match_num", ",", "sw_gain", ",", "new_match_num", ",", "\n", "file", "=", "ERROR_LOG", ")", "\n", "", "", "if", "sw_gain", ">", "largest_gain", ":", "\n", "                ", "largest_gain", "=", "sw_gain", "\n", "node1", "=", "i", "\n", "node2", "=", "j", "\n", "use_swap", "=", "True", "\n", "# generate a new mapping based on swap/move", "\n", "", "", "", "cur_mapping", "=", "mapping", "[", ":", "]", "\n", "if", "node1", "is", "not", "None", ":", "\n", "        ", "if", "use_swap", ":", "\n", "            ", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Use swap gain\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "temp", "=", "cur_mapping", "[", "node1", "]", "\n", "cur_mapping", "[", "node1", "]", "=", "cur_mapping", "[", "node2", "]", "\n", "cur_mapping", "[", "node2", "]", "=", "temp", "\n", "", "else", ":", "\n", "            ", "if", "veryVerbose", ":", "\n", "                ", "print", "(", "\"Use move gain\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "cur_mapping", "[", "node1", "]", "=", "node2", "\n", "", "", "else", ":", "\n", "        ", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"no move/swap gain found\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "", "if", "veryVerbose", ":", "\n", "        ", "print", "(", "\"Original mapping\"", ",", "mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Current mapping\"", ",", "cur_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "largest_gain", ",", "cur_mapping", "\n", "\n", "\n", "", "def", "print_alignment", "(", "mapping", ",", "instance1", ",", "instance2", ")", ":", "\n", "    ", "\"\"\"\n    print the alignment based on a node mapping\n    Args:\n        mapping: current node mapping list\n        instance1: nodes of AMR 1\n        instance2: nodes of AMR 2\n\n    \"\"\"", "\n", "result", "=", "[", "]", "\n", "for", "instance1_item", ",", "m", "in", "zip", "(", "instance1", ",", "mapping", ")", ":", "\n", "        ", "r", "=", "instance1_item", "[", "1", "]", "+", "\"(\"", "+", "instance1_item", "[", "2", "]", "+", "\")\"", "\n", "if", "m", "==", "-", "1", ":", "\n", "            ", "r", "+=", "\"-Null\"", "\n", "", "else", ":", "\n", "            ", "instance2_item", "=", "instance2", "[", "m", "]", "\n", "r", "+=", "\"-\"", "+", "instance2_item", "[", "1", "]", "+", "\"(\"", "+", "instance2_item", "[", "2", "]", "+", "\")\"", "\n", "", "result", ".", "append", "(", "r", ")", "\n", "", "return", "\" \"", ".", "join", "(", "result", ")", "\n", "\n", "\n", "", "def", "compute_f", "(", "match_num", ",", "test_num", ",", "gold_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the f-score based on the matching triple number,\n                                 triple number of AMR set 1,\n                                 triple number of AMR set 2\n    Args:\n        match_num: matching triple number\n        test_num:  triple number of AMR 1 (test file)\n        gold_num:  triple number of AMR 2 (gold file)\n    Returns:\n        precision: match_num/test_num\n        recall: match_num/gold_num\n        f_score: 2*precision*recall/(precision+recall)\n    \"\"\"", "\n", "if", "test_num", "==", "0", "or", "gold_num", "==", "0", ":", "\n", "        ", "return", "0.00", ",", "0.00", ",", "0.00", "\n", "", "precision", "=", "float", "(", "match_num", ")", "/", "float", "(", "test_num", ")", "\n", "recall", "=", "float", "(", "match_num", ")", "/", "float", "(", "gold_num", ")", "\n", "if", "(", "precision", "+", "recall", ")", "!=", "0", ":", "\n", "        ", "f_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "if", "veryVerbose", ":", "\n", "            ", "print", "(", "\"F-score:\"", ",", "f_score", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "precision", ",", "recall", ",", "f_score", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.print_alignment": [[674, 691], ["enumerate", "result.append", "result.append"], "function", ["None"], ["            ", "print", "(", "\"F-score:\"", ",", "\"0.0\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "return", "precision", ",", "recall", ",", "0.00", "\n", "\n", "\n", "", "", "def", "generate_amr_lines", "(", "list1", ",", "list2", ")", ":", "\n", "    ", "\"\"\"\n    Read one AMR line at a time from each file handle\n    :param f1: file handle (or any iterable of strings) to read AMR 1 lines from\n    :param f2: file handle (or any iterable of strings) to read AMR 2 lines from\n    :return: generator of cur_amr1, cur_amr2 pairs: one-line AMR strings\n    \"\"\"", "\n", "for", "l1", ",", "l2", "in", "zip", "(", "list1", ",", "list2", ")", ":", "\n", "        ", "lst_amr1", ",", "dic_amr1", "=", "l1", "\n", "lst_amr2", ",", "dic_amr2", "=", "l2", "\n", "amr1", "=", "parse_relations", "(", "lst_amr1", ",", "dic_amr1", ")", "\n", "amr2", "=", "parse_relations", "(", "lst_amr2", ",", "dic_amr2", ")", "\n", "yield", "amr1", ",", "amr2", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.compute_f": [[693, 722], ["None"], "function", ["None"], ["", "", "def", "get_amr_match", "(", "amr1", ",", "amr2", ",", "sent_num", "=", "1", ",", "justinstance", "=", "False", ",", "justattribute", "=", "False", ",", "justrelation", "=", "False", ")", ":", "\n", "    ", "prefix1", "=", "\"a\"", "\n", "prefix2", "=", "\"b\"", "\n", "# Rename node to \"a1\", \"a2\", .etc", "\n", "if", "str", "(", "amr1", ")", "!=", "''", ":", "\n", "        ", "amr1", ".", "rename_node", "(", "prefix1", ")", "\n", "# Renaming node to \"b1\", \"b2\", .etc", "\n", "", "if", "str", "(", "amr2", ")", "!=", "''", ":", "\n", "        ", "amr2", ".", "rename_node", "(", "prefix2", ")", "\n", "", "(", "instance1", ",", "attributes1", ",", "relation1", ")", "=", "amr1", ".", "get_triples", "(", ")", "\n", "(", "instance2", ",", "attributes2", ",", "relation2", ")", "=", "amr2", ".", "get_triples", "(", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"AMR pair\"", ",", "sent_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"============================================\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"AMR 1 (one-line):\"", ",", "cur_amr1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"AMR 2 (one-line):\"", ",", "cur_amr2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Instance triples of AMR 1:\"", ",", "len", "(", "instance1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "instance1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of AMR 1:\"", ",", "len", "(", "attributes1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "attributes1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of AMR 1:\"", ",", "len", "(", "relation1", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "relation1", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Instance triples of AMR 2:\"", ",", "len", "(", "instance2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "instance2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Attribute triples of AMR 2:\"", ",", "len", "(", "attributes2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "attributes2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Relation triples of AMR 2:\"", ",", "len", "(", "relation2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "relation2", ",", "file", "=", "DEBUG_LOG", ")", "\n", "# optionally turn off some of the node comparison", "\n", "", "doinstance", "=", "doattribute", "=", "dorelation", "=", "True", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.run": [[724, 839], ["zip", "smatch_fromlists.parse_relations", "smatch_fromlists.parse_relations", "parse_relations.rename_node", "parse_relations.rename_node", "parse_relations.get_triples", "parse_relations.get_triples", "smatch_fromlists.get_best_match", "match_triple_dict.clear", "smatch_fromlists.compute_f", "len", "len", "smatch_fromlists.compute_f", "print", "len", "len", "len", "len", "len", "len", "smatch_fromlists.print_alignment", "len", "len", "len", "len", "print", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.parse_relations", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.parse_relations", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_match", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.print_alignment", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["        ", "doattribute", "=", "dorelation", "=", "False", "\n", "", "if", "justattribute", ":", "\n", "        ", "doinstance", "=", "dorelation", "=", "False", "\n", "", "if", "justrelation", ":", "\n", "        ", "doinstance", "=", "doattribute", "=", "False", "\n", "", "(", "best_mapping", ",", "best_match_num", ")", "=", "get_best_match", "(", "instance1", ",", "attributes1", ",", "relation1", ",", "\n", "instance2", ",", "attributes2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ",", "doinstance", "=", "doinstance", ",", "\n", "doattribute", "=", "doattribute", ",", "dorelation", "=", "dorelation", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"best match number\"", ",", "best_match_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"best node mapping\"", ",", "best_mapping", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"Best node mapping alignment:\"", ",", "print_alignment", "(", "best_mapping", ",", "instance1", ",", "instance2", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "justinstance", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "instance1", ")", "\n", "gold_triple_num", "=", "len", "(", "instance2", ")", "\n", "", "elif", "justattribute", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "attributes1", ")", "\n", "gold_triple_num", "=", "len", "(", "attributes2", ")", "\n", "", "elif", "justrelation", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "relation1", ")", "\n", "gold_triple_num", "=", "len", "(", "relation2", ")", "\n", "", "else", ":", "\n", "        ", "test_triple_num", "=", "len", "(", "instance1", ")", "+", "len", "(", "attributes1", ")", "+", "len", "(", "relation1", ")", "\n", "gold_triple_num", "=", "len", "(", "instance2", ")", "+", "len", "(", "attributes2", ")", "+", "len", "(", "relation2", ")", "\n", "", "return", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", "\n", "\n", "\n", "", "def", "score_amr_pairs", "(", "f1", ",", "f2", ",", "justinstance", "=", "False", ",", "justattribute", "=", "False", ",", "justrelation", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Score one pair of AMR lines at a time from each file handle\n    :param f1: file handle (or any iterable of strings) to read AMR 1 lines from\n    :param f2: file handle (or any iterable of strings) to read AMR 2 lines from\n    :param justinstance: just pay attention to matching instances\n    :param justattribute: just pay attention to matching attributes\n    :param justrelation: just pay attention to matching relations\n    :return: generator of cur_amr1, cur_amr2 pairs: one-line AMR strings\n    \"\"\"", "\n", "# matching triple number, triple number in test file, triple number in gold file", "\n", "total_match_num", "=", "total_test_num", "=", "total_gold_num", "=", "0", "\n", "# Read amr pairs from two files", "\n", "for", "sent_num", ",", "(", "cur_amr1", ",", "cur_amr2", ")", "in", "enumerate", "(", "generate_amr_lines", "(", "f1", ",", "f2", ")", ",", "start", "=", "1", ")", ":", "\n", "        ", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", "=", "get_amr_match", "(", "cur_amr1", ",", "cur_amr2", ",", "\n", "sent_num", "=", "sent_num", ",", "# sentence number", "\n", "justinstance", "=", "justinstance", ",", "\n", "justattribute", "=", "justattribute", ",", "\n", "justrelation", "=", "justrelation", ")", "\n", "total_match_num", "+=", "best_match_num", "\n", "total_test_num", "+=", "test_triple_num", "\n", "total_gold_num", "+=", "gold_triple_num", "\n", "# clear the matching triple dictionary for the next AMR pair", "\n", "match_triple_dict", ".", "clear", "(", ")", "\n", "if", "not", "single_score", ":", "# if each AMR pair should have a score, compute and output it here", "\n", "            ", "yield", "compute_f", "(", "best_match_num", ",", "test_triple_num", ",", "gold_triple_num", ")", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\"Total match number, total triple number in AMR 1, and total triple number in AMR 2:\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "total_match_num", ",", "total_test_num", ",", "total_gold_num", ",", "file", "=", "DEBUG_LOG", ")", "\n", "print", "(", "\"---------------------------------------------------------------------------------\"", ",", "file", "=", "DEBUG_LOG", ")", "\n", "", "if", "single_score", ":", "# output document-level smatch score (a single f-score for all AMR pairs in two files)", "\n", "        ", "yield", "compute_f", "(", "total_match_num", ",", "total_test_num", ",", "total_gold_num", ")", "\n", "\n", "\n", "", "", "def", "run", "(", "list1", ",", "list2", ",", "pr_flag", ")", ":", "\n", "    ", "\"\"\"\n    Main function of smatch score calculation\n    \"\"\"", "\n", "global", "verbose", "\n", "global", "veryVerbose", "\n", "global", "iteration_num", "\n", "global", "single_score", "\n", "global", "match_triple_dict", "\n", "# set the iteration number", "\n", "# total iteration number = restart number + 1", "\n", "iteration_num", "=", "5", "\n", "# significant digits to print out", "\n", "floatdisplay", "=", "\"%%.%df\"", "%", "2", "\n", "for", "(", "precision", ",", "recall", ",", "best_f_score", ")", "in", "score_amr_pairs", "(", "list1", ",", "list2", ",", "\n", "justinstance", "=", "False", ",", "\n", "justattribute", "=", "False", ",", "\n", "justrelation", "=", "False", ")", ":", "\n", "        ", "return", "precision", ",", "recall", ",", "best_f_score", "\n", "\n", "", "", "def", "main", "(", "list1", ",", "list2", ",", "pr_flag", "=", "False", ")", ":", "\n", "    ", "return", "run", "(", "list1", ",", "list2", ",", "pr_flag", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromlists.main": [[842, 844], ["smatch_fromlists.run"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run"], []], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.parse_relations": [[17, 52], ["range", "enumerate", "amr.AMR", "len", "len", "len", "rel_dict.append", "att_dict.append", "str", "var_list.append", "conc_list.append", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["def", "parse_relations", "(", "rels", ",", "v2c", ")", ":", "\n", "    ", "var_list", "=", "[", "]", "\n", "conc_list", "=", "[", "]", "\n", "top", "=", "None", "\n", "for", "r", "in", "rels", ":", "\n", "        ", "if", "str", "(", "r", "[", "1", "]", ")", "not", "in", "var_list", "and", "str", "(", "r", "[", "1", "]", ")", "!=", "\"TOP\"", "and", "r", "[", "1", "]", "in", "v2c", ":", "\n", "#             var_list.append(str(r[1]))", "\n", "#             conc_list.append(str(v2c[r[1]]))", "\n", "            ", "top", "=", "str", "(", "r", "[", "1", "]", ")", "\n", "", "if", "str", "(", "r", "[", "2", "]", ")", "not", "in", "var_list", "and", "r", "[", "2", "]", "in", "v2c", ":", "\n", "            ", "var_list", ".", "append", "(", "str", "(", "r", "[", "2", "]", ")", ")", "\n", "conc_list", ".", "append", "(", "str", "(", "v2c", "[", "r", "[", "2", "]", "]", ")", ")", "\n", "", "", "rel_dict", "=", "[", "]", "*", "len", "(", "var_list", ")", "\n", "att_dict", "=", "[", "]", "*", "len", "(", "var_list", ")", "\n", "#     print >> DEBUG_LOG, conc_list", "\n", "for", "i", "in", "range", "(", "len", "(", "var_list", ")", ")", ":", "\n", "        ", "rel_dict", ".", "append", "(", "{", "}", ")", "\n", "att_dict", ".", "append", "(", "{", "}", ")", "\n", "", "if", "top", "is", "not", "None", ":", "\n", "        ", "att_dict", "[", "0", "]", "[", "\"TOP\"", "]", "=", "top", "\n", "#     if len(conc_list) > 0:", "\n", "#         att_dict[0][\"TOP\"] = conc_list[0]", "\n", "#     else:", "\n", "#         keys = [x for x in v2c.keys()]", "\n", "#         if len(keys) > 0:", "\n", "#             if len(att_dict) == 0:", "\n", "#                 att_dict.append({}) ", "\n", "#             att_dict[0][\"TOP\"] = keys[0]", "\n", "", "for", "k", ",", "v", "in", "enumerate", "(", "var_list", ")", ":", "\n", "        ", "for", "i", "in", "rels", ":", "\n", "            ", "if", "str", "(", "i", "[", "1", "]", ")", "==", "str", "(", "v", ")", "and", "i", "[", "2", "]", "in", "v2c", ":", "\n", "                ", "rel_dict", "[", "k", "]", "[", "str", "(", "i", "[", "2", "]", ")", "]", "=", "i", "[", "0", "]", "\n", "", "elif", "str", "(", "i", "[", "1", "]", ")", "==", "str", "(", "v", ")", ":", "\n", "                ", "att_dict", "[", "k", "]", "[", "i", "[", "0", "]", "]", "=", "str", "(", "i", "[", "2", "]", ")", "\n", "", "", "", "return", "amr", ".", "AMR", "(", "var_list", ",", "conc_list", ",", "rel_dict", ",", "att_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_amr_line": [[80, 105], ["line.strip.strip", "line.strip.strip().startswith", "cur_amr.append", "line.strip.strip", "line.strip.strip"], "function", ["None"], ["def", "get_amr_line", "(", "input_f", ")", ":", "\n", "    ", "\"\"\"\n    Read the file containing AMRs. AMRs are separated by a blank line.\n    Each call of get_amr_line() returns the next available AMR (in one-line form).\n    Note: this function does not verify if the AMR is valid\n\n    \"\"\"", "\n", "cur_amr", "=", "[", "]", "\n", "has_content", "=", "False", "\n", "for", "line", "in", "input_f", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "\"\"", ":", "\n", "            ", "if", "not", "has_content", ":", "\n", "# empty lines before current AMR", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "# end of current AMR", "\n", "                ", "break", "\n", "", "", "if", "line", ".", "strip", "(", ")", ".", "startswith", "(", "\"#\"", ")", ":", "\n", "# ignore the comment line (starting with \"#\") in the AMR file", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "has_content", "=", "True", "\n", "cur_amr", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "cur_amr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.build_arg_parser": [[107, 124], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.FileType"], "function", ["None"], ["", "def", "build_arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Build an argument parser using argparse. Use it when python version is 2.7 or later.\n\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Smatch calculator -- arguments\"", ")", "\n", "parser", ".", "add_argument", "(", "'-f'", ",", "nargs", "=", "2", ",", "required", "=", "True", ",", "type", "=", "argparse", ".", "FileType", "(", "'r'", ")", ",", "\n", "help", "=", "'Two files containing AMR pairs. AMRs in each file are separated by a single blank line'", ")", "\n", "parser", ".", "add_argument", "(", "'-r'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "'Restart number (Default:4)'", ")", "\n", "parser", ".", "add_argument", "(", "'-v'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Verbose output (Default:false)'", ")", "\n", "parser", ".", "add_argument", "(", "'-a'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Print alignments (Default:false)'", ")", "\n", "parser", ".", "add_argument", "(", "'--ms'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'Output multiple scores (one AMR pair a score)'", "'instead of a single document-level smatch score (Default: false)'", ")", "\n", "parser", ".", "add_argument", "(", "'--pr'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "\"Output precision and recall as well as the f-score. Default: false\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.build_arg_parser2": [[126, 145], ["optparse.OptionParser", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.add_option", "optparse.OptionParser.set_defaults"], "function", ["None"], ["", "def", "build_arg_parser2", "(", ")", ":", "\n", "    ", "\"\"\"\n    Build an argument parser using optparse. Use it when python version is 2.5 or 2.6.\n\n    \"\"\"", "\n", "usage_str", "=", "\"Smatch calculator -- arguments\"", "\n", "parser", "=", "optparse", ".", "OptionParser", "(", "usage", "=", "usage_str", ")", "\n", "parser", ".", "add_option", "(", "\"-f\"", ",", "\"--files\"", ",", "nargs", "=", "2", ",", "dest", "=", "\"f\"", ",", "type", "=", "\"string\"", ",", "\n", "help", "=", "'Two files containing AMR pairs. AMRs in each file are '", "'separated by a single blank line. This option is required.'", ")", "\n", "parser", ".", "add_option", "(", "\"-r\"", ",", "\"--restart\"", ",", "dest", "=", "\"r\"", ",", "type", "=", "\"int\"", ",", "help", "=", "'Restart number (Default: 4)'", ")", "\n", "parser", ".", "add_option", "(", "\"-v\"", ",", "\"--verbose\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"v\"", ",", "help", "=", "'Verbose output (Default:False)'", ")", "\n", "parser", ".", "add_option", "(", "\"--ms\"", ",", "\"--multiple_score\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"ms\"", ",", "\n", "help", "=", "'Output multiple scores (one AMR pair a score) instead of '", "'a single document-level smatch score (Default: False)'", ")", "\n", "parser", ".", "add_option", "(", "'--pr'", ",", "\"--precision_recall\"", ",", "action", "=", "'store_true'", ",", "dest", "=", "\"pr\"", ",", "\n", "help", "=", "\"Output precision and recall as well as the f-score. Default: false\"", ")", "\n", "parser", ".", "set_defaults", "(", "r", "=", "4", ",", "v", "=", "False", ",", "ms", "=", "False", ",", "pr", "=", "False", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_match": [[147, 215], ["smatch_fromsubgraphs.compute_pool", "range", "len", "smatch_fromsubgraphs.compute_match", "smatch_fromsubgraphs.smart_init_mapping", "smatch_fromsubgraphs.random_init_mapping", "smatch_fromsubgraphs.get_best_gain", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_pool", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.smart_init_mapping", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.random_init_mapping", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_gain"], ["", "def", "get_best_match", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ")", ":", "\n", "    ", "\"\"\"\n    Get the highest triple match number between two sets of triples via hill-climbing.\n    Arguments:\n        instance1: instance triples of AMR 1 (\"instance\", node name, node value)\n        attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n        relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n        instance2: instance triples of AMR 2 (\"instance\", node name, node value)\n        attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n        relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name)\n        prefix1: prefix label for AMR 1\n        prefix2: prefix label for AMR 2\n    Returns:\n        best_match: the node mapping that results in the highest triple matching number\n        best_match_num: the highest triple matching number\n\n    \"\"\"", "\n", "# Compute candidate pool - all possible node match candidates.", "\n", "# In the hill-climbing, we only consider candidate in this pool to save computing time.", "\n", "# weight_dict is a dictionary that maps a pair of node", "\n", "(", "candidate_mappings", ",", "weight_dict", ")", "=", "compute_pool", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ")", "\n", "\n", "if", "verbose", ":", "\n", "        ", "print", ">>", "DEBUG_LOG", ",", "\"Candidate mappings:\"", "\n", "print", ">>", "DEBUG_LOG", ",", "candidate_mappings", "\n", "print", ">>", "DEBUG_LOG", ",", "\"Weight dictionary\"", "\n", "print", ">>", "DEBUG_LOG", ",", "weight_dict", "\n", "", "best_match_num", "=", "0", "\n", "# initialize best match mapping", "\n", "# the ith entry is the node index in AMR 2 which maps to the ith node in AMR 1", "\n", "best_mapping", "=", "[", "-", "1", "]", "*", "len", "(", "instance1", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "iteration_num", ")", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", ">>", "DEBUG_LOG", ",", "\"Iteration\"", ",", "i", "\n", "", "if", "i", "==", "0", ":", "\n", "# smart initialization used for the first round", "\n", "            ", "cur_mapping", "=", "smart_init_mapping", "(", "candidate_mappings", ",", "instance1", ",", "instance2", ")", "\n", "", "else", ":", "\n", "# random initialization for the other round", "\n", "            ", "cur_mapping", "=", "random_init_mapping", "(", "candidate_mappings", ")", "\n", "# compute current triple match number", "\n", "", "match_num", "=", "compute_match", "(", "cur_mapping", ",", "weight_dict", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", ">>", "DEBUG_LOG", ",", "\"Node mapping at start\"", ",", "cur_mapping", "\n", "print", ">>", "DEBUG_LOG", ",", "\"Triple match number at start:\"", ",", "match_num", "\n", "", "while", "True", ":", "\n", "# get best gain", "\n", "            ", "(", "gain", ",", "new_mapping", ")", "=", "get_best_gain", "(", "cur_mapping", ",", "candidate_mappings", ",", "weight_dict", ",", "\n", "len", "(", "instance2", ")", ",", "match_num", ")", "\n", "if", "verbose", ":", "\n", "                ", "print", ">>", "DEBUG_LOG", ",", "\"Gain after the hill-climbing\"", ",", "gain", "\n", "# hill-climbing until there will be no gain for new node mapping", "\n", "", "if", "gain", "<=", "0", ":", "\n", "                ", "break", "\n", "# otherwise update match_num and mapping", "\n", "", "match_num", "+=", "gain", "\n", "cur_mapping", "=", "new_mapping", "[", ":", "]", "\n", "if", "verbose", ":", "\n", "                ", "print", ">>", "DEBUG_LOG", ",", "\"Update triple match number to:\"", ",", "match_num", "\n", "print", ">>", "DEBUG_LOG", ",", "\"Current mapping:\"", ",", "cur_mapping", "\n", "", "", "if", "match_num", ">", "best_match_num", ":", "\n", "            ", "best_mapping", "=", "cur_mapping", "[", ":", "]", "\n", "best_match_num", "=", "match_num", "\n", "", "", "return", "best_mapping", ",", "best_match_num", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_pool": [[217, 327], ["range", "range", "range", "len", "candidate_mapping.append", "range", "len", "range", "len", "range", "set", "len", "len", "len", "int", "int", "candidate_mapping[].add", "int", "int", "candidate_mapping[].add", "[].lower", "[].lower", "int", "int", "int", "int", "candidate_mapping[].add", "candidate_mapping[].add", "[].lower", "[].lower", "[].lower", "[].lower", "[].lower", "[].lower", "[].lower", "[].lower", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["", "def", "compute_pool", "(", "instance1", ",", "attribute1", ",", "relation1", ",", "\n", "instance2", ",", "attribute2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ")", ":", "\n", "    ", "\"\"\"\n    compute all possible node mapping candidates and their weights (the triple matching number gain resulting from\n    mapping one node in AMR 1 to another node in AMR2)\n\n    Arguments:\n        instance1: instance triples of AMR 1\n        attribute1: attribute triples of AMR 1 (attribute name, node name, attribute value)\n        relation1: relation triples of AMR 1 (relation name, node 1 name, node 2 name)\n        instance2: instance triples of AMR 2\n        attribute2: attribute triples of AMR 2 (attribute name, node name, attribute value)\n        relation2: relation triples of AMR 2 (relation name, node 1 name, node 2 name\n        prefix1: prefix label for AMR 1\n        prefix2: prefix label for AMR 2\n    Returns:\n      candidate_mapping: a list of candidate nodes.\n                       The ith element contains the node indices (in AMR 2) the ith node (in AMR 1) can map to.\n                       (resulting in non-zero triple match)\n      weight_dict: a dictionary which contains the matching triple number for every pair of node mapping. The key\n                   is a node pair. The value is another dictionary. key {-1} is triple match resulting from this node\n                   pair alone (instance triples and attribute triples), and other keys are node pairs that can result\n                   in relation triple match together with the first node pair.\n\n\n    \"\"\"", "\n", "candidate_mapping", "=", "[", "]", "\n", "weight_dict", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "instance1", ")", ")", ":", "\n", "# each candidate mapping is a set of node indices", "\n", "        ", "candidate_mapping", ".", "append", "(", "set", "(", ")", ")", "\n", "for", "j", "in", "range", "(", "0", ",", "len", "(", "instance2", ")", ")", ":", "\n", "# if both triples are instance triples and have the same value", "\n", "            ", "if", "instance1", "[", "i", "]", "[", "0", "]", ".", "lower", "(", ")", "==", "instance2", "[", "j", "]", "[", "0", "]", ".", "lower", "(", ")", "and", "instance1", "[", "i", "]", "[", "2", "]", ".", "lower", "(", ")", "==", "instance2", "[", "j", "]", "[", "2", "]", ".", "lower", "(", ")", ":", "\n", "# get node index by stripping the prefix", "\n", "                ", "node1_index", "=", "int", "(", "instance1", "[", "i", "]", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index", "=", "int", "(", "instance2", "[", "j", "]", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "candidate_mapping", "[", "node1_index", "]", ".", "add", "(", "node2_index", ")", "\n", "node_pair", "=", "(", "node1_index", ",", "node2_index", ")", "\n", "# use -1 as key in weight_dict for instance triples and attribute triples", "\n", "if", "node_pair", "in", "weight_dict", ":", "\n", "                    ", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "weight_dict", "[", "node_pair", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "=", "1", "\n", "", "", "", "", "for", "i", "in", "range", "(", "0", ",", "len", "(", "attribute1", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "0", ",", "len", "(", "attribute2", ")", ")", ":", "\n", "# if both attribute relation triple have the same relation name and value", "\n", "            ", "if", "attribute1", "[", "i", "]", "[", "0", "]", ".", "lower", "(", ")", "==", "attribute2", "[", "j", "]", "[", "0", "]", ".", "lower", "(", ")", "and", "attribute1", "[", "i", "]", "[", "2", "]", ".", "lower", "(", ")", "==", "attribute2", "[", "j", "]", "[", "2", "]", ".", "lower", "(", ")", ":", "\n", "                ", "node1_index", "=", "int", "(", "attribute1", "[", "i", "]", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index", "=", "int", "(", "attribute2", "[", "j", "]", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "candidate_mapping", "[", "node1_index", "]", ".", "add", "(", "node2_index", ")", "\n", "node_pair", "=", "(", "node1_index", ",", "node2_index", ")", "\n", "# use -1 as key in weight_dict for instance triples and attribute triples", "\n", "if", "node_pair", "in", "weight_dict", ":", "\n", "                    ", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "weight_dict", "[", "node_pair", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair", "]", "[", "-", "1", "]", "=", "1", "\n", "", "", "", "", "for", "i", "in", "range", "(", "0", ",", "len", "(", "relation1", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "0", ",", "len", "(", "relation2", ")", ")", ":", "\n", "# if both relation share the same name", "\n", "            ", "if", "relation1", "[", "i", "]", "[", "0", "]", ".", "lower", "(", ")", "==", "relation2", "[", "j", "]", "[", "0", "]", ".", "lower", "(", ")", ":", "\n", "                ", "node1_index_amr1", "=", "int", "(", "relation1", "[", "i", "]", "[", "1", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node1_index_amr2", "=", "int", "(", "relation2", "[", "j", "]", "[", "1", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "node2_index_amr1", "=", "int", "(", "relation1", "[", "i", "]", "[", "2", "]", "[", "len", "(", "prefix1", ")", ":", "]", ")", "\n", "node2_index_amr2", "=", "int", "(", "relation2", "[", "j", "]", "[", "2", "]", "[", "len", "(", "prefix2", ")", ":", "]", ")", "\n", "# add mapping between two nodes", "\n", "candidate_mapping", "[", "node1_index_amr1", "]", ".", "add", "(", "node1_index_amr2", ")", "\n", "candidate_mapping", "[", "node2_index_amr1", "]", ".", "add", "(", "node2_index_amr2", ")", "\n", "node_pair1", "=", "(", "node1_index_amr1", ",", "node1_index_amr2", ")", "\n", "node_pair2", "=", "(", "node2_index_amr1", ",", "node2_index_amr2", ")", "\n", "if", "node_pair2", "!=", "node_pair1", ":", "\n", "# update weight_dict weight. Note that we need to update both entries for future search", "\n", "# i.e weight_dict[node_pair1][node_pair2]", "\n", "#     weight_dict[node_pair2][node_pair1]", "\n", "                    ", "if", "node1_index_amr1", ">", "node2_index_amr1", ":", "\n", "# swap node_pair1 and node_pair2", "\n", "                        ", "node_pair1", "=", "(", "node2_index_amr1", ",", "node2_index_amr2", ")", "\n", "node_pair2", "=", "(", "node1_index_amr1", ",", "node1_index_amr2", ")", "\n", "", "if", "node_pair1", "in", "weight_dict", ":", "\n", "                        ", "if", "node_pair2", "in", "weight_dict", "[", "node_pair1", "]", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "[", "node_pair2", "]", "+=", "1", "\n", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair1", "]", "[", "node_pair2", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                        ", "weight_dict", "[", "node_pair1", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair1", "]", "[", "-", "1", "]", "=", "0", "\n", "weight_dict", "[", "node_pair1", "]", "[", "node_pair2", "]", "=", "1", "\n", "", "if", "node_pair2", "in", "weight_dict", ":", "\n", "                        ", "if", "node_pair1", "in", "weight_dict", "[", "node_pair2", "]", ":", "\n", "                            ", "weight_dict", "[", "node_pair2", "]", "[", "node_pair1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                            ", "weight_dict", "[", "node_pair2", "]", "[", "node_pair1", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                        ", "weight_dict", "[", "node_pair2", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair2", "]", "[", "-", "1", "]", "=", "0", "\n", "weight_dict", "[", "node_pair2", "]", "[", "node_pair1", "]", "=", "1", "\n", "", "", "else", ":", "\n", "# two node pairs are the same. So we only update weight_dict once.", "\n", "# this generally should not happen.", "\n", "                    ", "if", "node_pair1", "in", "weight_dict", ":", "\n", "                        ", "weight_dict", "[", "node_pair1", "]", "[", "-", "1", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "weight_dict", "[", "node_pair1", "]", "=", "{", "}", "\n", "weight_dict", "[", "node_pair1", "]", "[", "-", "1", "]", "=", "1", "\n", "", "", "", "", "", "return", "candidate_mapping", ",", "weight_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.smart_init_mapping": [[329, 377], ["random.seed", "enumerate", "list", "len", "result.append", "len", "no_word_match.append", "result.append", "len", "random.randint", "list.pop", "result.append", "len"], "function", ["None"], ["", "def", "smart_init_mapping", "(", "candidate_mapping", ",", "instance1", ",", "instance2", ")", ":", "\n", "    ", "\"\"\"\n    Initialize mapping based on the concept mapping (smart initialization)\n    Arguments:\n        candidate_mapping: candidate node match list\n        instance1: instance triples of AMR 1\n        instance2: instance triples of AMR 2\n    Returns:\n        initialized node mapping between two AMRs\n\n    \"\"\"", "\n", "random", ".", "seed", "(", ")", "\n", "matched_dict", "=", "{", "}", "\n", "result", "=", "[", "]", "\n", "# list to store node indices that have no concept match", "\n", "no_word_match", "=", "[", "]", "\n", "for", "i", ",", "candidates", "in", "enumerate", "(", "candidate_mapping", ")", ":", "\n", "        ", "if", "len", "(", "candidates", ")", "==", "0", ":", "\n", "# no possible mapping", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "continue", "\n", "# node value in instance triples of AMR 1", "\n", "", "value1", "=", "instance1", "[", "i", "]", "[", "2", "]", "\n", "for", "node_index", "in", "candidates", ":", "\n", "            ", "value2", "=", "instance2", "[", "node_index", "]", "[", "2", "]", "\n", "# find the first instance triple match in the candidates", "\n", "# instance triple match is having the same concept value", "\n", "if", "value1", "==", "value2", ":", "\n", "                ", "if", "node_index", "not", "in", "matched_dict", ":", "\n", "                    ", "result", ".", "append", "(", "node_index", ")", "\n", "matched_dict", "[", "node_index", "]", "=", "1", "\n", "break", "\n", "", "", "", "if", "len", "(", "result", ")", "==", "i", ":", "\n", "            ", "no_word_match", ".", "append", "(", "i", ")", "\n", "result", ".", "append", "(", "-", "1", ")", "\n", "# if no concept match, generate a random mapping", "\n", "", "", "for", "i", "in", "no_word_match", ":", "\n", "        ", "candidates", "=", "list", "(", "candidate_mapping", "[", "i", "]", ")", "\n", "while", "len", "(", "candidates", ")", ">", "0", ":", "\n", "# get a random node index from candidates", "\n", "            ", "rid", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "candidates", ")", "-", "1", ")", "\n", "if", "candidates", "[", "rid", "]", "in", "matched_dict", ":", "\n", "                ", "candidates", ".", "pop", "(", "rid", ")", "\n", "", "else", ":", "\n", "                ", "matched_dict", "[", "candidates", "[", "rid", "]", "]", "=", "1", "\n", "result", "[", "i", "]", "=", "candidates", "[", "rid", "]", "\n", "break", "\n", "", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.random_init_mapping": [[379, 413], ["random.seed", "list", "len", "result.append", "len", "random.randint", "result.append", "list.pop", "result.append", "len"], "function", ["None"], ["", "def", "random_init_mapping", "(", "candidate_mapping", ")", ":", "\n", "    ", "\"\"\"\n    Generate a random node mapping.\n    Args:\n        candidate_mapping: candidate_mapping: candidate node match list\n    Returns:\n        randomly-generated node mapping between two AMRs\n\n    \"\"\"", "\n", "# if needed, a fixed seed could be passed here to generate same random (to help debugging)", "\n", "random", ".", "seed", "(", ")", "\n", "matched_dict", "=", "{", "}", "\n", "result", "=", "[", "]", "\n", "for", "c", "in", "candidate_mapping", ":", "\n", "        ", "candidates", "=", "list", "(", "c", ")", "\n", "if", "len", "(", "candidates", ")", "==", "0", ":", "\n", "# -1 indicates no possible mapping", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "continue", "\n", "", "found", "=", "False", "\n", "while", "len", "(", "candidates", ")", ">", "0", ":", "\n", "# randomly generate an index in [0, length of candidates)", "\n", "            ", "rid", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "candidates", ")", "-", "1", ")", "\n", "# check if it has already been matched", "\n", "if", "candidates", "[", "rid", "]", "in", "matched_dict", ":", "\n", "                ", "candidates", ".", "pop", "(", "rid", ")", "\n", "", "else", ":", "\n", "                ", "matched_dict", "[", "candidates", "[", "rid", "]", "]", "=", "1", "\n", "result", ".", "append", "(", "candidates", "[", "rid", "]", ")", "\n", "found", "=", "True", "\n", "break", "\n", "", "", "if", "not", "found", ":", "\n", "            ", "result", ".", "append", "(", "-", "1", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match": [[415, 465], ["enumerate", "tuple", "tuple", "tuple", "tuple"], "function", ["None"], ["", "def", "compute_match", "(", "mapping", ",", "weight_dict", ")", ":", "\n", "    ", "\"\"\"\n    Given a node mapping, compute match number based on weight_dict.\n    Args:\n    mappings: a list of node index in AMR 2. The ith element (value j) means node i in AMR 1 maps to node j in AMR 2.\n    Returns:\n    matching triple number\n    Complexity: O(m*n) , m is the node number of AMR 1, n is the node number of AMR 2\n\n    \"\"\"", "\n", "# If this mapping has been investigated before, retrieve the value instead of re-computing.", "\n", "if", "verbose", ":", "\n", "        ", "print", ">>", "DEBUG_LOG", ",", "\"Computing match for mapping\"", "\n", "print", ">>", "DEBUG_LOG", ",", "mapping", "\n", "", "if", "tuple", "(", "mapping", ")", "in", "match_triple_dict", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", ">>", "DEBUG_LOG", ",", "\"saved value\"", ",", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", "\n", "", "return", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", "\n", "", "match_num", "=", "0", "\n", "# i is node index in AMR 1, m is node index in AMR 2", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "mapping", ")", ":", "\n", "        ", "if", "m", "==", "-", "1", ":", "\n", "# no node maps to this node", "\n", "            ", "continue", "\n", "# node i in AMR 1 maps to node m in AMR 2", "\n", "", "current_node_pair", "=", "(", "i", ",", "m", ")", "\n", "if", "current_node_pair", "not", "in", "weight_dict", ":", "\n", "            ", "continue", "\n", "", "if", "verbose", ":", "\n", "            ", "print", ">>", "DEBUG_LOG", ",", "\"node_pair\"", ",", "current_node_pair", "\n", "", "for", "key", "in", "weight_dict", "[", "current_node_pair", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "# matching triple resulting from instance/attribute triples", "\n", "                ", "match_num", "+=", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "if", "verbose", ":", "\n", "                    ", "print", ">>", "DEBUG_LOG", ",", "\"instance/attribute match\"", ",", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "# only consider node index larger than i to avoid duplicates", "\n", "# as we store both weight_dict[node_pair1][node_pair2] and", "\n", "#     weight_dict[node_pair2][node_pair1] for a relation", "\n", "", "", "elif", "key", "[", "0", "]", "<", "i", ":", "\n", "                ", "continue", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "match_num", "+=", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "if", "verbose", ":", "\n", "                    ", "print", ">>", "DEBUG_LOG", ",", "\"relation match with\"", ",", "key", ",", "weight_dict", "[", "current_node_pair", "]", "[", "key", "]", "\n", "", "", "", "", "if", "verbose", ":", "\n", "        ", "print", ">>", "DEBUG_LOG", ",", "\"match computing complete, result:\"", ",", "match_num", "\n", "# update match_triple_dict", "\n", "", "match_triple_dict", "[", "tuple", "(", "mapping", ")", "]", "=", "match_num", "\n", "return", "match_num", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.move_gain": [[467, 511], ["tuple", "tuple", "tuple"], "function", ["None"], ["", "def", "move_gain", "(", "mapping", ",", "node_id", ",", "old_id", ",", "new_id", ",", "weight_dict", ",", "match_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the triple match number gain from the move operation\n    Arguments:\n        mapping: current node mapping\n        node_id: remapped node in AMR 1\n        old_id: original node id in AMR 2 to which node_id is mapped\n        new_id: new node in to which node_id is mapped\n        weight_dict: weight dictionary\n        match_num: the original triple matching number\n    Returns:\n        the triple match gain number (might be negative)\n\n    \"\"\"", "\n", "# new node mapping after moving", "\n", "new_mapping", "=", "(", "node_id", ",", "new_id", ")", "\n", "# node mapping before moving", "\n", "old_mapping", "=", "(", "node_id", ",", "old_id", ")", "\n", "# new nodes mapping list (all node pairs)", "\n", "new_mapping_list", "=", "mapping", "[", ":", "]", "\n", "new_mapping_list", "[", "node_id", "]", "=", "new_id", "\n", "# if this mapping is already been investigated, use saved one to avoid duplicate computing", "\n", "if", "tuple", "(", "new_mapping_list", ")", "in", "match_triple_dict", ":", "\n", "        ", "return", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "-", "match_num", "\n", "", "gain", "=", "0", "\n", "# add the triple match incurred by new_mapping to gain", "\n", "if", "new_mapping", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "# instance/attribute triple match", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping", "]", "[", "-", "1", "]", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "# relation gain incurred by new_mapping and another node pair in new_mapping_list", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping", "]", "[", "key", "]", "\n", "# deduct the triple match incurred by old_mapping from gain", "\n", "", "", "", "if", "old_mapping", "in", "weight_dict", ":", "\n", "        ", "for", "k", "in", "weight_dict", "[", "old_mapping", "]", ":", "\n", "            ", "if", "k", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping", "]", "[", "-", "1", "]", "\n", "", "elif", "mapping", "[", "k", "[", "0", "]", "]", "==", "k", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping", "]", "[", "k", "]", "\n", "# update match number dictionary", "\n", "", "", "", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "=", "match_num", "+", "gain", "\n", "return", "gain", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.swap_gain": [[513, 577], ["tuple", "tuple", "tuple"], "function", ["None"], ["", "def", "swap_gain", "(", "mapping", ",", "node_id1", ",", "mapping_id1", ",", "node_id2", ",", "mapping_id2", ",", "weight_dict", ",", "match_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the triple match number gain from the swapping\n    Arguments:\n    mapping: current node mapping list\n    node_id1: node 1 index in AMR 1\n    mapping_id1: the node index in AMR 2 node 1 maps to (in the current mapping)\n    node_id2: node 2 index in AMR 1\n    mapping_id2: the node index in AMR 2 node 2 maps to (in the current mapping)\n    weight_dict: weight dictionary\n    match_num: the original matching triple number\n    Returns:\n    the gain number (might be negative)\n\n    \"\"\"", "\n", "new_mapping_list", "=", "mapping", "[", ":", "]", "\n", "# Before swapping, node_id1 maps to mapping_id1, and node_id2 maps to mapping_id2", "\n", "# After swapping, node_id1 maps to mapping_id2 and node_id2 maps to mapping_id1", "\n", "new_mapping_list", "[", "node_id1", "]", "=", "mapping_id2", "\n", "new_mapping_list", "[", "node_id2", "]", "=", "mapping_id1", "\n", "if", "tuple", "(", "new_mapping_list", ")", "in", "match_triple_dict", ":", "\n", "        ", "return", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "-", "match_num", "\n", "", "gain", "=", "0", "\n", "new_mapping1", "=", "(", "node_id1", ",", "mapping_id2", ")", "\n", "new_mapping2", "=", "(", "node_id2", ",", "mapping_id1", ")", "\n", "old_mapping1", "=", "(", "node_id1", ",", "mapping_id1", ")", "\n", "old_mapping2", "=", "(", "node_id2", ",", "mapping_id2", ")", "\n", "if", "node_id1", ">", "node_id2", ":", "\n", "        ", "new_mapping2", "=", "(", "node_id1", ",", "mapping_id2", ")", "\n", "new_mapping1", "=", "(", "node_id2", ",", "mapping_id1", ")", "\n", "old_mapping1", "=", "(", "node_id2", ",", "mapping_id2", ")", "\n", "old_mapping2", "=", "(", "node_id1", ",", "mapping_id1", ")", "\n", "", "if", "new_mapping1", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping1", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping1", "]", "[", "-", "1", "]", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping1", "]", "[", "key", "]", "\n", "", "", "", "if", "new_mapping2", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "new_mapping2", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping2", "]", "[", "-", "1", "]", "\n", "# to avoid duplicate", "\n", "", "elif", "key", "[", "0", "]", "==", "node_id1", ":", "\n", "                ", "continue", "\n", "", "elif", "new_mapping_list", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "+=", "weight_dict", "[", "new_mapping2", "]", "[", "key", "]", "\n", "", "", "", "if", "old_mapping1", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "old_mapping1", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping1", "]", "[", "-", "1", "]", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping1", "]", "[", "key", "]", "\n", "", "", "", "if", "old_mapping2", "in", "weight_dict", ":", "\n", "        ", "for", "key", "in", "weight_dict", "[", "old_mapping2", "]", ":", "\n", "            ", "if", "key", "==", "-", "1", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping2", "]", "[", "-", "1", "]", "\n", "# to avoid duplicate", "\n", "", "elif", "key", "[", "0", "]", "==", "node_id1", ":", "\n", "                ", "continue", "\n", "", "elif", "mapping", "[", "key", "[", "0", "]", "]", "==", "key", "[", "1", "]", ":", "\n", "                ", "gain", "-=", "weight_dict", "[", "old_mapping2", "]", "[", "key", "]", "\n", "", "", "", "match_triple_dict", "[", "tuple", "(", "new_mapping_list", ")", "]", "=", "match_num", "+", "gain", "\n", "return", "gain", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_gain": [[579, 677], ["set", "enumerate", "enumerate", "range", "range", "set.remove", "len", "smatch_fromsubgraphs.swap_gain", "smatch_fromsubgraphs.move_gain", "smatch_fromsubgraphs.compute_match", "smatch_fromsubgraphs.compute_match"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.swap_gain", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.move_gain", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_match"], ["", "def", "get_best_gain", "(", "mapping", ",", "candidate_mappings", ",", "weight_dict", ",", "instance_len", ",", "cur_match_num", ")", ":", "\n", "    ", "\"\"\"\n    Hill-climbing method to return the best gain swap/move can get\n    Arguments:\n    mapping: current node mapping\n    candidate_mappings: the candidates mapping list\n    weight_dict: the weight dictionary\n    instance_len: the number of the nodes in AMR 2\n    cur_match_num: current triple match number\n    Returns:\n    the best gain we can get via swap/move operation\n\n    \"\"\"", "\n", "largest_gain", "=", "0", "\n", "# True: using swap; False: using move", "\n", "use_swap", "=", "True", "\n", "# the node to be moved/swapped", "\n", "node1", "=", "None", "\n", "# store the other node affected. In swap, this other node is the node swapping with node1. In move, this other", "\n", "# node is the node node1 will move to.", "\n", "node2", "=", "None", "\n", "# unmatched nodes in AMR 2", "\n", "unmatched", "=", "set", "(", "range", "(", "0", ",", "instance_len", ")", ")", "\n", "# exclude nodes in current mapping", "\n", "# get unmatched nodes", "\n", "for", "nid", "in", "mapping", ":", "\n", "        ", "if", "nid", "in", "unmatched", ":", "\n", "            ", "unmatched", ".", "remove", "(", "nid", ")", "\n", "", "", "for", "i", ",", "nid", "in", "enumerate", "(", "mapping", ")", ":", "\n", "# current node i in AMR 1 maps to node nid in AMR 2", "\n", "        ", "for", "nm", "in", "unmatched", ":", "\n", "            ", "if", "nm", "in", "candidate_mappings", "[", "i", "]", ":", "\n", "# remap i to another unmatched node (move)", "\n", "# (i, m) -> (i, nm)", "\n", "                ", "if", "verbose", ":", "\n", "                    ", "print", ">>", "DEBUG_LOG", ",", "\"Remap node\"", ",", "i", ",", "\"from \"", ",", "nid", ",", "\"to\"", ",", "nm", "\n", "", "mv_gain", "=", "move_gain", "(", "mapping", ",", "i", ",", "nid", ",", "nm", ",", "weight_dict", ",", "cur_match_num", ")", "\n", "if", "verbose", ":", "\n", "                    ", "print", ">>", "DEBUG_LOG", ",", "\"Move gain:\"", ",", "mv_gain", "\n", "new_mapping", "=", "mapping", "[", ":", "]", "\n", "new_mapping", "[", "i", "]", "=", "nm", "\n", "new_match_num", "=", "compute_match", "(", "new_mapping", ",", "weight_dict", ")", "\n", "if", "new_match_num", "!=", "cur_match_num", "+", "mv_gain", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "mapping", ",", "new_mapping", "\n", "print", ">>", "ERROR_LOG", ",", "\"Inconsistency in computing: move gain\"", ",", "cur_match_num", ",", "mv_gain", ",", "new_match_num", "\n", "", "", "if", "mv_gain", ">", "largest_gain", ":", "\n", "                    ", "largest_gain", "=", "mv_gain", "\n", "node1", "=", "i", "\n", "node2", "=", "nm", "\n", "use_swap", "=", "False", "\n", "# compute swap gain", "\n", "", "", "", "", "for", "i", ",", "m", "in", "enumerate", "(", "mapping", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "mapping", ")", ")", ":", "\n", "            ", "m2", "=", "mapping", "[", "j", "]", "\n", "# swap operation (i, m) (j, m2) -> (i, m2) (j, m)", "\n", "# j starts from i+1, to avoid duplicate swap", "\n", "if", "verbose", ":", "\n", "                ", "print", ">>", "DEBUG_LOG", ",", "\"Swap node\"", ",", "i", ",", "\"and\"", ",", "j", "\n", "print", ">>", "DEBUG_LOG", ",", "\"Before swapping:\"", ",", "i", ",", "\"-\"", ",", "m", ",", "\",\"", ",", "j", ",", "\"-\"", ",", "m2", "\n", "print", ">>", "DEBUG_LOG", ",", "mapping", "\n", "print", ">>", "DEBUG_LOG", ",", "\"After swapping:\"", ",", "i", ",", "\"-\"", ",", "m2", ",", "\",\"", ",", "j", ",", "\"-\"", ",", "m", "\n", "", "sw_gain", "=", "swap_gain", "(", "mapping", ",", "i", ",", "m", ",", "j", ",", "m2", ",", "weight_dict", ",", "cur_match_num", ")", "\n", "if", "verbose", ":", "\n", "                ", "print", ">>", "DEBUG_LOG", ",", "\"Swap gain:\"", ",", "sw_gain", "\n", "new_mapping", "=", "mapping", "[", ":", "]", "\n", "new_mapping", "[", "i", "]", "=", "m2", "\n", "new_mapping", "[", "j", "]", "=", "m", "\n", "print", ">>", "DEBUG_LOG", ",", "new_mapping", "\n", "new_match_num", "=", "compute_match", "(", "new_mapping", ",", "weight_dict", ")", "\n", "if", "new_match_num", "!=", "cur_match_num", "+", "sw_gain", ":", "\n", "                    ", "print", ">>", "ERROR_LOG", ",", "match", ",", "new_match", "\n", "print", ">>", "ERROR_LOG", ",", "\"Inconsistency in computing: swap gain\"", ",", "cur_match_num", ",", "sw_gain", ",", "new_match_num", "\n", "", "", "if", "sw_gain", ">", "largest_gain", ":", "\n", "                ", "largest_gain", "=", "sw_gain", "\n", "node1", "=", "i", "\n", "node2", "=", "j", "\n", "use_swap", "=", "True", "\n", "# generate a new mapping based on swap/move", "\n", "", "", "", "cur_mapping", "=", "mapping", "[", ":", "]", "\n", "if", "node1", "is", "not", "None", ":", "\n", "        ", "if", "use_swap", ":", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", ">>", "DEBUG_LOG", ",", "\"Use swap gain\"", "\n", "", "temp", "=", "cur_mapping", "[", "node1", "]", "\n", "cur_mapping", "[", "node1", "]", "=", "cur_mapping", "[", "node2", "]", "\n", "cur_mapping", "[", "node2", "]", "=", "temp", "\n", "", "else", ":", "\n", "            ", "if", "verbose", ":", "\n", "                ", "print", ">>", "DEBUG_LOG", ",", "\"Use move gain\"", "\n", "", "cur_mapping", "[", "node1", "]", "=", "node2", "\n", "", "", "else", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", ">>", "DEBUG_LOG", ",", "\"no move/swap gain found\"", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", ">>", "DEBUG_LOG", ",", "\"Original mapping\"", ",", "mapping", "\n", "print", ">>", "DEBUG_LOG", ",", "\"Current mapping\"", ",", "cur_mapping", "\n", "", "return", "largest_gain", ",", "cur_mapping", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.print_alignment": [[679, 696], ["enumerate", "result.append", "result.append"], "function", ["None"], ["", "def", "print_alignment", "(", "mapping", ",", "instance1", ",", "instance2", ")", ":", "\n", "    ", "\"\"\"\n    print the alignment based on a node mapping\n    Args:\n        match: current node mapping list\n        instance1: nodes of AMR 1\n        instance2: nodes of AMR 2\n\n    \"\"\"", "\n", "result", "=", "[", "]", "\n", "for", "i", ",", "m", "in", "enumerate", "(", "mapping", ")", ":", "\n", "        ", "if", "m", "==", "-", "1", ":", "\n", "            ", "result", ".", "append", "(", "instance1", "[", "i", "]", "[", "1", "]", "+", "\"(\"", "+", "instance1", "[", "i", "]", "[", "2", "]", "+", "\")\"", "+", "\"-Null\"", ")", "\n", "", "else", ":", "\n", "            ", "result", ".", "append", "(", "instance1", "[", "i", "]", "[", "1", "]", "+", "\"(\"", "+", "instance1", "[", "i", "]", "[", "2", "]", "+", "\")\"", "+", "\"-\"", "\n", "+", "instance2", "[", "m", "]", "[", "1", "]", "+", "\"(\"", "+", "instance2", "[", "m", "]", "[", "2", "]", "+", "\")\"", ")", "\n", "", "", "return", "\" \"", ".", "join", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f": [[698, 727], ["None"], "function", ["None"], ["", "def", "compute_f", "(", "match_num", ",", "test_num", ",", "gold_num", ")", ":", "\n", "    ", "\"\"\"\n    Compute the f-score based on the matching triple number,\n                                 triple number of AMR set 1,\n                                 triple number of AMR set 2\n    Args:\n        match_num: matching triple number\n        test_num:  triple number of AMR 1 (test file)\n        gold_num:  triple number of AMR 2 (gold file)\n    Returns:\n        precision: match_num/test_num\n        recall: match_num/gold_num\n        f_score: 2*precision*recall/(precision+recall)\n    \"\"\"", "\n", "if", "test_num", "==", "0", "or", "gold_num", "==", "0", ":", "\n", "        ", "return", "0.00", ",", "0.00", ",", "0.00", "\n", "#print match_num, test_num", "\n", "#print match_num, gold_num", "\n", "", "precision", "=", "(", "0.000", "+", "match_num", ")", "/", "(", "test_num", "+", "0.000", ")", "\n", "recall", "=", "(", "0.000", "+", "match_num", ")", "/", "(", "gold_num", "+", "0.000", ")", "\n", "if", "(", "precision", "+", "recall", ")", "!=", "0", ":", "\n", "        ", "f_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", ">>", "DEBUG_LOG", ",", "\"F-score:\"", ",", "f_score", "\n", "", "return", "precision", ",", "recall", ",", "f_score", "\n", "", "else", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", ">>", "DEBUG_LOG", ",", "\"F-score:\"", ",", "\"0.0\"", "\n", "", "return", "precision", ",", "recall", ",", "0.00", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.run": [[729, 849], ["zip", "smatch_fromsubgraphs.parse_relations", "smatch_fromsubgraphs.parse_relations", "parse_relations.rename_node", "parse_relations.rename_node", "parse_relations.get_triples", "parse_relations.get_triples", "smatch_fromsubgraphs.get_best_match", "match_triple_dict.clear", "smatch_fromsubgraphs.compute_f", "len", "len", "smatch_fromsubgraphs.compute_f", "print", "len", "len", "len", "len", "len", "len", "smatch_fromsubgraphs.print_alignment", "len", "len", "len", "len", "print", "print", "str", "str"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.parse_relations", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.parse_relations", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_match", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.print_alignment", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "", "def", "run", "(", "list1", ",", "list2", ",", "pr_flag", ")", ":", "\n", "    ", "\"\"\"\n    Main function of smatch score calculation\n\n    \"\"\"", "\n", "global", "verbose", "\n", "global", "iteration_num", "\n", "global", "single_score", "\n", "#global pr_flag", "\n", "global", "match_triple_dict", "\n", "# set the iteration number", "\n", "# total iteration number = restart number + 1", "\n", "#iteration_num = arguments.r + 1", "\n", "iteration_num", "=", "5", "\n", "#if arguments.ms:", "\n", "#    single_score = False", "\n", "#if arguments.v:", "\n", "#    verbose = True", "\n", "#if arguments.pr:", "\n", "#    pr_flag = True", "\n", "# matching triple number", "\n", "total_match_num", "=", "0", "\n", "# triple number in test file", "\n", "total_test_num", "=", "0", "\n", "# triple number in gold file", "\n", "total_gold_num", "=", "0", "\n", "# sentence number", "\n", "sent_num", "=", "1", "\n", "# Read amr pairs from two files", "\n", "for", "l1", ",", "l2", "in", "zip", "(", "list1", ",", "list2", ")", ":", "\n", "        ", "lst_amr1", ",", "dic_amr1", "=", "l1", "\n", "lst_amr2", ",", "dic_amr2", "=", "l2", "\n", "amr1", "=", "parse_relations", "(", "lst_amr1", ",", "dic_amr1", ")", "\n", "amr2", "=", "parse_relations", "(", "lst_amr2", ",", "dic_amr2", ")", "\n", "#cur_amr1 = get_amr_line(args.f[0])", "\n", "#cur_amr2 = get_amr_line(args.f[1])", "\n", "#if cur_amr1 == \"\" and cur_amr2 == \"\":", "\n", "#    break", "\n", "#if cur_amr1 == \"\":", "\n", "#    print >> ERROR_LOG, \"Error: File 1 has less AMRs than file 2\"", "\n", "#    print >> ERROR_LOG, \"Ignoring remaining AMRs\"", "\n", "#    break", "\n", "#if cur_amr2 == \"\":", "\n", "#    print >> ERROR_LOG, \"Error: File 2 has less AMRs than file 1\"", "\n", "#    print >> ERROR_LOG, \"Ignoring remaining AMRs\"", "\n", "#    break", "\n", "#amr1 = amr.AMR.parse_AMR_line(cur_amr1)", "\n", "#amr2 = amr.AMR.parse_AMR_line(cur_amr2)", "\n", "prefix1", "=", "\"a\"", "\n", "prefix2", "=", "\"b\"", "\n", "# Rename node to \"a1\", \"a2\", .etc", "\n", "amr1", ".", "rename_node", "(", "prefix1", ")", "\n", "# Renaming node to \"b1\", \"b2\", .etc", "\n", "amr2", ".", "rename_node", "(", "prefix2", ")", "\n", "(", "instance1", ",", "attributes1", ",", "relation1", ")", "=", "amr1", ".", "get_triples", "(", ")", "\n", "(", "instance2", ",", "attributes2", ",", "relation2", ")", "=", "amr2", ".", "get_triples", "(", ")", "\n", "if", "verbose", ":", "\n", "# print parse results of two AMRs", "\n", "            ", "print", ">>", "DEBUG_LOG", ",", "\"AMR pair\"", ",", "sent_num", "\n", "print", ">>", "DEBUG_LOG", ",", "\"============================================\"", "\n", "#print >> DEBUG_LOG, \"AMR 1 (one-line):\", cur_amr1", "\n", "#print >> DEBUG_LOG, \"AMR 2 (one-line):\", cur_amr2", "\n", "print", ">>", "DEBUG_LOG", ",", "\"Instance triples of AMR 1:\"", ",", "len", "(", "instance1", ")", "\n", "print", ">>", "DEBUG_LOG", ",", "instance1", "\n", "print", ">>", "DEBUG_LOG", ",", "\"Attribute triples of AMR 1:\"", ",", "len", "(", "attributes1", ")", "\n", "print", ">>", "DEBUG_LOG", ",", "attributes1", "\n", "print", ">>", "DEBUG_LOG", ",", "\"Relation triples of AMR 1:\"", ",", "len", "(", "relation1", ")", "\n", "print", ">>", "DEBUG_LOG", ",", "relation1", "\n", "print", ">>", "DEBUG_LOG", ",", "\"Instance triples of AMR 2:\"", ",", "len", "(", "instance2", ")", "\n", "print", ">>", "DEBUG_LOG", ",", "instance2", "\n", "print", ">>", "DEBUG_LOG", ",", "\"Attribute triples of AMR 2:\"", ",", "len", "(", "attributes2", ")", "\n", "print", ">>", "DEBUG_LOG", ",", "attributes2", "\n", "print", ">>", "DEBUG_LOG", ",", "\"Relation triples of AMR 2:\"", ",", "len", "(", "relation2", ")", "\n", "print", ">>", "DEBUG_LOG", ",", "relation2", "\n", "", "relation1", "=", "[", "r", "for", "r", "in", "relation1", "if", "str", "(", "r", "[", "0", "]", ")", "!=", "'root'", "]", "\n", "relation2", "=", "[", "r", "for", "r", "in", "relation2", "if", "str", "(", "r", "[", "0", "]", ")", "!=", "'root'", "]", "\n", "#         attributes1 = [r for r in attributes1 if str(r[0]) != 'TOP']", "\n", "#         attributes2 = [r for r in attributes2 if str(r[0]) != 'TOP']", "\n", "(", "best_mapping", ",", "best_match_num", ")", "=", "get_best_match", "(", "instance1", ",", "attributes1", ",", "relation1", ",", "\n", "instance2", ",", "attributes2", ",", "relation2", ",", "\n", "prefix1", ",", "prefix2", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", ">>", "DEBUG_LOG", ",", "\"best match number\"", ",", "best_match_num", "\n", "print", ">>", "DEBUG_LOG", ",", "\"best node mapping\"", ",", "best_mapping", "\n", "print", ">>", "DEBUG_LOG", ",", "\"Best node mapping alignment:\"", ",", "print_alignment", "(", "best_mapping", ",", "instance1", ",", "instance2", ")", "\n", "\n", "", "test_triple_num", "=", "len", "(", "instance1", ")", "+", "len", "(", "attributes1", ")", "+", "len", "(", "relation1", ")", "\n", "gold_triple_num", "=", "len", "(", "instance2", ")", "+", "len", "(", "attributes2", ")", "+", "len", "(", "relation2", ")", "\n", "#if arguments.a: print(print_alignment(best_mapping, instance1, instance2))", "\n", "if", "not", "single_score", ":", "\n", "# if each AMR pair should have a score, compute and output it here", "\n", "            ", "(", "precision", ",", "recall", ",", "best_f_score", ")", "=", "compute_f", "(", "best_match_num", ",", "\n", "test_triple_num", ",", "\n", "gold_triple_num", ")", "\n", "#print \"Sentence\", sent_num", "\n", "if", "pr_flag", ":", "\n", "                ", "print", "(", "\"Precision: %.3f\"", "%", "precision", ")", "\n", "print", "(", "\"Recall: %.3f\"", "%", "recall", ")", "\n", "#            print \"Smatch score: %.3f\" % best_f_score", "\n", "", "print", "(", "\"%.3f\"", "%", "best_f_score", ")", "\n", "", "total_match_num", "+=", "best_match_num", "\n", "total_test_num", "+=", "test_triple_num", "\n", "total_gold_num", "+=", "gold_triple_num", "\n", "# clear the matching triple dictionary for the next AMR pair", "\n", "match_triple_dict", ".", "clear", "(", ")", "\n", "sent_num", "+=", "1", "\n", "", "if", "verbose", ":", "\n", "        ", "print", ">>", "DEBUG_LOG", ",", "\"Total match number, total triple number in AMR 1, and total triple number in AMR 2:\"", "\n", "print", ">>", "DEBUG_LOG", ",", "total_match_num", ",", "total_test_num", ",", "total_gold_num", "\n", "print", ">>", "DEBUG_LOG", ",", "\"---------------------------------------------------------------------------------\"", "\n", "# output document-level smatch score (a single f-score for all AMR pairs in two files)", "\n", "", "if", "single_score", ":", "\n", "        ", "(", "precision", ",", "recall", ",", "best_f_score", ")", "=", "compute_f", "(", "total_match_num", ",", "total_test_num", ",", "total_gold_num", ")", "\n", "#    if pr_flag:", "\n", "#        print (\"Precision: %.3f\" % precision)", "\n", "#        print (\"Recall: %.3f\" % recall)", "\n", "#print (\"Document F-score: %.3f, %.4f\" % (best_f_score, best_f_score))", "\n", "", "if", "pr_flag", ":", "\n", "        ", "return", "'%.3f'", "%", "(", "precision", ")", ",", "'%.3f'", "%", "(", "recall", ")", ",", "'%.3f'", "%", "(", "best_f_score", ")", "\n", "", "return", "'%.3f'", "%", "(", "best_f_score", ")", "\n", "#args.f[0].close()", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.main": [[852, 854], ["smatch_fromsubgraphs.run"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run"], ["", "def", "main", "(", "list1", ",", "list2", ",", "pr_flag", "=", "False", ")", ":", "\n", "    ", "return", "run", "(", "list1", ",", "list2", ",", "pr_flag", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.amr.AMR.__init__": [[37, 69], ["len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "node_list", "=", "None", ",", "node_value_list", "=", "None", ",", "relation_list", "=", "None", ",", "attribute_list", "=", "None", ",", "reent", "=", "None", ",", "allrelations", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        node_list: names of nodes in AMR graph, e.g. \"a11\", \"n\"\n        node_value_list: values of nodes in AMR graph, e.g. \"group\" for a node named \"g\"\n        relation_list: list of relations between two nodes\n        attribute_list: list of attributes (links between one node and one constant value)\n\n        \"\"\"", "\n", "# initialize AMR graph nodes using list of nodes name", "\n", "# root, by default, is the first in var_list", "\n", "attribute_list2", "=", "[", "]", "\n", "for", "dct", "in", "attribute_list", ":", "\n", "            ", "dct2", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "item", "in", "dct", ":", "\n", "                ", "if", "len", "(", "dct", "[", "item", "]", ")", ">", "1", "and", "dct", "[", "item", "]", ".", "endswith", "(", "\"_\"", ")", ":", "\n", "                    ", "dct", "[", "item", "]", "=", "'\"'", "+", "dct", "[", "item", "]", "[", "0", ":", "-", "1", "]", "+", "'\"'", "\n", "", "dct2", "[", "item", "]", "=", "dct", "[", "item", "]", "\n", "", "attribute_list2", ".", "append", "(", "dct2", ")", "\n", "", "reent2", "=", "[", "]", "\n", "for", "r", "in", "reent", ":", "\n", "            ", "if", "len", "(", "r", "[", "2", "]", ")", ">", "1", "and", "r", "[", "2", "]", ".", "endswith", "(", "\"_\"", ")", ":", "\n", "                ", "reent2", ".", "append", "(", "(", "r", "[", "0", "]", ",", "r", "[", "1", "]", ",", "'\"'", "+", "r", "[", "2", "]", "[", "0", ":", "-", "1", "]", "+", "'\"'", ")", ")", "\n", "", "else", ":", "\n", "                ", "reent2", ".", "append", "(", "r", ")", "\n", "", "", "allrelations2", "=", "[", "]", "\n", "for", "r", "in", "allrelations", ":", "\n", "            ", "if", "len", "(", "r", "[", "2", "]", ")", ">", "1", "and", "r", "[", "2", "]", ".", "endswith", "(", "\"_\"", ")", ":", "\n", "                ", "allrelations2", ".", "append", "(", "(", "r", "[", "0", "]", ",", "r", "[", "1", "]", ",", "'\"'", "+", "r", "[", "2", "]", "[", "0", ":", "-", "1", "]", "+", "'\"'", ")", ")", "\n", "", "else", ":", "\n", "                ", "allrelations2", ".", "append", "(", "r", ")", "\n", "", "", "if", "node_list", "is", "None", ":", "\n", "            ", "self", ".", "nodes", "=", "[", "]", "\n", "self", ".", "root", "=", "None", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.amr.AMR.rename_node": [[70, 88], ["range", "enumerate", "enumerate", "len", "d.items", "str"], "methods", ["None"], ["", "else", ":", "\n", "            ", "self", ".", "nodes", "=", "node_list", "[", ":", "]", "\n", "if", "len", "(", "node_list", ")", "!=", "0", ":", "\n", "                ", "self", ".", "root", "=", "node_list", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "root", "=", "None", "\n", "", "", "if", "node_value_list", "is", "None", ":", "\n", "            ", "self", ".", "node_values", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "node_values", "=", "node_value_list", "[", ":", "]", "\n", "", "if", "relation_list", "is", "None", ":", "\n", "            ", "self", ".", "relations", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "relations", "=", "relation_list", "[", ":", "]", "\n", "", "if", "attribute_list2", "is", "None", ":", "\n", "            ", "self", ".", "attributes", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "attributes", "=", "attribute_list2", "[", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.amr.AMR.get_triples": [[89, 111], ["range", "len", "instance_triple.append", "amr.AMR.relations[].items", "amr.AMR.attributes[].items", "relation_triple.append", "attribute_triple.append"], "methods", ["None"], ["", "self", ".", "reent", "=", "reent2", "\n", "self", ".", "allrelations", "=", "allrelations2", "\n", "\n", "", "def", "rename_node", "(", "self", ",", "prefix", ")", ":", "\n", "        ", "\"\"\"\n        Rename AMR graph nodes to prefix + node_index to avoid nodes with the same name in two different AMRs.\n\n        \"\"\"", "\n", "node_map_dict", "=", "{", "}", "\n", "# map each node to its new name (e.g. \"a1\")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "node_map_dict", "[", "self", ".", "nodes", "[", "i", "]", "]", "=", "prefix", "+", "str", "(", "i", ")", "\n", "# update node name", "\n", "", "for", "i", ",", "v", "in", "enumerate", "(", "self", ".", "nodes", ")", ":", "\n", "            ", "self", ".", "nodes", "[", "i", "]", "=", "node_map_dict", "[", "v", "]", "\n", "# update node name in relations", "\n", "", "for", "i", ",", "d", "in", "enumerate", "(", "self", ".", "relations", ")", ":", "\n", "            ", "new_dict", "=", "{", "}", "\n", "for", "k", ",", "v_lst", "in", "d", ".", "items", "(", ")", ":", "\n", "                ", "for", "v", "in", "v_lst", ":", "\n", "                    ", "if", "node_map_dict", "[", "k", "]", "not", "in", "new_dict", ":", "\n", "                        ", "new_dict", "[", "node_map_dict", "[", "k", "]", "]", "=", "[", "v", "]", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.amr.AMR.get_triples2": [[113, 138], ["range", "len", "instance_triple.append", "amr.AMR.relations[].items", "amr.AMR.attributes[].items", "relation_triple.append", "relation_triple.append"], "methods", ["None"], ["", "", "", "self", ".", "relations", "[", "i", "]", "=", "new_dict", "\n", "\n", "", "", "def", "get_triples", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the triples in three lists.\n        instance_triple: a triple representing an instance. E.g. instance(w, want-01)\n        attribute triple: relation of attributes, e.g. polarity(w, - )\n        and relation triple, e.g. arg0 (w, b)\n\n        \"\"\"", "\n", "instance_triple", "=", "[", "]", "\n", "relation_triple", "=", "[", "]", "\n", "attribute_triple", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "instance_triple", ".", "append", "(", "(", "\"instance\"", ",", "self", ".", "nodes", "[", "i", "]", ",", "self", ".", "node_values", "[", "i", "]", ")", ")", "\n", "# k is the other node this node has relation with", "\n", "# v is relation name", "\n", "for", "k", ",", "v_lst", "in", "self", ".", "relations", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "for", "v", "in", "v_lst", ":", "\n", "                    ", "relation_triple", ".", "append", "(", "(", "v", ",", "self", ".", "nodes", "[", "i", "]", ",", "k", ")", ")", "\n", "# k2 is the attribute name", "\n", "# v2 is the attribute value", "\n", "", "", "for", "k2", ",", "v2", "in", "self", ".", "attributes", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "attribute_triple", ".", "append", "(", "(", "k2", ",", "self", ".", "nodes", "[", "i", "]", ",", "v2", ")", ")", "\n", "", "", "return", "instance_triple", ",", "attribute_triple", ",", "relation_triple", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.amr.AMR.__str__": [[140, 155], ["range", "len", "lines.append", "lines.append", "lines.append", "amr.AMR.relations[].items", "amr.AMR.attributes[].items", "lines.append", "lines.append", "str"], "methods", ["None"], ["", "def", "get_triples2", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the triples in two lists:\n        instance_triple: a triple representing an instance. E.g. instance(w, want-01)\n        relation_triple: a triple representing all relations. E.g arg0 (w, b) or E.g. polarity(w, - )\n        Note that we do not differentiate between attribute triple and relation triple. Both are considered as relation\n        triples.\n        All triples are represented by (triple_type, argument 1 of the triple, argument 2 of the triple)\n\n        \"\"\"", "\n", "instance_triple", "=", "[", "]", "\n", "relation_triple", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "# an instance triple is instance(node name, node value).", "\n", "# For example, instance(b, boy).", "\n", "            ", "instance_triple", ".", "append", "(", "(", "\"instance\"", ",", "self", ".", "nodes", "[", "i", "]", ",", "self", ".", "node_values", "[", "i", "]", ")", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.amr.AMR.__repr__": [[156, 158], ["amr.AMR.__str__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.ATP.generate_amrized_srl.SRL.__str__"], ["# k is the other node this node has relation with", "\n", "# v is relation name", "\n", "for", "k", ",", "v_lst", "in", "self", ".", "relations", "[", "i", "]", ".", "items", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.amr.AMR.output_amr": [[159, 165], ["amr.AMR.__str__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.ATP.generate_amrized_srl.SRL.__str__"], ["                ", "for", "v", "in", "v_lst", ":", "\n", "                    ", "relation_triple", ".", "append", "(", "(", "v", ",", "self", ".", "nodes", "[", "i", "]", ",", "k", ")", ")", "\n", "# k2 is the attribute name", "\n", "# v2 is the attribute value", "\n", "", "", "for", "k2", ",", "v2", "in", "self", ".", "attributes", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "relation_triple", ".", "append", "(", "(", "k2", ",", "self", ".", "nodes", "[", "i", "]", ",", "v2", ")", ")", "\n", "", "", "return", "instance_triple", ",", "relation_triple", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.amr.AMR.parse_AMR_line": [[167, 399], ["collections.defaultdict", "collections.defaultdict", "enumerate", "amr.AMR", "line.strip", "relation_list.append", "attribute_list.append", "node_value_list.append", "cur_charseq.append", "cur_charseq.append", "cur_charseq.append", "cur_charseq.append", "temp_attr_value.split", "parts[].strip", "parts[].strip", "cur_charseq.append", "stack.append", "node_name_list.append", "stack.pop", "cur_charseq.append", "len", "len", "node_relation_dict2[].append", "node_relation_dict1[].append", "cur_charseq.append", "len", "temp_attr_value.split", "parts[].strip", "parts[].strip", "parts[].strip.endswith", "cur_relation_name.endswith", "node_relation_dict1[].append", "node_relation_dict1[].append", "len", "node_relation_dict1[].append", "node_relation_dict2[].append", "node_relation_dict1[].append"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "get_triples3", "(", "self", ")", ":", "\n", "        ", "relation_triple", "=", "[", "(", "self", ".", "nodes", "[", "0", "]", ",", "\"TOP\"", ",", "self", ".", "node_values", "[", "0", "]", ")", "]", "\n", "relation_triple", ".", "extend", "(", "self", ".", "allrelations", ")", "\n", "return", "relation_triple", "\n", "\n", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Generate AMR string for better readability\n\n        \"\"\"", "\n", "lines", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "lines", ".", "append", "(", "\"Node \"", "+", "str", "(", "i", ")", "+", "\" \"", "+", "self", ".", "nodes", "[", "i", "]", ")", "\n", "lines", ".", "append", "(", "\"Value: \"", "+", "self", ".", "node_values", "[", "i", "]", ")", "\n", "lines", ".", "append", "(", "\"Relations:\"", ")", "\n", "for", "k", ",", "v_lst", "in", "self", ".", "relations", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "for", "v", "in", "v_lst", ":", "\n", "                    ", "lines", ".", "append", "(", "\"Node \"", "+", "k", "+", "\" via \"", "+", "v", ")", "\n", "", "", "for", "k2", ",", "v2", "in", "self", ".", "attributes", "[", "i", "]", ".", "items", "(", ")", ":", "\n", "                ", "lines", ".", "append", "(", "\"Attribute: \"", "+", "k2", "+", "\" value \"", "+", "v2", ")", "\n", "", "", "return", "\"\\n\"", ".", "join", "(", "lines", ")", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__str__", "(", ")", "\n", "\n", "", "def", "output_amr", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Output AMR string\n\n        \"\"\"", "\n", "print", ">>", "DEBUG_LOG", ",", "self", ".", "__str__", "(", ")", "\n", "\n", "\n", "", "@", "staticmethod", "\n", "def", "parse_AMR_line", "(", "line", ",", "normalize_inv", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Parse a AMR from line representation to an AMR object.\n        This parsing algorithm scans the line once and process each character, in a shift-reduce style.\n\n        \"\"\"", "\n", "# Current state. It denotes the last significant symbol encountered. 1 for (, 2 for :, 3 for /,", "\n", "# and 0 for start state or ')'", "\n", "# Last significant symbol is ( --- start processing node name", "\n", "# Last significant symbol is : --- start processing relation name", "\n", "# Last significant symbol is / --- start processing node value (concept name)", "\n", "# Last significant symbol is ) --- current node processing is complete", "\n", "# Note that if these symbols are inside parenthesis, they are not significant symbols.", "\n", "state", "=", "0", "\n", "stack", "=", "[", "]", "\n", "# current not-yet-reduced character sequence", "\n", "cur_charseq", "=", "[", "]", "\n", "# key: node name value: node value", "\n", "node_dict", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "# node name list (order: occurrence of the node)", "\n", "node_name_list", "=", "[", "]", "\n", "# key: node name:  value: list of (relation name, the other node name)", "\n", "node_relation_dict1", "=", "defaultdict", "(", "list", ")", "\n", "# key: node name, value: list of (attribute name, const value) or (relation name, unseen node name)", "\n", "node_relation_dict2", "=", "defaultdict", "(", "list", ")", "\n", "allrelations", "=", "[", "]", "\n", "reent", "=", "[", "]", "\n", "# current relation name", "\n", "cur_relation_name", "=", "\"\"", "\n", "# having unmatched quote string", "\n", "in_quote", "=", "False", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "line", ".", "strip", "(", ")", ")", ":", "\n", "            ", "if", "c", "==", "\" \"", ":", "\n", "# allow space in relation name", "\n", "                ", "if", "state", "==", "2", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "", "continue", "\n", "", "if", "c", "==", "\"\\\"\"", ":", "\n", "# flip in_quote value when a quote symbol is encountered", "\n", "# insert placeholder if in_quote from last symbol", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "'_'", ")", "\n", "", "in_quote", "=", "not", "in_quote", "\n", "", "elif", "c", "==", "\"(\"", ":", "\n", "# not significant symbol if inside quote", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# get the attribute name", "\n", "# e.g :arg0 (x ...", "\n", "# at this point we get \"arg0\"", "\n", "", "if", "state", "==", "2", ":", "\n", "# in this state, current relation name should be empty", "\n", "                    ", "if", "cur_relation_name", "!=", "\"\"", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "\"Format error when processing \"", ",", "line", "[", "0", ":", "i", "+", "1", "]", "\n", "return", "None", "\n", "# update current relation name for future use", "\n", "", "cur_relation_name", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", ".", "strip", "(", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "", "state", "=", "1", "\n", "", "elif", "c", "==", "\":\"", ":", "\n", "# not significant symbol if inside quote", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# Last significant symbol is \"/\". Now we encounter \":\"", "\n", "# Example:", "\n", "# :OR (o2 / *OR*", "\n", "#    :mod (o3 / official)", "\n", "#  gets node value \"*OR*\" at this point", "\n", "", "if", "state", "==", "3", ":", "\n", "                    ", "node_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "# clear current char sequence", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "# pop node name (\"o2\" in the above example)", "\n", "cur_node_name", "=", "stack", "[", "-", "1", "]", "\n", "# update node name/value map", "\n", "node_dict", "[", "cur_node_name", "]", "=", "node_value", "\n", "# Last significant symbol is \":\". Now we encounter \":\"", "\n", "# Example:", "\n", "# :op1 w :quant 30", "\n", "# or :day 14 :month 3", "\n", "# the problem is that we cannot decide if node value is attribute value (constant)", "\n", "# or node value (variable) at this moment", "\n", "", "elif", "state", "==", "2", ":", "\n", "                    ", "temp_attr_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "parts", "=", "temp_attr_value", ".", "split", "(", ")", "\n", "if", "len", "(", "parts", ")", "<", "2", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "\"Error in processing; part len < 2\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", "\n", "return", "None", "\n", "# For the above example, node name is \"op1\", and node value is \"w\"", "\n", "# Note that this node name might not be encountered before", "\n", "", "relation_name", "=", "parts", "[", "0", "]", ".", "strip", "(", ")", "\n", "relation_value", "=", "parts", "[", "1", "]", ".", "strip", "(", ")", "\n", "# We need to link upper level node to the current", "\n", "# top of stack is upper level node", "\n", "if", "len", "(", "stack", ")", "==", "0", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "\"Error in processing\"", ",", "line", "[", ":", "i", "]", ",", "relation_name", ",", "relation_value", "\n", "return", "None", "\n", "# if we have not seen this node name before", "\n", "", "if", "relation_name", ".", "endswith", "(", "\"-of\"", ")", "and", "normalize_inv", ":", "\n", "                        ", "allrelations", ".", "append", "(", "(", "relation_value", ",", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "if", "relation_value", "not", "in", "node_dict", ":", "\n", "                            ", "node_relation_dict2", "[", "relation_value", "]", ".", "append", "(", "(", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                            ", "node_relation_dict1", "[", "relation_value", "]", ".", "append", "(", "(", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "", "reent", ".", "append", "(", "(", "relation_value", ",", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                        ", "allrelations", ".", "append", "(", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "if", "relation_value", "not", "in", "node_dict", ":", "\n", "                            ", "node_relation_dict2", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "", "else", ":", "\n", "                            ", "node_relation_dict1", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "", "reent", ".", "append", "(", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "", "", "state", "=", "2", "\n", "", "elif", "c", "==", "\"/\"", ":", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# Last significant symbol is \"(\". Now we encounter \"/\"", "\n", "# Example:", "\n", "# (d / default-01", "\n", "# get \"d\" here", "\n", "", "if", "state", "==", "1", ":", "\n", "                    ", "node_name", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "# if this node name is already in node_dict, it is duplicate", "\n", "if", "node_name", "in", "node_dict", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "\"Duplicate node name \"", ",", "node_name", ",", "\" in parsing AMR\"", "\n", "return", "None", "\n", "# push the node name to stack", "\n", "", "stack", ".", "append", "(", "node_name", ")", "\n", "# add it to node name list", "\n", "node_name_list", ".", "append", "(", "node_name", ")", "\n", "# if this node is part of the relation", "\n", "# Example:", "\n", "# :arg1 (n / nation)", "\n", "# cur_relation_name is arg1", "\n", "# node name is n", "\n", "# we have a relation arg1(upper level node, n)", "\n", "if", "cur_relation_name", "!=", "\"\"", ":", "\n", "# if relation name ends with \"-of\", e.g.\"arg0-of\",", "\n", "# it is reverse of some relation. For example, if a is \"arg0-of\" b,", "\n", "# we can also say b is \"arg0\" a.", "\n", "# If the relation name ends with \"-of\", we store the reverse relation.", "\n", "                        ", "if", "(", "not", "cur_relation_name", ".", "endswith", "(", "\"-of\"", ")", ")", "or", "normalize_inv", "==", "False", ":", "\n", "# stack[-2] is upper_level node we encountered, as we just add node_name to stack", "\n", "                            ", "node_relation_dict1", "[", "stack", "[", "-", "2", "]", "]", ".", "append", "(", "(", "cur_relation_name", ",", "node_name", ")", ")", "\n", "allrelations", ".", "append", "(", "(", "stack", "[", "-", "2", "]", ",", "cur_relation_name", ",", "node_name", ")", ")", "\n", "#if node_name in node_name_list:", "\n", "#\treent.append((stack[-2],cur_relation_name,node_name))", "\n", "", "else", ":", "\n", "# cur_relation_name[:-3] is to delete \"-of\"", "\n", "                            ", "node_relation_dict1", "[", "node_name", "]", ".", "append", "(", "(", "cur_relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "2", "]", ")", ")", "\n", "allrelations", ".", "append", "(", "(", "node_name", ",", "cur_relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "2", "]", ")", ")", "\n", "# clear current_relation_name", "\n", "", "cur_relation_name", "=", "\"\"", "\n", "", "", "else", ":", "\n", "# error if in other state", "\n", "                    ", "print", ">>", "ERROR_LOG", ",", "\"Error in parsing AMR\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", "\n", "return", "None", "\n", "", "state", "=", "3", "\n", "", "elif", "c", "==", "\")\"", ":", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# stack should be non-empty to find upper level node", "\n", "", "if", "len", "(", "stack", ")", "==", "0", ":", "\n", "                    ", "print", ">>", "ERROR_LOG", ",", "\"Unmatched parenthesis at position\"", ",", "i", ",", "\"in processing\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", "\n", "return", "None", "\n", "# Last significant symbol is \":\". Now we encounter \")\"", "\n", "# Example:", "\n", "# :op2 \"Brown\") or :op2 w)", "\n", "# get \\\"Brown\\\" or w here", "\n", "", "if", "state", "==", "2", ":", "\n", "                    ", "temp_attr_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "parts", "=", "temp_attr_value", ".", "split", "(", ")", "\n", "if", "len", "(", "parts", ")", "<", "2", ":", "\n", "                        ", "print", ">>", "ERROR_LOG", ",", "\"Error processing\"", ",", "line", "[", ":", "i", "+", "1", "]", ",", "temp_attr_value", "\n", "return", "None", "\n", "", "relation_name", "=", "parts", "[", "0", "]", ".", "strip", "(", ")", "\n", "relation_value", "=", "parts", "[", "1", "]", ".", "strip", "(", ")", "\n", "# store reverse of the relation", "\n", "# we are sure relation_value is a node here, as \"-of\" relation is only between two nodes", "\n", "if", "relation_name", ".", "endswith", "(", "\"-of\"", ")", "and", "normalize_inv", ":", "\n", "                        ", "allrelations", ".", "append", "(", "(", "relation_value", ",", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "node_relation_dict1", "[", "relation_value", "]", ".", "append", "(", "(", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "# attribute value not seen before", "\n", "# Note that it might be a constant attribute value, or an unseen node", "\n", "# process this after we have seen all the node names", "\n", "", "else", ":", "\n", "                        ", "allrelations", ".", "append", "(", "(", "stack", "[", "-", "1", "]", ",", "relation_name", ",", "relation_value", ")", ")", "\n", "", "if", "relation_value", "not", "in", "node_dict", ":", "\n", "                        ", "node_relation_dict2", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "", "else", ":", "\n", "                        ", "node_relation_dict1", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "#if relation_value in node_name_list:", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.bin.predict_amrs_from_plaintext.read_file_in_batches": [[10, 54], ["pathlib.Path().read_text().strip().splitlines", "line.strip.strip", "len", "sorted.append", "sorted", "predict_amrs_from_plaintext.read_file_in_batches._iterator"], "function", ["None"], ["def", "read_file_in_batches", "(", "path", ",", "batch_size", "=", "1000", ",", "max_length", "=", "100", ")", ":", "\n", "\n", "    ", "data", "=", "[", "]", "\n", "idx", "=", "0", "\n", "for", "line", "in", "Path", "(", "path", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "not", "line", ":", "\n", "            ", "continue", "\n", "", "n", "=", "len", "(", "line", ".", "split", "(", ")", ")", "\n", "if", "n", ">", "max_length", ":", "\n", "            ", "continue", "\n", "", "data", ".", "append", "(", "(", "idx", ",", "line", ",", "n", ")", ")", "\n", "idx", "+=", "1", "\n", "\n", "", "def", "_iterator", "(", "data", ")", ":", "\n", "\n", "        ", "data", "=", "sorted", "(", "data", ",", "key", "=", "lambda", "x", ":", "x", "[", "2", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "maxn", "=", "0", "\n", "batch", "=", "[", "]", "\n", "\n", "for", "sample", "in", "data", ":", "\n", "            ", "idx", ",", "line", ",", "n", "=", "sample", "\n", "if", "n", ">", "batch_size", ":", "\n", "                ", "if", "batch", ":", "\n", "                    ", "yield", "batch", "\n", "maxn", "=", "0", "\n", "batch", "=", "[", "]", "\n", "", "yield", "[", "sample", "]", "\n", "", "else", ":", "\n", "                ", "curr_batch_size", "=", "maxn", "*", "len", "(", "batch", ")", "\n", "cand_batch_size", "=", "max", "(", "maxn", ",", "n", ")", "*", "(", "len", "(", "batch", ")", "+", "1", ")", "\n", "\n", "if", "0", "<", "curr_batch_size", "<=", "batch_size", "and", "cand_batch_size", ">", "batch_size", ":", "\n", "                    ", "yield", "batch", "\n", "maxn", "=", "0", "\n", "batch", "=", "[", "]", "\n", "", "maxn", "=", "max", "(", "maxn", ",", "n", ")", "\n", "batch", ".", "append", "(", "sample", ")", "\n", "\n", "", "", "if", "batch", ":", "\n", "            ", "yield", "batch", "\n", "\n", "", "", "return", "_iterator", "(", "data", ")", ",", "len", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.bin.ChildTuningOptimizer.ChildTuningAdamW.__init__": [[8, 33], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "params", ":", "Iterable", "[", "torch", ".", "nn", ".", "parameter", ".", "Parameter", "]", ",", "\n", "lr", ":", "float", "=", "1e-3", ",", "\n", "betas", ":", "Tuple", "[", "float", ",", "float", "]", "=", "(", "0.9", ",", "0.999", ")", ",", "\n", "eps", ":", "float", "=", "1e-6", ",", "\n", "weight_decay", ":", "float", "=", "0.0", ",", "\n", "correct_bias", ":", "bool", "=", "True", ",", "\n", "reserve_p", "=", "1.0", ",", "\n", "mode", "=", "None", "\n", ")", ":", "\n", "        ", "if", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {} - should be >= 0.0\"", ".", "format", "(", "eps", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ",", "correct_bias", "=", "correct_bias", ")", "\n", "super", "(", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n", "self", ".", "gradient_mask", "=", "None", "\n", "self", ".", "reserve_p", "=", "reserve_p", "\n", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.bin.ChildTuningOptimizer.ChildTuningAdamW.set_gradient_mask": [[34, 36], ["None"], "methods", ["None"], ["", "def", "set_gradient_mask", "(", "self", ",", "gradient_mask", ")", ":", "\n", "        ", "self", ".", "gradient_mask", "=", "gradient_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.bin.ChildTuningOptimizer.ChildTuningAdamW.step": [[37, 106], ["closure", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "exp_avg_sq.sqrt().add_", "p.data.addcdiv_", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.distributions.bernoulli.Bernoulli", "exp_avg.mul_", "exp_avg_sq.mul_", "exp_avg_sq.sqrt", "grad.new_full", "torch.distributions.bernoulli.Bernoulli.sample", "math.sqrt", "grad.size"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "step", "(", "self", ",", "closure", ":", "Callable", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Performs a single optimization step.\n\n        Arguments:\n            closure (:obj:`Callable`, `optional`): A closure that reevaluates the model and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "\"params\"", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\"Adam does not support sparse gradients, please consider SparseAdam instead\"", ")", "\n", "\n", "# =================== HACK BEGIN =======================         ", "\n", "", "if", "self", ".", "mode", "is", "not", "None", ":", "\n", "                    ", "if", "self", ".", "mode", "==", "'ChildTuning-D'", ":", "\n", "                        ", "if", "p", "in", "self", ".", "gradient_mask", ":", "\n", "                            ", "grad", "*=", "self", ".", "gradient_mask", "[", "p", "]", "\n", "", "", "else", ":", "\n", "# ChildTuning-F", "\n", "                        ", "grad_mask", "=", "Bernoulli", "(", "grad", ".", "new_full", "(", "size", "=", "grad", ".", "size", "(", ")", ",", "fill_value", "=", "self", ".", "reserve_p", ")", ")", "\n", "grad", "*=", "grad_mask", ".", "sample", "(", ")", "/", "self", ".", "reserve_p", "\n", "# =================== HACK END =======================", "\n", "\n", "", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "\"step\"", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "\"exp_avg\"", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "\"exp_avg_sq\"", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "\"exp_avg\"", "]", ",", "state", "[", "\"exp_avg_sq\"", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "\"betas\"", "]", "\n", "\n", "state", "[", "\"step\"", "]", "+=", "1", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# In-place operations to update the averages at the same time", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "grad", ",", "alpha", "=", "1.0", "-", "beta1", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "grad", ",", "grad", ",", "value", "=", "1.0", "-", "beta2", ")", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "\"eps\"", "]", ")", "\n", "\n", "step_size", "=", "group", "[", "\"lr\"", "]", "\n", "if", "group", "[", "\"correct_bias\"", "]", ":", "# No bias correction for Bert", "\n", "                    ", "bias_correction1", "=", "1.0", "-", "beta1", "**", "state", "[", "\"step\"", "]", "\n", "bias_correction2", "=", "1.0", "-", "beta2", "**", "state", "[", "\"step\"", "]", "\n", "step_size", "=", "step_size", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "\n", "", "p", ".", "data", ".", "addcdiv_", "(", "exp_avg", ",", "denom", ",", "value", "=", "-", "step_size", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want to decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "# Add weight decay at the end (fixed version)", "\n", "p", ".", "data", ".", "add_", "(", "p", ".", "data", ",", "alpha", "=", "-", "group", "[", "\"lr\"", "]", "*", "group", "[", "\"weight_decay\"", "]", ")", "\n", "\n", "", "", "return", "loss", "", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.bin.eval_bleu.argument_parser": [[8, 26], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "argument_parser", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Preprocess AMR data'", ")", "\n", "# Multiple input parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--in-tokens\"", ",", "\n", "help", "=", "\"input tokens\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "str", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--in-reference-tokens\"", ",", "\n", "help", "=", "\"refrence tokens to compute metric\"", ",", "\n", "type", "=", "str", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.bin.eval_bleu.tokenize_sentence": [[28, 32], ["re.sub", "re.sub"], "function", ["None"], ["", "def", "tokenize_sentence", "(", "text", ",", "debug", "=", "False", ")", ":", "\n", "    ", "text", "=", "re", ".", "sub", "(", "r\"('ll|n't|'m|'s|'d|'re)\"", ",", "r\" \\1\"", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"(\\s+)\"", ",", "r\" \"", ",", "text", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.bin.eval_bleu.raw_corpus_bleu": [[34, 40], ["sacrebleu.corpus_bleu"], "function", ["None"], ["", "def", "raw_corpus_bleu", "(", "hypothesis", ":", "Iterable", "[", "str", "]", ",", "reference", ":", "Iterable", "[", "str", "]", ",", "\n", "offset", ":", "Optional", "[", "float", "]", "=", "0.01", ")", "->", "float", ":", "\n", "    ", "bleu", "=", "sacrebleu", ".", "corpus_bleu", "(", "hypothesis", ",", "reference", ",", "smooth_value", "=", "offset", ",", "\n", "force", "=", "True", ",", "use_effective_order", "=", "False", ",", "\n", "lowercase", "=", "True", ")", "\n", "return", "bleu", ".", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.bin.eval_bleu.raw_corpus_chrf": [[42, 48], ["sacrebleu.corpus_chrf"], "function", ["None"], ["", "def", "raw_corpus_chrf", "(", "hypotheses", ":", "Iterable", "[", "str", "]", ",", "\n", "references", ":", "Iterable", "[", "str", "]", ")", "->", "float", ":", "\n", "    ", "return", "sacrebleu", ".", "corpus_chrf", "(", "hypotheses", ",", "references", ",", "\n", "order", "=", "sacrebleu", ".", "CHRF_ORDER", ",", "\n", "beta", "=", "sacrebleu", ".", "CHRF_BETA", ",", "\n", "remove_whitespace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.bin.eval_bleu.read_tokens": [[49, 53], ["open", "fid.readlines"], "function", ["None"], ["", "def", "read_tokens", "(", "in_tokens_file", ")", ":", "\n", "    ", "with", "open", "(", "in_tokens_file", ")", "as", "fid", ":", "\n", "        ", "lines", "=", "fid", ".", "readlines", "(", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.bin.train.do_multitask_pretrain": [[33, 298], ["spring_amr.utils.instantiate_model_and_tokenizer_multitask", "print", "print", "torch.cuda.amp.grad_scaler.GradScaler", "spring_amr.utils.instantiate_real_multitask_loader", "print", "spring_amr.utils.instantiate_real_multitask_loader", "ignite.engine.Engine", "ignite.engine.Engine", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "model.cuda", "ignite.engine.Engine.run", "spring_amr.optim.ChildRAdam", "print", "spring_amr.optim.RAdam", "transformers.get_cosine_schedule_with_warmup", "dict", "model.cuda", "model.train", "model.named_parameters", "len", "print", "tqdm.tqdm", "print", "dict.items", "numpy.percentile", "print", "spring_amr.optim.RAdam.set_gradient_mask", "torch.no_grad", "print", "torch.cuda.amp.grad_scaler.GradScaler.unscale_", "torch.nn.utils.clip_grad_norm_", "torch.cuda.amp.grad_scaler.GradScaler.step", "torch.cuda.amp.grad_scaler.GradScaler.update", "spring_amr.optim.RAdam.zero_grad", "ignite.engine.Events.ITERATION_COMPLETED", "print", "ignite.engine.Engine.run", "print", "ignite.metrics.RunningAverage().attach", "ignite.metrics.RunningAverage().attach", "print", "ignite.handlers.ModelCheckpoint", "ignite.engine.Engine.add_event_handler", "next", "config.get", "model.parameters", "model.parameters", "transformers.get_constant_schedule_with_warmup", "len", "next", "model", "loss.backward", "model.named_parameters", "model.zero_grad", "v.view().cpu().numpy.view().cpu().numpy", "model.train", "model.eval", "model", "loss.item", "model.parameters", "transformers.get_constant_schedule_with_warmup.step", "next", "ignite.engine.Engine.on", "str", "str", "model.parameters", "model.parameters", "params.new_zeros", "numpy.append", "autocast", "model", "torch.cuda.amp.grad_scaler.GradScaler.scale().backward", "loss.item", "model.parameters", "spring_amr.evaluation.predict_amrs", "spring_amr.evaluation.write_predictions", "ignite.metrics.RunningAverage", "ignite.metrics.RunningAverage", "root.mkdir", "str", "str.mkdir", "ignite.handlers.global_step_from_engine", "params.size", "torch.nn.utils.clip_grad_norm_", "v.view().cpu().numpy.view().cpu", "next", "spring_amr.evaluation.compute_smatch", "torch.cuda.amp.grad_scaler.GradScaler.scale", "model.parameters", "str", "v.view().cpu().numpy.view", "str", "len", "list", "root.iterdir"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils.instantiate_model_and_tokenizer_multitask", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils.instantiate_real_multitask_loader", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils.instantiate_real_multitask_loader", "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.ChildRAdam.set_gradient_mask", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.evaluation.predict_amrs", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.evaluation.write_predictions", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.compute_smatch", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view"], ["from", "blink", ".", "candidate_ranking", ".", "bert_reranking", "import", "BertForReranking", "\n", "import", "logging", "\n", "import", "utils", "\n", "from", "evaluate", "import", "evaluate_model_on_dataset", ",", "evaluate", "\n", "\n", "logger", "=", "None", "\n", "\n", "\n", "def", "main", "(", "parameters", ")", ":", "\n", "# Read model", "\n", "    ", "reranker", "=", "utils", ".", "get_reranker", "(", "parameters", ")", "\n", "tokenizer", "=", "reranker", ".", "tokenizer", "\n", "model", "=", "reranker", ".", "model", "\n", "\n", "device", "=", "reranker", ".", "device", "\n", "n_gpu", "=", "reranker", ".", "n_gpu", "\n", "\n", "if", "parameters", "[", "\"gradient_accumulation_steps\"", "]", "<", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Invalid gradient_accumulation_steps parameter: {}, should be >= 1\"", ".", "format", "(", "\n", "parameters", "[", "\"gradient_accumulation_steps\"", "]", "\n", ")", "\n", ")", "\n", "\n", "# An effective batch size of `x`, when we are accumulating the gradient accross `y` batches will be achieved by having a batch size of `z = x / y`", "\n", "# args.gradient_accumulation_steps = args.gradient_accumulation_steps // n_gpu", "\n", "", "parameters", "[", "\"train_batch_size\"", "]", "=", "(", "\n", "parameters", "[", "\"train_batch_size\"", "]", "//", "parameters", "[", "\"gradient_accumulation_steps\"", "]", "\n", ")", "\n", "train_batch_size", "=", "parameters", "[", "\"train_batch_size\"", "]", "\n", "evaluation_batch_size", "=", "parameters", "[", "\"evaluation_batch_size\"", "]", "\n", "gradient_accumulation_steps", "=", "parameters", "[", "\"gradient_accumulation_steps\"", "]", "\n", "\n", "# Fix the random seeds", "\n", "seed", "=", "parameters", "[", "\"seed\"", "]", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "\n", "logger", "=", "None", "\n", "number_of_samples_per_dataset", "=", "{", "}", "\n", "\n", "if", "reranker", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n", "", "time_start", "=", "time", ".", "time", "(", ")", "\n", "model_output_path", "=", "parameters", "[", "\"model_output_path\"", "]", "\n", "\n", "# Make sure everything is in order with the output directiory", "\n", "if", "os", ".", "path", ".", "exists", "(", "model_output_path", ")", "and", "os", ".", "listdir", "(", "model_output_path", ")", ":", "\n", "        ", "print", "(", "\n", "\"Output directory ({}) already exists and is not empty.\"", ".", "format", "(", "\n", "model_output_path", "\n", ")", "\n", ")", "\n", "answer", "=", "input", "(", "\"Would you like to empty the existing directory? [Y/N]\\n\"", ")", "\n", "if", "answer", ".", "strip", "(", ")", "==", "\"Y\"", ":", "\n", "            ", "print", "(", "\"Deleteing {}...\"", ".", "format", "(", "model_output_path", ")", ")", "\n", "shutil", ".", "rmtree", "(", "model_output_path", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty.\"", ".", "format", "(", "\n", "model_output_path", "\n", ")", "\n", ")", "\n", "\n", "", "", "if", "not", "os", ".", "path", ".", "exists", "(", "model_output_path", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_output_path", ")", "\n", "\n", "", "utils", ".", "write_to_file", "(", "\n", "os", ".", "path", ".", "join", "(", "model_output_path", ",", "\"training_parameters.txt\"", ")", ",", "str", "(", "parameters", ")", "\n", ")", "\n", "\n", "logger", "=", "utils", ".", "get_logger", "(", "model_output_path", ")", "\n", "logger", ".", "info", "(", "\"Starting training\"", ")", "\n", "logger", ".", "info", "(", "\n", "\"device: {} n_gpu: {}, distributed training: {}\"", ".", "format", "(", "device", ",", "n_gpu", ",", "False", ")", "\n", ")", "\n", "\n", "### Load training data", "\n", "train_dataset_name", "=", "\"aida-train\"", "\n", "train_samples", "=", "utils", ".", "read_dataset", "(", "\n", "train_dataset_name", ",", "parameters", "[", "\"path_to_preprocessed_json_data\"", "]", "\n", ")", "\n", "train_samples_filtered", "=", "utils", ".", "filter_samples", "(", "train_samples", ",", "parameters", "[", "\"top_k\"", "]", ")", "\n", "logger", ".", "info", "(", "\n", "\"Retained {} out of {} samples\"", ".", "format", "(", "\n", "len", "(", "train_samples_filtered", ")", ",", "len", "(", "train_samples", ")", "\n", ")", "\n", ")", "\n", "number_of_samples_per_dataset", "[", "train_dataset_name", "]", "=", "len", "(", "train_samples", ")", "\n", "\n", "train_data", ",", "train_tensor_data", "=", "reranker", ".", "_process_mentions_for_model", "(", "\n", "parameters", "[", "\"context_key\"", "]", ",", "\n", "train_samples_filtered", ",", "\n", "tokenizer", ",", "\n", "parameters", "[", "\"max_seq_length\"", "]", ",", "\n", "silent", "=", "parameters", "[", "\"silent\"", "]", ",", "\n", "logger", "=", "logger", ",", "\n", "top_k", "=", "parameters", "[", "\"top_k\"", "]", ",", "\n", "debug", "=", "parameters", "[", "\"debug\"", "]", ",", "\n", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_tensor_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_tensor_data", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "train_batch_size", "\n", ")", "\n", "###", "\n", "\n", "### Loading dev data", "\n", "dev_dataset_name", "=", "\"aida-A\"", "\n", "dev_samples", "=", "utils", ".", "read_dataset", "(", "\n", "dev_dataset_name", ",", "parameters", "[", "\"path_to_preprocessed_json_data\"", "]", "\n", ")", "\n", "dev_samples_filtered", "=", "utils", ".", "filter_samples", "(", "dev_samples", ",", "parameters", "[", "\"top_k\"", "]", ")", "\n", "logger", ".", "info", "(", "\n", "\"Retained {} out of {} samples\"", ".", "format", "(", "\n", "len", "(", "dev_samples_filtered", ")", ",", "len", "(", "dev_samples", ")", "\n", ")", "\n", ")", "\n", "number_of_samples_per_dataset", "[", "dev_dataset_name", "]", "=", "len", "(", "dev_samples", ")", "\n", "\n", "dev_data", ",", "dev_tensor_data", "=", "reranker", ".", "_process_mentions_for_model", "(", "\n", "parameters", "[", "\"context_key\"", "]", ",", "\n", "train_samples_filtered", ",", "\n", "tokenizer", ",", "\n", "parameters", "[", "\"max_seq_length\"", "]", ",", "\n", "silent", "=", "parameters", "[", "\"silent\"", "]", ",", "\n", "logger", "=", "logger", ",", "\n", "top_k", "=", "parameters", "[", "\"top_k\"", "]", ",", "\n", "debug", "=", "parameters", "[", "\"debug\"", "]", ",", "\n", ")", "\n", "dev_sampler", "=", "SequentialSampler", "(", "dev_tensor_data", ")", "\n", "dev_dataloader", "=", "DataLoader", "(", "\n", "dev_tensor_data", ",", "sampler", "=", "dev_sampler", ",", "batch_size", "=", "evaluation_batch_size", "\n", ")", "\n", "###", "\n", "\n", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_samples_filtered", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Gradient accumulation steps = %d\"", ",", "gradient_accumulation_steps", ")", "\n", "\n", "optimizer", ",", "scheduler", "=", "reranker", ".", "get_scheduler_and_optimizer", "(", "\n", "parameters", ",", "train_tensor_data", ",", "logger", "\n", ")", "\n", "\n", "best_epoch_idx", "=", "-", "1", "\n", "best_score", "=", "-", "1", "\n", "\n", "num_train_epochs", "=", "parameters", "[", "\"num_train_epochs\"", "]", "\n", "\n", "model", ".", "train", "(", ")", "\n", "\n", "for", "epoch_idx", "in", "trange", "(", "int", "(", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ")", ":", "\n", "        ", "tr_loss", "=", "0", "\n", "results", "=", "None", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Batch\"", ")", ")", ":", "\n", "            ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "device", ")", "for", "t", "in", "batch", ")", "\n", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", ",", "entity_mask", "=", "batch", "\n", "loss", ",", "_", "=", "model", "(", "\n", "input_ids", ",", "segment_ids", ",", "input_mask", ",", "label_ids", ",", "entity_mask", "=", "entity_mask", "\n", ")", "\n", "\n", "# if n_gpu > 1:", "\n", "#     loss = loss.mean() # mean() to average on multi-gpu.", "\n", "\n", "if", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "gradient_accumulation_steps", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "(", "\n", "parameters", "[", "\"print_tr_loss_opt_steps_interval\"", "]", "\n", "*", "parameters", "[", "\"gradient_accumulation_steps\"", "]", "\n", ")", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Step {} - epoch {} average loss: {}\\n\"", ".", "format", "(", "\n", "step", ",", "\n", "epoch_idx", ",", "\n", "tr_loss", "\n", "/", "(", "\n", "parameters", "[", "\"print_tr_loss_opt_steps_interval\"", "]", "\n", "*", "gradient_accumulation_steps", "\n", ")", ",", "\n", ")", "\n", ")", "\n", "tr_loss", "=", "0", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "model", ".", "parameters", "(", ")", ",", "parameters", "[", "\"max_grad_norm\"", "]", "\n", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "", "if", "(", "step", "+", "1", ")", "%", "(", "\n", "parameters", "[", "\"dev_evaluation_interval\"", "]", "\n", "*", "gradient_accumulation_steps", "\n", "*", "train_batch_size", "\n", ")", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Evaluation on the development dataset\"", ")", "\n", "evaluate_model_on_dataset", "(", "\n", "model", ",", "\n", "dev_dataloader", ",", "\n", "dev_dataset_name", ",", "\n", "device", "=", "device", ",", "\n", "logger", "=", "logger", ",", "\n", "number_of_samples", "=", "number_of_samples_per_dataset", "[", "dev_dataset_name", "]", ",", "\n", ")", "\n", "model", ".", "train", "(", ")", "\n", "logger", ".", "info", "(", "\"\\n\"", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"***** Saving fine - tuned model *****\"", ")", "\n", "epoch_output_folder_path", "=", "os", ".", "path", ".", "join", "(", "\n", "model_output_path", ",", "\"epoch_{}\"", ".", "format", "(", "epoch_idx", ")", "\n", ")", "\n", "utils", ".", "save_model", "(", "model", ",", "tokenizer", ",", "epoch_output_folder_path", ")", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "epoch_output_folder_path", ",", "\"eval_results.txt\"", ")", "\n", "results", "=", "evaluate_model_on_dataset", "(", "\n", "model", ",", "\n", "dev_dataloader", ",", "\n", "dev_dataset_name", ",", "\n", "device", "=", "device", ",", "\n", "logger", "=", "logger", ",", "\n", "path_to_file_to_write_results", "=", "output_eval_file", ",", "\n", "number_of_samples", "=", "number_of_samples_per_dataset", "[", "dev_dataset_name", "]", ",", "\n", ")", "\n", "\n", "ls", "=", "[", "best_score", ",", "results", "[", "\"normalized_accuracy\"", "]", "]", "\n", "li", "=", "[", "best_epoch_idx", ",", "epoch_idx", "]", "\n", "\n", "best_score", "=", "ls", "[", "np", ".", "argmax", "(", "ls", ")", "]", "\n", "best_epoch_idx", "=", "li", "[", "np", ".", "argmax", "(", "ls", ")", "]", "\n", "logger", ".", "info", "(", "\"\\n\"", ")", "\n", "\n", "", "execution_time", "=", "(", "time", ".", "time", "(", ")", "-", "time_start", ")", "/", "60", "\n", "utils", ".", "write_to_file", "(", "\n", "os", ".", "path", ".", "join", "(", "model_output_path", ",", "\"training_time.txt\"", ")", ",", "\n", "\"The training took {} minutes\\n\"", ".", "format", "(", "execution_time", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"The training took {} minutes\\n\"", ".", "format", "(", "execution_time", ")", ")", "\n", "\n", "# save the best model in the parent_dir", "\n", "logger", ".", "info", "(", "\"Best performance in epoch: {}\"", ".", "format", "(", "best_epoch_idx", ")", ")", "\n", "parameters", "[", "\"path_to_model\"", "]", "=", "os", ".", "path", ".", "join", "(", "\n", "model_output_path", ",", "\"epoch_{}\"", ".", "format", "(", "best_epoch_idx", ")", "\n", ")", "\n", "reranker", "=", "utils", ".", "get_reranker", "(", "parameters", ")", "\n", "utils", ".", "save_model", "(", "reranker", ".", "model", ",", "tokenizer", ",", "model_output_path", ")", "\n", "\n", "if", "parameters", "[", "\"evaluate\"", "]", ":", "\n", "        ", "parameters", "[", "\"path_to_model\"", "]", "=", "model_output_path", "\n", "evaluate", "(", "parameters", ",", "logger", "=", "logger", ")", "\n", "\n", "\n", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--path_to_preprocessed_json_data\"", ",", "\n", "default", "=", "\"data/train_and_benchmark_processed_json\"", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.bin.train.do_single_pretrain": [[306, 558], ["spring_amr.utils.instantiate_model_and_tokenizer", "print", "print", "torch.cuda.amp.grad_scaler.GradScaler", "spring_amr.utils.instantiate_multitask_loader", "spring_amr.utils.instantiate_multitask_loader", "ignite.engine.Engine", "ignite.engine.Engine", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "model.cuda", "ignite.engine.Engine.run", "spring_amr.optim.ChildRAdam", "print", "spring_amr.optim.RAdam", "transformers.get_cosine_schedule_with_warmup", "dict", "model.cuda", "model.train", "model.named_parameters", "len", "print", "tqdm.tqdm", "print", "dict.items", "numpy.percentile", "print", "spring_amr.optim.RAdam.set_gradient_mask", "torch.no_grad", "print", "torch.cuda.amp.grad_scaler.GradScaler.unscale_", "torch.nn.utils.clip_grad_norm_", "torch.cuda.amp.grad_scaler.GradScaler.step", "torch.cuda.amp.grad_scaler.GradScaler.update", "spring_amr.optim.RAdam.zero_grad", "transformers.get_constant_schedule_with_warmup.step", "ignite.engine.Events.ITERATION_COMPLETED", "print", "ignite.engine.Engine.run", "print", "ignite.metrics.RunningAverage().attach", "ignite.metrics.RunningAverage().attach", "print", "ignite.handlers.ModelCheckpoint", "ignite.engine.Engine.add_event_handler", "next", "config.get", "model.parameters", "model.parameters", "transformers.get_constant_schedule_with_warmup", "next", "model", "loss.backward", "model.named_parameters", "model.zero_grad", "v.view().cpu().numpy.view().cpu().numpy", "model.train", "torch.cuda.amp.grad_scaler.GradScaler.scale().backward", "loss.item", "model.eval", "model", "loss.item", "model.parameters", "next", "ignite.engine.Engine.on", "str", "str", "model.parameters", "model.parameters", "params.new_zeros", "numpy.append", "autocast", "model", "model.parameters", "spring_amr.evaluation.predict_sentences", "spring_amr.evaluation.compute_bleu_from_files", "ignite.metrics.RunningAverage", "ignite.metrics.RunningAverage", "root.mkdir", "str", "str.mkdir", "ignite.handlers.global_step_from_engine", "params.size", "torch.nn.utils.clip_grad_norm_", "v.view().cpu().numpy.view().cpu", "torch.cuda.amp.grad_scaler.GradScaler.scale", "next", "str", "model.parameters", "str", "str", "v.view().cpu().numpy.view", "str", "str", "str", "len", "str", "list", "str", "root.iterdir"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.model_utils.instantiate_model_and_tokenizer", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils.instantiate_multitask_loader", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils.instantiate_multitask_loader", "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.ChildRAdam.set_gradient_mask", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.evaluation.predict_sentences", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.evaluation.compute_bleu_from_files", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view"], ["help", "=", "\"Bert pre-trained model selected in the list: bert-base-uncased, \"", "\n", "\"bert-large-uncased, bert-base-cased, bert-base-multilingual, bert-base-chinese.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_output_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the trained model is to be dumped.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--context_key\"", ",", "default", "=", "\"tagged_query_context_sent_prev_curr_next\"", ",", "type", "=", "str", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lowercase_flag\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to lower case the input text. True for uncased models, False for cased models.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--top_k\"", ",", "default", "=", "80", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "512", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after WordPiece tokenization. \\n\"", "\n", "\"Sequences longer than this will be truncated, and sequences shorter \\n\"", "\n", "\"than this will be padded.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--full_evaluation\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run the evaluation on all datasets.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_with_pregenerated_candidates\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run in debug mode with only 200 samples.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_eval_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The txt file where the the evaluation results will be written.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--debug\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run in debug mode with only 200 samples.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--silent\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to print progress bars.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Total batch size for training.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluation_batch_size\"", ",", "\n", "default", "=", "4", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Total batch size for evaluation.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dataparallel_bert\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to distributed the candidate generation process.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--learning_rate\"", ",", "\n", "default", "=", "3e-5", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "\n", "default", "=", "3", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--print_tr_loss_opt_steps_interval\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "20", ",", "\n", "help", "=", "\"Interval of loss printing\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dev_evaluation_interval\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "160", ",", "\n", "help", "=", "\"Interval for evaluation during training\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_interval\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"Interval for model saving\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--warmup_proportion\"", ",", "\n", "default", "=", "0.1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Proportion of training to perform linear learning rate warmup for. \"", "\n", "\"E.g., 0.1 = 10% of training.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether not to use CUDA when available\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "12345", ",", "help", "=", "\"random seed for initialization\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "8", ",", "\n", "help", "=", "\"Number of updates steps to accumualte before performing a backward/update pass.\"", ",", "\n", ")", "\n", "\n", "# args = argparse.Namespace(**params)", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "print", "(", "args", ")", "\n", "\n", "parameters", "=", "args", ".", "__dict__", "\n", "main", "(", "parameters", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.bin.train.do_train": [[564, 1020], ["spring_amr.utils.instantiate_model_and_tokenizer", "spring_amr.utils.instantiate_loader", "len", "print", "print", "print", "spring_amr.utils.instantiate_loader", "print", "torch.cuda.amp.grad_scaler.GradScaler", "ignite.engine.Engine", "ignite.engine.Engine", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "model.cuda", "ignite.engine.Engine.run", "print", "list", "set", "list", "spring_amr.optim.RAdam", "transformers.get_cosine_schedule_with_warmup", "dict", "model.cuda", "model.train", "model.named_parameters", "len", "print", "tqdm.tqdm", "print", "dict.items", "numpy.percentile", "print", "spring_amr.optim.RAdam.set_gradient_mask", "torch.no_grad", "print", "torch.cuda.amp.grad_scaler.GradScaler.unscale_", "torch.nn.utils.clip_grad_norm_", "torch.cuda.amp.grad_scaler.GradScaler.step", "torch.cuda.amp.grad_scaler.GradScaler.update", "spring_amr.optim.RAdam.zero_grad", "ignite.engine.Events.ITERATION_COMPLETED", "print", "ignite.engine.Engine.run", "print", "ignite.metrics.RunningAverage().attach", "ignite.metrics.RunningAverage().attach", "WandBLogger", "WandBLogger.attach_output_handler", "WandBLogger.attach_output_handler", "ignite.engine.Engine.on", "print", "ignite.handlers.ModelCheckpoint", "ignite.engine.Engine.add_event_handler", "next", "config.get", "model.model.encoder.parameters", "id", "spring_amr.optim.ChildRAdam", "print", "transformers.get_constant_schedule_with_warmup", "next", "model", "loss.backward", "model.named_parameters", "model.zero_grad", "v.view().cpu().numpy.view().cpu().numpy", "model.train", "model.eval", "model", "loss.item", "torch.no_grad", "model.parameters", "transformers.get_linear_schedule_with_warmup.step", "next", "ignite.engine.Engine.on", "ignite.engine.Engine.on", "ignite.metrics.RunningAverage().attach", "ignite.metrics.RunningAverage().attach", "WandBLogger.attach_output_handler", "WandBLogger.attach_output_handler", "WandBLogger.attach_output_handler", "wandb.log", "str", "str", "model.parameters", "model.model.decoder.parameters", "model.rev.model.decoder.parameters", "model.parameters", "ranger21.Ranger21", "print", "spring_amr.optim.RAdam", "transformers.get_linear_schedule_with_warmup", "model.parameters", "params.new_zeros", "numpy.append", "autocast", "model", "torch.cuda.amp.grad_scaler.GradScaler.scale().backward", "loss.item", "model.train", "spring_amr.dataset.reverse_direction", "torch.cuda.amp.grad_scaler.GradScaler.scale().backward", "loss.item", "model.eval", "spring_amr.dataset.reverse_direction", "model", "loss.item", "torch.no_grad", "model.parameters", "spring_amr.evaluation.predict_amrs", "spring_amr.evaluation.write_predictions", "spring_amr.evaluation.predict_sentences", "spring_amr.evaluation.compute_bleu", "ignite.metrics.RunningAverage", "ignite.metrics.RunningAverage", "ignite.metrics.RunningAverage().attach", "ignite.metrics.RunningAverage().attach", "ignite.metrics.RunningAverage().attach", "ignite.metrics.RunningAverage().attach", "WandBLogger.attach_output_handler", "metric_names_dev.append", "root.mkdir", "str", "str.mkdir", "ignite.handlers.global_step_from_engine", "id", "id", "model.parameters", "model.parameters", "params.size", "torch.nn.utils.clip_grad_norm_", "v.view().cpu().numpy.view().cpu", "autocast", "model.rev", "model.train", "torch.cuda.amp.grad_scaler.GradScaler.scale().backward", "loss1.item.item", "spring_amr.dataset.reverse_direction", "torch.cuda.amp.grad_scaler.GradScaler.scale().backward", "model.eval", "model", "spring_amr.dataset.reverse_direction", "model.rev", "next", "spring_amr.evaluation.compute_smatch", "next", "ignite.metrics.RunningAverage", "ignite.metrics.RunningAverage", "metric_names_dev.append", "torch.cuda.amp.grad_scaler.GradScaler.scale", "torch.cuda.amp.grad_scaler.GradScaler.scale", "autocast", "model", "autocast", "model.rev", "loss2.item", "loss1.item.item", "loss2.item", "model.parameters", "model.parameters", "ignite.metrics.RunningAverage", "ignite.metrics.RunningAverage", "ignite.metrics.RunningAverage", "ignite.metrics.RunningAverage", "metric_names_dev.extend", "transformers.get_linear_schedule_with_warmup.get_last_lr", "str", "v.view().cpu().numpy.view", "torch.cuda.amp.grad_scaler.GradScaler.scale", "torch.cuda.amp.grad_scaler.GradScaler.scale", "str", "len", "list", "root.iterdir"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.model_utils.instantiate_model_and_tokenizer", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils.instantiate_loader", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils.instantiate_loader", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.ChildRAdam.set_gradient_mask", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.reverse_direction", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.reverse_direction", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.evaluation.predict_amrs", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.evaluation.write_predictions", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.evaluation.predict_sentences", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.bleu_scorer.BLEUScorer.compute_bleu", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.rev", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.reverse_direction", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.reverse_direction", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.rev", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.compute_smatch", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.rev", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view"], []], "home.repos.pwc.inspect_result.chenllliang_atp.bin.train.seed_torch": [[1023, 1031], ["random.seed", "str", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.postprocessing.token_processing": [[17, 31], ["tok.isdigit", "eval", "tok.startswith", "tok.endswith", "tok.endswith", "tok.startswith"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval"], ["def", "token_processing", "(", "tok", ")", ":", "\n", "    ", "if", "tok", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "elif", "tok", ".", "isdigit", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "eval", "(", "tok", ")", "\n", "", "except", ":", "\n", "            ", "return", "tok", "\n", "", "", "elif", "tok", ".", "startswith", "(", "'\"'", ")", "and", "(", "not", "tok", ".", "endswith", "(", "'\"'", ")", ")", ":", "\n", "        ", "return", "tok", "+", "'\"'", "\n", "", "elif", "tok", ".", "endswith", "(", "'\"'", ")", "and", "(", "not", "tok", ".", "startswith", "(", "'\"'", ")", ")", ":", "\n", "        ", "return", "'\"'", "+", "tok", "\n", "", "else", ":", "\n", "        ", "return", "tok", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.postprocessing.decode_into_node_and_backreferences": [[32, 190], ["re.compile", "re.compile", "zip", "enumerate", "tokenizer.decoder.get", "max", "zip", "postprocessing.token_processing", "tokens.pop", "backreferences.pop", "tokens.append", "backreferences.append", "isinstance", "tokenizer.convert_tokens_to_string().lstrip", "old_tokens.index", "enumerate", "min", "len", "subtok.lstrip", "isinstance", "re.compile.match", "tokens.append", "backreferences.append", "len", "enumerate", "zip", "subtok.lstrip", "re.compile.match", "subtok.startswith", "tokenizer.convert_tokens_to_string", "len", "isinstance", "range", "len", "tokens.append", "backreferences.append", "list", "len", "str", "range", "tokens.append", "backreferences.append", "subtok.lstrip", "isinstance", "tokens[].startswith", "[].isdigit", "tokens.append", "backreferences.append", "old_tok.startswith", "len", "str", "len", "subtok.lstrip", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.token_processing"], ["", "", "def", "decode_into_node_and_backreferences", "(", "subtoken_ids", ",", "tokenizer", ")", ":", "\n", "    ", "rex_arg", "=", "re", ".", "compile", "(", "f\"^{tokenizer.INIT}(op|snt|conj|prep)\"", ")", "\n", "rex_spc", "=", "re", ".", "compile", "(", "r\"<(s|/s|lit|/lit|stop|unk|pad|mask)>\"", ")", "\n", "\n", "# get strings", "\n", "subtokens", "=", "[", "tokenizer", ".", "decoder", ".", "get", "(", "t", ")", "for", "t", "in", "subtoken_ids", "]", "\n", "# fix backreferences", "\n", "subtoken_backreferences", "=", "[", "max", "(", "t", "-", "len", "(", "tokenizer", ".", "encoder", ")", ",", "-", "1", ")", "for", "t", "in", "subtoken_ids", "]", "\n", "# strip padding", "\n", "subtokens", ",", "subtoken_backreferences", "=", "zip", "(", "\n", "*", "[", "(", "s", ",", "b", ")", "for", "s", ",", "b", "in", "zip", "(", "subtokens", ",", "subtoken_backreferences", ")", "if", "s", "!=", "(", "tokenizer", ".", "INIT", "+", "'<pad>'", ")", "]", ")", "\n", "\n", "# subword collapse", "\n", "tokens", "=", "[", "]", "\n", "backreferences", "=", "[", "]", "\n", "subword_to_token_map", "=", "{", "}", "\n", "current_token_i", "=", "0", "\n", "\n", "\n", "\n", "\n", "for", "subw_i", ",", "(", "subw_backr", ",", "subtok", ")", "in", "enumerate", "(", "zip", "(", "subtoken_backreferences", ",", "subtokens", ")", ")", ":", "\n", "        ", "subword_to_token_map", "[", "subw_i", "]", "=", "current_token_i", "\n", "\n", "# if empty you cannot do anything but add a new word", "\n", "if", "not", "tokens", ":", "\n", "            ", "tokens", ".", "append", "(", "subtok", ".", "lstrip", "(", "tokenizer", ".", "INIT", ")", ")", "# '\u0120<s>' -> '<s>'", "\n", "backreferences", ".", "append", "(", "-", "1", ")", "\n", "current_token_i", "+=", "1", "\n", "\n", "# backref can't be splitted", "\n", "# elif subw_backr > -1:", "\n", "#     tokens.append(None)", "\n", "#     backreferences.append(subword_to_token_map[subw_backr])", "\n", "#     current_token_i += 1", "\n", "\n", "# after a special token release", "\n", "", "elif", "isinstance", "(", "tokens", "[", "-", "1", "]", ",", "str", ")", "and", "rex_spc", ".", "match", "(", "tokens", "[", "-", "1", "]", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "subtok", ".", "lstrip", "(", "tokenizer", ".", "INIT", ")", ")", "\n", "backreferences", ".", "append", "(", "-", "1", ")", "\n", "current_token_i", "+=", "1", "\n", "\n", "# after a subtoken ':' (which should be followed by the rest of the edge) ignore tokenizer.INIT", "\n", "# TODO: this is an ugly patch due to the fact that BART tokenizer splits after ':'", "\n", "", "elif", "(", "tokens", "[", "-", "1", "]", "==", "':'", ")", "and", "rex_arg", ".", "match", "(", "subtok", ")", ":", "\n", "            ", "tokens", "[", "-", "1", "]", "=", "tokens", "[", "-", "1", "]", "+", "subtok", "[", "1", ":", "]", "\n", "\n", "# leading tokenizer.INIT", "\n", "", "elif", "subtok", ".", "startswith", "(", "tokenizer", ".", "INIT", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "subtok", ".", "lstrip", "(", "tokenizer", ".", "INIT", ")", ")", "\n", "backreferences", ".", "append", "(", "-", "1", ")", "\n", "current_token_i", "+=", "1", "\n", "\n", "# very ugly patch for some cases in which tokenizer.INIT is not in the following token to the edge", "\n", "", "elif", "isinstance", "(", "tokens", "[", "-", "1", "]", ",", "str", ")", "and", "tokens", "[", "-", "1", "]", ".", "startswith", "(", "':'", ")", "and", "tokens", "[", "-", "1", "]", "[", "-", "1", "]", ".", "isdigit", "(", ")", "and", "(", "subtok", "!=", "'-of'", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "subtok", ".", "lstrip", "(", "tokenizer", ".", "INIT", ")", ")", "\n", "backreferences", ".", "append", "(", "-", "1", ")", "\n", "current_token_i", "+=", "1", "\n", "\n", "# in any other case attach to the previous", "\n", "", "else", ":", "\n", "            ", "tokens", "[", "-", "1", "]", "=", "tokens", "[", "-", "1", "]", "+", "subtok", "\n", "\n", "# strip INIT and fix byte-level", "\n", "", "", "tokens", "=", "[", "tokenizer", ".", "convert_tokens_to_string", "(", "list", "(", "t", ")", ")", ".", "lstrip", "(", ")", "if", "isinstance", "(", "t", ",", "str", ")", "else", "t", "for", "t", "in", "tokens", "]", "\n", "# tokens = [t.replace(tokenizer.INIT, '') if isinstance(t, str) else t for t in tokens]", "\n", "\n", "# unks are substituted with thing", "\n", "tokens", "=", "[", "t", "if", "t", "!=", "'<unk>'", "else", "'thing'", "for", "t", "in", "tokens", "]", "\n", "\n", "old_tokens", "=", "tokens", "\n", "old_backreferences", "=", "backreferences", "\n", "\n", "# <lit> Barack Obama </lit> -> \"Barack Obama\"", "\n", "tokens", "=", "[", "]", "\n", "backreferences", "=", "[", "]", "\n", "token_to_token_map", "=", "{", "}", "\n", "start_search", "=", "0", "\n", "removed", "=", "0", "\n", "while", "True", ":", "\n", "        ", "try", ":", "\n", "\n", "            ", "lit_start", "=", "old_tokens", ".", "index", "(", "'<lit>'", ",", "start_search", ")", "\n", "token_addition", "=", "old_tokens", "[", "start_search", ":", "lit_start", "]", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "token_addition", ",", "start", "=", "start_search", ")", ":", "\n", "                ", "token_to_token_map", "[", "i", "]", "=", "i", "-", "removed", "\n", "", "tokens", "+=", "token_addition", "\n", "\n", "backreferences_addition", "=", "[", "token_to_token_map", "[", "b", "]", "if", "b", ">", "-", "1", "else", "-", "1", "for", "b", "in", "\n", "old_backreferences", "[", "start_search", ":", "lit_start", "]", "]", "\n", "backreferences", "+=", "backreferences_addition", "\n", "\n", "lit_end", "=", "min", "(", "lit_start", "+", "2", ",", "len", "(", "old_tokens", ")", "-", "1", ")", "\n", "\n", "while", "lit_end", "<", "len", "(", "old_tokens", ")", ":", "\n", "                ", "old_tok", "=", "old_tokens", "[", "lit_end", "]", "\n", "\n", "if", "isinstance", "(", "old_tok", ",", "str", ")", "and", "(", "\n", "(", "old_tok", ".", "startswith", "(", "':'", ")", "and", "len", "(", "old_tok", ")", ">", "3", ")", "or", "(", "old_tok", "==", "'<stop>'", ")", ")", ":", "\n", "                    ", "res_tok", "=", "old_tokens", "[", "lit_start", "+", "1", ":", "lit_end", "]", "\n", "for", "i", "in", "range", "(", "lit_start", ",", "lit_end", ")", ":", "\n", "                        ", "token_to_token_map", "[", "i", "]", "=", "len", "(", "tokens", ")", "\n", "\n", "# Remove possible wrong None", "\n", "", "res", "=", "old_tokens", "[", "lit_start", "+", "1", ":", "lit_end", "]", "\n", "res", "=", "[", "str", "(", "r", ")", "for", "r", "in", "res", "if", "r", "is", "not", "None", "]", "\n", "res", "=", "'\"'", "+", "'_'", ".", "join", "(", "res", ")", "+", "'\"'", "\n", "\n", "removed", "+=", "len", "(", "res_tok", ")", "\n", "start_search", "=", "lit_end", "\n", "tokens", "+=", "[", "res", ",", "old_tok", "]", "\n", "backreferences", "+=", "[", "-", "1", ",", "-", "1", "]", "\n", "break", "\n", "\n", "", "elif", "old_tok", "==", "'</lit>'", ":", "\n", "                    ", "res_tok", "=", "old_tokens", "[", "lit_start", "+", "1", ":", "lit_end", "]", "\n", "for", "i", "in", "range", "(", "lit_start", ",", "lit_end", "+", "1", ")", ":", "\n", "                        ", "token_to_token_map", "[", "i", "]", "=", "len", "(", "tokens", ")", "\n", "\n", "# Remove possible wrong None", "\n", "", "res", "=", "old_tokens", "[", "lit_start", "+", "1", ":", "lit_end", "]", "\n", "res", "=", "[", "str", "(", "r", ")", "for", "r", "in", "res", "if", "r", "is", "not", "None", "]", "\n", "res", "=", "'\"'", "+", "'_'", ".", "join", "(", "res", ")", "+", "'\"'", "\n", "\n", "removed", "+=", "len", "(", "res_tok", ")", "+", "1", "\n", "start_search", "=", "lit_end", "+", "1", "\n", "tokens", ".", "append", "(", "res", ")", "\n", "backreferences", ".", "append", "(", "-", "1", ")", "\n", "break", "\n", "\n", "", "else", ":", "\n", "                    ", "lit_end", "+=", "1", "\n", "start_search", "=", "lit_end", "\n", "\n", "", "", "", "except", "ValueError", ":", "\n", "            ", "token_addition", "=", "old_tokens", "[", "start_search", ":", "]", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "token_addition", ",", "start", "=", "start_search", ")", ":", "\n", "                ", "token_to_token_map", "[", "i", "]", "=", "i", "-", "removed", "\n", "", "backreferences_addition", "=", "[", "token_to_token_map", "[", "b", "]", "if", "b", ">", "-", "1", "else", "b", "for", "b", "in", "\n", "old_backreferences", "[", "start_search", ":", "]", "]", "\n", "tokens", "+=", "token_addition", "\n", "backreferences", "+=", "backreferences_addition", "\n", "break", "\n", "\n", "", "", "tokens", "=", "[", "token_processing", "(", "t", ")", "for", "t", "in", "tokens", "]", "\n", "\n", "shift", "=", "1", "\n", "if", "tokens", "[", "1", "]", "==", "'<s>'", ":", "\n", "        ", "shift", "=", "2", "\n", "\n", "", "tokens", "=", "tokens", "[", "shift", ":", "]", "\n", "backreferences", "=", "[", "b", "if", "b", "==", "-", "1", "else", "b", "-", "shift", "for", "b", "in", "backreferences", "[", "shift", ":", "]", "]", "\n", "\n", "if", "tokens", "[", "-", "1", "]", "==", "'</s>'", ":", "\n", "        ", "tokens", ".", "pop", "(", ")", "\n", "backreferences", ".", "pop", "(", ")", "\n", "\n", "", "return", "tokens", ",", "backreferences", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.postprocessing.index_of": [[192, 208], ["callable", "len", "postprocessing.index_of.check"], "function", ["None"], ["", "def", "index_of", "(", "element", ",", "iterable", ",", "default", "=", "None", ",", "start", "=", "None", ",", "end", "=", "None", ")", ":", "\n", "    ", "if", "not", "callable", "(", "element", ")", ":", "\n", "        ", "def", "check", "(", "x", ")", ":", "\n", "            ", "return", "element", "==", "x", "\n", "", "", "else", ":", "\n", "        ", "check", "=", "element", "\n", "", "if", "start", "is", "None", ":", "\n", "        ", "start", "=", "0", "\n", "", "if", "end", "is", "None", ":", "\n", "        ", "end", "=", "len", "(", "iterable", ")", "\n", "", "item", "=", "start", "\n", "while", "item", "<", "end", ":", "\n", "        ", "if", "check", "(", "iterable", "[", "item", "]", ")", ":", "\n", "            ", "return", "item", "\n", "", "item", "+=", "1", "\n", "", "return", "default", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.postprocessing.separate_edges_nodes": [[210, 235], ["len", "postprocessing.index_of", "is_arg", "edges.append", "nodes.append", "ret.append", "isinstance", "x.startswith"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.index_of"], ["", "def", "separate_edges_nodes", "(", "edges_nodes_slice", ",", "*", "other", ")", ":", "\n", "    ", "is_arg", "=", "lambda", "x", ":", "isinstance", "(", "x", ",", "str", ")", "and", "x", ".", "startswith", "(", "':'", ")", "\n", "start", "=", "0", "\n", "edges", "=", "[", "]", "\n", "nodes", "=", "[", "]", "\n", "l", "=", "len", "(", "edges_nodes_slice", ")", "\n", "while", "start", "<", "l", ":", "\n", "        ", "edge_index", "=", "index_of", "(", "\n", "is_arg", ",", "\n", "edges_nodes_slice", ",", "\n", "start", "=", "start", ")", "\n", "if", "edge_index", "is", "None", "or", "edge_index", "==", "(", "l", "-", "1", ")", ":", "\n", "            ", "break", "\n", "", "if", "is_arg", "(", "edges_nodes_slice", "[", "edge_index", "+", "1", "]", ")", ":", "\n", "            ", "start", "=", "edge_index", "+", "1", "\n", "continue", "\n", "", "edges", ".", "append", "(", "edge_index", ")", "\n", "nodes", ".", "append", "(", "edge_index", "+", "1", ")", "\n", "start", "=", "edge_index", "+", "2", "\n", "", "ret", "=", "[", "]", "\n", "for", "oth", "in", "other", ":", "\n", "        ", "edges_oth", "=", "[", "oth", "[", "i", "]", "for", "i", "in", "edges", "]", "\n", "nodes_oth", "=", "[", "oth", "[", "i", "]", "for", "i", "in", "nodes", "]", "\n", "ret", ".", "append", "(", "(", "edges_oth", ",", "nodes_oth", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.postprocessing._split_name_ops": [[236, 271], ["enumerate", "collections.defaultdict", "enumerate", "graph.triples.copy", "collections.defaultdict.items", "penman.Graph", "sorted", "zip", "enumerate", "rel.startswith", "name_vars_to_ops[].append", "tt.append", "isinstance", "lit.split", "str", "penman.Triple", "min", "v2.strip", "int"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "_split_name_ops", "(", "graph", ")", ":", "\n", "# identify name triples", "\n", "    ", "name_vars", "=", "{", "}", "\n", "for", "i", ",", "(", "v1", ",", "rel", ",", "v2", ")", "in", "enumerate", "(", "graph", ".", "triples", ")", ":", "\n", "        ", "if", "rel", "==", "':instance'", "and", "v2", "==", "'name'", ":", "\n", "            ", "name_vars", "[", "v1", "]", "=", "1", "\n", "\n", "# check if they have ops", "\n", "", "", "name_vars_to_ops", "=", "defaultdict", "(", "list", ")", "\n", "for", "i", ",", "(", "v1", ",", "rel", ",", "v2", ")", "in", "enumerate", "(", "graph", ".", "triples", ")", ":", "\n", "        ", "if", "v1", "in", "name_vars", "and", "rel", ".", "startswith", "(", "':op'", ")", ":", "\n", "            ", "name_vars_to_ops", "[", "v1", "]", ".", "append", "(", "(", "i", ",", "rel", ",", "v2", ".", "strip", "(", "'\"'", ")", ")", ")", "\n", "\n", "", "", "triples", "=", "graph", ".", "triples", ".", "copy", "(", ")", "\n", "for", "nv", ",", "ops", "in", "name_vars_to_ops", ".", "items", "(", ")", ":", "\n", "        ", "ops", "=", "sorted", "(", "ops", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", "[", "1", "]", "[", "3", ":", "]", ")", ")", "\n", "idx", ",", "_", ",", "lits", "=", "zip", "(", "*", "ops", ")", "\n", "for", "i", "in", "idx", ":", "\n", "            ", "triples", "[", "i", "]", "=", "None", "\n", "\n", "", "lits", "=", "[", "'\"'", "+", "l", "+", "'\"'", "for", "lit", "in", "lits", "for", "l", "in", "lit", ".", "split", "(", "'_'", ")", "]", "\n", "\n", "tt", "=", "[", "]", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "lits", ",", "start", "=", "1", ")", ":", "\n", "            ", "rel", "=", "':op'", "+", "str", "(", "i", ")", "\n", "tt", ".", "append", "(", "penman", ".", "Triple", "(", "nv", ",", "rel", ",", "l", ")", ")", "\n", "\n", "", "triples", "[", "min", "(", "idx", ")", "]", "=", "tt", "\n", "\n", "", "triples", "=", "[", "t", "if", "isinstance", "(", "t", ",", "list", ")", "else", "[", "t", "]", "for", "t", "in", "triples", "if", "t", "is", "not", "None", "]", "\n", "triples", "=", "[", "t", "for", "tt", "in", "triples", "for", "t", "in", "tt", "]", "\n", "\n", "graph_", "=", "penman", ".", "Graph", "(", "triples", ")", "\n", "graph_", ".", "metadata", "=", "graph", ".", "metadata", "\n", "return", "graph_", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.postprocessing._reconstruct_graph_from_nodes": [[272, 390], ["set", "collections.defaultdict", "penman.Graph", "len", "postprocessing.index_of", "list", "isinstance", "postprocessing.separate_edges_nodes", "zip", "range", "str", "src_node[].lower", "penman.Triple", "penman.Triple", "triples.append", "set.add", "isinstance", "n.startswith", "isinstance", "n.startswith", "n.endswith", "triples.append", "set.add", "len", "len", "e.startswith", "e.startswith", "len", "e.startswith", "re.match", "str", "isinstance", "n.startswith", "n.endswith", "len", "n.replace", "n[].lower", "penman.Triple", "n.startswith", "n.endswith", "triples.append", "set.add", "n.endswith", "n.startswith", "n.replace", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.index_of", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.separate_edges_nodes", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["", "def", "_reconstruct_graph_from_nodes", "(", "nodes", ",", "backreferences", ")", ":", "\n", "    ", "triples", "=", "[", "]", "\n", "triples_added", "=", "set", "(", ")", "\n", "\n", "variable2index", "=", "{", "}", "\n", "index2variable", "=", "{", "}", "\n", "start_index", "=", "0", "\n", "\n", "cnt", "=", "defaultdict", "(", "Counter", ")", "\n", "\n", "while", "start_index", "<", "len", "(", "nodes", ")", ":", "\n", "        ", "stop_index", "=", "index_of", "(", "'<stop>'", ",", "nodes", ",", "default", "=", "len", "(", "nodes", ")", "+", "1", ",", "start", "=", "start_index", ")", "\n", "old_start_index", "=", "start_index", "\n", "start_index", "=", "stop_index", "+", "1", "\n", "\n", "src_node", ",", "src_backr", "=", "nodes", "[", "old_start_index", "]", ",", "backreferences", "[", "old_start_index", "]", "\n", "\n", "if", "src_node", "==", "'<stop>'", ":", "\n", "            ", "continue", "\n", "\n", "", "trg_nodes_edges", "=", "nodes", "[", "old_start_index", ":", "stop_index", "]", "\n", "trg_nodes_edges_backr", "=", "backreferences", "[", "old_start_index", ":", "stop_index", "]", "\n", "trg_nodes_edges_indices", "=", "list", "(", "range", "(", "old_start_index", ",", "stop_index", ")", ")", "\n", "\n", "if", "isinstance", "(", "src_node", ",", "str", ")", ":", "\n", "            ", "if", "src_node", "in", "(", "'<s>'", ",", "'</s>'", ",", "'<stop>'", ")", ":", "\n", "                ", "continue", "\n", "", "elif", "(", "'/'", "in", "src_node", ")", "or", "(", "':'", "in", "src_node", ")", "or", "(", "'('", "in", "src_node", ")", "or", "(", "')'", "in", "src_node", ")", ":", "\n", "                ", "src_node", "=", "'thing'", "\n", "\n", "", "", "if", "src_node", "is", "not", "None", ":", "\n", "            ", "src_node", "=", "str", "(", "src_node", ")", "\n", "src_var", "=", "src_node", "[", "0", "]", ".", "lower", "(", ")", "\n", "if", "not", "src_var", "not", "in", "'abcdefghijklmnopqrstuvwxyz'", ":", "\n", "                ", "src_var", "=", "'x'", "\n", "#src_var = f'{src_var}_{len(variable2index)}'", "\n", "", "src_var", "=", "f'{src_var}{len(variable2index)}'", "\n", "src_var_i", "=", "old_start_index", "\n", "variable2index", "[", "src_var", "]", "=", "src_var_i", "\n", "index2variable", "[", "src_var_i", "]", "=", "src_var", "\n", "triple", "=", "penman", ".", "Triple", "(", "src_var", ",", "':instance'", ",", "src_node", ")", "\n", "if", "triple", "not", "in", "triples_added", ":", "\n", "                ", "triples", ".", "append", "(", "triple", ")", "\n", "triples_added", ".", "add", "(", "triple", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "src_backr", "in", "index2variable", ":", "\n", "                ", "src_var", "=", "index2variable", "[", "src_backr", "]", "\n", "# more resilient logic here", "\n", "", "", "(", "trg_edges", ",", "trg_nodes", ")", ",", "(", "_", ",", "trg_nodes_backr", ")", ",", "(", "_", ",", "trg_nodes_indices", ")", "=", "separate_edges_nodes", "(", "\n", "trg_nodes_edges", ",", "\n", "trg_nodes_edges", ",", "\n", "trg_nodes_edges_backr", ",", "\n", "trg_nodes_edges_indices", ")", "\n", "\n", "for", "n", ",", "e", ",", "nb", ",", "ni", "in", "zip", "(", "trg_nodes", ",", "trg_edges", ",", "trg_nodes_backr", ",", "trg_nodes_indices", ")", ":", "\n", "\n", "            ", "if", "isinstance", "(", "n", ",", "str", ")", "and", "n", ".", "startswith", "(", "':'", ")", ":", "\n", "                ", "continue", "\n", "", "if", "isinstance", "(", "n", ",", "str", ")", "and", "n", ".", "startswith", "(", "'<'", ")", "and", "n", ".", "endswith", "(", "'>'", ")", ":", "\n", "                ", "continue", "\n", "", "if", "e", "==", "':li'", ":", "\n", "                ", "pass", "\n", "", "elif", "len", "(", "e", ")", "<", "4", "or", "(", "not", "e", ".", "startswith", "(", "':'", ")", ")", ":", "\n", "                ", "continue", "\n", "\n", "# same edge more than once", "\n", "", "num", "=", "cnt", "[", "src_var", "]", "[", "e", "]", "\n", "# num = 0", "\n", "if", "num", ":", "\n", "\n", "                ", "if", "e", ".", "startswith", "(", "':op'", ")", "or", "e", ".", "startswith", "(", "':snt'", ")", ":", "\n", "                    ", "continue", "\n", "#elif e.startswith(':ARG'):", "\n", "#    continue", "\n", "", "elif", "num", ">", "3", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "if", "n", "is", "None", ":", "\n", "                ", "if", "nb", "not", "in", "index2variable", ":", "\n", "                    ", "continue", "\n", "", "trg_var", "=", "index2variable", "[", "nb", "]", "\n", "trg", "=", "trg_var", "\n", "", "elif", "e", "==", "':mode'", ":", "\n", "                ", "trg", "=", "n", "\n", "", "elif", "(", "not", "isinstance", "(", "n", ",", "str", ")", ")", "or", "re", ".", "match", "(", "r\"^[+-]?\\d+\\.?\\d*$\"", ",", "n", ")", "or", "(", "n", "==", "'-'", ")", "or", "(", "n", "==", "'+'", ")", ":", "\n", "                ", "trg", "=", "str", "(", "n", ")", "\n", "", "elif", "(", "n", ".", "startswith", "(", "'\"'", ")", "and", "n", ".", "endswith", "(", "'\"'", ")", "and", "len", "(", "n", ")", ">", "2", ")", ":", "\n", "                ", "trg", "=", "'\"'", "+", "n", ".", "replace", "(", "'\"'", ",", "''", ")", "+", "'\"'", "\n", "", "elif", "(", "'/'", "in", "n", ")", "or", "(", "':'", "in", "n", ")", "or", "(", "'('", "in", "n", ")", "or", "(", "')'", "in", "n", ")", "or", "(", "'='", "in", "n", ")", ":", "\n", "                ", "trg", "=", "f'\"{n}\"'", "\n", "", "elif", "n", "==", "'\"'", ":", "\n", "                ", "continue", "\n", "", "elif", "(", "n", ".", "startswith", "(", "'\"'", ")", "and", "(", "not", "n", ".", "endswith", "(", "'\"'", ")", ")", ")", "or", "(", "not", "n", ".", "startswith", "(", "'\"'", ")", "and", "(", "n", ".", "endswith", "(", "'\"'", ")", ")", ")", "or", "(", "'\"'", "in", "n", ")", ":", "\n", "                ", "trg", "=", "'\"'", "+", "n", ".", "replace", "(", "'\"'", ",", "''", ")", "+", "'\"'", "\n", "", "else", ":", "\n", "                ", "trg_var", "=", "n", "[", "0", "]", ".", "lower", "(", ")", "\n", "if", "trg_var", "not", "in", "'abcdefghijklmnopqrstuvwxyz'", ":", "\n", "                    ", "trg_var", "=", "'x'", "\n", "#trg_var = f'{trg_var}_{len(variable2index)}'", "\n", "", "trg_var", "=", "f'{trg_var}{len(variable2index)}'", "\n", "trg_var_i", "=", "ni", "\n", "variable2index", "[", "trg_var", "]", "=", "trg_var_i", "\n", "index2variable", "[", "trg_var_i", "]", "=", "trg_var", "\n", "triple", "=", "penman", ".", "Triple", "(", "trg_var", ",", "':instance'", ",", "n", ")", "\n", "if", "triple", "not", "in", "triples_added", ":", "\n", "                    ", "triples", ".", "append", "(", "triple", ")", "\n", "triples_added", ".", "add", "(", "triple", ")", "\n", "", "trg", "=", "trg_var", "\n", "\n", "", "triple", "=", "penman", ".", "Triple", "(", "src_var", ",", "e", ",", "trg", ")", "\n", "if", "triple", "not", "in", "triples_added", ":", "\n", "                ", "triples", ".", "append", "(", "triple", ")", "\n", "triples_added", ".", "add", "(", "triple", ")", "\n", "\n", "", "cnt", "[", "src_var", "]", "[", "e", "]", "+=", "1", "\n", "\n", "", "", "return", "penman", ".", "Graph", "(", "triples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.postprocessing.build_graph": [[391, 396], ["postprocessing._reconstruct_graph_from_nodes", "postprocessing._split_name_ops"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing._reconstruct_graph_from_nodes", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing._split_name_ops"], ["", "def", "build_graph", "(", "nodes", ",", "backreferences", ",", "restore_name_ops", "=", "False", ")", ":", "\n", "    ", "graph", "=", "_reconstruct_graph_from_nodes", "(", "nodes", ",", "backreferences", ")", "\n", "if", "restore_name_ops", ":", "\n", "        ", "graph", "=", "_split_name_ops", "(", "graph", ")", "\n", "", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.postprocessing.connect_graph_if_not_connected": [[402, 435], ["networkx.MultiGraph", "penman.Graph.variables", "penman.Graph.triples.copy", "graph.triples.copy.append", "enumerate", "penman.Graph", "penman.Graph.metadata.update", "spring_amr.c_penman.encode", "spring_amr.c_penman.encode", "penman.Triple", "networkx.connected_components", "sorted", "new_triples.append", "nx.MultiGraph.add_edge", "penman.Triple", "nx.MultiGraph.add_edge", "len", "int"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.SemanticGraph.variables", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode"], ["", "def", "connect_graph_if_not_connected", "(", "graph", ")", ":", "\n", "\n", "    ", "try", ":", "\n", "        ", "encoded", "=", "encode", "(", "graph", ")", "\n", "return", "graph", ",", "ParsedStatus", ".", "OK", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "\n", "", "nxgraph", "=", "nx", ".", "MultiGraph", "(", ")", "\n", "variables", "=", "graph", ".", "variables", "(", ")", "\n", "for", "v1", ",", "_", ",", "v2", "in", "graph", ".", "triples", ":", "\n", "        ", "if", "v1", "in", "variables", "and", "v2", "in", "variables", ":", "\n", "            ", "nxgraph", ".", "add_edge", "(", "v1", ",", "v2", ")", "\n", "", "elif", "v1", "in", "variables", ":", "\n", "            ", "nxgraph", ".", "add_edge", "(", "v1", ",", "v1", ")", "\n", "\n", "", "", "triples", "=", "graph", ".", "triples", ".", "copy", "(", ")", "\n", "new_triples", "=", "[", "]", "\n", "addition", "=", "f'a{len(variables) + 1}'", "\n", "triples", ".", "append", "(", "penman", ".", "Triple", "(", "addition", ",", "':instance'", ",", "'and'", ")", ")", "\n", "for", "i", ",", "conn_set", "in", "enumerate", "(", "nx", ".", "connected_components", "(", "nxgraph", ")", ",", "start", "=", "1", ")", ":", "\n", "        ", "edge", "=", "f':op{i}'", "\n", "conn_set", "=", "sorted", "(", "conn_set", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", "[", "1", ":", "]", ")", ")", "\n", "conn_set", "=", "[", "c", "for", "c", "in", "conn_set", "if", "c", "in", "variables", "]", "\n", "node", "=", "conn_set", "[", "0", "]", "\n", "new_triples", ".", "append", "(", "penman", ".", "Triple", "(", "addition", ",", "edge", ",", "node", ")", ")", "\n", "", "triples", "=", "new_triples", "+", "triples", "\n", "metadata", "=", "graph", ".", "metadata", "\n", "graph", "=", "penman", ".", "Graph", "(", "triples", ")", "\n", "graph", ".", "metadata", ".", "update", "(", "metadata", ")", "\n", "encode", "(", "graph", ")", "\n", "\n", "return", "graph", ",", "ParsedStatus", ".", "FIXED", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.postprocessing.restore_backreferences_from_pointers": [[436, 463], ["isinstance", "n.startswith", "n.endswith", "new_nodes.append", "new_backreferences.append", "new_nodes.append", "new_backreferences.append", "new_nodes.append", "new_backreferences.append", "len", "new_nodes.append", "new_backreferences.append"], "function", ["None"], ["", "def", "restore_backreferences_from_pointers", "(", "nodes", ")", ":", "\n", "    ", "new_nodes", ",", "new_backreferences", "=", "[", "]", ",", "[", "]", "\n", "prev_pointer", "=", "None", "\n", "pointer2i", "=", "{", "}", "\n", "for", "n", "in", "nodes", ":", "\n", "        ", "is_pointer", "=", "isinstance", "(", "n", ",", "str", ")", "and", "n", ".", "startswith", "(", "'<pointer:'", ")", "and", "n", ".", "endswith", "(", "'>'", ")", "\n", "\n", "if", "not", "is_pointer", ":", "\n", "            ", "if", "prev_pointer", "is", "not", "None", ":", "\n", "                ", "if", "prev_pointer", "in", "pointer2i", ":", "\n", "                    ", "new_nodes", ".", "append", "(", "None", ")", "\n", "new_backreferences", ".", "append", "(", "pointer2i", "[", "prev_pointer", "]", ")", "\n", "new_nodes", ".", "append", "(", "n", ")", "\n", "new_backreferences", ".", "append", "(", "-", "1", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "pointer2i", "[", "prev_pointer", "]", "=", "len", "(", "new_nodes", ")", "\n", "new_nodes", ".", "append", "(", "n", ")", "\n", "new_backreferences", ".", "append", "(", "-", "1", ")", "\n", "", "", "else", ":", "\n", "                ", "new_nodes", ".", "append", "(", "n", ")", "\n", "new_backreferences", ".", "append", "(", "-", "1", ")", "\n", "\n", "", "prev_pointer", "=", "None", "\n", "", "else", ":", "\n", "            ", "prev_pointer", "=", "n", "\n", "", "", "return", "new_nodes", ",", "new_backreferences", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils_new.init_AMRization_tokenizer": [[21, 23], ["utils_new.AMRization_Tokenizer"], "function", ["None"], ["", "def", "init_AMRization_tokenizer", "(", ")", ":", "\n", "    ", "return", "AMRization_Tokenizer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils_new.init_AMRization_model": [[24, 54], ["transformers.AutoConfig.from_pretrained", "transformers.models.bart.BartForConditionalGeneration.from_pretrained", "transformers.models.bart.BartForConditionalGeneration"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained"], ["", "def", "init_AMRization_model", "(", "name", ",", "checkpoint", ",", "dropout", ",", "attention_dropout", ",", "tokenizer", ",", "from_pretrained", "=", "True", ")", ":", "\n", "    ", "if", "name", "is", "None", ":", "\n", "        ", "name", "=", "'facebook/bart-large'", "\n", "\n", "", "if", "name", "==", "'facebook/bart-base'", ":", "\n", "        ", "tokenizer_name", "=", "'facebook/bart-large'", "\n", "", "else", ":", "\n", "        ", "tokenizer_name", "=", "name", "\n", "\n", "", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "name", ")", "\n", "config", ".", "output_past", "=", "False", "\n", "config", ".", "no_repeat_ngram_size", "=", "0", "\n", "config", ".", "prefix", "=", "\" \"", "\n", "config", ".", "output_attentions", "=", "True", "\n", "config", ".", "dropout", "=", "dropout", "\n", "config", ".", "attention_dropout", "=", "attention_dropout", "\n", "\n", "if", "from_pretrained", ":", "\n", "        ", "model", "=", "BartForConditionalGeneration", ".", "from_pretrained", "(", "name", ",", "config", "=", "config", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "BartForConditionalGeneration", "(", "config", ")", "\n", "\n", "# model.resize_token_embeddings(55555)", "\n", "#The number of new tokens in the embedding matrix. ", "\n", "#Increasing the size will add newly initialized vectors at the end.", "\n", "#Reducing the size will remove vectors from the end. ", "\n", "\n", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart_new.AMRizationBartEncoder.__init__": [[22, 47], ["torch.nn.Module.__init__", "BartLearnedPositionalEmbedding", "torch.nn.ModuleList", "torch.nn.LayerNorm", "modeling_bart_new.AMRizationBartEncoder.init_weights", "math.sqrt", "torch.nn.Embedding", "BartEncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.Embedding"], ["def", "__init__", "(", "self", ",", "config", ":", "bart", ".", "BartConfig", ",", "embed_tokens", ":", "Optional", "[", "nn", ".", "Embedding", "]", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "layerdrop", "=", "config", ".", "encoder_layerdrop", "\n", "\n", "embed_dim", "=", "config", ".", "d_model", "\n", "self", ".", "padding_idx", "=", "config", ".", "pad_token_id", "\n", "self", ".", "max_source_positions", "=", "config", ".", "max_position_embeddings", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_dim", ")", "if", "config", ".", "scale_embedding", "else", "1.0", "\n", "\n", "if", "embed_tokens", "is", "not", "None", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "", "else", ":", "\n", "            ", "self", ".", "embed_tokens", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "embed_dim", ",", "self", ".", "padding_idx", ")", "\n", "\n", "", "self", ".", "embed_positions", "=", "BartLearnedPositionalEmbedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "\n", "embed_dim", ",", "\n", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "BartEncoderLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "encoder_layers", ")", "]", ")", "\n", "self", ".", "layernorm_embedding", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "gradient_checkpointing", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart_new.AMRizationBartEncoder.get_input_embeddings": [[48, 50], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embed_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart_new.AMRizationBartEncoder.set_input_embeddings": [[51, 53], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "embed_tokens", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart_new.AMRizationBartEncoder.forward": [[54, 182], ["modeling_bart_new.AMRizationBartEncoder.embed_positions", "modeling_bart_new.AMRizationBartEncoder.layernorm_embedding", "torch.nn.functional.dropout", "enumerate", "BaseModelOutput", "ValueError", "_expand_mask", "random.uniform", "tuple", "input_ids.view.view.size", "input_ids.view.view.view", "modeling_bart_new.AMRizationBartEncoder.embed_tokens", "len", "ValueError", "head_mask.size", "len", "torch.utils.checkpoint.checkpoint", "encoder_layer", "inputs_embeds.size", "head_mask.size", "modeling_bart_new.AMRizationBartEncoder.forward.create_custom_forward"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "output_attentions", "=", "None", ",", "\n", "output_hidden_states", "=", "None", ",", "\n", "return_dict", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        Args:\n            input_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`):\n                Indices of input sequence tokens in the vocabulary. Padding will be ignored by default should you\n                provide it.\n\n                Indices can be obtained using :class:`~transformers.BartTokenizer`. See\n                :meth:`transformers.PreTrainedTokenizer.encode` and :meth:`transformers.PreTrainedTokenizer.__call__`\n                for details.\n\n                `What are input IDs? <../glossary.html#input-ids>`__\n            attention_mask (:obj:`torch.Tensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\n                Mask to avoid performing attention on padding token indices. Mask values selected in ``[0, 1]``:\n\n                - 1 for tokens that are **not masked**,\n                - 0 for tokens that are **masked**.\n\n                `What are attention masks? <../glossary.html#attention-mask>`__\n            head_mask (:obj:`torch.Tensor` of shape :obj:`(encoder_layers, encoder_attention_heads)`, `optional`):\n                Mask to nullify selected heads of the attention modules. Mask values selected in ``[0, 1]``:\n\n                - 1 indicates the head is **not masked**,\n                - 0 indicates the head is **masked**.\n\n            inputs_embeds (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`, `optional`):\n                Optionally, instead of passing :obj:`input_ids` you can choose to directly pass an embedded\n                representation. This is useful if you want more control over how to convert :obj:`input_ids` indices\n                into associated vectors than the model's internal embedding lookup matrix.\n            output_attentions (:obj:`bool`, `optional`):\n                Whether or not to return the attentions tensors of all attention layers. See ``attentions`` under\n                returned tensors for more detail.\n            output_hidden_states (:obj:`bool`, `optional`):\n                Whether or not to return the hidden states of all layers. See ``hidden_states`` under returned tensors\n                for more detail.\n            return_dict (:obj:`bool`, `optional`):\n                Whether or not to return a :class:`~transformers.file_utils.ModelOutput` instead of a plain tuple.\n        \"\"\"", "\n", "output_attentions", "=", "output_attentions", "if", "output_attentions", "is", "not", "None", "else", "self", ".", "config", ".", "output_attentions", "\n", "output_hidden_states", "=", "(", "\n", "output_hidden_states", "if", "output_hidden_states", "is", "not", "None", "else", "self", ".", "config", ".", "output_hidden_states", "\n", ")", "\n", "return_dict", "=", "return_dict", "if", "return_dict", "is", "not", "None", "else", "self", ".", "config", ".", "use_return_dict", "\n", "\n", "# retrieve input_ids and inputs_embeds", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "embed_tokens", "(", "input_ids", ")", "*", "self", ".", "embed_scale", "\n", "\n", "", "embed_pos", "=", "self", ".", "embed_positions", "(", "input_shape", ")", "\n", "\n", "hidden_states", "=", "inputs_embeds", "+", "embed_pos", "\n", "hidden_states", "=", "self", ".", "layernorm_embedding", "(", "hidden_states", ")", "\n", "hidden_states", "=", "nn", ".", "functional", ".", "dropout", "(", "hidden_states", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# expand attention_mask", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# [bsz, seq_len] -> [bsz, 1, tgt_seq_len, src_seq_len]", "\n", "            ", "attention_mask", "=", "_expand_mask", "(", "attention_mask", ",", "inputs_embeds", ".", "dtype", ")", "\n", "\n", "", "encoder_states", "=", "(", ")", "if", "output_hidden_states", "else", "None", "\n", "all_attentions", "=", "(", ")", "if", "output_attentions", "else", "None", "\n", "\n", "# check if head_mask has a correct number of layers specified if desired", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "assert", "head_mask", ".", "size", "(", ")", "[", "0", "]", "==", "(", "\n", "len", "(", "self", ".", "layers", ")", "\n", ")", ",", "f\"The head_mask should be specified for {len(self.layers)} layers, but it is for {head_mask.size()[0]}.\"", "\n", "", "for", "idx", ",", "encoder_layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "if", "output_hidden_states", ":", "\n", "                ", "encoder_states", "=", "encoder_states", "+", "(", "hidden_states", ",", ")", "\n", "# add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)", "\n", "", "dropout_probability", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "training", "and", "(", "dropout_probability", "<", "self", ".", "layerdrop", ")", ":", "# skip the layer", "\n", "                ", "layer_outputs", "=", "(", "None", ",", "None", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "gradient_checkpointing", "and", "self", ".", "training", ":", "\n", "\n", "                    ", "def", "create_custom_forward", "(", "module", ")", ":", "\n", "                        ", "def", "custom_forward", "(", "*", "inputs", ")", ":", "\n", "                            ", "return", "module", "(", "*", "inputs", ",", "output_attentions", ")", "\n", "\n", "", "return", "custom_forward", "\n", "\n", "", "layer_outputs", "=", "torch", ".", "utils", ".", "checkpoint", ".", "checkpoint", "(", "\n", "create_custom_forward", "(", "encoder_layer", ")", ",", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "(", "head_mask", "[", "idx", "]", "if", "head_mask", "is", "not", "None", "else", "None", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "layer_outputs", "=", "encoder_layer", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "layer_head_mask", "=", "(", "head_mask", "[", "idx", "]", "if", "head_mask", "is", "not", "None", "else", "None", ")", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", ")", "\n", "\n", "", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "", "if", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "\n", "", "", "if", "output_hidden_states", ":", "\n", "            ", "encoder_states", "=", "encoder_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "if", "not", "return_dict", ":", "\n", "            ", "return", "tuple", "(", "v", "for", "v", "in", "[", "hidden_states", ",", "encoder_states", ",", "all_attentions", "]", "if", "v", "is", "not", "None", ")", "\n", "", "return", "BaseModelOutput", "(", "\n", "last_hidden_state", "=", "hidden_states", ",", "hidden_states", "=", "encoder_states", ",", "attentions", "=", "all_attentions", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartEncoder.__init__": [[35, 65], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "math.sqrt", "transformers.modeling_bart.SinusoidalPositionalEmbedding", "transformers.modeling_bart.LearnedPositionalEmbedding", "transformers.modeling_bart.LayerNorm", "torch.nn.Identity", "transformers.modeling_bart.LayerNorm", "transformers.modeling_bart.EncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "bart", ".", "BartConfig", ",", "embed_tokens", ",", "backpointer_idx", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "backpointer_idx", "=", "backpointer_idx", "\n", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "layerdrop", "=", "config", ".", "encoder_layerdrop", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "embed_dim", "=", "embed_tokens", ".", "embedding_dim", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_dim", ")", "if", "config", ".", "scale_embedding", "else", "1.0", "\n", "self", ".", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "self", ".", "max_source_positions", "=", "config", ".", "max_position_embeddings", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "\n", "if", "config", ".", "static_position_embeddings", ":", "\n", "            ", "self", ".", "embed_positions", "=", "bart", ".", "SinusoidalPositionalEmbedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "embed_dim", ",", "self", ".", "padding_idx", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embed_positions", "=", "bart", ".", "LearnedPositionalEmbedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "embed_dim", ",", "self", ".", "padding_idx", ",", "#config.extra_pos_embeddings,", "\n", ")", "\n", "\n", "", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "bart", ".", "EncoderLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "encoder_layers", ")", "]", ")", "\n", "self", ".", "layernorm_embedding", "=", "bart", ".", "LayerNorm", "(", "embed_dim", ")", "if", "config", ".", "normalize_embedding", "else", "nn", ".", "Identity", "(", ")", "\n", "# mbart has one extra layer_norm", "\n", "self", ".", "layer_norm", "=", "bart", ".", "LayerNorm", "(", "config", ".", "d_model", ")", "if", "config", ".", "normalize_before", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartEncoder.forward": [[67, 128], ["modeling_bart.extract_backreferences", "transformers.modeling_bart.AMRBartEncoder.embed_positions", "transformers.modeling_bart.AMRBartEncoder.layernorm_embedding", "torch.nn.functional.dropout", "transformers.modeling_bart.AMRBartEncoder.transpose", "transformers.modeling_bart.AMRBartEncoder.transpose", "transformers.modeling_bart.invert_mask", "transformers.modeling_bart.AMRBartEncoder.embed_tokens", "random.uniform", "transformers.modeling_bart.AMRBartEncoder.layer_norm", "encoder_states.append", "hidden_state.transpose", "encoder_states.append", "encoder_layer", "all_attentions.append"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.extract_backreferences"], ["", "def", "forward", "(", "\n", "self", ",", "input_ids", ",", "embedded", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            input_ids (LongTensor): tokens in the source language of shape\n                `(batch, src_len)`\n            attention_mask (torch.LongTensor): indicating which indices are padding tokens.\n        Returns:\n            Tuple comprised of:\n                - **x** (Tensor): the last encoder layer's output of\n                  shape `(src_len, batch, embed_dim)`\n                - **encoder_states** (List[Tensor]): all intermediate\n                  hidden states of shape `(src_len, batch, embed_dim)`.\n                  Only populated if *self.output_hidden_states:* is True.\n                - **all_attentions** (List[Tensor]): Attention weights for each layer.\n                During training might not be of length n_layers because of layer dropout.\n        \"\"\"", "\n", "# check attention mask and invert", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "attention_mask", "=", "bart", ".", "invert_mask", "(", "attention_mask", ")", "\n", "\n", "", "input_ids", ",", "backreferences", "=", "extract_backreferences", "(", "\n", "input_ids", ",", "self", ".", "embed_tokens", ".", "num_embeddings", ",", "self", ".", "backpointer_idx", ")", "\n", "inputs_embeds", "=", "self", ".", "embed_tokens", "(", "input_ids", ")", "*", "self", ".", "embed_scale", "\n", "embed_pos", "=", "self", ".", "embed_positions", "(", "input_ids", ")", "\n", "x", "=", "inputs_embeds", "+", "embed_pos", "\n", "\n", "if", "embedded", "is", "not", "None", ":", "\n", "            ", "x", "+=", "embedded", "\n", "\n", "", "x", "=", "self", ".", "layernorm_embedding", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# B x T x C -> T x B x C", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "encoder_states", ",", "all_attentions", "=", "[", "]", ",", "[", "]", "\n", "for", "encoder_layer", "in", "self", ".", "layers", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "encoder_states", ".", "append", "(", "x", ")", "\n", "# add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)", "\n", "", "dropout_probability", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "training", "and", "(", "dropout_probability", "<", "self", ".", "layerdrop", ")", ":", "# skip the layer", "\n", "                ", "attn", "=", "None", "\n", "", "else", ":", "\n", "                ", "x", ",", "attn", "=", "encoder_layer", "(", "x", ",", "attention_mask", ")", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "attn", ")", "\n", "\n", "", "", "if", "self", ".", "layer_norm", ":", "\n", "            ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "encoder_states", ".", "append", "(", "x", ")", "\n", "\n", "# T x B x C -> B x T x C", "\n", "", "encoder_states", "=", "[", "hidden_state", ".", "transpose", "(", "0", ",", "1", ")", "for", "hidden_state", "in", "encoder_states", "]", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "return", "x", ",", "encoder_states", ",", "all_attentions", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartDecoder.__init__": [[138, 185], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.Linear", "torch.nn.Linear", "math.sqrt", "transformers.modeling_bart.SinusoidalPositionalEmbedding", "transformers.modeling_bart.LearnedPositionalEmbedding", "transformers.modeling_bart.LayerNorm", "torch.nn.Identity", "transformers.modeling_bart.LayerNorm", "transformers.modeling_bart.DecoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "bart", ".", "BartConfig", ",", "embed_tokens", ":", "nn", ".", "Embedding", ",", "backpointer_idx", ",", "amr_mode", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "layerdrop", "=", "config", ".", "decoder_layerdrop", "\n", "self", ".", "padding_idx", "=", "embed_tokens", ".", "padding_idx", "\n", "self", ".", "max_target_positions", "=", "config", ".", "max_position_embeddings", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "config", ".", "d_model", ")", "if", "config", ".", "scale_embedding", "else", "1.0", "\n", "self", ".", "backpointer_idx", "=", "backpointer_idx", "\n", "\n", "embed_dim", "=", "embed_tokens", ".", "embedding_dim", "\n", "\n", "self", ".", "embed_tokens", "=", "embed_tokens", "\n", "if", "config", ".", "static_position_embeddings", ":", "\n", "            ", "self", ".", "embed_positions", "=", "bart", ".", "SinusoidalPositionalEmbedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "embed_dim", ",", "self", ".", "padding_idx", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embed_positions", "=", "bart", ".", "LearnedPositionalEmbedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "embed_dim", ",", "self", ".", "padding_idx", ",", "#config.extra_pos_embeddings,", "\n", ")", "\n", "\n", "", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "\n", "[", "bart", ".", "DecoderLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "decoder_layers", ")", "]", "\n", ")", "# type: List[DecoderLayer]", "\n", "self", ".", "layernorm_embedding", "=", "bart", ".", "LayerNorm", "(", "config", ".", "d_model", ")", "if", "config", ".", "normalize_embedding", "else", "nn", ".", "Identity", "(", ")", "\n", "self", ".", "layer_norm", "=", "bart", ".", "LayerNorm", "(", "config", ".", "d_model", ")", "if", "config", ".", "add_final_layer_norm", "else", "None", "\n", "\n", "self", ".", "pointer_k", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "d_model", ")", "\n", "# self.pointer_k.weight.data = self.layers[-1].self_attn.k_proj.weight.data.clone()", "\n", "\n", "self", ".", "pointer_q", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "d_model", ")", "\n", "# self.pointer_q.weight.data = self.layers[-1].self_attn.q_proj.weight.data.clone()", "\n", "\n", "# self.pointer_k = nn.Sequential(", "\n", "#     nn.Linear(config.d_model, config.decoder_ffn_dim),", "\n", "#     nn.GELU(),", "\n", "#     nn.Linear(config.decoder_ffn_dim, config.d_model),", "\n", "# )", "\n", "# self.pointer_q = nn.Sequential(", "\n", "#     nn.Linear(config.d_model, config.decoder_ffn_dim),", "\n", "#     nn.GELU(),", "\n", "#     nn.Linear(config.decoder_ffn_dim, config.d_model),", "\n", "# )", "\n", "\n", "self", ".", "amr_mode", "=", "amr_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartDecoder.forward": [[186, 310], ["modeling_bart.extract_backreferences", "transformers.modeling_bart.AMRBartDecoder.embed_positions", "transformers.modeling_bart.AMRBartDecoder.layernorm_embedding", "torch.nn.functional.dropout", "transformers.modeling_bart.AMRBartDecoder.transpose", "encoder_hidden_states.transpose.transpose.transpose", "enumerate", "transformers.modeling_bart.AMRBartDecoder.transpose", "encoder_hidden_states.transpose.transpose.transpose", "transformers.modeling_bart.AMRBartDecoder.pointer_q", "transformers.modeling_bart.AMRBartDecoder.pointer_k", "transformers.modeling_bart.invert_mask", "transformers.modeling_bart.AMRBartDecoder.embed_tokens", "random.uniform", "decoder_layer", "hidden_state.transpose", "next_decoder_cache.append", "torch.einsum", "mask.triu.triu.unsqueeze", "torch.full", "list", "next_decoder_cache.append", "transformers.modeling_bart.AMRBartDecoder.layer_norm", "decoder_cached_states[].get", "torch.cat", "torch.full_like", "mask.triu.triu.triu", "torch.full_like", "mask.triu.triu.triu", "float", "layer_past.copy", "float", "float", "transformers.modeling_bart.AMRBartDecoder.size", "transformers.modeling_bart.AMRBartDecoder.size", "torch.cat.size", "len", "torch.cat.size"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.extract_backreferences", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_padding_mask", ",", "\n", "decoder_padding_mask", ",", "\n", "decoder_causal_mask", ",", "\n", "decoder_cached_states", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", "**", "unused", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Includes several features from \"Jointly Learning to Align and\n        Translate with Transformer Models\" (Garg et al., EMNLP 2019).\n\n        Args:\n            input_ids (LongTensor): previous decoder outputs of shape\n                `(batch, tgt_len)`, for teacher forcing\n            encoder_hidden_states: output from the encoder, used for\n                encoder-side attention\n            encoder_padding_mask: for ignoring pad tokens\n            decoder_cached_states (dict or None): dictionary used for storing state during generation\n\n        Returns:\n            tuple:\n                - the decoder's features of shape `(batch, tgt_len, embed_dim)`\n                - hidden states\n                - attentions\n        \"\"\"", "\n", "\n", "# check attention mask and invert", "\n", "if", "encoder_padding_mask", "is", "not", "None", ":", "\n", "            ", "encoder_padding_mask", "=", "bart", ".", "invert_mask", "(", "encoder_padding_mask", ")", "\n", "\n", "", "input_ids", ",", "backreferences", "=", "extract_backreferences", "(", "\n", "input_ids", ",", "\n", "self", ".", "embed_tokens", ".", "num_embeddings", ",", "\n", "self", ".", "backpointer_idx", ")", "\n", "# embed positions", "\n", "embed_pos", "=", "self", ".", "embed_positions", "(", "input_ids", ",", "use_cache", "=", "use_cache", ")", "\n", "positions", "=", "embed_pos", "\n", "\n", "# to do this during prediction the old positions should be removed", "\n", "if", "use_cache", ":", "\n", "            ", "input_ids", "=", "input_ids", "[", ":", ",", "-", "1", ":", "]", "\n", "positions", "=", "positions", "[", ":", ",", "-", "1", ":", "]", "# happens after we embed them", "\n", "# assert input_ids.ne(self.padding_idx).any()", "\n", "\n", "", "x", "=", "self", ".", "embed_tokens", "(", "input_ids", ")", "*", "self", ".", "embed_scale", "\n", "x", "+=", "positions", "\n", "x", "=", "self", ".", "layernorm_embedding", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "# Convert to Bart output format: (seq_len, BS, model_dim) -> (BS, seq_len, model_dim)", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "# decoder layers", "\n", "all_hidden_states", "=", "(", ")", "\n", "all_self_attns", "=", "(", ")", "\n", "next_decoder_cache", "=", "[", "]", "\n", "for", "idx", ",", "decoder_layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "# add LayerDrop (see https://arxiv.org/abs/1909.11556 for description)", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "+=", "(", "x", ",", ")", "\n", "", "dropout_probability", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "training", "and", "(", "dropout_probability", "<", "self", ".", "layerdrop", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "layer_state", "=", "decoder_cached_states", "[", "idx", "]", "if", "decoder_cached_states", "is", "not", "None", "else", "None", "\n", "\n", "x", ",", "layer_self_attn", ",", "layer_past", "=", "decoder_layer", "(", "\n", "x", ",", "\n", "encoder_hidden_states", ",", "\n", "encoder_attn_mask", "=", "encoder_padding_mask", ",", "\n", "decoder_padding_mask", "=", "decoder_padding_mask", ",", "\n", "layer_state", "=", "layer_state", ",", "\n", "causal_mask", "=", "decoder_causal_mask", ",", "\n", ")", "\n", "\n", "if", "use_cache", ":", "\n", "                ", "next_decoder_cache", ".", "append", "(", "layer_past", ".", "copy", "(", ")", ")", "\n", "\n", "", "if", "self", ".", "layer_norm", "and", "(", "idx", "==", "len", "(", "self", ".", "layers", ")", "-", "1", ")", ":", "# last layer of mbart", "\n", "                ", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_self_attns", "+=", "(", "layer_self_attn", ",", ")", "\n", "\n", "# Convert to standard output format: (seq_len, BS, model_dim) -> (BS, seq_len, model_dim)", "\n", "", "", "all_hidden_states", "=", "[", "hidden_state", ".", "transpose", "(", "0", ",", "1", ")", "for", "hidden_state", "in", "all_hidden_states", "]", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "xq", "=", "self", ".", "pointer_q", "(", "x", ")", "\n", "xk", "=", "self", ".", "pointer_k", "(", "x", ")", "\n", "\n", "if", "decoder_cached_states", "is", "not", "None", ":", "\n", "            ", "if", "'prev_key'", "in", "decoder_cached_states", "[", "-", "1", "]", ".", "get", "(", "'pointer'", ",", "{", "}", ")", ":", "\n", "                ", "last_state", "=", "decoder_cached_states", "[", "-", "1", "]", "[", "'pointer'", "]", "\n", "xk", "=", "torch", ".", "cat", "(", "[", "last_state", "[", "'prev_key'", "]", ",", "xk", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "", "next_state", "=", "{", "'pointer'", ":", "{", "'prev_key'", ":", "xk", "}", "}", "\n", "\n", "if", "use_cache", ":", "\n", "            ", "next_decoder_cache", ".", "append", "(", "next_state", ")", "\n", "\n", "", "if", "self", ".", "amr_mode", ":", "\n", "            ", "scores", "=", "torch", ".", "einsum", "(", "'bqh,bkh->bqk'", ",", "xq", ",", "xk", ")", "\n", "\n", "if", "decoder_cached_states", ":", "\n", "                ", "mask", "=", "torch", ".", "full_like", "(", "scores", "[", "0", "]", ",", "float", "(", "'-inf'", ")", ")", "\n", "mask", "=", "mask", ".", "triu", "(", "diagonal", "=", "xk", ".", "size", "(", "1", ")", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "mask", "=", "torch", ".", "full_like", "(", "scores", "[", "0", "]", ",", "float", "(", "'-inf'", ")", ")", "\n", "mask", "=", "mask", ".", "triu", "(", ")", "\n", "", "scores", "+=", "mask", ".", "unsqueeze", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "scores", "=", "torch", ".", "full", "(", "(", "xq", ".", "size", "(", "0", ")", ",", "xq", ".", "size", "(", "1", ")", ",", "xk", ".", "size", "(", "1", ")", ")", ",", "float", "(", "'-inf'", ")", ",", "device", "=", "xq", ".", "device", ")", "\n", "\n", "", "if", "use_cache", ":", "\n", "            ", "next_cache", "=", "(", "(", "encoder_hidden_states", ",", "encoder_padding_mask", ")", ",", "next_decoder_cache", ")", "\n", "", "else", ":", "\n", "            ", "next_cache", "=", "None", "\n", "", "return", "(", "x", ",", "scores", ")", ",", "next_cache", ",", "all_hidden_states", ",", "list", "(", "all_self_attns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartModel.__init__": [[313, 330], ["transformers.modeling_bart.PretrainedBartModel.__init__", "torch.nn.Embedding", "transformers.modeling_bart.AMRBartEncoder", "transformers.modeling_bart.AMRBartDecoder", "transformers.modeling_bart.AMRBartModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.Embedding"], ["    ", "def", "__init__", "(", "self", ",", "config", ":", "bart", ".", "BartConfig", ",", "backpointer_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "True", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "self", ".", "padding_idx", ",", "vocab_size", "=", "config", ".", "pad_token_id", ",", "config", ".", "vocab_size", "\n", "self", ".", "shared", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "config", ".", "d_model", ",", "self", ".", "padding_idx", ")", "\n", "\n", "if", "backpointer_idx", "is", "not", "None", ":", "\n", "            ", "self", ".", "backpointer_idx", "=", "backpointer_idx", "\n", "", "else", ":", "\n", "            ", "self", ".", "backpointer_idx", "=", "self", ".", "shared", ".", "num_embeddings", "-", "1", "\n", "\n", "", "self", ".", "encoder", "=", "AMRBartEncoder", "(", "config", ",", "self", ".", "shared", ",", "backpointer_idx", "=", "self", ".", "backpointer_idx", ")", "\n", "self", ".", "decoder", "=", "AMRBartDecoder", "(", "config", ",", "self", ".", "shared", ",", "backpointer_idx", "=", "self", ".", "backpointer_idx", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartModel.sentence_mode": [[335, 339], ["isinstance"], "methods", ["None"], ["", "@", "sentence_mode", ".", "setter", "\n", "def", "sentence_mode", "(", "self", ",", "value", ")", ":", "\n", "        ", "assert", "isinstance", "(", "value", ",", "bool", ")", "\n", "self", ".", "decoder", ".", "amr_mode", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartModel.forward": [[340, 383], ["isinstance", "transformers.modeling_bart.AMRBartModel.decoder", "isinstance", "isinstance", "transformers.modeling_bart._filter_out_falsey_values", "transformers.modeling_bart._prepare_bart_decoder_inputs", "transformers.modeling_bart.AMRBartModel.encoder"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "attention_mask", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "encoder_outputs", ":", "Optional", "[", "Tuple", "]", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "decoder_cached_states", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", ")", ":", "\n", "\n", "# make masks if user doesn't supply", "\n", "        ", "if", "not", "use_cache", ":", "\n", "            ", "decoder_input_ids", ",", "decoder_padding_mask", ",", "causal_mask", "=", "bart", ".", "_prepare_bart_decoder_inputs", "(", "\n", "self", ".", "config", ",", "\n", "input_ids", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "decoder_padding_mask", "=", "decoder_attention_mask", ",", "\n", "causal_mask_dtype", "=", "self", ".", "shared", ".", "weight", ".", "dtype", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "decoder_padding_mask", ",", "causal_mask", "=", "None", ",", "None", "\n", "\n", "", "assert", "decoder_input_ids", "is", "not", "None", "\n", "if", "encoder_outputs", "is", "None", ":", "\n", "            ", "encoder_outputs", "=", "self", ".", "encoder", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ")", "\n", "", "assert", "isinstance", "(", "encoder_outputs", ",", "tuple", ")", "\n", "# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)", "\n", "decoder_outputs", "=", "self", ".", "decoder", "(", "\n", "decoder_input_ids", ",", "\n", "encoder_outputs", "[", "0", "]", ",", "\n", "attention_mask", ",", "\n", "decoder_padding_mask", ",", "\n", "decoder_causal_mask", "=", "causal_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", ")", "\n", "# Attention and hidden_states will be [] or None if they aren't needed", "\n", "# decoder_outputs: Tuple = bart._filter_out_falsey_values(decoder_outputs)", "\n", "assert", "isinstance", "(", "decoder_outputs", "[", "0", "]", "[", "0", "]", ",", "torch", ".", "Tensor", ")", "\n", "assert", "isinstance", "(", "decoder_outputs", "[", "0", "]", "[", "1", "]", ",", "torch", ".", "Tensor", ")", "\n", "encoder_outputs", ":", "Tuple", "=", "bart", ".", "_filter_out_falsey_values", "(", "encoder_outputs", ")", "\n", "return", "decoder_outputs", "+", "encoder_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartModel.get_input_embeddings": [[384, 386], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartModel.set_input_embeddings": [[387, 391], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "shared", "=", "value", "\n", "self", ".", "encoder", ".", "embed_tokens", "=", "self", ".", "shared", "\n", "self", ".", "decoder", ".", "embed_tokens", "=", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartModel.get_output_embeddings": [[392, 394], ["transformers.modeling_bart._make_linear_from_emb"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "bart", ".", "_make_linear_from_emb", "(", "self", ".", "shared", ")", "# make it on the fly", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.__init__": [[399, 407], ["transformers.modeling_bart.PretrainedBartModel.__init__", "transformers.modeling_bart.AMRBartModel", "transformers.modeling_bart.AMRBartForConditionalGeneration.register_buffer", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "bart", ".", "BartConfig", ",", "backpointer_idx", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "base_model", "=", "AMRBartModel", "(", "config", ",", "backpointer_idx", ")", "\n", "self", ".", "model", "=", "base_model", "\n", "self", ".", "pad_index", "=", "base_model", ".", "shared", ".", "padding_idx", "\n", "self", ".", "register_buffer", "(", "\"final_logits_bias\"", ",", "torch", ".", "zeros", "(", "(", "1", ",", "self", ".", "model", ".", "shared", ".", "num_embeddings", ")", ")", ")", "\n", "self", ".", "backpointer_idx", "=", "backpointer_idx", "\n", "self", ".", "_rev", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.init_reverse_model": [[408, 417], ["transformers.modeling_bart.AMRBartForConditionalGeneration"], "methods", ["None"], ["", "def", "init_reverse_model", "(", "self", ")", ":", "\n", "        ", "rev", "=", "AMRBartForConditionalGeneration", "(", "self", ".", "model", ".", "config", ",", "self", ".", "backpointer_idx", ")", "\n", "rev", ".", "model", ".", "shared", "=", "self", ".", "model", ".", "shared", "\n", "rev", ".", "model", ".", "encoder", "=", "self", ".", "model", ".", "encoder", "\n", "rev", ".", "model", ".", "decoder", ".", "embed_tokens", "=", "self", ".", "model", ".", "decoder", ".", "embed_tokens", "\n", "rev", ".", "model", ".", "decoder", ".", "embed_positions", "=", "self", ".", "model", ".", "decoder", ".", "embed_positions", "\n", "self", ".", "amr_mode", "=", "True", "\n", "rev", ".", "amr_mode", "=", "False", "\n", "self", ".", "_rev", "=", "rev", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.rev": [[418, 424], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "rev", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_rev", "is", "None", ":", "\n", "            ", "return", "self", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_rev", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.amr_mode": [[429, 433], ["isinstance"], "methods", ["None"], ["", "@", "amr_mode", ".", "setter", "\n", "def", "amr_mode", "(", "self", ",", "value", ")", ":", "\n", "        ", "assert", "isinstance", "(", "value", ",", "bool", ")", "\n", "self", ".", "model", ".", "decoder", ".", "amr_mode", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.forward": [[434, 524], ["transformers.modeling_bart.AMRBartForConditionalGeneration.compute_logits", "torch.nn.functional.nll_loss", "uni_logits.log_softmax().contiguous().view", "lm_labels.contiguous().view", "uni_logits.size", "uni_logits.log_softmax().contiguous", "lm_labels.contiguous", "uni_logits.log_softmax"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.compute_logits", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "decoder_cached_states", "=", "None", ",", "\n", "lm_labels", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", "**", "unused", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        lm_labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`, defaults to :obj:`None`):\n            Labels for computing the masked language modeling loss.\n            Indices should either be in ``[0, ..., config.vocab_size]`` or -100 (see ``input_ids`` docstring).\n            Tokens with indices set to ``-100`` are ignored (masked), the loss is only computed for the tokens\n            with labels\n            in ``[0, ..., config.vocab_size]``.\n\n    Returns:\n        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.RobertaConfig`) and inputs:\n        masked_lm_loss (`optional`, returned when ``lm_labels`` is provided) ``torch.FloatTensor`` of shape ``(1,)``:\n            Masked language modeling loss.\n        prediction_scores (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, config.vocab_size)`)\n            Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n\n            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n\n            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n            heads.\n\n    Examples::\n\n            # Mask filling only works for bart-large\n            from transformers import BartTokenizer, BartForConditionalGeneration\n            tokenizer = BartTokenizer.from_pretrained('bart-large')\n            TXT = \"My friends are <mask> but they eat too many carbs.\"\n            model = BartForConditionalGeneration.from_pretrained('bart-large')\n            input_ids = tokenizer.batch_encode_plus([TXT], return_tensors='pt')['input_ids']\n            logits = model(input_ids)[0]\n            masked_index = (input_ids[0] == tokenizer.mask_token_id).nonzero().item()\n            probs = logits[0, masked_index].softmax(dim=0)\n            values, predictions = probs.topk(5)\n            tokenizer.decode(predictions).split()\n            # ['good', 'great', 'all', 'really', 'very']\n        \"\"\"", "\n", "# outputs = self.model(", "\n", "#     input_ids,", "\n", "#     attention_mask=attention_mask,", "\n", "#     decoder_input_ids=decoder_input_ids,", "\n", "#     encoder_outputs=encoder_outputs,", "\n", "#     decoder_attention_mask=decoder_attention_mask,", "\n", "#     decoder_cached_states=decoder_cached_states,", "\n", "#     use_cache=use_cache,", "\n", "# )", "\n", "# lm_logits = F.linear(outputs[0][0], self.model.shared.weight, bias=self.final_logits_bias)", "\n", "# po_logits = outputs[0][1]", "\n", "# po_padding = torch.full_like(po_logits[:, :, 0:1], float('-inf'))", "\n", "# po_padding = po_padding.repeat(1, 1, 1024 - po_logits.size(-1))", "\n", "# po_logits = torch.cat([po_logits, po_padding], -1)", "\n", "# uni_logits = torch.cat([lm_logits, po_logits], -1)", "\n", "#", "\n", "# outputs = (uni_logits,) + outputs[1:]  # Add cache, hidden states and attention if they are here", "\n", "\n", "outputs", "=", "self", ".", "compute_logits", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", ")", "\n", "\n", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "uni_logits", "=", "outputs", "[", "0", "]", "\n", "masked_lm_loss", "=", "F", ".", "nll_loss", "(", "\n", "uni_logits", ".", "log_softmax", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "uni_logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "lm_labels", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ",", "\n", "ignore_index", "=", "self", ".", "pad_index", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.compute_logits": [[525, 553], ["transformers.modeling_bart.AMRBartForConditionalGeneration.model", "torch.nn.functional.linear", "torch.full_like", "po_padding.repeat.repeat.repeat", "torch.cat", "torch.cat", "float", "torch.cat.size"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "compute_logits", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_outputs", "=", "None", ",", "\n", "decoder_input_ids", "=", "None", ",", "\n", "decoder_attention_mask", "=", "None", ",", "\n", "decoder_cached_states", "=", "None", ",", "\n", "use_cache", "=", "False", ",", "\n", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "model", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", ",", "\n", "decoder_cached_states", "=", "decoder_cached_states", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", ")", "\n", "\n", "lm_logits", "=", "F", ".", "linear", "(", "outputs", "[", "0", "]", "[", "0", "]", ",", "self", ".", "model", ".", "shared", ".", "weight", ",", "bias", "=", "self", ".", "final_logits_bias", ")", "\n", "po_logits", "=", "outputs", "[", "0", "]", "[", "1", "]", "\n", "po_padding", "=", "torch", ".", "full_like", "(", "po_logits", "[", ":", ",", ":", ",", "0", ":", "1", "]", ",", "float", "(", "'-inf'", ")", ")", "\n", "po_padding", "=", "po_padding", ".", "repeat", "(", "1", ",", "1", ",", "1024", "-", "po_logits", ".", "size", "(", "-", "1", ")", ")", "\n", "po_logits", "=", "torch", ".", "cat", "(", "[", "po_logits", ",", "po_padding", "]", ",", "-", "1", ")", "\n", "uni_logits", "=", "torch", ".", "cat", "(", "[", "lm_logits", ",", "po_logits", "]", ",", "-", "1", ")", "\n", "outputs", "=", "(", "uni_logits", ",", ")", "+", "outputs", "[", "1", ":", "]", "# Add cache, hidden states and attention if they are here", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.generate": [[554, 940], ["torch.no_grad", "isinstance", "isinstance", "isinstance", "hasattr", "transformers.modeling_bart.AMRBartForConditionalGeneration.get_output_embeddings", "AttributeError", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "torch.full", "torch.full.ne().long", "logger.warning", "hasattr", "callable", "transformers.modeling_bart.AMRBartForConditionalGeneration.get_encoder", "transformers.modeling_bart.AMRBartForConditionalGeneration.", "torch.full.unsqueeze().expand", "torch.full.new_ones.unsqueeze().expand", "torch.full.contiguous().view", "torch.full.new_ones.contiguous().view", "torch.full", "torch.arange().view().repeat().view().to", "transformers.modeling_bart.AMRBartForConditionalGeneration._generate_beam_search", "transformers.modeling_bart.AMRBartForConditionalGeneration._generate_no_beam_search", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "torch.full.dim", "torch.full.new_ones", "hasattr", "hasattr", "encoder_outputs[].index_select", "torch.full.ne", "torch.full.unsqueeze", "torch.full.new_ones.unsqueeze", "torch.full.contiguous", "torch.full.new_ones.contiguous", "torch.arange().view().repeat().view", "next", "next", "transformers.modeling_bart.AMRBartForConditionalGeneration.parameters", "transformers.modeling_bart.AMRBartForConditionalGeneration.parameters", "torch.arange().view().repeat", "torch.arange().view", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.get_output_embeddings", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.get_encoder", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration._generate_beam_search", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "\n", "self", ",", "\n", "input_ids", ":", "Optional", "[", "torch", ".", "LongTensor", "]", "=", "None", ",", "\n", "max_length", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "min_length", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "do_sample", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "early_stopping", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "num_beams", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "temperature", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "top_k", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "top_p", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "repetition_penalty", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "bad_words_ids", ":", "Optional", "[", "Iterable", "[", "int", "]", "]", "=", "None", ",", "\n", "bos_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "pad_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "eos_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "length_penalty", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "no_repeat_ngram_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "num_return_sequences", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "attention_mask", ":", "Optional", "[", "torch", ".", "LongTensor", "]", "=", "None", ",", "\n", "decoder_start_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "use_cache", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "**", "model_specific_kwargs", "\n", ")", "->", "torch", ".", "LongTensor", ":", "\n", "        ", "r\"\"\" Generates sequences for models with a LM head. The method currently supports greedy decoding, beam-search decoding, sampling with temperature, sampling with top-k or nucleus sampling.\n\n        Adapted in part from `Facebook's XLM beam search code`_.\n\n        .. _`Facebook's XLM beam search code`:\n           https://github.com/facebookresearch/XLM/blob/9e6f6814d17be4fe5b15f2e6c43eb2b2d76daeb4/src/model/transformer.py#L529\n\n\n        Parameters:\n\n            input_ids: (`optional`) `torch.LongTensor` of shape `(batch_size, sequence_length)`\n                The sequence used as a prompt for the generation. If `None` the method initializes\n                it as an empty `torch.LongTensor` of shape `(1,)`.\n\n            max_length: (`optional`) int\n                The max length of the sequence to be generated.  Between `min_length` and infinity. Default to 20.\n\n            min_length: (`optional`) int\n                The min length of the sequence to be generated.  Between 0 and infinity. Default to 0.\n\n            do_sample: (`optional`) bool\n                If set to `False` greedy decoding is used. Otherwise sampling is used. Defaults to `False` as defined in `configuration_utils.PretrainedConfig`.\n\n            early_stopping: (`optional`) bool\n                if set to `True` beam search is stopped when at least `num_beams` sentences finished per batch. Defaults to `False` as defined in `configuration_utils.PretrainedConfig`.\n\n            num_beams: (`optional`) int\n                Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search. Default to 1.\n\n            temperature: (`optional`) float\n                The value used to module the next token probabilities. Must be strictly positive. Default to 1.0.\n\n            top_k: (`optional`) int\n                The number of highest probability vocabulary tokens to keep for top-k-filtering. Between 1 and infinity. Default to 50.\n\n            top_p: (`optional`) float\n                The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Must be between 0 and 1. Default to 1.\n\n            repetition_penalty: (`optional`) float\n                The parameter for repetition penalty. Between 1.0 and infinity. 1.0 means no penalty. Default to 1.0.\n\n            pad_token_id: (`optional`) int\n                Padding token. Default to specicic model pad_token_id or None if it does not exist.\n\n            bos_token_id: (`optional`) int\n                BOS token. Defaults to `bos_token_id` as defined in the models config.\n\n            eos_token_id: (`optional`) int\n                EOS token. Defaults to `eos_token_id` as defined in the models config.\n\n            length_penalty: (`optional`) float\n                Exponential penalty to the length. Default to 1.\n\n            no_repeat_ngram_size: (`optional`) int\n                If set to int > 0, all ngrams of size `no_repeat_ngram_size` can only occur once.\n            bad_words_ids: (`optional`) list of lists of int\n                `bad_words_ids` contains tokens that are not allowed to be generated. In order to get the tokens of the words that should not appear in the generated text, use `tokenizer.encode(bad_word, add_prefix_space=True)`.\n\n            num_return_sequences: (`optional`) int\n                The number of independently computed returned sequences for each element in the batch. Default to 1.\n\n            attention_mask (`optional`) obj: `torch.LongTensor` of same shape as `input_ids`\n                Mask to avoid performing attention on padding token indices.\n                Mask values selected in ``[0, 1]``:\n                ``1`` for tokens that are NOT MASKED, ``0`` for MASKED tokens.\n                Defaults to `None`.\n\n                `What are attention masks? <../glossary.html#attention-mask>`__\n\n            decoder_start_token_id=None: (`optional`) int\n                If an encoder-decoder model starts decoding with a different token than BOS.\n                Defaults to `None` and is changed to `BOS` later.\n\n            use_cache: (`optional`) bool\n                If `use_cache` is True, past key values are used to speed up decoding if applicable to model. Defaults to `True`.\n\n            model_specific_kwargs: (`optional`) dict\n                Additional model specific kwargs will be forwarded to the `forward` function of the model.\n\n        Return:\n\n            output: `torch.LongTensor` of shape `(batch_size * num_return_sequences, sequence_length)`\n                sequence_length is either equal to max_length or shorter if all batches finished early due to the `eos_token_id`\n\n        Examples::\n\n            tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n            outputs = model.generate(max_length=40)  # do greedy decoding\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('openai-gpt')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('openai-gpt')    # Download model and configuration from S3 and cache.\n            input_context = 'The dog'\n            input_ids = tokenizer.encode(input_context, return_tensors='pt')  # encode input context\n            outputs = model.generate(input_ids=input_ids, num_beams=5, num_return_sequences=3, temperature=1.5)  # generate 3 independent sequences using beam search decoding (5 beams) with sampling from initial context 'The dog'\n            for i in range(3): #  3 output sequences were generated\n                print('Generated {}: {}'.format(i, tokenizer.decode(outputs[i], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n            input_context = 'The dog'\n            input_ids = tokenizer.encode(input_context, return_tensors='pt')  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=40, temperature=0.7, num_return_sequences=3)  # 3 generate sequences using by sampling\n            for i in range(3): #  3 output sequences were generated\n                print('Generated {}: {}'.format(i, tokenizer.decode(outputs[i], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('ctrl')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('ctrl')    # Download model and configuration from S3 and cache.\n            input_context = 'Legal My neighbor is'  # \"Legal\" is one of the control codes for ctrl\n            input_ids = tokenizer.encode(input_context, return_tensors='pt')  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=50, temperature=0.7, repetition_penalty=1.2)  # generate sequences\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('gpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('gpt2')    # Download model and configuration from S3 and cache.\n            input_context = 'My cute dog'  # \"Legal\" is one of the control codes for ctrl\n            bad_words_ids = [tokenizer.encode(bad_word, add_prefix_space=True) for bad_word in ['idiot', 'stupid', 'shut up']]\n            input_ids = tokenizer.encode(input_context, return_tensors='pt')  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=100, do_sample=True, bad_words_ids=bad_words_ids)  # generate sequences without allowing bad_words to be generated\n        \"\"\"", "\n", "\n", "# We cannot generate if the model does not have a LM head", "\n", "if", "self", ".", "get_output_embeddings", "(", ")", "is", "None", ":", "\n", "            ", "raise", "AttributeError", "(", "\n", "\"You tried to generate sequences with a model that does not have a LM Head.\"", "\n", "\"Please use another model class (e.g. `OpenAIGPTLMHeadModel`, `XLNetLMHeadModel`, `GPT2LMHeadModel`, `CTRLLMHeadModel`, `T5WithLMHeadModel`, `TransfoXLLMHeadModel`, `XLMWithLMHeadModel`, `BartForConditionalGeneration` )\"", "\n", ")", "\n", "\n", "", "max_length", "=", "max_length", "if", "max_length", "is", "not", "None", "else", "self", ".", "config", ".", "max_length", "\n", "min_length", "=", "min_length", "if", "min_length", "is", "not", "None", "else", "self", ".", "config", ".", "min_length", "\n", "do_sample", "=", "do_sample", "if", "do_sample", "is", "not", "None", "else", "self", ".", "config", ".", "do_sample", "\n", "early_stopping", "=", "early_stopping", "if", "early_stopping", "is", "not", "None", "else", "self", ".", "config", ".", "early_stopping", "\n", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "num_beams", "=", "num_beams", "if", "num_beams", "is", "not", "None", "else", "self", ".", "config", ".", "num_beams", "\n", "temperature", "=", "temperature", "if", "temperature", "is", "not", "None", "else", "self", ".", "config", ".", "temperature", "\n", "top_k", "=", "top_k", "if", "top_k", "is", "not", "None", "else", "self", ".", "config", ".", "top_k", "\n", "top_p", "=", "top_p", "if", "top_p", "is", "not", "None", "else", "self", ".", "config", ".", "top_p", "\n", "repetition_penalty", "=", "repetition_penalty", "if", "repetition_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "repetition_penalty", "\n", "bos_token_id", "=", "bos_token_id", "if", "bos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "bos_token_id", "\n", "pad_token_id", "=", "pad_token_id", "if", "pad_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "pad_token_id", "\n", "eos_token_id", "=", "eos_token_id", "if", "eos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "eos_token_id", "\n", "length_penalty", "=", "length_penalty", "if", "length_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "length_penalty", "\n", "no_repeat_ngram_size", "=", "(", "\n", "no_repeat_ngram_size", "if", "no_repeat_ngram_size", "is", "not", "None", "else", "self", ".", "config", ".", "no_repeat_ngram_size", "\n", ")", "\n", "bad_words_ids", "=", "bad_words_ids", "if", "bad_words_ids", "is", "not", "None", "else", "self", ".", "config", ".", "bad_words_ids", "\n", "num_return_sequences", "=", "(", "\n", "num_return_sequences", "if", "num_return_sequences", "is", "not", "None", "else", "self", ".", "config", ".", "num_return_sequences", "\n", ")", "\n", "decoder_start_token_id", "=", "(", "\n", "decoder_start_token_id", "if", "decoder_start_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "decoder_start_token_id", "\n", ")", "\n", "\n", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "batch_size", "=", "input_ids", ".", "shape", "[", "0", "]", "# overriden by the input batch_size", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "1", "\n", "\n", "", "assert", "isinstance", "(", "max_length", ",", "int", ")", "and", "max_length", ">", "0", ",", "\"`max_length` should be a strictly positive integer.\"", "\n", "assert", "isinstance", "(", "min_length", ",", "int", ")", "and", "min_length", ">=", "0", ",", "\"`min_length` should be a positive integer.\"", "\n", "assert", "isinstance", "(", "do_sample", ",", "bool", ")", ",", "\"`do_sample` should be a boolean.\"", "\n", "assert", "isinstance", "(", "early_stopping", ",", "bool", ")", ",", "\"`early_stopping` should be a boolean.\"", "\n", "assert", "isinstance", "(", "use_cache", ",", "bool", ")", ",", "\"`use_cache` should be a boolean.\"", "\n", "assert", "isinstance", "(", "num_beams", ",", "int", ")", "and", "num_beams", ">", "0", ",", "\"`num_beams` should be a strictly positive integer.\"", "\n", "assert", "temperature", ">", "0", ",", "\"`temperature` should be strictly positive.\"", "\n", "assert", "isinstance", "(", "top_k", ",", "int", ")", "and", "top_k", ">=", "0", ",", "\"`top_k` should be a positive integer.\"", "\n", "assert", "0", "<=", "top_p", "<=", "1", ",", "\"`top_p` should be between 0 and 1.\"", "\n", "assert", "repetition_penalty", ">=", "1.0", ",", "\"`repetition_penalty` should be >= 1.\"", "\n", "assert", "input_ids", "is", "not", "None", "or", "(", "\n", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", "\n", ")", ",", "\"If input_ids is not defined, `bos_token_id` should be a positive integer.\"", "\n", "assert", "pad_token_id", "is", "None", "or", "(", "\n", "isinstance", "(", "pad_token_id", ",", "int", ")", "and", "(", "pad_token_id", ">=", "0", ")", "\n", ")", ",", "\"`pad_token_id` should be a positive integer.\"", "\n", "assert", "(", "eos_token_id", "is", "None", ")", "or", "(", "\n", "isinstance", "(", "eos_token_id", ",", "int", ")", "and", "(", "eos_token_id", ">=", "0", ")", "\n", ")", ",", "\"`eos_token_id` should be a positive integer.\"", "\n", "assert", "length_penalty", ">", "0", ",", "\"`length_penalty` should be strictly positive.\"", "\n", "assert", "(", "\n", "isinstance", "(", "no_repeat_ngram_size", ",", "int", ")", "and", "no_repeat_ngram_size", ">=", "0", "\n", ")", ",", "\"`no_repeat_ngram_size` should be a positive integer.\"", "\n", "assert", "(", "\n", "isinstance", "(", "num_return_sequences", ",", "int", ")", "and", "num_return_sequences", ">", "0", "\n", ")", ",", "\"`num_return_sequences` should be a strictly positive integer.\"", "\n", "assert", "(", "\n", "bad_words_ids", "is", "None", "or", "isinstance", "(", "bad_words_ids", ",", "list", ")", "and", "isinstance", "(", "bad_words_ids", "[", "0", "]", ",", "list", ")", "\n", ")", ",", "\"`bad_words_ids` is either `None` or a list of lists of tokens that should not be generated\"", "\n", "\n", "if", "input_ids", "is", "None", ":", "\n", "            ", "assert", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", ",", "(", "\n", "\"you should either supply a context to complete as `input_ids` input \"", "\n", "\"or a `bos_token_id` (integer >= 0) as a first token to start the generation.\"", "\n", ")", "\n", "input_ids", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ")", ",", "bos_token_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "assert", "input_ids", ".", "dim", "(", ")", "==", "2", ",", "\"Input prompt should be of shape (batch_size, sequence length).\"", "\n", "\n", "# not allow to duplicate outputs when greedy decoding", "\n", "", "if", "do_sample", "is", "False", ":", "\n", "            ", "if", "num_beams", "==", "1", ":", "\n", "# no_beam_search greedy generation conditions", "\n", "                ", "assert", "(", "\n", "num_return_sequences", "==", "1", "\n", ")", ",", "\"Greedy decoding will always produce the same output for num_beams == 1 and num_return_sequences > 1. Please set num_return_sequences = 1\"", "\n", "\n", "", "else", ":", "\n", "# beam_search greedy generation conditions", "\n", "                ", "assert", "(", "\n", "num_beams", ">=", "num_return_sequences", "\n", ")", ",", "\"Greedy beam search decoding cannot return more sequences than it has beams. Please set num_beams >= num_return_sequences\"", "\n", "\n", "# create attention mask if necessary", "\n", "# TODO (PVP): this should later be handled by the forward fn() in each model in the future see PR 3140", "\n", "", "", "if", "(", "attention_mask", "is", "None", ")", "and", "(", "pad_token_id", "is", "not", "None", ")", "and", "(", "pad_token_id", "in", "input_ids", ")", ":", "\n", "            ", "attention_mask", "=", "input_ids", ".", "ne", "(", "pad_token_id", ")", ".", "long", "(", ")", "\n", "", "elif", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "input_ids", ".", "new_ones", "(", "input_ids", ".", "shape", ")", "\n", "\n", "# set pad_token_id to eos_token_id if not set. Important that this is done after", "\n", "# attention_mask is created", "\n", "", "if", "pad_token_id", "is", "None", "and", "eos_token_id", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Setting `pad_token_id` to {} (first `eos_token_id`) to generate sequence\"", ".", "format", "(", "eos_token_id", ")", "\n", ")", "\n", "pad_token_id", "=", "eos_token_id", "\n", "\n", "# current position and vocab size", "\n", "", "if", "hasattr", "(", "self", ".", "config", ",", "\"vocab_size\"", ")", ":", "\n", "            ", "vocab_size", "=", "self", ".", "config", ".", "vocab_size", "\n", "", "elif", "(", "\n", "self", ".", "config", ".", "is_encoder_decoder", "\n", "and", "hasattr", "(", "self", ".", "config", ",", "\"decoder\"", ")", "\n", "and", "hasattr", "(", "self", ".", "config", ".", "decoder", ",", "\"vocab_size\"", ")", "\n", ")", ":", "\n", "            ", "vocab_size", "=", "self", ".", "config", ".", "decoder", ".", "vocab_size", "\n", "\n", "", "vocab_size", "+=", "1024", "\n", "\n", "# set effective batch size and effective batch multiplier according to do_sample", "\n", "if", "do_sample", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "*", "num_return_sequences", "\n", "effective_batch_mult", "=", "num_return_sequences", "\n", "", "else", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "\n", "effective_batch_mult", "=", "1", "\n", "\n", "", "if", "self", ".", "config", ".", "is_encoder_decoder", ":", "\n", "            ", "if", "decoder_start_token_id", "is", "None", ":", "\n", "                ", "decoder_start_token_id", "=", "bos_token_id", "\n", "\n", "", "assert", "(", "\n", "decoder_start_token_id", "is", "not", "None", "\n", ")", ",", "\"decoder_start_token_id or bos_token_id has to be defined for encoder-decoder generation\"", "\n", "assert", "hasattr", "(", "self", ",", "\"get_encoder\"", ")", ",", "\"{} should have a 'get_encoder' function defined\"", ".", "format", "(", "self", ")", "\n", "assert", "callable", "(", "self", ".", "get_encoder", ")", ",", "\"{} should be a method\"", ".", "format", "(", "self", ".", "get_encoder", ")", "\n", "\n", "# get encoder and store encoder outputs", "\n", "encoder", "=", "self", ".", "get_encoder", "(", ")", "\n", "\n", "encoder_outputs", ":", "tuple", "=", "encoder", "(", "input_ids", ",", "attention_mask", "=", "attention_mask", ")", "\n", "\n", "# Expand input ids if num_beams > 1 or num_return_sequences > 1", "\n", "", "if", "num_return_sequences", ">", "1", "or", "num_beams", ">", "1", ":", "\n", "            ", "input_ids_len", "=", "input_ids", ".", "shape", "[", "-", "1", "]", "\n", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "effective_batch_mult", "*", "num_beams", ",", "input_ids_len", ")", "\n", "attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "\n", "batch_size", ",", "effective_batch_mult", "*", "num_beams", ",", "input_ids_len", "\n", ")", "\n", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "effective_batch_size", "*", "num_beams", ",", "input_ids_len", "\n", ")", "# shape: (batch_size * num_return_sequences * num_beams, cur_len)", "\n", "attention_mask", "=", "attention_mask", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "effective_batch_size", "*", "num_beams", ",", "input_ids_len", "\n", ")", "# shape: (batch_size * num_return_sequences * num_beams, cur_len)", "\n", "\n", "", "if", "self", ".", "config", ".", "is_encoder_decoder", ":", "\n", "# create empty decoder_input_ids", "\n", "            ", "input_ids", "=", "torch", ".", "full", "(", "\n", "(", "effective_batch_size", "*", "num_beams", ",", "1", ")", ",", "\n", "decoder_start_token_id", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ",", "\n", ")", "\n", "cur_len", "=", "1", "\n", "\n", "assert", "(", "\n", "batch_size", "==", "encoder_outputs", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", ")", ",", "f\"expected encoder_outputs[0] to have 1st dimension bs={batch_size}, got {encoder_outputs[0].shape[0]} \"", "\n", "\n", "# expand batch_idx to assign correct encoder output for expanded input_ids (due to num_beams > 1 and num_return_sequences > 1)", "\n", "expanded_batch_idxs", "=", "(", "\n", "torch", ".", "arange", "(", "batch_size", ")", "\n", ".", "view", "(", "-", "1", ",", "1", ")", "\n", ".", "repeat", "(", "1", ",", "num_beams", "*", "effective_batch_mult", ")", "\n", ".", "view", "(", "-", "1", ")", "\n", ".", "to", "(", "input_ids", ".", "device", ")", "\n", ")", "\n", "# expand encoder_outputs", "\n", "encoder_outputs", "=", "(", "encoder_outputs", "[", "0", "]", ".", "index_select", "(", "0", ",", "expanded_batch_idxs", ")", ",", "*", "encoder_outputs", "[", "1", ":", "]", ")", "\n", "\n", "", "else", ":", "\n", "            ", "encoder_outputs", "=", "None", "\n", "cur_len", "=", "input_ids", ".", "shape", "[", "-", "1", "]", "\n", "\n", "", "if", "num_beams", ">", "1", ":", "\n", "            ", "output", "=", "self", ".", "_generate_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", "=", "cur_len", ",", "\n", "max_length", "=", "max_length", ",", "\n", "min_length", "=", "min_length", ",", "\n", "do_sample", "=", "do_sample", ",", "\n", "early_stopping", "=", "early_stopping", ",", "\n", "temperature", "=", "temperature", ",", "\n", "top_k", "=", "top_k", ",", "\n", "top_p", "=", "top_p", ",", "\n", "repetition_penalty", "=", "repetition_penalty", ",", "\n", "no_repeat_ngram_size", "=", "no_repeat_ngram_size", ",", "\n", "bad_words_ids", "=", "bad_words_ids", ",", "\n", "bos_token_id", "=", "bos_token_id", ",", "\n", "pad_token_id", "=", "pad_token_id", ",", "\n", "decoder_start_token_id", "=", "decoder_start_token_id", ",", "\n", "eos_token_id", "=", "eos_token_id", ",", "\n", "batch_size", "=", "effective_batch_size", ",", "\n", "num_return_sequences", "=", "num_return_sequences", ",", "\n", "length_penalty", "=", "length_penalty", ",", "\n", "num_beams", "=", "num_beams", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "model_specific_kwargs", "=", "model_specific_kwargs", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_generate_no_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", "=", "cur_len", ",", "\n", "max_length", "=", "max_length", ",", "\n", "min_length", "=", "min_length", ",", "\n", "do_sample", "=", "do_sample", ",", "\n", "temperature", "=", "temperature", ",", "\n", "top_k", "=", "top_k", ",", "\n", "top_p", "=", "top_p", ",", "\n", "repetition_penalty", "=", "repetition_penalty", ",", "\n", "no_repeat_ngram_size", "=", "no_repeat_ngram_size", ",", "\n", "bad_words_ids", "=", "bad_words_ids", ",", "\n", "bos_token_id", "=", "bos_token_id", ",", "\n", "pad_token_id", "=", "pad_token_id", ",", "\n", "decoder_start_token_id", "=", "decoder_start_token_id", ",", "\n", "eos_token_id", "=", "eos_token_id", ",", "\n", "batch_size", "=", "effective_batch_size", ",", "\n", "encoder_outputs", "=", "encoder_outputs", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "model_specific_kwargs", "=", "model_specific_kwargs", ",", "\n", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration._generate_beam_search": [[941, 1214], ["torch.zeros", "beam_scores.new.new.view", "range", "torch.cat.new", "enumerate", "transformers.modeling_utils.BeamHypotheses", "transformers.modeling_bart.AMRBartForConditionalGeneration.prepare_inputs_for_generation", "transformers.modeling_bart.AMRBartForConditionalGeneration.", "transformers.modeling_bart.AMRBartForConditionalGeneration._use_cache", "torch.nn.functional.log_softmax", "range", "all", "beam_scores.new.new.new", "torch.cat.new", "torch.cat.new", "torch.cat", "range", "sorted", "range", "torch.cat.new.min().item", "torch.cat.new.max().item", "min", "torch.cat.new().fill_", "enumerate", "torch.stack().type().to", "range", "range", "transformers.modeling_bart.AMRBartForConditionalGeneration.enforce_repetition_penalty_", "transformers.modeling_bart.AMRBartForConditionalGeneration.prepare_logits_for_generation", "transformers.modeling_utils.calc_banned_ngram_tokens", "enumerate", "transformers.modeling_utils.calc_banned_bad_words_ids", "enumerate", "transformers.modeling_utils.top_k_top_p_filtering", "_scores.contiguous().view.contiguous().view.contiguous().view", "torch.nn.functional.softmax", "torch.multinomial", "torch.gather", "torch.sort", "torch.gather", "next_scores.view.view.view", "torch.topk", "next_scores.view.view.size", "torch.gather.size", "enumerate", "next_batch_beam.extend", "len", "transformers.modeling_bart.AMRBartForConditionalGeneration._reorder_cache", "torch.cat", "all", "torch.all", "beam_scores[].item", "generated_hyps[].add", "len", "best.append", "float", "beam_scores[].expand_as", "beam_scores[].expand_as", "next_batch_beam.extend", "zip", "generated_hyps[].is_done", "len", "len", "torch.cat.new.unsqueeze", "sorted.pop", "torch.cat.new.min", "torch.cat.new.max", "torch.cat.new.max().item", "torch.cat.new", "len", "torch.stack().type", "next", "float", "float", "_scores.contiguous().view.contiguous().view.contiguous", "len", "generated_hyps[].add", "next_sent_beam.append", "len", "next_scores[].max().item", "torch.cat.new_ones", "beam_scores.new.new.view", "transformers.modeling_bart.AMRBartForConditionalGeneration.parameters", "token_id.item", "input_ids[].clone", "beam_token_score.item", "beam_scores.new.new.view", "torch.cat.new.max", "torch.stack", "next_scores[].max"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.prepare_inputs_for_generation", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.prepare_logits_for_generation", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration._reorder_cache", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view"], ["", "def", "_generate_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "min_length", ",", "\n", "do_sample", ",", "\n", "early_stopping", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "no_repeat_ngram_size", ",", "\n", "bad_words_ids", ",", "\n", "bos_token_id", ",", "\n", "pad_token_id", ",", "\n", "eos_token_id", ",", "\n", "decoder_start_token_id", ",", "\n", "batch_size", ",", "\n", "num_return_sequences", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", "encoder_outputs", ",", "\n", "attention_mask", ",", "\n", "use_cache", ",", "\n", "model_specific_kwargs", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example with beam search.\n        \"\"\"", "\n", "\n", "# generated hypotheses", "\n", "generated_hyps", "=", "[", "\n", "BeamHypotheses", "(", "num_beams", ",", "max_length", ",", "length_penalty", ",", "early_stopping", "=", "early_stopping", ")", "\n", "for", "_", "in", "range", "(", "batch_size", ")", "\n", "]", "\n", "\n", "# scores for each sentence in the beam", "\n", "beam_scores", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "num_beams", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "\n", "# for greedy decoding it is made sure that only tokens of the first beam are considered to avoid sampling the exact same tokens three times", "\n", "if", "do_sample", "is", "False", ":", "\n", "            ", "beam_scores", "[", ":", ",", "1", ":", "]", "=", "-", "1e9", "\n", "", "beam_scores", "=", "beam_scores", ".", "view", "(", "-", "1", ")", "# shape (batch_size * num_beams,)", "\n", "\n", "# cache compute states", "\n", "past", "=", "encoder_outputs", "# defined for encoder-decoder models, None for decoder-only models", "\n", "\n", "# done sentences", "\n", "done", "=", "[", "False", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "            ", "model_inputs", "=", "self", ".", "prepare_inputs_for_generation", "(", "\n", "input_ids", ",", "past", "=", "past", ",", "attention_mask", "=", "attention_mask", ",", "use_cache", "=", "use_cache", ",", "**", "model_specific_kwargs", "\n", ")", "\n", "outputs", "=", "self", "(", "**", "model_inputs", ")", "# (batch_size * num_beams, cur_len, vocab_size)", "\n", "next_token_logits", "=", "outputs", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "# (batch_size * num_beams, vocab_size)", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_use_cache", "(", "outputs", ",", "use_cache", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty (from CTRL paper https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "self", ".", "enforce_repetition_penalty_", "(", "\n", "next_token_logits", ",", "batch_size", ",", "num_beams", ",", "input_ids", ",", "repetition_penalty", ",", "\n", ")", "\n", "\n", "", "if", "temperature", "!=", "1.0", ":", "\n", "                ", "next_token_logits", "=", "next_token_logits", "/", "temperature", "\n", "\n", "", "if", "self", ".", "config", ".", "is_encoder_decoder", "and", "do_sample", "is", "False", ":", "\n", "# TODO (PVP) still a bit hacky here - there might be a better solution", "\n", "                ", "next_token_logits", "=", "self", ".", "prepare_logits_for_generation", "(", "\n", "next_token_logits", ",", "cur_len", "=", "cur_len", ",", "max_length", "=", "max_length", "\n", ")", "\n", "\n", "", "scores", "=", "F", ".", "log_softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "\n", "# set eos token prob to zero if min_length is not reached", "\n", "if", "eos_token_id", "is", "not", "None", "and", "cur_len", "<", "min_length", ":", "\n", "                ", "scores", "[", ":", ",", "eos_token_id", "]", "=", "-", "float", "(", "\"inf\"", ")", "\n", "\n", "", "if", "no_repeat_ngram_size", ">", "0", ":", "\n", "# calculate a list of banned tokens to prevent repetitively generating the same ngrams", "\n", "                ", "num_batch_hypotheses", "=", "batch_size", "*", "num_beams", "\n", "# from fairseq: https://github.com/pytorch/fairseq/blob/a07cb6f40480928c9e0548b737aadd36ee66ac76/fairseq/sequence_generator.py#L345", "\n", "banned_batch_tokens", "=", "calc_banned_ngram_tokens", "(", "\n", "input_ids", ",", "num_batch_hypotheses", ",", "no_repeat_ngram_size", ",", "cur_len", "\n", ")", "\n", "for", "i", ",", "banned_tokens", "in", "enumerate", "(", "banned_batch_tokens", ")", ":", "\n", "                    ", "scores", "[", "i", ",", "banned_tokens", "]", "=", "-", "float", "(", "\"inf\"", ")", "\n", "\n", "", "", "if", "bad_words_ids", "is", "not", "None", ":", "\n", "# calculate a list of banned tokens according to bad words", "\n", "                ", "banned_tokens", "=", "calc_banned_bad_words_ids", "(", "input_ids", ",", "bad_words_ids", ")", "\n", "\n", "for", "i", ",", "banned_tokens", "in", "enumerate", "(", "banned_tokens", ")", ":", "\n", "                    ", "scores", "[", "i", ",", "banned_tokens", "]", "=", "-", "float", "(", "\"inf\"", ")", "\n", "\n", "", "", "assert", "scores", ".", "shape", "==", "(", "batch_size", "*", "num_beams", ",", "vocab_size", ")", ",", "\"Shapes of scores: {} != {}\"", ".", "format", "(", "\n", "scores", ".", "shape", ",", "(", "batch_size", "*", "num_beams", ",", "vocab_size", ")", "\n", ")", "\n", "\n", "if", "do_sample", ":", "\n", "                ", "_scores", "=", "scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "scores", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# Top-p/top-k filtering", "\n", "_scores", "=", "top_k_top_p_filtering", "(", "\n", "_scores", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ",", "min_tokens_to_keep", "=", "2", "\n", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# re-organize to group the beam together to sample from all beam_idxs", "\n", "_scores", "=", "_scores", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch_size", ",", "num_beams", "*", "vocab_size", "\n", ")", "# (batch_size, num_beams * vocab_size)", "\n", "\n", "# Sample 2 next tokens for each beam (so we have some spare tokens and match output of greedy beam search)", "\n", "probs", "=", "F", ".", "softmax", "(", "_scores", ",", "dim", "=", "-", "1", ")", "\n", "next_tokens", "=", "torch", ".", "multinomial", "(", "probs", ",", "num_samples", "=", "2", "*", "num_beams", ")", "# (batch_size, num_beams * 2)", "\n", "# Compute next scores", "\n", "next_scores", "=", "torch", ".", "gather", "(", "_scores", ",", "-", "1", ",", "next_tokens", ")", "# (batch_size, num_beams * 2)", "\n", "# sort the sampled vector to make sure that the first num_beams samples are the best", "\n", "next_scores", ",", "next_scores_indices", "=", "torch", ".", "sort", "(", "next_scores", ",", "descending", "=", "True", ",", "dim", "=", "1", ")", "\n", "next_tokens", "=", "torch", ".", "gather", "(", "next_tokens", ",", "-", "1", ",", "next_scores_indices", ")", "# (batch_size, num_beams * 2)", "\n", "\n", "", "else", ":", "\n", "                ", "next_scores", "=", "scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "scores", ")", "# (batch_size * num_beams, vocab_size)", "\n", "\n", "# re-organize to group the beam together (we are keeping top hypothesis accross beams)", "\n", "next_scores", "=", "next_scores", ".", "view", "(", "\n", "batch_size", ",", "num_beams", "*", "vocab_size", "\n", ")", "# (batch_size, num_beams * vocab_size)", "\n", "\n", "next_scores", ",", "next_tokens", "=", "torch", ".", "topk", "(", "next_scores", ",", "2", "*", "num_beams", ",", "dim", "=", "1", ",", "largest", "=", "True", ",", "sorted", "=", "True", ")", "\n", "\n", "", "assert", "next_scores", ".", "size", "(", ")", "==", "next_tokens", ".", "size", "(", ")", "==", "(", "batch_size", ",", "2", "*", "num_beams", ")", "\n", "\n", "# next batch beam content", "\n", "next_batch_beam", "=", "[", "]", "\n", "\n", "# for each sentence", "\n", "for", "batch_idx", "in", "range", "(", "batch_size", ")", ":", "\n", "\n", "# if we are done with this sentence", "\n", "                ", "if", "done", "[", "batch_idx", "]", ":", "\n", "                    ", "assert", "(", "\n", "len", "(", "generated_hyps", "[", "batch_idx", "]", ")", ">=", "num_beams", "\n", ")", ",", "\"Batch can only be done if at least {} beams have been generated\"", ".", "format", "(", "num_beams", ")", "\n", "assert", "(", "\n", "eos_token_id", "is", "not", "None", "and", "pad_token_id", "is", "not", "None", "\n", ")", ",", "\"generated beams >= num_beams -> eos_token_id and pad_token have to be defined\"", "\n", "next_batch_beam", ".", "extend", "(", "[", "(", "0", ",", "pad_token_id", ",", "0", ")", "]", "*", "num_beams", ")", "# pad the batch", "\n", "continue", "\n", "\n", "# next sentence beam content", "\n", "", "next_sent_beam", "=", "[", "]", "\n", "\n", "# next tokens for this sentence", "\n", "for", "beam_token_rank", ",", "(", "beam_token_id", ",", "beam_token_score", ")", "in", "enumerate", "(", "\n", "zip", "(", "next_tokens", "[", "batch_idx", "]", ",", "next_scores", "[", "batch_idx", "]", ")", "\n", ")", ":", "\n", "# get beam and token IDs", "\n", "                    ", "beam_id", "=", "beam_token_id", "//", "vocab_size", "\n", "token_id", "=", "beam_token_id", "%", "vocab_size", "\n", "\n", "effective_beam_id", "=", "batch_idx", "*", "num_beams", "+", "beam_id", "\n", "# add to generated hypotheses if end of sentence or last iteration", "\n", "if", "(", "eos_token_id", "is", "not", "None", ")", "and", "(", "token_id", ".", "item", "(", ")", "==", "eos_token_id", ")", ":", "\n", "# if beam_token does not belong to top num_beams tokens, it should not be added", "\n", "                        ", "is_beam_token_worse_than_top_num_beams", "=", "beam_token_rank", ">=", "num_beams", "\n", "if", "is_beam_token_worse_than_top_num_beams", ":", "\n", "                            ", "continue", "\n", "", "generated_hyps", "[", "batch_idx", "]", ".", "add", "(", "\n", "input_ids", "[", "effective_beam_id", "]", ".", "clone", "(", ")", ",", "beam_token_score", ".", "item", "(", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "# add next predicted token if it is not eos_token", "\n", "                        ", "next_sent_beam", ".", "append", "(", "(", "beam_token_score", ",", "token_id", ",", "effective_beam_id", ")", ")", "\n", "\n", "# the beam for next step is full", "\n", "", "if", "len", "(", "next_sent_beam", ")", "==", "num_beams", ":", "\n", "                        ", "break", "\n", "\n", "# Check if were done so that we can save a pad step if all(done)", "\n", "", "", "done", "[", "batch_idx", "]", "=", "done", "[", "batch_idx", "]", "or", "generated_hyps", "[", "batch_idx", "]", ".", "is_done", "(", "\n", "next_scores", "[", "batch_idx", "]", ".", "max", "(", ")", ".", "item", "(", ")", ",", "cur_len", "=", "cur_len", "\n", ")", "\n", "\n", "# update next beam content", "\n", "assert", "len", "(", "next_sent_beam", ")", "==", "num_beams", ",", "\"Beam should always be full\"", "\n", "next_batch_beam", ".", "extend", "(", "next_sent_beam", ")", "\n", "assert", "len", "(", "next_batch_beam", ")", "==", "num_beams", "*", "(", "batch_idx", "+", "1", ")", "\n", "\n", "# stop when we are done with each sentence", "\n", "", "if", "all", "(", "done", ")", ":", "\n", "                ", "break", "\n", "\n", "# sanity check / prepare next batch", "\n", "", "assert", "len", "(", "next_batch_beam", ")", "==", "batch_size", "*", "num_beams", "\n", "beam_scores", "=", "beam_scores", ".", "new", "(", "[", "x", "[", "0", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_tokens", "=", "input_ids", ".", "new", "(", "[", "x", "[", "1", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_idx", "=", "input_ids", ".", "new", "(", "[", "x", "[", "2", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "\n", "# re-order batch and update current length", "\n", "input_ids", "=", "input_ids", "[", "beam_idx", ",", ":", "]", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", ",", "beam_tokens", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# re-order internal states", "\n", "if", "past", "is", "not", "None", ":", "\n", "                ", "past", "=", "self", ".", "_reorder_cache", "(", "past", ",", "beam_idx", ")", "\n", "\n", "# extend attention_mask for new generated input if only decoder", "\n", "", "if", "self", ".", "config", ".", "is_encoder_decoder", "is", "False", ":", "\n", "                ", "attention_mask", "=", "torch", ".", "cat", "(", "\n", "[", "attention_mask", ",", "attention_mask", ".", "new_ones", "(", "(", "attention_mask", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "]", ",", "dim", "=", "-", "1", "\n", ")", "\n", "\n", "# finalize all open beam hypotheses and end to generated hypotheses", "\n", "", "", "for", "batch_idx", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "if", "done", "[", "batch_idx", "]", ":", "\n", "                ", "continue", "\n", "\n", "# test that beam scores match previously calculated scores if not eos and batch_idx not done", "\n", "", "if", "eos_token_id", "is", "not", "None", "and", "all", "(", "\n", "(", "token_id", "%", "vocab_size", ")", ".", "item", "(", ")", "is", "not", "eos_token_id", "for", "token_id", "in", "next_tokens", "[", "batch_idx", "]", "\n", ")", ":", "\n", "                ", "assert", "torch", ".", "all", "(", "\n", "next_scores", "[", "batch_idx", ",", ":", "num_beams", "]", "==", "beam_scores", ".", "view", "(", "batch_size", ",", "num_beams", ")", "[", "batch_idx", "]", "\n", ")", ",", "\"If batch_idx is not done, final next scores: {} have to equal to accumulated beam_scores: {}\"", ".", "format", "(", "\n", "next_scores", "[", ":", ",", ":", "num_beams", "]", "[", "batch_idx", "]", ",", "beam_scores", ".", "view", "(", "batch_size", ",", "num_beams", ")", "[", "batch_idx", "]", ",", "\n", ")", "\n", "\n", "# need to add best num_beams hypotheses to generated hyps", "\n", "", "for", "beam_id", "in", "range", "(", "num_beams", ")", ":", "\n", "                ", "effective_beam_id", "=", "batch_idx", "*", "num_beams", "+", "beam_id", "\n", "final_score", "=", "beam_scores", "[", "effective_beam_id", "]", ".", "item", "(", ")", "\n", "final_tokens", "=", "input_ids", "[", "effective_beam_id", "]", "\n", "generated_hyps", "[", "batch_idx", "]", ".", "add", "(", "final_tokens", ",", "final_score", ")", "\n", "\n", "# depending on whether greedy generation is wanted or not define different output_batch_size and output_num_return_sequences_per_batch", "\n", "", "", "output_batch_size", "=", "batch_size", "if", "do_sample", "else", "batch_size", "*", "num_return_sequences", "\n", "output_num_return_sequences_per_batch", "=", "1", "if", "do_sample", "else", "num_return_sequences", "\n", "\n", "# select the best hypotheses", "\n", "sent_lengths", "=", "input_ids", ".", "new", "(", "output_batch_size", ")", "\n", "best", "=", "[", "]", "\n", "\n", "# retrieve best hypotheses", "\n", "for", "i", ",", "hypotheses", "in", "enumerate", "(", "generated_hyps", ")", ":", "\n", "            ", "sorted_hyps", "=", "sorted", "(", "hypotheses", ".", "beams", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "for", "j", "in", "range", "(", "output_num_return_sequences_per_batch", ")", ":", "\n", "                ", "effective_batch_idx", "=", "output_num_return_sequences_per_batch", "*", "i", "+", "j", "\n", "best_hyp", "=", "sorted_hyps", ".", "pop", "(", ")", "[", "1", "]", "\n", "sent_lengths", "[", "effective_batch_idx", "]", "=", "len", "(", "best_hyp", ")", "\n", "best", ".", "append", "(", "best_hyp", ")", "\n", "\n", "# shorter batches are filled with pad_token", "\n", "", "", "if", "sent_lengths", ".", "min", "(", ")", ".", "item", "(", ")", "!=", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "assert", "pad_token_id", "is", "not", "None", ",", "\"`Pad_token_id` has to be defined\"", "\n", "sent_max_len", "=", "min", "(", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", "+", "1", ",", "max_length", ")", "\n", "decoded", "=", "input_ids", ".", "new", "(", "output_batch_size", ",", "sent_max_len", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "\n", "# fill with hypothesis and eos_token_id if necessary", "\n", "for", "i", ",", "hypo", "in", "enumerate", "(", "best", ")", ":", "\n", "                ", "decoded", "[", "i", ",", ":", "sent_lengths", "[", "i", "]", "]", "=", "hypo", "\n", "if", "sent_lengths", "[", "i", "]", "<", "max_length", ":", "\n", "                    ", "decoded", "[", "i", ",", "sent_lengths", "[", "i", "]", "]", "=", "eos_token_id", "\n", "", "", "", "else", ":", "\n", "# none of the hypotheses have an eos_token", "\n", "            ", "assert", "(", "len", "(", "hypo", ")", "==", "max_length", "for", "hypo", "in", "best", ")", "\n", "decoded", "=", "torch", ".", "stack", "(", "best", ")", ".", "type", "(", "torch", ".", "long", ")", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ")", "\n", "\n", "", "return", "decoded", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration._reorder_cache": [[1270, 1286], ["reordered_past.append", "enc_out.index_select", "enc_mask.index_select", "transformers.modeling_bart._reorder_buffer", "layer_past.items"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_reorder_cache", "(", "past", ",", "beam_idx", ")", ":", "\n", "        ", "(", "(", "enc_out", ",", "enc_mask", ")", ",", "decoder_cached_states", ")", "=", "past", "\n", "reordered_past", "=", "[", "]", "\n", "for", "layer_past", "in", "decoder_cached_states", ":", "\n", "# get the correct batch idx from decoder layer's batch dim for cross and self-attn", "\n", "            ", "layer_past_new", "=", "{", "\n", "attn_key", ":", "bart", ".", "_reorder_buffer", "(", "attn_cache", ",", "beam_idx", ")", "for", "attn_key", ",", "attn_cache", "in", "layer_past", ".", "items", "(", ")", "\n", "}", "\n", "reordered_past", ".", "append", "(", "layer_past_new", ")", "\n", "\n", "", "new_enc_out", "=", "enc_out", "if", "enc_out", "is", "None", "else", "enc_out", ".", "index_select", "(", "0", ",", "beam_idx", ")", "\n", "new_enc_mask", "=", "enc_mask", "if", "enc_mask", "is", "None", "else", "enc_mask", ".", "index_select", "(", "0", ",", "beam_idx", ")", "\n", "\n", "past", "=", "(", "(", "new_enc_out", ",", "new_enc_mask", ")", ",", "reordered_past", ")", "\n", "return", "past", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.resize_token_embeddings": [[1219, 1225], ["super().resize_token_embeddings", "transformers.modeling_bart.AMRBartForConditionalGeneration._resize_final_logits_bias"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.resize_token_embeddings", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration._resize_final_logits_bias"], ["", "def", "resize_token_embeddings", "(", "self", ",", "new_num_tokens", ":", "int", ")", "->", "nn", ".", "Embedding", ":", "\n", "        ", "old_num_tokens", "=", "self", ".", "model", ".", "shared", ".", "num_embeddings", "\n", "new_embeddings", "=", "super", "(", ")", ".", "resize_token_embeddings", "(", "new_num_tokens", ")", "\n", "self", ".", "model", ".", "shared", "=", "new_embeddings", "\n", "self", ".", "_resize_final_logits_bias", "(", "new_num_tokens", ",", "old_num_tokens", ")", "\n", "return", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration._resize_final_logits_bias": [[1226, 1233], ["transformers.modeling_bart.AMRBartForConditionalGeneration.register_buffer", "torch.zeros", "torch.cat"], "methods", ["None"], ["", "def", "_resize_final_logits_bias", "(", "self", ",", "new_num_tokens", ":", "int", ",", "old_num_tokens", ":", "int", ")", "->", "None", ":", "\n", "        ", "if", "new_num_tokens", "<=", "old_num_tokens", ":", "\n", "            ", "new_bias", "=", "self", ".", "final_logits_bias", "[", ":", ",", ":", "new_num_tokens", "]", "\n", "", "else", ":", "\n", "            ", "extra_bias", "=", "torch", ".", "zeros", "(", "(", "1", ",", "new_num_tokens", "-", "old_num_tokens", ")", ",", "device", "=", "self", ".", "final_logits_bias", ".", "device", ")", "\n", "new_bias", "=", "torch", ".", "cat", "(", "[", "self", ".", "final_logits_bias", ",", "extra_bias", "]", ",", "dim", "=", "1", ")", "\n", "", "self", ".", "register_buffer", "(", "\"final_logits_bias\"", ",", "new_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.prepare_inputs_for_generation": [[1234, 1249], ["None"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "decoder_input_ids", ",", "past", ",", "attention_mask", ",", "use_cache", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "past", "is", "not", "None", ",", "\"past has to be defined for encoder_outputs\"", "\n", "\n", "# first step, decoder_cached_states are empty", "\n", "if", "not", "past", "[", "1", "]", ":", "\n", "            ", "encoder_outputs", ",", "decoder_cached_states", "=", "past", ",", "None", "\n", "", "else", ":", "\n", "            ", "encoder_outputs", ",", "decoder_cached_states", "=", "past", "\n", "", "return", "{", "\n", "\"input_ids\"", ":", "None", ",", "# encoder_outputs is defined. input_ids not needed", "\n", "\"encoder_outputs\"", ":", "encoder_outputs", ",", "\n", "\"decoder_cached_states\"", ":", "decoder_cached_states", ",", "\n", "\"decoder_input_ids\"", ":", "decoder_input_ids", ",", "\n", "\"attention_mask\"", ":", "attention_mask", ",", "\n", "\"use_cache\"", ":", "use_cache", ",", "# change this to avoid caching (presumably for debugging)", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.prepare_logits_for_generation": [[1251, 1257], ["transformers.modeling_bart.AMRBartForConditionalGeneration._force_token_ids_generation"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration._force_token_ids_generation"], ["", "def", "prepare_logits_for_generation", "(", "self", ",", "logits", ",", "cur_len", ",", "max_length", ")", ":", "\n", "#if cur_len == 1:", "\n", "#    self._force_token_ids_generation(logits, self.config.bos_token_id)", "\n", "        ", "if", "cur_len", "==", "max_length", "-", "1", "and", "self", ".", "config", ".", "eos_token_id", "is", "not", "None", ":", "\n", "            ", "self", ".", "_force_token_ids_generation", "(", "logits", ",", "self", ".", "config", ".", "eos_token_id", ")", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration._force_token_ids_generation": [[1258, 1269], ["isinstance", "torch.tensor", "len", "float", "range", "next", "transformers.modeling_bart.AMRBartForConditionalGeneration.parameters"], "methods", ["None"], ["", "def", "_force_token_ids_generation", "(", "self", ",", "scores", ",", "token_ids", ")", "->", "None", ":", "\n", "        ", "\"\"\"force one of token_ids to be generated by setting prob of all other tokens to 0\"\"\"", "\n", "if", "isinstance", "(", "token_ids", ",", "int", ")", ":", "\n", "            ", "token_ids", "=", "[", "token_ids", "]", "\n", "", "all_but_token_ids_mask", "=", "torch", ".", "tensor", "(", "\n", "[", "x", "for", "x", "in", "range", "(", "self", ".", "config", ".", "vocab_size", ")", "if", "x", "not", "in", "token_ids", "]", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ",", "\n", ")", "\n", "assert", "len", "(", "scores", ".", "shape", ")", "==", "2", ",", "\"scores should be of rank 2 with shape: [batch_size, vocab_size]\"", "\n", "scores", "[", ":", ",", "all_but_token_ids_mask", "]", "=", "-", "float", "(", "\"inf\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.get_encoder": [[1287, 1289], ["None"], "methods", ["None"], ["", "def", "get_encoder", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.get_output_embeddings": [[1290, 1292], ["transformers.modeling_bart._make_linear_from_emb"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "bart", ".", "_make_linear_from_emb", "(", "self", ".", "model", ".", "shared", ")", "# make it on the fly", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.extract_backreferences": [[14, 25], ["ids.clone.clone", "ids.clone.clone", "torch.arange", "ids.clone.size"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["def", "extract_backreferences", "(", "ids", ",", "num_embeddings", ",", "backpointer_idx", ")", ":", "\n", "    ", "ids_mask", "=", "ids", ">=", "num_embeddings", "\n", "backreferences", "=", "ids", ".", "clone", "(", ")", "-", "num_embeddings", "\n", "backreferences", "[", "~", "ids_mask", "]", "=", "0", "\n", "backreferences", "+=", "(", "~", "ids_mask", ")", ".", "long", "(", ")", "*", "torch", ".", "arange", "(", "\n", "ids", ".", "size", "(", "1", ")", ",", "\n", "dtype", "=", "ids", ".", "dtype", ",", "\n", "device", "=", "ids", ".", "device", ")", "\n", "ids", "=", "ids", ".", "clone", "(", ")", "\n", "ids", "[", "ids_mask", "]", "=", "backpointer_idx", "\n", "return", "ids", ",", "backreferences", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.MultiTaskAmrTokenizer.__init__": [[32, 41], ["transformers.BartTokenizer.__init__", "regex.compile", "spring_amr.linearization.AMRLinearizer", "set"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "use_pointer_tokens", "=", "False", ",", "collapse_name_ops", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "patterns", "=", "re", ".", "compile", "(", "\n", "r\"\"\" ?<[a-z]+:?\\d*>| ?:[^\\s]+|'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"", ")", "\n", "self", ".", "linearizer", "=", "AMRLinearizer", "(", "use_pointer_tokens", "=", "use_pointer_tokens", ",", "collapse_name_ops", "=", "collapse_name_ops", ")", "\n", "self", ".", "use_pointer_tokens", "=", "use_pointer_tokens", "\n", "self", ".", "collapse_name_ops", "=", "collapse_name_ops", "\n", "self", ".", "recategorizations", "=", "set", "(", ")", "\n", "self", ".", "modified", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.MultiTaskAmrTokenizer.from_pretrained": [[42, 47], ["super().from_pretrained", "super().from_pretrained.init_amr_vocabulary"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.init_amr_vocabulary"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_path", ",", "pred_min", "=", "5", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "inst", "=", "super", "(", ")", ".", "from_pretrained", "(", "pretrained_model_path", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "inst", ".", "init_amr_vocabulary", "(", "pred_min", "=", "pred_min", ")", "\n", "return", "inst", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.MultiTaskAmrTokenizer.init_amr_vocabulary": [[48, 99], ["pathlib.Path().read_text().strip().splitlines", "pathlib.Path().read_text().strip().splitlines", "pathlib.Path().read_text().strip().splitlines", "pathlib.Path().read_text().strip().splitlines", "tokenization_bart.MultiTaskAmrTokenizer.add_special_tokens", "len", "enumerate", "len", "line.split", "tokens.append", "tokens.append", "tokens.append", "range", "pathlib.Path().read_text().strip", "int", "tokens.append", "pathlib.Path().read_text().strip", "pathlib.Path().read_text().strip", "pathlib.Path().read_text().strip", "tok.startswith", "tokenization_bart.MultiTaskAmrTokenizer.recategorizations.add", "tokens.append", "enumerate", "sorted", "sorted", "tokenization_bart.MultiTaskAmrTokenizer.encoder.items", "pathlib.Path().read_text", "pathlib.Path().read_text", "pathlib.Path().read_text", "pathlib.Path().read_text", "tokenization_bart.MultiTaskAmrTokenizer.encoder.items", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["", "def", "init_amr_vocabulary", "(", "self", ",", "pred_min", "=", "5", ")", ":", "\n", "        ", "for", "tok", "in", "[", "self", ".", "bos_token", ",", "self", ".", "eos_token", ",", "self", ".", "pad_token", ",", "'<mask>'", ",", "'<unk>'", "]", ":", "\n", "            ", "ntok", "=", "self", ".", "INIT", "+", "tok", "\n", "i", "=", "self", ".", "encoder", "[", "tok", "]", "\n", "self", ".", "decoder", "[", "i", "]", "=", "ntok", "\n", "del", "self", ".", "encoder", "[", "tok", "]", "\n", "self", ".", "encoder", "[", "ntok", "]", "=", "i", "\n", "\n", "", "tokens", "=", "[", "]", "\n", "for", "line", "in", "Path", "(", "ROOT", "/", "'data/vocab/predicates.txt'", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "tok", ",", "count", "=", "line", ".", "split", "(", ")", "\n", "if", "int", "(", "count", ")", ">=", "pred_min", ":", "\n", "                ", "tokens", ".", "append", "(", "tok", ")", "\n", "\n", "# add your vocab for one pretrain_task        ", "\n", "", "", "for", "tok", "in", "Path", "(", "\"../vocabs/dp_edges.txt\"", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "tok", ")", "\n", "\n", "", "for", "tok", "in", "Path", "(", "ROOT", "/", "'data/vocab/additions.txt'", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "tok", ")", "\n", "\n", "", "for", "tok", "in", "Path", "(", "ROOT", "/", "'data/vocab/recategorizations.txt'", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "if", "not", "tok", ".", "startswith", "(", "'_'", ")", ":", "\n", "                ", "self", ".", "recategorizations", ".", "add", "(", "tok", ")", "\n", "", "tokens", ".", "append", "(", "tok", ")", "\n", "\n", "", "if", "self", ".", "use_pointer_tokens", ":", "\n", "            ", "for", "cnt", "in", "range", "(", "512", ")", ":", "\n", "                ", "tokens", ".", "append", "(", "f\"<pointer:{cnt}>\"", ")", "\n", "\n", "", "", "tokens", "+=", "self", ".", "ADDITIONAL", "\n", "# HACK #", "\n", "# tokens += [self.INIT +\"S\",self.INIT +\"D\",self.INIT +\"A\"]", "\n", "\n", "self", ".", "add_special_tokens", "(", "{", "\"additional_special_tokens\"", ":", "[", "\"<amr>\"", ",", "\"<dp>\"", ",", "\"<srl>\"", "]", "}", ")", "\n", "\n", "\n", "tokens", "=", "[", "self", ".", "INIT", "+", "t", "if", "t", "[", "0", "]", "not", "in", "(", "'_'", ",", "'-'", ")", "else", "t", "for", "t", "in", "tokens", "]", "\n", "tokens", "=", "[", "t", "for", "t", "in", "tokens", "if", "t", "not", "in", "self", ".", "encoder", "]", "\n", "self", ".", "old_enc_size", "=", "old_enc_size", "=", "len", "(", "self", ".", "encoder", ")", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "tokens", ",", "start", "=", "old_enc_size", ")", ":", "\n", "            ", "self", ".", "encoder", "[", "t", "]", "=", "i", "\n", "\n", "", "self", ".", "encoder", "=", "{", "k", ":", "i", "for", "i", ",", "(", "k", ",", "v", ")", "in", "enumerate", "(", "sorted", "(", "self", ".", "encoder", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ")", "}", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "sorted", "(", "self", ".", "encoder", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "}", "\n", "self", ".", "modified", "=", "len", "(", "tokens", ")", "\n", "\n", "self", ".", "bos_token", "=", "self", ".", "INIT", "+", "'<s>'", "\n", "self", ".", "pad_token", "=", "self", ".", "INIT", "+", "'<pad>'", "\n", "self", ".", "eos_token", "=", "self", ".", "INIT", "+", "'</s>'", "\n", "self", ".", "unk_token", "=", "self", ".", "INIT", "+", "'<unk>'", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.MultiTaskAmrTokenizer.build_inputs_with_special_tokens_multi_task": [[100, 105], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens_multi_task", "(", "self", ",", "type_token", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "output", "=", "[", "self", ".", "bos_token_id", "]", "+", "[", "type_token", "]", "+", "token_ids_0", "+", "[", "self", ".", "eos_token_id", "]", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "output", "\n", "", "return", "output", "+", "[", "self", ".", "eos_token_id", "]", "+", "token_ids_1", "+", "[", "self", ".", "eos_token_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.MultiTaskAmrTokenizer.build_inputs_with_special_tokens": [[106, 111], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "output", "=", "[", "self", ".", "bos_token_id", "]", "+", "token_ids_0", "+", "[", "self", ".", "eos_token_id", "]", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "output", "\n", "", "return", "output", "+", "[", "self", ".", "eos_token_id", "]", "+", "token_ids_1", "+", "[", "self", ".", "eos_token_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.MultiTaskAmrTokenizer._tokenize": [[112, 128], ["text.lstrip().split", "tok_span.strip.strip.strip", "tok_span.strip.strip.rsplit", "text.lstrip", "bpe_tokens.extend", "regex.findall", "len", "bpe_tokens.extend", "token.encode", "tokenization_bart.MultiTaskAmrTokenizer.bpe().split", "tokenization_bart.MultiTaskAmrTokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. Modified in order to handle sentences with recategorization pointers\"\"\"", "\n", "bpe_tokens", "=", "[", "]", "\n", "for", "tok_span", "in", "text", ".", "lstrip", "(", ")", ".", "split", "(", "' '", ")", ":", "\n", "            ", "tok_span", "=", "tok_span", ".", "strip", "(", ")", "\n", "recats", "=", "tok_span", ".", "rsplit", "(", "'_'", ",", "1", ")", "\n", "if", "len", "(", "recats", ")", "==", "2", "and", "recats", "[", "0", "]", "in", "self", ".", "recategorizations", "and", "(", "'_'", "+", "recats", "[", "1", "]", ")", "in", "self", ".", "encoder", ":", "\n", "                ", "bpe_tokens", ".", "extend", "(", "[", "self", ".", "INIT", "+", "recats", "[", "0", "]", ",", "'_'", "+", "recats", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "for", "token", "in", "re", ".", "findall", "(", "self", ".", "pat", ",", "' '", "+", "tok_span", ")", ":", "\n", "                    ", "token", "=", "\"\"", ".", "join", "(", "\n", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "\"utf-8\"", ")", "\n", ")", "# Maps all our bytes to unicode strings, avoiding controle tokens of the BPE (spaces in our case)", "\n", "bpe_tokens", ".", "extend", "(", "bpe_token", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "\" \"", ")", ")", "\n", "\n", "", "", "", "return", "bpe_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.MultiTaskAmrTokenizer._tok_bpe": [[129, 144], ["token.strip", "token.strip.rsplit", "tokk.extend", "tokenization_bart.MultiTaskAmrTokenizer.patterns.findall", "len", "tokenization_bart.MultiTaskAmrTokenizer.bpe().split", "tokk.extend", "tokenization_bart.MultiTaskAmrTokenizer.bpe", "token.strip.encode"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode"], ["", "def", "_tok_bpe", "(", "self", ",", "token", ",", "add_space", "=", "True", ")", ":", "\n", "# if add_space:", "\n", "#     token = ' ' + token.lstrip()", "\n", "        ", "tokk", "=", "[", "]", "\n", "tok", "=", "token", ".", "strip", "(", ")", "\n", "recats", "=", "tok", ".", "rsplit", "(", "'_'", ",", "1", ")", "\n", "if", "len", "(", "recats", ")", "==", "2", "and", "recats", "[", "0", "]", "in", "self", ".", "recategorizations", "and", "(", "'_'", "+", "recats", "[", "1", "]", ")", "in", "self", ".", "encoder", ":", "\n", "            ", "tokk", ".", "extend", "(", "[", "self", ".", "INIT", "+", "recats", "[", "0", "]", ",", "'_'", "+", "recats", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "for", "tok", "in", "self", ".", "patterns", ".", "findall", "(", "' '", "+", "token", ")", ":", "\n", "                ", "tok", "=", "\"\"", ".", "join", "(", "\n", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "tok", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "toks", "=", "self", ".", "bpe", "(", "tok", ")", ".", "split", "(", "' '", ")", "\n", "tokk", ".", "extend", "(", "toks", ")", "\n", "", "", "return", "tokk", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.MultiTaskAmrTokenizer._get_nodes_and_backreferences": [[145, 149], ["tokenization_bart.MultiTaskAmrTokenizer.linearizer.linearize"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer.linearize"], ["", "def", "_get_nodes_and_backreferences", "(", "self", ",", "graph", ")", ":", "\n", "        ", "lin", "=", "self", ".", "linearizer", ".", "linearize", "(", "graph", ")", "\n", "linearized_nodes", ",", "backreferences", "=", "lin", ".", "nodes", ",", "lin", ".", "backreferences", "\n", "return", "linearized_nodes", ",", "backreferences", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.MultiTaskAmrTokenizer.tokenize_amr": [[150, 205], ["tokenization_bart.MultiTaskAmrTokenizer._get_nodes_and_backreferences", "enumerate", "zip", "bpe_tokens.append", "tokenization_bart.MultiTaskAmrTokenizer.encoder.get", "tokk[].replace.startswith", "tokk[].replace.startswith", "tokk[].replace.endswith", "tokk[].replace.startswith", "tokk[].replace.endswith", "regex.match", "tokk[].replace.startswith", "tokk[].replace.endswith", "tokk[].replace", "tokenization_bart.MultiTaskAmrTokenizer._tok_bpe", "tokenization_bart.MultiTaskAmrTokenizer.append", "list", "len", "bpe_backreferences.append", "bpe_backreferences.append", "len", "range", "tokenization_bart.MultiTaskAmrTokenizer._tok_bpe", "len", "tokenization_bart.MultiTaskAmrTokenizer._tok_bpe", "tokenization_bart.MultiTaskAmrTokenizer._tok_bpe", "tokenization_bart.MultiTaskAmrTokenizer._tok_bpe"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer._get_nodes_and_backreferences", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe"], ["", "def", "tokenize_amr", "(", "self", ",", "graph", ")", ":", "\n", "        ", "linearized_nodes", ",", "backreferences", "=", "self", ".", "_get_nodes_and_backreferences", "(", "graph", ")", "\n", "\n", "bpe_tokens", "=", "[", "]", "\n", "bpe_backreferences", "=", "[", "]", "\n", "counter", "=", "0", "\n", "\n", "for", "i", ",", "(", "backr", ",", "tokk", ")", "in", "enumerate", "(", "zip", "(", "backreferences", ",", "linearized_nodes", ")", ")", ":", "\n", "            ", "is_in_enc", "=", "self", ".", "INIT", "+", "tokk", "in", "self", ".", "encoder", "\n", "is_rel", "=", "tokk", ".", "startswith", "(", "':'", ")", "and", "len", "(", "tokk", ")", ">", "1", "\n", "is_spc", "=", "tokk", ".", "startswith", "(", "'<'", ")", "and", "tokk", ".", "endswith", "(", "'>'", ")", "\n", "is_of", "=", "tokk", ".", "startswith", "(", "':'", ")", "and", "tokk", ".", "endswith", "(", "'-of'", ")", "\n", "is_frame", "=", "re", ".", "match", "(", "r'.+-\\d\\d'", ",", "tokk", ")", "is", "not", "None", "\n", "\n", "if", "tokk", ".", "startswith", "(", "'\"'", ")", "and", "tokk", ".", "endswith", "(", "'\"'", ")", ":", "\n", "                ", "tokk", "=", "tokk", "[", "1", ":", "-", "1", "]", ".", "replace", "(", "'_'", ",", "' '", ")", "\n", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "AMRTokens", ".", "LIT_START", "]", "\n", "bpe_toks", "+=", "self", ".", "_tok_bpe", "(", "tokk", ",", "add_space", "=", "True", ")", "\n", "bpe_toks", ".", "append", "(", "self", ".", "INIT", "+", "AMRTokens", ".", "LIT_END", ")", "\n", "\n", "", "elif", "(", "is_rel", "or", "is_spc", "or", "is_frame", "or", "is_of", ")", ":", "\n", "                ", "if", "is_in_enc", ":", "\n", "                    ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "tokk", "]", "\n", "", "elif", "is_frame", ":", "\n", "                    ", "bpe_toks", "=", "self", ".", "_tok_bpe", "(", "tokk", "[", ":", "-", "3", "]", ",", "add_space", "=", "True", ")", "+", "[", "tokk", "[", "-", "3", ":", "]", "]", "\n", "", "elif", "is_of", ":", "\n", "                    ", "rel", "=", "tokk", "[", ":", "-", "3", "]", "\n", "if", "self", ".", "INIT", "+", "rel", "in", "self", ".", "encoder", ":", "\n", "                        ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "rel", ",", "'-of'", "]", "\n", "", "else", ":", "\n", "                        ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "':'", "]", "+", "self", ".", "_tok_bpe", "(", "rel", "[", "1", ":", "]", ",", "add_space", "=", "True", ")", "+", "[", "'-of'", "]", "\n", "", "", "elif", "is_rel", ":", "\n", "                    ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "':'", "]", "+", "self", ".", "_tok_bpe", "(", "tokk", "[", "1", ":", "]", ",", "add_space", "=", "True", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "\n", "\n", "", "", "else", ":", "\n", "                ", "if", "is_in_enc", ":", "\n", "                    ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "tokk", "]", "\n", "", "else", ":", "\n", "                    ", "bpe_toks", "=", "self", ".", "_tok_bpe", "(", "tokk", ",", "add_space", "=", "True", ")", "\n", "\n", "", "", "bpe_tokens", ".", "append", "(", "bpe_toks", ")", "\n", "\n", "if", "i", "==", "backr", ":", "\n", "                ", "bpe_backr", "=", "list", "(", "range", "(", "counter", ",", "counter", "+", "len", "(", "bpe_toks", ")", ")", ")", "\n", "counter", "+=", "len", "(", "bpe_toks", ")", "\n", "bpe_backreferences", ".", "append", "(", "bpe_backr", ")", "\n", "", "else", ":", "\n", "                ", "bpe_backreferences", ".", "append", "(", "bpe_backreferences", "[", "backr", "]", "[", "0", ":", "1", "]", ")", "\n", "counter", "+=", "1", "\n", "", "", "bpe_tokens", "=", "[", "b", "for", "bb", "in", "bpe_tokens", "for", "b", "in", "bb", "]", "\n", "bpe_token_ids", "=", "[", "self", ".", "encoder", ".", "get", "(", "b", ",", "self", ".", "unk_token_id", ")", "for", "b", "in", "bpe_tokens", "]", "\n", "bpe_backreferences", "=", "[", "b", "for", "bb", "in", "bpe_backreferences", "for", "b", "in", "bb", "]", "\n", "return", "bpe_tokens", ",", "bpe_token_ids", ",", "bpe_backreferences", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.MultiTaskAmrTokenizer.tokenize_dp": [[206, 223], ["dp.split", "tokenization_bart.MultiTaskAmrTokenizer.convert_tokens_to_ids", "len", "len", "tokenization_bart.MultiTaskAmrTokenizer._tok_bpe"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe"], ["", "def", "tokenize_dp", "(", "self", ",", "dp", ")", ":", "\n", "# (  ROOT  :root  (  introduced  :nsubj  (  members  :amod  Influential  :prep  (  of  :pobj  (  Ways  :det  the  :nn  House  :cc  and  :conj  (  Committee  :nn  Means  )  )  )  )  :dobj  (  legislation  :rcmod  (  restrict  :nsubj  that  :aux  would  :ccomp  (  raise  :advmod  how  :nsubj  (  agency  :det  the  :amod  new  :nn  savings-and-loan  :nn  bailout  )  :aux  can  :dobj  capital  )  :punct  ,  :xcomp  (  creating  :dobj  (  obstacle  :det  another  :amod  potential  :prep  (  to  :pobj  (  sale  :poss  (  government  :det  the  :possessive  's  )  :prep  (  of  :pobj  (  thrifts  :amod  sick  )  )  )  )  )  )  )  )  :punct  .  )  ) ", "\n", "        ", "snt", "=", "[", "]", "\n", "for", "i", "in", "dp", ".", "split", "(", "\" \"", ")", ":", "\n", "            ", "if", "i", "in", "dp_edges", ":", "\n", "                ", "assert", "self", ".", "INIT", "+", "i", "in", "self", ".", "encoder", "\n", "snt", "+=", "[", "self", ".", "INIT", "+", "i", "]", "\n", "", "elif", "self", ".", "INIT", "+", "i", "in", "self", ".", "encoder", ":", "\n", "                ", "snt", "+=", "[", "self", ".", "INIT", "+", "i", "]", "\n", "", "else", ":", "\n", "                ", "snt", "+=", "self", ".", "_tok_bpe", "(", "i", ")", "\n", "\n", "", "", "snt", "=", "snt", "[", ":", "-", "1", "]", "\n", "snt", "=", "[", "self", ".", "INIT", "+", "'<s>'", "]", "+", "snt", "+", "[", "self", ".", "INIT", "+", "'</s>'", "]", "\n", "snt_ids", "=", "self", ".", "convert_tokens_to_ids", "(", "snt", ")", "\n", "assert", "len", "(", "snt", ")", "==", "len", "(", "snt_ids", ")", "\n", "return", "snt_ids", ",", "snt", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.MultiTaskAmrTokenizer.batch_encode_sentences": [[224, 230], ["torch.device", "super().batch_encode_plus", "v.to", "super().batch_encode_plus.items"], "methods", ["None"], ["", "def", "batch_encode_sentences", "(", "self", ",", "sentences", ",", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", ":", "\n", "        ", "sentences", "=", "[", "s", "for", "s", "in", "sentences", "]", "\n", "extra", "=", "{", "'sentences'", ":", "sentences", "}", "\n", "batch", "=", "super", "(", ")", ".", "batch_encode_plus", "(", "sentences", ",", "return_tensors", "=", "'pt'", ",", "pad_to_max_length", "=", "True", ")", "\n", "batch", "=", "{", "k", ":", "v", ".", "to", "(", "device", ")", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", "}", "\n", "return", "batch", ",", "extra", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.MultiTaskAmrTokenizer.linearize": [[231, 243], ["len", "tokenization_bart.MultiTaskAmrTokenizer.tokenize_amr", "tokens.append", "token_ids.append", "token_uni_ids.append", "backreferences.append", "enumerate", "len", "zip"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer.tokenize_amr"], ["", "def", "linearize", "(", "self", ",", "graph", ")", ":", "\n", "        ", "shift", "=", "len", "(", "self", ".", "encoder", ")", "\n", "tokens", ",", "token_ids", ",", "backreferences", "=", "self", ".", "tokenize_amr", "(", "graph", ")", "\n", "extra", "=", "{", "'linearized_graphs'", ":", "tokens", ",", "'graphs'", ":", "graph", "}", "\n", "token_uni_ids", "=", "[", "idx", "if", "i", "==", "b", "else", "b", "+", "shift", "for", "i", ",", "(", "idx", ",", "b", ")", "in", "enumerate", "(", "zip", "(", "token_ids", ",", "backreferences", ")", ")", "]", "\n", "if", "token_uni_ids", "[", "-", "1", "]", "!=", "(", "self", ".", "INIT", "+", "AMRTokens", ".", "EOS_N", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "self", ".", "INIT", "+", "AMRTokens", ".", "EOS_N", ")", "\n", "token_ids", ".", "append", "(", "self", ".", "eos_token_id", ")", "\n", "token_uni_ids", ".", "append", "(", "self", ".", "eos_token_id", ")", "\n", "backreferences", ".", "append", "(", "len", "(", "backreferences", ")", ")", "\n", "", "return", "token_uni_ids", ",", "extra", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.MultiTaskAmrTokenizer.batch_encode_graphs": [[244, 247], ["torch.device", "zip", "tokenization_bart.MultiTaskAmrTokenizer.batch_encode_graphs_from_linearized", "tokenization_bart.MultiTaskAmrTokenizer.linearize"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_graphs_from_linearized", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer.linearize"], ["", "def", "batch_encode_graphs", "(", "self", ",", "graphs", ",", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", ":", "\n", "        ", "linearized", ",", "extras", "=", "zip", "(", "*", "[", "self", ".", "linearize", "(", "g", ")", "for", "g", "in", "graphs", "]", ")", "\n", "return", "self", ".", "batch_encode_graphs_from_linearized", "(", "linearized", ",", "extras", ",", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.MultiTaskAmrTokenizer.batch_encode_graphs_from_linearized": [[248, 265], ["torch.device", "torch.tensor().to", "max", "torch.tensor().to.append", "batch_extra[].append", "batch_extra[].append", "len", "torch.tensor", "len"], "methods", ["None"], ["", "def", "batch_encode_graphs_from_linearized", "(", "self", ",", "linearized", ",", "extras", "=", "None", ",", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", ":", "\n", "        ", "if", "extras", "is", "not", "None", ":", "\n", "            ", "batch_extra", "=", "{", "'linearized_graphs'", ":", "[", "]", ",", "'graphs'", ":", "[", "]", "}", "\n", "for", "extra", "in", "extras", ":", "\n", "                ", "batch_extra", "[", "'graphs'", "]", ".", "append", "(", "extra", "[", "'graphs'", "]", ")", "\n", "batch_extra", "[", "'linearized_graphs'", "]", ".", "append", "(", "extra", "[", "'linearized_graphs'", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "batch_extra", "=", "{", "}", "\n", "", "maxlen", "=", "0", "\n", "batch", "=", "[", "]", "\n", "for", "token_uni_ids", "in", "linearized", ":", "\n", "            ", "maxlen", "=", "max", "(", "len", "(", "token_uni_ids", ")", ",", "maxlen", ")", "\n", "batch", ".", "append", "(", "token_uni_ids", ")", "\n", "", "batch", "=", "[", "x", "+", "[", "self", ".", "pad_token_id", "]", "*", "(", "maxlen", "-", "len", "(", "x", ")", ")", "for", "x", "in", "batch", "]", "\n", "batch", "=", "torch", ".", "tensor", "(", "batch", ")", ".", "to", "(", "device", ")", "\n", "batch", "=", "{", "'decoder_input_ids'", ":", "batch", "[", ":", ",", ":", "-", "1", "]", ",", "'lm_labels'", ":", "batch", "[", ":", ",", "1", ":", "]", "}", "\n", "return", "batch", ",", "batch_extra", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.MultiTaskAmrTokenizer.decode_amr": [[266, 298], ["spring_amr.postprocessing.decode_into_node_and_backreferences", "spring_amr.postprocessing.restore_backreferences_from_pointers", "spring_amr.postprocessing.build_graph", "spring_amr.postprocessing.connect_graph_if_not_connected", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.decode_into_node_and_backreferences", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.restore_backreferences_from_pointers", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.build_graph", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.connect_graph_if_not_connected", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "decode_amr", "(", "self", ",", "tokens", ",", "restore_name_ops", "=", "False", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "nodes", ",", "backreferences", "=", "postprocessing", ".", "decode_into_node_and_backreferences", "(", "tokens", ",", "self", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Decoding failure:'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "postprocessing", ".", "BACKOFF", ",", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ",", "(", "None", ",", "None", ")", "\n", "", "if", "self", ".", "use_pointer_tokens", ":", "\n", "            ", "nodes", ",", "backreferences", "=", "postprocessing", ".", "restore_backreferences_from_pointers", "(", "nodes", ")", "\n", "", "try", ":", "\n", "            ", "graph_", "=", "graph", "=", "postprocessing", ".", "build_graph", "(", "nodes", ",", "backreferences", ",", "restore_name_ops", "=", "restore_name_ops", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Building failure:'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "nodes", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "backreferences", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "postprocessing", ".", "BACKOFF", ",", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ",", "(", "None", ",", "None", ")", "\n", "", "try", ":", "\n", "            ", "graph", ",", "status", "=", "postprocessing", ".", "connect_graph_if_not_connected", "(", "graph", ")", "\n", "if", "status", "==", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ":", "\n", "                ", "print", "(", "'Reconnection 1 failure:'", ")", "\n", "print", "(", "nodes", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "backreferences", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "graph_", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "", "return", "graph", ",", "status", ",", "(", "nodes", ",", "backreferences", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Reconnction 2 failure:'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "nodes", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "backreferences", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "graph_", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "postprocessing", ".", "BACKOFF", ",", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ",", "(", "nodes", ",", "backreferences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer.__init__": [[312, 321], ["transformers.BartTokenizer.__init__", "regex.compile", "spring_amr.linearization.AMRLinearizer", "set"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "use_pointer_tokens", "=", "False", ",", "collapse_name_ops", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "patterns", "=", "re", ".", "compile", "(", "\n", "r\"\"\" ?<[a-z]+:?\\d*>| ?:[^\\s]+|'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"", ")", "\n", "self", ".", "linearizer", "=", "AMRLinearizer", "(", "use_pointer_tokens", "=", "use_pointer_tokens", ",", "collapse_name_ops", "=", "collapse_name_ops", ")", "\n", "self", ".", "use_pointer_tokens", "=", "use_pointer_tokens", "\n", "self", ".", "collapse_name_ops", "=", "collapse_name_ops", "\n", "self", ".", "recategorizations", "=", "set", "(", ")", "\n", "self", ".", "modified", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer.from_pretrained": [[322, 327], ["super().from_pretrained", "super().from_pretrained.init_amr_vocabulary"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.init_amr_vocabulary"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_path", ",", "pred_min", "=", "5", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "inst", "=", "super", "(", ")", ".", "from_pretrained", "(", "pretrained_model_path", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "inst", ".", "init_amr_vocabulary", "(", "pred_min", "=", "pred_min", ")", "\n", "return", "inst", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer.init_amr_vocabulary": [[328, 373], ["pathlib.Path().read_text().strip().splitlines", "pathlib.Path().read_text().strip().splitlines", "pathlib.Path().read_text().strip().splitlines", "pathlib.Path().read_text().strip().splitlines", "len", "enumerate", "len", "line.split", "tokens.append", "tokens.append", "tokens.append", "range", "pathlib.Path().read_text().strip", "int", "tokens.append", "pathlib.Path().read_text().strip", "pathlib.Path().read_text().strip", "pathlib.Path().read_text().strip", "tok.startswith", "tokenization_bart.AMRBartTokenizer.recategorizations.add", "tokens.append", "enumerate", "sorted", "sorted", "tokenization_bart.AMRBartTokenizer.encoder.items", "pathlib.Path().read_text", "pathlib.Path().read_text", "pathlib.Path().read_text", "pathlib.Path().read_text", "tokenization_bart.AMRBartTokenizer.encoder.items", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["", "def", "init_amr_vocabulary", "(", "self", ",", "pred_min", "=", "5", ")", ":", "\n", "        ", "for", "tok", "in", "[", "self", ".", "bos_token", ",", "self", ".", "eos_token", ",", "self", ".", "pad_token", ",", "'<mask>'", ",", "'<unk>'", "]", ":", "\n", "            ", "ntok", "=", "self", ".", "INIT", "+", "tok", "\n", "i", "=", "self", ".", "encoder", "[", "tok", "]", "\n", "self", ".", "decoder", "[", "i", "]", "=", "ntok", "\n", "del", "self", ".", "encoder", "[", "tok", "]", "\n", "self", ".", "encoder", "[", "ntok", "]", "=", "i", "\n", "\n", "", "tokens", "=", "[", "]", "\n", "for", "line", "in", "Path", "(", "ROOT", "/", "'data/vocab/predicates.txt'", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "tok", ",", "count", "=", "line", ".", "split", "(", ")", "\n", "if", "int", "(", "count", ")", ">=", "pred_min", ":", "\n", "                ", "tokens", ".", "append", "(", "tok", ")", "\n", "\n", "# add your vocab for one pretrain_task        ", "\n", "", "", "for", "tok", "in", "Path", "(", "\"../vocabs/dp_edges.txt\"", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "tok", ")", "\n", "\n", "", "for", "tok", "in", "Path", "(", "ROOT", "/", "'data/vocab/additions.txt'", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "tok", ")", "\n", "\n", "", "for", "tok", "in", "Path", "(", "ROOT", "/", "'data/vocab/recategorizations.txt'", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "if", "not", "tok", ".", "startswith", "(", "'_'", ")", ":", "\n", "                ", "self", ".", "recategorizations", ".", "add", "(", "tok", ")", "\n", "", "tokens", ".", "append", "(", "tok", ")", "\n", "\n", "", "if", "self", ".", "use_pointer_tokens", ":", "\n", "            ", "for", "cnt", "in", "range", "(", "512", ")", ":", "\n", "                ", "tokens", ".", "append", "(", "f\"<pointer:{cnt}>\"", ")", "\n", "\n", "", "", "tokens", "+=", "self", ".", "ADDITIONAL", "\n", "tokens", "=", "[", "self", ".", "INIT", "+", "t", "if", "t", "[", "0", "]", "not", "in", "(", "'_'", ",", "'-'", ")", "else", "t", "for", "t", "in", "tokens", "]", "\n", "tokens", "=", "[", "t", "for", "t", "in", "tokens", "if", "t", "not", "in", "self", ".", "encoder", "]", "\n", "self", ".", "old_enc_size", "=", "old_enc_size", "=", "len", "(", "self", ".", "encoder", ")", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "tokens", ",", "start", "=", "old_enc_size", ")", ":", "\n", "            ", "self", ".", "encoder", "[", "t", "]", "=", "i", "\n", "\n", "", "self", ".", "encoder", "=", "{", "k", ":", "i", "for", "i", ",", "(", "k", ",", "v", ")", "in", "enumerate", "(", "sorted", "(", "self", ".", "encoder", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ")", "}", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "sorted", "(", "self", ".", "encoder", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "}", "\n", "self", ".", "modified", "=", "len", "(", "tokens", ")", "\n", "\n", "self", ".", "bos_token", "=", "self", ".", "INIT", "+", "'<s>'", "\n", "self", ".", "pad_token", "=", "self", ".", "INIT", "+", "'<pad>'", "\n", "self", ".", "eos_token", "=", "self", ".", "INIT", "+", "'</s>'", "\n", "self", ".", "unk_token", "=", "self", ".", "INIT", "+", "'<unk>'", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer.build_inputs_with_special_tokens": [[374, 379], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "output", "=", "[", "self", ".", "bos_token_id", "]", "+", "token_ids_0", "+", "[", "self", ".", "eos_token_id", "]", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "output", "\n", "", "return", "output", "+", "[", "self", ".", "eos_token_id", "]", "+", "token_ids_1", "+", "[", "self", ".", "eos_token_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer._tokenize": [[380, 396], ["text.lstrip().split", "tok_span.strip.strip.strip", "tok_span.strip.strip.rsplit", "text.lstrip", "bpe_tokens.extend", "regex.findall", "len", "bpe_tokens.extend", "token.encode", "tokenization_bart.AMRBartTokenizer.bpe().split", "tokenization_bart.AMRBartTokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. Modified in order to handle sentences with recategorization pointers\"\"\"", "\n", "bpe_tokens", "=", "[", "]", "\n", "for", "tok_span", "in", "text", ".", "lstrip", "(", ")", ".", "split", "(", "' '", ")", ":", "\n", "            ", "tok_span", "=", "tok_span", ".", "strip", "(", ")", "\n", "recats", "=", "tok_span", ".", "rsplit", "(", "'_'", ",", "1", ")", "\n", "if", "len", "(", "recats", ")", "==", "2", "and", "recats", "[", "0", "]", "in", "self", ".", "recategorizations", "and", "(", "'_'", "+", "recats", "[", "1", "]", ")", "in", "self", ".", "encoder", ":", "\n", "                ", "bpe_tokens", ".", "extend", "(", "[", "self", ".", "INIT", "+", "recats", "[", "0", "]", ",", "'_'", "+", "recats", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "for", "token", "in", "re", ".", "findall", "(", "self", ".", "pat", ",", "' '", "+", "tok_span", ")", ":", "\n", "                    ", "token", "=", "\"\"", ".", "join", "(", "\n", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "\"utf-8\"", ")", "\n", ")", "# Maps all our bytes to unicode strings, avoiding controle tokens of the BPE (spaces in our case)", "\n", "bpe_tokens", ".", "extend", "(", "bpe_token", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "\" \"", ")", ")", "\n", "\n", "", "", "", "return", "bpe_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer._tok_bpe": [[397, 413], ["token.strip", "token.strip.rsplit", "tokk.extend", "tokenization_bart.AMRBartTokenizer.patterns.findall", "len", "tokenization_bart.AMRBartTokenizer.bpe().split", "tokk.extend", "tokenization_bart.AMRBartTokenizer.bpe", "token.strip.encode"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode"], ["", "def", "_tok_bpe", "(", "self", ",", "token", ",", "add_space", "=", "True", ")", ":", "\n", "# if add_space:", "\n", "#     token = ' ' + token.lstrip()", "\n", "        ", "tokk", "=", "[", "]", "\n", "tok", "=", "token", ".", "strip", "(", ")", "\n", "recats", "=", "tok", ".", "rsplit", "(", "'_'", ",", "1", ")", "\n", "if", "len", "(", "recats", ")", "==", "2", "and", "recats", "[", "0", "]", "in", "self", ".", "recategorizations", "and", "(", "'_'", "+", "recats", "[", "1", "]", ")", "in", "self", ".", "encoder", ":", "\n", "            ", "tokk", ".", "extend", "(", "[", "self", ".", "INIT", "+", "recats", "[", "0", "]", ",", "'_'", "+", "recats", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "for", "tok", "in", "self", ".", "patterns", ".", "findall", "(", "' '", "+", "token", ")", ":", "# \u5982\u679c\u786e\u5b9a\u662f\u4e00\u4e2a\u5355\u8bcd\uff0c\u524d\u9762\u52a0\u7a7a\u683c\uff0c\u662f\u4e00\u4e2a\u7279\u70b9", "\n", "# BART \u4f7f\u7528\u7684\u662f byte-pair BPE \u8981\u8f6c\u6362\u6210\u7f16\u7801", "\n", "                ", "tok", "=", "\"\"", ".", "join", "(", "\n", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "tok", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "toks", "=", "self", ".", "bpe", "(", "tok", ")", ".", "split", "(", "' '", ")", "\n", "tokk", ".", "extend", "(", "toks", ")", "\n", "", "", "return", "tokk", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer._get_nodes_and_backreferences": [[414, 418], ["tokenization_bart.AMRBartTokenizer.linearizer.linearize"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer.linearize"], ["", "def", "_get_nodes_and_backreferences", "(", "self", ",", "graph", ")", ":", "\n", "        ", "lin", "=", "self", ".", "linearizer", ".", "linearize", "(", "graph", ")", "\n", "linearized_nodes", ",", "backreferences", "=", "lin", ".", "nodes", ",", "lin", ".", "backreferences", "\n", "return", "linearized_nodes", ",", "backreferences", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer.tokenize_amr": [[419, 474], ["tokenization_bart.AMRBartTokenizer._get_nodes_and_backreferences", "enumerate", "zip", "bpe_tokens.append", "tokenization_bart.AMRBartTokenizer.encoder.get", "tokk[].replace.startswith", "tokk[].replace.startswith", "tokk[].replace.endswith", "tokk[].replace.startswith", "tokk[].replace.endswith", "regex.match", "tokk[].replace.startswith", "tokk[].replace.endswith", "tokk[].replace", "tokenization_bart.AMRBartTokenizer._tok_bpe", "tokenization_bart.AMRBartTokenizer.append", "list", "len", "bpe_backreferences.append", "bpe_backreferences.append", "len", "range", "tokenization_bart.AMRBartTokenizer._tok_bpe", "len", "tokenization_bart.AMRBartTokenizer._tok_bpe", "tokenization_bart.AMRBartTokenizer._tok_bpe", "tokenization_bart.AMRBartTokenizer._tok_bpe"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer._get_nodes_and_backreferences", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe"], ["", "def", "tokenize_amr", "(", "self", ",", "graph", ")", ":", "\n", "        ", "linearized_nodes", ",", "backreferences", "=", "self", ".", "_get_nodes_and_backreferences", "(", "graph", ")", "\n", "\n", "bpe_tokens", "=", "[", "]", "\n", "bpe_backreferences", "=", "[", "]", "\n", "counter", "=", "0", "\n", "\n", "for", "i", ",", "(", "backr", ",", "tokk", ")", "in", "enumerate", "(", "zip", "(", "backreferences", ",", "linearized_nodes", ")", ")", ":", "\n", "            ", "is_in_enc", "=", "self", ".", "INIT", "+", "tokk", "in", "self", ".", "encoder", "\n", "is_rel", "=", "tokk", ".", "startswith", "(", "':'", ")", "and", "len", "(", "tokk", ")", ">", "1", "\n", "is_spc", "=", "tokk", ".", "startswith", "(", "'<'", ")", "and", "tokk", ".", "endswith", "(", "'>'", ")", "\n", "is_of", "=", "tokk", ".", "startswith", "(", "':'", ")", "and", "tokk", ".", "endswith", "(", "'-of'", ")", "\n", "is_frame", "=", "re", ".", "match", "(", "r'.+-\\d\\d'", ",", "tokk", ")", "is", "not", "None", "\n", "\n", "if", "tokk", ".", "startswith", "(", "'\"'", ")", "and", "tokk", ".", "endswith", "(", "'\"'", ")", ":", "# \u5e26\u5f15\u53f7\u7684\u53bb\u6389 \"United_States\" -> United_States", "\n", "                ", "tokk", "=", "tokk", "[", "1", ":", "-", "1", "]", ".", "replace", "(", "'_'", ",", "' '", ")", "# wiki\u5206\u8bcd  United_States -> United States", "\n", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "AMRTokens", ".", "LIT_START", "]", "# \u52a0\u5de6\u62ec\u53f7", "\n", "bpe_toks", "+=", "self", ".", "_tok_bpe", "(", "tokk", ",", "add_space", "=", "True", ")", "# bpe\u5206\u8bcd", "\n", "bpe_toks", ".", "append", "(", "self", ".", "INIT", "+", "AMRTokens", ".", "LIT_END", ")", "# \u52a0\u53f3\u62ec\u53f7", "\n", "\n", "", "elif", "(", "is_rel", "or", "is_spc", "or", "is_frame", "or", "is_of", ")", ":", "\n", "                ", "if", "is_in_enc", ":", "\n", "                    ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "tokk", "]", "\n", "", "elif", "is_frame", ":", "# go-05 \u5206\u8bcd\u6210 bpe(go) + \"-05\"", "\n", "                    ", "bpe_toks", "=", "self", ".", "_tok_bpe", "(", "tokk", "[", ":", "-", "3", "]", ",", "add_space", "=", "True", ")", "+", "[", "tokk", "[", "-", "3", ":", "]", "]", "\n", "", "elif", "is_of", ":", "\n", "                    ", "rel", "=", "tokk", "[", ":", "-", "3", "]", "\n", "if", "self", ".", "INIT", "+", "rel", "in", "self", ".", "encoder", ":", "\n", "                        ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "rel", ",", "'-of'", "]", "\n", "", "else", ":", "\n", "                        ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "':'", "]", "+", "self", ".", "_tok_bpe", "(", "rel", "[", "1", ":", "]", ",", "add_space", "=", "True", ")", "+", "[", "'-of'", "]", "\n", "", "", "elif", "is_rel", ":", "\n", "                    ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "':'", "]", "+", "self", ".", "_tok_bpe", "(", "tokk", "[", "1", ":", "]", ",", "add_space", "=", "True", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "\n", "\n", "", "", "else", ":", "\n", "                ", "if", "is_in_enc", ":", "\n", "                    ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "tokk", "]", "\n", "", "else", ":", "\n", "                    ", "bpe_toks", "=", "self", ".", "_tok_bpe", "(", "tokk", ",", "add_space", "=", "True", ")", "\n", "\n", "", "", "bpe_tokens", ".", "append", "(", "bpe_toks", ")", "\n", "\n", "if", "i", "==", "backr", ":", "\n", "                ", "bpe_backr", "=", "list", "(", "range", "(", "counter", ",", "counter", "+", "len", "(", "bpe_toks", ")", ")", ")", "\n", "counter", "+=", "len", "(", "bpe_toks", ")", "\n", "bpe_backreferences", ".", "append", "(", "bpe_backr", ")", "\n", "", "else", ":", "\n", "                ", "bpe_backreferences", ".", "append", "(", "bpe_backreferences", "[", "backr", "]", "[", "0", ":", "1", "]", ")", "\n", "counter", "+=", "1", "\n", "", "", "bpe_tokens", "=", "[", "b", "for", "bb", "in", "bpe_tokens", "for", "b", "in", "bb", "]", "\n", "bpe_token_ids", "=", "[", "self", ".", "encoder", ".", "get", "(", "b", ",", "self", ".", "unk_token_id", ")", "for", "b", "in", "bpe_tokens", "]", "\n", "bpe_backreferences", "=", "[", "b", "for", "bb", "in", "bpe_backreferences", "for", "b", "in", "bb", "]", "\n", "return", "bpe_tokens", ",", "bpe_token_ids", ",", "bpe_backreferences", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer.tokenize_dp": [[475, 510], ["dp.split", "tokenization_bart.AMRBartTokenizer.convert_tokens_to_ids", "len", "len", "i.replace.replace.replace", "len", "tokenization_bart.AMRBartTokenizer._tok_bpe", "tokenization_bart.AMRBartTokenizer._tok_bpe"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe"], ["", "def", "tokenize_dp", "(", "self", ",", "dp", ")", ":", "\n", "# (  ROOT  :root  (  introduced  :nsubj  (  members  :amod  Influential  :prep  (  of  :pobj  (  Ways  :det  the  :nn  House  :cc  and  :conj  (  Committee  :nn  Means  )  )  )  )  :dobj  (  legislation  :rcmod  (  restrict  :nsubj  that  :aux  would  :ccomp  (  raise  :advmod  how  :nsubj  (  agency  :det  the  :amod  new  :nn  savings-and-loan  :nn  bailout  )  :aux  can  :dobj  capital  )  :punct  ,  :xcomp  (  creating  :dobj  (  obstacle  :det  another  :amod  potential  :prep  (  to  :pobj  (  sale  :poss  (  government  :det  the  :possessive  's  )  :prep  (  of  :pobj  (  thrifts  :amod  sick  )  )  )  )  )  )  )  )  :punct  .  )  ) ", "\n", "\n", "# srl", "\n", "#( <pointer:0> multi-sentence :snt0 <pointer:1> be.03 :snt1 ( <pointer:2> close.01 :ARG1 <pointer:3> session ) :snt2 <pointer:4> session.01 :snt3 ( <pointer:5> need.01 :ARG1 <pointer:6> today 's rare closed session ) :snt4 ( <pointer:7> guard.01 :ARG0 <pointer:6> :ARG1 <pointer:8> national secrets ) ", "\n", "\n", "        ", "snt", "=", "[", "]", "\n", "for", "i", "in", "dp", ".", "split", "(", "\" \"", ")", ":", "\n", "            ", "if", "i", "in", "dp_edges", ":", "\n", "                ", "assert", "self", ".", "INIT", "+", "i", "in", "self", ".", "encoder", "\n", "snt", "+=", "[", "self", ".", "INIT", "+", "i", "]", "\n", "\n", "#HACK New From ARR Nov , is frame", "\n", "", "elif", "len", "(", "i", ")", ">", "3", "and", "i", "[", "-", "3", "]", "==", "\".\"", ":", "\n", "                ", "i", "=", "i", ".", "replace", "(", "\".\"", ",", "\"-\"", ")", "\n", "\n", "if", "self", ".", "INIT", "+", "i", "in", "self", ".", "encoder", ":", "\n", "                    ", "snt", "+=", "[", "self", ".", "INIT", "+", "i", "]", "\n", "", "else", ":", "\n", "                    ", "bpe_toks", "=", "self", ".", "_tok_bpe", "(", "i", "[", ":", "-", "3", "]", ",", "add_space", "=", "True", ")", "+", "[", "i", "[", "-", "3", ":", "]", "]", "\n", "snt", "+=", "bpe_toks", "\n", "\n", "\n", "", "", "elif", "self", ".", "INIT", "+", "i", "in", "self", ".", "encoder", ":", "\n", "                ", "snt", "+=", "[", "self", ".", "INIT", "+", "i", "]", "\n", "", "else", ":", "\n", "                ", "snt", "+=", "self", ".", "_tok_bpe", "(", "i", ")", "\n", "\n", "# HACK New From ARR Nov", "\n", "# snt = snt[:-1]", "\n", "\n", "", "", "snt", "=", "[", "self", ".", "INIT", "+", "'<s>'", "]", "+", "snt", "+", "[", "self", ".", "INIT", "+", "'</s>'", "]", "\n", "snt_ids", "=", "self", ".", "convert_tokens_to_ids", "(", "snt", ")", "\n", "assert", "len", "(", "snt", ")", "==", "len", "(", "snt_ids", ")", "\n", "return", "snt_ids", ",", "snt", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer.batch_encode_sentences": [[520, 526], ["torch.device", "super().batch_encode_plus", "v.to", "super().batch_encode_plus.items"], "methods", ["None"], ["", "def", "batch_encode_sentences", "(", "self", ",", "sentences", ",", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", ":", "\n", "        ", "sentences", "=", "[", "s", "for", "s", "in", "sentences", "]", "\n", "extra", "=", "{", "'sentences'", ":", "sentences", "}", "\n", "batch", "=", "super", "(", ")", ".", "batch_encode_plus", "(", "sentences", ",", "return_tensors", "=", "'pt'", ",", "pad_to_max_length", "=", "True", ")", "\n", "batch", "=", "{", "k", ":", "v", ".", "to", "(", "device", ")", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", "}", "\n", "return", "batch", ",", "extra", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer.linearize": [[529, 541], ["len", "tokenization_bart.AMRBartTokenizer.tokenize_amr", "tokens.append", "token_ids.append", "token_uni_ids.append", "backreferences.append", "enumerate", "len", "zip"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer.tokenize_amr"], ["", "def", "linearize", "(", "self", ",", "graph", ")", ":", "\n", "        ", "shift", "=", "len", "(", "self", ".", "encoder", ")", "\n", "tokens", ",", "token_ids", ",", "backreferences", "=", "self", ".", "tokenize_amr", "(", "graph", ")", "\n", "extra", "=", "{", "'linearized_graphs'", ":", "tokens", ",", "'graphs'", ":", "graph", "}", "\n", "token_uni_ids", "=", "[", "idx", "if", "i", "==", "b", "else", "b", "+", "shift", "for", "i", ",", "(", "idx", ",", "b", ")", "in", "enumerate", "(", "zip", "(", "token_ids", ",", "backreferences", ")", ")", "]", "\n", "if", "token_uni_ids", "[", "-", "1", "]", "!=", "(", "self", ".", "INIT", "+", "AMRTokens", ".", "EOS_N", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "self", ".", "INIT", "+", "AMRTokens", ".", "EOS_N", ")", "\n", "token_ids", ".", "append", "(", "self", ".", "eos_token_id", ")", "\n", "token_uni_ids", ".", "append", "(", "self", ".", "eos_token_id", ")", "\n", "backreferences", ".", "append", "(", "len", "(", "backreferences", ")", ")", "\n", "", "return", "token_uni_ids", ",", "extra", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer.batch_encode_graphs": [[542, 545], ["torch.device", "zip", "tokenization_bart.AMRBartTokenizer.batch_encode_graphs_from_linearized", "tokenization_bart.AMRBartTokenizer.linearize"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_graphs_from_linearized", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer.linearize"], ["", "def", "batch_encode_graphs", "(", "self", ",", "graphs", ",", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", ":", "\n", "        ", "linearized", ",", "extras", "=", "zip", "(", "*", "[", "self", ".", "linearize", "(", "g", ")", "for", "g", "in", "graphs", "]", ")", "\n", "return", "self", ".", "batch_encode_graphs_from_linearized", "(", "linearized", ",", "extras", ",", "device", "=", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer.batch_encode_graphs_from_linearized": [[546, 564], ["torch.device", "torch.tensor().to", "max", "torch.tensor().to.append", "batch_extra[].append", "batch_extra[].append", "len", "torch.tensor", "len"], "methods", ["None"], ["", "def", "batch_encode_graphs_from_linearized", "(", "self", ",", "linearized", ",", "extras", "=", "None", ",", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", ":", "\n", "        ", "if", "extras", "is", "not", "None", ":", "\n", "            ", "batch_extra", "=", "{", "'linearized_graphs'", ":", "[", "]", ",", "'graphs'", ":", "[", "]", "}", "\n", "for", "extra", "in", "extras", ":", "\n", "                ", "batch_extra", "[", "'graphs'", "]", ".", "append", "(", "extra", "[", "'graphs'", "]", ")", "\n", "batch_extra", "[", "'linearized_graphs'", "]", ".", "append", "(", "extra", "[", "'linearized_graphs'", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "batch_extra", "=", "{", "}", "\n", "", "maxlen", "=", "0", "\n", "batch", "=", "[", "]", "\n", "for", "token_uni_ids", "in", "linearized", ":", "\n", "            ", "maxlen", "=", "max", "(", "len", "(", "token_uni_ids", ")", ",", "maxlen", ")", "\n", "batch", ".", "append", "(", "token_uni_ids", ")", "\n", "", "batch", "=", "[", "x", "+", "[", "self", ".", "pad_token_id", "]", "*", "(", "maxlen", "-", "len", "(", "x", ")", ")", "for", "x", "in", "batch", "]", "\n", "batch", "=", "torch", ".", "tensor", "(", "batch", ")", ".", "to", "(", "device", ")", "\n", "batch", "=", "{", "'decoder_input_ids'", ":", "batch", "[", ":", ",", ":", "-", "1", "]", ",", "'lm_labels'", ":", "batch", "[", ":", ",", "1", ":", "]", "}", "\n", "\n", "return", "batch", ",", "batch_extra", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer.decode_amr": [[565, 597], ["spring_amr.postprocessing.decode_into_node_and_backreferences", "spring_amr.postprocessing.restore_backreferences_from_pointers", "spring_amr.postprocessing.build_graph", "spring_amr.postprocessing.connect_graph_if_not_connected", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.decode_into_node_and_backreferences", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.restore_backreferences_from_pointers", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.build_graph", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.connect_graph_if_not_connected", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "decode_amr", "(", "self", ",", "tokens", ",", "restore_name_ops", "=", "False", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "nodes", ",", "backreferences", "=", "postprocessing", ".", "decode_into_node_and_backreferences", "(", "tokens", ",", "self", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Decoding failure:'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "postprocessing", ".", "BACKOFF", ",", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ",", "(", "None", ",", "None", ")", "\n", "", "if", "self", ".", "use_pointer_tokens", ":", "\n", "            ", "nodes", ",", "backreferences", "=", "postprocessing", ".", "restore_backreferences_from_pointers", "(", "nodes", ")", "\n", "", "try", ":", "\n", "            ", "graph_", "=", "graph", "=", "postprocessing", ".", "build_graph", "(", "nodes", ",", "backreferences", ",", "restore_name_ops", "=", "restore_name_ops", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Building failure:'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "nodes", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "backreferences", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "postprocessing", ".", "BACKOFF", ",", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ",", "(", "None", ",", "None", ")", "\n", "", "try", ":", "\n", "            ", "graph", ",", "status", "=", "postprocessing", ".", "connect_graph_if_not_connected", "(", "graph", ")", "\n", "if", "status", "==", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ":", "\n", "                ", "print", "(", "'Reconnection 1 failure:'", ")", "\n", "print", "(", "nodes", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "backreferences", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "graph_", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "", "return", "graph", ",", "status", ",", "(", "nodes", ",", "backreferences", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Reconnction 2 failure:'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "nodes", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "backreferences", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "graph_", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "postprocessing", ".", "BACKOFF", ",", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ",", "(", "nodes", ",", "backreferences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.PENMANBartTokenizer.__init__": [[600, 605], ["tokenization_bart.AMRBartTokenizer.__init__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "raw_graph", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "linearizer", "=", "None", "\n", "self", ".", "remove_pars", "=", "False", "\n", "self", ".", "raw_graph", "=", "raw_graph", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.PENMANBartTokenizer._tokenize_encoded_graph": [[606, 622], ["regex.sub", "regex.sub().strip.split", "regex.sub().strip", "regex.sub().strip.split", "piece.strip.strip.startswith", "piece.strip.strip.endswith", "pieces.append", "piece.strip.strip.replace", "piece.strip.strip.replace", "piece.strip.strip.replace", "piece.strip.strip.replace", "piece.strip.strip.strip", "pieces.append", "regex.sub"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "_tokenize_encoded_graph", "(", "self", ",", "encoded", ")", ":", "\n", "        ", "linearized", "=", "re", ".", "sub", "(", "r\"(\\\".+?\\\")\"", ",", "r' \\1 '", ",", "encoded", ")", "\n", "pieces", "=", "[", "]", "\n", "for", "piece", "in", "linearized", ".", "split", "(", ")", ":", "\n", "            ", "if", "piece", ".", "startswith", "(", "'\"'", ")", "and", "piece", ".", "endswith", "(", "'\"'", ")", ":", "\n", "                ", "pieces", ".", "append", "(", "piece", ")", "\n", "", "else", ":", "\n", "                ", "piece", "=", "piece", ".", "replace", "(", "'('", ",", "' ( '", ")", "\n", "piece", "=", "piece", ".", "replace", "(", "')'", ",", "' ) '", ")", "\n", "piece", "=", "piece", ".", "replace", "(", "':'", ",", "' :'", ")", "\n", "piece", "=", "piece", ".", "replace", "(", "'/'", ",", "' / '", ")", "\n", "piece", "=", "piece", ".", "strip", "(", ")", "\n", "pieces", ".", "append", "(", "piece", ")", "\n", "", "", "linearized", "=", "re", ".", "sub", "(", "r'\\s+'", ",", "' '", ",", "' '", ".", "join", "(", "pieces", ")", ")", ".", "strip", "(", ")", "\n", "linearized_nodes", "=", "[", "AMRTokens", ".", "BOS_N", "]", "+", "linearized", ".", "split", "(", "' '", ")", "\n", "return", "linearized_nodes", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.PENMANBartTokenizer.tokenize_amr": [[623, 635], ["copy.deepcopy", "penman.encode", "regex.sub", "list", "tokenization_bart.AMRBartTokenizer.tokenize_amr", "tokenization_bart.PENMANBartTokenizer.encoder.get", "range", "tokenization_bart.PENMANBartTokenizer._tokenize", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer.tokenize_amr", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tokenize"], ["", "def", "tokenize_amr", "(", "self", ",", "graph", ")", ":", "\n", "        ", "if", "self", ".", "raw_graph", ":", "\n", "            ", "graph_", "=", "copy", ".", "deepcopy", "(", "graph", ")", "\n", "graph_", ".", "metadata", "=", "{", "}", "\n", "linearized", "=", "penman", ".", "encode", "(", "graph_", ")", "\n", "linearized", "=", "re", ".", "sub", "(", "r\"\\s+\"", ",", "' '", ",", "linearized", ")", "\n", "bpe_tokens", "=", "[", "self", ".", "bos_token", "]", "+", "self", ".", "_tokenize", "(", "linearized", ")", "[", ":", "1022", "]", "\n", "bpe_token_ids", "=", "[", "self", ".", "encoder", ".", "get", "(", "b", ",", "self", ".", "unk_token_id", ")", "for", "b", "in", "bpe_tokens", "]", "\n", "bpe_backreferences", "=", "list", "(", "range", "(", "len", "(", "bpe_token_ids", ")", ")", ")", "\n", "return", "bpe_tokens", ",", "bpe_token_ids", ",", "bpe_backreferences", "\n", "", "else", ":", "\n", "            ", "return", "super", "(", ")", ".", "tokenize_amr", "(", "graph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.PENMANBartTokenizer._get_nodes_and_backreferences": [[636, 667], ["copy.deepcopy", "penman.encode", "tokenization_bart.PENMANBartTokenizer._tokenize_encoded_graph", "list", "range", "range", "len", "len", "linearized_nodes_.append", "len", "lst.startswith", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer._tokenize_encoded_graph"], ["", "", "def", "_get_nodes_and_backreferences", "(", "self", ",", "graph", ")", ":", "\n", "        ", "graph_", "=", "copy", ".", "deepcopy", "(", "graph", ")", "\n", "graph_", ".", "metadata", "=", "{", "}", "\n", "linearized", "=", "penman", ".", "encode", "(", "graph_", ")", "\n", "linearized_nodes", "=", "self", ".", "_tokenize_encoded_graph", "(", "linearized", ")", "\n", "\n", "if", "self", ".", "use_pointer_tokens", ":", "\n", "            ", "remap", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "linearized_nodes", ")", ")", ":", "\n", "                ", "nxt", "=", "linearized_nodes", "[", "i", "]", "\n", "lst", "=", "linearized_nodes", "[", "i", "-", "1", "]", "\n", "if", "nxt", "==", "'/'", ":", "\n", "                    ", "remap", "[", "lst", "]", "=", "f'<pointer:{len(remap)}>'", "\n", "", "", "i", "=", "1", "\n", "linearized_nodes_", "=", "[", "linearized_nodes", "[", "0", "]", "]", "\n", "while", "i", "<", "(", "len", "(", "linearized_nodes", ")", ")", ":", "\n", "                ", "nxt", "=", "linearized_nodes", "[", "i", "]", "\n", "lst", "=", "linearized_nodes_", "[", "-", "1", "]", "\n", "if", "nxt", "in", "remap", ":", "\n", "                    ", "if", "lst", "==", "'('", "and", "linearized_nodes", "[", "i", "+", "1", "]", "==", "'/'", ":", "\n", "                        ", "nxt", "=", "remap", "[", "nxt", "]", "\n", "i", "+=", "1", "\n", "", "elif", "lst", ".", "startswith", "(", "':'", ")", ":", "\n", "                        ", "nxt", "=", "remap", "[", "nxt", "]", "\n", "", "", "linearized_nodes_", ".", "append", "(", "nxt", ")", "\n", "i", "+=", "1", "\n", "", "linearized_nodes", "=", "linearized_nodes_", "\n", "if", "self", ".", "remove_pars", ":", "\n", "                ", "linearized_nodes", "=", "[", "n", "for", "n", "in", "linearized_nodes", "if", "n", "!=", "'('", "]", "\n", "", "", "backreferences", "=", "list", "(", "range", "(", "len", "(", "linearized_nodes", ")", ")", ")", "\n", "return", "linearized_nodes", ",", "backreferences", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.PENMANBartTokenizer._classify": [[668, 694], ["isinstance", "regex.match", "node[].isdigit", "node.startswith", "node.endswith", "node.startswith", "node[].isalpha"], "methods", ["None"], ["", "def", "_classify", "(", "self", ",", "node", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "node", ",", "str", ")", ":", "\n", "            ", "return", "\"CONST\"", "\n", "", "elif", "node", "==", "'i'", ":", "\n", "            ", "return", "\"I\"", "\n", "", "elif", "re", ".", "match", "(", "r'^[a-z]\\d*$'", ",", "node", ")", "is", "not", "None", ":", "\n", "            ", "return", "\"VAR\"", "\n", "", "elif", "node", "[", "0", "]", ".", "isdigit", "(", ")", ":", "\n", "            ", "return", "\"CONST\"", "\n", "", "elif", "node", ".", "startswith", "(", "'\"'", ")", "and", "node", ".", "endswith", "(", "'\"'", ")", ":", "\n", "            ", "return", "\"CONST\"", "\n", "", "elif", "node", "in", "(", "'+'", ",", "'-'", ")", ":", "\n", "            ", "return", "\"CONST\"", "\n", "", "elif", "node", "==", "':mode'", ":", "\n", "            ", "return", "'MODE'", "\n", "", "elif", "node", ".", "startswith", "(", "':'", ")", ":", "\n", "            ", "return", "\"EDGE\"", "\n", "", "elif", "node", "in", "[", "'/'", ",", "'('", ",", "')'", "]", ":", "\n", "            ", "return", "node", "\n", "", "elif", "node", "[", "0", "]", ".", "isalpha", "(", ")", ":", "\n", "            ", "for", "char", "in", "(", "','", ",", "':'", ",", "'/'", ",", "'('", ",", "')'", ",", "'.'", ",", "'!'", ",", "'?'", ",", "'\\\\'", ")", ":", "\n", "                ", "if", "char", "in", "node", ":", "\n", "                    ", "return", "\"CONST\"", "\n", "", "", "return", "\"INST\"", "\n", "", "else", ":", "\n", "            ", "return", "'CONST'", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.PENMANBartTokenizer._fix_and_make_graph": [[695, 972], ["set", "regex.sub().strip", "penman.decode", "penman.Graph", "spring_amr.c_penman.encode", "tokenization_bart.PENMANBartTokenizer._fix_and_make_graph.fix_text"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode"], ["", "", "def", "_fix_and_make_graph", "(", "self", ",", "nodes", ")", ":", "\n", "\n", "        ", "nodes_", "=", "[", "]", "\n", "for", "n", "in", "nodes", ":", "\n", "            ", "if", "isinstance", "(", "n", ",", "str", ")", ":", "\n", "                ", "if", "n", ".", "startswith", "(", "'<'", ")", "and", "n", ".", "endswith", "(", "'>'", ")", "and", "(", "not", "n", ".", "startswith", "(", "'<pointer:'", ")", ")", ":", "\n", "                    ", "pass", "\n", "", "else", ":", "\n", "                    ", "nodes_", ".", "append", "(", "n", ")", "\n", "", "", "else", ":", "\n", "                ", "nodes_", ".", "append", "(", "n", ")", "\n", "", "", "nodes", "=", "nodes_", "\n", "\n", "if", "self", ".", "use_pointer_tokens", ":", "\n", "\n", "            ", "i", "=", "0", "\n", "nodes_", "=", "[", "]", "\n", "while", "i", "<", "len", "(", "nodes", ")", ":", "\n", "                ", "nxt", "=", "nodes", "[", "i", "]", "\n", "pst", "=", "None", "\n", "if", "isinstance", "(", "nxt", ",", "str", ")", "and", "nxt", ".", "startswith", "(", "'<pointer:'", ")", ":", "\n", "                    ", "e", "=", "nxt", ".", "find", "(", "'>'", ")", "\n", "if", "e", "!=", "len", "(", "nxt", ")", "-", "1", ":", "\n", "                        ", "pst", "=", "nxt", "[", "e", "+", "1", ":", "]", "\n", "nxt", "=", "nxt", "[", ":", "e", "+", "1", "]", "\n", "", "nodes_", ".", "append", "(", "nxt", ")", "\n", "if", "pst", "is", "not", "None", ":", "\n", "                        ", "nodes_", ".", "append", "(", "pst", ")", "\n", "", "", "else", ":", "\n", "                    ", "nodes_", ".", "append", "(", "nxt", ")", "\n", "", "i", "+=", "1", "\n", "", "nodes", "=", "nodes_", "\n", "\n", "i", "=", "1", "\n", "nodes_", "=", "[", "nodes", "[", "0", "]", "]", "\n", "while", "i", "<", "len", "(", "nodes", ")", ":", "\n", "                ", "nxt", "=", "nodes", "[", "i", "]", "\n", "if", "isinstance", "(", "nxt", ",", "str", ")", "and", "nxt", ".", "startswith", "(", "'<pointer:'", ")", ":", "\n", "                    ", "nxt", "=", "'z'", "+", "nxt", "[", "9", ":", "-", "1", "]", "\n", "fol", "=", "nodes", "[", "i", "+", "1", "]", "\n", "# is not expansion", "\n", "if", "isinstance", "(", "fol", ",", "str", ")", "and", "(", "fol", ".", "startswith", "(", "':'", ")", "or", "(", "fol", "==", "')'", ")", ")", ":", "\n", "                        ", "nodes_", ".", "append", "(", "nxt", ")", "\n", "", "else", ":", "\n", "                        ", "if", "self", ".", "remove_pars", ":", "\n", "                            ", "nodes_", ".", "append", "(", "'('", ")", "\n", "", "else", ":", "\n", "                            ", "if", "nodes_", "[", "-", "1", "]", "!=", "'('", ":", "\n", "                                ", "nodes_", ".", "append", "(", "'('", ")", "\n", "#pass", "\n", "", "", "nodes_", ".", "append", "(", "nxt", ")", "\n", "nodes_", ".", "append", "(", "'/'", ")", "\n", "", "", "else", ":", "\n", "                    ", "nodes_", ".", "append", "(", "nxt", ")", "\n", "", "i", "+=", "1", "\n", "", "nodes", "=", "nodes_", "\n", "\n", "", "i", "=", "0", "\n", "nodes_", "=", "[", "]", "\n", "while", "i", "<", "(", "len", "(", "nodes", ")", "-", "1", ")", ":", "\n", "            ", "if", "nodes", "[", "i", "]", "==", "':'", ":", "\n", "                ", "nodes_", ".", "append", "(", "nodes", "[", "i", "]", "+", "nodes", "[", "i", "+", "1", "]", ")", "\n", "i", "+=", "2", "\n", "last", "=", "False", "\n", "", "else", ":", "\n", "                ", "nodes_", ".", "append", "(", "nodes", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "last", "=", "True", "\n", "", "", "if", "last", ":", "\n", "            ", "nodes_", ".", "append", "(", "nodes", "[", "-", "1", "]", ")", "\n", "", "nodes", "=", "nodes_", "\n", "\n", "i", "=", "0", "\n", "nodes_", "=", "[", "]", "\n", "while", "i", "<", "(", "len", "(", "nodes", ")", ")", ":", "\n", "            ", "if", "i", "<", "2", ":", "\n", "                ", "nodes_", ".", "append", "(", "nodes", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "elif", "nodes_", "[", "-", "2", "]", "==", "'/'", "and", "nodes", "[", "i", "]", "==", "'/'", ":", "\n", "                ", "i", "+=", "2", "\n", "", "else", ":", "\n", "                ", "nodes_", ".", "append", "(", "nodes", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "nodes", "=", "nodes_", "\n", "\n", "i", "=", "0", "\n", "newvars", "=", "0", "\n", "variables", "=", "set", "(", ")", "\n", "remap", "=", "{", "}", "\n", "nodes_", "=", "[", "]", "\n", "while", "i", "<", "(", "len", "(", "nodes", ")", ")", ":", "\n", "\n", "            ", "next", "=", "nodes", "[", "i", "]", "\n", "\n", "if", "next", "==", "'/'", ":", "\n", "                ", "last", "=", "nodes_", "[", "-", "1", "]", "\n", "if", "last", "in", "variables", ":", "\n", "                    ", "last_remap", "=", "f\"z{newvars+1000}\"", "\n", "newvars", "+=", "1", "\n", "nodes_", "[", "-", "1", "]", "=", "last_remap", "\n", "remap", "[", "last", "]", "=", "last_remap", "\n", "", "variables", ".", "add", "(", "last", ")", "\n", "nodes_", ".", "append", "(", "next", ")", "\n", "\n", "", "elif", "self", ".", "_classify", "(", "next", ")", "==", "'VAR'", "and", "next", "in", "remap", "and", "(", "i", "<", "len", "(", "nodes", ")", "-", "1", ")", "and", "nodes", "[", "i", "+", "1", "]", "!=", "'/'", ":", "\n", "                ", "next", "=", "remap", "[", "next", "]", "\n", "nodes_", ".", "append", "(", "next", ")", "\n", "\n", "", "else", ":", "\n", "                ", "nodes_", ".", "append", "(", "next", ")", "\n", "\n", "", "i", "+=", "1", "\n", "\n", "", "nodes", "=", "nodes_", "\n", "pieces_", "=", "[", "]", "\n", "open_cnt", "=", "0", "\n", "closed_cnt", "=", "0", "\n", "if", "nodes", "[", "0", "]", "!=", "'('", ":", "\n", "            ", "pieces_", ".", "append", "(", "'('", ")", "\n", "open_cnt", "+=", "1", "\n", "", "for", "p", "in", "nodes", ":", "\n", "            ", "if", "p", "==", "'('", ":", "\n", "                ", "open_cnt", "+=", "1", "\n", "", "elif", "p", "==", "')'", ":", "\n", "                ", "closed_cnt", "+=", "1", "\n", "", "pieces_", ".", "append", "(", "p", ")", "\n", "if", "open_cnt", "==", "closed_cnt", ":", "\n", "                ", "break", "\n", "", "", "nodes", "=", "pieces_", "+", "[", "')'", "]", "*", "(", "open_cnt", "-", "closed_cnt", ")", "\n", "\n", "pieces", "=", "[", "]", "\n", "for", "piece", "in", "nodes", ":", "\n", "            ", "if", "not", "pieces", ":", "\n", "                ", "pieces", ".", "append", "(", "'('", ")", "\n", "", "else", ":", "\n", "                ", "piece", "=", "str", "(", "piece", ")", "\n", "if", "piece", ".", "startswith", "(", "'\"'", ")", "or", "piece", ".", "startswith", "(", "'\"'", ")", "or", "'\"'", "in", "piece", ".", "strip", "(", "'\"'", ")", ":", "\n", "                    ", "piece", "=", "'\"'", "+", "piece", ".", "replace", "(", "'\"'", ",", "''", ")", "+", "'\"'", "\n", "\n", "", "prev", "=", "self", ".", "_classify", "(", "pieces", "[", "-", "1", "]", ")", "\n", "next", "=", "self", ".", "_classify", "(", "piece", ")", "\n", "\n", "if", "next", "==", "'CONST'", ":", "\n", "                    ", "quote", "=", "False", "\n", "for", "char", "in", "(", "','", ",", "':'", ",", "'/'", ",", "'('", ",", "')'", ",", "'.'", ",", "'!'", ",", "'?'", ",", "'\\\\'", ",", "'_'", ",", "'='", ")", ":", "\n", "                        ", "if", "char", "in", "piece", ":", "\n", "                            ", "quote", "=", "True", "\n", "break", "\n", "", "", "if", "quote", ":", "\n", "                        ", "piece", "=", "'\"'", "+", "piece", ".", "strip", "(", "'\"'", ")", "+", "'\"'", "\n", "\n", "", "", "if", "prev", "==", "'('", ":", "\n", "                    ", "if", "next", "in", "(", "'VAR'", ",", "'I'", ")", ":", "\n", "                        ", "pieces", ".", "append", "(", "piece", ")", "\n", "", "", "elif", "prev", "==", "')'", ":", "\n", "                    ", "if", "next", "in", "(", "')'", ",", "'EDGE'", ",", "'MODE'", ")", ":", "\n", "                        ", "pieces", ".", "append", "(", "piece", ")", "\n", "", "", "elif", "prev", "==", "'VAR'", ":", "\n", "                    ", "if", "next", "in", "(", "'/'", ",", "'EDGE'", ",", "'MODE'", ",", "')'", ")", ":", "\n", "                        ", "pieces", ".", "append", "(", "piece", ")", "\n", "", "", "elif", "prev", "==", "'/'", ":", "\n", "                    ", "if", "next", "in", "(", "'INST'", ",", "'I'", ")", ":", "\n", "                        ", "pieces", ".", "append", "(", "piece", ")", "\n", "", "", "elif", "prev", "==", "'INST'", ":", "\n", "                    ", "if", "next", "in", "(", "')'", ",", "'EDGE'", ",", "'MODE'", ")", ":", "\n", "                        ", "pieces", ".", "append", "(", "piece", ")", "\n", "", "", "elif", "prev", "==", "'I'", ":", "\n", "                    ", "if", "next", "in", "(", "'/'", ",", "')'", ",", "'EDGE'", ",", "'MODE'", ")", ":", "\n", "                        ", "pieces", ".", "append", "(", "piece", ")", "\n", "", "", "elif", "prev", "==", "'EDGE'", ":", "\n", "                    ", "if", "next", "in", "(", "'('", ",", "'VAR'", ",", "'CONST'", ",", "'I'", ")", ":", "\n", "                        ", "pieces", ".", "append", "(", "piece", ")", "\n", "", "elif", "next", "==", "')'", ":", "\n", "                        ", "pieces", "[", "-", "1", "]", "=", "piece", "\n", "", "elif", "next", "in", "(", "'EDGE'", ",", "'MODE'", ")", ":", "\n", "                        ", "pieces", "[", "-", "1", "]", "=", "piece", "\n", "", "", "elif", "prev", "==", "'MODE'", ":", "\n", "                    ", "if", "next", "==", "'INST'", ":", "\n", "                        ", "pieces", ".", "append", "(", "piece", ")", "\n", "", "", "elif", "prev", "==", "'CONST'", ":", "\n", "                    ", "if", "next", "in", "(", "')'", ",", "'EDGE'", ",", "'MODE'", ")", ":", "\n", "                        ", "pieces", ".", "append", "(", "piece", ")", "\n", "\n", "", "", "", "", "pieces_", "=", "[", "]", "\n", "open_cnt", "=", "0", "\n", "closed_cnt", "=", "0", "\n", "if", "pieces", "[", "0", "]", "!=", "'('", ":", "\n", "            ", "pieces_", ".", "append", "(", "'('", ")", "\n", "open_cnt", "+=", "1", "\n", "", "for", "p", "in", "pieces", ":", "\n", "            ", "if", "p", "==", "'('", ":", "\n", "                ", "open_cnt", "+=", "1", "\n", "", "elif", "p", "==", "')'", ":", "\n", "                ", "closed_cnt", "+=", "1", "\n", "", "pieces_", ".", "append", "(", "p", ")", "\n", "if", "open_cnt", "==", "closed_cnt", ":", "\n", "                ", "break", "\n", "", "", "pieces", "=", "pieces_", "+", "[", "')'", "]", "*", "(", "open_cnt", "-", "closed_cnt", ")", "\n", "\n", "linearized", "=", "re", ".", "sub", "(", "r'\\s+'", ",", "' '", ",", "' '", ".", "join", "(", "pieces", ")", ")", ".", "strip", "(", ")", "\n", "\n", "\"\"\"\n        line = linearized\n        # make sure parentheses match\n        # copied from https://github.com/RikVN/AMR/blob/master/restoreAMR/restore_amr.py\n        open_count = 0\n        close_count = 0\n        for i, c in enumerate(line):\n            if c == '(':\n                open_count += 1\n            elif c == ')':\n                close_count += 1\n            if open_count == close_count and open_count > 0:\n                line = line[:i].strip()\n                break\n        old_line = line\n        while True:\n            open_count = len(re.findall(r'\\(', line))\n            close_count = len(re.findall(r'\\)', line))\n            if open_count > close_count:\n                line += ')' * (open_count - close_count)\n            elif close_count > open_count:\n                for i in range(close_count - open_count):\n                    line = line.rstrip(')')\n                    line = line.rstrip(' ')\n            if old_line == line:\n                break\n            old_line = line\n        \"\"\"", "\n", "\n", "graph", "=", "penman", ".", "decode", "(", "linearized", "+", "' '", ")", "\n", "triples", "=", "[", "]", "\n", "newvars", "=", "2000", "\n", "for", "triple", "in", "graph", ".", "triples", ":", "\n", "            ", "x", ",", "rel", ",", "y", "=", "triple", "\n", "if", "x", "is", "None", ":", "\n", "                ", "pass", "\n", "", "elif", "rel", "==", "':instance'", "and", "y", "is", "None", ":", "\n", "                ", "triples", ".", "append", "(", "penman", ".", "Triple", "(", "x", ",", "rel", ",", "'thing'", ")", ")", "\n", "", "elif", "y", "is", "None", ":", "\n", "                ", "var", "=", "f'z{newvars}'", "\n", "newvars", "+=", "1", "\n", "triples", ".", "append", "(", "penman", ".", "Triple", "(", "x", ",", "rel", ",", "var", ")", ")", "\n", "triples", ".", "append", "(", "penman", ".", "Triple", "(", "var", ",", "':instance'", ",", "'thing'", ")", ")", "\n", "", "else", ":", "\n", "                ", "triples", ".", "append", "(", "triple", ")", "\n", "", "", "graph", "=", "penman", ".", "Graph", "(", "triples", ")", "\n", "linearized", "=", "encode", "(", "graph", ")", "\n", "\n", "def", "fix_text", "(", "linearized", "=", "linearized", ")", ":", "\n", "            ", "n", "=", "0", "\n", "def", "_repl1", "(", "match", ")", ":", "\n", "                ", "nonlocal", "n", "\n", "out", "=", "match", ".", "group", "(", "1", ")", "+", "match", ".", "group", "(", "2", ")", "+", "str", "(", "3000", "+", "n", ")", "+", "' / '", "+", "match", ".", "group", "(", "2", ")", "+", "match", ".", "group", "(", "3", ")", "\n", "n", "+=", "1", "\n", "return", "out", "\n", "", "linearized", "=", "re", ".", "sub", "(", "r'(\\(\\s?)([a-z])([^\\/:\\)]+[:\\)])'", ",", "_repl1", ",", "linearized", ",", "\n", "flags", "=", "re", ".", "IGNORECASE", "|", "re", ".", "MULTILINE", ")", "\n", "\n", "def", "_repl2", "(", "match", ")", ":", "\n", "                ", "return", "match", ".", "group", "(", "1", ")", "\n", "", "linearized", "=", "re", ".", "sub", "(", "r'(\\(\\s*[a-z][\\d+]\\s*\\/\\s*[^\\s\\)\\(:\\/]+\\s*)((?:/\\s*[^\\s\\)\\(:\\/]+\\s*)+)'", ",", "_repl2", ",", "\n", "linearized", ",", "\n", "flags", "=", "re", ".", "IGNORECASE", "|", "re", ".", "MULTILINE", ")", "\n", "\n", "# adds a ':' to args w/o it", "\n", "linearized", "=", "re", ".", "sub", "(", "r'([^:])(ARG)'", ",", "r'\\1 :\\2'", ",", "linearized", ")", "\n", "\n", "# removes edges with no node", "\n", "# linearized = re.sub(r':[^\\s\\)\\(:\\/]+?\\s*\\)', ')', linearized, flags=re.MULTILINE)", "\n", "\n", "return", "linearized", "\n", "\n", "", "linearized", "=", "fix_text", "(", "linearized", ")", "\n", "\n", "g", "=", "penman", ".", "decode", "(", "linearized", ")", "\n", "return", "g", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.PENMANBartTokenizer.decode_amr": [[973, 1010], ["tokenization_bart.PENMANBartTokenizer._fix_and_make_graph", "spring_amr.postprocessing.connect_graph_if_not_connected", "tokenization_bart.PENMANBartTokenizer._tokenize_encoded_graph", "list", "spring_amr.postprocessing.decode_into_node_and_backreferences", "print", "print", "spring_amr.postprocessing._split_name_ops", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "tokenization_bart.PENMANBartTokenizer.decode", "range", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer._fix_and_make_graph", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.connect_graph_if_not_connected", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer._tokenize_encoded_graph", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.decode_into_node_and_backreferences", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing._split_name_ops", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "decode_amr", "(", "self", ",", "tokens", ",", "restore_name_ops", "=", "None", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "if", "self", ".", "raw_graph", ":", "\n", "                ", "nodes", "=", "self", ".", "_tokenize_encoded_graph", "(", "self", ".", "decode", "(", "tokens", ")", ")", "\n", "backreferences", "=", "list", "(", "range", "(", "len", "(", "nodes", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "nodes", ",", "backreferences", "=", "postprocessing", ".", "decode_into_node_and_backreferences", "(", "tokens", ",", "self", ")", "\n", "", "nodes_", "=", "nodes", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Decoding failure:'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "postprocessing", ".", "BACKOFF", ",", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ",", "(", "None", ",", "None", ")", "\n", "", "try", ":", "\n", "            ", "graph_", "=", "graph", "=", "self", ".", "_fix_and_make_graph", "(", "nodes", ")", "\n", "if", "self", ".", "collapse_name_ops", ":", "\n", "                ", "graph_", "=", "graph", "=", "postprocessing", ".", "_split_name_ops", "(", "graph", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Building failure:'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "nodes", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "backreferences", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "postprocessing", ".", "BACKOFF", ",", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ",", "(", "None", ",", "None", ")", "\n", "", "try", ":", "\n", "            ", "graph", ",", "status", "=", "postprocessing", ".", "connect_graph_if_not_connected", "(", "graph", ")", "\n", "if", "status", "==", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ":", "\n", "                ", "print", "(", "'Reconnection 1 failure:'", ")", "\n", "print", "(", "nodes", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "backreferences", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "graph_", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "", "return", "graph", ",", "status", ",", "(", "nodes_", ",", "backreferences", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Reconnction 2 failure:'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "nodes", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "backreferences", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "graph_", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "postprocessing", ".", "BACKOFF", ",", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ",", "(", "nodes_", ",", "backreferences", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.linearization.SemanticGraph.variables": [[36, 41], ["v.startswith"], "methods", ["None"], ["@", "cached_property", "\n", "def", "variables", "(", "self", ")", "->", "Set", "[", "str", "]", ":", "\n", "        ", "\"\"\"Set of variables in this semantic graph\"\"\"", "\n", "variables", "=", "{", "v", "for", "v", "in", "self", ".", "nodes_var", "if", "not", "v", ".", "startswith", "(", "'<'", ")", "}", "\n", "return", "variables", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.linearization.SemanticGraph.resolved_nodes_var": [[42, 45], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "resolved_nodes_var", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "return", "[", "self", ".", "nodes_var", "[", "b", "]", "for", "b", "in", "self", ".", "backreferences", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.linearization.SemanticGraph.nodes": [[46, 50], ["linearization.SemanticGraph.var2instance.get"], "methods", ["None"], ["", "@", "cached_property", "\n", "def", "nodes", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"Linearized nodes with varids replaced by instances\"\"\"", "\n", "return", "[", "self", ".", "var2instance", ".", "get", "(", "node", ",", "node", ")", "for", "node", "in", "self", ".", "nodes_var", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.linearization.SemanticGraph.resolved_nodes": [[51, 54], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "resolved_nodes", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "return", "[", "self", ".", "nodes", "[", "b", "]", "for", "b", "in", "self", ".", "backreferences", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.linearization.SemanticGraph.src_occurrence": [[55, 57], ["None"], "methods", ["None"], ["", "def", "src_occurrence", "(", "self", ",", "var", ":", "str", ")", "->", "int", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.linearization.BaseLinearizer.linearize": [[61, 64], ["None"], "methods", ["None"], ["    ", "@", "abc", ".", "abstractmethod", "\n", "def", "linearize", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "SemanticGraph", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.linearization.AMRTokens.is_node": [[97, 104], ["isinstance", "string.startswith"], "methods", ["None"], ["@", "classmethod", "\n", "def", "is_node", "(", "cls", ",", "string", ":", "str", ")", "->", "bool", ":", "\n", "        ", "if", "isinstance", "(", "string", ",", "str", ")", "and", "string", ".", "startswith", "(", "':'", ")", ":", "\n", "            ", "return", "False", "\n", "", "elif", "string", "in", "cls", ".", "_FIXED_SPECIAL_TOKENS_E", ":", "\n", "            ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.linearization.AMRTokens.read_backr": [[105, 114], ["cls._re_BACKR_SRC_N.search", "cls._re_BACKR_TRG_N.search"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "read_backr", "(", "cls", ",", "string", ":", "str", ")", "->", "Optional", ":", "\n", "        ", "m_src", "=", "cls", ".", "_re_BACKR_SRC_N", ".", "search", "(", "string", ")", "\n", "if", "m_src", "is", "not", "None", ":", "\n", "            ", "return", "m_src", "\n", "", "m_trg", "=", "cls", ".", "_re_BACKR_TRG_N", ".", "search", "(", "string", ")", "\n", "if", "m_trg", "is", "not", "None", ":", "\n", "            ", "return", "m_trg", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.linearization.AMRLinearizer.__init__": [[133, 141], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "use_pointer_tokens", ":", "bool", "=", "True", ",", "\n", "collapse_name_ops", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "collapse_name_ops", "=", "collapse_name_ops", "\n", "self", ".", "interleave_edges", "=", "False", "\n", "self", ".", "use_pointer_tokens", "=", "use_pointer_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.linearization.AMRLinearizer._collapse_name_ops": [[142, 168], ["enumerate", "collections.defaultdict", "enumerate", "amr.triples.copy", "collections.defaultdict.items", "penman.Graph", "sorted", "zip", "penman.Triple", "rel.startswith", "name_vars_to_ops[].append", "min", "v2.strip", "int"], "methods", ["None"], ["", "def", "_collapse_name_ops", "(", "self", ",", "amr", ")", ":", "\n", "# identify name triples", "\n", "        ", "name_vars", "=", "{", "}", "\n", "for", "i", ",", "(", "v1", ",", "rel", ",", "v2", ")", "in", "enumerate", "(", "amr", ".", "triples", ")", ":", "\n", "            ", "if", "rel", "==", "':instance'", "and", "v2", "==", "'name'", ":", "\n", "                ", "name_vars", "[", "v1", "]", "=", "1", "\n", "\n", "# check if they have ops", "\n", "", "", "name_vars_to_ops", "=", "defaultdict", "(", "list", ")", "\n", "for", "i", ",", "(", "v1", ",", "rel", ",", "v2", ")", "in", "enumerate", "(", "amr", ".", "triples", ")", ":", "\n", "            ", "if", "v1", "in", "name_vars", "and", "rel", ".", "startswith", "(", "':op'", ")", ":", "\n", "                ", "name_vars_to_ops", "[", "v1", "]", ".", "append", "(", "(", "i", ",", "rel", ",", "v2", ".", "strip", "(", "'\"'", ")", ")", ")", "\n", "\n", "", "", "triples", "=", "amr", ".", "triples", ".", "copy", "(", ")", "\n", "for", "nv", ",", "ops", "in", "name_vars_to_ops", ".", "items", "(", ")", ":", "\n", "            ", "ops", "=", "sorted", "(", "ops", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", "[", "1", "]", "[", "3", ":", "]", ")", ")", "\n", "idx", ",", "_", ",", "lits", "=", "zip", "(", "*", "ops", ")", "\n", "for", "i", "in", "idx", ":", "\n", "                ", "triples", "[", "i", "]", "=", "None", "\n", "", "lit", "=", "'\"'", "+", "'_'", ".", "join", "(", "lits", ")", "+", "'\"'", "\n", "triples", "[", "min", "(", "idx", ")", "]", "=", "penman", ".", "Triple", "(", "nv", ",", "':op1'", ",", "lit", ")", "\n", "\n", "", "triples", "=", "[", "t", "for", "t", "in", "triples", "if", "t", "is", "not", "None", "]", "\n", "amr_", "=", "penman", ".", "Graph", "(", "triples", ")", "\n", "amr_", ".", "metadata", "=", "amr", ".", "metadata", "\n", "return", "amr_", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.linearization.AMRLinearizer.linearize": [[170, 178], ["linearization.AMRLinearizer._linearize", "linearization.AMRLinearizer._interleave", "linearization.AMRLinearizer._collapse_name_ops", "linearization.AMRLinearizer._add_pointer_tokens"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer._linearize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer._interleave", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer._collapse_name_ops", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer._add_pointer_tokens"], ["", "def", "linearize", "(", "self", ",", "amr", ":", "penman", ".", "Graph", ")", "->", "SemanticGraph", ":", "\n", "        ", "if", "self", ".", "collapse_name_ops", ":", "\n", "            ", "amr", "=", "self", ".", "_collapse_name_ops", "(", "amr", ")", "\n", "", "linearized", "=", "self", ".", "_linearize", "(", "amr", ")", "\n", "linearized", "=", "self", ".", "_interleave", "(", "linearized", ")", "\n", "if", "self", ".", "use_pointer_tokens", ":", "\n", "            ", "linearized", "=", "self", ".", "_add_pointer_tokens", "(", "linearized", ")", "\n", "", "return", "linearized", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.linearization.AMRLinearizer._linearize": [[179, 318], ["set", "networkx.MultiDiGraph", "amr.edges", "amr.attributes", "collections.deque", "set", "set", "collections.deque", "collections.deque.append", "backreferences.append", "nodes_visit.append", "edges_visit.append", "linearization.SemanticGraph", "amr.variables", "itertools.chain", "networkx.MultiDiGraph.add_node", "networkx.MultiDiGraph.add_edge", "networkx.MultiDiGraph.add_edge", "sorted", "len", "len", "len", "len", "enumerate", "range", "range", "collections.deque.popleft", "collections.deque.popleft", "edges_visit.append", "networkx.MultiDiGraph.successors", "sorted", "backreferences.append", "nodes_visit.append", "edges_visit.append", "set.add", "backreferences.append", "nodes_visit.append", "set.add", "len", "list", "nodes_visit.append", "backreferences.append", "backreferences.append", "len", "nodes_visit.append", "networkx.MultiDiGraph.get_edge_data().values", "edges_visit.append", "len", "len", "networkx.MultiDiGraph.successors", "len", "sorted.append", "backreferences.append", "nodes_visit.append", "networkx.get_node_attributes", "networkx.MultiDiGraph.get_edge_data", "nodes_visit.append", "backreferences.append", "backreferences.append", "len", "nodes_visit.append", "list", "collections.deque.append", "set.add", "len", "len", "networkx.MultiDiGraph.successors", "networkx.get_node_attributes"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.SemanticGraph.variables", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["", "def", "_linearize", "(", "self", ",", "amr", ":", "penman", ".", "Graph", ")", "->", "SemanticGraph", ":", "\n", "        ", "variables", "=", "set", "(", "amr", ".", "variables", "(", ")", ")", "\n", "variables", "=", "{", "'var:'", "+", "v", "for", "v", "in", "variables", "}", "\n", "var2instance", "=", "{", "}", "\n", "\n", "graph", "=", "nx", ".", "MultiDiGraph", "(", ")", "\n", "\n", "triples2order", "=", "{", "k", ":", "i", "for", "i", ",", "k", "in", "enumerate", "(", "amr", ".", "triples", ")", "}", "\n", "\n", "for", "triple", "in", "amr", ".", "triples", ":", "\n", "            ", "var", ",", "rel", ",", "instance", "=", "triple", "\n", "order", "=", "triples2order", "[", "triple", "]", "\n", "if", "rel", "!=", "':instance'", ":", "\n", "                ", "continue", "\n", "", "for", "expansion_candidate", "in", "itertools", ".", "chain", "(", "range", "(", "order", "-", "1", ",", "-", "1", ")", ",", "range", "(", "order", "+", "1", ",", "len", "(", "amr", ".", "triples", ")", ")", ")", ":", "\n", "                ", "if", "var", "==", "amr", ".", "triples", "[", "expansion_candidate", "]", "[", "2", "]", ":", "\n", "                    ", "expansion", "=", "expansion_candidate", "\n", "break", "\n", "", "", "else", ":", "\n", "                ", "expansion", "=", "0", "\n", "", "var", "=", "'var:'", "+", "var", "\n", "var2instance", "[", "var", "]", "=", "instance", "\n", "graph", ".", "add_node", "(", "var", ",", "instance", "=", "instance", ",", "order", "=", "order", ",", "expansion", "=", "expansion", ")", "\n", "\n", "", "for", "triple", "in", "amr", ".", "edges", "(", ")", ":", "\n", "            ", "var1", ",", "rel", ",", "var2", "=", "triple", "\n", "order", "=", "triples2order", "[", "triple", "]", "\n", "if", "rel", "==", "':instance'", ":", "\n", "                ", "continue", "\n", "", "var1", "=", "'var:'", "+", "var1", "\n", "var2", "=", "'var:'", "+", "var2", "\n", "graph", ".", "add_edge", "(", "var1", ",", "var2", ",", "rel", "=", "rel", ",", "order", "=", "order", ")", "\n", "\n", "", "for", "triple", "in", "amr", ".", "attributes", "(", ")", ":", "\n", "            ", "var", ",", "rel", ",", "attr", "=", "triple", "\n", "order", "=", "triples2order", "[", "triple", "]", "\n", "if", "rel", "==", "':instance'", ":", "\n", "                ", "continue", "\n", "", "var", "=", "'var:'", "+", "var", "\n", "graph", ".", "add_edge", "(", "var", ",", "attr", ",", "rel", "=", "rel", ",", "order", "=", "order", ")", "\n", "\n", "# nodes that are not reachable from the root (e.g. because of reification)", "\n", "# will be present in the not_explored queue", "\n", "# undirected_graph = graph.to_undirected()", "\n", "# print(amr.variables())", "\n", "", "not_explored", "=", "deque", "(", "sorted", "(", "variables", ",", "key", "=", "lambda", "x", ":", "nx", ".", "get_node_attributes", "(", "graph", ",", "'order'", ")", "[", "x", "]", ")", ")", "\n", "# (", "\n", "#     len(nx.shortest_path(undirected_graph, 'var:' + amr.top, x)),", "\n", "#     -graph.out_degree(x),", "\n", "# )", "\n", "\n", "first_index", "=", "{", "}", "\n", "explored", "=", "set", "(", ")", "\n", "added_to_queue", "=", "set", "(", ")", "\n", "nodes_visit", "=", "[", "AMRTokens", ".", "BOS_N", "]", "\n", "edges_visit", "=", "[", "AMRTokens", ".", "BOS_E", "]", "\n", "backreferences", "=", "[", "0", "]", "\n", "queue", "=", "deque", "(", ")", "\n", "queue", ".", "append", "(", "'var:'", "+", "amr", ".", "top", ")", "\n", "\n", "while", "queue", "or", "not_explored", ":", "\n", "\n", "            ", "if", "queue", ":", "\n", "                ", "node1", "=", "queue", ".", "popleft", "(", ")", "\n", "", "else", ":", "\n", "                ", "node1", "=", "not_explored", ".", "popleft", "(", ")", "\n", "if", "node1", "in", "added_to_queue", ":", "\n", "                    ", "continue", "\n", "", "if", "not", "list", "(", "graph", ".", "successors", "(", "node1", ")", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "if", "node1", "in", "variables", ":", "\n", "                ", "if", "node1", "in", "explored", ":", "\n", "                    ", "continue", "\n", "", "if", "node1", "in", "first_index", ":", "\n", "                    ", "nodes_visit", ".", "append", "(", "AMRTokens", ".", "BACKR_TRG_N", ")", "\n", "backreferences", ".", "append", "(", "first_index", "[", "node1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "backreferences", ".", "append", "(", "len", "(", "nodes_visit", ")", ")", "\n", "first_index", "[", "node1", "]", "=", "len", "(", "nodes_visit", ")", "\n", "nodes_visit", ".", "append", "(", "node1", ")", "\n", "", "edges_visit", ".", "append", "(", "AMRTokens", ".", "START_E", ")", "\n", "\n", "successors", "=", "[", "]", "\n", "for", "node2", "in", "graph", ".", "successors", "(", "node1", ")", ":", "\n", "                    ", "for", "edge_data", "in", "graph", ".", "get_edge_data", "(", "node1", ",", "node2", ")", ".", "values", "(", ")", ":", "\n", "                        ", "rel", "=", "edge_data", "[", "'rel'", "]", "\n", "order", "=", "edge_data", "[", "'order'", "]", "\n", "successors", ".", "append", "(", "(", "order", ",", "rel", ",", "node2", ")", ")", "\n", "", "", "successors", "=", "sorted", "(", "successors", ")", "\n", "\n", "for", "order", ",", "rel", ",", "node2", "in", "successors", ":", "\n", "                    ", "edges_visit", ".", "append", "(", "rel", ")", "\n", "\n", "# node2 is a variable", "\n", "if", "node2", "in", "variables", ":", "\n", "# ... which was mentioned before", "\n", "                        ", "if", "node2", "in", "first_index", ":", "\n", "                            ", "nodes_visit", ".", "append", "(", "AMRTokens", ".", "BACKR_TRG_N", ")", "\n", "backreferences", ".", "append", "(", "first_index", "[", "node2", "]", ")", "\n", "\n", "# .. which is mentioned for the first time", "\n", "", "else", ":", "\n", "                            ", "backreferences", ".", "append", "(", "len", "(", "nodes_visit", ")", ")", "\n", "first_index", "[", "node2", "]", "=", "len", "(", "nodes_visit", ")", "\n", "nodes_visit", ".", "append", "(", "node2", ")", "\n", "\n", "# 1) not already in Q", "\n", "# 2) has children", "\n", "# 3) the edge right before its expansion has been encountered", "\n", "", "if", "(", "node2", "not", "in", "added_to_queue", ")", "and", "list", "(", "graph", ".", "successors", "(", "node2", ")", ")", "and", "(", "nx", ".", "get_node_attributes", "(", "graph", ",", "'expansion'", ")", "[", "node2", "]", "<=", "order", ")", ":", "\n", "                            ", "queue", ".", "append", "(", "node2", ")", "\n", "added_to_queue", ".", "add", "(", "node2", ")", "\n", "\n", "# node2 is a constant", "\n", "", "", "else", ":", "\n", "                        ", "backreferences", ".", "append", "(", "len", "(", "nodes_visit", ")", ")", "\n", "nodes_visit", ".", "append", "(", "node2", ")", "\n", "\n", "", "", "backreferences", ".", "append", "(", "len", "(", "nodes_visit", ")", ")", "\n", "nodes_visit", ".", "append", "(", "AMRTokens", ".", "STOP_N", ")", "\n", "edges_visit", ".", "append", "(", "AMRTokens", ".", "STOP_E", ")", "\n", "explored", ".", "add", "(", "node1", ")", "\n", "\n", "", "else", ":", "\n", "                ", "backreferences", ".", "append", "(", "len", "(", "nodes_visit", ")", ")", "\n", "nodes_visit", ".", "append", "(", "node1", ")", "\n", "explored", ".", "add", "(", "node1", ")", "\n", "\n", "", "", "backreferences", ".", "append", "(", "len", "(", "nodes_visit", ")", ")", "\n", "nodes_visit", ".", "append", "(", "AMRTokens", ".", "EOS_N", ")", "\n", "edges_visit", ".", "append", "(", "AMRTokens", ".", "EOS_E", ")", "\n", "assert", "len", "(", "nodes_visit", ")", "==", "len", "(", "edges_visit", ")", "==", "len", "(", "backreferences", ")", "\n", "return", "SemanticGraph", "(", "\n", "nodes_visit", ",", "\n", "edges_visit", ",", "\n", "backreferences", ",", "\n", "var2instance", ",", "\n", "extra", "=", "{", "'graph'", ":", "graph", ",", "'amr'", ":", "amr", "}", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.linearization.AMRLinearizer._interleave": [[320, 380], ["linearization.index_default", "linearization.AMRLinearizer._interleave.add_node"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.index_default"], ["", "def", "_interleave", "(", "self", ",", "graph", ":", "SemanticGraph", ")", "->", "SemanticGraph", ":", "\n", "\n", "        ", "new_backreferences_map", "=", "[", "]", "\n", "new_nodes", "=", "[", "]", "\n", "new_edges", "=", "None", "\n", "new_backreferences", "=", "[", "]", "\n", "\n", "# to isolate sublist to the stop token", "\n", "start_i", "=", "1", "\n", "end_i", "=", "index_default", "(", "AMRTokens", ".", "STOP_N", ",", "graph", ".", "nodes_var", ",", "start_i", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "def", "add_node", "(", "node", ",", "backr", "=", "None", ")", ":", "\n", "            ", "old_n_node", "=", "len", "(", "new_backreferences_map", ")", "\n", "new_n_node", "=", "len", "(", "new_nodes", ")", "\n", "\n", "if", "backr", "is", "None", ":", "\n", "                ", "backr", "=", "old_n_node", "\n", "\n", "", "new_backreferences_map", ".", "append", "(", "new_n_node", ")", "\n", "new_nodes", ".", "append", "(", "node", ")", "\n", "if", "old_n_node", "==", "backr", ":", "\n", "                ", "new_backreferences", ".", "append", "(", "new_n_node", ")", "\n", "", "else", ":", "\n", "                ", "new_backreferences", ".", "append", "(", "new_backreferences_map", "[", "backr", "]", ")", "\n", "\n", "", "", "def", "add_edge", "(", "edge", ")", ":", "\n", "            ", "new_nodes", ".", "append", "(", "edge", ")", "\n", "new_backreferences", ".", "append", "(", "len", "(", "new_backreferences", ")", ")", "\n", "\n", "", "add_node", "(", "AMRTokens", ".", "BOS_N", ")", "\n", "\n", "while", "end_i", ">", "-", "1", ":", "\n", "\n", "# src node", "\n", "            ", "add_node", "(", "graph", ".", "nodes_var", "[", "start_i", "]", ",", "graph", ".", "backreferences", "[", "start_i", "]", ")", "\n", "\n", "# edges and trg nodes, interleaved", "\n", "nodes", "=", "graph", ".", "nodes_var", "[", "start_i", "+", "1", ":", "end_i", "]", "\n", "edges", "=", "graph", ".", "edges", "[", "start_i", "+", "1", ":", "end_i", "]", "\n", "backr", "=", "graph", ".", "backreferences", "[", "start_i", "+", "1", ":", "end_i", "]", "\n", "for", "n", ",", "e", ",", "b", "in", "zip", "(", "nodes", ",", "edges", ",", "backr", ")", ":", "\n", "                ", "add_edge", "(", "e", ")", "\n", "add_node", "(", "n", ",", "b", ")", "\n", "\n", "# stop", "\n", "", "add_node", "(", "graph", ".", "nodes_var", "[", "end_i", "]", ",", "graph", ".", "backreferences", "[", "end_i", "]", ")", "\n", "\n", "start_i", "=", "end_i", "+", "1", "\n", "end_i", "=", "index_default", "(", "AMRTokens", ".", "STOP_N", ",", "graph", ".", "nodes_var", ",", "start_i", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "", "add_node", "(", "AMRTokens", ".", "EOS_N", ")", "\n", "\n", "new_graph", "=", "SemanticGraph", "(", "\n", "new_nodes", ",", "\n", "None", ",", "\n", "new_backreferences", ",", "\n", "graph", ".", "var2instance", ",", "\n", "extra", "=", "graph", ".", "extra", ",", "\n", ")", "\n", "return", "new_graph", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.linearization.AMRLinearizer._add_pointer_tokens": [[381, 406], ["zip", "list", "linearization.SemanticGraph", "range", "new_nodes.append", "len", "var2pointer.setdefault", "new_nodes.append", "new_nodes.append", "new_nodes.append", "len"], "methods", ["None"], ["", "def", "_add_pointer_tokens", "(", "self", ",", "graph", ":", "SemanticGraph", ")", "->", "SemanticGraph", ":", "\n", "        ", "new_nodes", "=", "[", "]", "\n", "var2pointer", "=", "{", "}", "\n", "for", "node", ",", "backr", "in", "zip", "(", "graph", ".", "nodes_var", ",", "graph", ".", "backreferences", ")", ":", "\n", "\n", "            ", "if", "node", "==", "AMRTokens", ".", "BACKR_TRG_N", ":", "\n", "                ", "node", "=", "graph", ".", "nodes_var", "[", "backr", "]", "\n", "pointer", "=", "var2pointer", "[", "node", "]", "\n", "new_nodes", ".", "append", "(", "pointer", ")", "\n", "", "elif", "node", "in", "graph", ".", "var2instance", ":", "\n", "                ", "pointer", "=", "var2pointer", ".", "setdefault", "(", "node", ",", "f\"<pointer:{len(var2pointer)}>\"", ")", "\n", "new_nodes", ".", "append", "(", "pointer", ")", "\n", "new_nodes", ".", "append", "(", "node", ")", "\n", "", "else", ":", "\n", "                ", "new_nodes", ".", "append", "(", "node", ")", "\n", "\n", "", "", "new_backreferences", "=", "list", "(", "range", "(", "len", "(", "new_nodes", ")", ")", ")", "\n", "new_graph", "=", "SemanticGraph", "(", "\n", "new_nodes", ",", "\n", "None", ",", "\n", "new_backreferences", ",", "\n", "graph", ".", "var2instance", ",", "\n", "extra", "=", "graph", ".", "extra", ",", "\n", ")", "\n", "return", "new_graph", "", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.linearization.index_default": [[119, 130], ["next", "len", "enumerate"], "function", ["None"], ["def", "index_default", "(", "\n", "item", ":", "T", ",", "list_", ":", "List", "[", "T", "]", ",", "\n", "start", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "stop", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "default", ":", "Optional", "[", "int", "]", "=", "None", "\n", ")", ":", "\n", "    ", "if", "start", "is", "None", ":", "\n", "        ", "start", "=", "0", "\n", "", "if", "stop", "is", "None", ":", "\n", "        ", "stop", "=", "len", "(", "list_", ")", "\n", "", "return", "next", "(", "(", "i", "for", "i", ",", "x", "in", "enumerate", "(", "list_", "[", "start", ":", "stop", "]", ",", "start", "=", "start", ")", "if", "x", "==", "item", ")", ",", "default", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.IO.read_raw_amr_data": [[6, 33], ["isinstance", "glob.glob", "str", "pathlib.Path", "graphs.extend", "eval", "spring_amr.c_penman.load", "t.endswith", "t.startswith", "t.startswith"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["def", "read_raw_amr_data", "(", "\n", "paths", ":", "List", "[", "Union", "[", "str", ",", "Path", "]", "]", ",", "\n", "use_recategorization", "=", "False", ",", "\n", "dereify", "=", "True", ",", "\n", "remove_wiki", "=", "False", ",", "\n", ")", ":", "\n", "    ", "assert", "paths", "\n", "\n", "if", "not", "isinstance", "(", "paths", ",", "Iterable", ")", ":", "\n", "        ", "paths", "=", "[", "paths", "]", "\n", "\n", "", "graphs", "=", "[", "]", "\n", "for", "path_", "in", "paths", ":", "\n", "        ", "for", "path", "in", "glob", ".", "glob", "(", "str", "(", "path_", ")", ")", ":", "\n", "            ", "path", "=", "Path", "(", "path", ")", "\n", "graphs", ".", "extend", "(", "pm_load", "(", "path", ",", "dereify", "=", "dereify", ",", "remove_wiki", "=", "remove_wiki", ")", ")", "\n", "\n", "", "", "assert", "graphs", "\n", "\n", "if", "use_recategorization", ":", "\n", "        ", "for", "g", "in", "graphs", ":", "\n", "            ", "metadata", "=", "g", ".", "metadata", "\n", "metadata", "[", "'snt_orig'", "]", "=", "metadata", "[", "'snt'", "]", "\n", "tokens", "=", "eval", "(", "metadata", "[", "'tokens'", "]", ")", "\n", "metadata", "[", "'snt'", "]", "=", "' '", ".", "join", "(", "[", "t", "for", "t", "in", "tokens", "if", "not", "(", "(", "t", ".", "startswith", "(", "'-L'", ")", "or", "t", ".", "startswith", "(", "'-R'", ")", ")", "and", "t", ".", "endswith", "(", "'-'", ")", ")", "]", ")", "\n", "\n", "", "", "return", "graphs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.SentenceDataset.__init__": [[25, 30], ["open", "f.readlines", "i.strip"], "methods", ["None"], ["mention", "=", "comps", "[", "2", "]", "\n", "lctx", "=", "comps", "[", "3", "]", "\n", "rctx", "=", "comps", "[", "4", "]", "\n", "\n", "if", "comps", "[", "6", "]", "!=", "\"EMPTYCAND\"", ":", "\n", "                ", "cands", "=", "[", "c", ".", "split", "(", "\",\"", ")", "for", "c", "in", "comps", "[", "6", ":", "-", "2", "]", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.SentenceDataset.__len__": [[31, 33], ["len"], "methods", ["None"], ["cands", "=", "[", "\n", "(", "\",\"", ".", "join", "(", "c", "[", "2", ":", "]", ")", ".", "replace", "(", "'\"'", ",", "\"%22\"", ")", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ",", "float", "(", "c", "[", "1", "]", ")", ")", "\n", "for", "c", "in", "cands", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.SentenceDataset.__getitem__": [[34, 39], ["None"], "methods", ["None"], ["]", "\n", "", "else", ":", "\n", "                ", "cands", "=", "[", "]", "\n", "\n", "", "gold", "=", "comps", "[", "-", "1", "]", ".", "split", "(", "\",\"", ")", "\n", "if", "gold", "[", "0", "]", "==", "\"-1\"", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.SentenceDataset.size": [[40, 42], ["len", "sample[].split"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["                ", "gold", "=", "(", "\n", "\",\"", ".", "join", "(", "gold", "[", "2", ":", "]", ")", ".", "replace", "(", "'\"'", ",", "\"%22\"", ")", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ",", "\n", "1e-5", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.SentenceDataset.collate_fn": [[43, 48], ["torch.device", "dataset.SentenceDataset.tokenizer.batch_encode_sentences"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_sentences"], ["-", "1", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "gold", "=", "(", "\n", "\",\"", ".", "join", "(", "gold", "[", "3", ":", "]", ")", ".", "replace", "(", "'\"'", ",", "\"%22\"", ")", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ",", "\n", "1e-5", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.SentenceLoader.__init__": [[51, 59], ["torch.device"], "methods", ["None"], ["\n", "", "if", "added_params", "[", "\"generate_cands\"", "]", ":", "\n", "                ", "if", "info", ":", "\n", "                    ", "print", "(", "\"Generating candidates\"", ")", "\n", "info", "=", "False", "\n", "", "cands", "=", "added_params", "[", "\"cand_generator\"", "]", ".", "process", "(", "mention", ")", "\n", "\n", "", "if", "doc_name", "not", "in", "data", ":", "\n", "                ", "data", "[", "doc_name", "]", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.SentenceLoader.__len__": [[60, 64], ["dataset.SentenceLoader.sampler", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.sampler"], ["\n", "", "data", "[", "doc_name", "]", ".", "append", "(", "\n", "{", "\n", "\"mention\"", ":", "mention", ",", "\n", "\"context\"", ":", "(", "lctx", ",", "rctx", ")", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.SentenceLoader.__iter__": [[65, 70], ["dataset.SentenceLoader.sampler", "dataset.SentenceLoader.dataset.collate_fn"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.sampler", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.collate_fn"], ["\"candidates\"", ":", "cands", ",", "\n", "\"gold\"", ":", "gold", ",", "\n", "}", "\n", ")", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.SentenceLoader.sort_ids": [[71, 80], ["isinstance", "zip", "list", "len", "len", "sorted", "s[].split", "s.split", "enumerate"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["\n", "### Adds original textual data to pregenerated data", "\n", "", "def", "read_conll_file", "(", "data", ",", "path", ")", ":", "\n", "    ", "conll", "=", "{", "}", "\n", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "        ", "cur_sent", "=", "None", "\n", "cur_doc", "=", "None", "\n", "\n", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.SentenceLoader.sampler": [[81, 121], ["list", "random.shuffle", "dataset.SentenceLoader.sort_ids.copy", "batch_ids.copy", "dataset.SentenceLoader.pop", "dataset.SentenceLoader.dataset.size", "max", "batch_ids.append", "range", "max", "dataset.SentenceLoader.sampler.discharge"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["if", "line", ".", "startswith", "(", "\"-DOCSTART-\"", ")", ":", "\n", "                ", "docname", "=", "line", ".", "split", "(", ")", "[", "1", "]", "[", "1", ":", "]", "\n", "conll", "[", "docname", "]", "=", "{", "\"sentences\"", ":", "[", "]", ",", "\"mentions\"", ":", "[", "]", "}", "\n", "cur_doc", "=", "conll", "[", "docname", "]", "\n", "cur_sent", "=", "[", "]", "\n", "\n", "", "else", ":", "\n", "                ", "if", "line", "==", "\"\"", ":", "\n", "                    ", "cur_doc", "[", "\"sentences\"", "]", ".", "append", "(", "cur_sent", ")", "\n", "cur_sent", "=", "[", "]", "\n", "\n", "", "else", ":", "\n", "                    ", "comps", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "tok", "=", "comps", "[", "0", "]", "\n", "cur_sent", ".", "append", "(", "tok", ")", "\n", "\n", "if", "len", "(", "comps", ")", ">=", "6", ":", "\n", "                        ", "bi", "=", "comps", "[", "1", "]", "\n", "wikilink", "=", "comps", "[", "4", "]", "\n", "if", "bi", "==", "\"I\"", ":", "\n", "                            ", "cur_doc", "[", "\"mentions\"", "]", "[", "-", "1", "]", "[", "\"end\"", "]", "+=", "1", "\n", "", "else", ":", "\n", "                            ", "new_ment", "=", "{", "\n", "\"sent_id\"", ":", "len", "(", "cur_doc", "[", "\"sentences\"", "]", ")", ",", "\n", "\"start\"", ":", "len", "(", "cur_sent", ")", "-", "1", ",", "\n", "\"end\"", ":", "len", "(", "cur_sent", ")", ",", "\n", "\"wikilink\"", ":", "wikilink", ",", "\n", "}", "\n", "cur_doc", "[", "\"mentions\"", "]", ".", "append", "(", "new_ment", ")", "\n", "\n", "# merge with data", "\n", "", "", "", "", "", "", "rmpunc", "=", "re", ".", "compile", "(", "\"[\\W]+\"", ")", "\n", "for", "doc_name", ",", "content", "in", "data", ".", "items", "(", ")", ":", "\n", "        ", "conll_doc", "=", "conll", "[", "doc_name", ".", "split", "(", ")", "[", "0", "]", "]", "\n", "content", "[", "0", "]", "[", "\"conll_doc\"", "]", "=", "conll_doc", "\n", "\n", "cur_conll_m_id", "=", "0", "\n", "for", "m", "in", "content", ":", "\n", "            ", "mention", "=", "m", "[", "\"mention\"", "]", "\n", "gold", "=", "m", "[", "\"gold\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.AMRDataset_Index.__init__": [[130, 173], ["torch.device", "spring_amr.IO.read_raw_amr_data", "max", "len", "dataset.AMRDataset_Index.tokenizer.linearize", "dataset.AMRDataset_Index.sentences.append", "dataset.AMRDataset_Index.graphs.append", "dataset.AMRDataset_Index.linearized.append", "dataset.AMRDataset_Index.linearized_extra.append", "enumerate", "dataset.AMRDataset_Index.tokenizer.batch_encode_sentences", "len", "logging.warning", "logging.warning", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.amr_rw.read_raw_amr_data", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer.linearize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_sentences"], ["\"\"", ",", "mention", ".", "lower", "(", ")", "\n", ")", ":", "\n", "                    ", "m", "[", "\"conll_m\"", "]", "=", "cur_conll_m", "\n", "cur_conll_m_id", "+=", "1", "\n", "break", "\n", "", "else", ":", "\n", "                    ", "cur_conll_m_id", "+=", "1", "\n", "\n", "", "", "", "", "return", "data", "\n", "\n", "\n", "##### Check whether an entity is a person and if the doc contains other references with a more descriptive name for the person", "\n", "##### (ex. John vs John Snow vs John Snow Stark). Then processes the candidate lists for all of the mentions that fit this description.", "\n", "\n", "\n", "", "def", "load_person_names", "(", "path", ")", ":", "\n", "    ", "data", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "data", ".", "append", "(", "line", ".", "strip", "(", ")", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ")", "\n", "", "", "return", "set", "(", "data", ")", "\n", "\n", "\n", "", "def", "find_coref", "(", "ment", ",", "mentlist", ",", "person_names", ")", ":", "\n", "    ", "cur_m", "=", "ment", "[", "\"mention\"", "]", ".", "lower", "(", ")", "\n", "coref", "=", "[", "]", "\n", "for", "m", "in", "mentlist", ":", "\n", "        ", "if", "len", "(", "m", "[", "\"candidates\"", "]", ")", "==", "0", "or", "m", "[", "\"candidates\"", "]", "[", "0", "]", "[", "0", "]", "not", "in", "person_names", ":", "\n", "            ", "continue", "\n", "\n", "", "mention", "=", "m", "[", "\"mention\"", "]", ".", "lower", "(", ")", "\n", "start_pos", "=", "mention", ".", "find", "(", "cur_m", ")", "\n", "if", "start_pos", "==", "-", "1", "or", "mention", "==", "cur_m", ":", "\n", "            ", "continue", "\n", "\n", "", "end_pos", "=", "start_pos", "+", "len", "(", "cur_m", ")", "-", "1", "\n", "if", "(", "start_pos", "==", "0", "or", "mention", "[", "start_pos", "-", "1", "]", "==", "\" \"", ")", "and", "(", "\n", "end_pos", "==", "len", "(", "mention", ")", "-", "1", "or", "mention", "[", "end_pos", "+", "1", "]", "==", "\" \"", "\n", ")", ":", "\n", "            ", "coref", ".", "append", "(", "m", ")", "\n", "\n", "", "", "return", "coref", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.AMRDataset_Index.__len__": [[176, 178], ["len"], "methods", ["None"], ["        ", "for", "cur_m", "in", "content", ":", "\n", "            ", "coref", "=", "find_coref", "(", "cur_m", ",", "content", ",", "person_names", ")", "\n", "if", "coref", "is", "not", "None", "and", "len", "(", "coref", ")", ">", "0", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.AMRDataset_Index.__getitem__": [[179, 187], ["sample.update"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update"], ["                ", "cur_cands", "=", "{", "}", "\n", "for", "m", "in", "coref", ":", "\n", "                    ", "for", "c", ",", "p", "in", "m", "[", "\"candidates\"", "]", ":", "\n", "                        ", "cur_cands", "[", "c", "]", "=", "cur_cands", ".", "get", "(", "c", ",", "0", ")", "+", "p", "\n", "", "", "for", "c", "in", "cur_cands", ".", "keys", "(", ")", ":", "\n", "                    ", "cur_cands", "[", "c", "]", "/=", "len", "(", "coref", ")", "\n", "", "cur_m", "[", "\"candidates\"", "]", "=", "sorted", "(", "\n", "list", "(", "cur_cands", ".", "items", "(", ")", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", "\n", ")", "[", ":", ":", "-", "1", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.AMRDataset_Index.size": [[188, 190], ["len"], "methods", ["None"], ["\n", "\n", "######", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.AMRDataset_Index.collate_fn": [[191, 202], ["torch.device", "dataset.AMRDataset_Index.tokenizer.batch_encode_sentences", "dataset.AMRDataset_Index.tokenizer.batch_encode_graphs_from_linearized", "extra.update"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_sentences", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_graphs_from_linearized", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update"], ["\n", "\n", "", "", "", "", "def", "eval", "(", "testset", ",", "system_pred", ",", "nel", "=", "False", ")", ":", "\n", "    ", "gold", "=", "[", "]", "\n", "pred", "=", "[", "]", "\n", "\n", "for", "doc_name", ",", "content", "in", "testset", ".", "items", "(", ")", ":", "\n", "        ", "gold", "+=", "[", "c", "[", "\"gold\"", "]", "[", "0", "]", "for", "c", "in", "content", "]", "# the gold named entity", "\n", "pred", "+=", "[", "\n", "c", "[", "\"pred\"", "]", "[", "0", "]", "for", "c", "in", "system_pred", "[", "doc_name", "]", "\n", "]", "# the predicted named entity", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.AMRDataset.__init__": [[205, 247], ["torch.device", "spring_amr.IO.read_raw_amr_data", "print", "dataset.AMRDataset.tokenizer.linearize", "dataset.AMRDataset.sentences.append", "dataset.AMRDataset.graphs.append", "dataset.AMRDataset.linearized.append", "dataset.AMRDataset.linearized_extra.append", "sentence_tokens_len.append", "len", "print", "logging.warning", "len", "dataset.AMRDataset.tokenizer.batch_encode_sentences"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.amr_rw.read_raw_amr_data", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer.linearize", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_sentences"], ["        ", "if", "g", "==", "p", "and", "p", "!=", "\"NIL\"", ":", "\n", "            ", "true_pos", "+=", "1", "\n", "\n", "", "", "if", "nel", ":", "\n", "        ", "NIL_preds", "=", "len", "(", "[", "p", "for", "p", "in", "pred", "if", "p", "==", "\"NIL\"", "]", ")", "\n", "total_discovered_mentions", "=", "0", "\n", "for", "doc_name", ",", "content", "in", "testset", ".", "items", "(", ")", ":", "\n", "            ", "total_discovered_mentions", "+=", "np", ".", "sum", "(", "\n", "len", "(", "ment", ")", "for", "ment", "in", "content", "[", "0", "]", "[", "\"ments_per_sent_flair\"", "]", "\n", ")", "\n", "\n", "", "precision", "=", "true_pos", "/", "(", "total_discovered_mentions", "-", "NIL_preds", ")", "\n", "", "else", ":", "\n", "        ", "precision", "=", "true_pos", "/", "len", "(", "[", "p", "for", "p", "in", "pred", "if", "p", "!=", "\"NIL\"", "]", ")", "\n", "\n", "", "recall", "=", "true_pos", "/", "len", "(", "gold", ")", "\n", "f1", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "return", "precision", ",", "recall", ",", "f1", "\n", "\n", "\n", "", "def", "get_candidate_generator", "(", "added_params", ")", ":", "\n", "    ", "if", "added_params", "[", "\"candidate_generator_type\"", "]", "==", "\"p_e_m\"", ":", "\n", "        ", "if", "\"p_e_m_data_path\"", "in", "added_params", ":", "\n", "            ", "return", "FetchCandidateEntities", "(", "added_params", "[", "\"p_e_m_data_path\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "FetchCandidateEntities", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "pass", "\n", "\n", "\n", "", "", "class", "CoNLLDataset", ":", "\n", "    ", "\"\"\"\n    reading dataset from CoNLL dataset, extracted by https://github.com/dalab/deep-ed/\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "path", ",", "person_path", ",", "conll_path", ",", "added_params", ")", ":", "\n", "        ", "if", "added_params", "[", "\"generate_ments_and_cands\"", "]", ":", "\n", "            ", "added_params", "[", "\"generate_cands\"", "]", "=", "False", "\n", "\n", "", "if", "added_params", "[", "\"generate_cands\"", "]", "or", "added_params", "[", "\"generate_ments_and_cands\"", "]", ":", "\n", "            ", "added_params", "[", "\"cand_generator\"", "]", "=", "get_candidate_generator", "(", "added_params", ")", "\n", "\n", "", "print", "(", "added_params", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.AMRDataset.__len__": [[259, 261], ["len"], "methods", ["None"], ["\n", "print", "(", "\"process coref\"", ")", "\n", "person_names", "=", "load_person_names", "(", "person_path", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.AMRDataset.__getitem__": [[262, 270], ["sample.update"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update"], ["with_coref", "(", "self", ".", "train", ",", "person_names", ")", "\n", "with_coref", "(", "self", ".", "testA", ",", "person_names", ")", "\n", "with_coref", "(", "self", ".", "testB", ",", "person_names", ")", "\n", "with_coref", "(", "self", ".", "ace2004", ",", "person_names", ")", "\n", "with_coref", "(", "self", ".", "aquaint", ",", "person_names", ")", "\n", "with_coref", "(", "self", ".", "clueweb", ",", "person_names", ")", "\n", "with_coref", "(", "self", ".", "msnbc", ",", "person_names", ")", "\n", "with_coref", "(", "self", ".", "wikipedia", ",", "person_names", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.AMRDataset.size": [[271, 273], ["len"], "methods", ["None"], ["print", "(", "\"load conll\"", ")", "\n", "read_conll_file", "(", "self", ".", "train", ",", "conll_path", "+", "\"/AIDA/aida_train.txt\"", ")", "\n", "read_conll_file", "(", "self", ".", "testA", ",", "conll_path", "+", "\"/AIDA/testa_testb_aggregate_original\"", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.AMRDataset.collate_fn": [[274, 285], ["torch.device", "dataset.AMRDataset.tokenizer.batch_encode_sentences", "dataset.AMRDataset.tokenizer.batch_encode_graphs_from_linearized", "extra.update"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_sentences", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_graphs_from_linearized", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update"], ["read_conll_file", "(", "self", ".", "testB", ",", "conll_path", "+", "\"/AIDA/testa_testb_aggregate_original\"", ")", "\n", "read_conll_file", "(", "\n", "self", ".", "ace2004", ",", "conll_path", "+", "\"/wned-datasets/ace2004/ace2004.conll\"", "\n", ")", "\n", "read_conll_file", "(", "\n", "self", ".", "aquaint", ",", "conll_path", "+", "\"/wned-datasets/aquaint/aquaint.conll\"", "\n", ")", "\n", "read_conll_file", "(", "self", ".", "msnbc", ",", "conll_path", "+", "\"/wned-datasets/msnbc/msnbc.conll\"", ")", "\n", "read_conll_file", "(", "\n", "self", ".", "clueweb", ",", "conll_path", "+", "\"/wned-datasets/clueweb/clueweb.conll\"", "\n", ")", "\n", "read_conll_file", "(", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.AMRDatasetTokenBatcherAndLoader.__init__": [[288, 296], ["torch.device"], "methods", ["None"], ["\n", "if", "added_params", "[", "\"generate_cands\"", "]", ":", "\n", "            ", "print", "(", "\n", "\"Number of candidates not present in p_e_m originally, but present when lowercased\"", ",", "\n", "len", "(", "added_params", "[", "\"cand_generator\"", "]", ".", "lower_org", ")", ",", "\n", ")", "\n", "print", "(", "\n", "\"Number of candidates not present in p_e_m originally, but present in p_e_m_lower when lowercased \"", ",", "\n", "len", "(", "added_params", "[", "\"cand_generator\"", "]", ".", "lower_lower", ")", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.AMRDatasetTokenBatcherAndLoader.__len__": [[297, 301], ["dataset.AMRDatasetTokenBatcherAndLoader.sampler", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.sampler"], [")", "\n", "\n", "\n", "", "", "", "class", "FetchCandidateEntities", "(", "object", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.AMRDatasetTokenBatcherAndLoader.__iter__": [[302, 307], ["dataset.AMRDatasetTokenBatcherAndLoader.sampler", "dataset.AMRDatasetTokenBatcherAndLoader.dataset.collate_fn"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.sampler", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.collate_fn"], ["\n", "\n", "def", "__init__", "(", "self", ",", "p_e_m_data_path", "=", "\"data/basic_data/p_e_m_data/\"", ")", ":", "\n", "        ", "print", "(", "\"Reading p_e_m dictionaries\"", ")", "\n", "# return", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.AMRDatasetTokenBatcherAndLoader.sort_ids": [[308, 317], ["isinstance", "zip", "list", "len", "len", "sorted", "s[].split", "s.split", "enumerate"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["wall_start", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "lower_org", "=", "[", "]", "\n", "self", ".", "lower_lower", "=", "[", "]", "\n", "self", ".", "p_e_m", "=", "pickle", ".", "load", "(", "\n", "open", "(", "os", ".", "path", ".", "join", "(", "p_e_m_data_path", ",", "\"p_e_m_dict.pickle\"", ")", ",", "\"rb\"", ")", "\n", ")", "\n", "self", ".", "p_e_m_lower", "=", "pickle", ".", "load", "(", "\n", "open", "(", "os", ".", "path", ".", "join", "(", "p_e_m_data_path", ",", "\"p_e_m_lower_dict.pickle\"", ")", ",", "\"rb\"", ")", "\n", ")", "\n", "self", ".", "mention_total_freq", "=", "pickle", ".", "load", "(", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.AMRDatasetTokenBatcherAndLoader.sampler": [[318, 358], ["list", "random.shuffle", "dataset.AMRDatasetTokenBatcherAndLoader.sort_ids.copy", "batch_ids.copy", "dataset.AMRDatasetTokenBatcherAndLoader.pop", "dataset.AMRDatasetTokenBatcherAndLoader.dataset.size", "max", "batch_ids.append", "range", "max", "dataset.AMRDatasetTokenBatcherAndLoader.sampler.discharge"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["open", "(", "os", ".", "path", ".", "join", "(", "p_e_m_data_path", ",", "\"mention_total_freq.pickle\"", ")", ",", "\"rb\"", ")", "\n", ")", "\n", "print", "(", "\"The reading took:\"", ",", "(", "time", ".", "time", "(", ")", "-", "wall_start", ")", "/", "60", ",", "\" minutes\"", ")", "\n", "\n", "", "def", "process", "(", "self", ",", "span", ")", ":", "\n", "        ", "\"\"\"span can be either a string or a list of words\"\"\"", "\n", "\n", "title", "=", "span", ".", "title", "(", ")", "\n", "# 'obama 44th president of united states'.title() # 'Obama 44Th President Of United States'", "\n", "title_freq", "=", "(", "\n", "self", ".", "mention_total_freq", "[", "title", "]", "if", "title", "in", "self", ".", "mention_total_freq", "else", "0", "\n", ")", "\n", "span_freq", "=", "(", "\n", "self", ".", "mention_total_freq", "[", "span", "]", "if", "span", "in", "self", ".", "mention_total_freq", "else", "0", "\n", ")", "\n", "\n", "if", "title_freq", "==", "0", "and", "span_freq", "==", "0", ":", "\n", "            ", "if", "span", ".", "lower", "(", ")", "in", "self", ".", "p_e_m", ":", "\n", "                ", "self", ".", "lower_org", ".", "append", "(", "span", ")", "\n", "return", "self", ".", "p_e_m", "[", "span", ".", "lower", "(", ")", "]", "\n", "", "elif", "span", ".", "lower", "(", ")", "in", "self", ".", "p_e_m_lower", ":", "\n", "                ", "self", ".", "lower_lower", ".", "append", "(", "span", ")", "\n", "return", "self", ".", "p_e_m_lower", "[", "span", ".", "lower", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "return", "[", "]", "\n", "", "", "else", ":", "\n", "            ", "if", "span_freq", ">", "title_freq", ":", "\n", "                ", "return", "self", ".", "p_e_m", "[", "span", "]", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "p_e_m", "[", "title", "]", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.MultiTaskDataset.__init__": [[389, 486], ["torch.device", "print", "print", "print", "print", "len", "len", "path_srcs.keys", "print", "spring_amr.IO.read_raw_amr_data", "path_srcs.keys", "dataset.read_dp_samples", "path_srcs.keys", "dataset.read_dp_samples", "isinstance", "isinstance", "dataset.MultiTaskDataset.tokenizer.linearize", "dataset.MultiTaskDataset.sentences.append", "dataset.MultiTaskDataset.graphs.append", "dataset.MultiTaskDataset.linearized.append", "dataset.MultiTaskDataset.lens.append", "tokenizer.tokenize_dp", "dataset.MultiTaskDataset.sentences.append", "dataset.MultiTaskDataset.lens.append", "dataset.MultiTaskDataset.linearized.append", "tokenizer.tokenize_dp", "dataset.MultiTaskDataset.sentences.append", "dataset.MultiTaskDataset.lens.append", "dataset.MultiTaskDataset.linearized.append", "len", "max", "pathlib.Path", "dataset.MultiTaskDataset.tokenizer.batch_encode_sentences", "len", "len", "len", "len", "len", "sum", "len", "pathlib.Path", "logging.warning", "len", "len", "len", "glob.glob.glob"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.amr_rw.read_raw_amr_data", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.read_dp_samples", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.read_dp_samples", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer.linearize", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer.tokenize_dp", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer.tokenize_dp", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_sentences"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.MultiTaskDataset.__len__": [[487, 489], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.MultiTaskDataset.size": [[490, 492], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.MultiTaskDataset.__getitem__": [[493, 500], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.MultiTaskDataset.collate_fn": [[501, 516], ["torch.device", "dataset.MultiTaskDataset.tokenizer.batch_encode_sentences", "sents.append", "dataset.MultiTaskDataset.tokenizer.batch_encode_graphs_from_linearized", "extra.update"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_sentences", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_graphs_from_linearized", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.DpPretrainDataset.__init__": [[526, 574], ["torch.device", "dataset.read_dp_samples", "print", "print", "print", "print", "tokenizer.tokenize_dp", "dataset.DpPretrainDataset.sentences.append", "dataset.DpPretrainDataset.lens.append", "dataset.DpPretrainDataset.tgt.append", "dataset.DpPretrainDataset.graphs.append", "open", "json.dump", "len", "len", "len", "max", "len", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.read_dp_samples", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.tokenization_bart.AMRBartTokenizer.tokenize_dp"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.DpPretrainDataset.__len__": [[575, 577], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.DpPretrainDataset.size": [[578, 580], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.DpPretrainDataset.__getitem__": [[581, 588], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.DpPretrainDataset.collate_fn": [[589, 600], ["torch.device", "dataset.DpPretrainDataset.tokenizer.batch_encode_sentences", "dataset.DpPretrainDataset.tokenizer.batch_encode_graphs_from_linearized", "extra.update"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_sentences", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_graphs_from_linearized", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.SrlPretrainDataset.__init__": [[605, 633], ["torch.device", "dataset.read_srl_tributes", "print", "print", "print", "dataset.SrlPretrainDataset.sentences.append", "tokenizer.encode_srl_tuples", "dataset.SrlPretrainDataset.gold_tuples.append", "dataset.SrlPretrainDataset.lens.append", "dataset.SrlPretrainDataset.tgt.append", "list", "len", "len", "filter", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.read_srl_tributes", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.SrlPretrainDataset.__len__": [[634, 636], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.SrlPretrainDataset.size": [[637, 639], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.SrlPretrainDataset.__getitem__": [[640, 647], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.SrlPretrainDataset.collate_fn": [[648, 659], ["torch.device", "dataset.SrlPretrainDataset.tokenizer.batch_encode_sentences", "dataset.SrlPretrainDataset.tokenizer.batch_encode_graphs_from_linearized", "extra.update"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_sentences", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_graphs_from_linearized", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.reverse_direction": [[14, 23], ["torch.cat", "torch.ones_like"], "function", ["None"], ["\n", "\n", "\n", "def", "read_csv_file", "(", "path", ",", "added_params", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "info", "=", "True", "\n", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "comps", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.read_srl_tributes": [[360, 373], ["open", "open.readlines", "i.strip().split", "snt.strip", "eval", "tributes.append", "tri.strip", "i.strip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.read_dp_samples": [[374, 386], ["open().readlines", "open().readlines", "zip", "len", "len", "samples.append", "open", "open", "i.strip", "j.strip"], "function", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.ChildRAdam.__init__": [[13, 35], ["dict", "torch.optim.optimizer.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "isinstance", "isinstance", "len", "range", "range"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["\t", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "weight_decay", "=", "0", ",", "degenerated_to_sgd", "=", "True", ",", "reserve_p", "=", "1.0", ",", "mode", "=", "None", ")", ":", "\n", "\t\t", "if", "not", "0.0", "<=", "lr", ":", "\n", "\t\t\t", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "\t\t\t", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "eps", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "\t\t\t", "raise", "ValueError", "(", "\"Invalid beta parameter at index 0: {}\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "\t\t\t", "raise", "ValueError", "(", "\"Invalid beta parameter at index 1: {}\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "\n", "", "self", ".", "degenerated_to_sgd", "=", "degenerated_to_sgd", "\n", "if", "isinstance", "(", "params", ",", "(", "list", ",", "tuple", ")", ")", "and", "len", "(", "params", ")", ">", "0", "and", "isinstance", "(", "params", "[", "0", "]", ",", "dict", ")", ":", "\n", "\t\t\t", "for", "param", "in", "params", ":", "\n", "\t\t\t\t", "if", "'betas'", "in", "param", "and", "(", "param", "[", "'betas'", "]", "[", "0", "]", "!=", "betas", "[", "0", "]", "or", "param", "[", "'betas'", "]", "[", "1", "]", "!=", "betas", "[", "1", "]", ")", ":", "\n", "\t\t\t\t\t", "param", "[", "'buffer'", "]", "=", "[", "[", "None", ",", "None", ",", "None", "]", "for", "_", "in", "range", "(", "10", ")", "]", "\n", "", "", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ",", "\n", "buffer", "=", "[", "[", "None", ",", "None", ",", "None", "]", "for", "_", "in", "range", "(", "10", ")", "]", ")", "\n", "super", "(", "ChildRAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n", "self", ".", "gradient_mask", "=", "None", "\n", "self", ".", "reserve_p", "=", "reserve_p", "\n", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.ChildRAdam.set_gradient_mask": [[36, 38], ["None"], "methods", ["None"], ["", "def", "set_gradient_mask", "(", "self", ",", "gradient_mask", ")", ":", "\n", "\t\t", "self", ".", "gradient_mask", "=", "gradient_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.ChildRAdam.__setstate__": [[39, 41], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "\t\t", "super", "(", "ChildRAdam", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.ChildRAdam.step": [[42, 123], ["closure", "p.grad.data.float", "p.data.float", "exp_avg_sq.mul_().addcmul_", "exp_avg.mul_().add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "state[].type_as", "state[].type_as", "exp_avg_sq.sqrt().add_", "p.data.float.addcdiv_", "p.data.copy_", "torch.distributions.bernoulli.Bernoulli", "exp_avg_sq.mul_", "exp_avg.mul_", "int", "p.data.float.add_", "p.data.float.add_", "p.data.copy_", "p.grad.data.float.new_full", "torch.distributions.bernoulli.Bernoulli.sample", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "exp_avg_sq.sqrt", "p.data.float.add_", "p.grad.data.float.size"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "\n", "\t\t", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "\t\t\t", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "\n", "\t\t\t", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "\t\t\t\t", "if", "p", ".", "grad", "is", "None", ":", "\n", "\t\t\t\t\t", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "\t\t\t\t\t", "raise", "RuntimeError", "(", "'RAdam does not support sparse gradients'", ")", "\n", "\n", "", "p_data_fp32", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "#  =================== HACK BEGIN =======================         ", "\n", "if", "self", ".", "mode", "is", "not", "None", ":", "\n", "\t\t\t\t\t", "if", "self", ".", "mode", "==", "'ChildTuning-D'", ":", "\n", "\t\t\t\t\t\t", "if", "p", "in", "self", ".", "gradient_mask", ":", "\n", "\t\t\t\t\t\t\t", "grad", "*=", "self", ".", "gradient_mask", "[", "p", "]", "\n", "", "", "else", ":", "\n", "# ChildTuning-F", "\n", "\t\t\t\t\t\t", "grad_mask", "=", "Bernoulli", "(", "grad", ".", "new_full", "(", "size", "=", "grad", ".", "size", "(", ")", ",", "fill_value", "=", "self", ".", "reserve_p", ")", ")", "\n", "grad", "*=", "grad_mask", ".", "sample", "(", ")", "/", "self", ".", "reserve_p", "\n", "# =================== HACK END =======================", "\n", "\n", "\n", "", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "\t\t\t\t\t", "state", "[", "'step'", "]", "=", "0", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "state", "[", "'exp_avg'", "]", "=", "state", "[", "'exp_avg'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "state", "[", "'exp_avg_sq'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "buffered", "=", "group", "[", "'buffer'", "]", "[", "int", "(", "state", "[", "'step'", "]", "%", "10", ")", "]", "\n", "if", "state", "[", "'step'", "]", "==", "buffered", "[", "0", "]", ":", "\n", "\t\t\t\t\t", "N_sma", ",", "step_size", "=", "buffered", "[", "1", "]", ",", "buffered", "[", "2", "]", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "buffered", "[", "0", "]", "=", "state", "[", "'step'", "]", "\n", "beta2_t", "=", "beta2", "**", "state", "[", "'step'", "]", "\n", "N_sma_max", "=", "2", "/", "(", "1", "-", "beta2", ")", "-", "1", "\n", "N_sma", "=", "N_sma_max", "-", "2", "*", "state", "[", "'step'", "]", "*", "beta2_t", "/", "(", "1", "-", "beta2_t", ")", "\n", "buffered", "[", "1", "]", "=", "N_sma", "\n", "\n", "# more conservative since it's an approximated value", "\n", "if", "N_sma", ">=", "5", ":", "\n", "\t\t\t\t\t\t", "step_size", "=", "math", ".", "sqrt", "(", "\n", "(", "1", "-", "beta2_t", ")", "*", "(", "N_sma", "-", "4", ")", "/", "(", "N_sma_max", "-", "4", ")", "*", "(", "N_sma", "-", "2", ")", "/", "N_sma", "*", "N_sma_max", "/", "(", "\n", "N_sma_max", "-", "2", ")", ")", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "", "elif", "self", ".", "degenerated_to_sgd", ":", "\n", "\t\t\t\t\t\t", "step_size", "=", "1.0", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "", "else", ":", "\n", "\t\t\t\t\t\t", "step_size", "=", "-", "1", "\n", "", "buffered", "[", "2", "]", "=", "step_size", "\n", "\n", "# more conservative since it's an approximated value", "\n", "", "if", "N_sma", ">=", "5", ":", "\n", "\t\t\t\t\t", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "\t\t\t\t\t\t", "p_data_fp32", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "group", "[", "'lr'", "]", ",", "p_data_fp32", ")", "\n", "", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "p_data_fp32", ".", "addcdiv_", "(", "-", "step_size", "*", "group", "[", "'lr'", "]", ",", "exp_avg", ",", "denom", ")", "\n", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "", "elif", "step_size", ">", "0", ":", "\n", "\t\t\t\t\t", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "\t\t\t\t\t\t", "p_data_fp32", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "group", "[", "'lr'", "]", ",", "p_data_fp32", ")", "\n", "", "p_data_fp32", ".", "add_", "(", "-", "step_size", "*", "group", "[", "'lr'", "]", ",", "exp_avg", ")", "\n", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.__init__": [[127, 145], ["dict", "torch.optim.optimizer.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "isinstance", "isinstance", "len", "range", "range"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["\t", "def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-8", ",", "weight_decay", "=", "0", ",", "degenerated_to_sgd", "=", "True", ")", ":", "\n", "\t\t", "if", "not", "0.0", "<=", "lr", ":", "\n", "\t\t\t", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "\t\t\t", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "eps", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "\t\t\t", "raise", "ValueError", "(", "\"Invalid beta parameter at index 0: {}\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "\t\t\t", "raise", "ValueError", "(", "\"Invalid beta parameter at index 1: {}\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "\n", "", "self", ".", "degenerated_to_sgd", "=", "degenerated_to_sgd", "\n", "if", "isinstance", "(", "params", ",", "(", "list", ",", "tuple", ")", ")", "and", "len", "(", "params", ")", ">", "0", "and", "isinstance", "(", "params", "[", "0", "]", ",", "dict", ")", ":", "\n", "\t\t\t", "for", "param", "in", "params", ":", "\n", "\t\t\t\t", "if", "'betas'", "in", "param", "and", "(", "param", "[", "'betas'", "]", "[", "0", "]", "!=", "betas", "[", "0", "]", "or", "param", "[", "'betas'", "]", "[", "1", "]", "!=", "betas", "[", "1", "]", ")", ":", "\n", "\t\t\t\t\t", "param", "[", "'buffer'", "]", "=", "[", "[", "None", ",", "None", ",", "None", "]", "for", "_", "in", "range", "(", "10", ")", "]", "\n", "", "", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ",", "\n", "buffer", "=", "[", "[", "None", ",", "None", ",", "None", "]", "for", "_", "in", "range", "(", "10", ")", "]", ")", "\n", "super", "(", "RAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.__setstate__": [[146, 148], ["super().__setstate__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.__setstate__"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "\t\t", "super", "(", "RAdam", ",", "self", ")", ".", "__setstate__", "(", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step": [[149, 218], ["closure", "p.grad.data.float", "p.data.float", "exp_avg_sq.mul_().addcmul_", "exp_avg.mul_().add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "state[].type_as", "state[].type_as", "exp_avg_sq.sqrt().add_", "p.data.float.addcdiv_", "p.data.copy_", "exp_avg_sq.mul_", "exp_avg.mul_", "int", "p.data.float.add_", "p.data.float.add_", "p.data.copy_", "math.sqrt", "math.sqrt", "math.sqrt", "math.sqrt", "exp_avg_sq.sqrt", "p.data.float.add_"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "\n", "\t\t", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "\t\t\t", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "\n", "\t\t\t", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "\t\t\t\t", "if", "p", ".", "grad", "is", "None", ":", "\n", "\t\t\t\t\t", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", ".", "float", "(", ")", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "\t\t\t\t\t", "raise", "RuntimeError", "(", "'RAdam does not support sparse gradients'", ")", "\n", "\n", "", "p_data_fp32", "=", "p", ".", "data", ".", "float", "(", ")", "\n", "\n", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "\t\t\t\t\t", "state", "[", "'step'", "]", "=", "0", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p_data_fp32", ")", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "state", "[", "'exp_avg'", "]", "=", "state", "[", "'exp_avg'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "state", "[", "'exp_avg_sq'", "]", ".", "type_as", "(", "p_data_fp32", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'betas'", "]", "\n", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "buffered", "=", "group", "[", "'buffer'", "]", "[", "int", "(", "state", "[", "'step'", "]", "%", "10", ")", "]", "\n", "if", "state", "[", "'step'", "]", "==", "buffered", "[", "0", "]", ":", "\n", "\t\t\t\t\t", "N_sma", ",", "step_size", "=", "buffered", "[", "1", "]", ",", "buffered", "[", "2", "]", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "buffered", "[", "0", "]", "=", "state", "[", "'step'", "]", "\n", "beta2_t", "=", "beta2", "**", "state", "[", "'step'", "]", "\n", "N_sma_max", "=", "2", "/", "(", "1", "-", "beta2", ")", "-", "1", "\n", "N_sma", "=", "N_sma_max", "-", "2", "*", "state", "[", "'step'", "]", "*", "beta2_t", "/", "(", "1", "-", "beta2_t", ")", "\n", "buffered", "[", "1", "]", "=", "N_sma", "\n", "\n", "# more conservative since it's an approximated value", "\n", "if", "N_sma", ">=", "5", ":", "\n", "\t\t\t\t\t\t", "step_size", "=", "math", ".", "sqrt", "(", "\n", "(", "1", "-", "beta2_t", ")", "*", "(", "N_sma", "-", "4", ")", "/", "(", "N_sma_max", "-", "4", ")", "*", "(", "N_sma", "-", "2", ")", "/", "N_sma", "*", "N_sma_max", "/", "(", "\n", "N_sma_max", "-", "2", ")", ")", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "", "elif", "self", ".", "degenerated_to_sgd", ":", "\n", "\t\t\t\t\t\t", "step_size", "=", "1.0", "/", "(", "1", "-", "beta1", "**", "state", "[", "'step'", "]", ")", "\n", "", "else", ":", "\n", "\t\t\t\t\t\t", "step_size", "=", "-", "1", "\n", "", "buffered", "[", "2", "]", "=", "step_size", "\n", "\n", "# more conservative since it's an approximated value", "\n", "", "if", "N_sma", ">=", "5", ":", "\n", "\t\t\t\t\t", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "\t\t\t\t\t\t", "p_data_fp32", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "group", "[", "'lr'", "]", ",", "p_data_fp32", ")", "\n", "", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'eps'", "]", ")", "\n", "p_data_fp32", ".", "addcdiv_", "(", "-", "step_size", "*", "group", "[", "'lr'", "]", ",", "exp_avg", ",", "denom", ")", "\n", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "", "elif", "step_size", ">", "0", ":", "\n", "\t\t\t\t\t", "if", "group", "[", "'weight_decay'", "]", "!=", "0", ":", "\n", "\t\t\t\t\t\t", "p_data_fp32", ".", "add_", "(", "-", "group", "[", "'weight_decay'", "]", "*", "group", "[", "'lr'", "]", ",", "p_data_fp32", ")", "\n", "", "p_data_fp32", ".", "add_", "(", "-", "step_size", "*", "group", "[", "'lr'", "]", ",", "exp_avg", ")", "\n", "p", ".", "data", ".", "copy_", "(", "p_data_fp32", ")", "\n", "\n", "", "", "", "return", "loss", "", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils_temp.instaniate_model_tokenizer_cl": [[13, 16], ["utils_temp.instantiate_model_and_tokenizer"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.model_utils.instantiate_model_and_tokenizer"], ["def", "instaniate_model_tokenizer_cl", "(", "name", ",", "checkpoint", ",", "dropout", ",", "attention_dropout", ")", ":", "\n", "    ", "return", "instantiate_model_and_tokenizer", "(", "name", "=", "name", ",", "checkpoint", "=", "checkpoint", ",", "dropout", "=", "dropout", ",", "attention_dropout", "=", "attention_dropout", ",", "\n", "use_pointer_tokens", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils_temp.instaniate_tokenizer": [[18, 20], ["None"], "function", ["None"], ["", "def", "instaniate_tokenizer", "(", "name", ")", ":", "\n", "    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils_temp.instantiate_model_and_tokenizer": [[21, 136], ["transformers.AutoConfig.from_pretrained", "spring_amr.utils_new.init_AMRization_model", "spring_amr.utils_new.init_AMRization_model.resize_token_embeddings", "spring_amr.tokenization_bart.PENMANBartTokenizer.from_pretrained", "spring_amr.tokenization_bart.AMRBartTokenizer.from_pretrained", "len", "AMRBartTokenizer.from_pretrained.encoder.items", "spring_amr.utils_new.init_AMRization_model.load_state_dict", "tok.lstrip.lstrip", "AMRBartTokenizer.from_pretrained.encoder.get", "torch.stack().mean", "torch.empty_like", "torch.empty_like.uniform_", "torch.load", "tok.lstrip.startswith", "tok.lstrip.endswith", "tok.lstrip.startswith", "tok.split.append", "tok.split.extend", "spring_amr.utils_new.init_AMRization_model.model.shared.weight.data[].clone", "vecs.append", "str", "tok.lstrip.startswith", "AMRBartTokenizer.from_pretrained._tok_bpe", "torch.stack", "[].strip", "tok.lstrip.split", "tok.lstrip.startswith", "tok.lstrip.startswith", "tok.lstrip.split", "str", "tok.lstrip.startswith", "int", "str", "int", "str", "tok.lstrip.lstrip().split", "int", "tok.lstrip.lstrip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils_new.init_AMRization_model", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.resize_token_embeddings", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "instantiate_model_and_tokenizer", "(", "\n", "name", "=", "None", ",", "\n", "checkpoint", "=", "None", ",", "\n", "additional_tokens_smart_init", "=", "True", ",", "\n", "dropout", "=", "0.15", ",", "\n", "attention_dropout", "=", "0.15", ",", "\n", "from_pretrained", "=", "True", ",", "\n", "init_reverse", "=", "False", ",", "\n", "collapse_name_ops", "=", "False", ",", "\n", "penman_linearization", "=", "False", ",", "\n", "use_pointer_tokens", "=", "False", ",", "\n", "raw_graph", "=", "False", ",", "\n", ")", ":", "\n", "    ", "if", "raw_graph", ":", "\n", "        ", "assert", "penman_linearization", "\n", "\n", "", "skip_relations", "=", "False", "\n", "\n", "if", "name", "is", "None", ":", "\n", "        ", "name", "=", "'facebook/bart-large'", "\n", "\n", "", "if", "name", "==", "'facebook/bart-base'", ":", "\n", "        ", "tokenizer_name", "=", "'facebook/bart-large'", "\n", "", "else", ":", "\n", "        ", "tokenizer_name", "=", "name", "\n", "\n", "", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "name", ")", "\n", "config", ".", "output_past", "=", "False", "\n", "config", ".", "no_repeat_ngram_size", "=", "0", "\n", "config", ".", "prefix", "=", "\" \"", "\n", "config", ".", "output_attentions", "=", "True", "\n", "config", ".", "dropout", "=", "dropout", "\n", "config", ".", "attention_dropout", "=", "attention_dropout", "\n", "\n", "if", "penman_linearization", ":", "\n", "        ", "tokenizer", "=", "PENMANBartTokenizer", ".", "from_pretrained", "(", "\n", "tokenizer_name", ",", "\n", "collapse_name_ops", "=", "collapse_name_ops", ",", "\n", "use_pointer_tokens", "=", "use_pointer_tokens", ",", "\n", "raw_graph", "=", "raw_graph", ",", "\n", "config", "=", "config", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "tokenizer", "=", "AMRBartTokenizer", ".", "from_pretrained", "(", "\n", "tokenizer_name", ",", "\n", "collapse_name_ops", "=", "collapse_name_ops", ",", "\n", "use_pointer_tokens", "=", "use_pointer_tokens", ",", "\n", "config", "=", "config", ",", "\n", ")", "\n", "\n", "", "model", "=", "init_AMRization_model", "(", "name", ",", "checkpoint", ",", "dropout", ",", "attention_dropout", ",", "tokenizer", ",", "from_pretrained", "=", "from_pretrained", ")", "\n", "\n", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ".", "encoder", ")", ")", "\n", "\n", "if", "additional_tokens_smart_init", ":", "\n", "        ", "modified", "=", "0", "\n", "for", "tok", ",", "idx", "in", "tokenizer", ".", "encoder", ".", "items", "(", ")", ":", "\n", "            ", "tok", "=", "tok", ".", "lstrip", "(", "tokenizer", ".", "INIT", ")", "\n", "\n", "if", "idx", "<", "tokenizer", ".", "old_enc_size", ":", "\n", "                ", "continue", "\n", "\n", "", "elif", "tok", ".", "startswith", "(", "'<pointer:'", ")", "and", "tok", ".", "endswith", "(", "'>'", ")", ":", "\n", "                ", "tok_split", "=", "[", "'pointer'", ",", "str", "(", "tok", ".", "split", "(", "':'", ")", "[", "1", "]", ".", "strip", "(", "'>'", ")", ")", "]", "\n", "\n", "", "elif", "tok", ".", "startswith", "(", "'<'", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "elif", "tok", ".", "startswith", "(", "':'", ")", ":", "\n", "\n", "                ", "if", "skip_relations", ":", "\n", "                    ", "continue", "\n", "\n", "", "elif", "tok", ".", "startswith", "(", "':op'", ")", ":", "\n", "                    ", "tok_split", "=", "[", "'relation'", ",", "'operator'", ",", "str", "(", "int", "(", "tok", "[", "3", ":", "]", ")", ")", "]", "\n", "\n", "", "elif", "tok", ".", "startswith", "(", "':snt'", ")", ":", "\n", "                    ", "tok_split", "=", "[", "'relation'", ",", "'sentence'", ",", "str", "(", "int", "(", "tok", "[", "4", ":", "]", ")", ")", "]", "\n", "\n", "", "elif", "tok", ".", "startswith", "(", "':ARG'", ")", ":", "\n", "                    ", "tok_split", "=", "[", "'relation'", ",", "'argument'", ",", "str", "(", "int", "(", "tok", "[", "4", ":", "]", ")", ")", "]", "\n", "\n", "", "else", ":", "\n", "                    ", "tok_split", "=", "[", "'relation'", "]", "+", "tok", ".", "lstrip", "(", "':'", ")", ".", "split", "(", "'-'", ")", "\n", "\n", "", "", "else", ":", "\n", "                ", "tok_split", "=", "tok", ".", "split", "(", "'-'", ")", "\n", "\n", "", "tok_split_", "=", "tok_split", "\n", "tok_split", "=", "[", "]", "\n", "for", "s", "in", "tok_split_", ":", "\n", "                ", "s_", "=", "s", "+", "tokenizer", ".", "INIT", "\n", "if", "s_", "in", "tokenizer", ".", "encoder", ":", "\n", "                    ", "tok_split", ".", "append", "(", "s_", ")", "\n", "", "else", ":", "\n", "                    ", "tok_split", ".", "extend", "(", "tokenizer", ".", "_tok_bpe", "(", "s", ")", ")", "\n", "\n", "", "", "vecs", "=", "[", "]", "\n", "for", "s", "in", "tok_split", ":", "\n", "                ", "idx_split", "=", "tokenizer", ".", "encoder", ".", "get", "(", "s", ",", "-", "1", ")", "\n", "if", "idx_split", ">", "-", "1", ":", "\n", "                    ", "vec_split", "=", "model", ".", "model", ".", "shared", ".", "weight", ".", "data", "[", "idx_split", "]", ".", "clone", "(", ")", "\n", "vecs", ".", "append", "(", "vec_split", ")", "\n", "\n", "", "", "if", "vecs", ":", "\n", "                ", "vec", "=", "torch", ".", "stack", "(", "vecs", ",", "0", ")", ".", "mean", "(", "0", ")", "\n", "noise", "=", "torch", ".", "empty_like", "(", "vec", ")", "\n", "noise", ".", "uniform_", "(", "-", "0.1", ",", "+", "0.1", ")", "\n", "model", ".", "model", ".", "shared", ".", "weight", ".", "data", "[", "idx", "]", "=", "vec", "+", "noise", "\n", "modified", "+=", "1", "\n", "\n", "", "", "", "if", "checkpoint", "is", "not", "None", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "checkpoint", ",", "map_location", "=", "'cpu'", ")", "[", "'model'", "]", ")", "\n", "\n", "", "return", "model", ",", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils_temp.instantiate_multitask_loader": [[138, 153], ["spring_amr.dataset.DpPretrainDataset", "spring_amr.dataset.AMRDatasetTokenBatcherAndLoader"], "function", ["None"], ["", "def", "instantiate_multitask_loader", "(", "\n", "task_name", ",", "\n", "path_src", ",", "\n", "path_gold", ",", "\n", "tokenizer", ",", "\n", "batch_size", "=", "500", ",", "\n", "remove_longer_than", "=", "None", ",", "\n", "evaluation", "=", "False", "\n", ")", ":", "\n", "\n", "    ", "if", "task_name", "==", "\"dp\"", ":", "\n", "        ", "dataset", "=", "DpPretrainDataset", "(", "path_src", ",", "path_gold", ",", "tokenizer", ",", "remove_longer_than", "=", "remove_longer_than", ")", "\n", "loader", "=", "AMRDatasetTokenBatcherAndLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "not", "evaluation", ")", "\n", "\n", "", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils_temp.instantiate_real_multitask_loader": [[154, 183], ["spring_amr.dataset.MultiTaskDataset", "spring_amr.dataset.AMRDatasetTokenBatcherAndLoader", "pathlib.Path().write_text", "isinstance", "isinstance", "pathlib.Path", "pathlib.Path", "pathlib.Path", "p.read_text", "glob.glob"], "function", ["None"], ["", "def", "instantiate_real_multitask_loader", "(", "\n", "task_name", ",", "\n", "path_src", ",", "\n", "path_gold", ",", "\n", "tokenizer", ",", "\n", "batch_size", "=", "500", ",", "\n", "remove_longer_than", "=", "None", ",", "\n", "evaluation", "=", "False", ",", "\n", "out", "=", "None", "\n", ")", ":", "\n", "\n", "    ", "dataset", "=", "MultiTaskDataset", "(", "path_src", ",", "path_gold", ",", "tokenizer", ",", "remove_longer_than", "=", "remove_longer_than", ")", "\n", "loader", "=", "AMRDatasetTokenBatcherAndLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "not", "evaluation", ")", "\n", "\n", "\n", "\n", "if", "evaluation", ":", "\n", "        ", "paths", "=", "[", "]", "\n", "if", "isinstance", "(", "path_src", "[", "'amr'", "]", ",", "str", ")", "or", "isinstance", "(", "path_src", "[", "'amr'", "]", ",", "Path", ")", ":", "\n", "            ", "glob_pattn", "=", "[", "path_src", "[", "'amr'", "]", "]", "\n", "for", "gpattn", "in", "glob_pattn", ":", "\n", "                ", "paths", "+=", "[", "Path", "(", "p", ")", "for", "p", "in", "glob", "(", "gpattn", ")", "]", "\n", "", "", "else", ":", "\n", "            ", "paths", "=", "[", "Path", "(", "p", ")", "for", "p", "in", "path_src", "[", "'amr'", "]", "]", "\n", "", "assert", "out", "is", "not", "None", "\n", "Path", "(", "out", ")", ".", "write_text", "(", "\n", "'\\n\\n'", ".", "join", "(", "[", "p", ".", "read_text", "(", ")", "for", "p", "in", "paths", "]", ")", ")", "\n", "\n", "", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils_temp.instantiate_loader_indexed": [[191, 229], ["spring_amr.dataset.AMRDataset_Index", "spring_amr.dataset.AMRDatasetTokenBatcherAndLoader", "isinstance", "isinstance", "pathlib.Path().write_text", "pathlib.Path", "glob.glob", "pathlib.Path", "p.read_text"], "function", ["None"], ["", "def", "instantiate_loader_indexed", "(", "\n", "glob_pattn", ",", "\n", "tokenizer", ",", "\n", "indexs", ",", "\n", "batch_size", "=", "500", ",", "\n", "evaluation", "=", "True", ",", "\n", "out", "=", "None", ",", "\n", "use_recategorization", "=", "False", ",", "\n", "remove_longer_than", "=", "None", ",", "\n", "remove_wiki", "=", "False", ",", "\n", "dereify", "=", "True", ",", "\n", ")", ":", "\n", "    ", "paths", "=", "[", "]", "\n", "if", "isinstance", "(", "glob_pattn", ",", "str", ")", "or", "isinstance", "(", "glob_pattn", ",", "Path", ")", ":", "\n", "        ", "glob_pattn", "=", "[", "glob_pattn", "]", "\n", "", "for", "gpattn", "in", "glob_pattn", ":", "\n", "        ", "paths", "+=", "[", "Path", "(", "p", ")", "for", "p", "in", "glob", "(", "gpattn", ")", "]", "\n", "", "if", "evaluation", ":", "\n", "        ", "assert", "out", "is", "not", "None", "\n", "Path", "(", "out", ")", ".", "write_text", "(", "\n", "'\\n\\n'", ".", "join", "(", "[", "p", ".", "read_text", "(", ")", "for", "p", "in", "paths", "]", ")", ")", "\n", "", "dataset", "=", "AMRDataset_Index", "(", "\n", "paths", ",", "\n", "tokenizer", ",", "\n", "indexs", "=", "indexs", ",", "\n", "use_recategorization", "=", "use_recategorization", ",", "\n", "remove_longer_than", "=", "remove_longer_than", ",", "\n", "remove_wiki", "=", "remove_wiki", ",", "\n", "dereify", "=", "dereify", ",", "\n", ")", "\n", "\n", "\n", "loader", "=", "AMRDatasetTokenBatcherAndLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "not", "evaluation", ",", "\n", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils_temp.instantiate_loader": [[232, 267], ["spring_amr.dataset.AMRDataset", "spring_amr.dataset.AMRDatasetTokenBatcherAndLoader", "isinstance", "isinstance", "pathlib.Path().write_text", "pathlib.Path", "glob.glob", "pathlib.Path", "p.read_text"], "function", ["None"], ["", "def", "instantiate_loader", "(", "\n", "glob_pattn", ",", "\n", "tokenizer", ",", "\n", "batch_size", "=", "500", ",", "\n", "evaluation", "=", "True", ",", "\n", "out", "=", "None", ",", "\n", "use_recategorization", "=", "False", ",", "\n", "remove_longer_than", "=", "1000", ",", "\n", "remove_wiki", "=", "False", ",", "\n", "dereify", "=", "True", ",", "\n", ")", ":", "\n", "    ", "paths", "=", "[", "]", "\n", "if", "isinstance", "(", "glob_pattn", ",", "str", ")", "or", "isinstance", "(", "glob_pattn", ",", "Path", ")", ":", "\n", "        ", "glob_pattn", "=", "[", "glob_pattn", "]", "\n", "", "for", "gpattn", "in", "glob_pattn", ":", "\n", "        ", "paths", "+=", "[", "Path", "(", "p", ")", "for", "p", "in", "glob", "(", "gpattn", ")", "]", "\n", "", "if", "evaluation", ":", "\n", "        ", "assert", "out", "is", "not", "None", "\n", "Path", "(", "out", ")", ".", "write_text", "(", "\n", "'\\n\\n'", ".", "join", "(", "[", "p", ".", "read_text", "(", ")", "for", "p", "in", "paths", "]", ")", ")", "\n", "", "dataset", "=", "AMRDataset", "(", "\n", "paths", ",", "\n", "tokenizer", ",", "\n", "use_recategorization", "=", "use_recategorization", ",", "\n", "remove_longer_than", "=", "remove_longer_than", ",", "\n", "remove_wiki", "=", "remove_wiki", ",", "\n", "dereify", "=", "dereify", ",", "\n", ")", "\n", "\n", "loader", "=", "AMRDatasetTokenBatcherAndLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "not", "evaluation", ",", "\n", ")", "\n", "return", "loader", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.entities.read_entities": [[3, 31], ["enumerate", "zip", "collections.defaultdict", "enumerate", "enumerate", "rel.startswith", "name_to_ops[].append"], "function", ["None"], ["def", "read_entities", "(", "sentences", ",", "graphs", ",", "just_tagged", "=", "True", ")", ":", "\n", "\n", "    ", "for", "i", ",", "(", "s", ",", "g", ")", "in", "enumerate", "(", "zip", "(", "sentences", ",", "graphs", ")", ")", ":", "\n", "\n", "        ", "with_wikis", "=", "{", "}", "\n", "name_to_entity", "=", "{", "}", "\n", "name_to_ops", "=", "defaultdict", "(", "list", ")", "\n", "\n", "for", "nt", ",", "t", "in", "enumerate", "(", "g", ".", "triples", ")", ":", "\n", "            ", "n1", ",", "rel", ",", "n2", "=", "t", "\n", "\n", "if", "n2", "==", "'-'", "and", "just_tagged", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "rel", "==", "':wiki'", ":", "\n", "                ", "with_wikis", "[", "n1", "]", "=", "(", "nt", ",", "n2", ")", "\n", "\n", "", "", "for", "t", "in", "g", ".", "triples", ":", "\n", "            ", "n1", ",", "rel", ",", "n2", "=", "t", "\n", "if", "(", "n1", "in", "with_wikis", ")", "and", "(", "rel", "==", "':name'", ")", ":", "\n", "                ", "name_to_entity", "[", "n2", "]", "=", "n1", "\n", "\n", "", "", "for", "nt", ",", "t", "in", "enumerate", "(", "g", ".", "triples", ")", ":", "\n", "            ", "n1", ",", "rel", ",", "n2", "=", "t", "\n", "if", "(", "n1", "in", "name_to_entity", ")", "and", "rel", ".", "startswith", "(", "':op'", ")", ":", "\n", "                ", "name_to_ops", "[", "n1", "]", ".", "append", "(", "t", ")", "\n", "\n", "", "", "yield", "(", "i", ",", "with_wikis", ",", "name_to_entity", ",", "name_to_ops", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils.instaniate_model_tokenizer_cl": [[13, 16], ["utils.instantiate_model_and_tokenizer"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.model_utils.instantiate_model_and_tokenizer"], ["\n", "##### Reading helpers #####", "\n", "def", "read_sentences_from_file", "(", "path_to_file", ",", "one_sentence_per_line", "=", "True", ")", ":", "\n", "    ", "lines", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils.instaniate_tokenizer": [[18, 20], ["None"], "function", ["None"], ["        ", "for", "line", "in", "file", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "!=", "\"\"", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils.instantiate_model_and_tokenizer_multitask": [[23, 135], ["transformers.AutoConfig.from_pretrained", "spring_amr.tokenization_bart.MultiTaskAmrTokenizer.from_pretrained", "spring_amr.modeling_bart.AMRBartForConditionalGeneration.resize_token_embeddings", "spring_amr.modeling_bart.AMRBartForConditionalGeneration.from_pretrained", "spring_amr.modeling_bart.AMRBartForConditionalGeneration", "len", "MultiTaskAmrTokenizer.from_pretrained.encoder.items", "spring_amr.modeling_bart.AMRBartForConditionalGeneration.init_reverse_model", "spring_amr.modeling_bart.AMRBartForConditionalGeneration.load_state_dict", "tok.lstrip.lstrip", "MultiTaskAmrTokenizer.from_pretrained.encoder.get", "torch.stack().mean", "torch.empty_like", "torch.empty_like.uniform_", "torch.load", "tok.lstrip.startswith", "tok.lstrip.endswith", "tok.lstrip.startswith", "tok.split.append", "tok.split.extend", "spring_amr.modeling_bart.AMRBartForConditionalGeneration.model.shared.weight.data[].clone", "vecs.append", "str", "tok.lstrip.startswith", "MultiTaskAmrTokenizer.from_pretrained._tok_bpe", "torch.stack", "[].strip", "tok.lstrip.split", "tok.lstrip.startswith", "tok.lstrip.startswith", "tok.lstrip.split", "str", "tok.lstrip.startswith", "int", "str", "int", "str", "tok.lstrip.lstrip().split", "int", "tok.lstrip.lstrip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.resize_token_embeddings", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.init_reverse_model", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "", "", "if", "one_sentence_per_line", ":", "\n", "        ", "sentences", "=", "lines", "\n", "", "else", ":", "\n", "        ", "text", "=", "\" \"", ".", "join", "(", "lines", ")", "\n", "sentences", "=", "list", "(", "split_multi", "(", "text", ")", ")", "\n", "sentences", "=", "[", "sentence", "for", "sentence", "in", "sentences", "if", "sentence", "!=", "\"\"", "]", "\n", "\n", "", "return", "sentences", "\n", "\n", "\n", "##### Printing / writing  helpers #####", "\n", "", "def", "get_candidate_summary", "(", "candidate", ")", ":", "\n", "    ", "wikipedia_id", "=", "candidate", "[", "\"wikipedia_id\"", "]", "\n", "wikidata_id", "=", "candidate", "[", "\"wikidata_id\"", "]", "\n", "wikipedia_title", "=", "candidate", "[", "\"wikipedia_title\"", "]", "\n", "\n", "return", "\"{}, {}, {}\"", ".", "format", "(", "wikipedia_id", ",", "wikidata_id", ",", "wikipedia_title", ")", "\n", "\n", "\n", "", "def", "present_sentence_mentions", "(", "sentence", ",", "mentions", ",", "output_file", ")", ":", "\n", "    ", "if", "output_file", "!=", "None", ":", "\n", "        ", "f", "=", "io", ".", "open", "(", "output_file", ",", "mode", "=", "\"a\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "output", "=", "lambda", "s", ":", "f", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "s", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "lambda", "s", ":", "print", "(", "s", ")", "\n", "", "output", "(", "\"Sentence: {}\"", ".", "format", "(", "sentence", ")", ")", "\n", "\n", "mention_entity_pairs", "=", "[", "]", "\n", "for", "mention", "in", "mentions", ":", "\n", "        ", "candidates", "=", "mention", "[", "\"candidates\"", "]", "\n", "# prediction = mention.get('predicted_candidate_idx', 0)", "\n", "prediction", "=", "mention", "[", "\"predicted_candidate_idx\"", "]", "\n", "\n", "if", "prediction", "<", "len", "(", "candidates", ")", ":", "\n", "# print(type(mention['prob_assigned_to_candidate']))", "\n", "# print(mention['prob_assigned_to_candidate'])", "\n", "            ", "mention_rep", "=", "\"{} ({}, {}) - {} (conf. {:.5f})\"", ".", "format", "(", "\n", "mention", "[", "\"text\"", "]", ",", "\n", "mention", "[", "\"start_pos\"", "]", ",", "\n", "mention", "[", "\"end_pos\"", "]", ",", "\n", "get_candidate_summary", "(", "candidates", "[", "prediction", "]", ")", ",", "\n", "mention", "[", "\"prob_assigned_to_candidate\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "mention_rep", "=", "\"{} ({}, {}) - {}\"", ".", "format", "(", "\n", "mention", "[", "\"text\"", "]", ",", "\n", "mention", "[", "\"start_pos\"", "]", ",", "\n", "mention", "[", "\"end_pos\"", "]", ",", "\n", "\"No candidate selected\"", ",", "\n", ")", "\n", "\n", "", "mention_entity_pairs", ".", "append", "(", "mention_rep", ")", "\n", "\n", "", "if", "len", "(", "mention_entity_pairs", ")", "!=", "0", ":", "\n", "        ", "output", "(", "\"Mention-Entity pairs: \\n{}\"", ".", "format", "(", "\"\\n\"", ".", "join", "(", "mention_entity_pairs", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "(", "\"No detected mentions\"", ")", "\n", "\n", "", "output", "(", "\"\"", ")", "\n", "\n", "\n", "", "def", "sentence_mentions_pairs", "(", "sentences", ",", "mentions", ")", ":", "\n", "    ", "mentions_per_sent", "=", "{", "}", "\n", "\n", "for", "m", "in", "mentions", ":", "\n", "        ", "sent_idx", "=", "int", "(", "m", "[", "\"sent_idx\"", "]", ")", "\n", "\n", "curr_ments", "=", "mentions_per_sent", ".", "get", "(", "sent_idx", ",", "[", "]", ")", "\n", "curr_ments", ".", "append", "(", "m", ")", "\n", "\n", "mentions_per_sent", "[", "sent_idx", "]", "=", "curr_ments", "\n", "\n", "", "pairs", "=", "[", "]", "\n", "\n", "for", "idx", ",", "sent", "in", "enumerate", "(", "sentences", ")", ":", "\n", "        ", "pairs", ".", "append", "(", "(", "sent", ",", "mentions_per_sent", ".", "get", "(", "idx", ",", "[", "]", ")", ")", ")", "\n", "\n", "", "return", "pairs", "\n", "\n", "\n", "", "def", "present_annotated_sentences", "(", "sentences", ",", "mentions", ",", "output_file", "=", "None", ")", ":", "\n", "    ", "pairs", "=", "sentence_mentions_pairs", "(", "sentences", ",", "mentions", ")", "\n", "\n", "for", "sent", ",", "ments", "in", "pairs", ":", "\n", "        ", "present_sentence_mentions", "(", "sent", ",", "ments", ",", "output_file", ")", "\n", "\n", "\n", "", "", "def", "write_dicts_as_json_per_line", "(", "list_of_dicts", ",", "txt_file_path", ")", ":", "\n", "    ", "with", "io", ".", "open", "(", "txt_file_path", ",", "mode", "=", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "file", ":", "\n", "        ", "for", "idx", ",", "mention", "in", "enumerate", "(", "list_of_dicts", ")", ":", "\n", "            ", "json_string", "=", "json", ".", "dumps", "(", "mention", ")", "\n", "file", ".", "write", "(", "json_string", ")", "\n", "\n", "if", "idx", "!=", "(", "len", "(", "list_of_dicts", ")", "-", "1", ")", ":", "\n", "                ", "file", ".", "write", "(", "\"\\n\"", ")", "\n", "\n", "\n", "", "", "", "", "def", "get_mentions_txt_file_path", "(", "output_folder_path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_folder_path", ",", "exist_ok", "=", "True", ")", "\n", "file_name", "=", "\"mentions.jsonl\"", "\n", "path_to_file", "=", "os", ".", "path", ".", "join", "(", "output_folder_path", ",", "file_name", ")", "\n", "\n", "return", "path_to_file", "\n", "\n", "\n", "", "def", "get_sentences_txt_file_path", "(", "output_folder_path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_folder_path", ",", "exist_ok", "=", "True", ")", "\n", "file_name", "=", "\"sentences.jsonl\"", "\n", "path_to_file", "=", "os", ".", "path", ".", "join", "(", "output_folder_path", ",", "file_name", ")", "\n", "\n", "return", "path_to_file", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils.instantiate_model_and_tokenizer": [[136, 257], ["transformers.AutoConfig.from_pretrained", "spring_amr.modeling_bart.AMRBartForConditionalGeneration.resize_token_embeddings", "spring_amr.tokenization_bart.PENMANBartTokenizer.from_pretrained", "spring_amr.tokenization_bart.AMRBartTokenizer.from_pretrained", "spring_amr.modeling_bart.AMRBartForConditionalGeneration.from_pretrained", "spring_amr.modeling_bart.AMRBartForConditionalGeneration", "len", "AMRBartTokenizer.from_pretrained.encoder.items", "spring_amr.modeling_bart.AMRBartForConditionalGeneration.init_reverse_model", "spring_amr.modeling_bart.AMRBartForConditionalGeneration.load_state_dict", "tok.lstrip.lstrip", "AMRBartTokenizer.from_pretrained.encoder.get", "torch.stack().mean", "torch.empty_like", "torch.empty_like.uniform_", "torch.load", "tok.lstrip.startswith", "tok.lstrip.endswith", "tok.lstrip.startswith", "tok.split.append", "tok.split.extend", "spring_amr.modeling_bart.AMRBartForConditionalGeneration.model.shared.weight.data[].clone", "vecs.append", "str", "tok.lstrip.startswith", "AMRBartTokenizer.from_pretrained._tok_bpe", "torch.stack", "[].strip", "tok.lstrip.split", "tok.lstrip.startswith", "tok.lstrip.startswith", "tok.lstrip.split", "str", "tok.lstrip.startswith", "int", "str", "int", "str", "tok.lstrip.lstrip().split", "int", "tok.lstrip.lstrip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.resize_token_embeddings", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.init_reverse_model", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "get_end2end_pickle_output_file_path", "(", "output_folder_path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_folder_path", ",", "exist_ok", "=", "True", ")", "\n", "file_name", "=", "\"mentions_and_sentences.pickle\"", "\n", "path_to_file", "=", "os", ".", "path", ".", "join", "(", "output_folder_path", ",", "file_name", ")", "\n", "\n", "return", "path_to_file", "\n", "\n", "\n", "", "def", "write_end2end_pickle_output", "(", "sentences", ",", "mentions", ",", "output_file_id", ")", ":", "\n", "    ", "obj", "=", "{", "\"sentences\"", ":", "sentences", ",", "\"mentions\"", ":", "mentions", "}", "\n", "with", "open", "(", "get_end2end_pickle_output_file_path", "(", "output_file_id", ")", ",", "\"wb\"", ")", "as", "file", ":", "\n", "        ", "pickle", ".", "dump", "(", "obj", ",", "file", ")", "\n", "\n", "\n", "", "", "def", "get_end2end_pretty_output_file_path", "(", "output_folder_path", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "output_folder_path", ",", "exist_ok", "=", "True", ")", "\n", "file_name", "=", "\"pretty.txt\"", "\n", "path_to_file", "=", "os", ".", "path", ".", "join", "(", "output_folder_path", ",", "file_name", ")", "\n", "return", "path_to_file", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils.instantiate_multitask_loader": [[259, 274], ["spring_amr.dataset.DpPretrainDataset", "spring_amr.dataset.AMRDatasetTokenBatcherAndLoader"], "function", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils.instantiate_real_multitask_loader": [[275, 304], ["spring_amr.dataset.MultiTaskDataset", "spring_amr.dataset.AMRDatasetTokenBatcherAndLoader", "pathlib.Path().write_text", "isinstance", "isinstance", "pathlib.Path", "pathlib.Path", "pathlib.Path", "p.read_text", "glob.glob"], "function", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils.instantiate_loader_indexed": [[312, 350], ["spring_amr.dataset.AMRDataset_Index", "spring_amr.dataset.AMRDatasetTokenBatcherAndLoader", "isinstance", "isinstance", "pathlib.Path().write_text", "pathlib.Path", "glob.glob", "pathlib.Path", "p.read_text"], "function", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.utils.instantiate_loader": [[353, 388], ["spring_amr.dataset.AMRDataset", "spring_amr.dataset.AMRDatasetTokenBatcherAndLoader", "isinstance", "isinstance", "pathlib.Path().write_text", "pathlib.Path", "glob.glob", "pathlib.Path", "p.read_text"], "function", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.evaluation.out_put_hidden_states": [[14, 39], ["len", "model.eval", "model.get_encoder", "model.get_encoder.eval", "print", "tqdm.tqdm", "model.get_encoder.", "torch.mean().cpu", "outputs_states.append", "torch.mean().cpu.detach().numpy", "torch.mean", "out[].squeeze", "torch.mean().cpu.detach"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.get_encoder", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["def", "out_put_hidden_states", "(", "loader", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "shuffle_orig", "=", "loader", ".", "shuffle", "\n", "sort_orig", "=", "loader", ".", "sort", "\n", "\n", "loader", ".", "shuffle", "=", "False", "\n", "loader", ".", "sort", "=", "True", "\n", "\n", "total", "=", "len", "(", "loader", ".", "dataset", ")", "\n", "model", ".", "eval", "(", ")", "\n", "model", ".", "amr_mode", "=", "True", "\n", "\n", "encoder", "=", "model", ".", "get_encoder", "(", ")", "\n", "encoder", ".", "eval", "(", ")", "\n", "\n", "print", "(", "encoder", ")", "\n", "\n", "outputs_states", "=", "[", "]", "\n", "\n", "for", "x", "in", "tqdm", "(", "loader", ")", ":", "\n", "        ", "out", "=", "encoder", "(", "input_ids", "=", "x", "[", "0", "]", "[", "'input_ids'", "]", ",", "attention_mask", "=", "x", "[", "0", "]", "[", "'attention_mask'", "]", ")", "\n", "average_states", "=", "torch", ".", "mean", "(", "out", "[", "0", "]", ".", "squeeze", "(", "0", ")", ",", "0", ")", ".", "cpu", "(", ")", "\n", "outputs_states", ".", "append", "(", "average_states", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "\n", "", "return", "outputs_states", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.evaluation.predict_amrs_from_sentence": [[40, 102], ["len", "model.eval", "range", "len", "graphs.append", "range", "tqdm.tqdm", "tokenizer.decode_amr", "graphs_same_source.append", "tuple", "ids.extend", "len", "range", "bar.update", "zip", "torch.no_grad", "model.generate", "model.generate.size", "tokens.append", "range", "out[].tolist", "tokens_same_source.append", "sorted", "enumerate"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer.decode_amr", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.inference.Inference.generate", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "predict_amrs_from_sentence", "(", "\n", "loader", ",", "model", ",", "tokenizer", ",", "beam_size", "=", "1", ",", "tokens", "=", "None", ",", "restore_name_ops", "=", "False", ",", "return_all", "=", "False", ")", ":", "\n", "\n", "    ", "shuffle_orig", "=", "loader", ".", "shuffle", "\n", "sort_orig", "=", "loader", ".", "sort", "\n", "\n", "loader", ".", "shuffle", "=", "False", "\n", "loader", ".", "sort", "=", "True", "\n", "\n", "total", "=", "len", "(", "loader", ".", "dataset", ")", "\n", "model", ".", "eval", "(", ")", "\n", "model", ".", "amr_mode", "=", "True", "\n", "\n", "if", "tokens", "is", "None", ":", "\n", "        ", "ids", "=", "[", "]", "\n", "tokens", "=", "[", "]", "\n", "with", "tqdm", "(", "total", "=", "total", ")", "as", "bar", ":", "\n", "            ", "for", "x", ",", "extra", "in", "loader", ":", "\n", "                ", "ii", "=", "extra", "[", "'ids'", "]", "\n", "ids", ".", "extend", "(", "ii", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "out", "=", "model", ".", "generate", "(", "\n", "**", "x", ",", "\n", "max_length", "=", "1024", ",", "\n", "decoder_start_token_id", "=", "0", ",", "\n", "num_beams", "=", "beam_size", ",", "\n", "num_return_sequences", "=", "beam_size", ")", "\n", "", "nseq", "=", "len", "(", "ii", ")", "\n", "for", "i1", "in", "range", "(", "0", ",", "out", ".", "size", "(", "0", ")", ",", "beam_size", ")", ":", "\n", "                    ", "tokens_same_source", "=", "[", "]", "\n", "tokens", ".", "append", "(", "tokens_same_source", ")", "\n", "for", "i2", "in", "range", "(", "i1", ",", "i1", "+", "beam_size", ")", ":", "\n", "                        ", "tokk", "=", "out", "[", "i2", "]", ".", "tolist", "(", ")", "\n", "tokens_same_source", ".", "append", "(", "tokk", ")", "\n", "", "", "bar", ".", "update", "(", "nseq", ")", "\n", "# reorder", "\n", "", "", "tokens", "=", "[", "tokens", "[", "i", "]", "for", "i", "in", "ids", "]", "\n", "tokens", "=", "[", "t", "for", "tt", "in", "tokens", "for", "t", "in", "tt", "]", "\n", "\n", "", "graphs", "=", "[", "]", "\n", "for", "i1", "in", "range", "(", "0", ",", "len", "(", "tokens", ")", ",", "beam_size", ")", ":", "\n", "        ", "graphs_same_source", "=", "[", "]", "\n", "graphs", ".", "append", "(", "graphs_same_source", ")", "\n", "for", "i2", "in", "range", "(", "i1", ",", "i1", "+", "beam_size", ")", ":", "\n", "            ", "tokk", "=", "tokens", "[", "i2", "]", "\n", "graph", ",", "status", ",", "(", "lin", ",", "backr", ")", "=", "tokenizer", ".", "decode_amr", "(", "tokk", ",", "restore_name_ops", "=", "restore_name_ops", ")", "\n", "graph", ".", "status", "=", "status", "\n", "graph", ".", "nodes", "=", "lin", "\n", "graph", ".", "backreferences", "=", "backr", "\n", "graph", ".", "tokens", "=", "tokk", "\n", "graphs_same_source", ".", "append", "(", "graph", ")", "\n", "", "graphs_same_source", "[", ":", "]", "=", "tuple", "(", "zip", "(", "*", "sorted", "(", "enumerate", "(", "graphs_same_source", ")", ",", "key", "=", "lambda", "x", ":", "(", "x", "[", "1", "]", ".", "status", ".", "value", ",", "x", "[", "0", "]", ")", ")", ")", ")", "[", "1", "]", "\n", "\n", "\n", "\n", "", "loader", ".", "shuffle", "=", "shuffle_orig", "\n", "loader", ".", "sort", "=", "sort_orig", "\n", "\n", "if", "not", "return_all", ":", "\n", "        ", "graphs", "=", "[", "gg", "[", "0", "]", "for", "gg", "in", "graphs", "]", "\n", "\n", "", "return", "graphs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.evaluation.predict_amrs": [[103, 172], ["len", "model.eval", "range", "zip", "len", "graphs.append", "range", "tqdm.tqdm", "tokenizer.decode_amr", "graphs_same_source.append", "tuple", "gg.metadata.copy", "str", "ids.extend", "len", "range", "bar.update", "zip", "datetime.datetime.now", "torch.no_grad", "model.generate", "model.generate.size", "tokens.append", "range", "out[].tolist", "tokens_same_source.append", "sorted", "enumerate"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer.decode_amr", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.inference.Inference.generate", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "predict_amrs", "(", "\n", "loader", ",", "model", ",", "tokenizer", ",", "beam_size", "=", "1", ",", "tokens", "=", "None", ",", "restore_name_ops", "=", "False", ",", "return_all", "=", "False", ")", ":", "\n", "\n", "    ", "shuffle_orig", "=", "loader", ".", "shuffle", "\n", "sort_orig", "=", "loader", ".", "sort", "\n", "\n", "loader", ".", "shuffle", "=", "False", "\n", "loader", ".", "sort", "=", "True", "\n", "\n", "total", "=", "len", "(", "loader", ".", "dataset", ")", "\n", "model", ".", "eval", "(", ")", "\n", "model", ".", "amr_mode", "=", "True", "\n", "\n", "if", "tokens", "is", "None", ":", "\n", "        ", "ids", "=", "[", "]", "\n", "tokens", "=", "[", "]", "\n", "with", "tqdm", "(", "total", "=", "total", ")", "as", "bar", ":", "\n", "            ", "for", "x", ",", "y", ",", "extra", "in", "loader", ":", "\n", "                ", "ii", "=", "extra", "[", "'ids'", "]", "\n", "ids", ".", "extend", "(", "ii", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "out", "=", "model", ".", "generate", "(", "\n", "**", "x", ",", "\n", "max_length", "=", "1024", ",", "\n", "decoder_start_token_id", "=", "0", ",", "\n", "num_beams", "=", "beam_size", ",", "\n", "num_return_sequences", "=", "beam_size", ")", "\n", "", "nseq", "=", "len", "(", "ii", ")", "\n", "for", "i1", "in", "range", "(", "0", ",", "out", ".", "size", "(", "0", ")", ",", "beam_size", ")", ":", "\n", "                    ", "tokens_same_source", "=", "[", "]", "\n", "tokens", ".", "append", "(", "tokens_same_source", ")", "\n", "for", "i2", "in", "range", "(", "i1", ",", "i1", "+", "beam_size", ")", ":", "\n", "                        ", "tokk", "=", "out", "[", "i2", "]", ".", "tolist", "(", ")", "\n", "tokens_same_source", ".", "append", "(", "tokk", ")", "\n", "", "", "bar", ".", "update", "(", "nseq", ")", "\n", "# reorder", "\n", "", "", "tokens", "=", "[", "tokens", "[", "i", "]", "for", "i", "in", "ids", "]", "\n", "tokens", "=", "[", "t", "for", "tt", "in", "tokens", "for", "t", "in", "tt", "]", "\n", "\n", "", "graphs", "=", "[", "]", "\n", "for", "i1", "in", "range", "(", "0", ",", "len", "(", "tokens", ")", ",", "beam_size", ")", ":", "\n", "        ", "graphs_same_source", "=", "[", "]", "\n", "graphs", ".", "append", "(", "graphs_same_source", ")", "\n", "for", "i2", "in", "range", "(", "i1", ",", "i1", "+", "beam_size", ")", ":", "\n", "            ", "tokk", "=", "tokens", "[", "i2", "]", "\n", "graph", ",", "status", ",", "(", "lin", ",", "backr", ")", "=", "tokenizer", ".", "decode_amr", "(", "tokk", ",", "restore_name_ops", "=", "restore_name_ops", ")", "\n", "graph", ".", "status", "=", "status", "\n", "graph", ".", "nodes", "=", "lin", "\n", "graph", ".", "backreferences", "=", "backr", "\n", "graph", ".", "tokens", "=", "tokk", "\n", "graphs_same_source", ".", "append", "(", "graph", ")", "\n", "", "graphs_same_source", "[", ":", "]", "=", "tuple", "(", "zip", "(", "*", "sorted", "(", "enumerate", "(", "graphs_same_source", ")", ",", "key", "=", "lambda", "x", ":", "(", "x", "[", "1", "]", ".", "status", ".", "value", ",", "x", "[", "0", "]", ")", ")", ")", ")", "[", "1", "]", "\n", "\n", "", "for", "gps", ",", "gg", "in", "zip", "(", "graphs", ",", "loader", ".", "dataset", ".", "graphs", ")", ":", "\n", "        ", "for", "gp", "in", "gps", ":", "\n", "            ", "metadata", "=", "gg", ".", "metadata", ".", "copy", "(", ")", "\n", "metadata", "[", "'annotator'", "]", "=", "'bart-amr'", "\n", "metadata", "[", "'date'", "]", "=", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ")", "\n", "if", "'save-date'", "in", "metadata", ":", "\n", "                ", "del", "metadata", "[", "'save-date'", "]", "\n", "", "gp", ".", "metadata", "=", "metadata", "\n", "\n", "", "", "loader", ".", "shuffle", "=", "shuffle_orig", "\n", "loader", ".", "sort", "=", "sort_orig", "\n", "\n", "if", "not", "return_all", ":", "\n", "        ", "graphs", "=", "[", "gg", "[", "0", "]", "for", "gg", "in", "graphs", "]", "\n", "\n", "", "return", "graphs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.evaluation.predict_sentences": [[173, 226], ["len", "model.eval", "open", "f.writelines", "tqdm.tqdm", "sentences.append", "sentences.append", "ids.extend", "spring_amr.dataset.reverse_direction", "range", "bar.update", "tokenizer.decode().strip", "torch.no_grad", "model.generate", "len", "tokens.append", "range", "tokenizer.decode().strip", "tokens_same_source.append", "model.generate.size", "tokenizer.decode", "tokenizer.decode", "tokk.tolist"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.dataset.reverse_direction", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.inference.Inference.generate", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "predict_sentences", "(", "loader", ",", "model", ",", "tokenizer", ",", "outdir", "=", "None", ",", "beam_size", "=", "1", ",", "tokens", "=", "None", ",", "return_all", "=", "False", ")", ":", "\n", "\n", "    ", "shuffle_orig", "=", "loader", ".", "shuffle", "\n", "sort_orig", "=", "loader", ".", "sort", "\n", "\n", "loader", ".", "shuffle", "=", "False", "\n", "loader", ".", "sort", "=", "True", "\n", "\n", "total", "=", "len", "(", "loader", ".", "dataset", ")", "\n", "model", ".", "eval", "(", ")", "\n", "model", ".", "amr_mode", "=", "False", "\n", "\n", "if", "tokens", "is", "None", ":", "\n", "        ", "ids", "=", "[", "]", "\n", "tokens", "=", "[", "]", "\n", "with", "tqdm", "(", "total", "=", "total", ")", "as", "bar", ":", "\n", "            ", "for", "x", ",", "y", ",", "extra", "in", "loader", ":", "\n", "                ", "ids", ".", "extend", "(", "extra", "[", "'ids'", "]", ")", "\n", "x", ",", "y", "=", "reverse_direction", "(", "x", ",", "y", ")", "\n", "x", "[", "'input_ids'", "]", "=", "x", "[", "'input_ids'", "]", "[", ":", ",", ":", "1024", "]", "\n", "x", "[", "'attention_mask'", "]", "=", "x", "[", "'attention_mask'", "]", "[", ":", ",", ":", "1024", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "out", "=", "model", ".", "generate", "(", "\n", "**", "x", ",", "\n", "max_length", "=", "350", ",", "\n", "decoder_start_token_id", "=", "0", ",", "\n", "num_beams", "=", "beam_size", ",", "\n", "num_return_sequences", "=", "beam_size", ")", "\n", "", "for", "i1", "in", "range", "(", "0", ",", "len", "(", "out", ")", ",", "beam_size", ")", ":", "\n", "                    ", "tokens_same_source", "=", "[", "]", "\n", "tokens", ".", "append", "(", "tokens_same_source", ")", "\n", "for", "i2", "in", "range", "(", "i1", ",", "i1", "+", "beam_size", ")", ":", "\n", "                        ", "tokk", "=", "out", "[", "i2", "]", "\n", "tokk", "=", "[", "t", "for", "t", "in", "tokk", ".", "tolist", "(", ")", "if", "t", ">", "2", "]", "\n", "tokens_same_source", ".", "append", "(", "tokk", ")", "\n", "", "", "bar", ".", "update", "(", "out", ".", "size", "(", "0", ")", "//", "beam_size", ")", "\n", "#reorder", "\n", "", "", "tokens", "=", "[", "tokens", "[", "i", "]", "for", "i", "in", "ids", "]", "\n", "\n", "", "sentences", "=", "[", "]", "\n", "for", "tokens_same_source", "in", "tokens", ":", "\n", "        ", "if", "return_all", ":", "\n", "            ", "sentences", ".", "append", "(", "[", "tokenizer", ".", "decode", "(", "tokk", ")", ".", "strip", "(", ")", "for", "tokk", "in", "tokens_same_source", "]", ")", "\n", "", "else", ":", "\n", "            ", "sentences", ".", "append", "(", "tokenizer", ".", "decode", "(", "tokens_same_source", "[", "0", "]", ")", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "loader", ".", "shuffle", "=", "shuffle_orig", "\n", "loader", ".", "sort", "=", "sort_orig", "\n", "\n", "with", "open", "(", "outdir", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "writelines", "(", "[", "i", "+", "\"\\n\"", "for", "i", "in", "sentences", "]", ")", "\n", "\n", "", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.evaluation.write_predictions": [[227, 231], ["pathlib.Path().write_text", "penman.encode", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode"], ["", "def", "write_predictions", "(", "predictions_path", ",", "tokenizer", ",", "graphs", ")", ":", "\n", "    ", "pieces", "=", "[", "penman", ".", "encode", "(", "g", ")", "for", "g", "in", "graphs", "]", "\n", "Path", "(", "predictions_path", ")", ".", "write_text", "(", "'\\n\\n'", ".", "join", "(", "pieces", ")", ".", "replace", "(", "tokenizer", ".", "INIT", ",", "''", ")", ")", "\n", "return", "predictions_path", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.evaluation.compute_smatch": [[232, 236], ["pathlib.Path().open", "pathlib.Path().open", "next", "smatch.score_amr_pairs", "pathlib.Path", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.score_amr_pairs"], ["", "def", "compute_smatch", "(", "test_path", ",", "predictions_path", ")", ":", "\n", "    ", "with", "Path", "(", "predictions_path", ")", ".", "open", "(", ")", "as", "p", ",", "Path", "(", "test_path", ")", ".", "open", "(", ")", "as", "g", ":", "\n", "        ", "score", "=", "next", "(", "smatch", ".", "score_amr_pairs", "(", "p", ",", "g", ")", ")", "\n", "", "return", "score", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.evaluation.compute_bleu": [[237, 239], ["sacrebleu.corpus_bleu"], "function", ["None"], ["", "def", "compute_bleu", "(", "gold_sentences", ",", "pred_sentences", ")", ":", "\n", "    ", "return", "corpus_bleu", "(", "pred_sentences", ",", "[", "gold_sentences", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.evaluation.compute_bleu_from_files": [[240, 244], ["open().readlines", "open().readlines", "sacrebleu.corpus_bleu", "open", "open"], "function", ["None"], ["", "def", "compute_bleu_from_files", "(", "gold", ",", "pred", ")", ":", "\n", "    ", "golds", "=", "open", "(", "gold", ",", "\"r\"", ")", ".", "readlines", "(", ")", "\n", "preds", "=", "open", "(", "pred", ",", "\"r\"", ")", ".", "readlines", "(", ")", "\n", "return", "corpus_bleu", "(", "preds", ",", "[", "golds", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman._get_model": [[13, 23], ["None"], "function", ["None"], ["def", "_get_model", "(", "dereify", ")", ":", "\n", "    ", "if", "dereify", "is", "None", ":", "\n", "        ", "return", "DEFAULT", "\n", "\n", "\n", "", "elif", "dereify", ":", "\n", "        ", "return", "op_model", "\n", "\n", "", "else", ":", "\n", "        ", "return", "noop_model", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman._remove_wiki": [[24, 35], ["penman.Graph", "triples.append", "penman.Triple"], "function", ["None"], ["", "", "def", "_remove_wiki", "(", "graph", ")", ":", "\n", "    ", "metadata", "=", "graph", ".", "metadata", "\n", "triples", "=", "[", "]", "\n", "for", "t", "in", "graph", ".", "triples", ":", "\n", "        ", "v1", ",", "rel", ",", "v2", "=", "t", "\n", "if", "rel", "==", "':wiki'", ":", "\n", "            ", "t", "=", "Triple", "(", "v1", ",", "rel", ",", "'+'", ")", "\n", "", "triples", ".", "append", "(", "t", ")", "\n", "", "graph", "=", "Graph", "(", "triples", ")", "\n", "graph", ".", "metadata", "=", "metadata", "\n", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.load": [[36, 43], ["c_penman._get_model", "penman.load", "range", "len", "c_penman._remove_wiki"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman._get_model", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.amr_rw._remove_wiki"], ["", "def", "load", "(", "source", ",", "dereify", "=", "None", ",", "remove_wiki", "=", "False", ")", ":", "\n", "    ", "model", "=", "_get_model", "(", "dereify", ")", "\n", "out", "=", "load_", "(", "source", "=", "source", ",", "model", "=", "model", ")", "\n", "if", "remove_wiki", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "out", ")", ")", ":", "\n", "            ", "out", "[", "i", "]", "=", "_remove_wiki", "(", "out", "[", "i", "]", ")", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads": [[44, 51], ["c_penman._get_model", "penman.loads", "range", "len", "c_penman._remove_wiki"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman._get_model", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.amr_rw._remove_wiki"], ["", "def", "loads", "(", "string", ",", "dereify", "=", "None", ",", "remove_wiki", "=", "False", ")", ":", "\n", "    ", "model", "=", "_get_model", "(", "dereify", ")", "\n", "out", "=", "loads_", "(", "string", "=", "string", ",", "model", "=", "model", ")", "\n", "if", "remove_wiki", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "out", ")", ")", ":", "\n", "            ", "out", "[", "i", "]", "=", "_remove_wiki", "(", "out", "[", "i", "]", ")", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode": [[52, 55], ["penman.encode"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode"], ["", "def", "encode", "(", "g", ",", "top", "=", "None", ",", "indent", "=", "-", "1", ",", "compact", "=", "False", ")", ":", "\n", "    ", "model", "=", "amr_model", "\n", "return", "encode_", "(", "g", "=", "g", ",", "top", "=", "top", ",", "indent", "=", "indent", ",", "compact", "=", "compact", ",", "model", "=", "model", ")", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.download": [[19, 26], ["utils.downloader.download_model", "os.path.basename", "os.path.join", "utils.downloader.set_symlink"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.downloader.download_model", "home.repos.pwc.inspect_result.chenllliang_atp.utils.downloader.set_symlink"], []], "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.load_stog_model": [[32, 37], ["models.model_factory.load_inference_model", "os.path.join"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.models.model_factory.load_inference_model"], []], "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.load_gtos_model": [[40, 45], ["models.model_factory.load_inference_model", "os.path.join"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.models.model_factory.load_inference_model"], []], "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.spacy_stog_doc": [[50, 56], ["stog_model.parse_spans", "__init__.load_stog_model"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_spans", "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.load_stog_model"], []], "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.spacy_stog_span": [[58, 63], ["stog_model.parse_spans", "__init__.load_stog_model"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_spans", "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.load_stog_model"], []], "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.setup_spacy_extension": [[65, 69], ["spacy.tokens.doc.Doc.set_extension", "spacy.tokens.span.Span.set_extension"], "function", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.40_Model_Generate_T5.14_Score_BLEU.read_file": [[10, 20], ["print", "open", "line.strip().lower.strip().lower", "nltk.tokenize.word_tokenize", "sents.append", "line.strip().lower.strip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["def", "read_file", "(", "fname", ")", ":", "\n", "    ", "print", "(", "'Reading '", ",", "fname", ")", "\n", "sents", "=", "[", "]", "\n", "with", "open", "(", "fname", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "if", "line", ":", "\n", "                ", "tokens", "=", "word_tokenize", "(", "line", ")", "\n", "sents", ".", "append", "(", "tokens", ")", "\n", "", "", "", "return", "sents", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.61_FAA_Aligner.18_Score_Alignments.load_oneline_alignments": [[7, 17], ["open", "alignments.append", "p.strip", "set", "len", "line.split"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["def", "load_oneline_alignments", "(", "fn", ",", "max_lines", "=", "200", ")", ":", "\n", "    ", "alignments", "=", "[", "]", "\n", "with", "open", "(", "fn", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "parts", "=", "[", "p", ".", "strip", "(", ")", "for", "p", "in", "line", ".", "split", "(", ")", "]", "\n", "parts", "=", "[", "p", "for", "p", "in", "parts", "if", "p", "]", "\n", "alignments", ".", "append", "(", "set", "(", "parts", ")", ")", "\n", "if", "len", "(", "alignments", ")", ">=", "max_lines", ":", "\n", "                ", "break", "\n", "", "", "", "return", "alignments", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.61_FAA_Aligner.30_Gather_LDC_For_Inference.get_graph_sent": [[9, 24], ["entry.splitlines", "line.strip.strip", "line.strip.startswith", "entries[].append", "entries[].append", "line[].strip", "line.strip.startswith", "gstrings.append", "len"], "function", ["None"], ["def", "get_graph_sent", "(", "amr_strings", ")", ":", "\n", "    ", "entries", "=", "{", "'sent'", ":", "[", "]", ",", "'graph'", ":", "[", "]", "}", "\n", "for", "entry", "in", "amr_strings", ":", "\n", "        ", "sent", "=", "None", "\n", "gstrings", "=", "[", "]", "\n", "for", "line", "in", "entry", ".", "splitlines", "(", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ".", "startswith", "(", "'# ::snt'", ")", ":", "\n", "                ", "sent", "=", "line", "[", "len", "(", "'# ::snt'", ")", ":", "]", ".", "strip", "(", ")", "\n", "", "if", "not", "line", ".", "startswith", "(", "'#'", ")", ":", "\n", "                ", "gstrings", ".", "append", "(", "line", ")", "\n", "", "", "if", "sent", "and", "gstrings", ":", "\n", "            ", "entries", "[", "'sent'", "]", ".", "append", "(", "sent", ")", "\n", "entries", "[", "'graph'", "]", ".", "append", "(", "' '", ".", "join", "(", "gstrings", ")", ")", "\n", "", "", "return", "entries", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.61_FAA_Aligner.30_Gather_LDC_For_Inference.write_lines": [[26, 32], ["os.path.join", "print", "open", "f.write"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "write_lines", "(", "dir", ",", "fn", ",", "lines", ")", ":", "\n", "    ", "fpath", "=", "os", ".", "path", ".", "join", "(", "dir", ",", "fn", ")", "\n", "print", "(", "'Writing to'", ",", "fpath", ")", "\n", "with", "open", "(", "fpath", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "lines", ":", "\n", "            ", "f", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.61_FAA_Aligner.34_Score_Alignments.load_oneline_alignments": [[7, 17], ["open", "alignments.append", "p.strip", "set", "len", "line.split"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["def", "load_oneline_alignments", "(", "fn", ",", "max_lines", "=", "200", ")", ":", "\n", "    ", "alignments", "=", "[", "]", "\n", "with", "open", "(", "fn", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "parts", "=", "[", "p", ".", "strip", "(", ")", "for", "p", "in", "line", ".", "split", "(", ")", "]", "\n", "parts", "=", "[", "p", "for", "p", "in", "parts", "if", "p", "]", "\n", "alignments", ".", "append", "(", "set", "(", "parts", ")", ")", "\n", "if", "len", "(", "alignments", ")", ">=", "max_lines", ":", "\n", "                ", "break", "\n", "", "", "", "return", "alignments", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.61_FAA_Aligner.10_Gather_LDC_For_Train.get_graph_sent": [[9, 24], ["entry.splitlines", "line.strip.strip", "line.strip.startswith", "entries[].append", "entries[].append", "line[].strip", "line.strip.startswith", "gstrings.append", "len"], "function", ["None"], ["def", "get_graph_sent", "(", "amr_strings", ")", ":", "\n", "    ", "entries", "=", "{", "'sent'", ":", "[", "]", ",", "'graph'", ":", "[", "]", "}", "\n", "for", "entry", "in", "amr_strings", ":", "\n", "        ", "sent", "=", "None", "\n", "gstrings", "=", "[", "]", "\n", "for", "line", "in", "entry", ".", "splitlines", "(", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ".", "startswith", "(", "'# ::snt'", ")", ":", "\n", "                ", "sent", "=", "line", "[", "len", "(", "'# ::snt'", ")", ":", "]", ".", "strip", "(", ")", "\n", "", "if", "not", "line", ".", "startswith", "(", "'#'", ")", ":", "\n", "                ", "gstrings", ".", "append", "(", "line", ")", "\n", "", "", "if", "sent", "and", "gstrings", ":", "\n", "            ", "entries", "[", "'sent'", "]", ".", "append", "(", "sent", ")", "\n", "entries", "[", "'graph'", "]", ".", "append", "(", "' '", ".", "join", "(", "gstrings", ")", ")", "\n", "", "", "return", "entries", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.61_FAA_Aligner.10_Gather_LDC_For_Train.write_lines": [[26, 32], ["os.path.join", "print", "open", "f.write"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "write_lines", "(", "dir", ",", "fn", ",", "lines", ")", ":", "\n", "    ", "fpath", "=", "os", ".", "path", ".", "join", "(", "dir", ",", "fn", ")", "\n", "print", "(", "'Writing to'", ",", "fpath", ")", "\n", "with", "open", "(", "fpath", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "lines", ":", "\n", "            ", "f", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.10_Misc.FindImports.find_files": [[13, 19], ["os.walk", "fnmatch.fnmatch", "os.path.join"], "function", ["None"], ["def", "find_files", "(", "directory", ",", "pattern", ")", ":", "\n", "    ", "for", "root", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "directory", ")", ":", "\n", "        ", "for", "basename", "in", "files", ":", "\n", "            ", "if", "fnmatch", ".", "fnmatch", "(", "basename", ",", "pattern", ")", ":", "\n", "                ", "filename", "=", "os", ".", "path", ".", "join", "(", "root", ",", "basename", ")", "\n", "yield", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.10_Misc.FindImports.find_imports": [[21, 63], ["set", "open", "f.readlines", "l.strip", "line.startswith", "line.split", "logger.warning", "line.split.index", "line.split.index", "lib.startswith", "lib.split", "set.add", "lib.startswith", "lib.split", "set.add"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["", "", "", "", "def", "find_imports", "(", "fpath", ")", ":", "\n", "    ", "imset", "=", "set", "(", ")", "\n", "with", "open", "(", "fpath", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "# strip line-feeds and keep lines with \"import\" in them", "\n", "", "lines", "=", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "lines", "if", "'import'", "in", "l", "]", "\n", "for", "line", "in", "lines", ":", "\n", "# Make sure it's not a comment line", "\n", "        ", "if", "line", ".", "startswith", "(", "'#'", ")", ":", "\n", "            ", "continue", "\n", "# Skip anything dymatic with importlib", "\n", "", "if", "'importlib'", "in", "line", ":", "\n", "            ", "continue", "\n", "# Split words on the line into a list", "\n", "", "parts", "=", "line", ".", "split", "(", ")", "\n", "# Look for \"from X import Y\" and add X to the set", "\n", "try", ":", "\n", "            ", "index", "=", "parts", ".", "index", "(", "'from'", ")", "\n", "lib", "=", "parts", "[", "index", "+", "1", "]", "\n", "# Skip relative imports since these are always local", "\n", "if", "not", "lib", ".", "startswith", "(", "'.'", ")", ":", "\n", "# only keep the top level module/home/bjascob/.local/lib/python3.8/site-packages", "\n", "                ", "modules", "=", "lib", ".", "split", "(", "'.'", ")", "\n", "imset", ".", "add", "(", "modules", "[", "0", "]", ")", "\n", "", "continue", "\n", "", "except", "ValueError", ":", "\n", "            ", "pass", "\n", "# If the above doesn't work, look for \"import X\" and add X to the set", "\n", "", "try", ":", "\n", "            ", "index", "=", "parts", ".", "index", "(", "'import'", ")", "\n", "lib", "=", "parts", "[", "index", "+", "1", "]", "\n", "# Skip relative imports since these are always local", "\n", "if", "not", "lib", ".", "startswith", "(", "'.'", ")", ":", "\n", "# only report the first portion of the name", "\n", "                ", "modules", "=", "lib", ".", "split", "(", "'.'", ")", "\n", "imset", ".", "add", "(", "modules", "[", "0", "]", ")", "\n", "", "continue", "\n", "", "except", "ValueError", ":", "\n", "            ", "pass", "\n", "# If neither worked then the line couldn't be parsed correctly", "\n", "", "logger", ".", "warning", "(", "'Not able to parse line %s'", "%", "line", ")", "\n", "", "return", "imset", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.10_Misc.FindImports.get_module_info": [[65, 70], ["pkgutil.iter_modules"], "function", ["None"], ["", "def", "get_module_info", "(", ")", ":", "\n", "    ", "minfo", "=", "{", "}", "\n", "for", "x", "in", "pkgutil", ".", "iter_modules", "(", ")", ":", "\n", "        ", "minfo", "[", "x", ".", "name", "]", "=", "x", "\n", "", "return", "minfo", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.10_Misc.FindImports.get_3rd_party": [[72, 75], ["None"], "function", ["None"], ["", "def", "get_3rd_party", "(", "packages", ")", ":", "\n", "    ", "plist", "=", "[", "p", "for", "p", "in", "packages", "if", "(", "'site-packages'", "in", "p", "[", "1", "]", "or", "'dist-packages'", "in", "p", "[", "1", "]", ")", "]", "\n", "return", "plist", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.10_Misc.FindImports.get_package_version": [[77, 95], ["vstring.endswith", "d.lower", "pkgname.lower", "len", "logger.warning", "len", "logger.warning", "vstring.endswith", "os.listdir", "os.path.isdir", "d.startswith", "len", "os.path.join", "len", "len"], "function", ["None"], ["", "def", "get_package_version", "(", "package", ")", ":", "\n", "    ", "pkgname", "=", "package", "[", "0", "]", "\n", "dirname", "=", "package", "[", "1", "]", "\n", "# Try to version the version from the directory name", "\n", "dirs", "=", "[", "d", ".", "lower", "(", ")", "for", "d", "in", "os", ".", "listdir", "(", "dirname", ")", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "dirname", ",", "d", ")", ")", "]", "\n", "ver_name", "=", "pkgname", ".", "lower", "(", ")", "+", "'-'", "\n", "dirs", "=", "[", "d", "for", "d", "in", "dirs", "if", "d", ".", "startswith", "(", "ver_name", ")", "]", "\n", "if", "len", "(", "dirs", ")", ">", "1", ":", "\n", "        ", "logger", ".", "warning", "(", "'Found multiple versions: %s'", "%", "dirs", ")", "\n", "", "if", "len", "(", "dirs", ")", "==", "0", ":", "\n", "        ", "logger", ".", "warning", "(", "'No version directory found for %s %s'", "%", "(", "dirname", ",", "pkgname", ")", ")", "\n", "# Extract the version", "\n", "", "vstring", "=", "dirs", "[", "0", "]", "[", "len", "(", "ver_name", ")", ":", "]", "\n", "if", "vstring", ".", "endswith", "(", "'.dist-info'", ")", ":", "\n", "        ", "vstring", "=", "vstring", "[", ":", "-", "len", "(", "'.dist-info'", ")", "]", "\n", "", "elif", "vstring", ".", "endswith", "(", "'.egg-info'", ")", ":", "\n", "        ", "vstring", "=", "vstring", "[", ":", "-", "len", "(", "'.egg-info'", ")", "]", "\n", "", "return", "vstring", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.62_ISI_Aligner.18_Score_Alignments.load_oneline_alignments": [[7, 17], ["open", "alignments.append", "p.strip", "set", "len", "line.split"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["def", "load_oneline_alignments", "(", "fn", ",", "max_lines", "=", "200", ")", ":", "\n", "    ", "alignments", "=", "[", "]", "\n", "with", "open", "(", "fn", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "parts", "=", "[", "p", ".", "strip", "(", ")", "for", "p", "in", "line", ".", "split", "(", ")", "]", "\n", "parts", "=", "[", "p", "for", "p", "in", "parts", "if", "p", "]", "\n", "alignments", ".", "append", "(", "set", "(", "parts", ")", ")", "\n", "if", "len", "(", "alignments", ")", ">=", "max_lines", ":", "\n", "                ", "break", "\n", "", "", "", "return", "alignments", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.62_ISI_Aligner.10_Gather_LDC.get_graph_sent": [[9, 24], ["entry.splitlines", "line.strip.strip", "line.strip.startswith", "entries[].append", "entries[].append", "line[].strip", "line.strip.startswith", "gstrings.append", "len"], "function", ["None"], ["def", "get_graph_sent", "(", "amr_strings", ")", ":", "\n", "    ", "entries", "=", "{", "'sent'", ":", "[", "]", ",", "'graph'", ":", "[", "]", "}", "\n", "for", "entry", "in", "amr_strings", ":", "\n", "        ", "sent", "=", "None", "\n", "gstrings", "=", "[", "]", "\n", "for", "line", "in", "entry", ".", "splitlines", "(", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ".", "startswith", "(", "'# ::snt'", ")", ":", "\n", "                ", "sent", "=", "line", "[", "len", "(", "'# ::snt'", ")", ":", "]", ".", "strip", "(", ")", "\n", "", "if", "not", "line", ".", "startswith", "(", "'#'", ")", ":", "\n", "                ", "gstrings", ".", "append", "(", "line", ")", "\n", "", "", "if", "sent", "and", "gstrings", ":", "\n", "            ", "entries", "[", "'sent'", "]", ".", "append", "(", "sent", ")", "\n", "entries", "[", "'graph'", "]", ".", "append", "(", "' '", ".", "join", "(", "gstrings", ")", ")", "\n", "", "", "return", "entries", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.62_ISI_Aligner.10_Gather_LDC.write_lines": [[26, 32], ["os.path.join", "print", "open", "f.write"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "write_lines", "(", "dir", ",", "fn", ",", "lines", ")", ":", "\n", "    ", "fpath", "=", "os", ".", "path", ".", "join", "(", "dir", ",", "fn", ")", "\n", "print", "(", "'Writing to'", ",", "fpath", ")", "\n", "with", "open", "(", "fpath", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "lines", ":", "\n", "            ", "f", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.60_RBW_Aligner.02_Build_Aligment_Test_Corpus.mod_graph_meta": [[10, 16], ["None"], "function", ["None"], ["def", "mod_graph_meta", "(", "graph", ")", ":", "\n", "    ", "id", "=", "graph", ".", "metadata", "[", "'id'", "]", "\n", "tok", "=", "graph", ".", "metadata", "[", "'tok'", "]", "\n", "aligns", "=", "graph", ".", "metadata", "[", "'alignments'", "]", "\n", "graph", ".", "metadata", "=", "{", "'id'", ":", "id", ",", "'tok'", ":", "tok", ",", "'isi_alignments'", ":", "aligns", "}", "\n", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.33_Model_Parse_XFM.10_Collect_AMR_Data.load_and_resave_amr_files": [[12, 34], ["isinstance", "sorted", "print", "print", "print", "glob.glob", "print", "graphs.extend", "open", "len", "amrlib.graph_processing.amr_loading_raw.load_raw_amr", "len", "f.write", "os.path.basename"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading_raw.load_raw_amr"], ["def", "load_and_resave_amr_files", "(", "glob_patterns", ",", "out_fpath", ")", ":", "\n", "    ", "if", "isinstance", "(", "glob_patterns", ",", "str", ")", ":", "\n", "        ", "glob_patterns", "=", "[", "glob_patterns", "]", "\n", "# Find all the files", "\n", "", "fpaths", "=", "[", "]", "\n", "for", "pattern", "in", "glob_patterns", ":", "\n", "        ", "glob_fpaths", "=", "glob", "(", "pattern", ")", "\n", "assert", "len", "(", "glob_fpaths", ")", ">", "0", "# check for invalid path in the list", "\n", "fpaths", "+=", "glob_fpaths", "\n", "", "graphs", "=", "[", "]", "\n", "# Load graphs sorted by filename for consistency", "\n", "for", "fpath", "in", "sorted", "(", "fpaths", ",", "key", "=", "lambda", "x", ":", "os", ".", "path", ".", "basename", "(", "x", ")", ")", ":", "\n", "        ", "print", "(", "'Loading'", ",", "fpath", ")", "\n", "graphs", ".", "extend", "(", "load_raw_amr", "(", "fpath", ")", ")", "\n", "", "print", "(", "'Loaded {:,} graphs'", ".", "format", "(", "len", "(", "graphs", ")", ")", ")", "\n", "# Save the collated data", "\n", "print", "(", "'Saving data to'", ",", "out_fpath", ")", "\n", "with", "open", "(", "out_fpath", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "graph", "in", "graphs", ":", "\n", "            ", "f", ".", "write", "(", "'%s\\n\\n'", "%", "graph", ")", "\n", "", "", "print", "(", ")", "\n", "return", "graphs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.33_Model_Parse_XFM.10_Collect_AMR_Data.collect_amr3": [[37, 47], ["os.path.join", "os.path.join", "10_Collect_AMR_Data.load_and_resave_amr_files", "print", "amrlib.graph_processing.wiki_remover.wiki_remove_file", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.33_Model_Parse_XFM.10_Collect_AMR_Data.load_and_resave_amr_files", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_remover.wiki_remove_file", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "collect_amr3", "(", "base_amr_dir", ",", "out_dir", ")", ":", "\n", "# Loop through the file tiles", "\n", "    ", "for", "amr_sub_dir", "in", "(", "'dev'", ",", "'test'", ",", "'training'", ")", ":", "\n", "        ", "glob_pat", "=", "os", ".", "path", ".", "join", "(", "base_amr_dir", ",", "amr_sub_dir", ",", "'*.txt'", ")", "\n", "out_fn", "=", "'train.txt'", "if", "amr_sub_dir", "==", "'training'", "else", "amr_sub_dir", "+", "'.txt'", "\n", "out_fpath", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "out_fn", ")", "\n", "load_and_resave_amr_files", "(", "glob_pat", ",", "out_fpath", ")", "\n", "print", "(", "'Removing wiki'", ")", "\n", "wiki_remove_file", "(", "out_dir", ",", "out_fn", ",", "out_dir", ",", "out_fn", "+", "'.nowiki'", ")", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.41_Model_Generate_T5wtense.30_Paraphrasing_Example.incoming_edge_count": [[10, 13], ["len", "pgraph.edges"], "function", ["None"], ["def", "incoming_edge_count", "(", "variable", ",", "pgraph", ")", ":", "\n", "    ", "incomings", "=", "[", "t", "for", "t", "in", "pgraph", ".", "edges", "(", ")", "if", "t", ".", "target", "==", "variable", "]", "\n", "return", "len", "(", "incomings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.41_Model_Generate_T5wtense.24_Score_BLEU.read_file": [[10, 20], ["print", "open", "line.strip().lower.strip().lower", "nltk.tokenize.word_tokenize", "sents.append", "line.strip().lower.strip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["def", "read_file", "(", "fname", ")", ":", "\n", "    ", "print", "(", "'Reading '", ",", "fname", ")", "\n", "sents", "=", "[", "]", "\n", "with", "open", "(", "fname", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "if", "line", ":", "\n", "                ", "tokens", "=", "word_tokenize", "(", "line", ")", "\n", "sents", ".", "append", "(", "tokens", ")", "\n", "", "", "", "return", "sents", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.41_Model_Generate_T5wtense.22_Generate.get_sentence": [[12, 17], ["graph.splitlines", "line.startswith", "line[].strip", "len"], "function", ["None"], ["def", "get_sentence", "(", "graph", ")", ":", "\n", "    ", "for", "line", "in", "graph", ".", "splitlines", "(", ")", ":", "\n", "        ", "if", "line", ".", "startswith", "(", "'# ::snt'", ")", ":", "\n", "            ", "return", "line", "[", "len", "(", "'# :snt'", ")", "+", "1", ":", "]", ".", "strip", "(", ")", "\n", "", "", "assert", "False", ",", "'Error, no sentence info in graph string'", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.tests.RunAllUnitTests.getAllPythonFiles": [[14, 21], ["os.walk", "sorted", "fnmatch.fnmatch", "test_fns.append", "fn.startswith", "os.path.join"], "function", ["None"], ["def", "getAllPythonFiles", "(", "base_dir", ")", ":", "\n", "    ", "test_fns", "=", "[", "]", "\n", "for", "root", ",", "subdirs", ",", "files", "in", "os", ".", "walk", "(", "base_dir", ")", ":", "\n", "        ", "for", "fn", "in", "files", ":", "\n", "            ", "if", "fnmatch", "(", "fn", ",", "'*.py'", ")", "and", "not", "fn", ".", "startswith", "(", "'_'", ")", ":", "\n", "                ", "test_fns", ".", "append", "(", "os", ".", "path", ".", "join", "(", "root", ",", "fn", ")", ")", "\n", "", "", "", "return", "sorted", "(", "test_fns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.tests.RunAllUnitTests.getTestClass": [[28, 50], ["prefix.split", "inspect.getmembers", "os.path.splitext", "importlib.util.spec_from_file_location", "importlib.util.module_from_spec", "importlib.util.spec_from_file_location.loader.exec_module"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "getTestClass", "(", "fn", ")", ":", "\n", "# Separate the filename into components to load the module", "\n", "    ", "prefix", "=", "os", ".", "path", ".", "splitext", "(", "fn", ")", "[", "0", "]", "\n", "parts", "=", "prefix", ".", "split", "(", "os", ".", "sep", ")", "\n", "prefix", "=", "'.'", ".", "join", "(", "parts", ")", "\n", "class_name", "=", "parts", "[", "-", "1", "]", "\n", "# Load the actual module", "\n", "try", ":", "\n", "        ", "spec", "=", "spec_from_file_location", "(", "prefix", ",", "fn", ")", "\n", "module", "=", "module_from_spec", "(", "spec", ")", "\n", "spec", ".", "loader", ".", "exec_module", "(", "module", ")", "\n", "", "except", "ModuleNotFoundError", ":", "\n", "        ", "return", "(", "None", ",", "None", ")", "\n", "# Loop through all classes that are part of the module.  Returns a tuple of (name, value)", "\n", "# ie.. the string name of the class and the actual class definition that can be instantiated", "\n", "# This is finding the class by assuming that the name of the class is the same as the name of the file", "\n", "", "my_class_tuple", "=", "(", "None", ",", "None", ")", "\n", "for", "class_tuple", "in", "inspect", ".", "getmembers", "(", "module", ",", "inspect", ".", "isclass", ")", ":", "\n", "# check class name is the same as module name and return that class.", "\n", "        ", "if", "class_tuple", "[", "0", "]", "==", "class_name", ":", "\n", "            ", "my_class_tuple", "=", "class_tuple", "\n", "", "", "return", "my_class_tuple", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseSPRING.ModelParseSPRING.__init__": [[25, 40], ["unittest.TestCase.__init__", "amrlib.setup_spacy_extension", "spacy.load", "print", "amrlib.load_stog_model"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.setup_spacy_extension", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.load_stog_model"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "amrlib", ".", "setup_spacy_extension", "(", ")", "\n", "# Load/cache spacy", "\n", "global", "SPACY_NLP", "\n", "if", "SPACY_NLP", "is", "None", ":", "\n", "            ", "SPACY_NLP", "=", "spacy", ".", "load", "(", "'en_core_web_sm'", ")", "\n", "", "self", ".", "nlp", "=", "SPACY_NLP", "\n", "# Load model in amrlib (amrlib will cache this itself)", "\n", "global", "SPRING_LOADED", "\n", "if", "SPRING_LOADED", "is", "None", ":", "\n", "            ", "print", "(", "'Loading'", ",", "self", ".", "model_dir", ")", "\n", "amrlib", ".", "load_stog_model", "(", "model_dir", "=", "self", ".", "model_dir", ")", "\n", "SPRING_LOADED", "=", "True", "\n", "", "self", ".", "stog", "=", "amrlib", ".", "stog_model", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseSPRING.ModelParseSPRING.testStoG": [[41, 44], ["ModelParseSPRING.ModelParseSPRING.stog.parse_sents", "ModelParseSPRING.ModelParseSPRING.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_sents"], ["", "def", "testStoG", "(", "self", ")", ":", "\n", "        ", "graphs", "=", "self", ".", "stog", ".", "parse_sents", "(", "[", "'This is a test of the system.'", "]", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseSPRING.ModelParseSPRING.testSpaCyDoc": [[45, 49], ["ModelParseSPRING.ModelParseSPRING.nlp", "ModelParseSPRING.ModelParseSPRING._.to_amr", "ModelParseSPRING.ModelParseSPRING.assertEqual", "len"], "methods", ["None"], ["", "def", "testSpaCyDoc", "(", "self", ")", ":", "\n", "        ", "doc", "=", "self", ".", "nlp", "(", "'This is a test of the SpaCy extension.  The test has multiple sentence'", ")", "\n", "graphs", "=", "doc", ".", "_", ".", "to_amr", "(", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseSPRING.ModelParseSPRING.testSpaCySpan": [[50, 55], ["ModelParseSPRING.ModelParseSPRING.nlp", "span._.to_amr", "ModelParseSPRING.ModelParseSPRING.assertEqual", "list", "len"], "methods", ["None"], ["", "def", "testSpaCySpan", "(", "self", ")", ":", "\n", "        ", "doc", "=", "self", ".", "nlp", "(", "'This is a test of the SpaCy extension.  The test has multiple sentence'", ")", "\n", "span", "=", "list", "(", "doc", ".", "sents", ")", "[", "0", "]", "# first sentence only", "\n", "graphs", "=", "span", ".", "_", ".", "to_amr", "(", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelGenerateT5wtense.ModelGenerateT5wtense.__init__": [[70, 72], ["unittest.TestCase.__init__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelGenerateT5wtense.ModelGenerateT5wtense.testModelInputHelper": [[73, 86], ["amrlib.models.generate_t5wtense.model_input_helper.ModelInputHelper", "ModelGenerateT5wtense.ModelGenerateT5wtense.assertTrue", "amrlib.models.generate_t5wtense.model_input_helper.ModelInputHelper", "ModelGenerateT5wtense.ModelGenerateT5wtense.assertFalse", "amrlib.models.generate_t5wtense.model_input_helper.ModelInputHelper", "ModelGenerateT5wtense.ModelGenerateT5wtense.assertTrue", "ModelGenerateT5wtense.ModelGenerateT5wtense.assertEqual", "ModelGenerateT5wtense.ModelGenerateT5wtense.assertEqual", "ModelGenerateT5wtense.ModelGenerateT5wtense.assertTrue", "amrlib.models.generate_t5wtense.model_input_helper.ModelInputHelper.get_tagged_oneline", "amrlib.models.generate_t5wtense.model_input_helper.ModelInputHelper.get_tagged_oneline", "amrlib.models.generate_t5wtense.model_input_helper.ModelInputHelper.get_tagged_oneline", "amrlib.models.generate_t5wtense.model_input_helper.ModelInputHelper.get_tagged_oneline", "ModelGenerateT5wtense.ModelGenerateT5wtense.assertRaises", "amrlib.models.generate_t5wtense.model_input_helper.ModelInputHelper"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.model_input_helper.ModelInputHelper.get_tagged_oneline", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.model_input_helper.ModelInputHelper.get_tagged_oneline", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.model_input_helper.ModelInputHelper.get_tagged_oneline", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.model_input_helper.ModelInputHelper.get_tagged_oneline"], ["", "def", "testModelInputHelper", "(", "self", ")", ":", "\n", "        ", "mih1", "=", "ModelInputHelper", "(", "graph01", ")", "# string doesn't have annotations", "\n", "self", ".", "assertTrue", "(", "mih1", ".", "annotation_performed", ")", "\n", "mih2", "=", "ModelInputHelper", "(", "graph02", ")", "# string has annotations", "\n", "self", ".", "assertFalse", "(", "mih2", ".", "annotation_performed", ")", "\n", "mih3", "=", "ModelInputHelper", "(", "graph02", ",", "force_annotate", "=", "True", ")", "\n", "self", ".", "assertTrue", "(", "mih3", ".", "annotation_performed", ")", "\n", "self", ".", "assertEqual", "(", "mih1", ".", "get_tagged_oneline", "(", ")", ",", "mih2", ".", "get_tagged_oneline", "(", ")", ")", "\n", "self", ".", "assertEqual", "(", "mih1", ".", "get_tagged_oneline", "(", ")", ",", "mih3", ".", "get_tagged_oneline", "(", ")", ")", "\n", "# Check for unable to annotate becuase there's no sentece metadata", "\n", "with", "self", ".", "assertRaises", "(", "KeyError", ")", "as", "context", ":", "\n", "            ", "mih4", "=", "ModelInputHelper", "(", "graph03", ")", "\n", "", "self", ".", "assertTrue", "(", "'snt'", ",", "context", ".", "exception", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelGenerateT5wtense.ModelGenerateT5wtense.testGtoS": [[87, 96], ["os.path.join", "amrlib.load_gtos_model", "amrlib.load_gtos_model.generate", "ModelGenerateT5wtense.ModelGenerateT5wtense.assertEqual", "ModelGenerateT5wtense.ModelGenerateT5wtense.assertTrue", "amrlib.load_gtos_model.generate", "ModelGenerateT5wtense.ModelGenerateT5wtense.assertEqual", "ModelGenerateT5wtense.ModelGenerateT5wtense.assertTrue", "len", "all", "len", "all"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.load_gtos_model", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.inference.Inference.generate", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.inference.Inference.generate"], ["", "def", "testGtoS", "(", "self", ")", ":", "\n", "        ", "model_dir", "=", "os", ".", "path", ".", "join", "(", "amrlib", ".", "defaults", ".", "data_dir", ",", "'model_generate_t5wtense'", ")", "\n", "gtos", "=", "amrlib", ".", "load_gtos_model", "(", "model_dir", "=", "model_dir", ")", "\n", "sents", ",", "clips", "=", "gtos", ".", "generate", "(", "[", "graph01", "]", ",", "disable_progress", "=", "True", ",", "use_tense", "=", "True", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "sents", ")", ",", "1", ")", "\n", "self", ".", "assertTrue", "(", "all", "(", "[", "c", "==", "0", "for", "c", "in", "clips", "]", ")", ")", "\n", "sents", ",", "clips", "=", "gtos", ".", "generate", "(", "[", "graph01", "]", ",", "disable_progress", "=", "True", ",", "use_tense", "=", "False", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "sents", ")", ",", "1", ")", "\n", "self", ".", "assertTrue", "(", "all", "(", "[", "c", "==", "0", "for", "c", "in", "clips", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseT5v1.ModelParseT5v1.__init__": [[25, 40], ["unittest.TestCase.__init__", "amrlib.setup_spacy_extension", "spacy.load", "print", "amrlib.load_stog_model"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.setup_spacy_extension", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.load_stog_model"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "amrlib", ".", "setup_spacy_extension", "(", ")", "\n", "# Load/cache spacy", "\n", "global", "SPACY_NLP", "\n", "if", "SPACY_NLP", "is", "None", ":", "\n", "            ", "SPACY_NLP", "=", "spacy", ".", "load", "(", "'en_core_web_sm'", ")", "\n", "", "self", ".", "nlp", "=", "SPACY_NLP", "\n", "# Load model in amrlib (amrlib will cache this itself)", "\n", "global", "T5V1_LOADED", "\n", "if", "T5V1_LOADED", "is", "None", ":", "\n", "            ", "print", "(", "'Loading'", ",", "self", ".", "model_dir", ")", "#rbf", "\n", "amrlib", ".", "load_stog_model", "(", "model_dir", "=", "self", ".", "model_dir", ")", "\n", "T5V1_LOADED", "=", "True", "\n", "", "self", ".", "stog", "=", "amrlib", ".", "stog_model", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseT5v1.ModelParseT5v1.testStoG": [[41, 44], ["ModelParseT5v1.ModelParseT5v1.stog.parse_sents", "ModelParseT5v1.ModelParseT5v1.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_sents"], ["", "def", "testStoG", "(", "self", ")", ":", "\n", "        ", "graphs", "=", "self", ".", "stog", ".", "parse_sents", "(", "[", "'This is a test of the system.'", "]", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseT5v1.ModelParseT5v1.testSpaCyDoc": [[45, 49], ["ModelParseT5v1.ModelParseT5v1.nlp", "ModelParseT5v1.ModelParseT5v1._.to_amr", "ModelParseT5v1.ModelParseT5v1.assertEqual", "len"], "methods", ["None"], ["", "def", "testSpaCyDoc", "(", "self", ")", ":", "\n", "        ", "doc", "=", "self", ".", "nlp", "(", "'This is a test of the SpaCy extension.  The test has multiple sentence'", ")", "\n", "graphs", "=", "doc", ".", "_", ".", "to_amr", "(", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseT5v1.ModelParseT5v1.testSpaCySpan": [[50, 55], ["ModelParseT5v1.ModelParseT5v1.nlp", "span._.to_amr", "ModelParseT5v1.ModelParseT5v1.assertEqual", "list", "len"], "methods", ["None"], ["", "def", "testSpaCySpan", "(", "self", ")", ":", "\n", "        ", "doc", "=", "self", ".", "nlp", "(", "'This is a test of the SpaCy extension.  The test has multiple sentence'", ")", "\n", "span", "=", "list", "(", "doc", ".", "sents", ")", "[", "0", "]", "# first sentence only", "\n", "graphs", "=", "span", ".", "_", ".", "to_amr", "(", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelGenericTypes.ModelGenericTypes.__init__": [[33, 37], ["unittest.TestCase.__init__", "amrlib.setup_spacy_extension"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.setup_spacy_extension"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "amrlib", ".", "setup_spacy_extension", "(", ")", "\n", "self", ".", "nlp", "=", "SPACY_NLP", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelGenericTypes.ModelGenericTypes.testStoG": [[38, 42], ["amrlib.load_stog_model", "amrlib.load_stog_model.parse_sents", "ModelGenericTypes.ModelGenericTypes.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.load_stog_model", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_sents"], ["", "def", "testStoG", "(", "self", ")", ":", "\n", "        ", "stog", "=", "amrlib", ".", "load_stog_model", "(", ")", "\n", "graphs", "=", "stog", ".", "parse_sents", "(", "[", "'This is a test of the system.'", "]", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelGenericTypes.ModelGenericTypes.testGtoS": [[43, 47], ["amrlib.load_gtos_model", "amrlib.load_gtos_model.generate", "ModelGenericTypes.ModelGenericTypes.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.load_gtos_model", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.inference.Inference.generate"], ["", "def", "testGtoS", "(", "self", ")", ":", "\n", "        ", "gtos", "=", "amrlib", ".", "load_gtos_model", "(", ")", "\n", "sents", ",", "clips", "=", "gtos", ".", "generate", "(", "[", "graph01", "]", ",", "disable_progress", "=", "True", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "sents", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelGenericTypes.ModelGenericTypes.testSpaCyDoc": [[48, 52], ["ModelGenericTypes.ModelGenericTypes.nlp", "ModelGenericTypes.ModelGenericTypes._.to_amr", "ModelGenericTypes.ModelGenericTypes.assertEqual", "len"], "methods", ["None"], ["", "def", "testSpaCyDoc", "(", "self", ")", ":", "\n", "        ", "doc", "=", "self", ".", "nlp", "(", "'This is a test of the SpaCy extension.  The test has multiple sentence'", ")", "\n", "graphs", "=", "doc", ".", "_", ".", "to_amr", "(", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelGenericTypes.ModelGenericTypes.testSpaCySpan": [[53, 58], ["ModelGenericTypes.ModelGenericTypes.nlp", "span._.to_amr", "ModelGenericTypes.ModelGenericTypes.assertEqual", "list", "len"], "methods", ["None"], ["", "def", "testSpaCySpan", "(", "self", ")", ":", "\n", "        ", "doc", "=", "self", ".", "nlp", "(", "'This is a test of the SpaCy extension.  The test has multiple sentence'", ")", "\n", "span", "=", "list", "(", "doc", ".", "sents", ")", "[", "0", "]", "# first sentence only", "\n", "graphs", "=", "span", ".", "_", ".", "to_amr", "(", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseXFMBartLarge.ModelParseT5v2.__init__": [[25, 40], ["unittest.TestCase.__init__", "amrlib.setup_spacy_extension", "spacy.load", "print", "amrlib.load_stog_model"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.setup_spacy_extension", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.load_stog_model"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "amrlib", ".", "setup_spacy_extension", "(", ")", "\n", "# Load/cache spacy", "\n", "global", "SPACY_NLP", "\n", "if", "SPACY_NLP", "is", "None", ":", "\n", "            ", "SPACY_NLP", "=", "spacy", ".", "load", "(", "'en_core_web_sm'", ")", "\n", "", "self", ".", "nlp", "=", "SPACY_NLP", "\n", "# Load model in amrlib (amrlib will cache this itself)", "\n", "global", "T5V2_LOADED", "\n", "if", "T5V2_LOADED", "is", "None", ":", "\n", "            ", "print", "(", "'Loading'", ",", "self", ".", "model_dir", ")", "\n", "amrlib", ".", "load_stog_model", "(", "model_dir", "=", "self", ".", "model_dir", ")", "\n", "T5V2_LOADED", "=", "True", "\n", "", "self", ".", "stog", "=", "amrlib", ".", "stog_model", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseXFMBartLarge.ModelParseT5v2.testStoG": [[41, 47], ["ModelParseXFMBartLarge.ModelParseT5v2.stog.parse_sents", "ModelParseXFMBartLarge.ModelParseT5v2.assertEqual", "ModelParseXFMBartLarge.ModelParseT5v2.stog.parse_sents", "ModelParseXFMBartLarge.ModelParseT5v2.assertNotEqual", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_sents", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_sents"], ["", "def", "testStoG", "(", "self", ")", ":", "\n", "        ", "graphs", "=", "self", ".", "stog", ".", "parse_sents", "(", "[", "'This is a test of the system.'", "]", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "1", ")", "\n", "# Test that \"imperative\" can be recognized as a node, not just an attribute", "\n", "graphs", "=", "self", ".", "stog", ".", "parse_sents", "(", "[", "'Making certain distinctions is imperative in looking back on the past'", "]", ")", "\n", "self", ".", "assertNotEqual", "(", "graphs", "[", "0", "]", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseXFMBartLarge.ModelParseT5v2.testSpaCyDoc": [[48, 52], ["ModelParseXFMBartLarge.ModelParseT5v2.nlp", "ModelParseXFMBartLarge.ModelParseT5v2._.to_amr", "ModelParseXFMBartLarge.ModelParseT5v2.assertEqual", "len"], "methods", ["None"], ["", "def", "testSpaCyDoc", "(", "self", ")", ":", "\n", "        ", "doc", "=", "self", ".", "nlp", "(", "'This is a test of the SpaCy extension.  The test has multiple sentence'", ")", "\n", "graphs", "=", "doc", ".", "_", ".", "to_amr", "(", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseXFMBartLarge.ModelParseT5v2.testSpaCySpan": [[53, 58], ["ModelParseXFMBartLarge.ModelParseT5v2.nlp", "span._.to_amr", "ModelParseXFMBartLarge.ModelParseT5v2.assertEqual", "list", "len"], "methods", ["None"], ["", "def", "testSpaCySpan", "(", "self", ")", ":", "\n", "        ", "doc", "=", "self", ".", "nlp", "(", "'This is a test of the SpaCy extension.  The test has multiple sentence'", ")", "\n", "span", "=", "list", "(", "doc", ".", "sents", ")", "[", "0", "]", "# first sentence only", "\n", "graphs", "=", "span", ".", "_", ".", "to_amr", "(", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.AlignerFAA.AlignerFAA.__init__": [[73, 75], ["unittest.TestCase.__init__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.AlignerFAA.AlignerFAA.testModelInputHelper": [[76, 83], ["AlignerFAA.get_test_graphs", "amrlib.alignments.faa_aligner.FAA_Aligner", "amrlib.alignments.faa_aligner.FAA_Aligner.align_sents", "AlignerFAA.AlignerFAA.assertEqual", "AlignerFAA.AlignerFAA.assertEqual", "AlignerFAA.AlignerFAA.assertEqual", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.auto.AlignerFAA.get_test_graphs", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.faa_aligner.FAA_Aligner.align_sents"], ["", "def", "testModelInputHelper", "(", "self", ")", ":", "\n", "        ", "sents", ",", "gstrings", "=", "get_test_graphs", "(", ")", "\n", "aligner", "=", "FAA_Aligner", "(", ")", "\n", "amr_surface_aligns", ",", "alignment_strings", "=", "aligner", ".", "align_sents", "(", "sents", ",", "gstrings", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "amr_surface_aligns", ")", ",", "len", "(", "alignment_strings", ")", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "sents", ")", ",", "len", "(", "alignment_strings", ")", ")", "\n", "self", ".", "assertEqual", "(", "alignment_strings", "[", "0", "]", ",", "alignment_strings", "[", "6", "]", ")", "# duplicate alignments", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.AlignerFAA.get_test_graphs": [[59, 70], ["test_graphs.split", "gstring.splitlines", "sents.append", "gstrings.append", "line.startswith", "nltk.tokenize.word_tokenize", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["def", "get_test_graphs", "(", ")", ":", "\n", "    ", "global", "graphs", "\n", "sents", ",", "gstrings", "=", "[", "]", ",", "[", "]", "\n", "for", "gstring", "in", "test_graphs", ".", "split", "(", "'\\n\\n'", ")", ":", "\n", "        ", "for", "line", "in", "gstring", ".", "splitlines", "(", ")", ":", "\n", "            ", "if", "line", ".", "startswith", "(", "'# ::snt'", ")", ":", "\n", "                ", "sent", "=", "line", "[", "len", "(", "'# ::snt'", ")", "+", "1", ":", "]", "\n", "sent", "=", "' '", ".", "join", "(", "word_tokenize", "(", "sent", ")", ")", "\n", "", "", "sents", ".", "append", "(", "sent", ")", "\n", "gstrings", ".", "append", "(", "gstring", ")", "\n", "", "return", "sents", ",", "gstrings", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseT5v2.ModelParseT5v2.__init__": [[25, 40], ["unittest.TestCase.__init__", "amrlib.setup_spacy_extension", "spacy.load", "print", "amrlib.load_stog_model"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.setup_spacy_extension", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.load_stog_model"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "amrlib", ".", "setup_spacy_extension", "(", ")", "\n", "# Load/cache spacy", "\n", "global", "SPACY_NLP", "\n", "if", "SPACY_NLP", "is", "None", ":", "\n", "            ", "SPACY_NLP", "=", "spacy", ".", "load", "(", "'en_core_web_sm'", ")", "\n", "", "self", ".", "nlp", "=", "SPACY_NLP", "\n", "# Load model in amrlib (amrlib will cache this itself)", "\n", "global", "T5V2_LOADED", "\n", "if", "T5V2_LOADED", "is", "None", ":", "\n", "            ", "print", "(", "'Loading'", ",", "self", ".", "model_dir", ")", "\n", "amrlib", ".", "load_stog_model", "(", "model_dir", "=", "self", ".", "model_dir", ")", "\n", "T5V2_LOADED", "=", "True", "\n", "", "self", ".", "stog", "=", "amrlib", ".", "stog_model", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseT5v2.ModelParseT5v2.testStoG": [[41, 47], ["ModelParseT5v2.ModelParseT5v2.stog.parse_sents", "ModelParseT5v2.ModelParseT5v2.assertEqual", "ModelParseT5v2.ModelParseT5v2.stog.parse_sents", "ModelParseT5v2.ModelParseT5v2.assertNotEqual", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_sents", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_sents"], ["", "def", "testStoG", "(", "self", ")", ":", "\n", "        ", "graphs", "=", "self", ".", "stog", ".", "parse_sents", "(", "[", "'This is a test of the system.'", "]", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "1", ")", "\n", "# Test that \"imperative\" can be recognized as a node, not just an attribute", "\n", "graphs", "=", "self", ".", "stog", ".", "parse_sents", "(", "[", "'Making certain distinctions is imperative in looking back on the past'", "]", ")", "\n", "self", ".", "assertNotEqual", "(", "graphs", "[", "0", "]", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseT5v2.ModelParseT5v2.testSpaCyDoc": [[48, 52], ["ModelParseT5v2.ModelParseT5v2.nlp", "ModelParseT5v2.ModelParseT5v2._.to_amr", "ModelParseT5v2.ModelParseT5v2.assertEqual", "len"], "methods", ["None"], ["", "def", "testSpaCyDoc", "(", "self", ")", ":", "\n", "        ", "doc", "=", "self", ".", "nlp", "(", "'This is a test of the SpaCy extension.  The test has multiple sentence'", ")", "\n", "graphs", "=", "doc", ".", "_", ".", "to_amr", "(", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseT5v2.ModelParseT5v2.testSpaCySpan": [[53, 58], ["ModelParseT5v2.ModelParseT5v2.nlp", "span._.to_amr", "ModelParseT5v2.ModelParseT5v2.assertEqual", "list", "len"], "methods", ["None"], ["", "def", "testSpaCySpan", "(", "self", ")", ":", "\n", "        ", "doc", "=", "self", ".", "nlp", "(", "'This is a test of the SpaCy extension.  The test has multiple sentence'", ")", "\n", "span", "=", "list", "(", "doc", ".", "sents", ")", "[", "0", "]", "# first sentence only", "\n", "graphs", "=", "span", ".", "_", ".", "to_amr", "(", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseXFMBartBase.ModelParseT5v2.__init__": [[25, 40], ["unittest.TestCase.__init__", "amrlib.setup_spacy_extension", "spacy.load", "print", "amrlib.load_stog_model"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.setup_spacy_extension", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.amrlib.__init__.load_stog_model"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "amrlib", ".", "setup_spacy_extension", "(", ")", "\n", "# Load/cache spacy", "\n", "global", "SPACY_NLP", "\n", "if", "SPACY_NLP", "is", "None", ":", "\n", "            ", "SPACY_NLP", "=", "spacy", ".", "load", "(", "'en_core_web_sm'", ")", "\n", "", "self", ".", "nlp", "=", "SPACY_NLP", "\n", "# Load model in amrlib (amrlib will cache this itself)", "\n", "global", "T5V2_LOADED", "\n", "if", "T5V2_LOADED", "is", "None", ":", "\n", "            ", "print", "(", "'Loading'", ",", "self", ".", "model_dir", ")", "\n", "amrlib", ".", "load_stog_model", "(", "model_dir", "=", "self", ".", "model_dir", ")", "\n", "T5V2_LOADED", "=", "True", "\n", "", "self", ".", "stog", "=", "amrlib", ".", "stog_model", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseXFMBartBase.ModelParseT5v2.testStoG": [[41, 47], ["ModelParseXFMBartBase.ModelParseT5v2.stog.parse_sents", "ModelParseXFMBartBase.ModelParseT5v2.assertEqual", "ModelParseXFMBartBase.ModelParseT5v2.stog.parse_sents", "ModelParseXFMBartBase.ModelParseT5v2.assertNotEqual", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_sents", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_sents"], ["", "def", "testStoG", "(", "self", ")", ":", "\n", "        ", "graphs", "=", "self", ".", "stog", ".", "parse_sents", "(", "[", "'This is a test of the system.'", "]", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "1", ")", "\n", "# Test that \"imperative\" can be recognized as a node, not just an attribute", "\n", "graphs", "=", "self", ".", "stog", ".", "parse_sents", "(", "[", "'Making certain distinctions is imperative in looking back on the past'", "]", ")", "\n", "self", ".", "assertNotEqual", "(", "graphs", "[", "0", "]", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseXFMBartBase.ModelParseT5v2.testSpaCyDoc": [[48, 52], ["ModelParseXFMBartBase.ModelParseT5v2.nlp", "ModelParseXFMBartBase.ModelParseT5v2._.to_amr", "ModelParseXFMBartBase.ModelParseT5v2.assertEqual", "len"], "methods", ["None"], ["", "def", "testSpaCyDoc", "(", "self", ")", ":", "\n", "        ", "doc", "=", "self", ".", "nlp", "(", "'This is a test of the SpaCy extension.  The test has multiple sentence'", ")", "\n", "graphs", "=", "doc", ".", "_", ".", "to_amr", "(", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.auto.ModelParseXFMBartBase.ModelParseT5v2.testSpaCySpan": [[53, 58], ["ModelParseXFMBartBase.ModelParseT5v2.nlp", "span._.to_amr", "ModelParseXFMBartBase.ModelParseT5v2.assertEqual", "list", "len"], "methods", ["None"], ["", "def", "testSpaCySpan", "(", "self", ")", ":", "\n", "        ", "doc", "=", "self", ".", "nlp", "(", "'This is a test of the SpaCy extension.  The test has multiple sentence'", ")", "\n", "span", "=", "list", "(", "doc", ".", "sents", ")", "[", "0", "]", "# first sentence only", "\n", "graphs", "=", "span", ".", "_", ".", "to_amr", "(", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "graphs", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.utils.md5sum.md5sum": [[13, 22], ["hashlib.md5", "hashlib.md5.hexdigest", "open", "f.read", "hashlib.md5.update"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update"], ["def", "md5sum", "(", "fn", ",", "chunksize", "=", "2", "**", "20", ",", "first_chunk_only", "=", "False", ")", ":", "\n", "    ", "file_hash", "=", "hashlib", ".", "md5", "(", ")", "\n", "with", "open", "(", "fn", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "chunk", "=", "f", ".", "read", "(", "chunksize", ")", "\n", "if", "not", "chunk", ":", "break", "\n", "file_hash", ".", "update", "(", "chunk", ")", "\n", "if", "first_chunk_only", ":", "break", "\n", "", "", "return", "file_hash", ".", "hexdigest", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.__init__": [[7, 10], ["config.Config.__dict__.update"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update"], ["    ", "def", "__init__", "(", "self", ",", "adict", "=", "None", ")", ":", "\n", "        ", "if", "adict", ":", "\n", "            ", "self", ".", "__dict__", ".", "update", "(", "adict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.__str__": [[11, 14], ["vars", "json.dumps"], "methods", ["None"], ["", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "config_dict", "=", "vars", "(", "self", ")", "\n", "return", "json", ".", "dumps", "(", "config_dict", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load": [[15, 23], ["cls", "json.load.items", "open", "json.load", "setattr"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["", "@", "classmethod", "\n", "def", "load", "(", "cls", ",", "fname", ")", ":", "\n", "        ", "self", "=", "cls", "(", ")", "\n", "with", "open", "(", "fname", ")", "as", "f", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "for", "k", ",", "v", "in", "data", ".", "items", "(", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "k", ",", "v", ")", "\n", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.save": [[24, 28], ["vars", "open", "json.dump"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "fname", ")", ":", "\n", "        ", "config_dict", "=", "vars", "(", "self", ")", "\n", "with", "open", "(", "fname", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "config_dict", ",", "f", ",", "indent", "=", "4", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.utils.logging.setup_logging": [[7, 22], ["logging.root.removeHandler", "os.makedirs", "logging.basicConfig", "logging.basicConfig", "os.path.dirname"], "function", ["None"], ["def", "setup_logging", "(", "logfname", "=", "None", ",", "level", "=", "None", ")", ":", "\n", "# Remove any existing handler (ie.. penman has logging.basicConfig() in __init__.py)", "\n", "# Note that in python 3.6 there is no \"force\" in basicConfig()", "\n", "# From https://stackoverflow.com/questions/12158048/changing-loggings-basicconfig-which-is-already-set", "\n", "    ", "for", "handler", "in", "logging", ".", "root", ".", "handlers", "[", ":", "]", ":", "\n", "        ", "logging", ".", "root", ".", "removeHandler", "(", "handler", ")", "\n", "# Setup the logger", "\n", "", "if", "level", "is", "None", ":", "\n", "        ", "level", "=", "logging", ".", "INFO", "\n", "", "format", "=", "'[%(levelname)s %(filename)s ln=%(lineno)s] %(message)s'", "\n", "if", "logfname", "is", "not", "None", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "logfname", ")", ",", "exist_ok", "=", "True", ")", "\n", "logging", ".", "basicConfig", "(", "level", "=", "level", ",", "filename", "=", "logfname", ",", "filemode", "=", "'w'", ",", "format", "=", "format", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "level", ",", "format", "=", "format", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.utils.logging.silence_penman": [[25, 30], ["logging.getLogger().setLevel", "logging.getLogger().setLevel", "logging.getLogger", "logging.getLogger"], "function", ["None"], ["", "", "def", "silence_penman", "(", ")", ":", "\n", "    ", "logging", ".", "getLogger", "(", "'penman'", ")", ".", "setLevel", "(", "logging", ".", "ERROR", ")", "\n", "#logging.getLogger('penman.layout').setLevel(logging.ERROR)", "\n", "#logging.getLogger('penman._lexer').setLevel(logging.ERROR)", "\n", "logging", ".", "getLogger", "(", "'pe'", ")", ".", "setLevel", "(", "logging", ".", "ERROR", ")", "# pre v1.1, penman._parse.py", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.utils.logging.silence_requests": [[33, 35], ["logging.getLogger().setLevel", "logging.getLogger"], "function", ["None"], ["", "def", "silence_requests", "(", ")", ":", "\n", "    ", "logging", ".", "getLogger", "(", "'urllib3.connectionpool'", ")", ".", "setLevel", "(", "logging", ".", "ERROR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.utils.logging.setup_smatch_log": [[38, 48], ["os.makedirs", "open", "atexit.register", "os.path.dirname"], "function", ["None"], ["", "def", "setup_smatch_log", "(", "fpath", ")", ":", "\n", "    ", "import", "amr", "\n", "import", "smatch", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "fpath", ")", ",", "exist_ok", "=", "True", ")", "\n", "smatch_log_f", "=", "open", "(", "fpath", ",", "'w'", ",", "buffering", "=", "1", ")", "# line buffering", "\n", "atexit", ".", "register", "(", "smatch_log_f", ".", "close", ")", "\n", "amr", ".", "ERROR_LOG", "=", "smatch_log_f", "\n", "amr", ".", "DEBUG_LOG", "=", "smatch_log_f", "\n", "smatch", ".", "ERROR_LOG", "=", "smatch_log_f", "\n", "smatch", ".", "DEBUG_LOG", "=", "smatch_log_f", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.utils.downloader.download_model": [[13, 33], ["os.path.join", "os.makedirs", "downloader.download_file", "print", "tarfile.open", "tarfile.open.extractall", "tarfile.open.close", "print", "os.path.basename", "os.remove", "os.path.isdir", "logger.error", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.downloader.download_file", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["def", "download_model", "(", "url", ",", "data_dir", ",", "rm_tar", "=", "True", ")", ":", "\n", "# Setup the download filename and data directory", "\n", "    ", "fn", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "os", ".", "path", ".", "basename", "(", "url", ")", ")", "\n", "os", ".", "makedirs", "(", "data_dir", ",", "exist_ok", "=", "True", ")", "\n", "# Download the file and extract it", "\n", "download_file", "(", "url", ",", "fn", ")", "\n", "# Extrac the tarfile", "\n", "print", "(", "'Extracting '", ",", "fn", ")", "\n", "tf", "=", "tarfile", ".", "open", "(", "fn", ")", "\n", "tf", ".", "extractall", "(", "data_dir", ")", "\n", "tf", ".", "close", "(", ")", "\n", "# Remove the tar file if requested", "\n", "if", "rm_tar", ":", "\n", "        ", "os", ".", "remove", "(", "fn", ")", "\n", "", "print", "(", "'Extraction complete'", ")", "\n", "model_dir", "=", "fn", "[", ":", "-", "len", "(", "'.tar.gz'", ")", "]", "# should be the name of created directory", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "model_dir", ")", ":", "\n", "        ", "logger", ".", "error", "(", "'Extraction error, missing model_dir %s'", "%", "model_dir", ")", "\n", "return", "None", "\n", "", "return", "model_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.utils.downloader.set_symlink": [[36, 41], ["os.path.lexists", "os.symlink", "print", "os.remove"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "set_symlink", "(", "src", ",", "dst", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "lexists", "(", "dst", ")", ":", "# remove old link it it exists", "\n", "        ", "os", ".", "remove", "(", "dst", ")", "\n", "", "os", ".", "symlink", "(", "src", ",", "dst", ",", "target_is_directory", "=", "True", ")", "\n", "print", "(", "'Symlink set from %s to %s'", "%", "(", "dst", ",", "src", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.utils.downloader.download_file": [[44, 56], ["requests.get", "open", "int", "requests.get.headers.get", "tqdm.tqdm", "requests.get.iter_content", "f.write", "f.flush", "pbar.update", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update"], ["", "def", "download_file", "(", "url", ",", "path", ")", ":", "\n", "    ", "r", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "with", "open", "(", "path", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "file_size", "=", "int", "(", "r", ".", "headers", ".", "get", "(", "'content-length'", ")", ")", "\n", "default_chunk_size", "=", "131072", "\n", "desc", "=", "'Downloading '", "+", "url", "\n", "with", "tqdm", "(", "total", "=", "file_size", ",", "unit", "=", "'B'", ",", "unit_scale", "=", "True", ",", "desc", "=", "desc", ")", "as", "pbar", ":", "\n", "            ", "for", "chunk", "in", "r", ".", "iter_content", "(", "chunk_size", "=", "default_chunk_size", ")", ":", "\n", "                ", "if", "chunk", ":", "\n", "                    ", "f", ".", "write", "(", "chunk", ")", "\n", "f", ".", "flush", "(", ")", "\n", "pbar", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.__init__": [[13, 20], ["os.path.join", "open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "fname", "=", "None", ",", "path", "=", "None", ",", "mode", "=", "'w'", ",", "to_logging", "=", "False", ")", ":", "\n", "        ", "self", ".", "logfh", "=", "None", "\n", "self", ".", "to_logging", "=", "to_logging", "\n", "if", "path", "is", "not", "None", "and", "fname", "is", "not", "None", ":", "\n", "            ", "fname", "=", "os", ".", "path", ".", "join", "(", "path", ",", "fname", ")", "\n", "", "if", "fname", ":", "\n", "            ", "self", ".", "logfh", "=", "open", "(", "fname", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print": [[21, 28], ["sys.stdout.write", "log_splitter.LogSplitter.logfh.write", "log_splitter.LogSplitter.logfh.flush", "logger.info"], "methods", ["None"], ["", "", "def", "print", "(", "self", ",", "string", "=", "''", ",", "end", "=", "'\\n'", ")", ":", "\n", "        ", "sys", ".", "stdout", ".", "write", "(", "string", "+", "end", ")", "\n", "if", "self", ".", "logfh", ":", "\n", "            ", "self", ".", "logfh", ".", "write", "(", "string", "+", "end", ")", "\n", "self", ".", "logfh", ".", "flush", "(", ")", "\n", "", "if", "self", ".", "to_logging", ":", "\n", "            ", "logger", ".", "info", "(", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close": [[29, 31], ["log_splitter.LogSplitter.logfh.close"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "logfh", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_remover.wiki_remove_file": [[12, 22], ["os.path.join", "amr_loading.load_amr_entries", "tqdm.tqdm", "os.path.join", "print", "penman.dump", "wiki_remover._process_entry", "graphs.append"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading.load_amr_entries", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator._process_entry"], ["def", "wiki_remove_file", "(", "indir", ",", "infn", ",", "outdir", ",", "outfn", ")", ":", "\n", "    ", "graphs", "=", "[", "]", "\n", "inpath", "=", "os", ".", "path", ".", "join", "(", "indir", ",", "infn", ")", "\n", "entries", "=", "load_amr_entries", "(", "inpath", ")", "\n", "for", "entry", "in", "tqdm", "(", "entries", ",", "ncols", "=", "100", ")", ":", "\n", "        ", "graph", "=", "_process_entry", "(", "entry", ")", "\n", "graphs", ".", "append", "(", "graph", ")", "\n", "", "outpath", "=", "os", ".", "path", ".", "join", "(", "outdir", ",", "outfn", ")", "\n", "print", "(", "'Saving file to '", ",", "outpath", ")", "\n", "penman", ".", "dump", "(", "graphs", ",", "outpath", ",", "indent", "=", "6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_remover.wiki_remove_graph": [[25, 27], ["wiki_remover._process_entry"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator._process_entry"], ["", "def", "wiki_remove_graph", "(", "entry", ")", ":", "\n", "    ", "return", "_process_entry", "(", "entry", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_remover._process_entry": [[30, 41], ["penman.decode", "penman.decode.attributes", "penman.decode.triples.remove", "logger.error"], "function", ["None"], ["", "def", "_process_entry", "(", "entry", ")", ":", "\n", "    ", "pen", "=", "penman", ".", "decode", "(", "entry", ")", "\n", "# Remove :wiki from the graphs since we want to ignore these", "\n", "triples", "=", "[", "t", "for", "t", "in", "pen", ".", "attributes", "(", ")", "if", "t", ".", "role", "==", "':wiki'", "]", "\n", "for", "t", "in", "triples", ":", "\n", "        ", "try", ":", "\n", "            ", "pen", ".", "triples", ".", "remove", "(", "t", ")", "\n", "del", "pen", ".", "epidata", "[", "t", "]", "\n", "", "except", ":", "\n", "            ", "logger", ".", "error", "(", "'Unable to remove triple: %s'", "%", "(", "t", ")", ")", "\n", "", "", "return", "pen", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.__init__": [[11, 17], ["graphviz.Digraph", "amr_plot.AMRPlot.graph.attr", "os.path.join", "tempfile.gettempdir"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "render_fn", "=", "None", ",", "format", "=", "'pdf'", ")", ":", "\n", "        ", "if", "render_fn", "is", "None", ":", "\n", "            ", "render_fn", "=", "os", ".", "path", ".", "join", "(", "tempfile", ".", "gettempdir", "(", ")", ",", "'amr_graph.gv'", ")", "\n", "", "self", ".", "graph", "=", "Digraph", "(", "'amr_graph'", ",", "filename", "=", "render_fn", ",", "format", "=", "format", ")", "\n", "self", ".", "graph", ".", "attr", "(", "rankdir", "=", "'LR'", ",", "size", "=", "'12,8'", ")", "# rankdir=left-to-right, size=width,height in inches", "\n", "self", ".", "counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.build_from_graph": [[22, 41], ["penman.decode.instances", "penman.decode.edges", "penman.decode.attributes", "penman.decode", "penman.models.noop.NoOpModel", "penman.decode", "amr_plot.AMRPlot._add_instance", "amr_plot.AMRPlot._add_edge", "amr_plot.AMRPlot._add_attribute", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot._add_instance", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph.AMRGraph._add_edge", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot._add_attribute", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "build_from_graph", "(", "self", ",", "entry", ",", "debug", "=", "False", ",", "allow_deinvert", "=", "False", ")", ":", "\n", "# Parse the AMR text", "\n", "        ", "if", "allow_deinvert", ":", "\n", "            ", "penman_graph", "=", "penman", ".", "decode", "(", "entry", ")", "\n", "", "else", ":", "\n", "            ", "model", "=", "NoOpModel", "(", ")", "# does not de-invert edges", "\n", "penman_graph", "=", "penman", ".", "decode", "(", "entry", ",", "model", "=", "model", ")", "\n", "# Build g.instances() => concept relations  (these are nodes)", "\n", "", "for", "t", "in", "penman_graph", ".", "instances", "(", ")", ":", "\n", "            ", "self", ".", "_add_instance", "(", "t", ")", "\n", "if", "debug", ":", "print", "(", "t", ")", "\n", "# Build g.edges() => relations between nodes", "\n", "", "for", "t", "in", "penman_graph", ".", "edges", "(", ")", ":", "\n", "            ", "self", ".", "_add_edge", "(", "t", ")", "\n", "if", "debug", ":", "print", "(", "t", ")", "\n", "# Build g.attributes  => relations between nodes and a constant", "\n", "", "for", "t", "in", "penman_graph", ".", "attributes", "(", ")", ":", "\n", "            ", "self", ".", "_add_attribute", "(", "t", ")", "\n", "if", "debug", ":", "print", "(", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.render": [[43, 46], ["amr_plot.AMRPlot.graph.render"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.render"], ["", "", "def", "render", "(", "self", ")", ":", "\n", "        ", "png_fname", "=", "self", ".", "graph", ".", "render", "(", ")", "\n", "return", "png_fname", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view": [[48, 50], ["amr_plot.AMRPlot.graph.view"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view"], ["", "def", "view", "(", "self", ")", ":", "\n", "        ", "self", ".", "graph", ".", "view", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot._add_instance": [[52, 56], ["amr_plot.AMRPlot.graph.node", "str", "str"], "methods", ["None"], ["", "def", "_add_instance", "(", "self", ",", "t", ")", ":", "\n", "# graph.node(name, label=None, _attributes=None, **attrs)", "\n", "        ", "label", "=", "str", "(", "t", ".", "source", ")", "+", "'/'", "+", "str", "(", "t", ".", "target", ")", "\n", "self", ".", "graph", ".", "node", "(", "t", ".", "source", ",", "label", "=", "label", ",", "shape", "=", "'circle'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot._add_edge": [[58, 61], ["amr_plot.AMRPlot.graph.edge"], "methods", ["None"], ["", "def", "_add_edge", "(", "self", ",", "t", ")", ":", "\n", "# gaph.edge(tail_name, head_name, label=None, _attributes=None, **attrs)", "\n", "        ", "self", ".", "graph", ".", "edge", "(", "t", ".", "source", ",", "t", ".", "target", ",", "label", "=", "t", ".", "role", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot._add_attribute": [[63, 67], ["amr_plot.AMRPlot.get_uid", "amr_plot.AMRPlot.graph.node", "amr_plot.AMRPlot.graph.edge"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.get_uid"], ["", "def", "_add_attribute", "(", "self", ",", "t", ")", ":", "\n", "        ", "node_id", "=", "self", ".", "get_uid", "(", ")", "\n", "self", ".", "graph", ".", "node", "(", "node_id", ",", "label", "=", "t", ".", "target", ",", "shape", "=", "'rectangle'", ")", "\n", "self", ".", "graph", ".", "edge", "(", "t", ".", "source", ",", "node_id", ",", "label", "=", "t", ".", "role", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.get_uid": [[69, 73], ["None"], "methods", ["None"], ["", "def", "get_uid", "(", "self", ")", ":", "\n", "        ", "uid", "=", "'node_%d'", "%", "self", ".", "counter", "\n", "self", ".", "counter", "+=", "1", "\n", "return", "uid", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_spotlight.WikiAdderSpotlight.__init__": [[31, 44], ["len", "wiki_adder_spotlight.WikiAdderSpotlight.manually_update_cache", "wiki_adder_spotlight.WikiAdderSpotlight.load_cache"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_spotlight.WikiAdderSpotlight.manually_update_cache", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_spotlight.WikiAdderSpotlight.load_cache"], ["    ", "def", "__init__", "(", "self", ",", "url", "=", "None", ",", "cache_fn", "=", "None", ")", ":", "\n", "        ", "self", ".", "confidence", "=", "0.5", "# Spotlight query confidence requirement", "\n", "self", ".", "url", "=", "url", "\n", "self", ".", "cache", "=", "self", ".", "load_cache", "(", "cache_fn", ")", "if", "cache_fn", "is", "not", "None", "else", "{", "}", "\n", "# For debug stats", "\n", "self", ".", "cache_init_sz", "=", "len", "(", "self", ".", "cache", ")", "\n", "self", ".", "wiki_lookups", "=", "0", "\n", "self", ".", "cache_hits", "=", "0", "\n", "self", ".", "server_queries", "=", "0", "\n", "self", ".", "server_errors", "=", "0", "\n", "self", ".", "wiki_found", "=", "0", "\n", "# Add some manual entries to the cache", "\n", "self", ".", "manually_update_cache", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_spotlight.WikiAdderSpotlight.get_stat_string": [[46, 56], ["None"], "methods", ["None"], ["", "def", "get_stat_string", "(", "self", ")", ":", "\n", "        ", "string", "=", "'Attempted {:,} wiki lookups\\n'", ".", "format", "(", "self", ".", "wiki_lookups", ")", "\n", "string", "+=", "'Initial cache size is {:,} entries\\n'", ".", "format", "(", "self", ".", "cache_init_sz", ")", "\n", "string", "+=", "'There were {:,} cache hits and {:,} server queries\\n'", ".", "format", "(", "self", ".", "cache_hits", ",", "self", ".", "server_queries", ")", "\n", "string", "+=", "'For a total of {:,} non-null (ie.. :wiki -) graph updates\\n'", ".", "format", "(", "self", ".", "wiki_found", ")", "\n", "if", "self", ".", "server_errors", ">", "0", ":", "\n", "            ", "string", "+=", "'!! There were {:,} server query errors !!\\n'", ".", "format", "(", "self", ".", "server_errors", ")", "\n", "", "return", "string", "[", ":", "-", "1", "]", "# string final line-feed", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_spotlight.WikiAdderSpotlight.wikify_file": [[58, 64], ["tqdm.tqdm.tqdm", "penman.dump", "penman.load", "wiki_adder_spotlight.WikiAdderSpotlight.wikify_graph", "new_graphs.append"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_spotlight.WikiAdderSpotlight.wikify_graph"], ["", "def", "wikify_file", "(", "self", ",", "infn", ",", "outfn", ")", ":", "\n", "        ", "new_graphs", "=", "[", "]", "\n", "for", "graph", "in", "tqdm", "(", "penman", ".", "load", "(", "infn", ")", ")", ":", "\n", "            ", "new_graph", "=", "self", ".", "wikify_graph", "(", "graph", ")", "\n", "new_graphs", ".", "append", "(", "new_graph", ")", "\n", "", "penman", ".", "dump", "(", "new_graphs", ",", "outfn", ",", "indent", "=", "6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_spotlight.WikiAdderSpotlight.wikify_graph": [[66, 104], ["graph.metadata.get", "logger.warning", "wiki_adder_spotlight.WikiAdderSpotlight.get_spotlight_wiki_data", "graph.triples.index", "graph.triples.insert", "graph.attributes", "graph.edges", "a.replace", "logger.warning", "logger.debug", "len", "logger.error", "graph.attributes", "str"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_spotlight.WikiAdderSpotlight.get_spotlight_wiki_data"], ["", "def", "wikify_graph", "(", "self", ",", "graph", ")", ":", "\n", "        ", "gid", "=", "graph", ".", "metadata", ".", "get", "(", "'id'", ",", "''", ")", "\n", "# Check for name attributes.  These shouldn't be present but might.", "\n", "for", "name_attrib", "in", "[", "t", "for", "t", "in", "graph", ".", "attributes", "(", ")", "if", "t", ".", "role", "==", "':name'", "]", ":", "\n", "            ", "logger", ".", "warning", "(", "'%s has :name attrib in graph %s'", "%", "(", "gid", ",", "name_attrib", ")", ")", "\n", "# Find all the name edges and loop through them", "\n", "", "name_edges", "=", "[", "t", "for", "t", "in", "graph", ".", "edges", "(", ")", "if", "t", ".", "role", "==", "':name'", "]", "\n", "for", "name_edge", "in", "name_edges", ":", "\n", "# Get the associated name string and the parent node to add :wiki to", "\n", "            ", "name_attribs", "=", "[", "t", ".", "target", "for", "t", "in", "graph", ".", "attributes", "(", ")", "if", "t", ".", "source", "==", "name_edge", ".", "target", "]", "\n", "name_attribs", "=", "[", "a", ".", "replace", "(", "'\"'", ",", "''", ")", "for", "a", "in", "name_attribs", "]", "\n", "name_string", "=", "' '", ".", "join", "(", "name_attribs", ")", "\n", "# This typically does not occur (only 1 instance in LDC2015E86),", "\n", "# however generated graphs may have more", "\n", "if", "not", "name_string", ":", "\n", "                ", "logger", ".", "warning", "(", "'%s No name assosiated with the edge %s'", "%", "(", "gid", ",", "str", "(", "name_edge", ")", ")", ")", "\n", "continue", "\n", "# Lookup the phrase in the spotlight data. .", "\n", "", "wiki_val", "=", "self", ".", "get_spotlight_wiki_data", "(", "name_string", ")", "\n", "if", "wiki_val", "is", "not", "None", ":", "\n", "                ", "wiki_val", "=", "'\"'", "+", "wiki_val", "+", "'\"'", "# string attributes are quoted", "\n", "self", ".", "wiki_found", "+=", "1", "\n", "", "else", ":", "\n", "                ", "logger", ".", "debug", "(", "'No wiki data for %s'", "%", "name_string", ")", "\n", "wiki_val", "=", "'-'", "#  Per AMR spec, a dash is used for no reference", "\n", "# Find the index of the parent in the graph.triples", "\n", "# The index technically doesn't matter but it may impact the print order", "\n", "", "parent_var", "=", "name_edge", ".", "source", "\n", "parent_triples", "=", "[", "t", "for", "t", "in", "graph", ".", "triples", "if", "t", "[", "1", "]", "==", "':instance'", "and", "t", "[", "0", "]", "==", "parent_var", "]", "\n", "if", "len", "(", "parent_triples", ")", "!=", "1", ":", "\n", "                ", "logger", ".", "error", "(", "'%s Graph lookup error for %s returned %s'", "%", "(", "gid", ",", "parent_var", ",", "parent_triples", ")", ")", "\n", "continue", "\n", "", "index", "=", "graph", ".", "triples", ".", "index", "(", "parent_triples", "[", "0", "]", ")", "\n", "# Now add this to the graph just after the parent and add an empty epidata entry", "\n", "triple", "=", "(", "parent_var", ",", "':wiki'", ",", "wiki_val", ")", "\n", "graph", ".", "triples", ".", "insert", "(", "index", ",", "triple", ")", "\n", "graph", ".", "epidata", "[", "triple", "]", "=", "[", "]", "\n", "", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_spotlight.WikiAdderSpotlight.get_spotlight_wiki_data": [[109, 135], ["wiki_adder_spotlight.WikiAdderSpotlight.query_spotlight_wiki_server", "sorted", "p[].lower", "phrase.lower"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_spotlight.WikiAdderSpotlight.query_spotlight_wiki_server"], ["", "def", "get_spotlight_wiki_data", "(", "self", ",", "phrase", ")", ":", "\n", "        ", "self", ".", "wiki_lookups", "+=", "1", "\n", "if", "phrase", "in", "self", ".", "cache", ":", "\n", "            ", "self", ".", "cache_hits", "+=", "1", "\n", "return", "self", ".", "cache", "[", "phrase", "]", "\n", "# Get the data from the URL and in if there are multiple, use the one with the highest score", "\n", "", "if", "self", ".", "url", "is", "not", "None", ":", "\n", "            ", "wiki_pages", "=", "self", ".", "query_spotlight_wiki_server", "(", "phrase", ")", "\n", "if", "not", "wiki_pages", ":", "\n", "                ", "return", "None", "\n", "# Filter out pages where the \"surfaceForm\" (aka \"text\") doesn't exactly match", "\n", "# Note that experimentally this appears to help the overall score but it also", "\n", "# eliminates some good ones", "\n", "# \"George W. Bush\" returns {'wiki': 'George_W._Bush', 'score': 0.9317, 'text': 'Bush'}", "\n", "# \"Nuclear Nonproliferation Treaty\" = returns..", "\n", "# {'wiki': 'Treaty_on_the_Non-Proliferation_of_Nuclear_Weapons', 'score': 1.0, 'text':", "\n", "#  'Nonproliferation Treaty'}", "\n", "", "wiki_pages", "=", "[", "p", "for", "p", "in", "wiki_pages", "if", "p", "[", "'text'", "]", ".", "lower", "(", ")", "==", "phrase", ".", "lower", "(", ")", "]", "\n", "if", "not", "wiki_pages", ":", "\n", "                ", "return", "None", "\n", "# Always keep highest scoring page", "\n", "", "wiki_pages", "=", "sorted", "(", "wiki_pages", ",", "key", "=", "lambda", "x", ":", "x", "[", "'score'", "]", ")", "\n", "wiki", "=", "wiki_pages", "[", "-", "1", "]", "[", "'wiki'", "]", "# take last, sorted low to high", "\n", "self", ".", "cache", "[", "phrase", "]", "=", "wiki", "\n", "return", "wiki", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_spotlight.WikiAdderSpotlight.query_spotlight_wiki_server": [[141, 163], ["json.loads.get", "requests.post", "requests.post.raise_for_status", "requests.post.content.decode", "json.loads", "unidecode.unidecode.unidecode", "float", "wiki_pages.append", "logger.error", "res[].split"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "query_spotlight_wiki_server", "(", "self", ",", "text", ")", ":", "\n", "        ", "self", ".", "server_queries", "+=", "1", "\n", "headers", "=", "{", "'accept'", ":", "'application/json'", "}", "\n", "data", "=", "{", "'text'", ":", "text", ",", "'confidence'", ":", "self", ".", "confidence", "}", "\n", "try", ":", "\n", "            ", "req", "=", "requests", ".", "post", "(", "self", ".", "url", ",", "data", "=", "data", ",", "headers", "=", "headers", ")", "\n", "req", ".", "raise_for_status", "(", ")", "\n", "ret", "=", "req", ".", "content", ".", "decode", "(", "'utf-8'", ")", "\n", "sdict", "=", "json", ".", "loads", "(", "ret", ")", "\n", "", "except", ":", "\n", "            ", "self", ".", "server_errors", "+=", "1", "\n", "logger", ".", "error", "(", "'Exception quering for: %s'", "%", "text", ")", "\n", "return", "{", "}", "\n", "# Form a list of the returned pages", "\n", "", "wiki_pages", "=", "[", "]", "\n", "for", "res", "in", "sdict", ".", "get", "(", "'Resources'", ",", "[", "]", ")", ":", "\n", "            ", "wiki", "=", "res", "[", "'@URI'", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "# ie.. http://dbpedia.org/resource/Barack_Obama", "\n", "wiki", "=", "unidecode", "(", "wiki", ")", "\n", "score", "=", "float", "(", "res", "[", "'@similarityScore'", "]", ")", "\n", "text", "=", "res", "[", "'@surfaceForm'", "]", "\n", "wiki_pages", ".", "append", "(", "{", "'wiki'", ":", "wiki", ",", "'score'", ":", "score", ",", "'text'", ":", "text", "}", ")", "\n", "", "return", "wiki_pages", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_spotlight.WikiAdderSpotlight.get_sents_from_AMR": [[165, 171], ["penman.load", "sents.append"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["", "@", "staticmethod", "\n", "def", "get_sents_from_AMR", "(", "infn", ")", ":", "\n", "        ", "sents", "=", "[", "]", "\n", "for", "graph", "in", "penman", ".", "load", "(", "infn", ")", ":", "\n", "            ", "sents", ".", "append", "(", "graph", ".", "metadata", "[", "'snt'", "]", ")", "\n", "", "return", "sents", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_spotlight.WikiAdderSpotlight.load_cache": [[173, 183], ["logger.info", "open", "json.load", "logger.warning", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["", "@", "staticmethod", "\n", "def", "load_cache", "(", "cache_fn", ")", ":", "\n", "        ", "cache", "=", "{", "}", "\n", "try", ":", "\n", "            ", "with", "open", "(", "cache_fn", ")", "as", "f", ":", "\n", "                ", "cache", "=", "json", ".", "load", "(", "f", ")", "\n", "", "logger", ".", "info", "(", "'%d entries loaded from cache_fn %s'", "%", "(", "len", "(", "cache", ")", ",", "cache_fn", ")", ")", "\n", "", "except", ":", "\n", "            ", "logger", ".", "warning", "(", "'Cache file %s does not exist.  Empty cache initialized'", "%", "cache_fn", ")", "\n", "", "return", "cache", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_spotlight.WikiAdderSpotlight.save_cache": [[185, 189], ["len", "open", "json.dump"], "methods", ["None"], ["", "def", "save_cache", "(", "self", ",", "cache_fn", ")", ":", "\n", "        ", "with", "open", "(", "cache_fn", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "cache", ",", "f", ",", "indent", "=", "4", ")", "\n", "", "return", "len", "(", "self", ".", "cache", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_spotlight.WikiAdderSpotlight.manually_update_cache": [[193, 198], ["None"], "methods", ["None"], ["", "def", "manually_update_cache", "(", "self", ")", ":", "\n", "        ", "self", ".", "cache", "[", "'U.S.'", "]", "=", "'United_States'", "\n", "self", ".", "cache", "[", "'U.S.A.'", "]", "=", "'United_States'", "\n", "self", ".", "cache", "[", "'America'", "]", "=", "'United_States'", "\n", "self", ".", "cache", "[", "'West'", "]", "=", "'Western_world'", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.__init__": [[15, 21], ["print", "wiki_adder_blink.WikiAdderBlink.load_models"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.load_models"], ["def", "__init__", "(", "self", ",", "models_path", "=", "None", ",", "score_thresh", "=", "0.0", ")", ":", "\n", "        ", "self", ".", "score_thresh", "=", "score_thresh", "# don't use predictions below this score", "\n", "self", ".", "models", "=", "None", "\n", "if", "models_path", "is", "not", "None", ":", "\n", "            ", "print", "(", "'Loading BLINK models'", ")", "\n", "self", ".", "load_models", "(", "models_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.wikify_file": [[23, 32], ["print", "penman.load", "wiki_adder_blink.WikiAdderBlink.find_wiki_nodes_for_graphs", "print", "wiki_adder_blink.WikiAdderBlink.predict_blink", "print", "wiki_adder_blink.WikiAdderBlink.add_wiki_to_graphs", "penman.dump"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.find_wiki_nodes_for_graphs", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.predict_blink", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.add_wiki_to_graphs"], ["", "", "def", "wikify_file", "(", "self", ",", "infpath", ",", "outfpath", ")", ":", "\n", "        ", "print", "(", "'Loading'", ",", "infpath", ")", "\n", "pgraphs", "=", "penman", ".", "load", "(", "infpath", ")", "\n", "winfo_list", "=", "self", ".", "find_wiki_nodes_for_graphs", "(", "pgraphs", ")", "\n", "print", "(", "'Running BLINK to get wiki values'", ")", "\n", "winfo_list", "=", "self", ".", "predict_blink", "(", "winfo_list", ")", "\n", "print", "(", "'Adding and saving graphs to'", ",", "outfpath", ")", "\n", "pgraphs", "=", "self", ".", "add_wiki_to_graphs", "(", "pgraphs", ",", "winfo_list", ")", "\n", "penman", ".", "dump", "(", "pgraphs", ",", "outfpath", ",", "indent", "=", "6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.find_wiki_nodes_for_graphs": [[40, 45], ["enumerate", "wiki_adder_blink.WikiAdderBlink.find_wiki_nodes"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.find_wiki_nodes"], ["", "def", "find_wiki_nodes_for_graphs", "(", "self", ",", "graphs", ")", ":", "\n", "        ", "winfo_list", "=", "[", "]", "\n", "for", "gidx", ",", "graph", "in", "enumerate", "(", "graphs", ")", ":", "\n", "            ", "winfo_list", "+=", "self", ".", "find_wiki_nodes", "(", "graph", ",", "gidx", ")", "\n", "", "return", "winfo_list", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.find_wiki_nodes": [[47, 105], ["graph.metadata.get", "collections.Counter", "collections.Counter.items", "logger.warning", "sorted", "sent.strip().lower.strip().lower.strip().lower", "winfo_list.append", "str", "graph.attributes", "graph.edges", "t.target.replace", "logger.warning", "sent.strip().lower.strip().lower.find", "logger.warning", "graph.attributes", "t.role.startswith", "sent.strip().lower.strip().lower.strip", "len", "str"], "methods", ["None"], ["", "def", "find_wiki_nodes", "(", "self", ",", "graph", ",", "graph_idx", ")", ":", "\n", "        ", "winfo_list", "=", "[", "]", "\n", "sent", "=", "graph", ".", "metadata", "[", "'snt'", "]", "\n", "gid", "=", "graph", ".", "metadata", ".", "get", "(", "'id'", ",", "'#'", "+", "str", "(", "graph_idx", ")", ")", "\n", "# Check for name attributes.  These shouldn't be present but might.", "\n", "for", "name_attrib", "in", "[", "t", "for", "t", "in", "graph", ".", "attributes", "(", ")", "if", "t", ".", "role", "==", "':name'", "]", ":", "\n", "            ", "logger", ".", "warning", "(", "'%s has :name attrib in graph %s'", "%", "(", "gid", ",", "name_attrib", ")", ")", "\n", "# Find all the name edges and loop through them", "\n", "", "name_edges", "=", "[", "t", "for", "t", "in", "graph", ".", "edges", "(", ")", "if", "t", ".", "role", "==", "':name'", "]", "\n", "for", "name_edge", "in", "name_edges", ":", "\n", "# Get all the :opX operators, sort them by X to extract the multi-word name", "\n", "# in all of the test data there are not any name_attribs that have roles other than :opX", "\n", "            ", "name_attribs", "=", "[", "t", "for", "t", "in", "graph", ".", "attributes", "(", ")", "if", "t", ".", "source", "==", "name_edge", ".", "target", "]", "\n", "name_attribs", "=", "sorted", "(", "name_attribs", ",", "key", "=", "lambda", "t", ":", "t", ".", "role", ")", "\n", "name_list", "=", "[", "t", ".", "target", ".", "replace", "(", "'\"'", ",", "''", ")", "for", "t", "in", "name_attribs", "if", "t", ".", "role", ".", "startswith", "(", "':op'", ")", "]", "\n", "if", "not", "name_list", ":", "\n", "                ", "logger", ".", "warning", "(", "'%s has no name assosiated with the edge %s'", "%", "(", "gid", ",", "str", "(", "name_edge", ")", ")", ")", "\n", "continue", "\n", "# Try to find the mention in the sentence and if so, split the sentence around it", "\n", "# The BLINK system uses all lower-case", "\n", "", "mention", "=", "' '", ".", "join", "(", "name_list", ")", ".", "lower", "(", ")", "\n", "sent", "=", "sent", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "mention_found", "=", "mention", "in", "sent", "\n", "if", "mention_found", ":", "\n", "                ", "left_idx", "=", "sent", ".", "find", "(", "mention", ")", "\n", "right_idx", "=", "left_idx", "+", "len", "(", "mention", ")", "\n", "context_left", "=", "sent", "[", ":", "left_idx", "]", "\n", "context_right", "=", "sent", "[", "right_idx", ":", "]", "\n", "# If exact mention is not in the sentence don't bother splitting.", "\n", "# Could do some fuzzy logic to find the split but this seems to work fairly well.", "\n", "", "else", ":", "\n", "                ", "context_left", "=", "sent", "\n", "context_right", "=", "sent", "\n", "# Create the wiki information dictionary to be use in the model and for further processing", "\n", "", "winfo", "=", "{", "\n", "# The following are required keys to run the BLINK model", "\n", "'label'", ":", "'unknown'", ",", "# blink's behavior keys off of this", "\n", "'label_id'", ":", "-", "1", ",", "# blink's behavior keys off of this", "\n", "'context_left'", ":", "context_left", ",", "\n", "'mention'", ":", "mention", ",", "\n", "'context_right'", ":", "context_right", ",", "\n", "# The following are for other internal processing or debug", "\n", "'graph_id'", ":", "gid", ",", "\n", "'graph_idx'", ":", "graph_idx", ",", "\n", "'source_var'", ":", "name_edge", ".", "source", ",", "\n", "'mention_found'", ":", "mention_found", ",", "\n", "# These will be filled in by self.predict_blink()", "\n", "'wiki_val'", ":", "'-'", ",", "\n", "'score'", ":", "-", "100.0", "}", "\n", "winfo_list", ".", "append", "(", "winfo", ")", "\n", "# Check that there aren't multiple source nodes.  This doesn't happen in the AMR3 test", "\n", "# or dev data but there are two instances in the training data where it does. Predicted", "\n", "# graphs may have some of these.", "\n", "", "sv_counter", "=", "Counter", "(", "[", "winfo", "[", "'source_var'", "]", "for", "winfo", "in", "winfo_list", "]", ")", "\n", "for", "svar", ",", "count", "in", "sv_counter", ".", "items", "(", ")", ":", "\n", "            ", "if", "count", ">", "1", ":", "\n", "                ", "logger", ".", "warning", "(", "'More than one wiki node for var %s in graph %s'", "%", "(", "svar", ",", "gid", ")", ")", "\n", "", "", "return", "winfo_list", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.add_wiki_to_graphs": [[111, 116], ["wiki_adder_blink.WikiAdderBlink.add_wiki"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.add_wiki"], ["", "def", "add_wiki_to_graphs", "(", "self", ",", "graphs", ",", "winfo_list", ")", ":", "\n", "        ", "for", "winfo", "in", "winfo_list", ":", "\n", "            ", "gidx", "=", "winfo", "[", "'graph_idx'", "]", "\n", "graphs", "[", "gidx", "]", "=", "self", ".", "add_wiki", "(", "graphs", "[", "gidx", "]", ",", "winfo", ")", "\n", "", "return", "graphs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.add_wiki": [[119, 141], ["graph.triples.index", "graph.triples.insert", "len", "logger.error", "wiki_val.startswith", "wiki_val.endswith"], "methods", ["None"], ["", "def", "add_wiki", "(", "self", ",", "graph", ",", "winfo", ")", ":", "\n", "        ", "svar", "=", "winfo", "[", "'source_var'", "]", "\n", "wiki_val", "=", "winfo", "[", "'wiki_val'", "]", "\n", "if", "self", ".", "score_thresh", "is", "not", "None", "and", "winfo", "[", "'score'", "]", "<", "self", ".", "score_thresh", ":", "\n", "            ", "wiki_val", "=", "'-'", "\n", "# Find the index of the parent in the graph.triples", "\n", "# The index technically doesn't matter but it may impact the print order", "\n", "", "parent_triples", "=", "[", "t", "for", "t", "in", "graph", ".", "triples", "if", "t", "[", "1", "]", "==", "':instance'", "and", "t", "[", "0", "]", "==", "svar", "]", "\n", "if", "len", "(", "parent_triples", ")", "!=", "1", ":", "\n", "            ", "logger", ".", "error", "(", "'%s Graph lookup error for %s returned %s'", "%", "(", "gid", ",", "svar", ",", "parent_triples", ")", ")", "\n", "", "index", "=", "graph", ".", "triples", ".", "index", "(", "parent_triples", "[", "0", "]", ")", "\n", "# Now add this to the graph just after the parent and add an empty epidata entry", "\n", "# string attributes are quoted", "\n", "if", "wiki_val", "!=", "'-'", ":", "\n", "            ", "if", "not", "wiki_val", ".", "startswith", "(", "'\"'", ")", ":", "\n", "                ", "wiki_val", "=", "'\"'", "+", "wiki_val", "\n", "", "if", "not", "wiki_val", ".", "endswith", "(", "'\"'", ")", ":", "\n", "                ", "wiki_val", "=", "wiki_val", "+", "'\"'", "\n", "", "", "triple", "=", "(", "svar", ",", "':wiki'", ",", "wiki_val", ")", "\n", "graph", ".", "triples", ".", "insert", "(", "index", ",", "triple", ")", "\n", "graph", ".", "epidata", "[", "triple", "]", "=", "[", "]", "\n", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.load_models": [[146, 150], ["wiki_adder_blink.WikiAdderBlink.build_blink_config", "blink.load_models"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.build_blink_config", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.load_models"], ["", "def", "load_models", "(", "self", ",", "models_path", ")", ":", "\n", "        ", "args", "=", "self", ".", "build_blink_config", "(", "models_path", ")", "\n", "self", ".", "blink_config", "=", "args", "\n", "self", ".", "models", "=", "main_dense", ".", "load_models", "(", "args", ",", "logger", "=", "self", ".", "blink_logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.predict_blink": [[151, 166], ["blink.run", "zip", "len", "len", "len", "prediction.replace.replace.replace", "float", "unidecode.unidecode.unidecode", "p.startswith"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run"], ["", "def", "predict_blink", "(", "self", ",", "winfo_list", ")", ":", "\n", "        ", "assert", "self", ".", "models", "is", "not", "None", "\n", "# return (biencoder_accuracy, recall_at, crossencoder_normalized_accuracy, overall_unormalized_accuracy,", "\n", "#         len(winfo_list), predictions, scores) all list of length(winfo_list)", "\n", "ret", "=", "main_dense", ".", "run", "(", "self", ".", "blink_config", ",", "self", ".", "blink_logger", ",", "*", "self", ".", "models", ",", "test_data", "=", "winfo_list", ")", "\n", "pred_list", ",", "score_list", "=", "ret", "[", "5", "]", ",", "ret", "[", "6", "]", "\n", "# Load the returned data back into the wiki info dictionaries", "\n", "assert", "len", "(", "winfo_list", ")", "==", "len", "(", "pred_list", ")", "==", "len", "(", "score_list", ")", "\n", "for", "winfo", ",", "preds", ",", "scores", "in", "zip", "(", "winfo_list", ",", "pred_list", ",", "score_list", ")", ":", "\n", "            ", "preds", "=", "[", "p", "for", "p", "in", "preds", "if", "not", "p", ".", "startswith", "(", "'List of'", ")", "]", "\n", "prediction", "=", "'\"%s\"'", "%", "unidecode", "(", "preds", "[", "0", "]", ")", "if", "preds", "else", "'-'", "\n", "prediction", "=", "prediction", ".", "replace", "(", "' '", ",", "'_'", ")", "\n", "winfo", "[", "'wiki_val'", "]", "=", "prediction", "\n", "winfo", "[", "'score'", "]", "=", "float", "(", "scores", "[", "0", "]", ")", "\n", "", "return", "winfo_list", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.wiki_adder_blink.WikiAdderBlink.build_blink_config": [[167, 187], ["types.SimpleNamespace", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "build_blink_config", "(", "self", ",", "models_path", ",", "fast", "=", "False", ")", ":", "\n", "        ", "blink_config", "=", "SimpleNamespace", "(", ")", "\n", "blink_config", ".", "interactive", "=", "False", "\n", "blink_config", ".", "test_entities", "=", "None", "\n", "blink_config", ".", "test_mentions", "=", "None", "\n", "blink_config", ".", "top_k", "=", "10", "\n", "blink_config", ".", "show_url", "=", "False", "\n", "blink_config", ".", "fast", "=", "False", "\n", "blink_config", ".", "biencoder_model", "=", "os", ".", "path", ".", "join", "(", "models_path", ",", "\"biencoder_wiki_large.bin\"", ")", "\n", "blink_config", ".", "biencoder_config", "=", "os", ".", "path", ".", "join", "(", "models_path", ",", "\"biencoder_wiki_large.json\"", ")", "\n", "blink_config", ".", "entity_catalogue", "=", "os", ".", "path", ".", "join", "(", "models_path", ",", "\"entity.jsonl\"", ")", "\n", "blink_config", ".", "entity_encoding", "=", "os", ".", "path", ".", "join", "(", "models_path", ",", "\"all_entities_large.t7\"", ")", "\n", "blink_config", ".", "crossencoder_model", "=", "os", ".", "path", ".", "join", "(", "models_path", ",", "\"crossencoder_wiki_large.bin\"", ")", "\n", "blink_config", ".", "crossencoder_config", "=", "os", ".", "path", ".", "join", "(", "models_path", ",", "\"crossencoder_wiki_large.json\"", ")", "\n", "#faiss_index = 'flat' does not improve scores and takes 2X as long to process", "\n", "#faiss_index = None ==> use the entity_encoding model (blink_config.index_path is not used)", "\n", "#faiss_index = 'flat' or 'hnsw' then requires index_path (replaces entity encoding model)", "\n", "blink_config", ".", "faiss_index", "=", "None", "\n", "#blink_config.index_path          = os.path.join(models_path, \"faiss_flat_index.pkl\")", "\n", "return", "blink_config", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading_raw.load_raw_amr": [[7, 19], ["amr_loading_raw.to_ascii", "to_ascii.split", "open", "f.read", "e.strip", "to_ascii.splitlines", "l.startswith", "l.startswith"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading_raw.to_ascii", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["def", "load_raw_amr", "(", "fname", ")", ":", "\n", "    ", "with", "open", "(", "fname", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "raw_bytes", "=", "f", ".", "read", "(", ")", "\n", "", "data", "=", "to_ascii", "(", "raw_bytes", ")", "\n", "# Strip off non-amr header info (see start of Little Prince corpus)", "\n", "lines", "=", "[", "l", "for", "l", "in", "data", ".", "splitlines", "(", ")", "if", "not", "(", "l", ".", "startswith", "(", "'#'", ")", "and", "not", "l", ".", "startswith", "(", "'# ::'", ")", ")", "]", "\n", "data", "=", "'\\n'", ".", "join", "(", "lines", ")", "\n", "# Split into different entries based on a space (ie.. extra linefeed) between the graph and text", "\n", "entries", "=", "data", ".", "split", "(", "'\\n\\n'", ")", "# split via standard amr", "\n", "entries", "=", "[", "e", ".", "strip", "(", ")", "for", "e", "in", "entries", "]", "# clean-up line-feeds, spaces, etc", "\n", "entries", "=", "[", "e", "for", "e", "in", "entries", "if", "e", "]", "# remove any empty entries", "\n", "return", "entries", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading_raw.to_ascii": [[46, 52], ["convert_dict.items", "raw_bytes.replace.decode", "unidecode.unidecode", "raw_bytes.replace.replace"], "function", ["None"], ["def", "to_ascii", "(", "raw_bytes", ")", ":", "\n", "    ", "for", "code", ",", "repl", "in", "convert_dict", ".", "items", "(", ")", ":", "\n", "        ", "raw_bytes", "=", "raw_bytes", ".", "replace", "(", "code", ",", "repl", ")", "\n", "", "text", "=", "raw_bytes", ".", "decode", "(", "'utf-8'", ")", "\n", "text", "=", "unidecode", "(", "text", ")", "# converts unicode to ASCII", "\n", "return", "text", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator.annotate_file": [[20, 35], ["annotator.load_spacy", "os.path.join", "amr_loading.load_amr_entries", "multiprocessing.Pool", "tqdm.tqdm", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "os.path.join", "print", "penman.dump", "multiprocessing.Pool.imap", "graphs.append", "infn.endswith", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator.load_spacy", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading.load_amr_entries", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["def", "annotate_file", "(", "indir", ",", "infn", ",", "outdir", ",", "outfn", ")", ":", "\n", "    ", "load_spacy", "(", ")", "\n", "graphs", "=", "[", "]", "\n", "inpath", "=", "os", ".", "path", ".", "join", "(", "indir", ",", "infn", ")", "\n", "entries", "=", "load_amr_entries", "(", "inpath", ")", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", ")", "\n", "#for pen in tqdm(map(_process_entry, entries), total=len(entries)):", "\n", "for", "pen", "in", "tqdm", "(", "pool", ".", "imap", "(", "_process_entry", ",", "entries", ")", ",", "total", "=", "len", "(", "entries", ")", ")", ":", "\n", "        ", "graphs", ".", "append", "(", "pen", ")", "\n", "", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "infn", "=", "infn", "[", ":", "-", "3", "]", "if", "infn", ".", "endswith", "(", "'.gz'", ")", "else", "infn", "# strip .gz if needed", "\n", "outpath", "=", "os", ".", "path", ".", "join", "(", "outdir", ",", "outfn", ")", "\n", "print", "(", "'Saving file to '", ",", "outpath", ")", "\n", "penman", ".", "dump", "(", "graphs", ",", "outpath", ",", "indent", "=", "6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator.annotate_graph": [[38, 41], ["annotator.load_spacy", "annotator._process_entry"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator.load_spacy", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator._process_entry"], ["", "def", "annotate_graph", "(", "entry", ",", "tokens", "=", "None", ")", ":", "\n", "    ", "load_spacy", "(", ")", "\n", "return", "_process_entry", "(", "entry", ",", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator.annotate_penman": [[43, 46], ["annotator.load_spacy", "annotator._process_penman"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator.load_spacy", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator._process_penman"], ["", "def", "annotate_penman", "(", "pgraph", ",", "tokens", "=", "None", ")", ":", "\n", "    ", "load_spacy", "(", ")", "\n", "return", "_process_penman", "(", "pgraph", ",", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator._process_entry": [[51, 54], ["penman.decode", "annotator._process_penman"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator._process_penman"], ["", "def", "_process_entry", "(", "entry", ",", "tokens", "=", "None", ")", ":", "\n", "    ", "pen", "=", "penman", ".", "decode", "(", "entry", ")", "# standard de-inverting penman loading process", "\n", "return", "_process_penman", "(", "pen", ",", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator._process_penman": [[56, 85], ["json.dumps", "json.dumps", "json.dumps", "json.dumps", "json.dumps", "spacy_nlp", "lemmas.append", "t.text.lower", "pen.metadata.items", "t.tag_.startswith", "t.lemma_.lower"], "function", ["None"], ["", "def", "_process_penman", "(", "pen", ",", "tokens", "=", "None", ")", ":", "\n", "# Filter out old tags and add the tags from SpaCy parse", "\n", "    ", "global", "keep_tags", "\n", "if", "keep_tags", "is", "not", "None", ":", "\n", "        ", "pen", ".", "metadata", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "pen", ".", "metadata", ".", "items", "(", ")", "if", "k", "in", "keep_tags", "}", "# filter extra tags", "\n", "# If tokens aren't supplied then annoate the graph", "\n", "", "if", "not", "tokens", ":", "\n", "        ", "global", "spacy_nlp", "\n", "assert", "spacy_nlp", "is", "not", "None", "\n", "tokens", "=", "spacy_nlp", "(", "pen", ".", "metadata", "[", "'snt'", "]", ")", "\n", "", "pen", ".", "metadata", "[", "'tokens'", "]", "=", "json", ".", "dumps", "(", "[", "t", ".", "text", "for", "t", "in", "tokens", "]", ")", "\n", "ner_tags", "=", "[", "t", ".", "ent_type_", "if", "t", ".", "ent_type_", "else", "'O'", "for", "t", "in", "tokens", "]", "# replace empty with 'O'", "\n", "pen", ".", "metadata", "[", "'ner_tags'", "]", "=", "json", ".", "dumps", "(", "ner_tags", ")", "\n", "pen", ".", "metadata", "[", "'ner_iob'", "]", "=", "json", ".", "dumps", "(", "[", "t", ".", "ent_iob_", "for", "t", "in", "tokens", "]", ")", "\n", "pen", ".", "metadata", "[", "'pos_tags'", "]", "=", "json", ".", "dumps", "(", "[", "t", ".", "tag_", "for", "t", "in", "tokens", "]", ")", "\n", "# Create lemmas", "\n", "# The spaCy 2.0 lemmatizer returns -PRON- for pronouns so strip these (spaCy 3.x does not do this)", "\n", "# Don't try to lemmatize any named-entities or proper nouns.  Lower-case any other words.", "\n", "lemmas", "=", "[", "]", "\n", "for", "t", "in", "tokens", ":", "\n", "        ", "if", "t", ".", "lemma_", "==", "'-PRON-'", ":", "# spaCy 2.x only", "\n", "            ", "lemma", "=", "t", ".", "text", ".", "lower", "(", ")", "\n", "", "elif", "t", ".", "tag_", ".", "startswith", "(", "'NNP'", ")", "or", "t", ".", "ent_type_", "not", "in", "(", "''", ",", "'O'", ")", ":", "\n", "            ", "lemma", "=", "t", ".", "text", "\n", "", "else", ":", "\n", "            ", "lemma", "=", "t", ".", "lemma_", ".", "lower", "(", ")", "\n", "", "lemmas", ".", "append", "(", "lemma", ")", "\n", "", "pen", ".", "metadata", "[", "'lemmas'", "]", "=", "json", ".", "dumps", "(", "lemmas", ")", "\n", "return", "pen", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator.add_lemmas": [[92, 122], ["annotator.load_spacy", "penman.decode", "spacy_nlp", "json.dumps", "json.dumps", "lemmas.append", "penman.decode.metadata[].split", "penman.models.noop.NoOpModel", "t.text.lower", "len", "len", "len", "t.tag_.startswith", "t.lemma_.lower"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator.load_spacy", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "add_lemmas", "(", "entry", ",", "snt_key", ",", "verify_tok_key", "=", "None", ")", ":", "\n", "    ", "global", "spacy_nlp", "\n", "load_spacy", "(", ")", "\n", "graph", "=", "penman", ".", "decode", "(", "entry", ",", "model", "=", "NoOpModel", "(", ")", ")", "# do not de-invert graphs", "\n", "doc", "=", "spacy_nlp", "(", "graph", ".", "metadata", "[", "snt_key", "]", ")", "\n", "nlp_tokens", "=", "[", "t", ".", "text", "for", "t", "in", "doc", "]", "\n", "graph", ".", "metadata", "[", "'tokens'", "]", "=", "json", ".", "dumps", "(", "nlp_tokens", ")", "\n", "# Create lemmas", "\n", "# SpaCy's lemmatizer returns -PRON- for pronouns so strip these", "\n", "# Don't try to lemmatize any named-entities or proper nouns.  Lower-case any other words.", "\n", "lemmas", "=", "[", "]", "\n", "for", "t", "in", "doc", ":", "\n", "        ", "if", "t", ".", "lemma_", "==", "'-PRON-'", ":", "\n", "            ", "lemma", "=", "t", ".", "text", ".", "lower", "(", ")", "\n", "", "elif", "t", ".", "tag_", ".", "startswith", "(", "'NNP'", ")", "or", "t", ".", "ent_type_", "not", "in", "(", "''", ",", "'O'", ")", ":", "\n", "            ", "lemma", "=", "t", ".", "text", "\n", "", "else", ":", "\n", "            ", "lemma", "=", "t", ".", "lemma_", ".", "lower", "(", ")", "\n", "", "lemmas", ".", "append", "(", "lemma", ")", "\n", "", "graph", ".", "metadata", "[", "'lemmas'", "]", "=", "json", ".", "dumps", "(", "lemmas", ")", "\n", "# If verify_tok_key is not None, verify that the new tokenization is the same as the existing", "\n", "# and only return the graph if the tokenized length is the same", "\n", "if", "verify_tok_key", "is", "not", "None", ":", "\n", "        ", "isi_tokens", "=", "graph", ".", "metadata", "[", "verify_tok_key", "]", ".", "split", "(", ")", "\n", "if", "len", "(", "isi_tokens", ")", "==", "len", "(", "lemmas", ")", "==", "len", "(", "nlp_tokens", ")", ":", "\n", "            ", "return", "graph", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "", "", "else", ":", "\n", "        ", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator.load_spacy": [[130, 138], ["spacy.load"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["def", "load_spacy", "(", "model_name", "=", "None", ")", ":", "\n", "    ", "global", "spacy_nlp", "\n", "if", "spacy_nlp", "is", "not", "None", ":", "# will return if a thread is already loading", "\n", "        ", "return", "\n", "", "model_name", "=", "model_name", "if", "model_name", "is", "not", "None", "else", "defaults", ".", "spacy_model_name", "\n", "#print('Loading SpaCy NLP Model:', model_name)", "\n", "import", "spacy", "\n", "spacy_nlp", "=", "spacy", ".", "load", "(", "model_name", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading.load_amr_entries": [[7, 23], ["fname.endswith", "f.read.split", "e.strip", "gzip.open", "f.read().decode", "open", "f.read", "f.read.splitlines", "f.read", "l.startswith", "l.startswith"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["def", "load_amr_entries", "(", "fname", ",", "strip_comments", "=", "True", ")", ":", "\n", "    ", "if", "fname", ".", "endswith", "(", "'.gz'", ")", ":", "\n", "        ", "with", "gzip", ".", "open", "(", "fname", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "data", "=", "f", ".", "read", "(", ")", ".", "decode", "(", ")", "\n", "", "", "else", ":", "\n", "        ", "with", "open", "(", "fname", ")", "as", "f", ":", "\n", "            ", "data", "=", "f", ".", "read", "(", ")", "\n", "# Strip off non-amr header info (see start of Little Prince corpus)", "\n", "", "", "if", "strip_comments", ":", "\n", "        ", "lines", "=", "[", "l", "for", "l", "in", "data", ".", "splitlines", "(", ")", "if", "not", "(", "l", ".", "startswith", "(", "'#'", ")", "and", "not", "l", ".", "startswith", "(", "'# ::'", ")", ")", "]", "\n", "data", "=", "'\\n'", ".", "join", "(", "lines", ")", "\n", "", "entries", "=", "data", ".", "split", "(", "'\\n\\n'", ")", "# split via standard amr", "\n", "entries", "=", "[", "e", ".", "strip", "(", ")", "for", "e", "in", "entries", "]", "# clean-up line-feeds, spaces, etc", "\n", "entries", "=", "[", "e", "for", "e", "in", "entries", "if", "e", "]", "# remove any empty entries", "\n", "return", "entries", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading.split_amr_meta": [[27, 41], ["entry.splitlines", "line.strip.strip", "line.strip.startswith", "meta_lines.append", "line.strip.startswith", "graph_lines.append"], "function", ["None"], ["", "def", "split_amr_meta", "(", "entry", ")", ":", "\n", "    ", "meta_lines", "=", "[", "]", "\n", "graph_lines", "=", "[", "]", "\n", "for", "line", "in", "entry", ".", "splitlines", "(", ")", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "not", "line", ":", "\n", "            ", "continue", "\n", "", "if", "line", ".", "startswith", "(", "'# ::'", ")", ":", "\n", "            ", "meta_lines", ".", "append", "(", "line", ")", "\n", "", "elif", "line", ".", "startswith", "(", "'#'", ")", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "graph_lines", ".", "append", "(", "line", ")", "\n", "", "", "return", "meta_lines", ",", "graph_lines", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading.load_amr_graph_sent": [[45, 62], ["f.read.split", "open", "f.read", "entry.splitlines", "line.strip.strip", "line.strip.startswith", "entries[].append", "entries[].append", "line[].strip", "line.strip.startswith", "gstrings.append", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "load_amr_graph_sent", "(", "fpath", ")", ":", "\n", "    ", "entries", "=", "{", "'sent'", ":", "[", "]", ",", "'graph'", ":", "[", "]", "}", "\n", "with", "open", "(", "fpath", ")", "as", "f", ":", "\n", "        ", "data", "=", "f", ".", "read", "(", ")", "\n", "", "for", "entry", "in", "data", ".", "split", "(", "'\\n\\n'", ")", ":", "\n", "        ", "sent", "=", "None", "\n", "gstrings", "=", "[", "]", "\n", "for", "line", "in", "entry", ".", "splitlines", "(", ")", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ".", "startswith", "(", "'# ::snt'", ")", ":", "\n", "                ", "sent", "=", "line", "[", "len", "(", "'# ::snt'", ")", ":", "]", ".", "strip", "(", ")", "\n", "", "if", "not", "line", ".", "startswith", "(", "'#'", ")", ":", "\n", "                ", "gstrings", ".", "append", "(", "line", ")", "\n", "", "", "if", "sent", "and", "gstrings", ":", "\n", "            ", "entries", "[", "'sent'", "]", ".", "append", "(", "sent", ")", "\n", "entries", "[", "'graph'", "]", ".", "append", "(", "' '", ".", "join", "(", "gstrings", ")", ")", "\n", "", "", "return", "entries", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading.get_graph_only": [[66, 80], ["entry.splitlines", "re.sub", "line.startswith", "graph_lines.append", "l.strip"], "function", ["None"], ["", "def", "get_graph_only", "(", "entry", ",", "one_line", "=", "False", ")", ":", "\n", "    ", "graph_lines", "=", "[", "]", "\n", "for", "line", "in", "entry", ".", "splitlines", "(", ")", ":", "\n", "        ", "if", "not", "line", "or", "line", ".", "startswith", "(", "'#'", ")", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "graph_lines", ".", "append", "(", "line", ")", "\n", "", "", "if", "one_line", ":", "\n", "        ", "graph_lines", "=", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "graph_lines", "]", "\n", "gstring", "=", "' '", ".", "join", "(", "graph_lines", ")", "\n", "gstring", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "gstring", ")", "# squeeze multiple spaces into a single", "\n", "return", "gstring", "\n", "", "else", ":", "\n", "        ", "return", "'\\n'", ".", "join", "(", "graph_lines", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.alignments.penman_utils.test_for_decode_encode_issue": [[9, 16], ["penman.decode", "penman.encode", "penman_utils.to_graph_line", "penman_utils.to_graph_line", "penman.models.noop.NoOpModel", "penman.models.noop.NoOpModel"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode", "home.repos.pwc.inspect_result.chenllliang_atp.alignments.penman_utils.to_graph_line", "home.repos.pwc.inspect_result.chenllliang_atp.alignments.penman_utils.to_graph_line"], ["def", "test_for_decode_encode_issue", "(", "gold", ")", ":", "\n", "    ", "graph", "=", "penman", ".", "decode", "(", "gold", ",", "model", "=", "NoOpModel", "(", ")", ")", "\n", "test", "=", "penman", ".", "encode", "(", "graph", ",", "indent", "=", "6", ",", "compact", "=", "True", ",", "model", "=", "NoOpModel", "(", ")", ")", "\n", "gold", "=", "to_graph_line", "(", "gold", ")", "\n", "test", "=", "to_graph_line", "(", "test", ")", "\n", "is_good", "=", "test", "==", "gold", "\n", "return", "graph", ",", "is_good", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.alignments.penman_utils.to_graph_line": [[18, 25], ["re.sub.replace", "re.sub", "re.sub.strip", "l.strip", "e.splitlines", "l.startswith"], "function", ["None"], ["", "def", "to_graph_line", "(", "e", ")", ":", "\n", "    ", "lines", "=", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "e", ".", "splitlines", "(", ")", "]", "\n", "lines", "=", "[", "l", "for", "l", "in", "lines", "if", "(", "l", "and", "not", "l", ".", "startswith", "(", "'#'", ")", ")", "]", "\n", "string", "=", "' '", ".", "join", "(", "lines", ")", "\n", "string", "=", "string", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "string", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "string", ")", "\n", "return", "string", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.alignments.penman_utils.strip_surface_alignments": [[27, 31], ["re.sub"], "function", ["None"], ["", "def", "strip_surface_alignments", "(", "graph_string", ")", ":", "\n", "# Match ~e. plus 1 or more integers plus zero or more of the patterns ,\\d+", "\n", "# ie, strip  ~.e4,5,10", "\n", "    ", "return", "re", ".", "sub", "(", "r'~e\\.\\d+[,\\d+]*'", ",", "''", ",", "graph_string", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.match_candidates.get_match_candidates": [[38, 59], ["token.lower", "month2num.get", "word2words.get", "lemma.lower", "word2number.w2n.word_to_num", "candidates.append", "candidates.append", "token.lower.startswith", "token.lower.startswith", "token.lower.startswith", "candidates.append", "str"], "function", ["None"], ["def", "get_match_candidates", "(", "token", ",", "lemma", ")", ":", "\n", "# Obvious candidates", "\n", "    ", "word", "=", "token", ".", "lower", "(", ")", "\n", "candidates", "=", "[", "word", ",", "lemma", ".", "lower", "(", ")", "]", "\n", "# Get candidates for numbers", "\n", "try", ":", "\n", "        ", "number", "=", "w2n", ".", "word_to_num", "(", "word", ")", "\n", "candidates", ".", "append", "(", "str", "(", "number", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "pass", "\n", "# Get candidates for months", "\n", "", "month", "=", "month2num", ".", "get", "(", "word", ",", "None", ")", "\n", "if", "month", "is", "not", "None", ":", "\n", "        ", "candidates", ".", "append", "(", "month", ")", "\n", "# Get misc alternate word candidates", "\n", "", "candidates", "+=", "word2words", ".", "get", "(", "word", ",", "[", "]", ")", "\n", "# Check for words that are negative (graphs should include '-') and get the", "\n", "# non-negative version of the word", "\n", "if", "word", ".", "startswith", "(", "'in'", ")", "or", "word", ".", "startswith", "(", "'un'", ")", "or", "word", ".", "startswith", "(", "'ir'", ")", ":", "\n", "        ", "candidates", ".", "append", "(", "word", "[", "2", ":", "]", ")", "\n", "", "return", "candidates", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.__init__": [[23, 33], ["kwargs.get", "kwargs.get", "rbw_aligner.RBWAligner.align_words", "rbw_aligner.RBWAligner.add_surface_alignments", "rbw_aligner.RBWAligner.add_alignment_string"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.align_words", "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.add_surface_alignments", "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.add_alignment_string"], ["def", "__init__", "(", "self", ",", "pen_graph", ",", "token_list", ",", "lemma_list", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "graph", "=", "pen_graph", "\n", "self", ".", "tokens", "=", "token_list", "\n", "self", ".", "lemmas", "=", "lemma_list", "\n", "self", ".", "fuzzy_min_ml", "=", "kwargs", ".", "get", "(", "'fuzzy_min_ml'", ",", "4", ")", "# minimum number of characters to look at for fuzzy match", "\n", "self", ".", "align_str_name", "=", "kwargs", ".", "get", "(", "'align_str_name'", ",", "'alignments'", ")", "\n", "self", ".", "align_prefix", "=", "'e.'", "# part of align_re above so not setable for now", "\n", "self", ".", "align_words", "(", ")", "\n", "self", ".", "add_surface_alignments", "(", ")", "\n", "self", ".", "add_alignment_string", "(", "self", ".", "graph", ",", "self", ".", "align_str_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.from_string_w_json": [[36, 41], ["isinstance", "penman.decode", "cls.from_penman_w_json", "penman.models.noop.NoOpModel"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.from_penman_w_json"], ["", "@", "classmethod", "\n", "def", "from_string_w_json", "(", "cls", ",", "graph", ",", "token_key", "=", "'tokens'", ",", "lemma_key", "=", "'lemmas'", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "isinstance", "(", "graph", ",", "str", ")", "\n", "graph", "=", "penman", ".", "decode", "(", "graph", ",", "model", "=", "NoOpModel", "(", ")", ")", "\n", "return", "cls", ".", "from_penman_w_json", "(", "graph", ",", "token_key", ",", "lemma_key", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.from_penman_w_json": [[43, 49], ["isinstance", "cls", "json.loads", "json.loads"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads"], ["", "@", "classmethod", "\n", "def", "from_penman_w_json", "(", "cls", ",", "graph", ",", "token_key", "=", "'tokens'", ",", "lemma_key", "=", "'lemmas'", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "isinstance", "(", "graph", ",", "penman", ".", "graph", ".", "Graph", ")", "\n", "tokens", "=", "[", "w", "for", "w", "in", "json", ".", "loads", "(", "graph", ".", "metadata", "[", "token_key", "]", ")", "]", "\n", "lemmas", "=", "[", "w", "for", "w", "in", "json", ".", "loads", "(", "graph", ".", "metadata", "[", "lemma_key", "]", ")", "]", "\n", "return", "cls", "(", "graph", ",", "tokens", ",", "lemmas", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.get_penman_graph": [[51, 53], ["None"], "methods", ["None"], ["", "def", "get_penman_graph", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.get_graph_string": [[55, 57], ["penman.encode", "penman.models.noop.NoOpModel"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode"], ["", "def", "get_graph_string", "(", "self", ")", ":", "\n", "        ", "return", "penman", ".", "encode", "(", "self", ".", "graph", ",", "model", "=", "NoOpModel", "(", ")", ",", "indent", "=", "6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.remove_surface_alignments": [[59, 62], ["rbw_aligner.RBWAligner.graph.epidata.items", "isinstance"], "methods", ["None"], ["", "def", "remove_surface_alignments", "(", "self", ")", ":", "\n", "        ", "for", "key", ",", "values", "in", "self", ".", "graph", ".", "epidata", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "graph", ".", "epidata", "[", "key", "]", "=", "[", "x", "for", "x", "in", "values", "if", "not", "isinstance", "(", "x", ",", "AlignmentMarker", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.align_words": [[69, 91], ["logger.debug", "match_candidates.get_match_candidates", "len", "rbw_aligner.RBWAligner.get_triple_info", "logger.getEffectiveLevel", "zip", "rbw_aligner.RBWAligner.exact_alignment", "logger.debug", "rbw_aligner.RBWAligner.fuzzy_alignment", "logger.debug", "zip", "str"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.match_candidates.get_match_candidates", "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.get_triple_info", "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.exact_alignment", "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.fuzzy_alignment"], ["", "", "def", "align_words", "(", "self", ")", ":", "\n", "# For debug", "\n", "        ", "logger", ".", "debug", "(", "'Aligning '", "+", "' '", ".", "join", "(", "self", ".", "tokens", ")", ")", "\n", "# Get a 2D list of candidate words for each token/lemma in the sentence", "\n", "self", ".", "wlist_candidates", "=", "[", "get_match_candidates", "(", "t", ",", "l", ")", "for", "t", ",", "l", "in", "zip", "(", "self", ".", "tokens", ",", "self", ".", "lemmas", ")", "]", "\n", "self", ".", "alignments", "=", "[", "None", "]", "*", "len", "(", "self", ".", "wlist_candidates", ")", "# index in tokens", "\n", "# Loop through all triples in the graph and extract the concept", "\n", "for", "t", "in", "self", ".", "graph", ".", "triples", ":", "# (source, role, target)", "\n", "# Get the concept for the triple (this is what's matched to the words in the sentence)", "\n", "            ", "for", "tinfo", "in", "self", ".", "get_triple_info", "(", "t", ")", ":", "\n", "# Try to do an exact match and if that files, do a fuzzy one.", "\n", "                ", "found", "=", "self", ".", "exact_alignment", "(", "tinfo", ")", "\n", "if", "not", "found", ":", "\n", "                    ", "found", "=", "self", ".", "fuzzy_alignment", "(", "tinfo", ")", "\n", "# Print debug info for the triple/concept not aligned to words in the sentence", "\n", "", "if", "not", "found", ":", "\n", "                    ", "logger", ".", "debug", "(", "'Concept not found: '", "+", "tinfo", ".", "concept", ")", "\n", "# Print debug info for sentence words not aligned to concepts/triples", "\n", "", "", "", "if", "logger", ".", "getEffectiveLevel", "(", ")", ">=", "logging", ".", "DEBUG", ":", "\n", "            ", "missing", "=", "[", "t", "for", "t", ",", "a", "in", "zip", "(", "self", ".", "tokens", ",", "self", ".", "alignments", ")", "if", "a", "is", "not", "None", "]", "\n", "if", "missing", ":", "\n", "                ", "logger", ".", "debug", "(", "'Words not aligned to triples: '", "+", "str", "(", "missing", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.get_triple_info": [[95, 130], ["rbw_aligner.RBWAligner.concept_re.match", "t[].lower", "match[].lower", "t[].lower", "rbw_aligner.TInfo", "t[].lower", "concept.replace.replace.replace", "rbw_aligner.TInfo", "rbw_aligner.RBWAligner.extract_edge_role", "rbw_aligner.RBWAligner.extract_edge_role", "rbw_aligner.RBWAligner.graph.variables", "rbw_aligner.TInfo", "rbw_aligner.TInfo"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.extract_edge_role", "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.extract_edge_role", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.SemanticGraph.variables"], ["", "", "", "def", "get_triple_info", "(", "self", ",", "t", ")", ":", "\n", "# fix issue where penman triple can have None in it", "\n", "        ", "if", "None", "in", "t", ":", "\n", "            ", "return", "[", "]", "\n", "# Instance triples are the concept nodes", "\n", "", "if", "t", "[", "1", "]", "==", "penman", ".", "graph", ".", "CONCEPT_ROLE", ":", "# CONCEPT_ROLE = ':instance'", "\n", "            ", "if", "t", "[", "2", "]", ".", "lower", "(", ")", "==", "'multi-sentence'", ":", "# special case to skip", "\n", "                ", "return", "[", "]", "\n", "# remove the word sense from the concept string (ie.. strip -01 from establish-01)", "\n", "", "match", "=", "self", ".", "concept_re", ".", "match", "(", "t", "[", "2", "]", ")", "\n", "if", "match", "is", "not", "None", ":", "\n", "                ", "concept", "=", "match", "[", "1", "]", ".", "lower", "(", ")", "# match returns [fullmatch, g1] where g1 is what proceeds -X", "\n", "", "else", ":", "\n", "                ", "concept", "=", "t", "[", "2", "]", ".", "lower", "(", ")", "\n", "", "return", "[", "TInfo", "(", "t", ",", "concept", ",", "'concept'", ")", "]", "\n", "# Attribute triples are the constant values nodes with an associated role", "\n", "", "elif", "t", "[", "1", "]", "!=", "penman", ".", "graph", ".", "CONCEPT_ROLE", "and", "t", "[", "2", "]", "not", "in", "self", ".", "graph", ".", "variables", "(", ")", ":", "\n", "            ", "if", "t", "[", "1", "]", "==", "':wiki'", ":", "# don't match wiki attributes", "\n", "                ", "return", "[", "]", "\n", "# Get the target value (ie.. the constant value)", "\n", "", "concept", "=", "t", "[", "2", "]", ".", "lower", "(", ")", "\n", "concept", "=", "concept", ".", "replace", "(", "'\"'", ",", "''", ")", "# string attributes are quoted, so remove the quotes", "\n", "concept_tinfo", "=", "TInfo", "(", "t", ",", "concept", ",", "'concept'", ")", "\n", "# Get the edge role", "\n", "role", "=", "self", ".", "extract_edge_role", "(", "t", "[", "1", "]", ")", "\n", "if", "role", "is", "None", ":", "\n", "                ", "return", "[", "concept_tinfo", "]", "\n", "", "else", ":", "\n", "                ", "return", "[", "concept_tinfo", ",", "TInfo", "(", "t", ",", "role", ",", "'role'", ")", "]", "\n", "# Edges are the relations between nodes", "\n", "", "", "else", ":", "\n", "            ", "role", "=", "self", ".", "extract_edge_role", "(", "t", "[", "1", "]", ")", "\n", "if", "role", "is", "None", ":", "\n", "                ", "return", "[", "]", "\n", "", "return", "[", "TInfo", "(", "t", ",", "role", ",", "'role'", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.extract_edge_role": [[132, 142], ["edge.lower.lower.lower", "edge.lower.lower.startswith", "edge.lower.lower.startswith", "role.split"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "", "@", "staticmethod", "\n", "def", "extract_edge_role", "(", "edge", ")", ":", "\n", "        ", "edge", "=", "edge", ".", "lower", "(", ")", "\n", "# skip some generic / utility edges that shouldn't match words", "\n", "if", "edge", "[", ":", "4", "]", "in", "(", "':snt'", ",", "':arg'", ",", "':mod'", ",", "':pos'", ",", "':li'", ",", "':ord'", ",", "':polarity'", ",", "':wiki'", ")", "or", "edge", ".", "startswith", "(", "':op'", ")", "or", "edge", ".", "startswith", "(", "':arg'", ")", ":", "\n", "            ", "return", "None", "\n", "", "role", "=", "edge", "[", "1", ":", "]", "# remove colon from start of edge", "\n", "role", "=", "role", ".", "split", "(", "'-'", ")", "[", "0", "]", "# remove hyphenates", "\n", "return", "role", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.exact_alignment": [[144, 156], ["enumerate", "logger.debug"], "methods", ["None"], ["", "def", "exact_alignment", "(", "self", ",", "tinfo", ")", ":", "\n", "        ", "found", "=", "False", "\n", "for", "i", ",", "candidates", "in", "enumerate", "(", "self", ".", "wlist_candidates", ")", ":", "\n", "            ", "for", "word", "in", "candidates", ":", "\n", "                ", "if", "word", "==", "tinfo", ".", "concept", "and", "self", ".", "alignments", "[", "i", "]", "==", "None", ":", "\n", "                    ", "if", "found", ":", "\n", "                        ", "logger", ".", "debug", "(", "'Duplicate exact match for concept: '", "+", "tinfo", ".", "concept", ")", "\n", "", "else", ":", "\n", "#logger.debug('Exact match found concept: ' + concept + '  word: ' + word)", "\n", "                        ", "self", ".", "alignments", "[", "i", "]", "=", "tinfo", "\n", "", "found", "=", "True", "\n", "", "", "", "return", "found", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.fuzzy_alignment": [[159, 178], ["enumerate", "max", "match_lengths.append", "range", "rbw_aligner.RBWAligner.match_length", "max", "len", "logger.debug"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.match_length"], ["", "def", "fuzzy_alignment", "(", "self", ",", "tinfo", ")", ":", "\n", "        ", "found", "=", "False", "\n", "# Find the best match length", "\n", "match_lengths", "=", "[", "]", "\n", "for", "i", ",", "candidates", "in", "enumerate", "(", "self", ".", "wlist_candidates", ")", ":", "\n", "            ", "ml", "=", "[", "self", ".", "match_length", "(", "w", ",", "tinfo", ".", "concept", ")", "for", "w", "in", "candidates", "]", "\n", "match_lengths", ".", "append", "(", "max", "(", "ml", ")", ")", "\n", "", "max_ml", "=", "max", "(", "match_lengths", ")", "\n", "# Sort out the good candidates", "\n", "if", "max_ml", ">=", "self", ".", "fuzzy_min_ml", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "wlist_candidates", ")", ")", ":", "\n", "                ", "if", "match_lengths", "[", "i", "]", "==", "max_ml", "and", "self", ".", "alignments", "[", "i", "]", "==", "None", ":", "\n", "                    ", "if", "found", ":", "\n", "                        ", "logger", ".", "debug", "(", "'Duplicate fuzzy matches for concept: '", "+", "tinfo", ".", "concept", ")", "\n", "", "else", ":", "\n", "#logger.debug('Fuzzy match found concept: ' + concept + '  word: ' + self.wlist_candidates[i][0])", "\n", "                        ", "self", ".", "alignments", "[", "i", "]", "=", "tinfo", "\n", "", "found", "=", "True", "\n", "", "", "", "return", "found", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.match_length": [[180, 187], ["zip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "match_length", "(", "string1", ",", "string2", ")", ":", "\n", "        ", "length", "=", "0", "\n", "for", "t1", ",", "t2", "in", "zip", "(", "string1", ",", "string2", ")", ":", "\n", "            ", "if", "t1", "==", "t2", ":", "length", "+=", "1", "\n", "else", ":", "break", "\n", "", "return", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.add_surface_alignments": [[189, 199], ["enumerate", "tinfo.is_concept", "rbw_aligner.RBWAligner.graph.epidata[].append", "tinfo.is_role", "penman.surface.Alignment", "rbw_aligner.RBWAligner.graph.epidata[].append", "RuntimeError", "penman.surface.RoleAlignment"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.TInfo.is_concept", "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.TInfo.is_role"], ["", "def", "add_surface_alignments", "(", "self", ")", ":", "\n", "        ", "for", "i", ",", "tinfo", "in", "enumerate", "(", "self", ".", "alignments", ")", ":", "\n", "            ", "if", "tinfo", "is", "None", ":", "\n", "                 ", "continue", "\n", "", "elif", "tinfo", ".", "is_concept", "(", ")", ":", "\n", "                ", "self", ".", "graph", ".", "epidata", "[", "tinfo", ".", "triple", "]", ".", "append", "(", "penman", ".", "surface", ".", "Alignment", "(", "(", "i", ",", ")", ",", "prefix", "=", "self", ".", "align_prefix", ")", ")", "\n", "", "elif", "tinfo", ".", "is_role", "(", ")", ":", "\n", "                ", "self", ".", "graph", ".", "epidata", "[", "tinfo", ".", "triple", "]", ".", "append", "(", "penman", ".", "surface", ".", "RoleAlignment", "(", "(", "i", ",", ")", ",", "prefix", "=", "self", ".", "align_prefix", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "'Invalid alignment type'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.add_alignment_string": [[207, 230], ["cls.get_addresses", "sorted", "cls.align_re.match", "cls.form_single_alignment", "cls.form_single_alignment", "sorted.append", "int", "logger.error", "match[].split"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.get_addresses", "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.form_single_alignment", "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.form_single_alignment", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "", "", "@", "classmethod", "\n", "def", "add_alignment_string", "(", "cls", ",", "graph", ",", "align_key", "=", "'alignments'", ")", ":", "\n", "        ", "results", "=", "cls", ".", "get_addresses", "(", "graph", ")", "\n", "alignments", "=", "[", "]", "\n", "# Loop through the results", "\n", "for", "result", "in", "results", ":", "\n", "            ", "match", "=", "cls", ".", "align_re", ".", "match", "(", "result", ".", "name", ")", "\n", "if", "match", ":", "\n", "                ", "is_role", "=", "True", "if", "result", ".", "type", "==", "'role'", "else", "False", "\n", "try", ":", "\n", "                    ", "tnums", "=", "[", "int", "(", "n", ")", "for", "n", "in", "match", "[", "2", "]", ".", "split", "(", "','", ")", "]", "# alignments are a comma separated list", "\n", "", "except", ":", "\n", "                    ", "logger", ".", "error", "(", "'Failed to convert to tnums: %s'", "%", "result", ".", "name", ")", "\n", "tnums", "=", "[", "]", "\n", "", "for", "tnum", "in", "tnums", ":", "\n", "                    ", "sort_key", "=", "cls", ".", "form_single_alignment", "(", "tnum", ",", "result", ".", "addr", ",", "is_role", ",", "True", ")", "\n", "align_str", "=", "cls", ".", "form_single_alignment", "(", "tnum", ",", "result", ".", "addr", ",", "is_role", ",", "False", ")", "\n", "alignments", ".", "append", "(", "(", "sort_key", ",", "align_str", ")", ")", "\n", "# Sort by the token number", "\n", "", "", "", "alignments", "=", "sorted", "(", "alignments", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "align_strings", "=", "[", "x", "[", "1", "]", "for", "x", "in", "alignments", "]", "\n", "align_string", "=", "' '", ".", "join", "(", "align_strings", ")", "\n", "graph", ".", "metadata", "[", "align_key", "]", "=", "align_string", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.form_single_alignment": [[232, 241], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "form_single_alignment", "(", "tnum", ",", "address", ",", "is_role", ",", "for_sorting", ")", ":", "\n", "        ", "if", "for_sorting", ":", "\n", "            ", "string", "=", "'%03d-%s'", "%", "(", "tnum", ",", "address", ")", "# normal sorting puts '10-' before '2-'", "\n", "", "else", ":", "\n", "            ", "string", "=", "'%d-%s'", "%", "(", "tnum", ",", "address", ")", "\n", "", "if", "is_role", ":", "\n", "            ", "string", "+=", "'.r'", "\n", "", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.get_addresses": [[244, 265], ["penman.configure", "cls.walk_tree", "results.append", "penman.tree.is_atomic", "types.SimpleNamespace", "penman.models.noop.NoOpModel", "concept.startswith", "penman.tree.is_atomic", "rbw_aligner.RBWAligner.get_addresses.add_result"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.walk_tree"], ["", "@", "classmethod", "\n", "def", "get_addresses", "(", "cls", ",", "graph", ")", ":", "\n", "        ", "results", "=", "[", "]", "\n", "def", "add_result", "(", "addr", ",", "name", ",", "type", ")", ":", "\n", "            ", "results", ".", "append", "(", "SimpleNamespace", "(", "addr", "=", "addr", ",", "name", "=", "name", ",", "type", "=", "type", ")", ")", "\n", "", "tree", "=", "penman", ".", "configure", "(", "graph", ",", "model", "=", "NoOpModel", "(", ")", ")", "\n", "for", "path", ",", "branch", "in", "cls", ".", "walk_tree", "(", "tree", ".", "node", ",", "(", "1", ",", ")", ")", ":", "\n", "# Get the node and attribute addresses", "\n", "            ", "if", "penman", ".", "tree", ".", "is_atomic", "(", "branch", "[", "1", "]", ")", ":", "# ==> is None or isinstance(x, (str, int, float))", "\n", "                ", "address", "=", "'.'", ".", "join", "(", "map", "(", "str", ",", "path", ")", ")", "\n", "concept", "=", "branch", "[", "1", "]", "\n", "if", "concept", ".", "startswith", "(", "'\"'", ")", ":", "# Attribute", "\n", "                    ", "add_result", "(", "address", ",", "concept", ",", "'attrib'", ")", "\n", "", "else", ":", "\n", "                    ", "add_result", "(", "address", ",", "concept", ",", "'node'", ")", "\n", "# Get the edge addresses", "\n", "", "", "if", "penman", ".", "tree", ".", "is_atomic", "(", "branch", "[", "0", "]", ")", "and", "branch", "[", "0", "]", "!=", "'/'", ":", "\n", "                ", "address", "=", "'.'", ".", "join", "(", "map", "(", "str", ",", "path", ")", ")", "\n", "edge_name", "=", "branch", "[", "0", "]", "\n", "add_result", "(", "address", ",", "edge_name", ",", "'role'", ")", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.walk_tree": [[267, 279], ["enumerate", "penman.tree.is_atomic", "cls.walk_tree"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.walk_tree"], ["", "@", "classmethod", "\n", "def", "walk_tree", "(", "cls", ",", "node", ",", "path", ")", ":", "\n", "        ", "var", ",", "branches", "=", "node", "\n", "for", "i", ",", "branch", "in", "enumerate", "(", "branches", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "curpath", "=", "path", "\n", "", "else", ":", "\n", "                ", "curpath", "=", "path", "+", "(", "i", ",", ")", "\n", "", "yield", "(", "curpath", ",", "branch", ")", "\n", "_", ",", "target", "=", "branch", "\n", "if", "not", "penman", ".", "tree", ".", "is_atomic", "(", "target", ")", ":", "\n", "                ", "yield", "from", "cls", ".", "walk_tree", "(", "target", ",", "curpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.TInfo.__init__": [[282, 287], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "triple", ",", "concept", ",", "atype", ")", ":", "\n", "        ", "assert", "atype", "in", "(", "'concept'", ",", "'role'", ")", "\n", "self", ".", "triple", "=", "triple", "# penman triple tuple (source, role, target)", "\n", "self", ".", "concept", "=", "concept", "# concept or role", "\n", "self", ".", "atype", "=", "atype", "# align to concept (aka node) or role (aka edge)", "\n", "", "def", "is_concept", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.TInfo.is_concept": [[287, 289], ["None"], "methods", ["None"], ["", "def", "is_concept", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "atype", "==", "'concept'", "\n", "", "def", "is_role", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.TInfo.is_role": [[289, 291], ["None"], "methods", ["None"], ["", "def", "is_role", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "atype", "==", "'role'", "\n", "", "def", "__str__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.TInfo.__str__": [[291, 293], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "'%s / %s / %s'", "%", "(", "self", ".", "triple", ",", "self", ".", "concept", ",", "self", ".", "atype", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.isi_aligner.transpose-ttable.transpose_ttable": [[5, 30], ["numpy.zeros", "numpy.nonzero", "open", "open", "max", "max", "open", "range", "line.strip().split", "line.strip().split", "range", "int", "float", "int", "float", "line.strip", "line.strip", "fout.write", "int", "int", "int"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["def", "transpose_ttable", "(", "t0_fn", ",", "t1_fn", ",", "tout_fn", ")", ":", "\n", "    ", "TSIZE", "=", "11000", "\n", "p", "=", "numpy", ".", "zeros", "(", "shape", "=", "(", "TSIZE", ",", "TSIZE", ")", ",", "dtype", "=", "'double'", ")", "\n", "\n", "with", "open", "(", "t0_fn", ")", "as", "fin0", ":", "\n", "        ", "for", "line", "in", "fin0", ":", "\n", "            ", "a", ",", "b", ",", "val", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "int", "(", "a", ")", "==", "0", ":", "\n", "                ", "p", "[", "0", "]", "[", "int", "(", "b", ")", "]", "=", "float", "(", "val", ")", "\n", "", "else", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "with", "open", "(", "t1_fn", ")", "as", "fin1", ":", "\n", "        ", "for", "line", "in", "fin1", ":", "\n", "            ", "a", ",", "b", ",", "val", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "if", "int", "(", "b", ")", "!=", "0", ":", "\n", "                ", "p", "[", "int", "(", "b", ")", "]", "[", "int", "(", "a", ")", "]", "=", "float", "(", "val", ")", "\n", "\n", "", "", "", "i", ",", "j", "=", "numpy", ".", "nonzero", "(", "p", ")", "\n", "max_i", ",", "max_j", "=", "max", "(", "i", ")", ",", "max", "(", "j", ")", "\n", "with", "open", "(", "tout_fn", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "for", "i", "in", "range", "(", "max_i", "+", "1", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "max_j", "+", "1", ")", ":", "\n", "                ", "if", "p", "[", "i", "]", "[", "j", "]", ">", "0.000000001", ":", "\n", "                    ", "fout", ".", "write", "(", "'%d %d %f\\n'", "%", "(", "i", ",", "j", ",", "p", "[", "i", "]", "[", "j", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.isi_aligner.transpose-adtable.transpose_adtable": [[6, 43], ["numpy.zeros", "numpy.zeros", "open", "open", "open", "range", "open", "range", "line.strip().split", "float", "line.strip().split", "float", "range", "range", "int", "int", "range", "range", "line.strip", "line.strip", "fout.write", "fout.write"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["def", "transpose_adtable", "(", "ain_fn", ",", "din_fn", ",", "aout_fn", ",", "dout_fn", ")", ":", "\n", "    ", "TSIZE", "=", "220", "\n", "HALF", "=", "110", "\n", "a", "=", "numpy", ".", "zeros", "(", "shape", "=", "(", "TSIZE", ",", "TSIZE", ",", "TSIZE", ")", ",", "dtype", "=", "'double'", ")", "\n", "d", "=", "numpy", ".", "zeros", "(", "shape", "=", "(", "TSIZE", ",", "TSIZE", ",", "TSIZE", ")", ",", "dtype", "=", "'double'", ")", "\n", "\n", "# eg.. 1 1 3 100 0.25", "\n", "with", "open", "(", "ain_fn", ")", "as", "fin", ":", "\n", "        ", "for", "line", "in", "fin", ":", "\n", "            ", "parts", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "a1", ",", "a2", ",", "a3", ",", "a4", "=", "[", "int", "(", "a", ")", "for", "a", "in", "parts", "[", ":", "4", "]", "]", "\n", "a", "[", "a1", "]", "[", "a2", "]", "[", "a3", "]", "=", "float", "(", "parts", "[", "4", "]", ")", "\n", "\n", "# eg.. 1 1 3 100 0.25", "\n", "", "", "with", "open", "(", "din_fn", ")", "as", "fin", ":", "\n", "        ", "for", "line", "in", "fin", ":", "\n", "            ", "parts", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "a1", ",", "a2", ",", "a3", ",", "a4", "=", "[", "int", "(", "a", ")", "for", "a", "in", "parts", "[", ":", "4", "]", "]", "\n", "d", "[", "a1", "]", "[", "a2", "]", "[", "a4", "]", "=", "float", "(", "parts", "[", "4", "]", ")", "\n", "\n", "# for (int i = 0; i < 110; i++) for (int j = 0; j < 110; j++) for (int k = 0; k < 110; k++) if (d[k][j][i] > 0) {", "\n", "#   fout0 << j << \" \" << k << \" \" << i << \" \" << \"100\" << \" \" << d[k][j][i] << endl;", "\n", "", "", "with", "open", "(", "aout_fn", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "for", "i", "in", "range", "(", "HALF", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "HALF", ")", ":", "\n", "                ", "for", "k", "in", "range", "(", "HALF", ")", ":", "\n", "                    ", "if", "d", "[", "k", "]", "[", "j", "]", "[", "i", "]", ">", "0", ":", "\n", "                        ", "fout", ".", "write", "(", "'%d %d %d %d %f\\n'", "%", "(", "j", ",", "k", ",", "i", ",", "100", ",", "d", "[", "k", "]", "[", "j", "]", "[", "i", "]", ")", ")", "\n", "\n", "# for (int i = 0; i < 110; i++) for (int j = 0; j < 110; j++) for (int k = 0; k < 110; k++) if (a[k][j][i] > 0) {", "\n", "#   fout1 << j << \" \" << k << \" \"  << \"100\" << \" \" << i << \" \" << a[k][j][i] << endl;", "\n", "", "", "", "", "", "with", "open", "(", "dout_fn", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "for", "i", "in", "range", "(", "HALF", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "HALF", ")", ":", "\n", "                ", "for", "k", "in", "range", "(", "HALF", ")", ":", "\n", "                    ", "if", "a", "[", "k", "]", "[", "j", "]", "[", "i", "]", ">", "0", ":", "\n", "                        ", "fout", ".", "write", "(", "'%d %d %d %d %f\\n'", "%", "(", "j", ",", "k", ",", "100", ",", "i", ",", "a", "[", "k", "]", "[", "j", "]", "[", "i", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.trainer.Trainer.__init__": [[7, 38], ["os.environ.get", "kwargs.get", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "fwd_cmd.split", "rev_cmd.split", "tools_cmd.split"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["    ", "def", "__init__", "(", "self", ",", "in_fpath", ",", "out_dir", ",", "**", "kwargs", ")", ":", "\n", "# If the bin_dir is not provided, get it from the environment, but default to ''", "\n", "# which means it must be in the path", "\n", "        ", "bin_dir", "=", "os", ".", "environ", ".", "get", "(", "'FABIN_DIR'", ",", "''", ")", "\n", "bin_dir", "=", "kwargs", ".", "get", "(", "'bin_dir'", ",", "bin_dir", ")", "\n", "self", ".", "fwd_out", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'fa_out_fwd.txt'", ")", "\n", "self", ".", "rev_out", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'fa_out_rev.txt'", ")", "\n", "self", ".", "final_out", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'model_out.txt'", ")", "\n", "self", ".", "fwd_params", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'fwd_params'", ")", "\n", "self", ".", "rev_params", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'rev_params'", ")", "\n", "self", ".", "fwd_err", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'fwd_err'", ")", "\n", "self", ".", "rev_err", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'rev_err'", ")", "\n", "self", ".", "param_fn", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'train_params.json'", ")", "\n", "fast_align", "=", "os", ".", "path", ".", "join", "(", "bin_dir", ",", "'fast_align'", ")", "\n", "atools", "=", "os", ".", "path", ".", "join", "(", "bin_dir", ",", "'atools'", ")", "\n", "p", "=", "{", "}", "\n", "p", "[", "'I'", "]", "=", "kwargs", ".", "get", "(", "'I'", ",", "5", ")", "\n", "p", "[", "'q'", "]", "=", "kwargs", ".", "get", "(", "'q'", ",", "0.08", ")", "\n", "p", "[", "'a'", "]", "=", "kwargs", ".", "get", "(", "'a'", ",", "0.01", ")", "\n", "p", "[", "'T'", "]", "=", "kwargs", ".", "get", "(", "'T'", ",", "4", ")", "\n", "p", "[", "'heuristic'", "]", "=", "kwargs", ".", "get", "(", "'heuristic'", ",", "'grow-diag-final-and'", ")", "\n", "self", ".", "params", "=", "p", "\n", "# Create the actual commands to execute", "\n", "fwd_cmd", "=", "'%s -i %s -d -o -v -I %d -q %f -a %f -T %d -p %s'", "%", "(", "fast_align", ",", "in_fpath", ",", "p", "[", "'I'", "]", ",", "p", "[", "'q'", "]", ",", "p", "[", "'a'", "]", ",", "p", "[", "'T'", "]", ",", "self", ".", "fwd_params", ")", "\n", "rev_cmd", "=", "'%s -i %s -d -o -v -I %d -q %f -a %f -T %d -p %s -r'", "%", "(", "fast_align", ",", "in_fpath", ",", "p", "[", "'I'", "]", ",", "p", "[", "'q'", "]", ",", "p", "[", "'a'", "]", ",", "p", "[", "'T'", "]", ",", "self", ".", "rev_params", ")", "\n", "tools_cmd", "=", "'%s -i %s -j %s -c %s'", "%", "(", "atools", ",", "self", ".", "fwd_out", ",", "self", ".", "rev_out", ",", "p", "[", "'heuristic'", "]", ")", "\n", "self", ".", "fwd_cmd", "=", "fwd_cmd", ".", "split", "(", ")", "\n", "self", ".", "rev_cmd", "=", "rev_cmd", ".", "split", "(", ")", "\n", "self", ".", "tools_cmd", "=", "tools_cmd", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.trainer.Trainer.train": [[39, 53], ["trainer.Trainer.read_err", "trainer.Trainer.read_err", "open", "open", "subprocess.run", "open", "open", "subprocess.run", "open", "subprocess.run", "open", "json.dump"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.trainer.Trainer.read_err", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.trainer.Trainer.read_err", "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run", "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run", "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run"], ["", "def", "train", "(", "self", ")", ":", "\n", "# Run the training", "\n", "        ", "with", "open", "(", "self", ".", "fwd_out", ",", "'w'", ")", "as", "fout", ",", "open", "(", "self", ".", "fwd_err", ",", "'w'", ")", "as", "ferr", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "fwd_cmd", ",", "stdout", "=", "fout", ",", "stderr", "=", "ferr", ")", "\n", "", "with", "open", "(", "self", ".", "rev_out", ",", "'w'", ")", "as", "fout", ",", "open", "(", "self", ".", "rev_err", ",", "'w'", ")", "as", "ferr", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "rev_cmd", ",", "stdout", "=", "fout", ",", "stderr", "=", "ferr", ")", "\n", "", "with", "open", "(", "self", ".", "final_out", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "tools_cmd", ",", "stdout", "=", "fout", ")", "\n", "# Get a few final parameters", "\n", "", "self", ".", "params", "[", "'fwd_T'", "]", ",", "self", ".", "params", "[", "'fwd_m'", "]", "=", "self", ".", "read_err", "(", "self", ".", "fwd_err", ")", "\n", "self", ".", "params", "[", "'rev_T'", "]", ",", "self", ".", "params", "[", "'rev_m'", "]", "=", "self", ".", "read_err", "(", "self", ".", "rev_err", ")", "\n", "# Save the parameters for use during inference", "\n", "with", "open", "(", "self", ".", "param_fn", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "params", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.trainer.Trainer.read_err": [[54, 65], ["open", "float", "float", "line.split", "line.split"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "", "def", "read_err", "(", "self", ",", "err", ")", ":", "\n", "        ", "T", ",", "m", "=", "''", ",", "''", "\n", "with", "open", "(", "err", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "# expected target length = source length * N", "\n", "                ", "if", "'expected target length'", "in", "line", ":", "\n", "                    ", "m", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "# final tension: N", "\n", "", "elif", "'final tension'", "in", "line", ":", "\n", "                    ", "T", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "", "", "", "return", "float", "(", "T", ")", ",", "float", "(", "m", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.postprocess.postprocess": [[13, 36], ["process_utils.giza2isi", "len", "process_utils.map_ibmpos_to_origpos_amr_as_f", "process_utils.get_aligned_tuple_amr_as_f_add_align", "feat2tree.align", "get_alignments.GetAlignments.from_amr_strings", "GetAlignments.from_amr_strings.get_alignments", "l.strip().replace", "process_utils.swap", "len", "len", "l.strip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.giza2isi", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.map_ibmpos_to_origpos_amr_as_f", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.get_aligned_tuple_amr_as_f_add_align", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.align", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.from_amr_strings", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.get_alignments", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.swap"], ["def", "postprocess", "(", "data", ",", "**", "kwargs", ")", ":", "\n", "# Read the output of the aligner or use the supplied input above", "\n", "# fast_align outputs with a dash but the code from the isi aligner is setup for spaces", "\n", "    ", "giza_align_lines", "=", "[", "l", ".", "strip", "(", ")", ".", "replace", "(", "'-'", ",", "' '", ")", "for", "l", "in", "data", ".", "model_out_lines", "]", "\n", "isi_align_lines", "=", "giza2isi", "(", "giza_align_lines", ")", "\n", "num_lines", "=", "len", "(", "data", ".", "amr_lines", ")", "\n", "align_real_lines", "=", "swap", "(", "isi_align_lines", ")", "[", ":", "num_lines", "]", "# rm data added for training, past original sentences", "\n", "\n", "# Align the original position lines", "\n", "align_origpos_lines", "=", "map_ibmpos_to_origpos_amr_as_f", "(", "data", ".", "eng_tok_origpos_lines", ",", "align_real_lines", ")", "\n", "\n", "# Get the aligned tuples", "\n", "aligned_tuple_lines", "=", "get_aligned_tuple_amr_as_f_add_align", "(", "data", ".", "amr_tuple_lines", ",", "align_origpos_lines", ")", "\n", "\n", "# Create amr graphs with surface alignments", "\n", "amr_surface_aligns", "=", "feat2tree", ".", "align", "(", "data", ".", "amr_lines", ",", "aligned_tuple_lines", ")", "\n", "assert", "len", "(", "amr_surface_aligns", ")", "==", "len", "(", "data", ".", "amr_lines", ")", "\n", "\n", "# Get the final alignment string from the surface alignments", "\n", "ga", "=", "GetAlignments", ".", "from_amr_strings", "(", "amr_surface_aligns", ")", "\n", "alignment_strings", "=", "ga", ".", "get_alignments", "(", ")", "\n", "\n", "return", "amr_surface_aligns", ",", "alignment_strings", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.__init__": [[8, 17], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "eng_lines", "=", "None", ",", "amr_lines", "=", "None", ",", "\n", "eng_tok_origpos_lines", "=", "None", ",", "amr_tuple_lines", "=", "None", ",", "\n", "eng_preproc_lines", "=", "None", ",", "amr_preproc_lines", "=", "None", ")", ":", "\n", "        ", "self", ".", "eng_lines", "=", "eng_lines", "\n", "self", ".", "amr_lines", "=", "amr_lines", "\n", "self", ".", "eng_tok_origpos_lines", "=", "eng_tok_origpos_lines", "\n", "self", ".", "amr_tuple_lines", "=", "amr_tuple_lines", "\n", "self", ".", "eng_preproc_lines", "=", "eng_preproc_lines", "\n", "self", ".", "amr_preproc_lines", "=", "amr_preproc_lines", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save": [[19, 29], ["proc_data.ProcData.build_filenames", "proc_data.ProcData.save_lines", "proc_data.ProcData.save_lines", "proc_data.ProcData.save_lines", "proc_data.ProcData.save_lines", "open", "zip", "f.write"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.build_filenames", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save_lines", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save_lines", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save_lines", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save_lines"], ["", "def", "save", "(", "self", ",", "wk_dir", ",", "save_input_data", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "build_filenames", "(", "wk_dir", ",", "**", "kwargs", ")", "\n", "if", "save_input_data", ":", "\n", "            ", "self", ".", "save_lines", "(", "self", ".", "eng_fn", ",", "self", ".", "eng_lines", ")", "\n", "self", ".", "save_lines", "(", "self", ".", "amr_fn", ",", "self", ".", "amr_lines", ")", "\n", "", "self", ".", "save_lines", "(", "self", ".", "eng_tok_pos_fn", ",", "self", ".", "eng_tok_origpos_lines", ")", "\n", "self", ".", "save_lines", "(", "self", ".", "amr_tuple_fn", ",", "self", ".", "amr_tuple_lines", ")", "\n", "with", "open", "(", "self", ".", "fa_in_fn", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "for", "en_line", ",", "amr_line", "in", "zip", "(", "self", ".", "eng_preproc_lines", ",", "self", ".", "amr_preproc_lines", ")", ":", "\n", "                ", "f", ".", "write", "(", "'%s ||| %s\\n'", "%", "(", "en_line", ",", "amr_line", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.from_directory": [[31, 41], ["cls", "cls.build_filenames", "cls.load_lines", "cls.load_lines", "cls.load_lines", "cls.load_lines", "cls.load_lines"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.build_filenames", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.load_lines", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.load_lines", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.load_lines", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.load_lines", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.load_lines"], ["", "", "", "@", "classmethod", "\n", "def", "from_directory", "(", "cls", ",", "wk_dir", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", "=", "cls", "(", ")", "\n", "self", ".", "build_filenames", "(", "wk_dir", ",", "**", "kwargs", ")", "\n", "self", ".", "eng_lines", "=", "self", ".", "load_lines", "(", "self", ".", "eng_fn", ")", "\n", "self", ".", "amr_lines", "=", "self", ".", "load_lines", "(", "self", ".", "amr_fn", ")", "\n", "self", ".", "eng_tok_origpos_lines", "=", "self", ".", "load_lines", "(", "self", ".", "eng_tok_pos_fn", ")", "\n", "self", ".", "amr_tuple_lines", "=", "self", ".", "load_lines", "(", "self", ".", "amr_tuple_fn", ")", "\n", "self", ".", "model_out_lines", "=", "self", ".", "load_lines", "(", "self", ".", "model_out_fn", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.build_filenames": [[43, 50], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get"], "methods", ["None"], ["", "def", "build_filenames", "(", "self", ",", "wk_dir", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "eng_fn", "=", "os", ".", "path", ".", "join", "(", "wk_dir", ",", "kwargs", ".", "get", "(", "'eng_fn'", ",", "'sents.txt'", ")", ")", "\n", "self", ".", "amr_fn", "=", "os", ".", "path", ".", "join", "(", "wk_dir", ",", "kwargs", ".", "get", "(", "'amr_fn'", ",", "'gstrings.txt'", ")", ")", "\n", "self", ".", "eng_tok_pos_fn", "=", "os", ".", "path", ".", "join", "(", "wk_dir", ",", "kwargs", ".", "get", "(", "'eng_tok_pos_fn'", ",", "'eng_tok_origpos.txt'", ")", ")", "\n", "self", ".", "amr_tuple_fn", "=", "os", ".", "path", ".", "join", "(", "wk_dir", ",", "kwargs", ".", "get", "(", "'amr_tuple_fn'", ",", "'amr_tuple.txt'", ")", ")", "\n", "self", ".", "fa_in_fn", "=", "os", ".", "path", ".", "join", "(", "wk_dir", ",", "kwargs", ".", "get", "(", "'fa_in_fn'", ",", "'fa_in.txt'", ")", ")", "\n", "self", ".", "model_out_fn", "=", "os", ".", "path", ".", "join", "(", "wk_dir", ",", "kwargs", ".", "get", "(", "'model_out_fn'", ",", "'model_out.txt'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save_lines": [[52, 57], ["open", "f.write"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "save_lines", "(", "fn", ",", "lines", ")", ":", "\n", "        ", "with", "open", "(", "fn", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "lines", ":", "\n", "                ", "f", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.load_lines": [[59, 64], ["open", "l.strip"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "load_lines", "(", "fn", ")", ":", "\n", "        ", "with", "open", "(", "fn", ")", "as", "f", ":", "\n", "            ", "lines", "=", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "f", "]", "\n", "", "return", "lines", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.preprocess.preprocess_infer": [[15, 51], ["kwargs.get", "kwargs.get", "kwargs.get", "process_utils.filter_eng_by_stopwords", "process_utils.get_lineartok_with_rel", "proc_data.ProcData", "len", "len", "os.path.join", "os.path.join", "kwargs.get", "enumerate", "process_utils.stem_4_letters_line", "line.split", "amr_preproc_lines.append", "len", "len", "re.sub", "stem_4_letters_word().strip.replace", "process_utils.stem_4_letters_word().strip", "new_tokens.append", "line.strip", "ValueError", "process_utils.stem_4_letters_word"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.filter_eng_by_stopwords", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.get_lineartok_with_rel", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.stem_4_letters_line", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.stem_4_letters_word"], ["def", "preprocess_infer", "(", "eng_lines", ",", "amr_lines", ",", "**", "kwargs", ")", ":", "\n", "    ", "assert", "len", "(", "eng_lines", ")", "==", "len", "(", "amr_lines", ")", "\n", "# Resource filenames", "\n", "res_dir", "=", "kwargs", ".", "get", "(", "'res_dir'", ",", "default_res_dir", ")", "\n", "eng_sw_fn", "=", "kwargs", ".", "get", "(", "'eng_sw_fn'", ",", "os", ".", "path", ".", "join", "(", "res_dir", ",", "'eng_stopwords.txt'", ")", ")", "\n", "amr_sw_fn", "=", "kwargs", ".", "get", "(", "'amr_sw_fn'", ",", "os", ".", "path", ".", "join", "(", "res_dir", ",", "'amr_stopwords.txt'", ")", ")", "\n", "\n", "# Filter out stopwords from sentences", "\n", "eng_tok_filtered_lines", ",", "eng_tok_origpos_lines", "=", "filter_eng_by_stopwords", "(", "eng_lines", ",", "eng_sw_fn", ")", "\n", "if", "not", "kwargs", ".", "get", "(", "'skip_empty_check'", ",", "False", ")", ":", "\n", "        ", "for", "i", ",", "line", "in", "enumerate", "(", "eng_tok_origpos_lines", ")", ":", "\n", "            ", "if", "not", "line", ".", "strip", "(", ")", ":", "\n", "                ", "raise", "ValueError", "(", "'!!! ERROR Empty line# %d. This will cause issues and must be fixed !!!'", "%", "i", ")", "\n", "\n", "# Stem sentence tokens", "\n", "", "", "", "eng_preproc_lines", "=", "[", "stem_4_letters_line", "(", "l", ")", "for", "l", "in", "eng_tok_filtered_lines", "]", "\n", "\n", "# Process the AMR data / remove stopwords", "\n", "amr_linear_lines", ",", "amr_tuple_lines", "=", "get_lineartok_with_rel", "(", "amr_lines", ",", "amr_sw_fn", ")", "\n", "\n", "# Stem the AMR lines", "\n", "amr_preproc_lines", "=", "[", "]", "\n", "for", "line", "in", "amr_linear_lines", ":", "\n", "        ", "new_tokens", "=", "[", "]", "\n", "for", "token", "in", "line", ".", "split", "(", ")", ":", "\n", "            ", "token", "=", "re", ".", "sub", "(", "r'\\-[0-9]{2,3}$'", ",", "''", ",", "token", ")", "\n", "token", "=", "token", ".", "replace", "(", "'\"'", ",", "''", ")", "\n", "token", "=", "stem_4_letters_word", "(", "token", ")", ".", "strip", "(", ")", "\n", "new_tokens", ".", "append", "(", "token", ")", "\n", "", "amr_preproc_lines", ".", "append", "(", "' '", ".", "join", "(", "new_tokens", ")", ")", "\n", "\n", "# Gather the data", "\n", "", "assert", "len", "(", "eng_preproc_lines", ")", "==", "len", "(", "amr_preproc_lines", ")", "\n", "data", "=", "ProcData", "(", "eng_lines", ",", "amr_lines", ",", "eng_tok_origpos_lines", ",", "amr_tuple_lines", ",", "\n", "eng_preproc_lines", ",", "amr_preproc_lines", ",", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.preprocess.preprocess_train": [[55, 105], ["kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "preprocess.preprocess_infer", "process_utils.get_id_mapping_uniq", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "process_utils.stem_4_letters_line", "open", "process_utils.stem_4_letters_line", "open", "len", "len", "l.strip", "x.split", "process_utils.stem_4_letters_line", "x.split", "process_utils.stem_4_letters_line", "range", "range", "l.strip", "l.strip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.preprocess.preprocess_infer", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.get_id_mapping_uniq", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.stem_4_letters_line", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.stem_4_letters_line", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.stem_4_letters_line", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.stem_4_letters_line"], ["", "def", "preprocess_train", "(", "eng_lines", ",", "amr_lines", ",", "**", "kwargs", ")", ":", "\n", "    ", "repeat_td", "=", "kwargs", ".", "get", "(", "'repeat_td'", ",", "10", ")", "# 10X is original value from isi aligner", "\n", "# Resource filenames", "\n", "res_dir", "=", "kwargs", ".", "get", "(", "'res_dir'", ",", "default_res_dir", ")", "\n", "prep_roles_fn", "=", "kwargs", ".", "get", "(", "'prep_roles_fn'", ",", "os", ".", "path", ".", "join", "(", "res_dir", ",", "'prep-roles_id.txt'", ")", ")", "\n", "eng_id_map_fn", "=", "kwargs", ".", "get", "(", "'eng_id_map_fn'", ",", "os", ".", "path", ".", "join", "(", "res_dir", ",", "'eng_id_map.txt'", ")", ")", "\n", "amr_id_map_fn", "=", "kwargs", ".", "get", "(", "'amr_id_map_fn'", ",", "os", ".", "path", ".", "join", "(", "res_dir", ",", "'amr_id_map.txt'", ")", ")", "\n", "\n", "# Run the inference process which creates the basic translation data", "\n", "data", "=", "preprocess_infer", "(", "eng_lines", ",", "amr_lines", ",", "**", "kwargs", ")", "\n", "eng_preproc_lines", "=", "data", ".", "eng_preproc_lines", "\n", "amr_preproc_lines", "=", "data", ".", "amr_preproc_lines", "\n", "\n", "# Get tokens common between the two datasets (obvious translations", "\n", "common_tok_lines", "=", "get_id_mapping_uniq", "(", "eng_preproc_lines", ",", "amr_preproc_lines", ")", "\n", "eng_td_lines", "=", "common_tok_lines", "[", ":", "]", "# copy", "\n", "\n", "# Append the second field in prep-roles.id.txt", "\n", "res_fn", "=", "os", ".", "path", ".", "join", "(", "res_dir", ",", "'prep-roles_id.txt'", ")", "\n", "with", "open", "(", "res_fn", ")", "as", "f", ":", "\n", "        ", "prep_roles_lines", "=", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "f", "]", "\n", "", "add_lines", "=", "[", "x", ".", "split", "(", ")", "[", "1", "]", "for", "x", "in", "prep_roles_lines", "]", "\n", "add_lines", "=", "[", "stem_4_letters_line", "(", "l", ")", "for", "l", "in", "add_lines", "]", "\n", "eng_td_lines", "=", "eng_td_lines", "+", "add_lines", "\n", "\n", "# Append some custom translations data", "\n", "with", "open", "(", "eng_id_map_fn", ")", "as", "f", ":", "\n", "        ", "add_lines", "=", "[", "stem_4_letters_line", "(", "l", ".", "strip", "(", ")", ")", "for", "l", "in", "f", "]", "\n", "", "eng_td_lines", "=", "eng_td_lines", "+", "add_lines", "\n", "\n", "# Get a copy of the original common_tok_lines data", "\n", "amr_td_lines", "=", "common_tok_lines", "[", ":", "]", "\n", "\n", "# Append the first field in prep-roles.id.txt", "\n", "add_lines", "=", "[", "x", ".", "split", "(", ")", "[", "0", "]", "for", "x", "in", "prep_roles_lines", "]", "# loaded above", "\n", "add_lines", "=", "[", "stem_4_letters_line", "(", "l", ")", "for", "l", "in", "add_lines", "]", "\n", "amr_td_lines", "=", "amr_td_lines", "+", "add_lines", "\n", "\n", "# Append some custom translation data", "\n", "with", "open", "(", "amr_id_map_fn", ")", "as", "f", ":", "\n", "        ", "add_lines", "=", "[", "stem_4_letters_line", "(", "l", ".", "strip", "(", ")", ")", "for", "l", "in", "f", "]", "\n", "", "amr_td_lines", "=", "amr_td_lines", "+", "add_lines", "\n", "\n", "# Create the final training data using the original sentences", "\n", "# and 10X copies of the additional data (other translations)", "\n", "data", ".", "eng_preproc_lines", "+=", "[", "l", "for", "_", "in", "range", "(", "repeat_td", ")", "for", "l", "in", "eng_td_lines", "]", "\n", "data", ".", "amr_preproc_lines", "+=", "[", "l", "for", "_", "in", "range", "(", "repeat_td", ")", "for", "l", "in", "amr_td_lines", "]", "\n", "assert", "len", "(", "data", ".", "eng_preproc_lines", ")", "==", "len", "(", "data", ".", "amr_preproc_lines", ")", "\n", "\n", "return", "data", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.stem_4_letters_word": [[11, 13], ["w.startswith", "w.startswith", "w.endswith"], "function", ["None"], ["def", "stem_4_letters_word", "(", "w", ")", ":", "\n", "    ", "return", "w", "if", "w", ".", "startswith", "(", "':'", ")", "or", "(", "w", ".", "startswith", "(", "'++'", ")", "and", "w", ".", "endswith", "(", "'++'", ")", ")", "else", "w", "[", ":", "3", "]", "\n", "", "def", "stem_4_letters_line", "(", "line", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.stem_4_letters_line": [[13, 15], ["process_utils.stem_4_letters_word", "line.strip().split", "line.strip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.stem_4_letters_word", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "stem_4_letters_line", "(", "line", ")", ":", "\n", "    ", "return", "' '", ".", "join", "(", "stem_4_letters_word", "(", "w", ")", "for", "w", "in", "line", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "", "def", "stem_4_letters_string", "(", "string", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.stem_4_letters_string": [[15, 17], ["process_utils.stem_4_letters_line", "string.splitlines"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.stem_4_letters_line"], ["", "def", "stem_4_letters_string", "(", "string", ")", ":", "\n", "    ", "return", "'\\n'", ".", "join", "(", "stem_4_letters_line", "(", "line", ")", "for", "line", "in", "string", ".", "splitlines", "(", ")", ")", "+", "'\\n'", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.filter_eng_by_stopwords": [[20, 34], ["open", "set", "enumerate", "orig_ind_line_list.append", "out_tok_line_list.append", "line.strip().split", "i.strip", "orig_ind_list.append", "out_tok_list.append", "line.strip", "str"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "filter_eng_by_stopwords", "(", "lines", ",", "f_stopwords", ")", ":", "\n", "    ", "orig_ind_line_list", ",", "out_tok_line_list", "=", "[", "]", ",", "[", "]", "\n", "with", "open", "(", "f_stopwords", ")", "as", "f", ":", "\n", "        ", "STOP_SET", "=", "set", "(", "i", ".", "strip", "(", ")", "for", "i", "in", "f", ")", "\n", "", "for", "line", "in", "lines", ":", "\n", "        ", "orig_ind_list", "=", "[", "]", "\n", "out_tok_list", "=", "[", "]", "\n", "for", "ind", ",", "tok", "in", "enumerate", "(", "line", ".", "strip", "(", ")", ".", "split", "(", ")", ")", ":", "\n", "            ", "if", "tok", "not", "in", "STOP_SET", ":", "\n", "                ", "orig_ind_list", ".", "append", "(", "ind", ")", "\n", "out_tok_list", ".", "append", "(", "tok", ")", "\n", "", "", "orig_ind_line_list", ".", "append", "(", "' '", ".", "join", "(", "out_tok_list", ")", ")", "\n", "out_tok_line_list", ".", "append", "(", "' '", ".", "join", "(", "str", "(", "i", ")", "for", "i", "in", "orig_ind_list", ")", ")", "\n", "", "return", "orig_ind_line_list", ",", "out_tok_line_list", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.get_lineartok_with_rel": [[37, 75], ["open", "set", "line.strip().lower.strip().lower", "feat2tree.input_amrparse", "process_utils.get_lineartok_with_rel.getterminal_except_ne"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.input_amrparse"], ["", "def", "get_lineartok_with_rel", "(", "lines", ",", "f_stopwords", ")", ":", "\n", "    ", "ind", "=", "-", "1", "\n", "def", "getterminal_except_ne", "(", "amr", ",", "nt_list", ")", ":", "\n", "        ", "nonlocal", "ind", "# allow modification of variable in outer function", "\n", "if", "(", "not", "amr", ".", "feats", ")", ":", "\n", "            ", "ind", "=", "ind", "+", "1", "\n", "if", "(", "amr", ".", "val", "not", "in", "[", "nt", ".", "val", "for", "nt", "in", "nt_list", "]", ")", ":", "\n", "                ", "return", "[", "(", "amr", ".", "pi", ".", "val", ",", "amr", ".", "pi_edge", ",", "amr", ".", "val", ")", "]", "\n", "", "", "ret", "=", "[", "]", "\n", "for", "f", "in", "amr", ".", "feats", ":", "\n", "            ", "ind", "=", "ind", "+", "1", "\n", "if", "f", ".", "edge", "==", "INSTANCE", ":", "\n", "# as \"company\" in the context of \".. / company :name (..\"", "\n", "                ", "if", "':name'", "in", "[", "ff", ".", "edge", "for", "ff", "in", "amr", ".", "feats", "]", ":", "\n", "                    ", "continue", "\n", "", "if", "f", ".", "node", ".", "val", "==", "'name'", "and", "f", ".", "node", ".", "pi", ".", "pi_edge", "==", "':name'", ":", "\n", "                    ", "continue", "\n", "", "if", "f", ".", "node", ".", "val", "in", "STOP_SET", ":", "\n", "                    ", "continue", "\n", "", "ret", ".", "append", "(", "(", "amr", ".", "val", ",", "INSTANCE", ",", "f", ".", "node", ".", "val", ")", ")", "\n", "", "else", ":", "\n", "                ", "if", "f", ".", "edge", "not", "in", "STOP_SET", ":", "\n", "                    ", "ret", ".", "append", "(", "(", "amr", ".", "val", ",", "f", ".", "edge", ")", ")", "\n", "", "ret", ".", "extend", "(", "getterminal_except_ne", "(", "f", ".", "node", ",", "nt_list", ")", ")", "\n", "", "", "return", "(", "ret", ")", "\n", "", "with", "open", "(", "f_stopwords", ")", "as", "f", ":", "\n", "        ", "STOP_SET", "=", "set", "(", "i", ".", "strip", "(", ")", "for", "i", "in", "f", ")", "\n", "", "count", "=", "0", "\n", "amr_linear_lines", ",", "amr_tuple_lines", "=", "[", "]", ",", "[", "]", "\n", "ds_string2", "=", "''", "\n", "for", "line", "in", "lines", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "count", "+=", "1", "\n", "_", ",", "amr", "=", "input_amrparse", "(", "line", ")", "\n", "t_list", "=", "getterminal_except_ne", "(", "amr", ",", "amr", ".", "get_nonterm_nodes", "(", ")", ")", "\n", "amr_linear_lines", ".", "append", "(", "' '", ".", "join", "(", "i", "[", "-", "1", "]", "for", "i", "in", "t_list", ")", ")", "\n", "amr_tuple_lines", ".", "append", "(", "' '", ".", "join", "(", "'__'", ".", "join", "(", "i", ")", "for", "i", "in", "t_list", ")", ")", "\n", "", "return", "amr_linear_lines", ",", "amr_tuple_lines", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.get_id_mapping_uniq": [[78, 85], ["set", "zip", "list", "line1.strip().split", "line2.strip().split", "set", "set", "line1.strip", "line2.strip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "get_id_mapping_uniq", "(", "lines_1", ",", "lines_2", ")", ":", "\n", "    ", "common", "=", "set", "(", ")", "\n", "for", "line1", ",", "line2", "in", "zip", "(", "lines_1", ",", "lines_2", ")", ":", "\n", "        ", "l1", "=", "line1", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "l2", "=", "line2", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "common", "|=", "set", "(", "l1", ")", "&", "set", "(", "l2", ")", "\n", "", "return", "list", "(", "common", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.map_ibmpos_to_origpos_amr_as_f": [[88, 110], ["enumerate", "zip", "origpos_line.strip().split", "real_line.strip().split", "out_lines.append", "link.split", "logger.warning", "origpos_line.strip", "real_line.strip", "out_link_list.append", "index_errors.append", "int", "int"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "map_ibmpos_to_origpos_amr_as_f", "(", "origpos_lines", ",", "real_lines", ")", ":", "\n", "    ", "out_lines", "=", "[", "]", "\n", "for", "lnum", ",", "(", "origpos_line", ",", "real_line", ")", "in", "enumerate", "(", "zip", "(", "origpos_lines", ",", "real_lines", ")", ")", ":", "\n", "        ", "orig_pos_list", "=", "origpos_line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "out_link_list", "=", "[", "]", "\n", "index_errors", "=", "[", "]", "\n", "for", "link", "in", "real_line", ".", "strip", "(", ")", ".", "split", "(", ")", ":", "\n", "            ", "ibmpos_f", ",", "ibmpos_e", "=", "link", ".", "split", "(", "'-'", ")", "\n", "try", ":", "\n", "                ", "link_line", "=", "ibmpos_f", "+", "'-'", "+", "orig_pos_list", "[", "int", "(", "ibmpos_e", ")", "]", "\n", "out_link_list", ".", "append", "(", "link_line", ")", "\n", "", "except", ":", "\n", "                ", "index_errors", ".", "append", "(", "int", "(", "ibmpos_e", ")", ")", "\n", "", "", "out_lines", ".", "append", "(", "' '", ".", "join", "(", "out_link_list", ")", ")", "\n", "if", "index_errors", ":", "\n", "# A single empty line in tmp.eng.tok.origpos.txt will cause a cascade of errors.  ie.. everything after that point", "\n", "# is screwed up.  I'm guessing that it causes something to shift in the aliger logic but I'm not sure where.", "\n", "# Check for a missing line in tmp.eng.tok.origpos.txt and for original sentences that are only a period or", "\n", "# graphs that are (a / amr-empty)", "\n", "# Note that the run-time code (FAA_aligner.align_sents) will handle these correctly", "\n", "            ", "logger", ".", "warning", "(", "'Indexing error on line %d. Check for empty lines in eng_tok_origpos.txt'", "%", "lnum", ")", "\n", "", "", "return", "out_lines", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.get_aligned_tuple_amr_as_f_add_align": [[113, 138], ["zip", "collections.defaultdict", "align_str.split", "tuple_str.split", "enumerate", "out_lines.append", "align.split", "align_dict[].add", "int", "tuple_one.split", "out.append", "out.append", "len", "out.append", "out.append", "int", "tuple_list[].split", "len", "str", "tuple_list[].split", "str", "str"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "get_aligned_tuple_amr_as_f_add_align", "(", "tuple_str_list", ",", "align_str_list", ")", ":", "\n", "    ", "out_lines", "=", "[", "]", "\n", "for", "tuple_str", ",", "align_str", "in", "zip", "(", "tuple_str_list", ",", "align_str_list", ")", ":", "\n", "# e->f", "\n", "        ", "align_dict", "=", "defaultdict", "(", "set", ")", "\n", "for", "align", "in", "align_str", ".", "split", "(", ")", ":", "\n", "            ", "f", ",", "e", "=", "align", ".", "split", "(", "'-'", ")", "\n", "align_dict", "[", "int", "(", "f", ")", "]", ".", "add", "(", "int", "(", "e", ")", ")", "\n", "", "out", "=", "[", "]", "\n", "tuple_list", "=", "tuple_str", ".", "split", "(", ")", "\n", "\n", "for", "ind", ",", "tuple_one", "in", "enumerate", "(", "tuple_list", ")", ":", "\n", "            ", "concept", "=", "tuple_one", ".", "split", "(", "'__'", ")", "[", "-", "1", "]", "\n", "if", "align_dict", "[", "ind", "]", ":", "\n", "                ", "out", ".", "append", "(", "tuple_one", "+", "'__'", "+", "'e.'", "+", "','", ".", "join", "(", "str", "(", "i", ")", "for", "i", "in", "align_dict", "[", "ind", "]", ")", ")", "\n", "", "elif", "concept", "in", "[", "'product'", ",", "'company'", ",", "'person'", ",", "'thing'", "]", "and", "ind", "+", "2", "<", "len", "(", "tuple_list", ")", "and", "tuple_list", "[", "ind", "+", "1", "]", ".", "split", "(", "'__'", ")", "[", "-", "1", "]", "in", "[", "':arg0-of'", ",", "':arg1-of'", ",", "':arg2-of'", "]", "and", "align_dict", "[", "ind", "+", "2", "]", ":", "\n", "                ", "out", ".", "append", "(", "tuple_one", "+", "'__'", "+", "'e.'", "+", "','", ".", "join", "(", "str", "(", "i", ")", "for", "i", "in", "align_dict", "[", "ind", "+", "2", "]", ")", ")", "\n", "", "elif", "ind", "-", "1", ">=", "0", "and", "tuple_list", "[", "ind", "-", "1", "]", ".", "split", "(", "'__'", ")", "[", "-", "1", "]", "in", "[", "'product'", ",", "'company'", ",", "'person'", ",", "'thing'", "]", "and", "concept", "in", "[", "':arg0-of'", ",", "':arg1-of'", ",", "':arg2-of'", "]", "and", "ind", "+", "1", "<", "len", "(", "tuple_list", ")", "and", "align_dict", "[", "ind", "+", "1", "]", ":", "\n", "                ", "out", ".", "append", "(", "tuple_one", "+", "'__'", "+", "'e.'", "+", "','", ".", "join", "(", "str", "(", "i", ")", "for", "i", "in", "align_dict", "[", "ind", "+", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "out", ".", "append", "(", "tuple_one", ")", "\n", "", "", "out_lines", ".", "append", "(", "' '", ".", "join", "(", "out", ")", ")", "\n", "", "return", "out_lines", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.add_word_pos": [[141, 150], ["line.strip.strip", "out_lines.append", "out_lines.append", "str", "enumerate", "line.strip.split"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "add_word_pos", "(", "lines", ")", ":", "\n", "    ", "out_lines", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "not", "line", ":", "\n", "            ", "out_lines", ".", "append", "(", "''", ")", "\n", "", "else", ":", "\n", "            ", "out_lines", ".", "append", "(", "' '", ".", "join", "(", "word", "+", "'_'", "+", "str", "(", "pos", ")", "for", "pos", ",", "word", "in", "enumerate", "(", "line", ".", "split", "(", ")", ")", ")", ")", "\n", "", "", "return", "out_lines", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.giza2isi": [[153, 159], ["line.strip().split", "lines_out.append", "line.strip", "range", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "giza2isi", "(", "lines", ")", ":", "\n", "    ", "lines_out", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "        ", "l", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "lines_out", ".", "append", "(", "' '", ".", "join", "(", "l", "[", "ind", "]", "+", "'-'", "+", "l", "[", "ind", "+", "1", "]", "for", "ind", "in", "range", "(", "0", ",", "len", "(", "l", ")", "-", "1", ",", "2", ")", ")", ")", "\n", "", "return", "lines_out", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.process_utils.swap": [[161, 171], ["line.strip().split", "lines_out.append", "i.split", "newl.append", "line.strip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "swap", "(", "lines", ")", ":", "\n", "    ", "lines_out", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "        ", "l", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "newl", "=", "[", "]", "\n", "for", "i", "in", "l", ":", "\n", "            ", "pos1", ",", "pos2", "=", "i", ".", "split", "(", "'-'", ")", "\n", "newl", ".", "append", "(", "pos2", "+", "'-'", "+", "pos1", ")", "\n", "", "lines_out", ".", "append", "(", "' '", ".", "join", "(", "newl", ")", ")", "\n", "", "return", "lines_out", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.faa_aligner.FAA_Aligner.__init__": [[19, 30], ["kwargs.get", "kwargs.get", "faa_aligner.FAA_Aligner.setup_model_dir", "faa_aligner.TrainedAligner", "os.path.join", "os.path.join", "faa_aligner.FAA_Aligner.aligner.check_for_binaries", "logger.critical"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.faa_aligner.FAA_Aligner.setup_model_dir", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.faa_aligner.TrainedAligner.check_for_binaries"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "model_dir", "=", "kwargs", ".", "get", "(", "'model_dir'", ",", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'model_aligner_faa'", ")", ")", "\n", "self", ".", "model_tar_fn", "=", "kwargs", ".", "get", "(", "'model_tar_fn'", ",", "os", ".", "path", ".", "join", "(", "this_dir", ",", "'model_aligner_faa.tar.gz'", ")", ")", "\n", "self", ".", "setup_model_dir", "(", ")", "\n", "self", ".", "aligner", "=", "TrainedAligner", "(", "self", ".", "model_dir", ",", "**", "kwargs", ")", "\n", "try", ":", "\n", "            ", "self", ".", "aligner", ".", "check_for_binaries", "(", ")", "# Will raise FileNotFoundError if binaries can't be found", "\n", "", "except", "FileNotFoundError", ":", "\n", "            ", "logger", ".", "critical", "(", "'No binaries for fast_algin (https://github.com/clab/fast_align) found. '", "'These must be installed to use the faa_aligner. See the amrlib docs for details.'", ")", "\n", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.faa_aligner.FAA_Aligner.align_sents": [[33, 56], ["preprocess.preprocess_infer", "enumerate", "faa_aligner.FAA_Aligner.aligner.align", "range", "postprocess.postprocess.postprocess", "len", "len", "penman_utils.to_graph_line", "set", "zip", "len", "len", "len", "len", "eng_l.strip", "amr_l.strip", "skips.add", "eng_lines.append", "amr_lines.append", "faa_aligner.FAA_Aligner.pop"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.preprocess.preprocess_infer", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.align", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.postprocess.postprocess", "home.repos.pwc.inspect_result.chenllliang_atp.alignments.penman_utils.to_graph_line", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["", "", "def", "align_sents", "(", "self", ",", "space_tok_sents", ",", "graph_strings", ")", ":", "\n", "        ", "assert", "len", "(", "space_tok_sents", ")", "==", "len", "(", "graph_strings", ")", "\n", "graph_strings", "=", "[", "to_graph_line", "(", "g", ")", "for", "g", "in", "graph_strings", "]", "\n", "data", "=", "preprocess_infer", "(", "space_tok_sents", ",", "graph_strings", ",", "skip_empty_check", "=", "True", ")", "\n", "# Filter lines for empty strings.  The aligner doesn't return a value for blanks on either eng or amr", "\n", "skips", ",", "eng_lines", ",", "amr_lines", "=", "set", "(", ")", ",", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "(", "eng_l", ",", "amr_l", ")", "in", "enumerate", "(", "zip", "(", "data", ".", "eng_preproc_lines", ",", "data", ".", "amr_preproc_lines", ")", ")", ":", "\n", "            ", "eng_l", ",", "amr_l", "=", "eng_l", ".", "strip", "(", ")", ",", "amr_l", ".", "strip", "(", ")", "\n", "if", "not", "eng_l", "or", "not", "amr_l", ":", "\n", "                ", "skips", ".", "add", "(", "i", ")", "\n", "", "else", ":", "\n", "                ", "eng_lines", ".", "append", "(", "eng_l", ")", "\n", "amr_lines", ".", "append", "(", "amr_l", ")", "\n", "", "", "model_out_lines", "=", "self", ".", "aligner", ".", "align", "(", "eng_lines", ",", "amr_lines", ")", "\n", "assert", "len", "(", "model_out_lines", ")", "==", "len", "(", "eng_lines", ")", "\n", "# Add back in blanks for skipped lines", "\n", "final_astrings", "=", "[", "''", "]", "*", "len", "(", "data", ".", "eng_preproc_lines", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "final_astrings", ")", ")", ":", "\n", "            ", "if", "i", "not", "in", "skips", ":", "\n", "                ", "final_astrings", "[", "i", "]", "=", "model_out_lines", ".", "pop", "(", "0", ")", "\n", "", "", "data", ".", "model_out_lines", "=", "final_astrings", "\n", "amr_surface_aligns", ",", "alignment_strings", "=", "postprocess", "(", "data", ")", "\n", "return", "amr_surface_aligns", ",", "alignment_strings", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.faa_aligner.FAA_Aligner.setup_model_dir": [[60, 76], ["os.path.isfile", "os.path.join", "os.path.isfile", "tarfile.open", "tarfile.open.extractall", "logger.info", "os.path.isfile", "logger.critical", "os.path.join"], "methods", ["None"], ["", "def", "setup_model_dir", "(", "self", ")", ":", "\n", "# Check for the metadata and if so, consider the model ready to go", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "self", ".", "model_dir", ",", "'amrlib_meta.json'", ")", ")", ":", "\n", "            ", "return", "True", "\n", "# if there's a local copy, etract it", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "self", ".", "model_tar_fn", ")", ":", "\n", "            ", "tar", "=", "tarfile", ".", "open", "(", "self", ".", "model_tar_fn", ")", "\n", "tar", ".", "extractall", "(", "path", "=", "data_dir", ")", "\n", "logger", ".", "info", "(", "'Extracting a local copy of model'", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "self", ".", "model_dir", ",", "'amrlib_meta.json'", ")", ")", ":", "\n", "                ", "return", "True", "\n", "", "else", ":", "\n", "                ", "return", "False", "\n", "", "", "else", ":", "\n", "            ", "logger", ".", "critical", "(", "'No model in model_dir and no local version available to extract'", ")", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.faa_aligner.TrainedAligner.__init__": [[80, 104], ["os.environ.get", "kwargs.get", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "kwargs.get", "fwd_cmd.split", "rev_cmd.split", "tools_cmd.split", "open", "json.load", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["    ", "def", "__init__", "(", "self", ",", "model_in_dir", ",", "**", "kwargs", ")", ":", "\n", "# If the bin_dir is not provided, get it from the environment, but default", "\n", "# to '' which means it must be in the path", "\n", "        ", "bin_dir", "=", "os", ".", "environ", ".", "get", "(", "'FABIN_DIR'", ",", "''", ")", "\n", "bin_dir", "=", "kwargs", ".", "get", "(", "'bin_dir'", ",", "bin_dir", ")", "\n", "self", ".", "fast_align", "=", "os", ".", "path", ".", "join", "(", "bin_dir", ",", "'fast_align'", ")", "\n", "self", ".", "atools", "=", "os", ".", "path", ".", "join", "(", "bin_dir", ",", "'atools'", ")", "\n", "fwd_params_fn", "=", "os", ".", "path", ".", "join", "(", "model_in_dir", ",", "'fwd_params'", ")", "\n", "rev_params_fn", "=", "os", ".", "path", ".", "join", "(", "model_in_dir", ",", "'rev_params'", ")", "\n", "# Get the parameters from the metadata", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "model_in_dir", ",", "'amrlib_meta.json'", ")", ")", "as", "f", ":", "\n", "            ", "meta", "=", "json", ".", "load", "(", "f", ")", "\n", "", "p", "=", "meta", "[", "'train_params'", "]", "\n", "# timeout the exe to exit", "\n", "self", ".", "timeout", "=", "kwargs", ".", "get", "(", "'timeout'", ",", "1.0", ")", "\n", "# Create the actual commands to execute", "\n", "fwd_cmd", "=", "'%s -i - -d -q %f -a %f -T %f -m %f -f %s'", "%", "(", "self", ".", "fast_align", ",", "p", "[", "'q'", "]", ",", "p", "[", "'a'", "]", ",", "p", "[", "'fwd_T'", "]", ",", "p", "[", "'fwd_m'", "]", ",", "fwd_params_fn", ")", "\n", "rev_cmd", "=", "'%s -i - -d -q %f -a %f -T %f -m %f -f %s -r'", "%", "(", "self", ".", "fast_align", ",", "p", "[", "'q'", "]", ",", "p", "[", "'a'", "]", ",", "p", "[", "'fwd_T'", "]", ",", "p", "[", "'fwd_m'", "]", ",", "rev_params_fn", ")", "\n", "tools_cmd", "=", "'%s -i - -j - -c %s'", "%", "(", "self", ".", "atools", ",", "p", "[", "'heuristic'", "]", ")", "\n", "self", ".", "fwd_cmd", "=", "fwd_cmd", ".", "split", "(", ")", "\n", "self", ".", "rev_cmd", "=", "rev_cmd", ".", "split", "(", ")", "\n", "self", ".", "tools_cmd", "=", "tools_cmd", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.faa_aligner.TrainedAligner.popen_io": [[106, 110], ["subprocess.Popen"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "popen_io", "(", "cmd", ")", ":", "\n", "        ", "return", "subprocess", ".", "Popen", "(", "cmd", ",", "stdin", "=", "subprocess", ".", "PIPE", ",", "stdout", "=", "subprocess", ".", "PIPE", ",", "\n", "stderr", "=", "subprocess", ".", "PIPE", ",", "text", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.faa_aligner.TrainedAligner.align": [[111, 131], ["faa_aligner.TrainedAligner.popen_io", "faa_aligner.TrainedAligner.popen_io", "faa_aligner.TrainedAligner.popen_io", "faa_aligner.TrainedAligner.fwd_align.communicate", "faa_aligner.TrainedAligner.rev_align.communicate", "faa_aligner.TrainedAligner.tools.communicate", "[].strip", "[].strip", "l.strip", "zip", "l.strip", "fwd_out.splitlines", "rev_out.splitlines", "at_out.splitlines", "l.split", "l.split", "zip"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.faa_aligner.TrainedAligner.popen_io", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.faa_aligner.TrainedAligner.popen_io", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.faa_aligner.TrainedAligner.popen_io", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "align", "(", "self", ",", "eng_td_lines", ",", "amr_td_lines", ")", ":", "\n", "# Combine lines into fast align input format", "\n", "        ", "lines", "=", "[", "'%s ||| %s'", "%", "(", "el", ",", "al", ")", "for", "el", ",", "al", "in", "zip", "(", "eng_td_lines", ",", "amr_td_lines", ")", "]", "\n", "# Open connections to the alignment binaries", "\n", "self", ".", "fwd_align", "=", "self", ".", "popen_io", "(", "self", ".", "fwd_cmd", ")", "\n", "self", ".", "rev_align", "=", "self", ".", "popen_io", "(", "self", ".", "rev_cmd", ")", "\n", "self", ".", "tools", "=", "self", ".", "popen_io", "(", "self", ".", "tools_cmd", ")", "\n", "# Input to fast_align", "\n", "fa_in", "=", "'\\n'", ".", "join", "(", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "lines", "]", ")", "\n", "fwd_out", ",", "fwd_err", "=", "self", ".", "fwd_align", ".", "communicate", "(", "fa_in", ",", "timeout", "=", "self", ".", "timeout", ")", "\n", "rev_out", ",", "fwd_err", "=", "self", ".", "rev_align", ".", "communicate", "(", "fa_in", ",", "timeout", "=", "self", ".", "timeout", ")", "\n", "# output is     f words ||| e words ||| links ||| score", "\n", "fwd_lines", "=", "[", "l", ".", "split", "(", "'|||'", ")", "[", "2", "]", ".", "strip", "(", ")", "for", "l", "in", "fwd_out", ".", "splitlines", "(", ")", "if", "l", "]", "\n", "rev_lines", "=", "[", "l", ".", "split", "(", "'|||'", ")", "[", "2", "]", ".", "strip", "(", ")", "for", "l", "in", "rev_out", ".", "splitlines", "(", ")", "if", "l", "]", "\n", "# Input to atools", "\n", "# be sure to put a line-feed at the end or you'll get a duplicate line in the output", "\n", "at_in", "=", "'\\n'", ".", "join", "(", "[", "'%s\\n%s'", "%", "(", "fl", ",", "rl", ")", "for", "fl", ",", "rl", "in", "zip", "(", "fwd_lines", ",", "rev_lines", ")", "]", ")", "+", "'\\n'", "\n", "at_out", ",", "at_err", "=", "self", ".", "tools", ".", "communicate", "(", "at_in", ",", "timeout", "=", "self", ".", "timeout", ")", "\n", "at_lines", "=", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "at_out", ".", "splitlines", "(", ")", "]", "\n", "return", "at_lines", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.faa_aligner.TrainedAligner.check_for_binaries": [[135, 138], ["subprocess.run", "subprocess.run"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run", "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run"], ["", "def", "check_for_binaries", "(", "self", ")", ":", "\n", "        ", "ret_fa", "=", "subprocess", ".", "run", "(", "self", ".", "fast_align", ",", "stderr", "=", "subprocess", ".", "PIPE", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "ret_tool", "=", "subprocess", ".", "run", "(", "self", ".", "atools", ",", "stderr", "=", "subprocess", ".", "PIPE", ",", "stdout", "=", "subprocess", ".", "PIPE", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.Feat.__init__": [[19, 28], ["set", "edge.split", "len", "set", "int", "[].split", "alignsplit[].split"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["def", "__init__", "(", "self", ",", "edge", ",", "node", ",", "id", "=", "None", ")", ":", "\n", "        ", "self", ".", "edge", "=", "edge", "\n", "self", ".", "node", "=", "node", "\n", "self", ".", "id", "=", "id", "\n", "self", ".", "alignset", "=", "set", "(", ")", "\n", "alignsplit", "=", "edge", ".", "split", "(", "'~'", ")", "\n", "if", "len", "(", "alignsplit", ")", ">", "1", ":", "\n", "            ", "self", ".", "alignset", "|=", "set", "(", "int", "(", "i", ")", "for", "i", "in", "alignsplit", "[", "1", "]", ".", "split", "(", "'e.'", ")", "[", "1", "]", ".", "split", "(", "','", ")", ")", "\n", "self", ".", "edge", "=", "alignsplit", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.Feat.__str__": [[29, 31], ["str"], "methods", ["None"], ["", "", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "edge", "+", "'_'", "+", "str", "(", "self", ".", "node", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.Feat.__eq__": [[32, 34], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "node", "==", "other", ".", "node", "and", "self", ".", "edge", "==", "other", ".", "edge", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.Feat.__hash__": [[35, 37], ["hash"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "hash", "(", "self", ".", "node", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.FeatGraph.__init__": [[45, 66], ["set", "val.startswith", "val.split", "val.split", "len", "set", "int", "[].split", "alignsplit[].split"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["def", "__init__", "(", "self", ",", "id", ",", "val", ",", "type", ",", "feats", "=", "None", ",", "is_virtual", "=", "False", ",", "pi", "=", "''", ",", "pi_edge", "=", "''", ")", ":", "\n", "        ", "self", ".", "id", "=", "id", "\n", "self", ".", "val", "=", "val", "\n", "self", ".", "type", "=", "type", "\n", "self", ".", "feats", "=", "feats", "\n", "self", ".", "is_virtual", "=", "is_virtual", "\n", "self", ".", "pi", "=", "pi", "\n", "self", ".", "pi_edge", "=", "pi_edge", "\n", "# yanggao20130912: change alignset to be a set of tuples, for reentrancy case!", "\n", "self", ".", "alignset", "=", "set", "(", ")", "\n", "# Attribs could possibly have a tilde inside them so strip off the quoted portion", "\n", "if", "val", ".", "startswith", "(", "'\"'", ")", ":", "\n", "            ", "val", "=", "val", ".", "split", "(", "'\"'", ")", "[", "-", "1", "]", "\n", "", "alignsplit", "=", "val", ".", "split", "(", "'~'", ")", "\n", "try", ":", "# It's possible there is no 'e.' to split on so catch indexing error", "\n", "            ", "if", "len", "(", "alignsplit", ")", ">", "1", ":", "\n", "                ", "alignset", "=", "set", "(", "int", "(", "i", ")", "for", "i", "in", "alignsplit", "[", "1", "]", ".", "split", "(", "'e.'", ")", "[", "1", "]", ".", "split", "(", "','", ")", ")", "\n", "self", ".", "alignset", "|=", "alignset", "\n", "self", ".", "val", "=", "alignsplit", "[", "0", "]", "\n", "", "", "except", "IndexError", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.FeatGraph.pp": [[68, 90], ["set", "enumerate", "set", "feat.node.pp", "set", "feat.node.get_nonterm_nodes", "feats_str_list.append", "feats_str_list.append", "s.strip", "str", "sorted", "str", "sorted"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.FeatGraph.pp", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.FeatGraph.get_nonterm_nodes"], ["", "", "def", "pp", "(", "self", ",", "printed_nodes", "=", "set", "(", "[", "]", ")", ")", ":", "\n", "        ", "'''features:\n           1) one-line output\n           2) corefering nodes are fully specified once and once only\n        '''", "\n", "if", "not", "self", ".", "feats", "or", "self", "in", "printed_nodes", ":", "\n", "            ", "if", "self", ".", "alignset", ":", "\n", "                ", "return", "self", ".", "val", "+", "'~e.'", "+", "','", ".", "join", "(", "str", "(", "i", ")", "for", "i", "in", "sorted", "(", "self", ".", "alignset", ")", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "val", "\n", "", "", "s", "=", "self", ".", "val", "+", "' '", "\n", "feats_str_list", "=", "[", "]", "\n", "printed_nodes", "=", "printed_nodes", "|", "set", "(", "[", "self", "]", ")", "\n", "for", "ind", ",", "feat", "in", "enumerate", "(", "self", ".", "feats", ")", ":", "\n", "            ", "node_repr", "=", "feat", ".", "node", ".", "pp", "(", "printed_nodes", ")", "\n", "printed_nodes", "|=", "set", "(", "feat", ".", "node", ".", "get_nonterm_nodes", "(", ")", ")", "\n", "if", "feat", ".", "alignset", ":", "\n", "                ", "feats_str_list", ".", "append", "(", "feat", ".", "edge", "+", "'~e.'", "+", "','", ".", "join", "(", "str", "(", "i", ")", "for", "i", "in", "sorted", "(", "feat", ".", "alignset", ")", ")", "+", "' '", "+", "node_repr", ")", "\n", "", "else", ":", "\n", "                ", "feats_str_list", ".", "append", "(", "feat", ".", "edge", "+", "' '", "+", "node_repr", ")", "\n", "", "", "s", "+=", "' '", ".", "join", "(", "feats_str_list", ")", "\n", "return", "'('", "+", "s", ".", "strip", "(", ")", "+", "')'", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.FeatGraph.get_nonterm_nodes": [[91, 98], ["ret.append", "ret.extend", "f.node.get_nonterm_nodes"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.FeatGraph.get_nonterm_nodes"], ["", "def", "get_nonterm_nodes", "(", "self", ")", ":", "\n", "        ", "ret", "=", "[", "]", "\n", "if", "self", ".", "feats", ":", "\n", "            ", "ret", ".", "append", "(", "self", ")", "\n", "", "for", "f", "in", "self", ".", "feats", ":", "\n", "            ", "ret", ".", "extend", "(", "f", ".", "node", ".", "get_nonterm_nodes", "(", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.FeatGraph.assign_id": [[99, 106], ["f.node.assign_id"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.FeatGraph.assign_id"], ["", "def", "assign_id", "(", "self", ")", ":", "\n", "        ", "global", "global_input_node_id", "\n", "if", "self", ".", "id", "==", "None", ":", "\n", "            ", "self", ".", "id", "=", "global_input_node_id", "\n", "global_input_node_id", "+=", "1", "\n", "for", "f", "in", "self", ".", "feats", ":", "\n", "                ", "f", ".", "node", ".", "assign_id", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.FeatGraph.corefy": [[109, 138], ["enumerate", "f.node.corefy", "logger.info", "feat2tree.FeatGraph"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.FeatGraph.corefy"], ["", "", "", "def", "corefy", "(", "self", ",", "all_nt", ")", ":", "\n", "        ", "'''make the coref i under :ARG1 in\n           (w / want :ARG0 (i / i) :ARG1 i)\n           pointing to the primary subgraph\n           i.e., (i / i) under :ARG0\n\n           identify coref node by these criteria:\n           1) has no feats\n           2) val same as a nonterm node\n           3) not under the INSTANCE arg, since we may\n              have (i / i) where the second i is not coref\n           4) assumes that property value cannot have the\n              form of [a-zA-Z]\\d*, so not same as nonterm\n        '''", "\n", "if", "not", "self", ".", "feats", ":", "\n", "            ", "for", "nt", "in", "all_nt", ":", "\n", "                ", "if", "self", ".", "val", "==", "nt", ".", "val", ":", "\n", "                    ", "global", "global_input_id", "\n", "logger", ".", "info", "(", "'amr %d corefy.  referent triple: (%s %s %s)'", "%", "(", "global_input_id", ",", "self", ".", "pi", ".", "val", ",", "self", ".", "pi_edge", ",", "self", ".", "val", ")", ")", "\n", "# return a non-recursive copy", "\n", "return", "FeatGraph", "(", "None", ",", "self", ".", "val", ",", "None", ",", "[", "]", ")", "\n", "\n", "", "", "", "for", "ind", ",", "f", "in", "enumerate", "(", "self", ".", "feats", ")", ":", "\n", "# don't mistake the second i in", "\n", "# (w / want :ARG0 (i / i) :ARG1 i) as coref", "\n", "            ", "if", "f", ".", "edge", "!=", "INSTANCE", ":", "\n", "                ", "self", ".", "feats", "[", "ind", "]", ".", "node", "=", "f", ".", "node", ".", "corefy", "(", "all_nt", ")", "\n", "", "", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.input_amrparse": [[157, 201], ["COMMENT.match", "NODE_AMR.match", "NODE_BEGIN_AMR.match", "COMMENT.match.end", "COMMENT.match.group().strip", "NODE_AMR.match.end", "NODE_AMR.match.group().strip", "feat2tree.FeatGraph", "NODE_BEGIN_AMR.match.end", "feat2tree.input_amrparse", "len", "NODE_END_AMR.match", "REL_LABEL_AMR.match", "COMMENT.match.group", "NODE_AMR.match.group", "NODE_END_AMR.match.end", "REL_LABEL_AMR.match.end", "REL_LABEL_AMR.match.group().strip", "feat2tree.input_amrparse", "FeatGraph.feats.append", "print", "rel_match.group().strip.split", "logger.error", "feat2tree.Feat", "REL_LABEL_AMR.match.group"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.input_amrparse", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.input_amrparse", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["def", "input_amrparse", "(", "s", ",", "pos", "=", "0", ",", "depth", "=", "0", ")", ":", "\n", "    ", "'''return a (pos, FeatGraph) pair\n    '''", "\n", "comment_match", "=", "COMMENT", ".", "match", "(", "s", ",", "pos", ")", "\n", "if", "comment_match", ":", "\n", "        ", "pos", "=", "comment_match", ".", "end", "(", ")", "\n", "comment_symbol", "=", "comment_match", ".", "group", "(", ")", ".", "strip", "(", ")", "\n", "\n", "", "node_match", "=", "NODE_AMR", ".", "match", "(", "s", ",", "pos", ")", "\n", "if", "node_match", ":", "\n", "        ", "pos", "=", "node_match", ".", "end", "(", ")", "\n", "node_symbol", "=", "node_match", ".", "group", "(", ")", ".", "strip", "(", ")", "\n", "node", "=", "FeatGraph", "(", "None", ",", "node_symbol", ",", "None", ",", "[", "]", ")", "\n", "return", "pos", ",", "node", "\n", "\n", "", "nb_match", "=", "NODE_BEGIN_AMR", ".", "match", "(", "s", ",", "pos", ")", "\n", "if", "nb_match", ":", "\n", "        ", "pos", "=", "nb_match", ".", "end", "(", ")", "\n", "pos", ",", "node", "=", "input_amrparse", "(", "s", ",", "pos", ",", "depth", "+", "1", ")", "\n", "\n", "if", "not", "node", ":", "\n", "            ", "return", "pos", ",", "None", "\n", "\n", "", "while", "pos", "<", "len", "(", "s", ")", ":", "\n", "            ", "ne_match", "=", "NODE_END_AMR", ".", "match", "(", "s", ",", "pos", ")", "\n", "if", "ne_match", ":", "\n", "                ", "pos", "=", "ne_match", ".", "end", "(", ")", "\n", "return", "pos", ",", "node", "\n", "\n", "", "rel_match", "=", "REL_LABEL_AMR", ".", "match", "(", "s", ",", "pos", ")", "\n", "if", "rel_match", ":", "\n", "                ", "pos", "=", "rel_match", ".", "end", "(", ")", "\n", "rel_symbol", "=", "rel_match", ".", "group", "(", ")", ".", "strip", "(", ")", "\n", "rel", "=", "''", ".", "join", "(", "rel_symbol", ".", "split", "(", ")", ")", "\n", "pos", ",", "newnode", "=", "input_amrparse", "(", "s", ",", "pos", ",", "depth", "+", "1", ")", "\n", "if", "not", "newnode", ":", "\n", "                    ", "logger", ".", "error", "(", "'error, return pos %d'", "%", "pos", ")", "\n", "return", "pos", ",", "None", "\n", "", "node", ".", "feats", ".", "append", "(", "Feat", "(", "rel", ",", "newnode", ")", ")", "\n", "newnode", ".", "pi", ",", "newnode", ".", "pi_edge", "=", "node", ",", "rel", "\n", "", "else", ":", "\n", "                ", "print", "(", "'does not match ne or rel, pos %d'", "%", "pos", ")", "\n", "return", "pos", ",", "None", "\n", "", "", "", "return", "pos", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.get_alignment": [[203, 213], ["feat2tree.get_alignment", "tuple", "set", "int", "len", "[].split", "len", "tup[].rsplit"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.get_alignment", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "get_alignment", "(", "amr", ",", "tuples", ")", ":", "\n", "    ", "for", "f", "in", "amr", ".", "feats", ":", "\n", "        ", "for", "tup", "in", "tuples", ":", "\n", "            ", "amr_tuple", "=", "tuple", "(", "tup", "[", ":", "-", "1", "]", ")", "\n", "alignset", "=", "set", "(", "int", "(", "i", ")", "for", "i", "in", "tup", "[", "-", "1", "]", ".", "rsplit", "(", "'e.'", ",", "1", ")", "[", "1", "]", ".", "split", "(", "','", ")", ")", "\n", "if", "len", "(", "amr_tuple", ")", "==", "2", "and", "(", "amr", ".", "val", ",", "f", ".", "edge", ")", "==", "amr_tuple", ":", "\n", "                ", "f", ".", "alignset", "=", "alignset", "\n", "", "elif", "len", "(", "amr_tuple", ")", "==", "3", "and", "(", "amr", ".", "val", ",", "f", ".", "edge", ",", "f", ".", "node", ".", "val", ")", "==", "amr_tuple", ":", "\n", "                ", "f", ".", "node", ".", "alignset", "=", "alignset", "\n", "", "", "get_alignment", "(", "f", ".", "node", ",", "tuples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.align": [[215, 232], ["zip", "amr_str.strip().lower.strip().lower", "align_str.strip().lower.strip().lower", "feat2tree.input_amrparse", "amr.corefy", "amr.assign_id", "list", "feat2tree.get_alignment", "lines_out.append", "amr.get_nonterm_nodes", "amr.pp", "amr_str.strip().lower.strip", "align_str.strip().lower.strip", "tuple", "i.split", "align_str.strip().lower.split", "re.match"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.input_amrparse", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.FeatGraph.corefy", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.FeatGraph.assign_id", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.get_alignment", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.FeatGraph.get_nonterm_nodes", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.feat2tree.FeatGraph.pp", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "", "def", "align", "(", "amr_str_lines", ",", "align_str_lines", ")", ":", "\n", "    ", "global", "global_input_id", ",", "global_input_node_id", "\n", "\n", "global_input_id", "=", "-", "1", "\n", "lines_out", "=", "[", "]", "\n", "for", "amr_str", ",", "align_str", "in", "zip", "(", "amr_str_lines", ",", "align_str_lines", ")", ":", "\n", "        ", "amr_str", "=", "amr_str", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "align_str", "=", "align_str", ".", "strip", "(", ")", ".", "lower", "(", ")", "\n", "_", ",", "amr", "=", "input_amrparse", "(", "amr_str", ")", "\n", "global_input_id", "+=", "1", "\n", "amr", ".", "corefy", "(", "amr", ".", "get_nonterm_nodes", "(", ")", ")", "\n", "global_input_node_id", "=", "0", "\n", "amr", ".", "assign_id", "(", ")", "\n", "tups", "=", "list", "(", "tuple", "(", "i", ".", "split", "(", "'__'", ")", ")", "for", "i", "in", "align_str", ".", "split", "(", ")", "if", "re", ".", "match", "(", "r'.+e\\.[\\d,]+$'", ",", "i", ")", ")", "\n", "get_alignment", "(", "amr", ",", "tups", ")", "\n", "lines_out", ".", "append", "(", "amr", ".", "pp", "(", ")", ")", "\n", "", "return", "lines_out", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.__init__": [[8, 15], ["numpy.zeros", "numpy.zeros", "numpy.zeros"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "tokens", "=", "[", "]", "# strings", "\n", "self", ".", "level", "=", "[", "]", "# ints", "\n", "self", ".", "tree", "=", "numpy", ".", "zeros", "(", "shape", "=", "(", "1000", ",", "100", ")", ",", "dtype", "=", "'int'", ")", "\n", "self", ".", "deg", "=", "numpy", ".", "zeros", "(", "shape", "=", "(", "1000", ",", ")", ",", "dtype", "=", "'int'", ")", "\n", "self", ".", "p", "=", "numpy", ".", "zeros", "(", "shape", "=", "(", "1000", ",", ")", ",", "dtype", "=", "'int'", ")", "\n", "self", ".", "fout", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.from_amr_aligned": [[16, 24], ["cls", "cls.build_alignment_strings", "open", "l.strip", "l.startswith"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.build_alignment_strings"], ["", "@", "classmethod", "\n", "def", "from_amr_aligned", "(", "cls", ",", "infn", ")", ":", "\n", "        ", "self", "=", "cls", "(", ")", "\n", "with", "open", "(", "infn", ")", "as", "fin", ":", "\n", "            ", "lines", "=", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "fin", "]", "\n", "", "lines", "=", "[", "l", "for", "l", "in", "lines", "if", "l", "and", "not", "l", ".", "startswith", "(", "'#'", ")", "]", "\n", "self", ".", "build_alignment_strings", "(", "lines", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.from_amr_strings": [[25, 30], ["cls", "cls.build_alignment_strings"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.build_alignment_strings"], ["", "@", "classmethod", "\n", "def", "from_amr_strings", "(", "cls", ",", "strings", ")", ":", "\n", "        ", "self", "=", "cls", "(", ")", "\n", "self", ".", "build_alignment_strings", "(", "strings", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.write_to_file": [[31, 35], ["open", "get_alignments.GetAlignments.fout.seek", "shutil.copyfileobj"], "methods", ["None"], ["", "def", "write_to_file", "(", "self", ",", "outfn", ")", ":", "\n", "        ", "with", "open", "(", "outfn", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "self", ".", "fout", ".", "seek", "(", "0", ")", "\n", "shutil", ".", "copyfileobj", "(", "self", ".", "fout", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.get_alignments": [[36, 38], ["get_alignments.GetAlignments.fout.getvalue().splitlines", "get_alignments.GetAlignments.fout.getvalue"], "methods", ["None"], ["", "", "def", "get_alignments", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "fout", ".", "getvalue", "(", ")", ".", "splitlines", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.build_alignment_strings": [[44, 50], ["io.StringIO", "get_alignments.GetAlignments.parse", "get_alignments.GetAlignments.print_tree", "get_alignments.GetAlignments.fout.write"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.parse", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.print_tree"], ["", "def", "build_alignment_strings", "(", "self", ",", "lines", ")", ":", "\n", "        ", "self", ".", "fout", "=", "io", ".", "StringIO", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "self", ".", "parse", "(", "line", ")", "\n", "self", ".", "print_tree", "(", "0", ",", "'1'", ")", "\n", "self", ".", "fout", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.print_tree": [[51, 89], ["range", "range", "len", "range", "get_alignments.GetAlignments.print_tree", "get_alignments.GetAlignments.print_tree", "len", "get_alignments.GetAlignments.fout.write", "get_alignments.GetAlignments.fout.write", "get_alignments.GetAlignments.print_tree", "get_alignments.GetAlignments.print_tree", "get_alignments.GetAlignments.fout.write", "get_alignments.GetAlignments.fout.write", "str"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.print_tree", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.print_tree", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.print_tree", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.print_tree"], ["", "", "def", "print_tree", "(", "self", ",", "r", ",", "l", ")", ":", "\n", "        ", "s", "=", "''", "\n", "tkn", "=", "self", ".", "tokens", "[", "r", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "tkn", ")", ")", ":", "\n", "            ", "if", "tkn", "[", "i", "]", "==", "'~'", ":", "\n", "                ", "stkn", "=", "tkn", "[", "i", "+", "3", ":", "]", "\n", "al", "=", "''", "\n", "for", "j", "in", "range", "(", "len", "(", "stkn", ")", ")", ":", "\n", "                    ", "if", "stkn", "[", "j", "]", "==", "','", ":", "\n", "                        ", "if", "tkn", "[", "0", "]", "==", "':'", ":", "\n", "                            ", "self", ".", "fout", ".", "write", "(", "'%s-%s.r '", "%", "(", "al", ",", "l", ")", ")", "\n", "", "else", ":", "\n", "                            ", "self", ".", "fout", ".", "write", "(", "'%s-%s '", "%", "(", "al", ",", "l", ")", ")", "\n", "", "al", "=", "''", "\n", "", "else", ":", "\n", "                        ", "al", "=", "al", "+", "stkn", "[", "j", "]", "\n", "", "", "if", "tkn", "[", "0", "]", "==", "':'", ":", "\n", "                    ", "self", ".", "fout", ".", "write", "(", "'%s-%s.r '", "%", "(", "al", ",", "l", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "fout", ".", "write", "(", "'%s-%s '", "%", "(", "al", ",", "l", ")", ")", "\n", "", "break", "\n", "", "", "if", "self", ".", "tokens", "[", "r", "]", "==", "'/'", ":", "\n", "            ", "s", "=", "s", "+", "'/'", "+", "self", ".", "print_tree", "(", "self", ".", "tree", "[", "r", "]", "[", "0", "]", ",", "l", ")", "\n", "return", "s", "\n", "", "if", "self", ".", "tokens", "[", "r", "]", "==", "':'", ":", "\n", "            ", "s", "=", "s", "+", "self", ".", "tokens", "[", "r", "]", "+", "' '", "+", "self", ".", "print_tree", "(", "self", ".", "tree", "[", "r", "]", "[", "0", "]", ",", "l", ")", "\n", "return", "s", "\n", "", "if", "self", ".", "deg", "[", "r", "]", ">", "0", ":", "\n", "            ", "s", "=", "s", "+", "'('", "\n", "", "s", "=", "s", "+", "self", ".", "tokens", "[", "r", "]", "+", "' '", "\n", "for", "i", "in", "range", "(", "self", ".", "deg", "[", "r", "]", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "s", "=", "s", "+", "' '", "+", "self", ".", "print_tree", "(", "self", ".", "tree", "[", "r", "]", "[", "i", "]", ",", "l", ")", "\n", "", "else", ":", "\n", "                ", "s", "=", "s", "+", "' '", "+", "self", ".", "print_tree", "(", "self", ".", "tree", "[", "r", "]", "[", "i", "]", ",", "l", "+", "'.'", "+", "str", "(", "i", ")", ")", "\n", "", "", "if", "self", ".", "deg", "[", "r", "]", ">", "0", ":", "\n", "            ", "s", "=", "s", "+", "')'", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.add_child": [[90, 94], ["None"], "methods", ["None"], ["", "def", "add_child", "(", "self", ",", "par", ",", "ch", ")", ":", "\n", "        ", "self", ".", "p", "[", "ch", "]", "=", "par", "\n", "self", ".", "tree", "[", "par", "]", "[", "self", ".", "deg", "[", "par", "]", "]", "=", "ch", "\n", "self", ".", "deg", "[", "par", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.make_tree": [[95, 107], ["range", "len", "get_alignments.GetAlignments.add_child", "get_alignments.GetAlignments.add_child"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.add_child", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.add_child"], ["", "def", "make_tree", "(", "self", ")", ":", "\n", "        ", "par", "=", "0", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "tokens", ")", ")", ":", "\n", "            ", "if", "self", ".", "level", "[", "i", "]", "<", "self", ".", "level", "[", "i", "-", "1", "]", ":", "\n", "                ", "while", "self", ".", "level", "[", "par", "]", ">", "self", ".", "level", "[", "i", "]", ":", "\n", "                    ", "par", "=", "self", ".", "p", "[", "par", "]", "\n", "", "par", "=", "self", ".", "p", "[", "par", "]", "\n", "", "if", "self", ".", "level", "[", "i", "]", ">", "self", ".", "level", "[", "i", "-", "1", "]", ":", "\n", "                ", "par", "=", "i", "\n", "", "if", "self", ".", "tokens", "[", "i", "]", "==", "'/'", "or", "self", ".", "tokens", "[", "i", "]", "[", "0", "]", "==", "':'", ":", "\n", "                ", "self", ".", "add_child", "(", "par", ",", "i", ")", "\n", "self", ".", "add_child", "(", "i", ",", "i", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.find_first_of": [[108, 115], ["set", "enumerate", "list"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "find_first_of", "(", "string", ",", "chars", ",", "pos", ")", ":", "\n", "        ", "char_set", "=", "set", "(", "list", "(", "chars", ")", ")", "\n", "for", "i", ",", "string_char", "in", "enumerate", "(", "string", "[", "pos", ":", "]", ")", ":", "\n", "            ", "if", "string_char", "in", "char_set", ":", "\n", "                ", "return", "i", "+", "pos", "\n", "", "", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.parse": [[116, 154], ["range", "range", "get_alignments.GetAlignments.make_tree", "get_alignments.GetAlignments.find_first_of", "len", "v.append", "len", "get_alignments.GetAlignments.tokens.append", "get_alignments.GetAlignments.level.append", "v.append", "v.append", "v.append"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.make_tree", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.get_alignments.GetAlignments.find_first_of"], ["", "def", "parse", "(", "self", ",", "s0", ")", ":", "\n", "        ", "v", "=", "[", "]", "# string", "\n", "prev", "=", "0", "\n", "#while (pos := self.find_first_of(s0, ' ()', prev)) < 0:   # := operator new in python 3.8", "\n", "while", "True", ":", "\n", "            ", "pos", "=", "self", ".", "find_first_of", "(", "s0", ",", "' ()'", ",", "prev", ")", "\n", "if", "pos", "<", "0", ":", "break", "\n", "if", "pos", ">", "prev", ":", "\n", "                ", "if", "s0", "[", "prev", "]", "==", "'\\\"'", ":", "\n", "                    ", "pos", "=", "prev", "+", "1", "\n", "while", "s0", "[", "pos", "]", "!=", "'\\\"'", ":", "\n", "                        ", "pos", "+=", "1", "\n", "", "while", "s0", "[", "pos", "]", "!=", "')'", "and", "s0", "[", "pos", "]", "!=", "'('", "and", "s0", "[", "pos", "]", "!=", "' '", ":", "\n", "                        ", "pos", "+=", "1", "\n", "", "", "v", ".", "append", "(", "s0", "[", "prev", ":", "pos", "]", ")", "\n", "", "if", "s0", "[", "pos", "]", "==", "'('", ":", "\n", "                ", "v", ".", "append", "(", "'('", ")", "\n", "", "if", "s0", "[", "pos", "]", "==", "')'", ":", "\n", "                ", "v", ".", "append", "(", "')'", ")", "\n", "", "prev", "=", "pos", "+", "1", "\n", "", "if", "prev", "<", "len", "(", "s0", ")", ":", "\n", "            ", "v", ".", "append", "(", "s0", "[", "prev", ":", "]", ")", "\n", "", "self", ".", "tokens", "=", "[", "]", "\n", "self", ".", "level", "=", "[", "]", "\n", "l", "=", "0", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "v", ")", ")", ":", "\n", "            ", "if", "v", "[", "i", "]", "==", "'('", ":", "\n", "                ", "l", "+=", "1", "\n", "continue", "\n", "", "if", "v", "[", "i", "]", "==", "')'", ":", "\n", "                ", "l", "-=", "1", "\n", "continue", "\n", "", "self", ".", "tokens", ".", "append", "(", "v", "[", "i", "]", ")", "\n", "self", ".", "level", ".", "append", "(", "l", ")", "\n", "", "for", "i", "in", "range", "(", "1000", ")", ":", "\n", "            ", "self", ".", "deg", "[", "i", "]", "=", "0", "\n", "self", ".", "p", "[", "i", "]", "=", "-", "1", "\n", "", "self", ".", "make_tree", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_gtos.ProcessorGTOS.__init__": [[10, 22], ["config.get", "config.get", "config.get", "config.get", "logger.warning", "threading.Thread", "threading.Thread.start"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "disabled", "=", "False", ")", ":", "\n", "        ", "self", ".", "model_dir", "=", "config", "[", "'gtos_model_dir'", "]", "\n", "self", ".", "num_ret_seq", "=", "config", ".", "get", "(", "'gtos_num_ret_seq'", ",", "1", ")", "\n", "self", ".", "num_beams", "=", "config", ".", "get", "(", "'gtos_num_beams'", ",", "1", ")", "\n", "self", ".", "batch_size", "=", "config", ".", "get", "(", "'gtos_batch_size'", ",", "1", ")", "\n", "self", ".", "device", "=", "config", ".", "get", "(", "'gtos_device'", ")", "\n", "self", ".", "inference", "=", "None", "\n", "if", "disabled", ":", "\n", "            ", "logger", ".", "warning", "(", "'!!! ProcessorGTOS disabled for debug !!!'", ")", "\n", "", "else", ":", "\n", "            ", "lm_thread", "=", "Thread", "(", "target", "=", "self", ".", "load_model", ")", "# loads self.inference", "\n", "lm_thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_gtos.ProcessorGTOS.is_ready": [[23, 25], ["None"], "methods", ["None"], ["", "", "def", "is_ready", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "inference", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_gtos.ProcessorGTOS.run": [[26, 37], ["processor_gtos.ProcessorGTOS.inference.generate", "enumerate", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.inference.Inference.generate"], ["", "def", "run", "(", "self", ",", "amr_text", ")", ":", "\n", "        ", "if", "self", ".", "inference", "is", "None", ":", "\n", "            ", "return", "\n", "", "answers", ",", "clips", "=", "self", ".", "inference", ".", "generate", "(", "[", "amr_text", "]", ",", "disable_progress", "=", "True", ")", "\n", "if", "clips", "[", "0", "]", ":", "\n", "            ", "logger", ".", "warning", "(", "'Graph was clipped'", ")", "\n", "# Concatenate multiple return sequences", "\n", "", "string", "=", "''", "\n", "for", "i", ",", "ans", "in", "enumerate", "(", "answers", ")", ":", "\n", "            ", "string", "+=", "'%2d)  %s\\n'", "%", "(", "i", "+", "1", ",", "ans", ")", "\n", "", "return", "string", "[", ":", "-", "1", "]", "# strip final line-feed", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_gtos.ProcessorGTOS.load_model": [[38, 44], ["models.model_factory.load_inference_model", "logger.info", "print"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.models.model_factory.load_inference_model", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "load_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "inference", "=", "load_inference_model", "(", "self", ".", "model_dir", ",", "num_beams", "=", "self", ".", "num_beams", ",", "\n", "device", "=", "self", ".", "device", ",", "num_ret_seq", "=", "self", ".", "num_ret_seq", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "logger", ".", "info", "(", "'Graph to sequence model ready'", ")", "\n", "print", "(", "'Graph to sequence model ready'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.__init__": [[12, 23], ["logger.warning", "threading.Thread", "threading.Thread.start"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "disabled", "=", "False", ")", ":", "\n", "        ", "self", ".", "model_dir", "=", "config", "[", "'stog_model_dir'", "]", "\n", "self", ".", "model_fn", "=", "config", "[", "'stog_model_fn'", "]", "\n", "self", ".", "device", "=", "config", "[", "'stog_device'", "]", "\n", "self", ".", "show_metadata", "=", "True", "\n", "self", ".", "inference", "=", "None", "\n", "if", "disabled", ":", "\n", "            ", "logger", ".", "warning", "(", "'!!! ProcessorSTOG disabled for debug !!!'", ")", "\n", "", "else", ":", "\n", "            ", "lm_thread", "=", "Thread", "(", "target", "=", "self", ".", "load_model", ")", "# loads self.inference", "\n", "lm_thread", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.is_ready": [[24, 26], ["None"], "methods", ["None"], ["", "", "def", "is_ready", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "inference", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run": [[27, 32], ["processor_stog.ProcessorSTOG.inference.parse_sents"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_sents"], ["", "def", "run", "(", "self", ",", "sent", ")", ":", "\n", "        ", "if", "self", ".", "inference", "is", "None", ":", "\n", "            ", "return", "\n", "", "entries", "=", "self", ".", "inference", ".", "parse_sents", "(", "[", "sent", "]", ",", "self", ".", "show_metadata", ")", "\n", "return", "entries", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.load_model": [[33, 38], ["graph_processing.annotator.load_spacy", "models.model_factory.load_inference_model", "logger.info", "print"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator.load_spacy", "home.repos.pwc.inspect_result.chenllliang_atp.models.model_factory.load_inference_model", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "load_model", "(", "self", ")", ":", "\n", "        ", "load_spacy", "(", ")", "# pre-load this for the annotator", "\n", "self", ".", "inference", "=", "load_inference_model", "(", "self", ".", "model_dir", ",", "device", "=", "self", ".", "device", ")", "\n", "logger", ".", "info", "(", "'Sequence to graph model ready'", ")", "\n", "print", "(", "'Sequence to graph model ready'", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.cli.main": [[17, 37], ["amrlib.utils.logging.setup_logging", "amrlib.utils.logging.silence_penman", "os.path.realpath", "os.path.realpath", "print", "json.load.items", "QApplication", "amrlib.amr_view.main_window.MainWindow", "QApplication.exec_", "open", "json.load", "os.path.join", "os.path.join", "print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.logging.setup_logging", "home.repos.pwc.inspect_result.chenllliang_atp.utils.logging.silence_penman", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["def", "main", "(", ")", ":", "\n", "    ", "setup_logging", "(", "level", "=", "WARN", ")", "\n", "silence_penman", "(", ")", "\n", "\n", "# Open the config file", "\n", "with", "open", "(", "config_fn", ")", "as", "f", ":", "\n", "        ", "config", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "# Modify model paths to be absolute, relative to this file", "\n", "", "config", "[", "'gtos_model_dir'", "]", "=", "os", ".", "path", ".", "realpath", "(", "os", ".", "path", ".", "join", "(", "base_dir", ",", "config", "[", "'gtos_model_dir'", "]", ")", ")", "\n", "config", "[", "'stog_model_dir'", "]", "=", "os", ".", "path", ".", "realpath", "(", "os", ".", "path", ".", "join", "(", "base_dir", ",", "config", "[", "'stog_model_dir'", "]", ")", ")", "\n", "\n", "# For debug", "\n", "print", "(", "'AMRView Config'", ")", "\n", "for", "k", ",", "v", "in", "config", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "'%s = %s'", "%", "(", "k", ",", "v", ")", ")", "\n", "\n", "", "app", "=", "QApplication", "(", "[", "]", ")", "\n", "window", "=", "MainWindow", "(", "config", ")", "\n", "app", ".", "exec_", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.Ui_MainWindow.Ui_MainWindow.setupUi": [[15, 108], ["MainWindow.setObjectName", "MainWindow.resize", "MainWindow.setMinimumSize", "PyQt5.QtWidgets.QWidget", "Ui_MainWindow.Ui_MainWindow.centralwidget.setObjectName", "PyQt5.QtWidgets.QGridLayout", "Ui_MainWindow.Ui_MainWindow.gridLayout.setObjectName", "PyQt5.QtWidgets.QVBoxLayout", "Ui_MainWindow.Ui_MainWindow.verticalLayout_2.setObjectName", "PyQt5.QtWidgets.QHBoxLayout", "Ui_MainWindow.Ui_MainWindow.horizontalLayout_2.setObjectName", "PyQt5.QtWidgets.QLabel", "Ui_MainWindow.Ui_MainWindow.inputSentLBL.setObjectName", "Ui_MainWindow.Ui_MainWindow.horizontalLayout_2.addWidget", "PyQt5.QtWidgets.QSpacerItem", "Ui_MainWindow.Ui_MainWindow.horizontalLayout_2.addItem", "Ui_MainWindow.Ui_MainWindow.verticalLayout_2.addLayout", "PyQt5.QtWidgets.QVBoxLayout", "Ui_MainWindow.Ui_MainWindow.verticalLayout.setObjectName", "PyQt5.QtWidgets.QLineEdit", "Ui_MainWindow.Ui_MainWindow.inputSentLE.setObjectName", "Ui_MainWindow.Ui_MainWindow.verticalLayout.addWidget", "Ui_MainWindow.Ui_MainWindow.verticalLayout_2.addLayout", "PyQt5.QtWidgets.QHBoxLayout", "Ui_MainWindow.Ui_MainWindow.horizontalLayout.setObjectName", "PyQt5.QtWidgets.QLabel", "Ui_MainWindow.Ui_MainWindow.amrLBL.setObjectName", "Ui_MainWindow.Ui_MainWindow.horizontalLayout.addWidget", "PyQt5.QtWidgets.QSpacerItem", "Ui_MainWindow.Ui_MainWindow.horizontalLayout.addItem", "PyQt5.QtWidgets.QPushButton", "Ui_MainWindow.Ui_MainWindow.showGraphPB.setObjectName", "Ui_MainWindow.Ui_MainWindow.horizontalLayout.addWidget", "PyQt5.QtWidgets.QPushButton", "Ui_MainWindow.Ui_MainWindow.toAmrPB.setObjectName", "Ui_MainWindow.Ui_MainWindow.horizontalLayout.addWidget", "Ui_MainWindow.Ui_MainWindow.verticalLayout_2.addLayout", "PyQt5.QtWidgets.QPlainTextEdit", "Ui_MainWindow.Ui_MainWindow.amrTE.setLineWrapMode", "Ui_MainWindow.Ui_MainWindow.amrTE.setObjectName", "Ui_MainWindow.Ui_MainWindow.verticalLayout_2.addWidget", "PyQt5.QtWidgets.QHBoxLayout", "Ui_MainWindow.Ui_MainWindow.horizontalLayout_4.setObjectName", "PyQt5.QtWidgets.QLabel", "Ui_MainWindow.Ui_MainWindow.generatedLBL.setObjectName", "Ui_MainWindow.Ui_MainWindow.horizontalLayout_4.addWidget", "PyQt5.QtWidgets.QSpacerItem", "Ui_MainWindow.Ui_MainWindow.horizontalLayout_4.addItem", "PyQt5.QtWidgets.QPushButton", "Ui_MainWindow.Ui_MainWindow.generatePB.setObjectName", "Ui_MainWindow.Ui_MainWindow.horizontalLayout_4.addWidget", "Ui_MainWindow.Ui_MainWindow.verticalLayout_2.addLayout", "PyQt5.QtWidgets.QPlainTextEdit", "PyQt5.QtWidgets.QSizePolicy", "PyQt5.QtWidgets.QSizePolicy.setHorizontalStretch", "PyQt5.QtWidgets.QSizePolicy.setVerticalStretch", "PyQt5.QtWidgets.QSizePolicy.setHeightForWidth", "Ui_MainWindow.Ui_MainWindow.generatedTE.setSizePolicy", "Ui_MainWindow.Ui_MainWindow.generatedTE.setMinimumSize", "Ui_MainWindow.Ui_MainWindow.generatedTE.setMaximumSize", "Ui_MainWindow.Ui_MainWindow.generatedTE.setLineWrapMode", "Ui_MainWindow.Ui_MainWindow.generatedTE.setObjectName", "Ui_MainWindow.Ui_MainWindow.verticalLayout_2.addWidget", "PyQt5.QtWidgets.QHBoxLayout", "Ui_MainWindow.Ui_MainWindow.horizontalLayout_5.setObjectName", "PyQt5.QtWidgets.QSpacerItem", "Ui_MainWindow.Ui_MainWindow.horizontalLayout_5.addItem", "PyQt5.QtWidgets.QPushButton", "Ui_MainWindow.Ui_MainWindow.exitPB.setObjectName", "Ui_MainWindow.Ui_MainWindow.horizontalLayout_5.addWidget", "Ui_MainWindow.Ui_MainWindow.verticalLayout_2.addLayout", "Ui_MainWindow.Ui_MainWindow.gridLayout.addLayout", "MainWindow.setCentralWidget", "PyQt5.QtWidgets.QMenuBar", "Ui_MainWindow.Ui_MainWindow.menubar.setGeometry", "Ui_MainWindow.Ui_MainWindow.menubar.setObjectName", "PyQt5.QtWidgets.QMenu", "Ui_MainWindow.Ui_MainWindow.menuFile.setObjectName", "MainWindow.setMenuBar", "PyQt5.QtWidgets.QStatusBar", "Ui_MainWindow.Ui_MainWindow.statusbar.setObjectName", "MainWindow.setStatusBar", "PyQt5.QtWidgets.QAction", "Ui_MainWindow.Ui_MainWindow.actionLoadAMR.setObjectName", "PyQt5.QtWidgets.QAction", "Ui_MainWindow.Ui_MainWindow.actionSaveAMR.setObjectName", "Ui_MainWindow.Ui_MainWindow.menuFile.addAction", "Ui_MainWindow.Ui_MainWindow.menuFile.addAction", "Ui_MainWindow.Ui_MainWindow.menubar.addAction", "Ui_MainWindow.Ui_MainWindow.retranslateUi", "PyQt5.QtCore.QMetaObject.connectSlotsByName", "PyQt5.QtCore.QSize", "Ui_MainWindow.Ui_MainWindow.generatedTE.sizePolicy().hasHeightForWidth", "PyQt5.QtCore.QSize", "PyQt5.QtCore.QSize", "PyQt5.QtCore.QRect", "Ui_MainWindow.Ui_MainWindow.menuFile.menuAction", "Ui_MainWindow.Ui_MainWindow.generatedTE.sizePolicy"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.amr_view.Ui_MainWindow.Ui_MainWindow.retranslateUi"], ["    ", "def", "setupUi", "(", "self", ",", "MainWindow", ")", ":", "\n", "        ", "MainWindow", ".", "setObjectName", "(", "\"MainWindow\"", ")", "\n", "MainWindow", ".", "resize", "(", "1175", ",", "981", ")", "\n", "MainWindow", ".", "setMinimumSize", "(", "QtCore", ".", "QSize", "(", "200", ",", "300", ")", ")", "\n", "self", ".", "centralwidget", "=", "QtWidgets", ".", "QWidget", "(", "MainWindow", ")", "\n", "self", ".", "centralwidget", ".", "setObjectName", "(", "\"centralwidget\"", ")", "\n", "self", ".", "gridLayout", "=", "QtWidgets", ".", "QGridLayout", "(", "self", ".", "centralwidget", ")", "\n", "self", ".", "gridLayout", ".", "setObjectName", "(", "\"gridLayout\"", ")", "\n", "self", ".", "verticalLayout_2", "=", "QtWidgets", ".", "QVBoxLayout", "(", ")", "\n", "self", ".", "verticalLayout_2", ".", "setObjectName", "(", "\"verticalLayout_2\"", ")", "\n", "self", ".", "horizontalLayout_2", "=", "QtWidgets", ".", "QHBoxLayout", "(", ")", "\n", "self", ".", "horizontalLayout_2", ".", "setObjectName", "(", "\"horizontalLayout_2\"", ")", "\n", "self", ".", "inputSentLBL", "=", "QtWidgets", ".", "QLabel", "(", "self", ".", "centralwidget", ")", "\n", "self", ".", "inputSentLBL", ".", "setObjectName", "(", "\"inputSentLBL\"", ")", "\n", "self", ".", "horizontalLayout_2", ".", "addWidget", "(", "self", ".", "inputSentLBL", ")", "\n", "spacerItem", "=", "QtWidgets", ".", "QSpacerItem", "(", "40", ",", "20", ",", "QtWidgets", ".", "QSizePolicy", ".", "Expanding", ",", "QtWidgets", ".", "QSizePolicy", ".", "Minimum", ")", "\n", "self", ".", "horizontalLayout_2", ".", "addItem", "(", "spacerItem", ")", "\n", "self", ".", "verticalLayout_2", ".", "addLayout", "(", "self", ".", "horizontalLayout_2", ")", "\n", "self", ".", "verticalLayout", "=", "QtWidgets", ".", "QVBoxLayout", "(", ")", "\n", "self", ".", "verticalLayout", ".", "setObjectName", "(", "\"verticalLayout\"", ")", "\n", "self", ".", "inputSentLE", "=", "QtWidgets", ".", "QLineEdit", "(", "self", ".", "centralwidget", ")", "\n", "self", ".", "inputSentLE", ".", "setObjectName", "(", "\"inputSentLE\"", ")", "\n", "self", ".", "verticalLayout", ".", "addWidget", "(", "self", ".", "inputSentLE", ")", "\n", "self", ".", "verticalLayout_2", ".", "addLayout", "(", "self", ".", "verticalLayout", ")", "\n", "self", ".", "horizontalLayout", "=", "QtWidgets", ".", "QHBoxLayout", "(", ")", "\n", "self", ".", "horizontalLayout", ".", "setObjectName", "(", "\"horizontalLayout\"", ")", "\n", "self", ".", "amrLBL", "=", "QtWidgets", ".", "QLabel", "(", "self", ".", "centralwidget", ")", "\n", "self", ".", "amrLBL", ".", "setObjectName", "(", "\"amrLBL\"", ")", "\n", "self", ".", "horizontalLayout", ".", "addWidget", "(", "self", ".", "amrLBL", ")", "\n", "spacerItem1", "=", "QtWidgets", ".", "QSpacerItem", "(", "40", ",", "20", ",", "QtWidgets", ".", "QSizePolicy", ".", "Expanding", ",", "QtWidgets", ".", "QSizePolicy", ".", "Minimum", ")", "\n", "self", ".", "horizontalLayout", ".", "addItem", "(", "spacerItem1", ")", "\n", "self", ".", "showGraphPB", "=", "QtWidgets", ".", "QPushButton", "(", "self", ".", "centralwidget", ")", "\n", "self", ".", "showGraphPB", ".", "setObjectName", "(", "\"showGraphPB\"", ")", "\n", "self", ".", "horizontalLayout", ".", "addWidget", "(", "self", ".", "showGraphPB", ")", "\n", "self", ".", "toAmrPB", "=", "QtWidgets", ".", "QPushButton", "(", "self", ".", "centralwidget", ")", "\n", "self", ".", "toAmrPB", ".", "setObjectName", "(", "\"toAmrPB\"", ")", "\n", "self", ".", "horizontalLayout", ".", "addWidget", "(", "self", ".", "toAmrPB", ")", "\n", "self", ".", "verticalLayout_2", ".", "addLayout", "(", "self", ".", "horizontalLayout", ")", "\n", "self", ".", "amrTE", "=", "QtWidgets", ".", "QPlainTextEdit", "(", "self", ".", "centralwidget", ")", "\n", "self", ".", "amrTE", ".", "setLineWrapMode", "(", "QtWidgets", ".", "QPlainTextEdit", ".", "NoWrap", ")", "\n", "self", ".", "amrTE", ".", "setObjectName", "(", "\"amrTE\"", ")", "\n", "self", ".", "verticalLayout_2", ".", "addWidget", "(", "self", ".", "amrTE", ")", "\n", "self", ".", "horizontalLayout_4", "=", "QtWidgets", ".", "QHBoxLayout", "(", ")", "\n", "self", ".", "horizontalLayout_4", ".", "setObjectName", "(", "\"horizontalLayout_4\"", ")", "\n", "self", ".", "generatedLBL", "=", "QtWidgets", ".", "QLabel", "(", "self", ".", "centralwidget", ")", "\n", "self", ".", "generatedLBL", ".", "setObjectName", "(", "\"generatedLBL\"", ")", "\n", "self", ".", "horizontalLayout_4", ".", "addWidget", "(", "self", ".", "generatedLBL", ")", "\n", "spacerItem2", "=", "QtWidgets", ".", "QSpacerItem", "(", "40", ",", "20", ",", "QtWidgets", ".", "QSizePolicy", ".", "Expanding", ",", "QtWidgets", ".", "QSizePolicy", ".", "Minimum", ")", "\n", "self", ".", "horizontalLayout_4", ".", "addItem", "(", "spacerItem2", ")", "\n", "self", ".", "generatePB", "=", "QtWidgets", ".", "QPushButton", "(", "self", ".", "centralwidget", ")", "\n", "self", ".", "generatePB", ".", "setObjectName", "(", "\"generatePB\"", ")", "\n", "self", ".", "horizontalLayout_4", ".", "addWidget", "(", "self", ".", "generatePB", ")", "\n", "self", ".", "verticalLayout_2", ".", "addLayout", "(", "self", ".", "horizontalLayout_4", ")", "\n", "self", ".", "generatedTE", "=", "QtWidgets", ".", "QPlainTextEdit", "(", "self", ".", "centralwidget", ")", "\n", "sizePolicy", "=", "QtWidgets", ".", "QSizePolicy", "(", "QtWidgets", ".", "QSizePolicy", ".", "Expanding", ",", "QtWidgets", ".", "QSizePolicy", ".", "Fixed", ")", "\n", "sizePolicy", ".", "setHorizontalStretch", "(", "0", ")", "\n", "sizePolicy", ".", "setVerticalStretch", "(", "0", ")", "\n", "sizePolicy", ".", "setHeightForWidth", "(", "self", ".", "generatedTE", ".", "sizePolicy", "(", ")", ".", "hasHeightForWidth", "(", ")", ")", "\n", "self", ".", "generatedTE", ".", "setSizePolicy", "(", "sizePolicy", ")", "\n", "self", ".", "generatedTE", ".", "setMinimumSize", "(", "QtCore", ".", "QSize", "(", "0", ",", "80", ")", ")", "\n", "self", ".", "generatedTE", ".", "setMaximumSize", "(", "QtCore", ".", "QSize", "(", "16777215", ",", "80", ")", ")", "\n", "self", ".", "generatedTE", ".", "setLineWrapMode", "(", "QtWidgets", ".", "QPlainTextEdit", ".", "NoWrap", ")", "\n", "self", ".", "generatedTE", ".", "setObjectName", "(", "\"generatedTE\"", ")", "\n", "self", ".", "verticalLayout_2", ".", "addWidget", "(", "self", ".", "generatedTE", ")", "\n", "self", ".", "horizontalLayout_5", "=", "QtWidgets", ".", "QHBoxLayout", "(", ")", "\n", "self", ".", "horizontalLayout_5", ".", "setObjectName", "(", "\"horizontalLayout_5\"", ")", "\n", "spacerItem3", "=", "QtWidgets", ".", "QSpacerItem", "(", "40", ",", "20", ",", "QtWidgets", ".", "QSizePolicy", ".", "Expanding", ",", "QtWidgets", ".", "QSizePolicy", ".", "Minimum", ")", "\n", "self", ".", "horizontalLayout_5", ".", "addItem", "(", "spacerItem3", ")", "\n", "self", ".", "exitPB", "=", "QtWidgets", ".", "QPushButton", "(", "self", ".", "centralwidget", ")", "\n", "self", ".", "exitPB", ".", "setObjectName", "(", "\"exitPB\"", ")", "\n", "self", ".", "horizontalLayout_5", ".", "addWidget", "(", "self", ".", "exitPB", ")", "\n", "self", ".", "verticalLayout_2", ".", "addLayout", "(", "self", ".", "horizontalLayout_5", ")", "\n", "self", ".", "gridLayout", ".", "addLayout", "(", "self", ".", "verticalLayout_2", ",", "0", ",", "0", ",", "1", ",", "1", ")", "\n", "MainWindow", ".", "setCentralWidget", "(", "self", ".", "centralwidget", ")", "\n", "self", ".", "menubar", "=", "QtWidgets", ".", "QMenuBar", "(", "MainWindow", ")", "\n", "self", ".", "menubar", ".", "setGeometry", "(", "QtCore", ".", "QRect", "(", "0", ",", "0", ",", "1175", ",", "22", ")", ")", "\n", "self", ".", "menubar", ".", "setObjectName", "(", "\"menubar\"", ")", "\n", "self", ".", "menuFile", "=", "QtWidgets", ".", "QMenu", "(", "self", ".", "menubar", ")", "\n", "self", ".", "menuFile", ".", "setObjectName", "(", "\"menuFile\"", ")", "\n", "MainWindow", ".", "setMenuBar", "(", "self", ".", "menubar", ")", "\n", "self", ".", "statusbar", "=", "QtWidgets", ".", "QStatusBar", "(", "MainWindow", ")", "\n", "self", ".", "statusbar", ".", "setObjectName", "(", "\"statusbar\"", ")", "\n", "MainWindow", ".", "setStatusBar", "(", "self", ".", "statusbar", ")", "\n", "self", ".", "actionLoadAMR", "=", "QtWidgets", ".", "QAction", "(", "MainWindow", ")", "\n", "self", ".", "actionLoadAMR", ".", "setObjectName", "(", "\"actionLoadAMR\"", ")", "\n", "self", ".", "actionSaveAMR", "=", "QtWidgets", ".", "QAction", "(", "MainWindow", ")", "\n", "self", ".", "actionSaveAMR", ".", "setObjectName", "(", "\"actionSaveAMR\"", ")", "\n", "self", ".", "menuFile", ".", "addAction", "(", "self", ".", "actionLoadAMR", ")", "\n", "self", ".", "menuFile", ".", "addAction", "(", "self", ".", "actionSaveAMR", ")", "\n", "self", ".", "menubar", ".", "addAction", "(", "self", ".", "menuFile", ".", "menuAction", "(", ")", ")", "\n", "\n", "self", ".", "retranslateUi", "(", "MainWindow", ")", "\n", "QtCore", ".", "QMetaObject", ".", "connectSlotsByName", "(", "MainWindow", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.Ui_MainWindow.Ui_MainWindow.retranslateUi": [[109, 122], ["MainWindow.setWindowTitle", "Ui_MainWindow.Ui_MainWindow.inputSentLBL.setText", "Ui_MainWindow.Ui_MainWindow.amrLBL.setText", "Ui_MainWindow.Ui_MainWindow.showGraphPB.setText", "Ui_MainWindow.Ui_MainWindow.toAmrPB.setText", "Ui_MainWindow.Ui_MainWindow.generatedLBL.setText", "Ui_MainWindow.Ui_MainWindow.generatePB.setText", "Ui_MainWindow.Ui_MainWindow.exitPB.setText", "Ui_MainWindow.Ui_MainWindow.menuFile.setTitle", "Ui_MainWindow.Ui_MainWindow.actionLoadAMR.setText", "Ui_MainWindow.Ui_MainWindow.actionSaveAMR.setText", "_translate", "_translate", "_translate", "_translate", "_translate", "_translate", "_translate", "_translate", "_translate", "_translate", "_translate"], "methods", ["None"], ["", "def", "retranslateUi", "(", "self", ",", "MainWindow", ")", ":", "\n", "        ", "_translate", "=", "QtCore", ".", "QCoreApplication", ".", "translate", "\n", "MainWindow", ".", "setWindowTitle", "(", "_translate", "(", "\"MainWindow\"", ",", "\"MainWindow\"", ")", ")", "\n", "self", ".", "inputSentLBL", ".", "setText", "(", "_translate", "(", "\"MainWindow\"", ",", "\"Input Sentence\"", ")", ")", "\n", "self", ".", "amrLBL", ".", "setText", "(", "_translate", "(", "\"MainWindow\"", ",", "\"AMR\"", ")", ")", "\n", "self", ".", "showGraphPB", ".", "setText", "(", "_translate", "(", "\"MainWindow\"", ",", "\"Show Graph\"", ")", ")", "\n", "self", ".", "toAmrPB", ".", "setText", "(", "_translate", "(", "\"MainWindow\"", ",", "\"To AMR\"", ")", ")", "\n", "self", ".", "generatedLBL", ".", "setText", "(", "_translate", "(", "\"MainWindow\"", ",", "\"Generated\"", ")", ")", "\n", "self", ".", "generatePB", ".", "setText", "(", "_translate", "(", "\"MainWindow\"", ",", "\"Generate\"", ")", ")", "\n", "self", ".", "exitPB", ".", "setText", "(", "_translate", "(", "\"MainWindow\"", ",", "\"Exit\"", ")", ")", "\n", "self", ".", "menuFile", ".", "setTitle", "(", "_translate", "(", "\"MainWindow\"", ",", "\"File\"", ")", ")", "\n", "self", ".", "actionLoadAMR", ".", "setText", "(", "_translate", "(", "\"MainWindow\"", ",", "\"Load AMR\"", ")", ")", "\n", "self", ".", "actionSaveAMR", ".", "setText", "(", "_translate", "(", "\"MainWindow\"", ",", "\"Save AMR\"", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.main_window.MainWindow.__init__": [[19, 48], ["PyQt5.QtWidgets.QMainWindow.__init__", "main_window.MainWindow.setupUi", "PyQt5.QtGui.QFontDatabase.systemFont", "PyQt5.QtGui.QFontDatabase.systemFont.setPointSize", "main_window.MainWindow.amrTE.setFont", "main_window.MainWindow.show", "main_window.MainWindow.exitPB.pressed.connect", "main_window.MainWindow.toAmrPB.pressed.connect", "main_window.MainWindow.generatePB.pressed.connect", "main_window.MainWindow.showGraphPB.pressed.connect", "main_window.MainWindow.actionLoadAMR.triggered.connect", "main_window.MainWindow.actionSaveAMR.triggered.connect", "processor_stog.ProcessorSTOG", "processor_gtos.ProcessorGTOS", "PyQt5.QtCore.QTimer", "main_window.MainWindow.startup_timer.setInterval", "main_window.MainWindow.startup_timer.timeout.connect", "main_window.MainWindow.startup_timer.start"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.Ui_MainWindow.Ui_MainWindow.setupUi"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MainWindow", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "config", "=", "config", "\n", "# Setup the UI", "\n", "self", ".", "setupUi", "(", "self", ")", "\n", "fixed_font", "=", "QFontDatabase", ".", "systemFont", "(", "QFontDatabase", ".", "FixedFont", ")", "\n", "fixed_font", ".", "setPointSize", "(", "8", ")", "\n", "#self.inputSentLE.setFont(fixed_font)", "\n", "#self.generatedTE.setFont(fixed_font)", "\n", "self", ".", "amrTE", ".", "setFont", "(", "fixed_font", ")", "\n", "self", ".", "show", "(", ")", "\n", "# Setup the signals/slots for buttons", "\n", "self", ".", "exitPB", ".", "pressed", ".", "connect", "(", "self", ".", "exit_slot", ")", "\n", "self", ".", "toAmrPB", ".", "pressed", ".", "connect", "(", "self", ".", "parse_slot", ")", "\n", "self", ".", "generatePB", ".", "pressed", ".", "connect", "(", "self", ".", "generate_slot", ")", "\n", "self", ".", "showGraphPB", ".", "pressed", ".", "connect", "(", "self", ".", "show_graph_slot", ")", "\n", "# Signals/slots for menu itesm", "\n", "self", ".", "actionLoadAMR", ".", "triggered", ".", "connect", "(", "self", ".", "load_amr_slot", ")", "\n", "self", ".", "actionSaveAMR", ".", "triggered", ".", "connect", "(", "self", ".", "save_amr_slot", ")", "\n", "self", ".", "last_open", "=", "'.'", "\n", "self", ".", "last_save", "=", "'.'", "\n", "# Create the processors", "\n", "self", ".", "stog_processor", "=", "ProcessorSTOG", "(", "self", ".", "config", ",", "disabled", "=", "False", ")", "# Disable for debug", "\n", "self", ".", "gtos_processor", "=", "ProcessorGTOS", "(", "self", ".", "config", ",", "disabled", "=", "False", ")", "\n", "# Set the main window title  / status with a qtimer", "\n", "self", ".", "startup_timer", "=", "QTimer", "(", "self", ")", "\n", "self", ".", "startup_timer", ".", "setInterval", "(", "250", ")", "# ms", "\n", "self", ".", "startup_timer", ".", "timeout", ".", "connect", "(", "self", ".", "set_window_title", ")", "\n", "self", ".", "startup_timer", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.main_window.MainWindow.set_window_title": [[49, 55], ["main_window.MainWindow.stog_processor.is_ready", "main_window.MainWindow.gtos_processor.is_ready", "main_window.MainWindow.setWindowTitle", "main_window.MainWindow.startup_timer.stop", "main_window.MainWindow.setWindowTitle"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.is_ready", "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.is_ready"], ["", "def", "set_window_title", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "stog_processor", ".", "is_ready", "(", ")", "and", "self", ".", "gtos_processor", ".", "is_ready", "(", ")", ":", "\n", "            ", "self", ".", "setWindowTitle", "(", "'AMR Visualization - Ready'", ")", "\n", "self", ".", "startup_timer", ".", "stop", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "setWindowTitle", "(", "'AMR Visualization - Loading Models'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.main_window.MainWindow.exit_slot": [[56, 58], ["sys.exit"], "methods", ["None"], ["", "", "def", "exit_slot", "(", "self", ")", ":", "\n", "        ", "sys", ".", "exit", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.main_window.MainWindow.parse_slot": [[59, 69], ["main_window.MainWindow.inputSentLE.text().strip", "main_window.MainWindow.stog_processor.is_ready", "main_window.MainWindow.stog_processor.run().strip", "main_window.MainWindow.amrTE.setPlainText", "main_window.MainWindow.inputSentLE.text", "main_window.MainWindow.amrTE.setPlainText", "traceback.print_exc", "main_window.MainWindow.stog_processor.run"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.is_ready", "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run"], ["", "def", "parse_slot", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "stog_processor", ".", "is_ready", "(", ")", ":", "\n", "            ", "return", "\n", "", "text", "=", "self", ".", "inputSentLE", ".", "text", "(", ")", ".", "strip", "(", ")", "\n", "try", ":", "\n", "            ", "amr_string", "=", "self", ".", "stog_processor", ".", "run", "(", "text", ")", ".", "strip", "(", ")", "\n", "self", ".", "amrTE", ".", "setPlainText", "(", "amr_string", ")", "\n", "", "except", ":", "\n", "            ", "self", ".", "amrTE", ".", "setPlainText", "(", "'\\nERROR - Not able to parse.'", ")", "\n", "traceback", ".", "print_exc", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.main_window.MainWindow.generate_slot": [[70, 80], ["main_window.MainWindow.amrTE.toPlainText().strip", "main_window.MainWindow.gtos_processor.is_ready", "main_window.MainWindow.gtos_processor.run", "main_window.MainWindow.generatedTE.setPlainText", "main_window.MainWindow.amrTE.toPlainText", "main_window.MainWindow.generatedTE.setPlainText", "traceback.print_exc"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.is_ready", "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.processor_stog.ProcessorSTOG.run"], ["", "", "def", "generate_slot", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "gtos_processor", ".", "is_ready", "(", ")", ":", "\n", "            ", "return", "\n", "", "text", "=", "self", ".", "amrTE", ".", "toPlainText", "(", ")", ".", "strip", "(", ")", "\n", "try", ":", "\n", "            ", "string", "=", "self", ".", "gtos_processor", ".", "run", "(", "text", ")", "\n", "self", ".", "generatedTE", ".", "setPlainText", "(", "string", ")", "\n", "", "except", ":", "\n", "            ", "self", ".", "generatedTE", ".", "setPlainText", "(", "'\\nERROR - Not able to generate.'", ")", "\n", "traceback", ".", "print_exc", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.main_window.MainWindow.show_graph_slot": [[81, 99], ["main_window.MainWindow.amrTE.toPlainText().strip", "main_window.MainWindow.parse_slot", "main_window.MainWindow.amrTE.toPlainText().strip", "main_window.MainWindow.config.get", "main_window.MainWindow.config.get", "graph_processing.amr_plot.AMRPlot", "graph_processing.amr_plot.AMRPlot.build_from_graph", "graph_processing.amr_plot.AMRPlot.view", "main_window.MainWindow.amrTE.toPlainText", "logger.warning", "logger.warning", "traceback.print_exc", "main_window.MainWindow.amrTE.toPlainText"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.amr_view.main_window.MainWindow.parse_slot", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.build_from_graph", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view"], ["", "", "def", "show_graph_slot", "(", "self", ")", ":", "\n", "        ", "text", "=", "self", ".", "amrTE", ".", "toPlainText", "(", ")", ".", "strip", "(", ")", "\n", "# Generate first", "\n", "if", "not", "text", ":", "\n", "            ", "self", ".", "parse_slot", "(", ")", "\n", "text", "=", "self", ".", "amrTE", ".", "toPlainText", "(", ")", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "                ", "logger", ".", "warning", "(", "'No graph to plot'", ")", "\n", "return", "\n", "", "", "try", ":", "\n", "            ", "render_fn", "=", "self", ".", "config", ".", "get", "(", "'render_fn'", ",", "None", ")", "\n", "format", "=", "self", ".", "config", ".", "get", "(", "'render_format'", ",", "'pdf'", ")", "\n", "plot", "=", "AMRPlot", "(", "render_fn", ",", "format", ")", "\n", "plot", ".", "build_from_graph", "(", "text", ")", "\n", "plot", ".", "view", "(", ")", "\n", "", "except", ":", "\n", "            ", "logger", ".", "warning", "(", "'Exception when trying to plot'", ")", "\n", "traceback", ".", "print_exc", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.main_window.MainWindow.load_amr_slot": [[100, 122], ["PyQt5.QtWidgets.QFileDialog", "PyQt5.QtWidgets.QFileDialog.resize", "PyQt5.QtWidgets.QFileDialog.getOpenFileName", "PyQt5.QtWidgets.QInputDialog().getInt", "max", "main_window.MainWindow.inputSentLE.clear", "main_window.MainWindow.generatedTE.clear", "main_window.MainWindow.amrTE.setPlainText", "graph_processing.amr_loading.load_amr_entries", "min", "logger.warning", "PyQt5.QtWidgets.QInputDialog", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading.load_amr_entries"], ["", "", "def", "load_amr_slot", "(", "self", ")", ":", "\n", "# Get the filename from the file dialog", "\n", "        ", "dlg", "=", "QFileDialog", "(", ")", "\n", "dlg", ".", "resize", "(", "100", ",", "100", ")", "\n", "path", ",", "_", "=", "dlg", ".", "getOpenFileName", "(", "self", ",", "\"Open file\"", ",", "self", ".", "last_open", ",", "\"TXT (*.txt);; (*.*)\"", ")", "\n", "self", ".", "last_open", "=", "path", "\n", "if", "not", "path", ":", "\n", "            ", "return", "\n", "# Load the entire file", "\n", "", "try", ":", "\n", "            ", "entries", "=", "load_amr_entries", "(", "path", ")", "\n", "", "except", ":", "\n", "            ", "logger", ".", "warning", "(", "'Unable to load %s'", "%", "path", ")", "\n", "# Find which entry to display", "\n", "", "num", ",", "ok", "=", "QInputDialog", "(", ")", ".", "getInt", "(", "self", ",", "'Which entry to load'", ",", "'Entry number'", ")", "\n", "if", "not", "ok", ":", "return", "\n", "# Load and display the entry", "\n", "num", "=", "max", "(", "0", ",", "min", "(", "num", ",", "len", "(", "entries", ")", "-", "1", ")", ")", "# clip possible values", "\n", "entry", "=", "entries", "[", "num", "]", "\n", "self", ".", "inputSentLE", ".", "clear", "(", ")", "\n", "self", ".", "generatedTE", ".", "clear", "(", ")", "\n", "self", ".", "amrTE", ".", "setPlainText", "(", "entry", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.amr_view.main_window.MainWindow.save_amr_slot": [[123, 136], ["PyQt5.QtWidgets.QFileDialog.getSaveFileName", "main_window.MainWindow.amrTE.toPlainText().strip", "logger.info", "logger.warning", "open", "f.write", "main_window.MainWindow.amrTE.toPlainText"], "methods", ["None"], ["", "def", "save_amr_slot", "(", "self", ")", ":", "\n", "# Get the filename", "\n", "        ", "path", ",", "_", "=", "QFileDialog", ".", "getSaveFileName", "(", "self", ",", "\"Save to file\"", ",", "self", ".", "last_save", ",", "\"TXT (*.txt);; All (*.*)\"", ")", "\n", "self", ".", "last_save", "=", "path", "\n", "if", "not", "path", ":", "\n", "            ", "return", "\n", "", "text", "=", "self", ".", "amrTE", ".", "toPlainText", "(", ")", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "            ", "logger", ".", "warning", "(", "'No AMR to save'", ")", "\n", "return", "\n", "", "with", "open", "(", "path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "text", "+", "'\\n'", ")", "\n", "", "logger", ".", "info", "(", "'File saved to %s'", "%", "path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.__init__": [[205, 237], ["len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "node_list", "=", "None", ",", "node_value_list", "=", "None", ",", "relation_list", "=", "None", ",", "attribute_list", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        node_list: names of nodes in AMR graph, e.g. \"a11\", \"n\"\n        node_value_list: values of nodes in AMR graph, e.g. \"group\" for a node named \"g\"\n        relation_list: list of relations between two nodes\n        attribute_list: list of attributes (links between one node and one constant value)\n\n        \"\"\"", "\n", "# initialize AMR graph nodes using list of nodes name", "\n", "# root, by default, is the first in var_list", "\n", "\n", "if", "node_list", "is", "None", ":", "\n", "            ", "self", ".", "nodes", "=", "[", "]", "\n", "self", ".", "root", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "nodes", "=", "node_list", "[", ":", "]", "\n", "if", "len", "(", "node_list", ")", "!=", "0", ":", "\n", "                ", "self", ".", "root", "=", "node_list", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "root", "=", "None", "\n", "", "", "if", "node_value_list", "is", "None", ":", "\n", "            ", "self", ".", "node_values", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "node_values", "=", "node_value_list", "[", ":", "]", "\n", "", "if", "relation_list", "is", "None", ":", "\n", "            ", "self", ".", "relations", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "relations", "=", "relation_list", "[", ":", "]", "\n", "", "if", "attribute_list", "is", "None", ":", "\n", "            ", "self", ".", "attributes", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "attributes", "=", "attribute_list", "[", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node": [[238, 256], ["range", "enumerate", "enumerate", "len", "list", "str", "d.items"], "methods", ["None"], ["", "", "def", "rename_node", "(", "self", ",", "prefix", ")", ":", "\n", "        ", "\"\"\"\n        Rename AMR graph nodes to prefix + node_index to avoid nodes with the same name in two different AMRs.\n\n        \"\"\"", "\n", "node_map_dict", "=", "{", "}", "\n", "# map each node to its new name (e.g. \"a1\")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "node_map_dict", "[", "self", ".", "nodes", "[", "i", "]", "]", "=", "prefix", "+", "str", "(", "i", ")", "\n", "# update node name", "\n", "", "for", "i", ",", "v", "in", "enumerate", "(", "self", ".", "nodes", ")", ":", "\n", "            ", "self", ".", "nodes", "[", "i", "]", "=", "node_map_dict", "[", "v", "]", "\n", "# update node name in relations", "\n", "", "for", "i", ",", "d", "in", "enumerate", "(", "self", ".", "relations", ")", ":", "\n", "            ", "new_dict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "list", "(", "d", ".", "items", "(", ")", ")", ":", "\n", "                ", "new_dict", "[", "node_map_dict", "[", "k", "]", "]", "=", "v", "\n", "", "self", ".", "relations", "[", "i", "]", "=", "new_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples": [[257, 279], ["range", "len", "instance_triple.append", "list", "list", "smatch_reentracy_srl.AMR.relations[].items", "relation_triple.append", "smatch_reentracy_srl.AMR.attributes[].items", "attribute_triple.append"], "methods", ["None"], ["", "", "def", "get_triples", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the triples in three lists.\n        instance_triple: a triple representing an instance. E.g. instance(w, want-01)\n        attribute triple: relation of attributes, e.g. polarity(w, - )\n        and relation triple, e.g. arg0 (w, b)\n\n        \"\"\"", "\n", "instance_triple", "=", "[", "]", "\n", "relation_triple", "=", "[", "]", "\n", "attribute_triple", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "instance_triple", ".", "append", "(", "(", "\"instance\"", ",", "self", ".", "nodes", "[", "i", "]", ",", "self", ".", "node_values", "[", "i", "]", ")", ")", "\n", "# k is the other node this node has relation with", "\n", "# v is relation name", "\n", "for", "k", ",", "v", "in", "list", "(", "self", ".", "relations", "[", "i", "]", ".", "items", "(", ")", ")", ":", "\n", "                ", "relation_triple", ".", "append", "(", "(", "v", ",", "self", ".", "nodes", "[", "i", "]", ",", "k", ")", ")", "\n", "# k2 is the attribute name", "\n", "# v2 is the attribute value", "\n", "", "for", "k2", ",", "v2", "in", "list", "(", "self", ".", "attributes", "[", "i", "]", ".", "items", "(", ")", ")", ":", "\n", "                ", "attribute_triple", ".", "append", "(", "(", "k2", ",", "self", ".", "nodes", "[", "i", "]", ",", "v2", ")", ")", "\n", "", "", "return", "instance_triple", ",", "attribute_triple", ",", "relation_triple", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples2": [[281, 306], ["range", "len", "instance_triple.append", "list", "list", "smatch_reentracy_srl.AMR.relations[].items", "relation_triple.append", "smatch_reentracy_srl.AMR.attributes[].items", "relation_triple.append"], "methods", ["None"], ["", "def", "get_triples2", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the triples in two lists:\n        instance_triple: a triple representing an instance. E.g. instance(w, want-01)\n        relation_triple: a triple representing all relations. E.g arg0 (w, b) or E.g. polarity(w, - )\n        Note that we do not differentiate between attribute triple and relation triple. Both are considered as relation\n        triples.\n        All triples are represented by (triple_type, argument 1 of the triple, argument 2 of the triple)\n\n        \"\"\"", "\n", "instance_triple", "=", "[", "]", "\n", "relation_triple", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "# an instance triple is instance(node name, node value).", "\n", "# For example, instance(b, boy).", "\n", "            ", "instance_triple", ".", "append", "(", "(", "\"instance\"", ",", "self", ".", "nodes", "[", "i", "]", ",", "self", ".", "node_values", "[", "i", "]", ")", ")", "\n", "# k is the other node this node has relation with", "\n", "# v is relation name", "\n", "for", "k", ",", "v", "in", "list", "(", "self", ".", "relations", "[", "i", "]", ".", "items", "(", ")", ")", ":", "\n", "                ", "relation_triple", ".", "append", "(", "(", "v", ",", "self", ".", "nodes", "[", "i", "]", ",", "k", ")", ")", "\n", "# k2 is the attribute name", "\n", "# v2 is the attribute value", "\n", "", "for", "k2", ",", "v2", "in", "list", "(", "self", ".", "attributes", "[", "i", "]", ".", "items", "(", ")", ")", ":", "\n", "                ", "relation_triple", ".", "append", "(", "(", "k2", ",", "self", ".", "nodes", "[", "i", "]", ",", "v2", ")", ")", "\n", "", "", "return", "instance_triple", ",", "relation_triple", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.__str__": [[308, 323], ["range", "len", "lines.append", "lines.append", "lines.append", "list", "list", "smatch_reentracy_srl.AMR.relations[].items", "lines.append", "smatch_reentracy_srl.AMR.attributes[].items", "lines.append", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Generate AMR string for better readability\n\n        \"\"\"", "\n", "lines", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "nodes", ")", ")", ":", "\n", "            ", "lines", ".", "append", "(", "\"Node \"", "+", "str", "(", "i", ")", "+", "\" \"", "+", "self", ".", "nodes", "[", "i", "]", ")", "\n", "lines", ".", "append", "(", "\"Value: \"", "+", "self", ".", "node_values", "[", "i", "]", ")", "\n", "lines", ".", "append", "(", "\"Relations:\"", ")", "\n", "for", "k", ",", "v", "in", "list", "(", "self", ".", "relations", "[", "i", "]", ".", "items", "(", ")", ")", ":", "\n", "                ", "lines", ".", "append", "(", "\"Node \"", "+", "k", "+", "\" via \"", "+", "v", ")", "\n", "", "for", "k2", ",", "v2", "in", "list", "(", "self", ".", "attributes", "[", "i", "]", ".", "items", "(", ")", ")", ":", "\n", "                ", "lines", ".", "append", "(", "\"Attribute: \"", "+", "k2", "+", "\" value \"", "+", "v2", ")", "\n", "", "", "return", "\"\\n\"", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.__repr__": [[324, 326], ["smatch_reentracy_srl.AMR.__str__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.ATP.generate_amrized_srl.SRL.__str__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__str__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.output_amr": [[327, 333], ["print", "smatch_reentracy_srl.AMR.__str__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.ATP.generate_amrized_srl.SRL.__str__"], ["", "def", "output_amr", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Output AMR string\n\n        \"\"\"", "\n", "print", "(", "self", ".", "__str__", "(", ")", ",", "file", "=", "DEBUG_LOG", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.parse_AMR_line": [[335, 568], ["collections.defaultdict", "collections.defaultdict", "enumerate", "smatch_reentracy_srl.AMR", "line.strip", "relation_list.append", "attribute_list.append", "len", "print", "print", "node_value_list.append", "cur_charseq.append", "cur_charseq.append", "cur_charseq.append", "print", "cur_charseq.append", "temp_attr_value.split", "parts[].strip", "parts[].strip", "cur_charseq.append", "stack.append", "node_name_list.append", "print", "stack.pop", "cur_charseq.append", "len", "print", "len", "print", "node_relation_dict2[].append", "node_relation_dict1[].append", "print", "cur_charseq.append", "len", "print", "temp_attr_value.split", "parts[].strip", "parts[].strip", "parts[].strip.endswith", "cur_relation_name.endswith", "node_relation_dict1[].append", "node_relation_dict1[].append", "len", "print", "node_relation_dict1[].append", "node_relation_dict2[].append", "node_relation_dict1[].append"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "@", "staticmethod", "\n", "def", "parse_AMR_line", "(", "line", ")", ":", "\n", "        ", "\"\"\"\n        Parse a AMR from line representation to an AMR object.\n        This parsing algorithm scans the line once and process each character, in a shift-reduce style.\n\n        \"\"\"", "\n", "# Current state. It denotes the last significant symbol encountered. 1 for (, 2 for :, 3 for /,", "\n", "# and 0 for start state or ')'", "\n", "# Last significant symbol is ( --- start processing node name", "\n", "# Last significant symbol is : --- start processing relation name", "\n", "# Last significant symbol is / --- start processing node value (concept name)", "\n", "# Last significant symbol is ) --- current node processing is complete", "\n", "# Note that if these symbols are inside parenthesis, they are not significant symbols.", "\n", "state", "=", "0", "\n", "# node stack for parsing", "\n", "stack", "=", "[", "]", "\n", "# current not-yet-reduced character sequence", "\n", "cur_charseq", "=", "[", "]", "\n", "# key: node name value: node value", "\n", "node_dict", "=", "{", "}", "\n", "# node name list (order: occurrence of the node)", "\n", "node_name_list", "=", "[", "]", "\n", "# key: node name:  value: list of (relation name, the other node name)", "\n", "node_relation_dict1", "=", "defaultdict", "(", "list", ")", "\n", "# key: node name, value: list of (attribute name, const value) or (relation name, unseen node name)", "\n", "node_relation_dict2", "=", "defaultdict", "(", "list", ")", "\n", "# current relation name", "\n", "cur_relation_name", "=", "\"\"", "\n", "# having unmatched quote string", "\n", "in_quote", "=", "False", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "line", ".", "strip", "(", ")", ")", ":", "\n", "            ", "if", "c", "==", "\" \"", ":", "\n", "# allow space in relation name", "\n", "                ", "if", "state", "==", "2", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "", "continue", "\n", "", "if", "c", "==", "\"\\\"\"", ":", "\n", "# flip in_quote value when a quote symbol is encountered", "\n", "# insert placeholder if in_quote from last symbol", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "'_'", ")", "\n", "", "in_quote", "=", "not", "in_quote", "\n", "", "elif", "c", "==", "\"(\"", ":", "\n", "# not significant symbol if inside quote", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# get the attribute name", "\n", "# e.g :arg0 (x ...", "\n", "# at this point we get \"arg0\"", "\n", "", "if", "state", "==", "2", ":", "\n", "# in this state, current relation name should be empty", "\n", "                    ", "if", "cur_relation_name", "!=", "\"\"", ":", "\n", "                        ", "print", "(", "\"Format error when processing \"", ",", "line", "[", "0", ":", "i", "+", "1", "]", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "# update current relation name for future use", "\n", "", "cur_relation_name", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", ".", "strip", "(", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "", "state", "=", "1", "\n", "", "elif", "c", "==", "\":\"", ":", "\n", "# not significant symbol if inside quote", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# Last significant symbol is \"/\". Now we encounter \":\"", "\n", "# Example:", "\n", "# :OR (o2 / *OR*", "\n", "#    :mod (o3 / official)", "\n", "#  gets node value \"*OR*\" at this point", "\n", "", "if", "state", "==", "3", ":", "\n", "                    ", "node_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "# clear current char sequence", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "# pop node name (\"o2\" in the above example)", "\n", "cur_node_name", "=", "stack", "[", "-", "1", "]", "\n", "# update node name/value map", "\n", "node_dict", "[", "cur_node_name", "]", "=", "node_value", "\n", "# Last significant symbol is \":\". Now we encounter \":\"", "\n", "# Example:", "\n", "# :op1 w :quant 30", "\n", "# or :day 14 :month 3", "\n", "# the problem is that we cannot decide if node value is attribute value (constant)", "\n", "# or node value (variable) at this moment", "\n", "", "elif", "state", "==", "2", ":", "\n", "                    ", "temp_attr_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "parts", "=", "temp_attr_value", ".", "split", "(", ")", "\n", "if", "len", "(", "parts", ")", "<", "2", ":", "\n", "                        ", "print", "(", "\"Error in processing; part len < 2\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "# For the above example, node name is \"op1\", and node value is \"w\"", "\n", "# Note that this node name might not be encountered before", "\n", "", "relation_name", "=", "parts", "[", "0", "]", ".", "strip", "(", ")", "\n", "relation_value", "=", "parts", "[", "1", "]", ".", "strip", "(", ")", "\n", "# We need to link upper level node to the current", "\n", "# top of stack is upper level node", "\n", "if", "len", "(", "stack", ")", "==", "0", ":", "\n", "                        ", "print", "(", "\"Error in processing\"", ",", "line", "[", ":", "i", "]", ",", "relation_name", ",", "relation_value", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "# if we have not seen this node name before", "\n", "", "if", "relation_value", "not", "in", "node_dict", ":", "\n", "                        ", "node_relation_dict2", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "", "else", ":", "\n", "                        ", "node_relation_dict1", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "", "", "state", "=", "2", "\n", "", "elif", "c", "==", "\"/\"", ":", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# Last significant symbol is \"(\". Now we encounter \"/\"", "\n", "# Example:", "\n", "# (d / default-01", "\n", "# get \"d\" here", "\n", "", "if", "state", "==", "1", ":", "\n", "                    ", "node_name", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "# if this node name is already in node_dict, it is duplicate", "\n", "if", "node_name", "in", "node_dict", ":", "\n", "                        ", "print", "(", "\"Duplicate node name \"", ",", "node_name", ",", "\" in parsing AMR\"", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "# push the node name to stack", "\n", "", "stack", ".", "append", "(", "node_name", ")", "\n", "# add it to node name list", "\n", "node_name_list", ".", "append", "(", "node_name", ")", "\n", "# if this node is part of the relation", "\n", "# Example:", "\n", "# :arg1 (n / nation)", "\n", "# cur_relation_name is arg1", "\n", "# node name is n", "\n", "# we have a relation arg1(upper level node, n)", "\n", "if", "cur_relation_name", "!=", "\"\"", ":", "\n", "# if relation name ends with \"-of\", e.g.\"arg0-of\",", "\n", "# it is reverse of some relation. For example, if a is \"arg0-of\" b,", "\n", "# we can also say b is \"arg0\" a.", "\n", "# If the relation name ends with \"-of\", we store the reverse relation.", "\n", "                        ", "if", "not", "cur_relation_name", ".", "endswith", "(", "\"-of\"", ")", ":", "\n", "# stack[-2] is upper_level node we encountered, as we just add node_name to stack", "\n", "                            ", "node_relation_dict1", "[", "stack", "[", "-", "2", "]", "]", ".", "append", "(", "(", "cur_relation_name", ",", "node_name", ")", ")", "\n", "", "else", ":", "\n", "# cur_relation_name[:-3] is to delete \"-of\"", "\n", "                            ", "node_relation_dict1", "[", "node_name", "]", ".", "append", "(", "(", "cur_relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "2", "]", ")", ")", "\n", "# clear current_relation_name", "\n", "", "cur_relation_name", "=", "\"\"", "\n", "", "", "else", ":", "\n", "# error if in other state", "\n", "                    ", "print", "(", "\"Error in parsing AMR\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "", "state", "=", "3", "\n", "", "elif", "c", "==", "\")\"", ":", "\n", "                ", "if", "in_quote", ":", "\n", "                    ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "continue", "\n", "# stack should be non-empty to find upper level node", "\n", "", "if", "len", "(", "stack", ")", "==", "0", ":", "\n", "                    ", "print", "(", "\"Unmatched parenthesis at position\"", ",", "i", ",", "\"in processing\"", ",", "line", "[", "0", ":", "i", "+", "1", "]", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "# Last significant symbol is \":\". Now we encounter \")\"", "\n", "# Example:", "\n", "# :op2 \"Brown\") or :op2 w)", "\n", "# get \\\"Brown\\\" or w here", "\n", "", "if", "state", "==", "2", ":", "\n", "                    ", "temp_attr_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "parts", "=", "temp_attr_value", ".", "split", "(", ")", "\n", "if", "len", "(", "parts", ")", "<", "2", ":", "\n", "                        ", "print", "(", "\"Error processing\"", ",", "line", "[", ":", "i", "+", "1", "]", ",", "temp_attr_value", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "", "relation_name", "=", "parts", "[", "0", "]", ".", "strip", "(", ")", "\n", "relation_value", "=", "parts", "[", "1", "]", ".", "strip", "(", ")", "\n", "# store reverse of the relation", "\n", "# we are sure relation_value is a node here, as \"-of\" relation is only between two nodes", "\n", "if", "relation_name", ".", "endswith", "(", "\"-of\"", ")", ":", "\n", "                        ", "node_relation_dict1", "[", "relation_value", "]", ".", "append", "(", "(", "relation_name", "[", ":", "-", "3", "]", ",", "stack", "[", "-", "1", "]", ")", ")", "\n", "# attribute value not seen before", "\n", "# Note that it might be a constant attribute value, or an unseen node", "\n", "# process this after we have seen all the node names", "\n", "", "elif", "relation_value", "not", "in", "node_dict", ":", "\n", "                        ", "node_relation_dict2", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "", "else", ":", "\n", "                        ", "node_relation_dict1", "[", "stack", "[", "-", "1", "]", "]", ".", "append", "(", "(", "relation_name", ",", "relation_value", ")", ")", "\n", "# Last significant symbol is \"/\". Now we encounter \")\"", "\n", "# Example:", "\n", "# :arg1 (n / nation)", "\n", "# we get \"nation\" here", "\n", "", "", "elif", "state", "==", "3", ":", "\n", "                    ", "node_value", "=", "\"\"", ".", "join", "(", "cur_charseq", ")", "\n", "cur_charseq", "[", ":", "]", "=", "[", "]", "\n", "cur_node_name", "=", "stack", "[", "-", "1", "]", "\n", "# map node name to its value", "\n", "node_dict", "[", "cur_node_name", "]", "=", "node_value", "\n", "# pop from stack, as the current node has been processed", "\n", "", "stack", ".", "pop", "(", ")", "\n", "cur_relation_name", "=", "\"\"", "\n", "state", "=", "0", "\n", "", "else", ":", "\n", "# not significant symbols, so we just shift.", "\n", "                ", "cur_charseq", ".", "append", "(", "c", ")", "\n", "#create data structures to initialize an AMR", "\n", "", "", "node_value_list", "=", "[", "]", "\n", "relation_list", "=", "[", "]", "\n", "attribute_list", "=", "[", "]", "\n", "for", "v", "in", "node_name_list", ":", "\n", "            ", "if", "v", "not", "in", "node_dict", ":", "\n", "                ", "print", "(", "\"Error: Node name not found\"", ",", "v", ",", "file", "=", "ERROR_LOG", ")", "\n", "return", "None", "\n", "", "else", ":", "\n", "                ", "node_value_list", ".", "append", "(", "node_dict", "[", "v", "]", ")", "\n", "# build relation map and attribute map for this node", "\n", "", "relation_dict", "=", "{", "}", "\n", "attribute_dict", "=", "{", "}", "\n", "if", "v", "in", "node_relation_dict1", ":", "\n", "                ", "for", "v1", "in", "node_relation_dict1", "[", "v", "]", ":", "\n", "                    ", "relation_dict", "[", "v1", "[", "1", "]", "]", "=", "v1", "[", "0", "]", "\n", "", "", "if", "v", "in", "node_relation_dict2", ":", "\n", "                ", "for", "v2", "in", "node_relation_dict2", "[", "v", "]", ":", "\n", "# if value is in quote, it is a constant value", "\n", "# strip the quote and put it in attribute map", "\n", "                    ", "if", "v2", "[", "1", "]", "[", "0", "]", "==", "\"\\\"\"", "and", "v2", "[", "1", "]", "[", "-", "1", "]", "==", "\"\\\"\"", ":", "\n", "                        ", "attribute_dict", "[", "v2", "[", "0", "]", "]", "=", "v2", "[", "1", "]", "[", "1", ":", "-", "1", "]", "\n", "# if value is a node name", "\n", "", "elif", "v2", "[", "1", "]", "in", "node_dict", ":", "\n", "                        ", "relation_dict", "[", "v2", "[", "1", "]", "]", "=", "v2", "[", "0", "]", "\n", "", "else", ":", "\n", "                        ", "attribute_dict", "[", "v2", "[", "0", "]", "]", "=", "v2", "[", "1", "]", "\n", "# each node has a relation map and attribute map", "\n", "", "", "", "relation_list", ".", "append", "(", "relation_dict", ")", "\n", "attribute_list", ".", "append", "(", "attribute_dict", ")", "\n", "# add TOP as an attribute. The attribute value is the top node value", "\n", "", "if", "len", "(", "node_value_list", ")", "==", "0", ":", "print", "(", "line", ")", "\n", "attribute_list", "[", "0", "]", "[", "\"TOP\"", "]", "=", "node_value_list", "[", "0", "]", "\n", "result_amr", "=", "AMR", "(", "node_name_list", ",", "node_value_list", ",", "relation_list", ",", "attribute_list", ")", "\n", "return", "result_amr", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.compute_reentracy_srl": [[25, 60], ["zip", "smatch_reentracy_srl.compute_smatch_2", "smatch_reentracy_srl.compute_smatch_2", "smatch_reentracy_srl.AMR.parse_AMR_line", "smatch_reentracy_srl.var2concept", "triples_pred.extend", "smatch_reentracy_srl.AMR.parse_AMR_line", "smatch_reentracy_srl.var2concept", "triples_gold.extend", "reentrancies_pred.append", "reentrancies_gold.append", "srl_pred.append", "srl_gold.append", "AMR.parse_AMR_line.replace", "logger.error", "AMR.parse_AMR_line.replace", "logger.error", "smatch_reentracy_srl.reentrancy", "smatch_reentracy_srl.reentrancy", "smatch_reentracy_srl.srl", "smatch_reentracy_srl.srl", "AMR.parse_AMR_line.get_triples", "AMR.parse_AMR_line.get_triples", "AMR.parse_AMR_line.get_triples", "AMR.parse_AMR_line.get_triples"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.compute_smatch_2", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.compute_smatch_2", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.parse_AMR_line", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.var2concept", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.parse_AMR_line", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.var2concept", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.reentrancy", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.reentrancy", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.srl", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.srl", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples"], ["def", "compute_reentracy_srl", "(", "pred", ",", "gold", ")", ":", "\n", "    ", "reentrancies_pred", "=", "[", "]", "\n", "reentrancies_gold", "=", "[", "]", "\n", "srl_pred", "=", "[", "]", "\n", "srl_gold", "=", "[", "]", "\n", "# Loop through all entries", "\n", "for", "amr_pred", ",", "amr_gold", "in", "zip", "(", "pred", ",", "gold", ")", ":", "\n", "# Create the predicted data", "\n", "        ", "amr_pred", "=", "AMR", ".", "parse_AMR_line", "(", "amr_pred", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", "\n", "if", "amr_pred", "is", "None", ":", "\n", "            ", "logger", ".", "error", "(", "'Empty amr_pred entry'", ")", "\n", "continue", "\n", "", "dict_pred", "=", "var2concept", "(", "amr_pred", ")", "\n", "triples_pred", "=", "[", "t", "for", "t", "in", "amr_pred", ".", "get_triples", "(", ")", "[", "1", "]", "]", "\n", "triples_pred", ".", "extend", "(", "[", "t", "for", "t", "in", "amr_pred", ".", "get_triples", "(", ")", "[", "2", "]", "]", ")", "\n", "# Create the gold data", "\n", "amr_gold", "=", "AMR", ".", "parse_AMR_line", "(", "amr_gold", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", "\n", "if", "amr_gold", "is", "None", ":", "\n", "            ", "logger", ".", "error", "(", "'Empty amr_gold entry'", ")", "\n", "continue", "\n", "", "dict_gold", "=", "var2concept", "(", "amr_gold", ")", "\n", "triples_gold", "=", "[", "t", "for", "t", "in", "amr_gold", ".", "get_triples", "(", ")", "[", "1", "]", "]", "\n", "triples_gold", ".", "extend", "(", "[", "t", "for", "t", "in", "amr_gold", ".", "get_triples", "(", ")", "[", "2", "]", "]", ")", "\n", "# Rentracies data", "\n", "reentrancies_pred", ".", "append", "(", "reentrancy", "(", "dict_pred", ",", "triples_pred", ")", ")", "\n", "reentrancies_gold", ".", "append", "(", "reentrancy", "(", "dict_gold", ",", "triples_gold", ")", ")", "\n", "# SRL data", "\n", "srl_pred", ".", "append", "(", "srl", "(", "dict_pred", ",", "triples_pred", ")", ")", "\n", "srl_gold", ".", "append", "(", "srl", "(", "dict_gold", ",", "triples_gold", ")", ")", "\n", "\n", "# Compute and add reentracies/SRL smatch scores to dictionary", "\n", "", "rdict", "=", "{", "}", "\n", "rdict", "[", "'Reentrancies'", "]", "=", "compute_smatch_2", "(", "reentrancies_pred", ",", "reentrancies_gold", ")", "\n", "rdict", "[", "'SRL'", "]", "=", "compute_smatch_2", "(", "srl_pred", ",", "srl_gold", ")", "\n", "return", "rdict", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.compute_smatch_2": [[62, 74], ["zip", "multiprocessing.Pool", "multiprocessing.Pool.imap_unordered", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "smatch.compute_f"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f"], ["", "def", "compute_smatch_2", "(", "list1", ",", "list2", ")", ":", "\n", "    ", "num_match", ",", "num_test", ",", "num_gold", "=", "(", "0", ",", "0", ",", "0", ")", "\n", "pairs", "=", "zip", "(", "list1", ",", "list2", ")", "\n", "pool", "=", "Pool", "(", ")", "\n", "for", "(", "n1", ",", "n2", ",", "n3", ")", "in", "pool", ".", "imap_unordered", "(", "match_pair_2", ",", "pairs", ")", ":", "\n", "        ", "num_match", "+=", "n1", "\n", "num_test", "+=", "n2", "\n", "num_gold", "+=", "n3", "\n", "", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "precision", ",", "recall", ",", "f_score", "=", "smatch", ".", "compute_f", "(", "num_match", ",", "num_test", ",", "num_gold", ")", "\n", "return", "precision", ",", "recall", ",", "f_score", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.match_pair_2": [[76, 92], ["smatch.match_triple_dict.clear", "smatch_reentracy_srl.parse_relations", "smatch_reentracy_srl.parse_relations", "parse_relations.rename_node", "parse_relations.rename_node", "parse_relations.get_triples", "parse_relations.get_triples", "smatch.get_best_match", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.parse_relations", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.parse_relations", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.rename_node", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.get_best_match"], ["", "def", "match_pair_2", "(", "pair", ")", ":", "\n", "    ", "(", "lst_amr1", ",", "dic_amr1", ")", ",", "(", "lst_amr2", ",", "dic_amr2", ")", "=", "pair", "\n", "prefix1", "=", "'a'", "\n", "prefix2", "=", "'b'", "\n", "smatch", ".", "match_triple_dict", ".", "clear", "(", ")", "\n", "amr1", "=", "parse_relations", "(", "lst_amr1", ",", "dic_amr1", ")", "\n", "amr2", "=", "parse_relations", "(", "lst_amr2", ",", "dic_amr2", ")", "\n", "amr1", ".", "rename_node", "(", "prefix1", ")", "# Rename node to \"a1\", \"a2\", .etc", "\n", "amr2", ".", "rename_node", "(", "prefix2", ")", "# Rename node to \"b1\", \"b2\", .etc", "\n", "inst1", ",", "attrib1", ",", "rel1", "=", "amr1", ".", "get_triples", "(", ")", "\n", "inst2", ",", "attrib2", ",", "rel2", "=", "amr2", ".", "get_triples", "(", ")", "\n", "_", ",", "best_match_num", "=", "smatch", ".", "get_best_match", "(", "inst1", ",", "attrib1", ",", "rel1", ",", "inst2", ",", "attrib2", ",", "rel2", ",", "\n", "prefix1", ",", "prefix2", ")", "\n", "num_test", "=", "len", "(", "inst1", ")", "+", "len", "(", "attrib1", ")", "+", "len", "(", "rel1", ")", "\n", "num_gold", "=", "len", "(", "inst2", ")", "+", "len", "(", "attrib2", ")", "+", "len", "(", "rel2", ")", "\n", "return", "best_match_num", ",", "num_test", ",", "num_gold", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.var2concept": [[95, 100], ["zip"], "function", ["None"], ["", "def", "var2concept", "(", "amr", ")", ":", "\n", "    ", "v2c", "=", "{", "}", "\n", "for", "n", ",", "v", "in", "zip", "(", "amr", ".", "nodes", ",", "amr", ".", "node_values", ")", ":", "\n", "        ", "v2c", "[", "n", "]", "=", "v", "\n", "", "return", "v2c", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.parse_relations": [[102, 124], ["smatch_reentracy_srl.AMR", "len", "len", "rel_dict.append", "att_dict.append", "var_list.append", "conc_list.append", "var_list.append", "conc_list.append", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["", "def", "parse_relations", "(", "rels", ",", "v2c", ")", ":", "\n", "    ", "var_list", "=", "[", "]", "\n", "conc_list", "=", "[", "]", "\n", "for", "r", "in", "rels", ":", "\n", "        ", "if", "str", "(", "r", "[", "1", "]", ")", "not", "in", "var_list", "and", "str", "(", "r", "[", "1", "]", ")", "!=", "\"TOP\"", "and", "r", "[", "1", "]", "in", "v2c", ":", "\n", "            ", "var_list", ".", "append", "(", "str", "(", "r", "[", "1", "]", ")", ")", "\n", "conc_list", ".", "append", "(", "str", "(", "v2c", "[", "r", "[", "1", "]", "]", ")", ")", "\n", "", "if", "str", "(", "r", "[", "2", "]", ")", "not", "in", "var_list", "and", "r", "[", "2", "]", "in", "v2c", ":", "\n", "            ", "var_list", ".", "append", "(", "str", "(", "r", "[", "2", "]", ")", ")", "\n", "conc_list", ".", "append", "(", "str", "(", "v2c", "[", "r", "[", "2", "]", "]", ")", ")", "\n", "", "", "k", "=", "0", "\n", "rel_dict", "=", "[", "]", "*", "len", "(", "var_list", ")", "\n", "att_dict", "=", "[", "]", "*", "len", "(", "var_list", ")", "\n", "for", "v", "in", "var_list", ":", "\n", "        ", "rel_dict", ".", "append", "(", "{", "}", ")", "\n", "att_dict", ".", "append", "(", "{", "}", ")", "\n", "for", "i", "in", "rels", ":", "\n", "            ", "if", "str", "(", "i", "[", "1", "]", ")", "==", "str", "(", "v", ")", "and", "i", "[", "2", "]", "in", "v2c", ":", "\n", "                ", "rel_dict", "[", "k", "]", "[", "str", "(", "i", "[", "2", "]", ")", "]", "=", "i", "[", "0", "]", "\n", "att_dict", "[", "k", "]", "[", "i", "[", "0", "]", "]", "=", "str", "(", "v2c", "[", "i", "[", "2", "]", "]", ")", "\n", "", "", "k", "+=", "1", "\n", "", "return", "AMR", "(", "var_list", ",", "conc_list", ",", "rel_dict", ",", "att_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.reentrancy": [[126, 142], ["list", "v2c_dict.keys", "len", "lst.append", "vrs.extend"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend"], ["", "def", "reentrancy", "(", "v2c_dict", ",", "triples", ")", ":", "\n", "    ", "lst", "=", "[", "]", "\n", "vrs", "=", "[", "]", "\n", "for", "n", "in", "list", "(", "v2c_dict", ".", "keys", "(", ")", ")", ":", "\n", "        ", "parents", "=", "[", "(", "l", ",", "v1", ",", "v2", ")", "for", "(", "l", ",", "v1", ",", "v2", ")", "in", "triples", "if", "v2", "==", "n", "and", "l", "!=", "\"instance\"", "]", "\n", "if", "len", "(", "parents", ")", ">", "1", ":", "\n", "#extract triples involving this (multi-parent) node", "\n", "            ", "for", "t", "in", "parents", ":", "\n", "                ", "lst", ".", "append", "(", "t", ")", "\n", "vrs", ".", "extend", "(", "[", "t", "[", "1", "]", ",", "t", "[", "2", "]", "]", ")", "\n", "#collect var/concept pairs for all extracted nodes", "\n", "", "", "", "dict1", "=", "{", "}", "\n", "for", "i", "in", "v2c_dict", ":", "\n", "        ", "if", "i", "in", "vrs", ":", "\n", "            ", "dict1", "[", "i", "]", "=", "v2c_dict", "[", "i", "]", "\n", "", "", "return", "(", "lst", ",", "dict1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.srl": [[144, 164], ["t[].startswith", "t[].endswith", "lst.append", "vrs.extend", "lst.append", "vrs.extend"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend"], ["", "def", "srl", "(", "v2c_dict", ",", "triples", ")", ":", "\n", "    ", "lst", "=", "[", "]", "\n", "vrs", "=", "[", "]", "\n", "for", "t", "in", "triples", ":", "\n", "        ", "if", "t", "[", "0", "]", ".", "startswith", "(", "\"ARG\"", ")", ":", "\n", "#although the smatch code we use inverts the -of relations", "\n", "#there seems to be cases where this is not done so we invert", "\n", "#them here", "\n", "            ", "if", "t", "[", "0", "]", ".", "endswith", "(", "\"of\"", ")", ":", "\n", "                ", "lst", ".", "append", "(", "(", "t", "[", "0", "]", "[", "0", ":", "-", "3", "]", ",", "t", "[", "2", "]", ",", "t", "[", "1", "]", ")", ")", "\n", "vrs", ".", "extend", "(", "[", "t", "[", "2", "]", ",", "t", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "lst", ".", "append", "(", "t", ")", "\n", "vrs", ".", "extend", "(", "[", "t", "[", "1", "]", ",", "t", "[", "2", "]", "]", ")", "\n", "#collect var/concept pairs for all extracted nodes", "\n", "", "", "", "dict1", "=", "{", "}", "\n", "for", "i", "in", "v2c_dict", ":", "\n", "        ", "if", "i", "in", "vrs", ":", "\n", "            ", "dict1", "[", "i", "]", "=", "v2c_dict", "[", "i", "]", "\n", "", "", "return", "(", "lst", ",", "dict1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.alignment_scorer.AlignmentScorer.__init__": [[25, 31], ["zip", "len", "len", "alignment_scorer.AlignmentScorer._add_score", "len", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.evaluate.alignment_scorer.AlignmentScorer._add_score"], ["    ", "def", "__init__", "(", "self", ",", "gold_alignments", ",", "test_alignments", ")", ":", "\n", "        ", "assert", "len", "(", "gold_alignments", ")", "==", "len", "(", "test_alignments", ")", ",", "'%s != %s'", "%", "(", "len", "(", "gold_alignments", ")", ",", "len", "(", "test_alignments", ")", ")", "\n", "self", ".", "precision_scores", "=", "[", "]", "\n", "self", ".", "recall_scores", "=", "[", "]", "\n", "for", "y_true", ",", "y_pred", "in", "zip", "(", "gold_alignments", ",", "test_alignments", ")", ":", "\n", "            ", "self", ".", "_add_score", "(", "y_true", ",", "y_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.alignment_scorer.AlignmentScorer._add_score": [[32, 42], ["len", "set().intersection", "len", "alignment_scorer.AlignmentScorer.precision_scores.append", "alignment_scorer.AlignmentScorer.precision_scores.append", "len", "alignment_scorer.AlignmentScorer.recall_scores.append", "alignment_scorer.AlignmentScorer.recall_scores.append", "set", "set", "len", "len"], "methods", ["None"], ["", "", "def", "_add_score", "(", "self", ",", "y_true", ",", "y_pred", ")", ":", "\n", "        ", "intersection", "=", "len", "(", "set", "(", "y_pred", ")", ".", "intersection", "(", "set", "(", "y_true", ")", ")", ")", "\n", "if", "len", "(", "y_pred", ")", ">", "0", ":", "\n", "            ", "self", ".", "precision_scores", ".", "append", "(", "intersection", "/", "len", "(", "y_pred", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "precision_scores", ".", "append", "(", "0", ")", "\n", "", "if", "len", "(", "y_true", ")", ">", "0", ":", "\n", "            ", "self", ".", "recall_scores", ".", "append", "(", "intersection", "/", "len", "(", "y_true", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "recall_scores", ".", "append", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.alignment_scorer.AlignmentScorer.get_precision_recall_f1": [[43, 51], ["sum", "len", "sum", "len"], "methods", ["None"], ["", "", "def", "get_precision_recall_f1", "(", "self", ")", ":", "\n", "        ", "precision", "=", "sum", "(", "self", ".", "precision_scores", ")", "/", "len", "(", "self", ".", "precision_scores", ")", "\n", "recall", "=", "sum", "(", "self", ".", "recall_scores", ")", "/", "len", "(", "self", ".", "recall_scores", ")", "\n", "if", "precision", "+", "recall", ">", "0", ":", "\n", "            ", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "", "else", ":", "\n", "            ", "f1", "=", "0", "\n", "", "return", "precision", ",", "recall", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.alignment_scorer.AlignmentScorer.__str__": [[52, 57], ["alignment_scorer.AlignmentScorer.get_precision_recall_f1"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.evaluate.alignment_scorer.AlignmentScorer.get_precision_recall_f1"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "precision", ",", "recall", ",", "f1", "=", "self", ".", "get_precision_recall_f1", "(", ")", "\n", "string", "=", "''", "\n", "string", "+=", "'Precision: {:.2f}   Recall: {:.2f}   F1: {:.2f}'", ".", "format", "(", "100.", "*", "precision", ",", "100.", "*", "recall", ",", "100.", "*", "f1", ")", "\n", "return", "string", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.alignment_scorer.load_gold_alignments": [[5, 20], ["len", "open", "len", "line[].strip.startswith", "line[].strip", "ids.append", "line[].strip.startswith", "line[].strip.strip", "line[].strip", "alignments.append", "p.strip", "line[].strip.split", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["def", "load_gold_alignments", "(", "fn", ")", ":", "\n", "    ", "ids", "=", "[", "]", "\n", "alignments", "=", "[", "]", "\n", "with", "open", "(", "fn", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "line", ".", "startswith", "(", "'# ::id'", ")", ":", "\n", "                ", "line", "=", "line", "[", "len", "(", "'# ::id'", ")", "+", "1", ":", "]", ".", "strip", "(", ")", "\n", "ids", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "elif", "line", ".", "startswith", "(", "'# ::alignments'", ")", ":", "\n", "                ", "line", "=", "line", "[", "len", "(", "'# ::alignments'", ")", "+", "1", ":", "]", ".", "strip", "(", ")", "\n", "parts", "=", "[", "p", ".", "strip", "(", ")", "for", "p", "in", "line", ".", "split", "(", ")", "]", "\n", "parts", "=", "[", "p", "for", "p", "in", "parts", "if", "p", "]", "\n", "alignments", ".", "append", "(", "parts", ")", "\n", "", "", "", "assert", "len", "(", "alignments", ")", "==", "100", ",", "len", "(", "alignments", ")", "\n", "return", "alignments", ",", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.redirect_smatch_errors": [[41, 50], ["open", "atexit.register"], "function", ["None"], ["def", "redirect_smatch_errors", "(", "fname", ")", ":", "\n", "    ", "global", "smatch_log_f", "\n", "smatch_log_f", "=", "open", "(", "fname", ",", "'w'", ",", "buffering", "=", "1", ")", "# line buffering", "\n", "amr", ".", "ERROR_LOG", "=", "smatch_log_f", "\n", "amr", ".", "DEBUG_LOG", "=", "smatch_log_f", "\n", "smatch", ".", "ERROR_LOG", "=", "smatch_log_f", "\n", "smatch", ".", "DEBUG_LOG", "=", "smatch_log_f", "\n", "import", "atexit", "\n", "atexit", ".", "register", "(", "close_smatch_log", ")", "\n", "", "def", "close_smatch_log", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.close_smatch_log": [[50, 54], ["smatch_log_f.close"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close"], ["", "def", "close_smatch_log", "(", ")", ":", "\n", "    ", "global", "smatch_log_f", "\n", "if", "smatch_log_f", "is", "not", "None", ":", "\n", "        ", "smatch_log_f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.compute_smatch": [[58, 70], ["zip", "multiprocessing.Pool", "multiprocessing.Pool.imap_unordered", "multiprocessing.Pool.close", "multiprocessing.Pool.join", "smatch.compute_f"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.smatch_old.smatch_fromsubgraphs.compute_f"], ["", "", "def", "compute_smatch", "(", "test_entries", ",", "gold_entries", ")", ":", "\n", "    ", "pairs", "=", "zip", "(", "test_entries", ",", "gold_entries", ")", "\n", "mum_match", "=", "mum_test", "=", "mum_gold", "=", "0", "\n", "pool", "=", "Pool", "(", ")", "\n", "for", "(", "n1", ",", "n2", ",", "n3", ")", "in", "pool", ".", "imap_unordered", "(", "match_pair", ",", "pairs", ")", ":", "\n", "        ", "mum_match", "+=", "n1", "\n", "mum_test", "+=", "n2", "\n", "mum_gold", "+=", "n3", "\n", "", "pool", ".", "close", "(", ")", "\n", "pool", ".", "join", "(", ")", "\n", "precision", ",", "recall", ",", "f_score", "=", "smatch", ".", "compute_f", "(", "mum_match", ",", "mum_test", ",", "mum_gold", ")", "\n", "return", "precision", ",", "recall", ",", "f_score", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.compute_scores": [[72, 98], ["smatch_enhanced.get_entries", "smatch_enhanced.get_entries", "smatch_enhanced.compute_smatch", "smatch_enhanced.output_score", "smatch_enhanced.compute_smatch", "smatch_enhanced.output_score", "smatch_enhanced.compute_smatch", "smatch_enhanced.output_score", "smatch_enhanced.compute_subscores", "smatch_reentracy_srl.compute_reentracy_srl.items", "smatch_reentracy_srl.compute_reentracy_srl", "smatch_reentracy_srl.compute_reentracy_srl.items", "len", "len", "smatch_enhanced.unlabel", "smatch_enhanced.unlabel", "smatch_enhanced.remove_wsd", "smatch_enhanced.remove_wsd", "smatch_enhanced.output_score", "smatch_enhanced.output_score", "len", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.get_entries", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.get_entries", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.compute_smatch", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.output_score", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.compute_smatch", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.output_score", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.compute_smatch", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.output_score", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.compute_subscores", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.compute_reentracy_srl", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.unlabel", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.unlabel", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.remove_wsd", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.remove_wsd", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.output_score", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.output_score"], ["", "def", "compute_scores", "(", "test_fn", ",", "gold_fn", ")", ":", "\n", "# Get the graph from each entry in each file", "\n", "    ", "test_entries", "=", "get_entries", "(", "test_fn", ")", "\n", "gold_entries", "=", "get_entries", "(", "gold_fn", ")", "\n", "assert", "len", "(", "test_entries", ")", "==", "len", "(", "gold_entries", ")", ",", "'%d != %d'", "%", "(", "len", "(", "test_entries", ")", ",", "len", "(", "gold_entries", ")", ")", "\n", "# Compute standard smatch scores", "\n", "precision", ",", "recall", ",", "f_score", "=", "compute_smatch", "(", "test_entries", ",", "gold_entries", ")", "\n", "output_score", "(", "'Smatch'", ",", "precision", ",", "recall", ",", "f_score", ")", "\n", "# Compute unlabeled data", "\n", "tes", "=", "[", "unlabel", "(", "e", ")", "for", "e", "in", "test_entries", "]", "\n", "ges", "=", "[", "unlabel", "(", "e", ")", "for", "e", "in", "gold_entries", "]", "\n", "precision", ",", "recall", ",", "f_score", "=", "compute_smatch", "(", "tes", ",", "ges", ")", "\n", "output_score", "(", "'Unlabeled'", ",", "precision", ",", "recall", ",", "f_score", ")", "\n", "# Compute withough Word Sense Disambiguation", "\n", "tes", "=", "[", "remove_wsd", "(", "e", ")", "for", "e", "in", "test_entries", "]", "\n", "ges", "=", "[", "remove_wsd", "(", "e", ")", "for", "e", "in", "gold_entries", "]", "\n", "precision", ",", "recall", ",", "f_score", "=", "compute_smatch", "(", "tes", ",", "ges", ")", "\n", "output_score", "(", "'No WSD'", ",", "precision", ",", "recall", ",", "f_score", ")", "\n", "# get the other misc sub-scores", "\n", "score_dict", "=", "compute_subscores", "(", "test_entries", ",", "gold_entries", ")", "\n", "for", "stype", ",", "(", "pr", ",", "rc", ",", "f", ")", "in", "score_dict", ".", "items", "(", ")", ":", "\n", "        ", "output_score", "(", "stype", ",", "pr", ",", "rc", ",", "f", ")", "\n", "# Get the Reentracies and SRL scores", "\n", "", "score_dict", "=", "compute_reentracy_srl", "(", "test_entries", ",", "gold_entries", ")", "\n", "for", "stype", ",", "(", "pr", ",", "rc", ",", "f", ")", "in", "score_dict", ".", "items", "(", ")", ":", "\n", "        ", "output_score", "(", "stype", ",", "pr", ",", "rc", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.get_entries": [[101, 114], ["f.read.split", "open", "f.read", "re.sub.replace", "re.sub", "l.strip", "entries.append", "e.splitlines", "l.startswith"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "", "def", "get_entries", "(", "fname", ")", ":", "\n", "    ", "with", "open", "(", "fname", ")", "as", "f", ":", "\n", "        ", "data", "=", "f", ".", "read", "(", ")", "\n", "", "entries", "=", "[", "]", "\n", "for", "e", "in", "data", ".", "split", "(", "'\\n\\n'", ")", ":", "\n", "        ", "lines", "=", "[", "l", ".", "strip", "(", ")", "for", "l", "in", "e", ".", "splitlines", "(", ")", "]", "\n", "lines", "=", "[", "l", "for", "l", "in", "lines", "if", "(", "l", "and", "not", "l", ".", "startswith", "(", "'#'", ")", ")", "]", "\n", "string", "=", "' '", ".", "join", "(", "lines", ")", "\n", "string", "=", "string", ".", "replace", "(", "'\\t'", ",", "' '", ")", "# replace tabs with a space", "\n", "string", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "string", ")", "# squeeze multiple spaces into a single", "\n", "if", "string", ":", "\n", "            ", "entries", ".", "append", "(", "string", ")", "\n", "", "", "return", "entries", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.output_score": [[120, 122], ["print"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "output_score", "(", "stype", ",", "precision", ",", "recall", ",", "f_score", ")", ":", "\n", "    ", "print", "(", "'%-16s -> P: %.3f,  R: %.3f,  F: %.3f'", "%", "(", "stype", ",", "precision", ",", "recall", ",", "f_score", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.match_pair": [[124, 132], ["smatch.match_triple_dict.clear", "smatch.get_amr_match"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.smatch.smatch_amrFC.get_amr_match"], ["", "def", "match_pair", "(", "pair", ")", ":", "\n", "    ", "amr1", ",", "amr2", "=", "pair", "\n", "smatch", ".", "match_triple_dict", ".", "clear", "(", ")", "# clear the matching triple dictionary", "\n", "try", ":", "\n", "        ", "ret", "=", "smatch", ".", "get_amr_match", "(", "amr1", ",", "amr2", ")", "\n", "return", "ret", "\n", "", "except", ":", "\n", "        ", "return", "0", ",", "0", ",", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.var2concept": [[134, 139], ["zip"], "function", ["None"], ["", "", "def", "var2concept", "(", "amr", ")", ":", "\n", "    ", "v2c", "=", "{", "}", "\n", "for", "n", ",", "v", "in", "zip", "(", "amr", ".", "nodes", ",", "amr", ".", "node_values", ")", ":", "\n", "        ", "v2c", "[", "n", "]", "=", "v", "\n", "", "return", "v2c", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.compute_subscores": [[141, 213], ["collections.defaultdict", "collections.defaultdict", "collections.defaultdict", "zip", "collections.OrderedDict", "amr.AMR.parse_AMR_line", "smatch_enhanced.var2concept", "triples_pred.extend", "amr.AMR.parse_AMR_line", "smatch_enhanced.var2concept", "triples_gold.extend", "smatch_enhanced.non_sense_frames", "smatch_enhanced.non_sense_frames", "len", "len", "len", "smatch_enhanced.wikification", "smatch_enhanced.wikification", "len", "len", "len", "smatch_enhanced.namedent", "smatch_enhanced.namedent", "len", "len", "len", "smatch_enhanced.negations", "smatch_enhanced.negations", "len", "len", "len", "smatch_enhanced.everything", "smatch_enhanced.everything", "len", "len", "len", "smatch_enhanced.concepts", "smatch_enhanced.concepts", "len", "len", "len", "smatch_enhanced.frames", "smatch_enhanced.frames", "len", "len", "len", "amr.AMR.parse_AMR_line.replace", "logger.error", "amr.AMR.parse_AMR_line.replace", "logger.error", "list", "set", "set", "list", "set", "set", "list", "set", "set", "list", "set", "set", "list", "set", "set", "list", "set", "set", "list", "set", "set", "float", "float", "amr.AMR.parse_AMR_line.get_triples", "amr.AMR.parse_AMR_line.get_triples", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "set", "amr.AMR.parse_AMR_line.get_triples", "amr.AMR.parse_AMR_line.get_triples"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.parse_AMR_line", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.var2concept", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.parse_AMR_line", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.var2concept", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.non_sense_frames", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.non_sense_frames", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.wikification", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.wikification", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.namedent", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.namedent", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.negations", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.negations", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.everything", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.everything", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.concepts", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.concepts", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.frames", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.frames", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_reentracy_srl.AMR.get_triples"], ["", "def", "compute_subscores", "(", "pred", ",", "gold", ")", ":", "\n", "    ", "inters", "=", "defaultdict", "(", "int", ")", "\n", "golds", "=", "defaultdict", "(", "int", ")", "\n", "preds", "=", "defaultdict", "(", "int", ")", "\n", "# Loop through all entries", "\n", "for", "amr_pred", ",", "amr_gold", "in", "zip", "(", "pred", ",", "gold", ")", ":", "\n", "# Create the predicted data", "\n", "        ", "amr_pred", "=", "amr", ".", "AMR", ".", "parse_AMR_line", "(", "amr_pred", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", "\n", "if", "amr_pred", "is", "None", ":", "\n", "            ", "logger", ".", "error", "(", "'Empty amr_pred entry'", ")", "\n", "continue", "\n", "", "dict_pred", "=", "var2concept", "(", "amr_pred", ")", "\n", "triples_pred", "=", "[", "t", "for", "t", "in", "amr_pred", ".", "get_triples", "(", ")", "[", "1", "]", "]", "\n", "triples_pred", ".", "extend", "(", "[", "t", "for", "t", "in", "amr_pred", ".", "get_triples", "(", ")", "[", "2", "]", "]", ")", "\n", "# Create the gold data", "\n", "amr_gold", "=", "amr", ".", "AMR", ".", "parse_AMR_line", "(", "amr_gold", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", "\n", "if", "amr_gold", "is", "None", ":", "\n", "            ", "logger", ".", "error", "(", "'Empty amr_gold entry'", ")", "\n", "continue", "\n", "", "dict_gold", "=", "var2concept", "(", "amr_gold", ")", "\n", "triples_gold", "=", "[", "t", "for", "t", "in", "amr_gold", ".", "get_triples", "(", ")", "[", "1", "]", "]", "\n", "triples_gold", ".", "extend", "(", "[", "t", "for", "t", "in", "amr_gold", ".", "get_triples", "(", ")", "[", "2", "]", "]", ")", "\n", "# Non_sense_frames scores", "\n", "list_pred", "=", "non_sense_frames", "(", "dict_pred", ")", "\n", "list_gold", "=", "non_sense_frames", "(", "dict_gold", ")", "\n", "inters", "[", "\"Non_sense_frames\"", "]", "+=", "len", "(", "list", "(", "set", "(", "list_pred", ")", "&", "set", "(", "list_gold", ")", ")", ")", "\n", "preds", "[", "\"Non_sense_frames\"", "]", "+=", "len", "(", "set", "(", "list_pred", ")", ")", "\n", "golds", "[", "\"Non_sense_frames\"", "]", "+=", "len", "(", "set", "(", "list_gold", ")", ")", "\n", "# Wikification scores", "\n", "list_pred", "=", "wikification", "(", "triples_pred", ")", "\n", "list_gold", "=", "wikification", "(", "triples_gold", ")", "\n", "inters", "[", "\"Wikification\"", "]", "+=", "len", "(", "list", "(", "set", "(", "list_pred", ")", "&", "set", "(", "list_gold", ")", ")", ")", "\n", "preds", "[", "\"Wikification\"", "]", "+=", "len", "(", "set", "(", "list_pred", ")", ")", "\n", "golds", "[", "\"Wikification\"", "]", "+=", "len", "(", "set", "(", "list_gold", ")", ")", "\n", "# Named entity scores", "\n", "list_pred", "=", "namedent", "(", "dict_pred", ",", "triples_pred", ")", "\n", "list_gold", "=", "namedent", "(", "dict_gold", ",", "triples_gold", ")", "\n", "inters", "[", "\"Named Ent.\"", "]", "+=", "len", "(", "list", "(", "set", "(", "list_pred", ")", "&", "set", "(", "list_gold", ")", ")", ")", "\n", "preds", "[", "\"Named Ent.\"", "]", "+=", "len", "(", "set", "(", "list_pred", ")", ")", "\n", "golds", "[", "\"Named Ent.\"", "]", "+=", "len", "(", "set", "(", "list_gold", ")", ")", "\n", "# Negation scores", "\n", "list_pred", "=", "negations", "(", "dict_pred", ",", "triples_pred", ")", "\n", "list_gold", "=", "negations", "(", "dict_gold", ",", "triples_gold", ")", "\n", "inters", "[", "\"Negations\"", "]", "+=", "len", "(", "list", "(", "set", "(", "list_pred", ")", "&", "set", "(", "list_gold", ")", ")", ")", "\n", "preds", "[", "\"Negations\"", "]", "+=", "len", "(", "set", "(", "list_pred", ")", ")", "\n", "golds", "[", "\"Negations\"", "]", "+=", "len", "(", "set", "(", "list_gold", ")", ")", "\n", "# Ignore Vars scores", "\n", "list_pred", "=", "everything", "(", "dict_pred", ",", "triples_pred", ")", "\n", "list_gold", "=", "everything", "(", "dict_gold", ",", "triples_gold", ")", "\n", "inters", "[", "\"IgnoreVars\"", "]", "+=", "len", "(", "list", "(", "set", "(", "list_pred", ")", "&", "set", "(", "list_gold", ")", ")", ")", "\n", "preds", "[", "\"IgnoreVars\"", "]", "+=", "len", "(", "set", "(", "list_pred", ")", ")", "\n", "golds", "[", "\"IgnoreVars\"", "]", "+=", "len", "(", "set", "(", "list_gold", ")", ")", "\n", "# Concepts scores", "\n", "list_pred", "=", "concepts", "(", "dict_pred", ")", "\n", "list_gold", "=", "concepts", "(", "dict_gold", ")", "\n", "inters", "[", "\"Concepts\"", "]", "+=", "len", "(", "list", "(", "set", "(", "list_pred", ")", "&", "set", "(", "list_gold", ")", ")", ")", "\n", "preds", "[", "\"Concepts\"", "]", "+=", "len", "(", "set", "(", "list_pred", ")", ")", "\n", "golds", "[", "\"Concepts\"", "]", "+=", "len", "(", "set", "(", "list_gold", ")", ")", "\n", "# Frames scores", "\n", "list_pred", "=", "frames", "(", "dict_pred", ")", "\n", "list_gold", "=", "frames", "(", "dict_gold", ")", "\n", "inters", "[", "\"Frames\"", "]", "+=", "len", "(", "list", "(", "set", "(", "list_pred", ")", "&", "set", "(", "list_gold", ")", ")", ")", "\n", "preds", "[", "\"Frames\"", "]", "+=", "len", "(", "set", "(", "list_pred", ")", ")", "\n", "golds", "[", "\"Frames\"", "]", "+=", "len", "(", "set", "(", "list_gold", ")", ")", "\n", "# Create the return dictionary", "\n", "", "rdict", "=", "OrderedDict", "(", ")", "\n", "for", "score", "in", "preds", ":", "\n", "        ", "pr", "=", "0", "if", "preds", "[", "score", "]", "<=", "0", "else", "inters", "[", "score", "]", "/", "float", "(", "preds", "[", "score", "]", ")", "\n", "rc", "=", "0", "if", "golds", "[", "score", "]", "<=", "0", "else", "inters", "[", "score", "]", "/", "float", "(", "golds", "[", "score", "]", ")", "\n", "f", "=", "0", "if", "pr", "+", "rc", "<=", "0", "else", "2", "*", "(", "pr", "*", "rc", ")", "/", "(", "pr", "+", "rc", ")", "\n", "rdict", "[", "score", "]", "=", "(", "pr", ",", "rc", ",", "f", ")", "\n", "", "return", "rdict", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.unlabel": [[222, 226], ["re.sub", "re.sub"], "function", ["None"], ["def", "unlabel", "(", "amr", ")", ":", "\n", "    ", "amr", "=", "re", ".", "sub", "(", "match_no_of", ",", "\":label\"", ",", "amr", ")", "\n", "amr", "=", "re", ".", "sub", "(", "match_of", ",", "\":label-of\"", ",", "amr", ")", "\n", "return", "amr", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.remove_wsd": [[229, 231], ["re.sub"], "function", ["None"], ["def", "remove_wsd", "(", "text", ")", ":", "\n", "    ", "return", "re", ".", "sub", "(", "match_wsd", ",", "r'\\1-01'", ",", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.concepts": [[233, 235], ["str", "list", "v2c_dict.values"], "function", ["None"], ["def", "concepts", "(", "v2c_dict", ")", ":", "\n", "    ", "return", "[", "str", "(", "v", ")", "for", "v", "in", "list", "(", "v2c_dict", ".", "values", "(", ")", ")", "]", "\n", "", "def", "frames", "(", "v2c_dict", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.frames": [[235, 237], ["str", "list", "v2c_dict.values", "RE_FRAME_NUM.search"], "function", ["None"], ["", "def", "frames", "(", "v2c_dict", ")", ":", "\n", "    ", "return", "[", "str", "(", "v", ")", "for", "v", "in", "list", "(", "v2c_dict", ".", "values", "(", ")", ")", "if", "RE_FRAME_NUM", ".", "search", "(", "v", ")", "is", "not", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.non_sense_frames": [[238, 241], ["re.sub", "str", "list", "v2c_dict.values", "RE_FRAME_NUM.search"], "function", ["None"], ["", "def", "non_sense_frames", "(", "v2c_dict", ")", ":", "\n", "    ", "return", "[", "re", ".", "sub", "(", "RE_FRAME_NUM", ",", "''", ",", "str", "(", "v", ")", ")", "for", "v", "in", "list", "(", "v2c_dict", ".", "values", "(", ")", ")", "if", "RE_FRAME_NUM", ".", "search", "(", "v", ")", "is", "not", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.namedent": [[242, 244], ["str"], "function", ["None"], ["", "def", "namedent", "(", "v2c_dict", ",", "triples", ")", ":", "\n", "    ", "return", "[", "str", "(", "v2c_dict", "[", "v1", "]", ")", "for", "(", "l", ",", "v1", ",", "v2", ")", "in", "triples", "if", "l", "==", "\"name\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.negations": [[245, 247], ["None"], "function", ["None"], ["", "def", "negations", "(", "v2c_dict", ",", "triples", ")", ":", "\n", "    ", "return", "[", "v2c_dict", "[", "v1", "]", "for", "(", "l", ",", "v1", ",", "v2", ")", "in", "triples", "if", "l", "==", "\"polarity\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.wikification": [[248, 250], ["None"], "function", ["None"], ["", "def", "wikification", "(", "triples", ")", ":", "\n", "    ", "return", "[", "v2", "for", "(", "l", ",", "v1", ",", "v2", ")", "in", "triples", "if", "l", "==", "\"wiki\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.everything": [[251, 262], ["lst.append"], "function", ["None"], ["", "def", "everything", "(", "v2c_dict", ",", "triples", ")", ":", "\n", "    ", "lst", "=", "[", "]", "\n", "for", "t", "in", "triples", ":", "\n", "        ", "c1", "=", "t", "[", "1", "]", "\n", "c2", "=", "t", "[", "2", "]", "\n", "if", "t", "[", "1", "]", "in", "v2c_dict", ":", "\n", "            ", "c1", "=", "v2c_dict", "[", "t", "[", "1", "]", "]", "\n", "", "if", "t", "[", "2", "]", "in", "v2c_dict", ":", "\n", "            ", "c2", "=", "v2c_dict", "[", "t", "[", "2", "]", "]", "\n", "", "lst", ".", "append", "(", "(", "t", "[", "0", "]", ",", "c1", ",", "c2", ")", ")", "\n", "", "return", "lst", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.bleu_scorer.BLEUScorer.__init__": [[7, 9], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.bleu_scorer.BLEUScorer.compute_bleu": [[11, 17], ["bleu_scorer.BLEUScorer.get_length", "bleu_scorer.BLEUScorer.get_length", "bleu_scorer.BLEUScorer.add_ref_dimension", "nltk.translate.bleu_score.corpus_bleu"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.evaluate.bleu_scorer.BLEUScorer.get_length", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.bleu_scorer.BLEUScorer.get_length", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.bleu_scorer.BLEUScorer.add_ref_dimension"], ["", "def", "compute_bleu", "(", "self", ",", "refs", ",", "hyps", ")", ":", "\n", "        ", "ref_len", "=", "self", ".", "get_length", "(", "refs", ")", "\n", "hyp_len", "=", "self", ".", "get_length", "(", "hyps", ")", "\n", "refs", "=", "self", ".", "add_ref_dimension", "(", "refs", ")", "# nltk allows multiple ref per hyp", "\n", "bleu", "=", "corpus_bleu", "(", "refs", ",", "hyps", ")", "# even weights=(0.25, 0.25, 0.25, 0.25)", "\n", "return", "bleu", ",", "ref_len", ",", "hyp_len", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.bleu_scorer.BLEUScorer.get_length": [[18, 22], ["sum", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_length", "(", "tokenized_sents", ")", ":", "\n", "        ", "length", "=", "sum", "(", "[", "len", "(", "ts", ")", "for", "ts", "in", "tokenized_sents", "]", ")", "\n", "return", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.bleu_scorer.BLEUScorer.tokenize_strings": [[23, 33], ["vals.append", "w.lower", "w.lower", "string.split", "nltk.tokenize.word_tokenize"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "@", "staticmethod", "\n", "def", "tokenize_strings", "(", "strings", ",", "space_tokenize", "=", "False", ")", ":", "\n", "        ", "vals", "=", "[", "]", "\n", "for", "string", "in", "strings", ":", "\n", "            ", "if", "space_tokenize", ":", "\n", "                ", "tokens", "=", "[", "w", ".", "lower", "(", ")", "for", "w", "in", "string", ".", "split", "(", ")", "]", "\n", "", "else", ":", "\n", "                ", "tokens", "=", "[", "w", ".", "lower", "(", ")", "for", "w", "in", "word_tokenize", "(", "string", ")", "]", "\n", "", "vals", ".", "append", "(", "tokens", ")", "\n", "", "return", "vals", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.bleu_scorer.BLEUScorer.add_ref_dimension": [[34, 38], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_ref_dimension", "(", "refs", ")", ":", "\n", "        ", "refs", "=", "[", "[", "r", "]", "for", "r", "in", "refs", "]", "\n", "return", "refs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.models.model_factory.dynamic_load": [[12, 21], ["importlib.import_module", "getattr"], "function", ["None"], ["def", "dynamic_load", "(", "module_name", ",", "class_name", ",", "package", "=", "'amrlib.models'", ")", ":", "\n", "# the module \"parse_t5\" has been replaced with \"parse_xfm\" which is code compatible", "\n", "# for the inference class. For the 2 older model_parse_t5-v0_2_0 and -v0_1_0", "\n", "# translate to the new module.", "\n", "    ", "if", "module_name", "==", "'.parse_t5.inference'", ":", "\n", "        ", "module_name", "=", "'.parse_xfm.inference'", "\n", "", "module", "=", "importlib", ".", "import_module", "(", "module_name", ",", "package", "=", "package", ")", "\n", "my_class", "=", "getattr", "(", "module", ",", "class_name", ")", "\n", "return", "my_class", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.models.model_factory.get_non_config_model": [[26, 43], ["os.path.join", "os.path.exists", "os.path.join", "os.path.exists", "utils.md5sum.md5sum", "utils.md5sum.md5sum"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.md5sum.md5sum", "home.repos.pwc.inspect_result.chenllliang_atp.utils.md5sum.md5sum"], ["def", "get_non_config_model", "(", "model_directory", ")", ":", "\n", "# Check for model_parse_gsii-v0_1_0", "\n", "    ", "fpath", "=", "os", ".", "path", ".", "join", "(", "model_directory", ",", "'model.pt'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fpath", ")", ":", "\n", "        ", "hash_id", "=", "md5sum", "(", "fpath", ",", "chunksize", "=", "MD5SUM_CHUNKSIZE", ",", "first_chunk_only", "=", "True", ")", "\n", "if", "hash_id", "==", "'09048d8ba12dc729d815963348d6e901'", ":", "\n", "            ", "return", "{", "\"version\"", ":", "\"0.0.1\"", ",", "\"model_type\"", ":", "\"stog\"", ",", "\"inference_module\"", ":", "\".parse_gsii.inference\"", ",", "\n", "\"inference_class\"", ":", "\"Inference\"", ",", "\"model_fn\"", ":", "\"model.pt\"", "}", "\n", "# Check for model_generate_t5-v0_1_0", "\n", "", "", "fpath", "=", "os", ".", "path", ".", "join", "(", "model_directory", ",", "'pytorch_model.bin'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fpath", ")", ":", "\n", "        ", "hash_id", "=", "md5sum", "(", "fpath", ",", "chunksize", "=", "MD5SUM_CHUNKSIZE", ",", "first_chunk_only", "=", "True", ")", "\n", "if", "hash_id", "==", "'786e3f9d33a6981ffae7c5f42a935cc9'", ":", "\n", "            ", "return", "{", "\"version\"", ":", "\"0.0.1\"", ",", "\"model_type\"", ":", "\"gtos\"", ",", "\"inference_module\"", ":", "\".generate_t5.inference\"", ",", "\n", "\"inference_class\"", ":", "\"Inference\"", ",", "\"model_fn\"", ":", "\"pytorch_model.bin\"", "}", "\n", "# Doesn't match anything here", "\n", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.models.model_factory.load_inference_model": [[48, 72], ["os.path.join", "os.path.exists", "model_factory.dynamic_load", "json.load.get", "meta.get.update", "dynamic_load.", "os.path.isdir", "FileNotFoundError", "logger.info", "model_factory.get_non_config_model", "FileNotFoundError", "os.strerror", "open", "json.load"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.models.model_factory.dynamic_load", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.models.model_factory.get_non_config_model", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["", "def", "load_inference_model", "(", "model_directory", ",", "**", "kwargs", ")", ":", "\n", "# Error check", "\n", "    ", "if", "not", "os", ".", "path", ".", "isdir", "(", "model_directory", ")", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "errno", ".", "ENOENT", ",", "os", ".", "strerror", "(", "errno", ".", "ENOENT", ")", ",", "model_directory", ")", "\n", "", "meta", "=", "None", "\n", "# See if an amrlib_meta.json file exist in the model directory, and if so load it", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "model_directory", ",", "'amrlib_meta.json'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fpath", ")", ":", "\n", "        ", "with", "open", "(", "fpath", ")", "as", "f", ":", "\n", "            ", "meta", "=", "json", ".", "load", "(", "f", ")", "\n", "# If we can't get it from a file, try the hard-coded values (used for initial models)", "\n", "", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "'No amrlib_meta.json file, trying hard-coded config match'", ")", "\n", "meta", "=", "get_non_config_model", "(", "model_directory", ")", "\n", "# Raise an error if we can't load at this point", "\n", "", "if", "not", "meta", ":", "\n", "        ", "msg", "=", "'No meta-data (amrlib_meta.json or hard-coded) available for'", "\n", "raise", "FileNotFoundError", "(", "errno", ".", "ENOENT", ",", "msg", ",", "model_directory", ")", "\n", "# With the meta-data, load the model and instantiate it", "\n", "", "model_class", "=", "dynamic_load", "(", "module_name", "=", "meta", "[", "'inference_module'", "]", ",", "class_name", "=", "meta", "[", "'inference_class'", "]", ")", "\n", "model_kwargs", "=", "meta", ".", "get", "(", "'kwargs'", ",", "{", "}", ")", "# get any model kwargs from the meta-data", "\n", "model_kwargs", ".", "update", "(", "kwargs", ")", "# override them with amything passed in", "\n", "model", "=", "model_class", "(", "model_directory", ",", "meta", "[", "'model_fn'", "]", ",", "**", "model_kwargs", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.models.inference_bases.STOGInferenceBase.__init__": [[7, 10], ["None"], "methods", ["None"], ["    ", "@", "abstractmethod", "\n", "def", "__init__", "(", "self", ",", "model_dir", ",", "model_fn", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.models.inference_bases.STOGInferenceBase.parse_sents": [[14, 17], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "parse_sents", "(", "self", ",", "sents", ",", "add_metadata", "=", "True", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.models.inference_bases.STOGInferenceBase.parse_spans": [[21, 24], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "parse_spans", "(", "self", ",", "spans", ",", "add_metadata", "=", "True", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.models.inference_bases.GTOSInferenceBase.__init__": [[30, 33], ["None"], "methods", ["None"], ["    ", "@", "abstractmethod", "\n", "def", "__init__", "(", "self", ",", "model_dir", ",", "model_fn", ",", "**", "kwargs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.models.inference_bases.GTOSInferenceBase.generate": [[35, 38], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "generate", "(", "self", ",", "graphs", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5.inference.Inference.__init__": [[12, 34], ["kwargs.get", "torch.device", "logging.getLogger", "logging.getLogger.getEffectiveLevel", "logging.getLogger.setLevel", "transformers.T5ForConditionalGeneration.from_pretrained().to", "logging.getLogger.setLevel", "kwargs.get", "transformers.T5Tokenizer.from_pretrained", "set", "kwargs.get", "kwargs.get", "kwargs.get", "torch.cuda.is_available", "logger.warn", "transformers.T5ForConditionalGeneration.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained"], ["    ", "def", "__init__", "(", "self", ",", "model_dir", ",", "model_fn", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "default_device", "=", "'cuda:0'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", "\n", "device", "=", "kwargs", ".", "get", "(", "'device'", ",", "default_device", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "# The following produces a logger warning that we can ignore so eliminate temporarily set the level higher", "\n", "xfm_logger", "=", "logging", ".", "getLogger", "(", "'transformers.modeling_utils'", ")", "\n", "original_level", "=", "xfm_logger", ".", "getEffectiveLevel", "(", ")", "\n", "xfm_logger", ".", "setLevel", "(", "logging", ".", "ERROR", ")", "\n", "self", ".", "model", "=", "T5ForConditionalGeneration", ".", "from_pretrained", "(", "model_dir", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "xfm_logger", ".", "setLevel", "(", "original_level", ")", "\n", "# End logger ignore warning", "\n", "self", ".", "max_graph_len", "=", "self", ".", "model", ".", "config", ".", "task_specific_params", "[", "'translation_amr_to_text'", "]", "[", "'max_in_len'", "]", "\n", "self", ".", "max_sent_len", "=", "self", ".", "model", ".", "config", ".", "task_specific_params", "[", "'translation_amr_to_text'", "]", "[", "'max_out_len'", "]", "\n", "tokenizer_name", "=", "kwargs", ".", "get", "(", "'tokenizer_name'", ",", "'t5-base'", ")", "# name or path", "\n", "self", ".", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "tokenizer_name", ")", "\n", "self", ".", "seq_ends", "=", "set", "(", "[", "self", ".", "tokenizer", ".", "eos_token_id", ",", "self", ".", "tokenizer", ".", "pad_token_id", "]", ")", "\n", "self", ".", "batch_size", "=", "kwargs", ".", "get", "(", "'batch_size'", ",", "32", ")", "\n", "self", ".", "num_beams", "=", "kwargs", ".", "get", "(", "'num_beams'", ",", "1", ")", "# 1 => greedy", "\n", "self", ".", "num_ret_seq", "=", "kwargs", ".", "get", "(", "'num_ret_seq'", ",", "1", ")", "\n", "if", "self", ".", "num_ret_seq", ">", "self", ".", "num_beams", ":", "\n", "            ", "logger", ".", "warn", "(", "'Need at least as many beams as returned sequences - increasing beam count'", ")", "\n", "self", ".", "num_beams", "=", "self", ".", "num_ret_seq", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5.inference.Inference.generate": [[37, 67], ["isinstance", "torch.utils.data.DataLoader", "tqdm.tqdm.tqdm", "graph_processing.amr_loading.split_amr_meta", "stripped_graphs.append", "inference.Inference.tokenizer.batch_encode_plus", "clips.extend", "torch.LongTensor().to", "torch.LongTensor().to", "inference.Inference.model.generate", "sents.extend", "inference.Inference.tokenizer.decode", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading.split_amr_meta", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.inference.Inference.generate", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend"], ["", "", "def", "generate", "(", "self", ",", "graphs", ",", "disable_progress", "=", "True", ")", ":", "\n", "        ", "assert", "isinstance", "(", "graphs", ",", "list", ")", "\n", "# Make sure the user isn't passing in meta-data, only the graph strings", "\n", "stripped_graphs", "=", "[", "]", "\n", "for", "graph", "in", "graphs", ":", "\n", "            ", "meta_lines", ",", "graph_lines", "=", "split_amr_meta", "(", "graph", ")", "\n", "stripped_graphs", ".", "append", "(", "' '", ".", "join", "(", "graph_lines", ")", ")", "\n", "# Loop though batches", "\n", "", "sents", "=", "[", "]", "\n", "clips", "=", "[", "]", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "stripped_graphs", ",", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "for", "batch", "in", "tqdm", "(", "dataloader", ",", "disable", "=", "disable_progress", ")", ":", "\n", "# Form encodings and tokenize", "\n", "            ", "input_text", "=", "[", "'%s'", "%", "graph", "for", "graph", "in", "batch", "]", "\n", "input_encodings", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "input_text", ",", "padding", "=", "True", ",", "\n", "truncation", "=", "True", ",", "max_length", "=", "self", ".", "max_graph_len", ",", "\n", "return_overflowing_tokens", "=", "True", ")", "\n", "# Check if any graphs were truncated (requires return_overflowing_tokens=True)", "\n", "clip", "=", "[", "l", ">", "0", "for", "l", "in", "input_encodings", "[", "'num_truncated_tokens'", "]", "]", "\n", "clips", ".", "extend", "(", "clip", ")", "\n", "# Convert to tensors", "\n", "input_ids", "=", "torch", ".", "LongTensor", "(", "input_encodings", "[", "'input_ids'", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "attention_mask", "=", "torch", ".", "LongTensor", "(", "input_encodings", "[", "'attention_mask'", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "# Generate", "\n", "outs", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "\n", "max_length", "=", "self", ".", "max_sent_len", ",", "early_stopping", "=", "True", ",", "num_beams", "=", "self", ".", "num_beams", ",", "\n", "num_return_sequences", "=", "self", ".", "num_ret_seq", ")", "\n", "outs", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "ids", ",", "skip_special_tokens", "=", "True", ")", "for", "ids", "in", "outs", "]", "\n", "sents", ".", "extend", "(", "outs", ")", "\n", "", "return", "sents", ",", "clips", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5.inference.Inference.get_ans_group": [[70, 72], ["None"], "methods", ["None"], ["", "def", "get_ans_group", "(", "self", ",", "answers", ",", "group_num", ")", ":", "\n", "        ", "return", "answers", "[", "group_num", "*", "self", ".", "num_ret_seq", ":", "(", "group_num", "+", "1", ")", "*", "self", ".", "num_ret_seq", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5.trainer.AMRDataset.__init__": [[18, 22], ["None"], "methods", ["None"], ["self", ".", "rev_err", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'rev_err'", ")", "\n", "self", ".", "param_fn", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'train_params.json'", ")", "\n", "fast_align", "=", "os", ".", "path", ".", "join", "(", "bin_dir", ",", "'fast_align'", ")", "\n", "atools", "=", "os", ".", "path", ".", "join", "(", "bin_dir", ",", "'atools'", ")", "\n", "p", "=", "{", "}", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5.trainer.AMRDataset.__len__": [[23, 25], ["len"], "methods", ["None"], ["p", "[", "'I'", "]", "=", "kwargs", ".", "get", "(", "'I'", ",", "5", ")", "\n", "p", "[", "'q'", "]", "=", "kwargs", ".", "get", "(", "'q'", ",", "0.08", ")", "\n", "p", "[", "'a'", "]", "=", "kwargs", ".", "get", "(", "'a'", ",", "0.01", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5.trainer.AMRDataset.__getitem__": [[26, 28], ["trainer.AMRDataset.encodings.items"], "methods", ["None"], ["p", "[", "'T'", "]", "=", "kwargs", ".", "get", "(", "'T'", ",", "4", ")", "\n", "p", "[", "'heuristic'", "]", "=", "kwargs", ".", "get", "(", "'heuristic'", ",", "'grow-diag-final-and'", ")", "\n", "self", ".", "params", "=", "p", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5.trainer.T2TDataCollator.__call__": [[37, 45], ["torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["self", ".", "tools_cmd", "=", "tools_cmd", ".", "split", "(", ")", "\n", "\n", "", "def", "train", "(", "self", ")", ":", "\n", "# Run the training", "\n", "        ", "with", "open", "(", "self", ".", "fwd_out", ",", "'w'", ")", "as", "fout", ",", "open", "(", "self", ".", "fwd_err", ",", "'w'", ")", "as", "ferr", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "fwd_cmd", ",", "stdout", "=", "fout", ",", "stderr", "=", "ferr", ")", "\n", "", "with", "open", "(", "self", ".", "rev_out", ",", "'w'", ")", "as", "fout", ",", "open", "(", "self", ".", "rev_err", ",", "'w'", ")", "as", "ferr", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "rev_cmd", ",", "stdout", "=", "fout", ",", "stderr", "=", "ferr", ")", "\n", "", "with", "open", "(", "self", ".", "final_out", ",", "'w'", ")", "as", "fout", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5.trainer.Trainer.__init__": [[50, 63], ["transformers.TrainingArguments", "transformers.set_seed"], "methods", ["None"], ["# Save the parameters for use during inference", "\n", "with", "open", "(", "self", ".", "param_fn", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "params", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n", "", "", "def", "read_err", "(", "self", ",", "err", ")", ":", "\n", "        ", "T", ",", "m", "=", "''", ",", "''", "\n", "with", "open", "(", "err", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "# expected target length = source length * N", "\n", "                ", "if", "'expected target length'", "in", "line", ":", "\n", "                    ", "m", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "# final tension: N", "\n", "", "elif", "'final tension'", "in", "line", ":", "\n", "                    ", "T", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5.trainer.Trainer.train": [[64, 94], ["os.makedirs", "print", "transformers.T5Tokenizer.from_pretrained", "transformers.T5ForConditionalGeneration.from_pretrained", "print", "os.path.join", "os.path.join", "transformers.Trainer.Trainer.build_dataset", "print", "transformers.Trainer.Trainer.build_dataset", "print", "print", "transformers.Trainer", "transformers.Trainer.train", "print", "transformers.Trainer.save_model", "len", "len", "len", "len", "transformers.Trainer.T2TDataCollator"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.trainer.Trainer.build_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.trainer.Trainer.build_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.save_model"], ["", "", "", "return", "float", "(", "T", ")", ",", "float", "(", "m", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5.trainer.Trainer.build_dataset": [[97, 130], ["graph_processing.amr_loading.load_amr_graph_sent", "trainer.Trainer.tokenizer.batch_encode_plus", "trainer.Trainer.tokenizer.batch_encode_plus", "set", "enumerate", "trainer.AMRDataset", "zip", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "set.add", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading.load_amr_graph_sent", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.GraphBuilder.__init__": [[12, 19], ["collections.Counter"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "rel_vocab", ")", ":", "\n", "        ", "self", ".", "enumerator", "=", "Counter", "(", ")", "\n", "self", ".", "rel_vocab", "=", "rel_vocab", "\n", "self", ".", "concepts", "=", "[", "]", "# List of node names (concets and attributes)", "\n", "self", ".", "relations", "=", "[", "]", "# list of (target_id, source_id, arc_prob, rel_prob:list(vocab))", "\n", "self", ".", "names", "=", "[", "]", "# names for concepts (1:1) ie..  n1, n2, p1, Ohio@attr4@ , ..", "\n", "self", ".", "arc_thresh", "=", "0.50", "# Threshold of arc probability to add an edge  **1", "\n", "# **1: Experimentally 0.5 is about optimal, though increasing to 0.9 doesn't decrease the score", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.GraphBuilder.build": [[25, 36], ["collections.defaultdict", "graph_builder.GraphBuilder.build_instance_triples", "graph_builder.GraphBuilder.build_edge_attrib_triples", "penman.graph.Graph", "penman.encode", "re.sub"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.GraphBuilder.build_instance_triples", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.GraphBuilder.build_edge_attrib_triples", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode"], ["", "def", "build", "(", "self", ",", "concepts", ",", "relations", ")", ":", "\n", "        ", "self", ".", "concepts", "=", "concepts", "\n", "self", ".", "relations", "=", "relations", "\n", "self", ".", "used_arcs", "=", "defaultdict", "(", "set", ")", "# keep track of edge names aready seen (key is source_id)", "\n", "triples", "=", "self", ".", "build_instance_triples", "(", ")", "# add self.names", "\n", "triples", "+=", "self", ".", "build_edge_attrib_triples", "(", ")", "\n", "graph", "=", "penman", ".", "graph", ".", "Graph", "(", "triples", ")", "\n", "string", "=", "penman", ".", "encode", "(", "graph", ",", "indent", "=", "6", ")", "\n", "# Strip the uniqueness post tag (ie.. 2007@attr1@ -> 2007)", "\n", "string", "=", "re", ".", "sub", "(", "r'@attr\\d+@'", ",", "''", ",", "string", ")", "\n", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.GraphBuilder.build_instance_triples": [[39, 75], ["graph_builder.GraphBuilder.enumerator.clear", "enumerate", "amr_graph.need_an_instance", "graph_builder.GraphBuilder.names.append", "concept.replace.replace.replace", "concept.replace.replace.replace", "concept.replace.replace.replace", "concept.replace.replace.replace", "graph_builder.GraphBuilder.get_enumerated_var", "triples.append", "concept.replace.replace.endswith", "concept[].replace"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph.need_an_instance", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.GraphBuilder.get_enumerated_var"], ["", "def", "build_instance_triples", "(", "self", ")", ":", "\n", "        ", "self", ".", "enumerator", ".", "clear", "(", ")", "\n", "self", ".", "names", "=", "[", "]", "# unique variable or attribute with tag", "\n", "triples", "=", "[", "]", "\n", "# Loop through the concepts", "\n", "for", "i", ",", "concept", "in", "enumerate", "(", "self", ".", "concepts", ")", ":", "\n", "# strings patterns match concept forms and thus require and instance variable", "\n", "            ", "if", "need_an_instance", "(", "concept", ")", ":", "\n", "# The penman library has an issue parsing concepts with parens or tildes", "\n", "# These characters shouldn't be present but parsing errors can lead to this.", "\n", "# I found 11 instances in 55,635 training data samples", "\n", "# The Smatch scoring AMR reader looks to have an additional issue when it sees a quote in a concept", "\n", "                ", "concept", "=", "concept", ".", "replace", "(", "'('", ",", "''", ")", "\n", "concept", "=", "concept", ".", "replace", "(", "')'", ",", "''", ")", "\n", "concept", "=", "concept", ".", "replace", "(", "'~'", ",", "''", ")", "\n", "concept", "=", "concept", ".", "replace", "(", "'\"'", ",", "''", ")", "\n", "if", "concept", "!=", "self", ".", "concepts", "[", "i", "]", ":", "\n", "                    ", "self", ".", "concepts", "[", "i", "]", "=", "concept", "\n", "# get the enumerated graph variable and add a triple for it", "\n", "", "name", "=", "self", ".", "get_enumerated_var", "(", "concept", ")", "\n", "triples", ".", "append", "(", "(", "name", ",", "'instance'", ",", "concept", ")", ")", "\n", "# Attributes", "\n", "", "else", ":", "\n", "# AMRGraph.py adds an underscore to the end of any string attributes", "\n", "# Trade the underscore for quotes so we can put it back in the penman format", "\n", "                ", "if", "concept", ".", "endswith", "(", "'_'", ")", ":", "\n", "# The penman library has an issue parsing an attribute with a quote inside it", "\n", "# and, practially this probably doesn't make sense anyway, so remove it.", "\n", "                    ", "name", "=", "'\"'", "+", "concept", "[", ":", "-", "1", "]", ".", "replace", "(", "'\"'", ",", "''", ")", "+", "'\"'", "\n", "# Numbers or other things which don't get double-quotes applied to them", "\n", "", "else", ":", "\n", "                    ", "name", "=", "concept", "\n", "# Add a temporary tag to attribute names to gaurentee uniqueness. These will be stripped later.", "\n", "", "name", "=", "name", "+", "'@attr%d@ '", "%", "i", "\n", "", "self", ".", "names", ".", "append", "(", "name", ")", "\n", "", "return", "triples", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.GraphBuilder.get_enumerated_var": [[77, 87], ["first.isalpha"], "methods", ["None"], ["", "def", "get_enumerated_var", "(", "self", ",", "concept", ")", ":", "\n", "        ", "first", "=", "concept", "[", "0", "]", "# first letter", "\n", "if", "not", "first", ".", "isalpha", "(", ")", ":", "\n", "            ", "first", "=", "'x'", "\n", "", "idx", "=", "self", ".", "enumerator", "[", "first", "]", "\n", "self", ".", "enumerator", "[", "first", "]", "+=", "1", "\n", "# de-facto standard is to not append a 0 on the first instance but this", "\n", "# seems to cause an issue with my version of the smatch scorer's AMR reader,", "\n", "# so for now always append a number since a unique value is all that the spec requires.", "\n", "return", "'%s%d'", "%", "(", "first", ",", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.GraphBuilder.build_edge_attrib_triples": [[89, 126], ["collections.defaultdict", "types.SimpleNamespace", "rel_dict[].append", "range", "types.SimpleNamespace", "len", "amr_graph._is_attr_form", "amr_graph._is_attr_form", "triples.append", "graph_builder.GraphBuilder.form_relation_triple", "amr_graph._is_attr_form", "triples.append", "graph_builder.GraphBuilder.form_relation_triple"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph._is_attr_form", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph._is_attr_form", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.GraphBuilder.form_relation_triple", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph._is_attr_form", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.GraphBuilder.form_relation_triple"], ["", "def", "build_edge_attrib_triples", "(", "self", ")", ":", "\n", "# Put relations n a little more readable format and create a dictionary of them based on target_id", "\n", "        ", "rel_dict", "=", "defaultdict", "(", "list", ")", "\n", "for", "rel", "in", "self", ".", "relations", ":", "\n", "            ", "target_id", ",", "source_id", ",", "arc_prob", ",", "rel_probs", "=", "rel", "\n", "entry", "=", "SimpleNamespace", "(", "target_id", "=", "target_id", ",", "source_id", "=", "source_id", ",", "arc_prob", "=", "arc_prob", ",", "rel_probs", "=", "rel_probs", ")", "\n", "rel_dict", "[", "target_id", "]", ".", "append", "(", "entry", ")", "\n", "# Loop through an index for every concepts except the first, to find the best relation", "\n", "# Note that this is iterating target id backwards, which is not the way the original code was.", "\n", "# This produces much better results when combined with enforcing the rule that ARGx can not be", "\n", "# repeated for any source node.  When iterating forward, smatch drops ~0.15 points", "\n", "", "triples", "=", "[", "]", "\n", "for", "target_id", "in", "range", "(", "1", ",", "len", "(", "self", ".", "concepts", ")", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "# Look at all relations attached to this target concept.", "\n", "# Add triples for any non-attribute relation with a probability greater than 50%.", "\n", "# If none are above 50%, add the best one.", "\n", "# For attributes, add the best one (attribs only have 1 source connection)", "\n", "            ", "best", "=", "SimpleNamespace", "(", "target_id", "=", "None", ",", "source_id", "=", "None", ",", "arc_prob", "=", "0", ",", "rel_probs", "=", "[", "]", ")", "\n", "for", "entry", "in", "rel_dict", "[", "target_id", "]", ":", "\n", "                ", "assert", "entry", ".", "target_id", "==", "target_id", "\n", "assert", "entry", ".", "source_id", "<", "entry", ".", "target_id", "\n", "# Attribtes are never sources, they are always terminal nodes.", "\n", "if", "_is_attr_form", "(", "self", ".", "concepts", "[", "entry", ".", "source_id", "]", ")", ":", "\n", "                    ", "continue", "\n", "# If greater than a 50% arc probability and it's not an attribute, add a triple for it", "\n", "", "if", "entry", ".", "arc_prob", ">=", "self", ".", "arc_thresh", ":", "\n", "                    ", "if", "not", "_is_attr_form", "(", "self", ".", "concepts", "[", "entry", ".", "target_id", "]", ")", ":", "\n", "                        ", "triples", ".", "append", "(", "self", ".", "form_relation_triple", "(", "entry", ")", ")", "\n", "# Keep track of the max probabilities", "\n", "", "", "if", "entry", ".", "arc_prob", ">", "best", ".", "arc_prob", ":", "\n", "                    ", "best", "=", "entry", "\n", "# If the max probability is less than 50% or if the target is an attibute then the code above", "\n", "# didn't add any triples so add the best one.", "\n", "", "", "if", "best", ".", "arc_prob", "<", "self", ".", "arc_thresh", "or", "_is_attr_form", "(", "self", ".", "concepts", "[", "best", ".", "target_id", "]", ")", ":", "\n", "                ", "assert", "best", ".", "target_id", "==", "target_id", "\n", "triples", ".", "append", "(", "self", ".", "form_relation_triple", "(", "best", ")", ")", "\n", "", "", "return", "triples", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.GraphBuilder.form_relation_triple": [[128, 135], ["graph_builder.GraphBuilder.edge_name_from_rules", "graph_builder.GraphBuilder.endswith"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.GraphBuilder.edge_name_from_rules"], ["", "def", "form_relation_triple", "(", "self", ",", "entry", ")", ":", "\n", "        ", "edge_name", "=", "self", ".", "edge_name_from_rules", "(", "entry", ")", "\n", "# If the edge is a reverse type, form the triple backwards to show this", "\n", "if", "edge_name", ".", "endswith", "(", "'_reverse_'", ")", ":", "\n", "            ", "return", "(", "self", ".", "names", "[", "entry", ".", "target_id", "]", ",", "edge_name", "[", ":", "-", "9", "]", ",", "self", ".", "names", "[", "entry", ".", "source_id", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "self", ".", "names", "[", "entry", ".", "source_id", "]", ",", "edge_name", ",", "self", ".", "names", "[", "entry", ".", "target_id", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.GraphBuilder.edge_name_from_rules": [[139, 172], ["amr_graph._is_attr_form", "graph_builder.EdgeNameIterator", "graph_builder.EdgeNameIterator.get_next", "graph_builder.GraphBuilder.used_arcs[].add", "graph_builder.EdgeNameIterator.get_next", "graph_builder.EdgeNameIterator.get_next", "graph_builder.EdgeNameIterator.get_next", "graph_builder.EdgeNameIterator.get_next", "graph_builder.EdgeNameIterator.get_next", "graph_builder.EdgeNameIterator.get_next", "graph_builder.EdgeNameIterator.get_next", "graph_builder.EdgeNameIterator.get_next"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph._is_attr_form", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.EdgeNameIterator.get_next", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.EdgeNameIterator.get_next", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.EdgeNameIterator.get_next", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.EdgeNameIterator.get_next", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.EdgeNameIterator.get_next", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.EdgeNameIterator.get_next", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.EdgeNameIterator.get_next", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.EdgeNameIterator.get_next", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.EdgeNameIterator.get_next"], ["", "", "def", "edge_name_from_rules", "(", "self", ",", "entry", ")", ":", "\n", "        ", "target", "=", "self", ".", "concepts", "[", "entry", ".", "target_id", "]", "\n", "is_attrib", "=", "_is_attr_form", "(", "target", ")", "\n", "# Rules that exactly dictate the edge name", "\n", "# Rule: imperative and expressive attributes always have mode as the edge", "\n", "if", "target", "in", "(", "'imperative'", ",", "'expressive'", ")", "and", "is_attrib", ":", "\n", "            ", "return", "'mode'", "# edge_name", "\n", "# Loop until all rules are satisfied", "\n", "", "edge_name_it", "=", "EdgeNameIterator", "(", "self", ".", "rel_vocab", ",", "entry", ".", "rel_probs", ")", "\n", "edge_name", "=", "edge_name_it", ".", "get_next", "(", ")", "\n", "while", "edge_name_it", ".", "was_advanced", ":", "\n", "            ", "edge_name_it", ".", "was_advanced", "=", "False", "\n", "# Rule: don't repeat ARGx egdes", "\n", "if", "edge_name", ".", "startswith", "(", "'ARG'", ")", "and", "edge_name", "in", "self", ".", "used_arcs", "[", "entry", ".", "source_id", "]", ":", "\n", "                ", "edge_name", "=", "edge_name_it", ".", "get_next", "(", ")", "\n", "# Rule: edges for attributes should not be reversed (X-of type)", "\n", "", "elif", "edge_name", ".", "endswith", "(", "'_reverse_'", ")", "and", "is_attrib", ":", "\n", "                ", "edge_name", "=", "edge_name_it", ".", "get_next", "(", ")", "\n", "# Rule: domain is never an attribute, the target is always a node", "\n", "", "elif", "edge_name", "==", "'domain'", "and", "is_attrib", ":", "\n", "                ", "edge_name", "=", "edge_name_it", ".", "get_next", "(", ")", "\n", "# Rule: polarity attributes are always have '-' for a value", "\n", "", "elif", "edge_name", "==", "'polarity'", "and", "target", "!=", "'-'", ":", "\n", "                ", "edge_name", "=", "edge_name_it", ".", "get_next", "(", ")", "\n", "# Rule: All \"name\" edges end lead into \"name\" nodes (but the reverse is not always true)", "\n", "", "elif", "edge_name", "==", "'name'", "and", "target", "!=", "'name'", ":", "\n", "                ", "edge_name", "=", "edge_name_it", ".", "get_next", "(", ")", "\n", "# Rule: mode is always an attribute", "\n", "", "elif", "edge_name", "==", "'mode'", "and", "not", "is_attrib", ":", "\n", "                ", "edge_name", "=", "edge_name_it", ".", "get_next", "(", ")", "\n", "# Keep track of used arcs and don't repeat them for the node", "\n", "", "", "self", ".", "used_arcs", "[", "entry", ".", "source_id", "]", ".", "add", "(", "edge_name", ")", "\n", "return", "edge_name", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.EdgeNameIterator.__init__": [[176, 181], ["numpy.argsort"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "rel_vocab", ",", "rel_probs", ")", ":", "\n", "        ", "self", ".", "rel_vocab", "=", "rel_vocab", "\n", "self", ".", "indices", "=", "np", ".", "argsort", "(", "rel_probs", ")", "[", ":", ":", "-", "1", "]", "# index of the probabilities, sorted high to low", "\n", "self", ".", "ptr", "=", "0", "\n", "self", ".", "was_advanced", "=", "False", "\n", "", "def", "get_next", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.EdgeNameIterator.get_next": [[181, 186], ["graph_builder.EdgeNameIterator.rel_vocab.idx2token"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.idx2token"], ["", "def", "get_next", "(", "self", ")", ":", "\n", "        ", "index", "=", "self", ".", "indices", "[", "self", ".", "ptr", "]", "\n", "self", ".", "ptr", "+=", "1", "# let this through an exception if we exhaust all available edges", "\n", "self", ".", "was_advanced", "=", "True", "\n", "return", "self", ".", "rel_vocab", ".", "idx2token", "(", "index", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.DataLoader.__init__": [[136, 158], ["vocabs.get", "zip", "data_loader.get_concepts", "data_loader.DataLoader.data.append", "amr_graph.read_file", "amr.root_centered_sort", "vocabs.get.tokenize", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.get_concepts", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph.read_file", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph.AMRGraph.root_centered_sort", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "source", ",", "batch_size", ",", "for_train", ",", "gpu_size", "=", "12000", ")", ":", "\n", "        ", "self", ".", "data", "=", "[", "]", "\n", "bert_tokenizer", "=", "vocabs", ".", "get", "(", "'bert_tokenizer'", ",", "None", ")", "\n", "for", "amr", ",", "token", ",", "lemma", ",", "pos", ",", "ner", "in", "zip", "(", "*", "read_file", "(", "source", ")", ")", ":", "\n", "            ", "if", "for_train", ":", "\n", "                ", "_", ",", "_", ",", "not_ok", "=", "amr", ".", "root_centered_sort", "(", ")", "\n", "if", "not_ok", "or", "len", "(", "token", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "", "cp_seq", ",", "mp_seq", ",", "token2idx", ",", "idx2token", "=", "get_concepts", "(", "lemma", ",", "vocabs", "[", "'predictable_concept'", "]", ")", "\n", "datum", "=", "{", "'amr'", ":", "amr", ",", "'tok'", ":", "token", ",", "'lem'", ":", "lemma", ",", "'pos'", ":", "pos", ",", "'ner'", ":", "ner", ",", "'cp_seq'", ":", "cp_seq", ",", "'mp_seq'", ":", "mp_seq", ",", "'token2idx'", ":", "token2idx", ",", "'idx2token'", ":", "idx2token", "}", "\n", "if", "bert_tokenizer", "is", "not", "None", ":", "\n", "                ", "bert_token", ",", "token_subword_index", "=", "bert_tokenizer", ".", "tokenize", "(", "token", ")", "\n", "datum", "[", "'bert_token'", "]", "=", "bert_token", "\n", "datum", "[", "'token_subword_index'", "]", "=", "token_subword_index", "\n", "", "self", ".", "data", ".", "append", "(", "datum", ")", "\n", "", "self", ".", "vocabs", "=", "vocabs", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "train", "=", "for_train", "\n", "self", ".", "unk_rate", "=", "0.", "\n", "self", ".", "gpu_size", "=", "gpu_size", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.DataLoader.set_unk_rate": [[159, 161], ["None"], "methods", ["None"], ["", "def", "set_unk_rate", "(", "self", ",", "x", ")", ":", "\n", "        ", "self", ".", "unk_rate", "=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.DataLoader.__iter__": [[162, 195], ["list", "range", "random.shuffle", "list.sort", "data.append", "batches.append", "random.shuffle", "len", "len", "len", "batches.append", "len", "batches.append", "data_loader.batchify", "len", "batches.append", "max", "max", "max", "len", "len", "max", "len", "len", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.batchify"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "idx", "=", "list", "(", "range", "(", "len", "(", "self", ".", "data", ")", ")", ")", "\n", "\n", "if", "self", ".", "train", ":", "\n", "            ", "random", ".", "shuffle", "(", "idx", ")", "\n", "idx", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "self", ".", "data", "[", "x", "]", "[", "'tok'", "]", ")", "+", "len", "(", "self", ".", "data", "[", "x", "]", "[", "'amr'", "]", ")", ")", "\n", "\n", "", "batches", "=", "[", "]", "\n", "num_tokens", ",", "data", "=", "0", ",", "[", "]", "\n", "for", "i", "in", "idx", ":", "\n", "            ", "num_tokens", "+=", "len", "(", "self", ".", "data", "[", "i", "]", "[", "'tok'", "]", ")", "+", "len", "(", "self", ".", "data", "[", "i", "]", "[", "'amr'", "]", ")", "\n", "data", ".", "append", "(", "self", ".", "data", "[", "i", "]", ")", "\n", "if", "num_tokens", ">=", "self", ".", "batch_size", ":", "\n", "                ", "sz", "=", "len", "(", "data", ")", "*", "(", "2", "+", "max", "(", "len", "(", "x", "[", "'tok'", "]", ")", "for", "x", "in", "data", ")", "+", "max", "(", "len", "(", "x", "[", "'amr'", "]", ")", "for", "x", "in", "data", ")", ")", "\n", "if", "sz", ">", "self", ".", "gpu_size", ":", "\n", "# because we only have limited GPU memory", "\n", "                    ", "batches", ".", "append", "(", "data", "[", ":", "len", "(", "data", ")", "//", "2", "]", ")", "\n", "data", "=", "data", "[", "len", "(", "data", ")", "//", "2", ":", "]", "\n", "", "batches", ".", "append", "(", "data", ")", "\n", "num_tokens", ",", "data", "=", "0", ",", "[", "]", "\n", "", "", "if", "data", ":", "\n", "            ", "sz", "=", "len", "(", "data", ")", "*", "(", "2", "+", "max", "(", "len", "(", "x", "[", "'tok'", "]", ")", "for", "x", "in", "data", ")", "+", "max", "(", "len", "(", "x", "[", "'amr'", "]", ")", "for", "x", "in", "data", ")", ")", "\n", "if", "sz", ">", "self", ".", "gpu_size", ":", "\n", "# because we only have limited GPU memory", "\n", "                ", "batches", ".", "append", "(", "data", "[", ":", "len", "(", "data", ")", "//", "2", "]", ")", "\n", "data", "=", "data", "[", "len", "(", "data", ")", "//", "2", ":", "]", "\n", "", "batches", ".", "append", "(", "data", ")", "\n", "\n", "", "if", "self", ".", "train", ":", "\n", "            ", "random", ".", "shuffle", "(", "batches", ")", "\n", "\n", "", "for", "batch", "in", "batches", ":", "\n", "            ", "yield", "batchify", "(", "batch", ",", "self", ".", "vocabs", ",", "self", ".", "unk_rate", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.get_concepts": [[12, 30], ["set", "zip", "cp_seq.append", "mp_seq.append", "dict", "dict", "vocab.token2idx", "set.add", "vocab.token2idx", "set.add"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.token2idx", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.token2idx", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["def", "get_concepts", "(", "lem", ",", "vocab", ")", ":", "\n", "    ", "cp_seq", ",", "mp_seq", "=", "[", "]", ",", "[", "]", "\n", "new_tokens", "=", "set", "(", ")", "\n", "for", "le", "in", "lem", ":", "\n", "        ", "cp_seq", ".", "append", "(", "le", "+", "'_'", ")", "\n", "mp_seq", ".", "append", "(", "le", ")", "\n", "", "for", "cp", ",", "mp", "in", "zip", "(", "cp_seq", ",", "mp_seq", ")", ":", "\n", "        ", "if", "vocab", ".", "token2idx", "(", "cp", ")", "==", "vocab", ".", "unk_idx", ":", "\n", "            ", "new_tokens", ".", "add", "(", "cp", ")", "\n", "", "if", "vocab", ".", "token2idx", "(", "mp", ")", "==", "vocab", ".", "unk_idx", ":", "\n", "            ", "new_tokens", ".", "add", "(", "mp", ")", "\n", "", "", "nxt", "=", "vocab", ".", "size", "\n", "token2idx", ",", "idx2token", "=", "dict", "(", ")", ",", "dict", "(", ")", "\n", "for", "x", "in", "new_tokens", ":", "\n", "        ", "token2idx", "[", "x", "]", "=", "nxt", "\n", "idx2token", "[", "nxt", "]", "=", "x", "\n", "nxt", "+=", "1", "\n", "", "return", "cp_seq", ",", "mp_seq", ",", "token2idx", ",", "idx2token", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ListsToTensor": [[32, 54], ["max", "enumerate", "numpy.transpose", "isinstance", "vocab.token2idx", "ys.append", "numpy.array", "random.random", "len", "data_loader.ListsToTensor.toIdx"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.token2idx"], ["", "def", "ListsToTensor", "(", "xs", ",", "vocab", "=", "None", ",", "local_vocabs", "=", "None", ",", "unk_rate", "=", "0.", ")", ":", "\n", "    ", "pad", "=", "vocab", ".", "padding_idx", "if", "vocab", "else", "0", "\n", "def", "toIdx", "(", "w", ",", "i", ")", ":", "\n", "        ", "if", "vocab", "is", "None", ":", "\n", "            ", "return", "w", "\n", "", "if", "isinstance", "(", "w", ",", "list", ")", ":", "\n", "            ", "return", "[", "toIdx", "(", "_", ",", "i", ")", "for", "_", "in", "w", "]", "\n", "", "if", "random", ".", "random", "(", ")", "<", "unk_rate", ":", "\n", "            ", "return", "vocab", ".", "unk_idx", "\n", "", "if", "local_vocabs", "is", "not", "None", ":", "\n", "            ", "local_vocab", "=", "local_vocabs", "[", "i", "]", "\n", "if", "(", "local_vocab", "is", "not", "None", ")", "and", "(", "w", "in", "local_vocab", ")", ":", "\n", "                ", "return", "local_vocab", "[", "w", "]", "\n", "", "", "return", "vocab", ".", "token2idx", "(", "w", ")", "\n", "\n", "", "max_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "xs", ")", "\n", "ys", "=", "[", "]", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "xs", ")", ":", "\n", "        ", "y", "=", "toIdx", "(", "x", ",", "i", ")", "+", "[", "pad", "]", "*", "(", "max_len", "-", "len", "(", "x", ")", ")", "\n", "ys", ".", "append", "(", "y", ")", "\n", "", "data", "=", "np", ".", "transpose", "(", "np", ".", "array", "(", "ys", ",", "dtype", "=", "np", ".", "int64", ")", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ListsofStringToTensor": [[56, 68], ["max", "numpy.transpose", "ys.append", "numpy.array", "len", "list", "zs.append", "len", "vocab.token2idx", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.token2idx"], ["", "def", "ListsofStringToTensor", "(", "xs", ",", "vocab", ",", "max_string_len", "=", "20", ")", ":", "\n", "    ", "max_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "xs", ")", "\n", "ys", "=", "[", "]", "\n", "for", "x", "in", "xs", ":", "\n", "        ", "y", "=", "x", "+", "[", "PAD", "]", "*", "(", "max_len", "-", "len", "(", "x", ")", ")", "\n", "zs", "=", "[", "]", "\n", "for", "z", "in", "y", ":", "\n", "            ", "z", "=", "list", "(", "z", "[", ":", "max_string_len", "]", ")", "\n", "zs", ".", "append", "(", "vocab", ".", "token2idx", "(", "[", "CLS", "]", "+", "z", "+", "[", "END", "]", ")", "+", "[", "vocab", ".", "padding_idx", "]", "*", "(", "max_string_len", "-", "len", "(", "z", ")", ")", ")", "\n", "", "ys", ".", "append", "(", "zs", ")", "\n", "", "data", "=", "np", ".", "transpose", "(", "np", ".", "array", "(", "ys", ",", "dtype", "=", "np", ".", "int64", ")", ",", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ArraysToTensor": [[70, 80], ["numpy.array", "numpy.zeros", "enumerate", "list", "list", "tuple", "list", "len", "np.array.max", "slice", "slice"], "function", ["None"], ["", "def", "ArraysToTensor", "(", "xs", ")", ":", "\n", "    ", "\"list of numpy array, each has the same demonsionality\"", "\n", "x", "=", "np", ".", "array", "(", "[", "list", "(", "x", ".", "shape", ")", "for", "x", "in", "xs", "]", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "shape", "=", "[", "len", "(", "xs", ")", "]", "+", "list", "(", "x", ".", "max", "(", "axis", "=", "0", ")", ")", "\n", "data", "=", "np", ".", "zeros", "(", "shape", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "xs", ")", ":", "\n", "        ", "slicing_shape", "=", "list", "(", "x", ".", "shape", ")", "\n", "slices", "=", "tuple", "(", "[", "slice", "(", "i", ",", "i", "+", "1", ")", "]", "+", "[", "slice", "(", "0", ",", "x", ")", "for", "x", "in", "slicing_shape", "]", ")", "\n", "data", "[", "slices", "]", "=", "x", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.batchify": [[82, 131], ["data_loader.ListsToTensor", "data_loader.ListsToTensor", "data_loader.ListsToTensor", "data_loader.ListsToTensor", "data_loader.ListsofStringToTensor", "data_loader.ListsToTensor", "data_loader.ListsToTensor", "numpy.full", "enumerate", "vocabs.get", "amr.root_centered_sort", "concept.append", "edge.append", "data_loader.ListsofStringToTensor", "data_loader.ListsToTensor", "data_loader.ListsToTensor", "vocabs[].token2idx", "zip", "enumerate", "numpy.stack", "data_loader.ArraysToTensor", "data_loader.ArraysToTensor", "vocabs[].token2idx", "vocabs[].token2idx"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ListsToTensor", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ListsToTensor", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ListsToTensor", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ListsToTensor", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ListsofStringToTensor", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ListsToTensor", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ListsToTensor", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph.AMRGraph.root_centered_sort", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ListsofStringToTensor", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ListsToTensor", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ListsToTensor", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.token2idx", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ArraysToTensor", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ArraysToTensor", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.token2idx", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.token2idx"], ["", "def", "batchify", "(", "data", ",", "vocabs", ",", "unk_rate", "=", "0.", ")", ":", "\n", "    ", "_tok", "=", "ListsToTensor", "(", "[", "[", "CLS", "]", "+", "x", "[", "'tok'", "]", "for", "x", "in", "data", "]", ",", "vocabs", "[", "'tok'", "]", ",", "unk_rate", "=", "unk_rate", ")", "\n", "_lem", "=", "ListsToTensor", "(", "[", "[", "CLS", "]", "+", "x", "[", "'lem'", "]", "for", "x", "in", "data", "]", ",", "vocabs", "[", "'lem'", "]", ",", "unk_rate", "=", "unk_rate", ")", "\n", "_pos", "=", "ListsToTensor", "(", "[", "[", "CLS", "]", "+", "x", "[", "'pos'", "]", "for", "x", "in", "data", "]", ",", "vocabs", "[", "'pos'", "]", ",", "unk_rate", "=", "unk_rate", ")", "\n", "_ner", "=", "ListsToTensor", "(", "[", "[", "CLS", "]", "+", "x", "[", "'ner'", "]", "for", "x", "in", "data", "]", ",", "vocabs", "[", "'ner'", "]", ",", "unk_rate", "=", "unk_rate", ")", "\n", "_word_char", "=", "ListsofStringToTensor", "(", "[", "[", "CLS", "]", "+", "x", "[", "'tok'", "]", "for", "x", "in", "data", "]", ",", "vocabs", "[", "'word_char'", "]", ")", "\n", "\n", "local_token2idx", "=", "[", "x", "[", "'token2idx'", "]", "for", "x", "in", "data", "]", "\n", "local_idx2token", "=", "[", "x", "[", "'idx2token'", "]", "for", "x", "in", "data", "]", "\n", "_cp_seq", "=", "ListsToTensor", "(", "[", "x", "[", "'cp_seq'", "]", "for", "x", "in", "data", "]", ",", "vocabs", "[", "'predictable_concept'", "]", ",", "local_token2idx", ")", "\n", "_mp_seq", "=", "ListsToTensor", "(", "[", "x", "[", "'mp_seq'", "]", "for", "x", "in", "data", "]", ",", "vocabs", "[", "'predictable_concept'", "]", ",", "local_token2idx", ")", "\n", "\n", "concept", ",", "edge", "=", "[", "]", ",", "[", "]", "\n", "for", "x", "in", "data", ":", "\n", "        ", "amr", "=", "x", "[", "'amr'", "]", "\n", "concept_i", ",", "edge_i", ",", "_", "=", "amr", ".", "root_centered_sort", "(", "vocabs", "[", "'rel'", "]", ".", "priority", ")", "\n", "concept", ".", "append", "(", "concept_i", ")", "\n", "edge", ".", "append", "(", "edge_i", ")", "\n", "\n", "", "augmented_concept", "=", "[", "[", "DUM", "]", "+", "x", "+", "[", "END", "]", "for", "x", "in", "concept", "]", "\n", "\n", "_concept_char_in", "=", "ListsofStringToTensor", "(", "augmented_concept", ",", "vocabs", "[", "'concept_char'", "]", ")", "[", ":", "-", "1", "]", "\n", "_concept_in", "=", "ListsToTensor", "(", "augmented_concept", ",", "vocabs", "[", "'concept'", "]", ",", "unk_rate", "=", "unk_rate", ")", "[", ":", "-", "1", "]", "\n", "_concept_out", "=", "ListsToTensor", "(", "augmented_concept", ",", "vocabs", "[", "'predictable_concept'", "]", ",", "local_token2idx", ")", "[", "1", ":", "]", "\n", "\n", "out_conc_len", ",", "bsz", "=", "_concept_out", ".", "shape", "\n", "_rel", "=", "np", ".", "full", "(", "(", "1", "+", "out_conc_len", ",", "bsz", ",", "out_conc_len", ")", ",", "vocabs", "[", "'rel'", "]", ".", "token2idx", "(", "PAD", ")", ",", "dtype", "=", "np", ".", "int64", ")", "\n", "# v: [<dummy>, concept_0, ..., concept_l, ..., concept_{n-1}, <end>] u: [<dummy>, concept_0, ..., concept_l, ..., concept_{n-1}]", "\n", "\n", "for", "bidx", ",", "(", "x", ",", "y", ")", "in", "enumerate", "(", "zip", "(", "edge", ",", "concept", ")", ")", ":", "\n", "        ", "for", "l", ",", "_", "in", "enumerate", "(", "y", ")", ":", "\n", "            ", "if", "l", ">", "0", ":", "\n", "# l=1 => pos=l+1=2", "\n", "                ", "_rel", "[", "l", "+", "1", ",", "bidx", ",", "1", ":", "l", "+", "1", "]", "=", "vocabs", "[", "'rel'", "]", ".", "token2idx", "(", "NIL", ")", "\n", "", "", "for", "v", ",", "u", ",", "r", "in", "x", ":", "\n", "            ", "r", "=", "vocabs", "[", "'rel'", "]", ".", "token2idx", "(", "r", ")", "\n", "_rel", "[", "v", "+", "1", ",", "bidx", ",", "u", "+", "1", "]", "=", "r", "\n", "\n", "", "", "ret", "=", "{", "'lem'", ":", "_lem", ",", "'tok'", ":", "_tok", ",", "'pos'", ":", "_pos", ",", "'ner'", ":", "_ner", ",", "'word_char'", ":", "_word_char", ",", "'copy_seq'", ":", "np", ".", "stack", "(", "[", "_cp_seq", ",", "_mp_seq", "]", ",", "-", "1", ")", ",", "'local_token2idx'", ":", "local_token2idx", ",", "'local_idx2token'", ":", "local_idx2token", ",", "'concept_in'", ":", "_concept_in", ",", "'concept_char_in'", ":", "_concept_char_in", ",", "'concept_out'", ":", "_concept_out", ",", "'rel'", ":", "_rel", "}", "\n", "\n", "bert_tokenizer", "=", "vocabs", ".", "get", "(", "'bert_tokenizer'", ",", "None", ")", "\n", "if", "bert_tokenizer", "is", "not", "None", ":", "\n", "        ", "ret", "[", "'bert_token'", "]", "=", "ArraysToTensor", "(", "[", "x", "[", "'bert_token'", "]", "for", "x", "in", "data", "]", ")", "\n", "ret", "[", "'token_subword_index'", "]", "=", "ArraysToTensor", "(", "[", "x", "[", "'token_subword_index'", "]", "for", "x", "in", "data", "]", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.inference.Inference.__init__": [[26, 38], ["kwargs.get", "torch.device", "kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "torch.cuda.is_available", "inference.Inference._load_model"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.inference.Inference._load_model"], ["self", ".", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "tokenizer_name", ")", "\n", "self", ".", "seq_ends", "=", "set", "(", "[", "self", ".", "tokenizer", ".", "eos_token_id", ",", "self", ".", "tokenizer", ".", "pad_token_id", "]", ")", "\n", "self", ".", "batch_size", "=", "kwargs", ".", "get", "(", "'batch_size'", ",", "32", ")", "\n", "self", ".", "num_beams", "=", "kwargs", ".", "get", "(", "'num_beams'", ",", "1", ")", "# 1 => greedy", "\n", "self", ".", "num_ret_seq", "=", "kwargs", ".", "get", "(", "'num_ret_seq'", ",", "1", ")", "\n", "if", "self", ".", "num_ret_seq", ">", "self", ".", "num_beams", ":", "\n", "            ", "logger", ".", "warn", "(", "'Need at least as many beams as returned sequences - increasing beam count'", ")", "\n", "self", ".", "num_beams", "=", "self", ".", "num_ret_seq", "\n", "\n", "# Generate sentences from a list of AMR text graphs", "\n", "# For generate params see https://huggingface.co/transformers/master/main_classes/model.html", "\n", "", "", "def", "generate", "(", "self", ",", "graphs", ",", "disable_progress", "=", "True", ")", ":", "\n", "        ", "assert", "isinstance", "(", "graphs", ",", "list", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.inference.Inference.build_from_model": [[40, 48], ["cls", "graph_builder.GraphBuilder"], "methods", ["None"], ["stripped_graphs", "=", "[", "]", "\n", "for", "graph", "in", "graphs", ":", "\n", "            ", "meta_lines", ",", "graph_lines", "=", "split_amr_meta", "(", "graph", ")", "\n", "stripped_graphs", ".", "append", "(", "' '", ".", "join", "(", "graph_lines", ")", ")", "\n", "# Loop though batches", "\n", "", "sents", "=", "[", "]", "\n", "clips", "=", "[", "]", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "stripped_graphs", ",", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "for", "batch", "in", "tqdm", "(", "dataloader", ",", "disable", "=", "disable_progress", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.inference.Inference.parse_sents": [[50, 68], ["isinstance", "io.StringIO", "enumerate", "io.StringIO.seek", "inference.Inference.parse_file_handle", "sent.replace.replace.replace", "graph_processing.annotator.annotate_graph", "penman.encode", "io.StringIO.write", "io.StringIO.write", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.inference.Inference.parse_file_handle", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator.annotate_graph", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode"], ["            ", "input_text", "=", "[", "'%s'", "%", "graph", "for", "graph", "in", "batch", "]", "\n", "input_encodings", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "input_text", ",", "padding", "=", "True", ",", "\n", "truncation", "=", "True", ",", "max_length", "=", "self", ".", "max_graph_len", ",", "\n", "return_overflowing_tokens", "=", "True", ")", "\n", "# Check if any graphs were truncated (requires return_overflowing_tokens=True)", "\n", "clip", "=", "[", "l", ">", "0", "for", "l", "in", "input_encodings", "[", "'num_truncated_tokens'", "]", "]", "\n", "clips", ".", "extend", "(", "clip", ")", "\n", "# Convert to tensors", "\n", "input_ids", "=", "torch", ".", "LongTensor", "(", "input_encodings", "[", "'input_ids'", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "attention_mask", "=", "torch", ".", "LongTensor", "(", "input_encodings", "[", "'attention_mask'", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "# Generate", "\n", "outs", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "\n", "max_length", "=", "self", ".", "max_sent_len", ",", "early_stopping", "=", "True", ",", "num_beams", "=", "self", ".", "num_beams", ",", "\n", "num_return_sequences", "=", "self", ".", "num_ret_seq", ")", "\n", "outs", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "ids", ",", "skip_special_tokens", "=", "True", ")", "for", "ids", "in", "outs", "]", "\n", "sents", ".", "extend", "(", "outs", ")", "\n", "", "return", "sents", ",", "clips", "\n", "\n", "# When num_ret_seq > 1, additional sentences are appended to the list, after the first", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.inference.Inference.parse_spans": [[71, 85], ["io.StringIO", "enumerate", "io.StringIO.seek", "inference.Inference.parse_file_handle", "list", "graph_processing.annotator.annotate_graph", "penman.encode", "io.StringIO.write", "io.StringIO.write", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.inference.Inference.parse_file_handle", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator.annotate_graph", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode"], ["        ", "return", "answers", "[", "group_num", "*", "self", ".", "num_ret_seq", ":", "(", "group_num", "+", "1", ")", "*", "self", ".", "num_ret_seq", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.inference.Inference.parse_file_handle": [[89, 108], ["data_loader.DataLoader.DataLoader", "utils.move_to_device", "inference.Inference._parse_batch", "zip", "sio_f.seek", "sio_f.read().split", "inference.Inference.graph_builder.build", "output_entries.append", "len", "len", "sio_f.read", "graph_processing.amr_loading.split_amr_meta", "zip"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.utils.move_to_device", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.inference.Inference._parse_batch", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.GraphBuilder.build", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading.split_amr_meta"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.inference.Inference.reparse_annotated_file": [[111, 148], ["os.path.join", "os.path.join", "print", "data_loader.DataLoader", "graph_processing.amr_loading.load_amr_entries", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm.close", "open", "evaluate.smatch_enhanced.compute_smatch", "print", "len", "utils.move_to_device", "inference.Inference._parse_batch", "zip", "logger.error", "graph_processing.amr_loading.split_amr_meta", "gold_entries.append", "inference.Inference.graph_builder.build", "test_entries.append", "fo.write", "tqdm.tqdm.tqdm.update", "fo.write", "inference.Inference.splitlines"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading.load_amr_entries", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.compute_smatch", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.utils.move_to_device", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.inference.Inference._parse_batch", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading.split_amr_meta", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.graph_builder.GraphBuilder.build", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.inference.Inference._parse_batch": [[150, 174], ["dict", "inference.Inference.model.work", "range", "concept_batch.append", "score_batch.append", "relation_batch.append", "beam.get_k_best", "len", "enumerate", "best_hyp.state_dict[].squeeze_().exp_", "best_hyp.state_dict[].squeeze_().exp_", "zip", "predicted_rel.append", "arc.tolist", "rel.tolist", "best_hyp.state_dict[].squeeze_", "best_hyp.state_dict[].squeeze_"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.modules.parser.Parser.work", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.search.Beam.get_k_best"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.inference.Inference._load_model": [[176, 214], ["os.path.join", "print", "torch.load", "utils.config.Config", "vocabs.get_vocabs.get_vocabs", "graph_builder.GraphBuilder.GraphBuilder", "modules.parser.Parser", "model.to.to.state_dict().items", "model.to.to.load_state_dict", "model.to.to.to", "model.to.to.eval", "os.path.join", "bert_utils.BertEncoderTokenizer.from_pretrained", "bert_utils.BertEncoder.from_pretrained", "k.startswith", "model.to.to.state_dict"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.get_vocabs", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.trainer.update_lr": [[21, 26], ["min"], "function", ["None"], ["atools", "=", "os", ".", "path", ".", "join", "(", "bin_dir", ",", "'atools'", ")", "\n", "p", "=", "{", "}", "\n", "p", "[", "'I'", "]", "=", "kwargs", ".", "get", "(", "'I'", ",", "5", ")", "\n", "p", "[", "'q'", "]", "=", "kwargs", ".", "get", "(", "'q'", ",", "0.08", ")", "\n", "p", "[", "'a'", "]", "=", "kwargs", ".", "get", "(", "'a'", ",", "0.01", ")", "\n", "p", "[", "'T'", "]", "=", "kwargs", ".", "get", "(", "'T'", ",", "4", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.trainer.run_training": [[28, 148], ["ls.print", "os.makedirs", "list", "vocabs.get_vocabs", "torch.manual_seed", "torch.cuda.manual_seed_all", "random.seed", "torch.device", "ls.print", "modules.parser.Parser", "model.to.to", "model.to.named_parameters", "torch.optim.AdamW", "ls.print", "data_loader.DataLoader", "data_loader.DataLoader.set_unk_rate", "ls.print", "range", "ls.print", "zip", "os.path.join", "bert_utils.BertEncoderTokenizer.from_pretrained", "ls.print", "bert_utils.BertEncoder.from_pretrained", "BertEncoder.from_pretrained.parameters", "ls.print", "torch.load", "model.to.load_state_dict", "torch.load.get", "time.time", "ls.print", "datetime.datetime.now().strftime", "len", "name.endswith", "no_weight_decay_params.append", "weight_decay_params.append", "torch.optim.AdamW.load_state_dict", "ls.print", "model.to.train", "utils.move_to_device", "model.to.", "loss.item", "concept_loss.item", "arc_loss.item", "rel_loss.item", "loss.backward", "torch.nn.utils.clip_grad_norm_", "trainer.update_lr", "torch.optim.AdamW.step", "torch.optim.AdamW.zero_grad", "time.time", "model.to.eval", "ls.print", "torch.save", "model.to.train", "datetime.datetime.now().strftime", "model.to.parameters", "torch.optim.AdamW.state_dict", "inference.Inference.build_from_model", "Inference.build_from_model.reparse_annotated_file", "ls.print", "datetime.datetime.now", "vars", "model.to.state_dict", "ls.print", "traceback.print_exc", "datetime.datetime.now", "os.path.join"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.get_vocabs", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.DataLoader.set_unk_rate", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.utils.move_to_device", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.trainer.update_lr", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.inference.Inference.build_from_model", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.inference.Inference.reparse_annotated_file", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["self", ".", "params", "=", "p", "\n", "# Create the actual commands to execute", "\n", "fwd_cmd", "=", "'%s -i %s -d -o -v -I %d -q %f -a %f -T %d -p %s'", "%", "(", "fast_align", ",", "in_fpath", ",", "p", "[", "'I'", "]", ",", "p", "[", "'q'", "]", ",", "p", "[", "'a'", "]", ",", "p", "[", "'T'", "]", ",", "self", ".", "fwd_params", ")", "\n", "rev_cmd", "=", "'%s -i %s -d -o -v -I %d -q %f -a %f -T %d -p %s -r'", "%", "(", "fast_align", ",", "in_fpath", ",", "p", "[", "'I'", "]", ",", "p", "[", "'q'", "]", ",", "p", "[", "'a'", "]", ",", "p", "[", "'T'", "]", ",", "self", ".", "rev_params", ")", "\n", "tools_cmd", "=", "'%s -i %s -j %s -c %s'", "%", "(", "atools", ",", "self", ".", "fwd_out", ",", "self", ".", "rev_out", ",", "p", "[", "'heuristic'", "]", ")", "\n", "self", ".", "fwd_cmd", "=", "fwd_cmd", ".", "split", "(", ")", "\n", "self", ".", "rev_cmd", "=", "rev_cmd", ".", "split", "(", ")", "\n", "self", ".", "tools_cmd", "=", "tools_cmd", ".", "split", "(", ")", "\n", "\n", "", "def", "train", "(", "self", ")", ":", "\n", "# Run the training", "\n", "        ", "with", "open", "(", "self", ".", "fwd_out", ",", "'w'", ")", "as", "fout", ",", "open", "(", "self", ".", "fwd_err", ",", "'w'", ")", "as", "ferr", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "fwd_cmd", ",", "stdout", "=", "fout", ",", "stderr", "=", "ferr", ")", "\n", "", "with", "open", "(", "self", ".", "rev_out", ",", "'w'", ")", "as", "fout", ",", "open", "(", "self", ".", "rev_err", ",", "'w'", ")", "as", "ferr", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "rev_cmd", ",", "stdout", "=", "fout", ",", "stderr", "=", "ferr", ")", "\n", "", "with", "open", "(", "self", ".", "final_out", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "tools_cmd", ",", "stdout", "=", "fout", ")", "\n", "# Get a few final parameters", "\n", "", "self", ".", "params", "[", "'fwd_T'", "]", ",", "self", ".", "params", "[", "'fwd_m'", "]", "=", "self", ".", "read_err", "(", "self", ".", "fwd_err", ")", "\n", "self", ".", "params", "[", "'rev_T'", "]", ",", "self", ".", "params", "[", "'rev_m'", "]", "=", "self", ".", "read_err", "(", "self", ".", "rev_err", ")", "\n", "# Save the parameters for use during inference", "\n", "with", "open", "(", "self", ".", "param_fn", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "params", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n", "", "", "def", "read_err", "(", "self", ",", "err", ")", ":", "\n", "        ", "T", ",", "m", "=", "''", ",", "''", "\n", "with", "open", "(", "err", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "# expected target length = source length * N", "\n", "                ", "if", "'expected target length'", "in", "line", ":", "\n", "                    ", "m", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "# final tension: N", "\n", "", "elif", "'final tension'", "in", "line", ":", "\n", "                    ", "T", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "", "", "", "return", "float", "(", "T", ")", ",", "float", "(", "m", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.__init__": [[23, 46], ["dict", "dict", "open", "f.readlines", "int", "zip", "line.rstrip().split", "int", "idx2token.append", "range", "print", "len", "line.rstrip"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["    ", "def", "__init__", "(", "self", ",", "filename", ",", "min_occur_cnt", ",", "specials", "=", "None", ")", ":", "\n", "        ", "idx2token", "=", "[", "PAD", ",", "UNK", "]", "+", "(", "specials", "if", "specials", "is", "not", "None", "else", "[", "]", ")", "\n", "self", ".", "_priority", "=", "dict", "(", ")", "\n", "num_tot_tokens", "=", "0", "\n", "num_vocab_tokens", "=", "0", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "for", "line", "in", "lines", ":", "\n", "            ", "try", ":", "\n", "                ", "token", ",", "cnt", "=", "line", ".", "rstrip", "(", "'\\n'", ")", ".", "split", "(", "'\\t'", ")", "\n", "cnt", "=", "int", "(", "cnt", ")", "\n", "num_tot_tokens", "+=", "cnt", "\n", "", "except", ":", "\n", "                ", "print", "(", "line", ")", "\n", "", "if", "cnt", ">=", "min_occur_cnt", ":", "\n", "                ", "idx2token", ".", "append", "(", "token", ")", "\n", "num_vocab_tokens", "+=", "cnt", "\n", "", "self", ".", "_priority", "[", "token", "]", "=", "int", "(", "cnt", ")", "\n", "", "self", ".", "coverage", "=", "num_vocab_tokens", "/", "num_tot_tokens", "\n", "self", ".", "_token2idx", "=", "dict", "(", "zip", "(", "idx2token", ",", "range", "(", "len", "(", "idx2token", ")", ")", ")", ")", "\n", "self", ".", "_idx2token", "=", "idx2token", "\n", "self", ".", "_padding_idx", "=", "self", ".", "_token2idx", "[", "PAD", "]", "\n", "self", ".", "_unk_idx", "=", "self", ".", "_token2idx", "[", "UNK", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.priority": [[47, 49], ["vocabs.Vocab._priority.get"], "methods", ["None"], ["", "def", "priority", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "_priority", ".", "get", "(", "x", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.size": [[50, 53], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_idx2token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.unk_idx": [[54, 57], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "unk_idx", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_unk_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.padding_idx": [[58, 61], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "padding_idx", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_padding_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.idx2token": [[62, 66], ["isinstance", "vocabs.Vocab.idx2token"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.idx2token"], ["", "def", "idx2token", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "return", "[", "self", ".", "idx2token", "(", "i", ")", "for", "i", "in", "x", "]", "\n", "", "return", "self", ".", "_idx2token", "[", "x", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.token2idx": [[67, 71], ["isinstance", "vocabs.Vocab._token2idx.get", "vocabs.Vocab.token2idx"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.token2idx"], ["", "def", "token2idx", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "            ", "return", "[", "self", ".", "token2idx", "(", "i", ")", "for", "i", "in", "x", "]", "\n", "", "return", "self", ".", "_token2idx", ".", "get", "(", "x", ",", "self", ".", "unk_idx", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.get_vocabs": [[8, 20], ["dict", "vocabs.Vocab", "vocabs.Vocab", "vocabs.Vocab", "vocabs.Vocab", "vocabs.Vocab", "vocabs.Vocab", "vocabs.Vocab", "vocabs.Vocab", "vocabs.Vocab", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["def", "get_vocabs", "(", "vocab_dir", ")", ":", "\n", "    ", "vocabs", "=", "dict", "(", ")", "\n", "vocabs", "[", "'tok'", "]", "=", "Vocab", "(", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'tok_vocab'", ")", ",", "5", ",", "[", "CLS", "]", ")", "\n", "vocabs", "[", "'lem'", "]", "=", "Vocab", "(", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'lem_vocab'", ")", ",", "5", ",", "[", "CLS", "]", ")", "\n", "vocabs", "[", "'pos'", "]", "=", "Vocab", "(", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'pos_vocab'", ")", ",", "5", ",", "[", "CLS", "]", ")", "\n", "vocabs", "[", "'ner'", "]", "=", "Vocab", "(", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'ner_vocab'", ")", ",", "5", ",", "[", "CLS", "]", ")", "\n", "vocabs", "[", "'predictable_concept'", "]", "=", "Vocab", "(", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'predictable_concept_vocab'", ")", ",", "5", ",", "[", "DUM", ",", "END", "]", ")", "\n", "vocabs", "[", "'concept'", "]", "=", "Vocab", "(", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'concept_vocab'", ")", ",", "5", ",", "[", "DUM", ",", "END", "]", ")", "\n", "vocabs", "[", "'rel'", "]", "=", "Vocab", "(", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'rel_vocab'", ")", ",", "50", ",", "[", "NIL", "]", ")", "\n", "vocabs", "[", "'word_char'", "]", "=", "Vocab", "(", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'word_char_vocab'", ")", ",", "100", ",", "[", "CLS", ",", "END", "]", ")", "\n", "vocabs", "[", "'concept_char'", "]", "=", "Vocab", "(", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'concept_char_vocab'", ")", ",", "100", ",", "[", "CLS", ",", "END", "]", ")", "\n", "return", "vocabs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph.AMRGraph.__init__": [[32, 74], ["set", "collections.defaultdict", "dict", "g.instances", "g.attributes", "g.edges", "g.metadata.get", "amr_graph._is_attr_form", "concept.lower", "amr_graph.AMRGraph.nodes.add", "amr_graph.AMRGraph._add_edge", "amr_graph.AMRGraph._add_edge", "logger.warn", "discard_regexp.match", "logger.warn", "amr_graph._is_attr_form", "logger.warn", "value.replace", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph._is_attr_form", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph.AMRGraph._add_edge", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph.AMRGraph._add_edge", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph._is_attr_form"], ["    ", "def", "__init__", "(", "self", ",", "g", ")", ":", "\n", "        ", "self", ".", "root", "=", "g", ".", "top", "\n", "self", ".", "nodes", "=", "set", "(", ")", "\n", "self", ".", "undirected_edges", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "name2concept", "=", "dict", "(", ")", "\n", "\n", "# Get the id field for debug", "\n", "gid", "=", "g", ".", "metadata", ".", "get", "(", "'id'", ",", "'?'", ")", "[", "-", "8", ":", "]", "# limit string to last 8 characters", "\n", "\n", "# Loop through all instance triples (name -> the variable name, ie.. n1)", "\n", "for", "name", ",", "_", ",", "concept", "in", "g", ".", "instances", "(", ")", ":", "\n", "            ", "if", "_is_attr_form", "(", "concept", ")", ":", "\n", "                ", "logger", ".", "warn", "(", "'%s has bad instance concept %s %s '", "%", "(", "gid", ",", "name", ",", "concept", ")", ")", "\n", "", "self", ".", "name2concept", "[", "name", "]", "=", "concept", ".", "lower", "(", ")", "\n", "self", ".", "nodes", ".", "add", "(", "name", ")", "\n", "\n", "# Loop through all attribute triples", "\n", "", "for", "concept", ",", "rel", ",", "value", "in", "g", ".", "attributes", "(", ")", ":", "\n", "# remove leading colon from penam triple notation", "\n", "            ", "rel", "=", "rel", "[", "1", ":", "]", "\n", "# For attributes penman double-quotes words but the convention here is to use an underscore", "\n", "# attributes that are not quoted (just numbers ?) are left as-is", "\n", "if", "'\"'", "in", "value", ":", "\n", "                ", "value", "=", "value", ".", "replace", "(", "'\"'", ",", "''", ")", "+", "'_'", "\n", "# discard name attributes who's taget value is another name node (ie.. n, n1, etc..)", "\n", "", "if", "rel", "==", "'name'", "and", "discard_regexp", ".", "match", "(", "value", ")", ":", "\n", "                ", "logger", ".", "warn", "(", "'%s has empty name attrib (%s, %s, %s)'", "%", "(", "gid", ",", "concept", ",", "rel", ",", "value", ")", ")", "\n", "continue", "\n", "", "if", "not", "_is_attr_form", "(", "value", ")", ":", "\n", "                ", "logger", ".", "warn", "(", "'%s has bad attribute (%s, %s, %s)'", "%", "(", "gid", ",", "concept", ",", "rel", ",", "value", ")", ")", "\n", "continue", "\n", "# Enumerate the attributes to assure uniqueness", "\n", "", "name", "=", "\"%s_attr_%d\"", "%", "(", "value", ",", "len", "(", "self", ".", "name2concept", ")", ")", "\n", "self", ".", "name2concept", "[", "name", "]", "=", "value", "# Keep casing on attribs", "\n", "self", ".", "_add_edge", "(", "rel", ",", "concept", ",", "name", ")", "\n", "\n", "# Loop though all edge triples", "\n", "# Note that from penman, relations all have a starting colon (ie.. :op1)", "\n", "", "for", "head", ",", "rel", ",", "tail", "in", "g", ".", "edges", "(", ")", ":", "\n", "# remove leading colon from penam triple notation", "\n", "            ", "rel", "=", "rel", "[", "1", ":", "]", "\n", "self", ".", "_add_edge", "(", "rel", ",", "head", ",", "tail", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph.AMRGraph._add_edge": [[77, 82], ["amr_graph.AMRGraph.nodes.add", "amr_graph.AMRGraph.nodes.add", "amr_graph.AMRGraph.undirected_edges[].append", "amr_graph.AMRGraph.undirected_edges[].append"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["", "", "def", "_add_edge", "(", "self", ",", "rel", ",", "src", ",", "des", ")", ":", "\n", "        ", "self", ".", "nodes", ".", "add", "(", "src", ")", "\n", "self", ".", "nodes", ".", "add", "(", "des", ")", "\n", "self", ".", "undirected_edges", "[", "src", "]", ".", "append", "(", "(", "rel", ",", "des", ")", ")", "\n", "self", ".", "undirected_edges", "[", "des", "]", ".", "append", "(", "(", "rel", "+", "'_reverse_'", ",", "src", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph.AMRGraph.root_centered_sort": [[83, 120], ["set", "dict", "set", "len", "random.shuffle", "len", "len", "zip", "set.add", "range", "random.random", "amr_graph.AMRGraph.undirected_edges[].sort", "amr_graph.AMRGraph.undirected_edges[].sort", "queue.append", "set.add", "len", "edge.append", "r.endswith", "rel_order", "x[].startswith", "x[].startswith", "rel_order"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["", "def", "root_centered_sort", "(", "self", ",", "rel_order", "=", "None", ")", ":", "\n", "        ", "queue", "=", "[", "self", ".", "root", "]", "\n", "visited", "=", "set", "(", "queue", ")", "\n", "step", "=", "0", "\n", "while", "len", "(", "queue", ")", ">", "step", ":", "\n", "            ", "src", "=", "queue", "[", "step", "]", "\n", "step", "+=", "1", "\n", "if", "src", "not", "in", "self", ".", "undirected_edges", ":", "\n", "                ", "continue", "\n", "", "random", ".", "shuffle", "(", "self", ".", "undirected_edges", "[", "src", "]", ")", "\n", "if", "rel_order", "is", "not", "None", ":", "\n", "# Do some random thing here for performance enhancement", "\n", "                ", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                    ", "self", ".", "undirected_edges", "[", "src", "]", ".", "sort", "(", "key", "=", "lambda", "x", ":", "-", "rel_order", "(", "x", "[", "0", "]", ")", "if", "(", "x", "[", "0", "]", ".", "startswith", "(", "'snt'", ")", "or", "x", "[", "0", "]", ".", "startswith", "(", "'op'", ")", ")", "else", "-", "1", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "undirected_edges", "[", "src", "]", ".", "sort", "(", "key", "=", "lambda", "x", ":", "-", "rel_order", "(", "x", "[", "0", "]", ")", ")", "\n", "", "", "for", "rel", ",", "des", "in", "self", ".", "undirected_edges", "[", "src", "]", ":", "\n", "                ", "if", "des", "in", "visited", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "queue", ".", "append", "(", "des", ")", "\n", "visited", ".", "add", "(", "des", ")", "\n", "", "", "", "not_connected", "=", "len", "(", "queue", ")", "!=", "len", "(", "self", ".", "nodes", ")", "\n", "assert", "(", "not", "not_connected", ")", "\n", "name2pos", "=", "dict", "(", "zip", "(", "queue", ",", "range", "(", "len", "(", "queue", ")", ")", ")", ")", "\n", "visited", "=", "set", "(", ")", "\n", "edge", "=", "[", "]", "\n", "for", "x", "in", "queue", ":", "\n", "            ", "if", "x", "not", "in", "self", ".", "undirected_edges", ":", "\n", "                ", "continue", "\n", "", "for", "r", ",", "y", "in", "self", ".", "undirected_edges", "[", "x", "]", ":", "\n", "                ", "if", "y", "in", "visited", ":", "\n", "                    ", "r", "=", "r", "[", ":", "-", "9", "]", "if", "r", ".", "endswith", "(", "'_reverse_'", ")", "else", "r", "+", "'_reverse_'", "\n", "edge", ".", "append", "(", "(", "name2pos", "[", "x", "]", ",", "name2pos", "[", "y", "]", ",", "r", ")", ")", "# x -> y: r", "\n", "", "", "visited", ".", "add", "(", "x", ")", "\n", "", "return", "[", "self", ".", "name2concept", "[", "x", "]", "for", "x", "in", "queue", "]", ",", "edge", ",", "not_connected", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph.AMRGraph.__len__": [[122, 124], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "name2concept", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph.read_file": [[14, 29], ["penman.load", "logger.info", "token.append", "lemma.append", "pos.append", "ner.append", "amr_graph.AMRGraph", "amrs.append", "json.loads", "json.loads", "json.loads", "json.loads", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads"], ["def", "read_file", "(", "source", ")", ":", "\n", "# read preprocessed amr file", "\n", "    ", "token", ",", "lemma", ",", "pos", ",", "ner", ",", "amrs", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "graphs", "=", "penman", ".", "load", "(", "source", ")", "\n", "logger", ".", "info", "(", "'read from %s, %d amrs'", "%", "(", "source", ",", "len", "(", "graphs", ")", ")", ")", "\n", "for", "g", "in", "graphs", ":", "\n", "# Load the metadata", "\n", "        ", "token", ".", "append", "(", "json", ".", "loads", "(", "g", ".", "metadata", "[", "'tokens'", "]", ")", ")", "\n", "lemma", ".", "append", "(", "json", ".", "loads", "(", "g", ".", "metadata", "[", "'lemmas'", "]", ")", ")", "\n", "pos", ".", "append", "(", "json", ".", "loads", "(", "g", ".", "metadata", "[", "'pos_tags'", "]", ")", ")", "\n", "ner", ".", "append", "(", "json", ".", "loads", "(", "g", ".", "metadata", "[", "'ner_tags'", "]", ")", ")", "\n", "# Build the AMRGraph from the penman graph", "\n", "amr_graph", "=", "AMRGraph", "(", "g", ")", "\n", "amrs", ".", "append", "(", "amr_graph", ")", "\n", "", "return", "amrs", ",", "token", ",", "lemma", ",", "pos", ",", "ner", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph._is_attr_form": [[131, 133], ["x.endswith", "number_regexp.match"], "function", ["None"], ["", "", "def", "_is_attr_form", "(", "x", ")", ":", "\n", "    ", "return", "(", "x", "in", "attr_value_set", "or", "x", ".", "endswith", "(", "'_'", ")", "or", "number_regexp", ".", "match", "(", "x", ")", "is", "not", "None", ")", "\n", "# If the string should have an instance variable (everything but attributes)", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph.need_an_instance": [[134, 136], ["amr_graph._is_attr_form"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph._is_attr_form"], ["", "def", "need_an_instance", "(", "x", ")", ":", "\n", "    ", "return", "(", "not", "_is_attr_form", "(", "x", ")", ")", "\n", "# Regex / data for above functions", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.search.Hypothesis.__init__": [[12, 16], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "state_dict", ",", "seq", ",", "score", ")", ":", "\n", "        ", "self", ".", "state_dict", "=", "state_dict", "\n", "self", ".", "seq", "=", "seq", "\n", "self", ".", "score", "=", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.search.Hypothesis.is_completed": [[17, 21], ["None"], "methods", ["None"], ["", "def", "is_completed", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "seq", "[", "-", "1", "]", "==", "END", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.search.Hypothesis.__len__": [[22, 24], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.search.Beam.__init__": [[28, 35], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "beam_size", ",", "min_time_step", ",", "max_time_step", ",", "hypotheses", ")", ":", "\n", "        ", "self", ".", "beam_size", "=", "beam_size", "\n", "self", ".", "min_time_step", "=", "min_time_step", "\n", "self", ".", "max_time_step", "=", "max_time_step", "\n", "self", ".", "completed_hypotheses", "=", "[", "]", "\n", "self", ".", "steps", "=", "0", "\n", "self", ".", "hypotheses", "=", "hypotheses", "# hypotheses are the collection of *alive* hypotheses only", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.search.Beam.merge_score": [[37, 49], ["amr_graph._is_attr_form", "float", "float", "float", "len", "token.endswith"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph._is_attr_form"], ["", "def", "merge_score", "(", "self", ",", "prev_hyp", ",", "step", ")", ":", "\n", "        ", "token", ",", "score", "=", "step", "# step has two attributes: token and score", "\n", "prefix", "=", "prev_hyp", ".", "seq", "\n", "\n", "if", "len", "(", "prefix", ")", "==", "1", "and", "_is_attr_form", "(", "token", ")", ":", "\n", "            ", "return", "float", "(", "'-inf'", ")", "\n", "", "if", "not", "token", ".", "endswith", "(", "'_'", ")", "and", "(", "':'", "in", "token", "or", "'/'", "in", "token", "or", "','", "in", "token", ")", ":", "\n", "            ", "return", "float", "(", "'-inf'", ")", "\n", "", "if", "token", "==", "UNK", ":", "\n", "            ", "return", "float", "(", "'-inf'", ")", "\n", "", "new_score", "=", "prev_hyp", ".", "score", "+", "score", "\n", "return", "new_score", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.search.Beam.update": [[53, 91], ["enumerate", "candidates.sort", "dict", "torch.tensor().to", "new_states.items", "enumerate", "len", "v.index_select().split", "dict", "dict.items", "new_hyps.append", "hyp.is_completed", "search.Beam.merge_score", "candidates.append", "torch.tensor", "search.Hypothesis", "search.Beam.hypotheses.append", "len", "v.index_select", "search.Beam.completed_hypotheses.append", "v.size"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.search.Hypothesis.is_completed", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.search.Beam.merge_score", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "update", "(", "self", ",", "new_states", ",", "next_steps", ",", "device", ")", ":", "\n", "# collect the top (#beam_size-len(self.completed_hypotheses)) new candidates", "\n", "        ", "candidates", "=", "[", "]", "# list of triples (prev_hyp_idx, token, score)", "\n", "for", "prev_hyp_idx", ",", "steps", "in", "enumerate", "(", "next_steps", ")", ":", "\n", "            ", "for", "step", "in", "steps", ":", "\n", "                ", "token", "=", "step", "[", "0", "]", "\n", "score", "=", "self", ".", "merge_score", "(", "self", ".", "hypotheses", "[", "prev_hyp_idx", "]", ",", "step", ")", "\n", "candidates", ".", "append", "(", "(", "prev_hyp_idx", ",", "token", ",", "score", ")", ")", "\n", "\n", "", "", "candidates", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ",", "reverse", "=", "True", ")", "\n", "live_nyp_num", "=", "self", ".", "beam_size", "-", "len", "(", "self", ".", "completed_hypotheses", ")", "\n", "candidates", "=", "candidates", "[", ":", "live_nyp_num", "]", "\n", "\n", "# collect new states for selected top candidates", "\n", "_split_state", "=", "dict", "(", ")", "# key => list of length live_nyp_num (number of selected top candidates)", "\n", "_prev_hyp_idx", "=", "torch", ".", "tensor", "(", "[", "x", "[", "0", "]", "for", "x", "in", "candidates", "]", ")", ".", "to", "(", "device", ")", "\n", "for", "k", ",", "v", "in", "new_states", ".", "items", "(", ")", ":", "\n", "            ", "split_dim", "=", "1", "if", "len", "(", "v", ".", "size", "(", ")", ")", ">=", "3", "else", "0", "\n", "_split_state", "[", "k", "]", "=", "v", ".", "index_select", "(", "split_dim", ",", "_prev_hyp_idx", ")", ".", "split", "(", "1", ",", "dim", "=", "split_dim", ")", "\n", "\n", "# pack new hypotheses", "\n", "", "new_hyps", "=", "[", "]", "\n", "for", "idx", ",", "(", "prev_hyp_idx", ",", "token", ",", "score", ")", "in", "enumerate", "(", "candidates", ")", ":", "\n", "            ", "state", "=", "dict", "(", ")", "\n", "for", "k", ",", "v", "in", "_split_state", ".", "items", "(", ")", ":", "\n", "                ", "state", "[", "k", "]", "=", "_split_state", "[", "k", "]", "[", "idx", "]", "\n", "", "seq", "=", "self", ".", "hypotheses", "[", "prev_hyp_idx", "]", ".", "seq", "+", "[", "token", "]", "\n", "new_hyps", ".", "append", "(", "Hypothesis", "(", "state", ",", "seq", ",", "score", ")", ")", "\n", "\n", "# send new hypotheses to self.completed_hypotheses or self.hypotheses accordingly", "\n", "", "self", ".", "hypotheses", "=", "[", "]", "\n", "for", "hyp", "in", "new_hyps", ":", "\n", "            ", "if", "hyp", ".", "is_completed", "(", ")", ":", "\n", "                ", "if", "self", ".", "steps", ">=", "self", ".", "min_time_step", ":", "\n", "                    ", "self", ".", "completed_hypotheses", ".", "append", "(", "hyp", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "hypotheses", ".", "append", "(", "hyp", ")", "\n", "", "", "self", ".", "steps", "+=", "1", "\n", "#self.print_everything()", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.search.Beam.completed": [[93, 97], ["len"], "methods", ["None"], ["", "def", "completed", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "completed_hypotheses", ")", "<", "self", ".", "beam_size", "and", "self", ".", "steps", "<", "self", ".", "max_time_step", ":", "\n", "            ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.search.Beam.get_k_best": [[98, 103], ["search.Beam.completed_hypotheses.sort", "len", "len"], "methods", ["None"], ["", "def", "get_k_best", "(", "self", ",", "k", ",", "alpha", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "completed_hypotheses", ")", "==", "0", ":", "\n", "            ", "self", ".", "completed_hypotheses", "=", "self", ".", "hypotheses", "\n", "", "self", ".", "completed_hypotheses", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "score", "/", "(", "(", "1", "+", "len", "(", "x", ".", "seq", ")", ")", "**", "alpha", ")", ",", "reverse", "=", "True", ")", "\n", "return", "self", ".", "completed_hypotheses", "[", ":", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.search.Beam.print_everything": [[104, 111], ["print", "print", "print", "print"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "print_everything", "(", "self", ")", ":", "\n", "        ", "print", "(", "'alive:'", ")", "\n", "for", "x", "in", "self", ".", "hypotheses", ":", "\n", "            ", "print", "(", "x", ".", "seq", ")", "\n", "", "print", "(", "'completed:'", ")", "\n", "for", "x", "in", "self", ".", "completed_hypotheses", ":", "\n", "            ", "print", "(", "x", ".", "seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.search.search_by_batch": [[120, 183], ["model.prepare_incremental_input", "dict", "dict.items", "enumerate", "search.search_by_batch.ready_to_submit"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.modules.parser.Parser.prepare_incremental_input"], ["", "", "", "def", "search_by_batch", "(", "model", ",", "beams", ",", "mem_dict", ")", ":", "\n", "\n", "# prepare state_dict and next token, output them as one batch", "\n", "    ", "def", "ready_to_submit", "(", "hypotheses", ")", ":", "\n", "        ", "inp", "=", "model", ".", "prepare_incremental_input", "(", "[", "hyp", ".", "seq", "[", "-", "1", ":", "]", "for", "hyp", "in", "hypotheses", "]", ")", "\n", "concat_hyps", "=", "dict", "(", ")", "\n", "for", "hyp", "in", "hypotheses", ":", "\n", "            ", "for", "k", ",", "v", "in", "hyp", ".", "state_dict", ".", "items", "(", ")", ":", "\n", "                ", "concat_hyps", "[", "k", "]", "=", "concat_hyps", ".", "get", "(", "k", ",", "[", "]", ")", "+", "[", "v", "]", "\n", "", "", "for", "k", ",", "v", "in", "concat_hyps", ".", "items", "(", ")", ":", "\n", "            ", "if", "len", "(", "v", "[", "0", "]", ".", "size", "(", ")", ")", ">=", "3", ":", "\n", "                ", "concat_hyps", "[", "k", "]", "=", "torch", ".", "cat", "(", "v", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "concat_hyps", "[", "k", "]", "=", "torch", ".", "cat", "(", "v", ",", "0", ")", "\n", "", "", "return", "concat_hyps", ",", "inp", "\n", "\n", "", "while", "True", ":", "\n", "# collect incomplete beams and put all hypotheses together", "\n", "        ", "hypotheses", "=", "[", "]", "\n", "indices", "=", "[", "]", "#", "\n", "offset", "=", "-", "1", "# the position of last token", "\n", "for", "idx", ",", "beam", "in", "enumerate", "(", "beams", ")", ":", "\n", "            ", "if", "not", "beam", ".", "completed", "(", ")", ":", "\n", "                ", "for", "hyp", "in", "beam", ".", "hypotheses", ":", "\n", "                    ", "hypotheses", ".", "append", "(", "hyp", ")", "\n", "indices", ".", "append", "(", "idx", ")", "\n", "offset", "=", "len", "(", "hyp", ".", "seq", ")", "-", "1", "\n", "", "", "", "if", "not", "hypotheses", ":", "\n", "            ", "break", "\n", "\n", "", "state_dict", ",", "inp", "=", "ready_to_submit", "(", "hypotheses", ")", "\n", "\n", "# collect mem_dict", "\n", "cur_mem_dict", "=", "dict", "(", ")", "\n", "indices", "=", "torch", ".", "tensor", "(", "indices", ")", ".", "to", "(", "model", ".", "device", ")", "\n", "for", "k", ",", "v", "in", "mem_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "v", ",", "list", ")", ":", "\n", "                ", "cur_mem_dict", "[", "k", "]", "=", "[", "v", "[", "i", "]", "for", "i", "in", "indices", "]", "\n", "", "else", ":", "\n", "                ", "cur_mem_dict", "[", "k", "]", "=", "v", ".", "index_select", "(", "1", ",", "indices", ")", "\n", "\n", "# run one decode step", "\n", "# state_dict: for each item in state_dict, it must have the shape of (seq_len x bsz x *) or (bsz x dim)", "\n", "# next_steps: list (bsz) of list (#beam_size) of (token, score)", "\n", "", "", "state_dict", ",", "results", "=", "model", ".", "decode_step", "(", "inp", ",", "state_dict", ",", "cur_mem_dict", ",", "offset", ",", "beams", "[", "0", "]", ".", "beam_size", ")", "\n", "\n", "# dispatch the outcome to each beam", "\n", "_len_each_beam", "=", "[", "len", "(", "beam", ".", "hypotheses", ")", "for", "beam", "in", "beams", "if", "not", "beam", ".", "completed", "(", ")", "]", "\n", "_state_dict_each_beam", "=", "[", "dict", "(", ")", "for", "_", "in", "_len_each_beam", "]", "\n", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "            ", "split_dim", "=", "1", "if", "len", "(", "v", ".", "size", "(", ")", ")", ">=", "3", "else", "0", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "v", ".", "split", "(", "_len_each_beam", ",", "dim", "=", "split_dim", ")", ")", ":", "\n", "                ", "_state_dict_each_beam", "[", "i", "]", "[", "k", "]", "=", "x", "\n", "\n", "", "", "_pos", "=", "0", "\n", "_idx", "=", "0", "\n", "for", "beam", "in", "beams", ":", "\n", "            ", "if", "not", "beam", ".", "completed", "(", ")", ":", "\n", "                ", "_len", "=", "len", "(", "beam", ".", "hypotheses", ")", "\n", "beam", ".", "update", "(", "_state_dict_each_beam", "[", "_idx", "]", ",", "results", "[", "_pos", ":", "_pos", "+", "_len", "]", ",", "model", ".", "device", ")", "\n", "_pos", "+=", "_len", "\n", "_idx", "+=", "1", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.__init__": [[7, 9], ["transformers.BertTokenizer.__init__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BertEncoderTokenizer", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize": [[10, 34], ["numpy.array", "max", "numpy.zeros", "enumerate", "bert_utils.BertEncoderTokenizer.convert_tokens_to_ids", "enumerate", "_gather_indexes.append", "enumerate", "bert_utils.BertEncoderTokenizer.wordpiece_tokenizer.tokenize", "indexes.append", "split_tokens.append", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer.tokenize"], ["", "def", "tokenize", "(", "self", ",", "tokens", ",", "split", "=", "True", ")", ":", "\n", "        ", "tokens", "=", "[", "'[CLS]'", "]", "+", "tokens", "+", "[", "'[SEP]'", "]", "\n", "if", "not", "split", ":", "\n", "            ", "split_tokens", "=", "[", "t", "if", "t", "in", "self", ".", "vocab", "else", "'[UNK]'", "for", "t", "in", "tokens", "]", "\n", "gather_indexes", "=", "None", "\n", "", "else", ":", "\n", "            ", "split_tokens", ",", "_gather_indexes", "=", "[", "]", ",", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "                ", "indexes", "=", "[", "]", "\n", "for", "i", ",", "sub_token", "in", "enumerate", "(", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", ")", ":", "\n", "                    ", "indexes", ".", "append", "(", "len", "(", "split_tokens", ")", ")", "\n", "split_tokens", ".", "append", "(", "sub_token", ")", "\n", "", "_gather_indexes", ".", "append", "(", "indexes", ")", "\n", "\n", "# We only want CLS and tokens (exclude SEP)", "\n", "", "_gather_indexes", "=", "_gather_indexes", "[", ":", "-", "1", "]", "\n", "max_index_list_len", "=", "max", "(", "len", "(", "indexes", ")", "for", "indexes", "in", "_gather_indexes", ")", "\n", "gather_indexes", "=", "np", ".", "zeros", "(", "(", "len", "(", "_gather_indexes", ")", ",", "max_index_list_len", ")", ")", "\n", "for", "i", ",", "indexes", "in", "enumerate", "(", "_gather_indexes", ")", ":", "\n", "                ", "for", "j", ",", "index", "in", "enumerate", "(", "indexes", ")", ":", "\n", "                    ", "gather_indexes", "[", "i", ",", "j", "]", "=", "index", "\n", "\n", "", "", "", "token_ids", "=", "np", ".", "array", "(", "self", ".", "convert_tokens_to_ids", "(", "split_tokens", ")", ")", "\n", "return", "token_ids", ",", "gather_indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoderTokenizer._back_to_txt_for_check": [[35, 38], ["print", "bert_utils.BertEncoderTokenizer.convert_ids_to_tokens"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "_back_to_txt_for_check", "(", "self", ",", "token_ids", ")", ":", "\n", "        ", "for", "tokens", "in", "token_ids", ":", "\n", "            ", "print", "(", "self", ".", "convert_ids_to_tokens", "(", "tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoder.__init__": [[41, 43], ["transformers.BertModel.__init__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEncoder", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoder.forward": [[44, 61], ["input_ids.ne", "super().forward", "bert_utils.BertEncoder.average_pooling"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.SinusoidalPositionalEmbedding.forward", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoder.average_pooling"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_subword_index", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param input_ids: same as it in BertModel\n        :param output_all_encoded_layers: same as it in BertModel\n        :param token_subword_index: [batch_size, num_tokens, num_subwords]\n        :return:\n        \"\"\"", "\n", "# encoded_layers: [batch_size, num_subword_pieces, hidden_size]", "\n", "token_type_ids", "=", "None", "\n", "attention_mask", "=", "input_ids", ".", "ne", "(", "0", ")", "\n", "\n", "encoded_layers", ",", "pooled_output", "=", "super", "(", "BertEncoder", ",", "self", ")", ".", "forward", "(", "\n", "input_ids", ",", "attention_mask", ",", "token_type_ids", ",", "return_dict", "=", "False", ")", "\n", "if", "token_subword_index", "is", "None", ":", "\n", "            ", "return", "encoded_layers", "[", ":", ",", "1", ":", "-", "1", "]", ",", "pooled_output", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "average_pooling", "(", "encoded_layers", ",", "token_subword_index", ")", ",", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoder.average_pooling": [[62, 84], ["token_subword_index.size", "torch.arange().view().type_as", "torch.arange().view().type_as", "encoded_layers.size", "encoded_layers.unsqueeze().expand", "token_subword_index.eq().unsqueeze().expand", "token_reprs.masked_fill_", "torch.sum", "token_subword_index.ne().sum", "token_subword_index.ne().sum.eq().long", "torch.arange().view", "torch.arange().view", "encoded_layers.unsqueeze", "token_subword_index.eq().unsqueeze", "token_subword_index.ne", "token_subword_index.ne().sum.eq", "torch.arange", "torch.arange", "token_subword_index.eq"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view"], ["", "", "def", "average_pooling", "(", "self", ",", "encoded_layers", ",", "token_subword_index", ")", ":", "\n", "        ", "batch_size", ",", "num_tokens", ",", "num_subwords", "=", "token_subword_index", ".", "size", "(", ")", "\n", "batch_index", "=", "torch", ".", "arange", "(", "batch_size", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "type_as", "(", "token_subword_index", ")", "\n", "token_index", "=", "torch", ".", "arange", "(", "num_tokens", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", ".", "type_as", "(", "token_subword_index", ")", "\n", "_", ",", "num_total_subwords", ",", "hidden_size", "=", "encoded_layers", ".", "size", "(", ")", "\n", "expanded_encoded_layers", "=", "encoded_layers", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "\n", "batch_size", ",", "num_tokens", ",", "num_total_subwords", ",", "hidden_size", ")", "\n", "# [batch_size, num_tokens, num_subwords, hidden_size]", "\n", "token_reprs", "=", "expanded_encoded_layers", "[", "batch_index", ",", "token_index", ",", "token_subword_index", "]", "\n", "subword_pad_mask", "=", "token_subword_index", ".", "eq", "(", "0", ")", ".", "unsqueeze", "(", "3", ")", ".", "expand", "(", "\n", "batch_size", ",", "num_tokens", ",", "num_subwords", ",", "hidden_size", ")", "\n", "token_reprs", ".", "masked_fill_", "(", "subword_pad_mask", ",", "0", ")", "\n", "# [batch_size, num_tokens, hidden_size]", "\n", "sum_token_reprs", "=", "torch", ".", "sum", "(", "token_reprs", ",", "dim", "=", "2", ")", "\n", "# [batch_size, num_tokens]", "\n", "num_valid_subwords", "=", "token_subword_index", ".", "ne", "(", "0", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "pad_mask", "=", "num_valid_subwords", ".", "eq", "(", "0", ")", ".", "long", "(", ")", "\n", "# Add ones to arrays where there is no valid subword.", "\n", "divisor", "=", "(", "num_valid_subwords", "+", "pad_mask", ")", ".", "unsqueeze", "(", "2", ")", ".", "type_as", "(", "sum_token_reprs", ")", "\n", "# [batch_size, num_tokens, hidden_size]", "\n", "avg_token_reprs", "=", "sum_token_reprs", "/", "divisor", "\n", "return", "avg_token_reprs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.bert_utils.BertEncoder.max_pooling": [[85, 105], ["token_subword_index.size", "torch.arange().view().type_as", "torch.arange().view().type_as", "encoded_layers.size", "encoded_layers.unsqueeze().expand", "token_subword_index.eq().unsqueeze().expand", "token_reprs.masked_fill_", "torch.max", "token_subword_index.ne().sum", "token_subword_index.ne().sum.eq().unsqueeze().expand", "max_token_reprs.masked_fill", "torch.arange().view", "torch.arange().view", "encoded_layers.unsqueeze", "token_subword_index.eq().unsqueeze", "float", "token_subword_index.ne", "token_subword_index.ne().sum.eq().unsqueeze", "torch.arange", "torch.arange", "token_subword_index.eq", "token_subword_index.ne().sum.eq"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view"], ["", "def", "max_pooling", "(", "self", ",", "encoded_layers", ",", "token_subword_index", ")", ":", "\n", "        ", "batch_size", ",", "num_tokens", ",", "num_subwords", "=", "token_subword_index", ".", "size", "(", ")", "\n", "batch_index", "=", "torch", ".", "arange", "(", "batch_size", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", ".", "type_as", "(", "token_subword_index", ")", "\n", "token_index", "=", "torch", ".", "arange", "(", "num_tokens", ")", ".", "view", "(", "1", ",", "-", "1", ",", "1", ")", ".", "type_as", "(", "token_subword_index", ")", "\n", "_", ",", "num_total_subwords", ",", "hidden_size", "=", "encoded_layers", ".", "size", "(", ")", "\n", "expanded_encoded_layers", "=", "encoded_layers", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "\n", "batch_size", ",", "num_tokens", ",", "num_total_subwords", ",", "hidden_size", ")", "\n", "# [batch_size, num_tokens, num_subwords, hidden_size]", "\n", "token_reprs", "=", "expanded_encoded_layers", "[", "batch_index", ",", "token_index", ",", "token_subword_index", "]", "\n", "subword_pad_mask", "=", "token_subword_index", ".", "eq", "(", "0", ")", ".", "unsqueeze", "(", "3", ")", ".", "expand", "(", "\n", "batch_size", ",", "num_tokens", ",", "num_subwords", ",", "hidden_size", ")", "\n", "token_reprs", ".", "masked_fill_", "(", "subword_pad_mask", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "# [batch_size, num_tokens, hidden_size]", "\n", "max_token_reprs", ",", "_", "=", "torch", ".", "max", "(", "token_reprs", ",", "dim", "=", "2", ")", "\n", "# [batch_size, num_tokens]", "\n", "num_valid_subwords", "=", "token_subword_index", ".", "ne", "(", "0", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "pad_mask", "=", "num_valid_subwords", ".", "eq", "(", "0", ")", ".", "unsqueeze", "(", "2", ")", ".", "expand", "(", "\n", "batch_size", ",", "num_tokens", ",", "hidden_size", ")", "\n", "max_token_reprs", ".", "masked_fill", "(", "pad_mask", ",", "0", ")", "\n", "return", "max_token_reprs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.utils.move_to_device": [[6, 21], ["torch.is_tensor", "maybe_tensor.to", "isinstance", "torch.from_numpy().to().contiguous", "isinstance", "isinstance", "torch.from_numpy().to", "utils.move_to_device", "isinstance", "maybe_tensor.items", "utils.move_to_device", "tuple", "torch.from_numpy", "utils.move_to_device"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.utils.move_to_device", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.utils.move_to_device", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.utils.move_to_device"], ["#", "\n", "import", "io", "\n", "import", "json", "\n", "import", "os", "\n", "import", "pickle", "\n", "\n", "from", "segtok", ".", "segmenter", "import", "split_multi", "\n", "\n", "##### Reading helpers #####", "\n", "def", "read_sentences_from_file", "(", "path_to_file", ",", "one_sentence_per_line", "=", "True", ")", ":", "\n", "    ", "lines", "=", "[", "]", "\n", "with", "io", ".", "open", "(", "path_to_file", ",", "mode", "=", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "file", ":", "\n", "        ", "for", "line", "in", "file", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "!=", "\"\"", ":", "\n", "                ", "lines", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.utils.compute_f_by_tensor": [[22, 48], ["input.view().tolist.view().tolist", "target.view().tolist.view().tolist", "mask.view().tolist.view().tolist", "zip", "input.view().tolist.view", "target.view().tolist.view", "mask.view().tolist.view"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view"], ["\n", "", "", "", "if", "one_sentence_per_line", ":", "\n", "        ", "sentences", "=", "lines", "\n", "", "else", ":", "\n", "        ", "text", "=", "\" \"", ".", "join", "(", "lines", ")", "\n", "sentences", "=", "list", "(", "split_multi", "(", "text", ")", ")", "\n", "sentences", "=", "[", "sentence", "for", "sentence", "in", "sentences", "if", "sentence", "!=", "\"\"", "]", "\n", "\n", "", "return", "sentences", "\n", "\n", "\n", "##### Printing / writing  helpers #####", "\n", "", "def", "get_candidate_summary", "(", "candidate", ")", ":", "\n", "    ", "wikipedia_id", "=", "candidate", "[", "\"wikipedia_id\"", "]", "\n", "wikidata_id", "=", "candidate", "[", "\"wikidata_id\"", "]", "\n", "wikipedia_title", "=", "candidate", "[", "\"wikipedia_title\"", "]", "\n", "\n", "return", "\"{}, {}, {}\"", ".", "format", "(", "wikipedia_id", ",", "wikidata_id", ",", "wikipedia_title", ")", "\n", "\n", "\n", "", "def", "present_sentence_mentions", "(", "sentence", ",", "mentions", ",", "output_file", ")", ":", "\n", "    ", "if", "output_file", "!=", "None", ":", "\n", "        ", "f", "=", "io", ".", "open", "(", "output_file", ",", "mode", "=", "\"a\"", ",", "encoding", "=", "\"utf-8\"", ")", "\n", "output", "=", "lambda", "s", ":", "f", ".", "write", "(", "\"{}\\n\"", ".", "format", "(", "s", ")", ")", "\n", "", "else", ":", "\n", "        ", "output", "=", "lambda", "s", ":", "print", "(", "s", ")", "\n", "", "output", "(", "\"Sentence: {}\"", ".", "format", "(", "sentence", ")", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.utils.gelu_fast": [[49, 53], ["hasattr", "math.sqrt", "torch.tanh", "torch.pow"], "function", ["None"], ["\n", "mention_entity_pairs", "=", "[", "]", "\n", "for", "mention", "in", "mentions", ":", "\n", "        ", "candidates", "=", "mention", "[", "\"candidates\"", "]", "\n", "# prediction = mention.get('predicted_candidate_idx', 0)", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.utils.gelu": [[54, 56], ["torch.erf", "math.sqrt"], "function", ["None"], ["prediction", "=", "mention", "[", "\"predicted_candidate_idx\"", "]", "\n", "\n", "if", "prediction", "<", "len", "(", "candidates", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.utils.label_smoothed_nll_loss": [[58, 68], ["log_probs.gather().squeeze", "log_probs.sum", "log_probs.size", "log_probs.gather", "target.unsqueeze"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["# print(mention['prob_assigned_to_candidate'])", "\n", "            ", "mention_rep", "=", "\"{} ({}, {}) - {} (conf. {:.5f})\"", ".", "format", "(", "\n", "mention", "[", "\"text\"", "]", ",", "\n", "mention", "[", "\"start_pos\"", "]", ",", "\n", "mention", "[", "\"end_pos\"", "]", ",", "\n", "get_candidate_summary", "(", "candidates", "[", "prediction", "]", ")", ",", "\n", "mention", "[", "\"prob_assigned_to_candidate\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "mention_rep", "=", "\"{} ({}, {}) - {}\"", ".", "format", "(", "\n", "mention", "[", "\"text\"", "]", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.make_vocab": [[8, 19], ["collections.Counter", "collections.Counter", "collections.Counter.most_common", "collections.Counter.update", "list"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update"], ["def", "make_vocab", "(", "batch_seq", ",", "char_level", "=", "False", ")", ":", "\n", "    ", "cnt", "=", "Counter", "(", ")", "\n", "for", "seq", "in", "batch_seq", ":", "\n", "        ", "cnt", ".", "update", "(", "seq", ")", "# count once for every item", "\n", "", "if", "not", "char_level", ":", "\n", "        ", "return", "cnt", "\n", "", "char_cnt", "=", "Counter", "(", ")", "\n", "for", "x", ",", "y", "in", "cnt", ".", "most_common", "(", ")", ":", "\n", "        ", "for", "ch", "in", "list", "(", "x", ")", ":", "\n", "            ", "char_cnt", "[", "ch", "]", "+=", "y", "\n", "", "", "return", "cnt", ",", "char_cnt", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.write_vocab": [[21, 27], ["open", "sorted", "sorted", "sorted.items", "fo.write"], "function", ["None"], ["", "def", "write_vocab", "(", "vocab", ",", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "'w'", ")", "as", "fo", ":", "\n", "        ", "vocab", "=", "sorted", "(", "vocab", ".", "items", "(", ")", ")", "# Counter() to list of tuples, sorted by name", "\n", "vocab", "=", "sorted", "(", "vocab", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "# Now sort by count, reversed", "\n", "for", "name", ",", "count", "in", "vocab", ":", "\n", "            ", "fo", ".", "write", "(", "'%s\\t%d\\n'", "%", "(", "name", ",", "count", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.create_vocabs": [[28, 75], ["print", "amr_graph.read_file", "print", "tqdm.tqdm", "create_vocabs.make_vocab", "create_vocabs.make_vocab", "create_vocabs.make_vocab", "create_vocabs.make_vocab", "create_vocabs.make_vocab", "create_vocabs.make_vocab", "create_vocabs.make_vocab", "sum", "sum", "print", "print", "create_vocabs.write_vocab", "create_vocabs.write_vocab", "create_vocabs.write_vocab", "create_vocabs.write_vocab", "create_vocabs.write_vocab", "create_vocabs.write_vocab", "create_vocabs.write_vocab", "create_vocabs.write_vocab", "create_vocabs.write_vocab", "create_vocabs.write_vocab", "zip", "range", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "amr.root_centered_sort", "relations.append", "len", "len", "concepts.append", "set", "predictable_conc.append"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph.read_file", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.make_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.make_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.make_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.make_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.make_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.make_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.make_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.write_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.write_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.write_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.write_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.write_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.write_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.write_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.write_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.write_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.create_vocabs.write_vocab", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.amr_graph.AMRGraph.root_centered_sort"], ["", "", "", "def", "create_vocabs", "(", "train_data", ",", "vocab_dir", ")", ":", "\n", "    ", "print", "(", "'Loading'", ",", "train_data", ")", "\n", "# Read the data file and obtain a list of items, 1 for each AMR entry", "\n", "amrs", ",", "token", ",", "lemma", ",", "pos", ",", "ner", "=", "read_file", "(", "train_data", ")", "\n", "# collect concepts and relations", "\n", "concepts", "=", "[", "]", "# nodes", "\n", "relations", "=", "[", "]", "# edges", "\n", "predictable_conc", "=", "[", "]", "\n", "print", "(", "'Processing'", ")", "\n", "for", "amr", ",", "lem", "in", "tqdm", "(", "zip", "(", "amrs", ",", "lemma", ")", ",", "total", "=", "len", "(", "amrs", ")", ")", ":", "\n", "# run 10 times for random sort to get the priorities of different types of edges", "\n", "# Using the root_centered_sort() gives a realistic count of the number of times", "\n", "# the vocab is used, which is used for priority later.", "\n", "        ", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "            ", "concept", ",", "edge", ",", "not_ok", "=", "amr", ".", "root_centered_sort", "(", ")", "# edges are randomly shuffled", "\n", "relations", ".", "append", "(", "[", "e", "[", "-", "1", "]", "for", "e", "in", "edge", "]", ")", "# edge is (node-a, node-b, relation)", "\n", "if", "i", "==", "0", ":", "# concepts are not shuffled", "\n", "                ", "concepts", ".", "append", "(", "concept", ")", "\n", "lexical_concepts", "=", "set", "(", "[", "l", "for", "l", "in", "lem", "]", "+", "[", "l", "+", "'_'", "for", "l", "in", "lem", "]", ")", "\n", "predictable_conc", ".", "append", "(", "[", "c", "for", "c", "in", "concept", "if", "c", "not", "in", "lexical_concepts", "]", ")", "\n", "\n", "# make vocabularies", "\n", "", "", "", "token_vocab", ",", "token_char_vocab", "=", "make_vocab", "(", "token", ",", "char_level", "=", "True", ")", "\n", "lemma_vocab", ",", "lemma_char_vocab", "=", "make_vocab", "(", "lemma", ",", "char_level", "=", "True", ")", "\n", "pos_vocab", "=", "make_vocab", "(", "pos", ")", "\n", "ner_vocab", "=", "make_vocab", "(", "ner", ")", "\n", "conc_vocab", ",", "conc_char_vocab", "=", "make_vocab", "(", "concepts", ",", "char_level", "=", "True", ")", "\n", "predictable_conc_vocab", "=", "make_vocab", "(", "predictable_conc", ")", "\n", "rel_vocab", "=", "make_vocab", "(", "relations", ")", "\n", "\n", "# Print some stats", "\n", "num_pc", "=", "sum", "(", "len", "(", "x", ")", "for", "x", "in", "predictable_conc", ")", "\n", "num_conc", "=", "sum", "(", "len", "(", "x", ")", "for", "x", "in", "concepts", ")", "\n", "pct", "=", "100.", "*", "num_pc", "/", "num_conc", "\n", "print", "(", "'predictable concept coverage: {:,}/{:,} = {:.1f}%'", ".", "format", "(", "num_pc", ",", "num_conc", ",", "pct", ")", ")", "\n", "\n", "print", "(", "'Saving vocabs to '", ",", "vocab_dir", ")", "\n", "write_vocab", "(", "token_vocab", ",", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'tok_vocab'", ")", ")", "\n", "write_vocab", "(", "token_char_vocab", ",", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'word_char_vocab'", ")", ")", "\n", "write_vocab", "(", "lemma_vocab", ",", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'lem_vocab'", ")", ")", "\n", "write_vocab", "(", "lemma_char_vocab", ",", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'lem_char_vocab'", ")", ")", "\n", "write_vocab", "(", "pos_vocab", ",", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'pos_vocab'", ")", ")", "\n", "write_vocab", "(", "ner_vocab", ",", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'ner_vocab'", ")", ")", "\n", "write_vocab", "(", "conc_vocab", ",", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'concept_vocab'", ")", ")", "\n", "write_vocab", "(", "conc_char_vocab", ",", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'concept_char_vocab'", ")", ")", "\n", "write_vocab", "(", "predictable_conc_vocab", ",", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'predictable_concept_vocab'", ")", ")", "\n", "write_vocab", "(", "rel_vocab", ",", "os", ".", "path", ".", "join", "(", "vocab_dir", ",", "'rel_vocab'", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.WordEncoder.__init__": [[76, 97], ["torch.nn.Module.__init__", "encoder.AMREmbedding", "encoder.CNNEncoder", "encoder.AMREmbedding", "torch.nn.Linear", "torch.nn.Linear", "encoder.WordEncoder.reset_parameters", "encoder.AMREmbedding", "encoder.AMREmbedding"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.AMREmbedding", "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.AMREmbedding", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.LearnedPositionalEmbedding.reset_parameters", "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.AMREmbedding", "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.AMREmbedding"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "char_dim", ",", "word_dim", ",", "pos_dim", ",", "ner_dim", ",", "\n", "embed_dim", ",", "filters", ",", "char2word_dim", ",", "dropout", ",", "pretrained_file", "=", "None", ")", ":", "\n", "        ", "super", "(", "WordEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "char_embed", "=", "AMREmbedding", "(", "vocabs", "[", "'word_char'", "]", ",", "char_dim", ")", "\n", "self", ".", "char2word", "=", "CNNEncoder", "(", "filters", ",", "char_dim", ",", "char2word_dim", ")", "\n", "self", ".", "lem_embed", "=", "AMREmbedding", "(", "vocabs", "[", "'lem'", "]", ",", "word_dim", ",", "pretrained_file", ")", "\n", "\n", "if", "pos_dim", ">", "0", ":", "\n", "            ", "self", ".", "pos_embed", "=", "AMREmbedding", "(", "vocabs", "[", "'pos'", "]", ",", "pos_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "pos_embed", "=", "None", "\n", "", "if", "ner_dim", ">", "0", ":", "\n", "            ", "self", ".", "ner_embed", "=", "AMREmbedding", "(", "vocabs", "[", "'ner'", "]", ",", "ner_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ner_embed", "=", "None", "\n", "\n", "", "tot_dim", "=", "word_dim", "+", "pos_dim", "+", "ner_dim", "+", "char2word_dim", "\n", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "tot_dim", ",", "embed_dim", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.WordEncoder.reset_parameters": [[98, 101], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "out_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.WordEncoder.forward": [[102, 123], ["char_input.size", "encoder.WordEncoder.char_embed", "encoder.WordEncoder.char2word().view", "encoder.WordEncoder.lem_embed", "torch.dropout", "torch.dropout", "encoder.WordEncoder.out_proj", "char_input.view", "encoder.WordEncoder.pos_embed", "reprs.append", "encoder.WordEncoder.ner_embed", "reprs.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoder.WordEncoder.char2word"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view"], ["", "def", "forward", "(", "self", ",", "char_input", ",", "tok_input", ",", "lem_input", ",", "pos_input", ",", "ner_input", ")", ":", "\n", "# char: seq_len x bsz x word_len", "\n", "# word, pos, ner: seq_len x bsz", "\n", "        ", "seq_len", ",", "bsz", ",", "_", "=", "char_input", ".", "size", "(", ")", "\n", "char_repr", "=", "self", ".", "char_embed", "(", "char_input", ".", "view", "(", "seq_len", "*", "bsz", ",", "-", "1", ")", ")", "\n", "char_repr", "=", "self", ".", "char2word", "(", "char_repr", ")", ".", "view", "(", "seq_len", ",", "bsz", ",", "-", "1", ")", "\n", "\n", "lem_repr", "=", "self", ".", "lem_embed", "(", "lem_input", ")", "\n", "reprs", "=", "[", "char_repr", ",", "lem_repr", "]", "\n", "\n", "if", "self", ".", "pos_embed", "is", "not", "None", ":", "\n", "            ", "pos_repr", "=", "self", ".", "pos_embed", "(", "pos_input", ")", "\n", "reprs", ".", "append", "(", "pos_repr", ")", "\n", "\n", "", "if", "self", ".", "ner_embed", "is", "not", "None", ":", "\n", "            ", "ner_repr", "=", "self", ".", "ner_embed", "(", "ner_input", ")", "\n", "reprs", ".", "append", "(", "ner_repr", ")", "\n", "\n", "", "word", "=", "F", ".", "dropout", "(", "torch", ".", "cat", "(", "reprs", ",", "-", "1", ")", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "word", "=", "self", ".", "out_proj", "(", "word", ")", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.ConceptEncoder.__init__": [[125, 138], ["torch.nn.Module.__init__", "encoder.AMREmbedding", "encoder.AMREmbedding", "encoder.CNNEncoder", "torch.nn.Linear", "torch.nn.Linear", "encoder.ConceptEncoder.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.AMREmbedding", "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.AMREmbedding", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "char_dim", ",", "concept_dim", ",", "embed_dim", ",", "filters", ",", "char2concept_dim", ",", "dropout", ",", "pretrained_file", "=", "None", ")", ":", "\n", "        ", "super", "(", "ConceptEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "char_embed", "=", "AMREmbedding", "(", "vocabs", "[", "'concept_char'", "]", ",", "char_dim", ")", "\n", "self", ".", "concept_embed", "=", "AMREmbedding", "(", "vocabs", "[", "'concept'", "]", ",", "concept_dim", ",", "pretrained_file", ",", "amr", "=", "True", ")", "\n", "self", ".", "char2concept", "=", "CNNEncoder", "(", "filters", ",", "char_dim", ",", "char2concept_dim", ")", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "tot_dim", "=", "char2concept_dim", "+", "concept_dim", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "tot_dim", ",", "embed_dim", ")", "\n", "self", ".", "char_dim", "=", "char_dim", "\n", "self", ".", "concept_dim", "=", "concept_dim", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.ConceptEncoder.reset_parameters": [[139, 142], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "out_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.ConceptEncoder.forward": [[143, 153], ["char_input.size", "encoder.ConceptEncoder.char_embed", "encoder.ConceptEncoder.char2concept().view", "encoder.ConceptEncoder.concept_embed", "torch.dropout", "torch.dropout", "encoder.ConceptEncoder.out_proj", "char_input.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoder.ConceptEncoder.char2concept"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view"], ["", "def", "forward", "(", "self", ",", "char_input", ",", "concept_input", ")", ":", "\n", "\n", "        ", "seq_len", ",", "bsz", ",", "_", "=", "char_input", ".", "size", "(", ")", "\n", "char_repr", "=", "self", ".", "char_embed", "(", "char_input", ".", "view", "(", "seq_len", "*", "bsz", ",", "-", "1", ")", ")", "\n", "char_repr", "=", "self", ".", "char2concept", "(", "char_repr", ")", ".", "view", "(", "seq_len", ",", "bsz", ",", "-", "1", ")", "\n", "concept_repr", "=", "self", ".", "concept_embed", "(", "concept_input", ")", "\n", "\n", "concept", "=", "F", ".", "dropout", "(", "torch", ".", "cat", "(", "[", "char_repr", ",", "concept_repr", "]", ",", "-", "1", ")", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "concept", "=", "self", ".", "out_proj", "(", "concept", ")", "\n", "return", "concept", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.CNNEncoder.__init__": [[156, 165], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "sum", "encoder.Highway", "torch.nn.Linear", "torch.nn.Linear", "encoder.CNNEncoder.reset_parameters", "encoder.CNNEncoder.convolutions.append", "torch.nn.Conv1d", "torch.nn.Conv1d"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "filters", ",", "input_dim", ",", "output_dim", ",", "highway_layers", "=", "1", ")", ":", "\n", "        ", "super", "(", "CNNEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "convolutions", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "width", ",", "out_c", "in", "filters", ":", "\n", "            ", "self", ".", "convolutions", ".", "append", "(", "nn", ".", "Conv1d", "(", "input_dim", ",", "out_c", ",", "kernel_size", "=", "width", ")", ")", "\n", "", "final_dim", "=", "sum", "(", "f", "[", "1", "]", "for", "f", "in", "filters", ")", "\n", "self", ".", "highway", "=", "Highway", "(", "final_dim", ",", "highway_layers", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "final_dim", ",", "output_dim", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.CNNEncoder.reset_parameters": [[166, 169], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "out_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.CNNEncoder.forward": [[170, 183], ["input.transpose", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoder.CNNEncoder.highway", "encoder.CNNEncoder.out_proj", "conv", "torch.max", "torch.max", "torch.max", "torch.max", "torch.relu", "torch.relu", "encoder.CNNEncoder.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "# input: batch_size x seq_len x input_dim", "\n", "        ", "x", "=", "input", ".", "transpose", "(", "1", ",", "2", ")", "\n", "conv_result", "=", "[", "]", "\n", "for", "i", ",", "conv", "in", "enumerate", "(", "self", ".", "convolutions", ")", ":", "\n", "            ", "y", "=", "conv", "(", "x", ")", "\n", "y", ",", "_", "=", "torch", ".", "max", "(", "y", ",", "-", "1", ")", "\n", "y", "=", "F", ".", "relu", "(", "y", ")", "\n", "conv_result", ".", "append", "(", "y", ")", "\n", "\n", "", "conv_result", "=", "torch", ".", "cat", "(", "conv_result", ",", "dim", "=", "-", "1", ")", "\n", "conv_result", "=", "self", ".", "highway", "(", "conv_result", ")", "\n", "return", "self", ".", "out_proj", "(", "conv_result", ")", "#  batch_size x output_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.Highway.__init__": [[185, 191], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "encoder.Highway.reset_parameters", "torch.nn.Linear", "torch.nn.Linear", "range"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "layers", ")", ":", "\n", "        ", "super", "(", "Highway", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "input_dim", ",", "input_dim", "*", "2", ")", "\n", "for", "_", "in", "range", "(", "layers", ")", "]", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.Highway.reset_parameters": [[192, 197], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "layer", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "layer", ".", "bias", "[", "self", ".", "input_dim", ":", "]", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "layer", ".", "bias", "[", ":", "self", ".", "input_dim", "]", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.Highway.forward": [[198, 206], ["layer", "torch.relu.chunk", "torch.relu", "torch.relu", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "new_x", "=", "layer", "(", "x", ")", "\n", "new_x", ",", "gate", "=", "new_x", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "new_x", "=", "F", ".", "relu", "(", "new_x", ")", "\n", "gate", "=", "torch", ".", "sigmoid", "(", "gate", ")", "\n", "x", "=", "gate", "*", "x", "+", "(", "1", "-", "gate", ")", "*", "new_x", "\n", "", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.encoder.AMREmbedding": [[9, 73], ["set", "range", "numpy.asarray", "print", "float", "float", "float", "float", "print", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "range", "embedding_matrix[].fill_", "torch.nn.Embedding.from_pretrained", "transformer.Embedding", "vocab.idx2token", "set.add", "open", "open", "embeddings_file.readlines", "open.close", "list", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "vocab.idx2token", "re.sub", "line.rstrip().split", "embeddings.values", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.asarray", "re.sub", "line.rstrip", "len", "open.write", "torch.FloatTensor", "torch.FloatTensor"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.Embedding", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.idx2token", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.idx2token", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["def", "AMREmbedding", "(", "vocab", ",", "embedding_dim", ",", "pretrained_file", "=", "None", ",", "amr", "=", "False", ",", "dump_file", "=", "None", ")", ":", "\n", "    ", "if", "pretrained_file", "is", "None", ":", "\n", "        ", "return", "Embedding", "(", "vocab", ".", "size", ",", "embedding_dim", ",", "vocab", ".", "padding_idx", ")", "\n", "\n", "", "tokens_to_keep", "=", "set", "(", ")", "\n", "for", "idx", "in", "range", "(", "vocab", ".", "size", ")", ":", "\n", "        ", "token", "=", "vocab", ".", "idx2token", "(", "idx", ")", "\n", "# TODO: Is there a better way to do this? Currently we have a very specific 'amr' param.", "\n", "if", "amr", ":", "\n", "            ", "token", "=", "re", ".", "sub", "(", "r'-\\d\\d$'", ",", "''", ",", "token", ")", "\n", "", "tokens_to_keep", ".", "add", "(", "token", ")", "\n", "\n", "", "embeddings", "=", "{", "}", "\n", "\n", "if", "dump_file", "is", "not", "None", ":", "\n", "        ", "fo", "=", "open", "(", "dump_file", ",", "'w'", ",", "encoding", "=", "'utf8'", ")", "\n", "\n", "", "with", "open", "(", "pretrained_file", ",", "encoding", "=", "'utf8'", ")", "as", "embeddings_file", ":", "\n", "        ", "for", "line", "in", "embeddings_file", ".", "readlines", "(", ")", ":", "\n", "            ", "fields", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "' '", ")", "\n", "if", "len", "(", "fields", ")", "-", "1", "!=", "embedding_dim", ":", "\n", "                ", "continue", "\n", "", "token", "=", "fields", "[", "0", "]", "\n", "if", "token", "in", "tokens_to_keep", ":", "\n", "                ", "if", "dump_file", "is", "not", "None", ":", "\n", "                    ", "fo", ".", "write", "(", "line", ")", "\n", "", "vector", "=", "np", ".", "asarray", "(", "fields", "[", "1", ":", "]", ",", "dtype", "=", "'float32'", ")", "\n", "embeddings", "[", "token", "]", "=", "vector", "\n", "\n", "", "", "", "if", "dump_file", "is", "not", "None", ":", "\n", "        ", "fo", ".", "close", "(", ")", "\n", "\n", "", "all_embeddings", "=", "np", ".", "asarray", "(", "list", "(", "embeddings", ".", "values", "(", ")", ")", ")", "\n", "print", "(", "'pretrained'", ",", "all_embeddings", ".", "shape", ")", "\n", "embeddings_mean", "=", "float", "(", "np", ".", "mean", "(", "all_embeddings", ")", ")", "\n", "embeddings_std", "=", "float", "(", "np", ".", "std", "(", "all_embeddings", ")", ")", "\n", "\n", "\n", "all_embeddings", "-=", "embeddings_mean", "\n", "all_embeddings", "/=", "embeddings_std", "\n", "all_embeddings", "*=", "0.02", "\n", "embeddings_mean", "=", "float", "(", "np", ".", "mean", "(", "all_embeddings", ")", ")", "\n", "embeddings_std", "=", "float", "(", "np", ".", "std", "(", "all_embeddings", ")", ")", "\n", "print", "(", "embeddings_mean", ",", "embeddings_std", ")", "\n", "# Now we initialize the weight matrix for an embedding layer, starting with random vectors,", "\n", "# then filling in the word vectors we just read.", "\n", "embedding_matrix", "=", "torch", ".", "FloatTensor", "(", "vocab", ".", "size", ",", "embedding_dim", ")", ".", "normal_", "(", "embeddings_mean", ",", "\n", "embeddings_std", ")", "\n", "\n", "for", "i", "in", "range", "(", "vocab", ".", "size", ")", ":", "\n", "        ", "token", "=", "vocab", ".", "idx2token", "(", "i", ")", "\n", "\n", "# If we don't have a pre-trained vector for this word, we'll just leave this row alone,", "\n", "# so the word has a random initialization.", "\n", "if", "token", "in", "embeddings", ":", "\n", "            ", "embedding_matrix", "[", "i", "]", "=", "torch", ".", "FloatTensor", "(", "embeddings", "[", "token", "]", ")", "\n", "", "else", ":", "\n", "            ", "if", "amr", ":", "\n", "                ", "normalized_token", "=", "re", ".", "sub", "(", "r'-\\d\\d$'", ",", "''", ",", "token", ")", "\n", "if", "normalized_token", "in", "embeddings", ":", "\n", "                    ", "embedding_matrix", "[", "i", "]", "=", "torch", ".", "FloatTensor", "(", "embeddings", "[", "normalized_token", "]", ")", "\n", "", "", "", "", "embedding_matrix", "[", "vocab", ".", "padding_idx", "]", ".", "fill_", "(", "0.", ")", "\n", "\n", "return", "nn", ".", "Embedding", ".", "from_pretrained", "(", "embedding_matrix", ",", "freeze", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.parser.Parser.__init__": [[15, 44], ["torch.nn.Module.__init__", "encoder.WordEncoder", "encoder.ConceptEncoder", "transformer.Transformer", "transformer.Transformer", "math.sqrt", "transformer.SinusoidalPositionalEmbedding", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "transformer.SelfAttentionMask", "decoder.DecodeLayer", "torch.nn.Linear", "torch.nn.Linear", "parser.Parser.reset_parameters", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "word_char_dim", ",", "word_dim", ",", "pos_dim", ",", "ner_dim", ",", "\n", "concept_char_dim", ",", "concept_dim", ",", "\n", "cnn_filters", ",", "char2word_dim", ",", "char2concept_dim", ",", "\n", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "\n", "snt_layers", ",", "graph_layers", ",", "inference_layers", ",", "rel_dim", ",", "device", ",", "\n", "pretrained_file", "=", "None", ",", "bert_encoder", "=", "None", ")", ":", "\n", "        ", "super", "(", "Parser", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "self", ".", "word_encoder", "=", "WordEncoder", "(", "vocabs", ",", "word_char_dim", ",", "word_dim", ",", "pos_dim", ",", "ner_dim", ",", "\n", "embed_dim", ",", "cnn_filters", ",", "char2word_dim", ",", "dropout", ",", "pretrained_file", ")", "\n", "self", ".", "concept_encoder", "=", "ConceptEncoder", "(", "vocabs", ",", "concept_char_dim", ",", "concept_dim", ",", "embed_dim", ",", "\n", "cnn_filters", ",", "char2concept_dim", ",", "dropout", ",", "pretrained_file", ")", "\n", "self", ".", "snt_encoder", "=", "Transformer", "(", "snt_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ")", "\n", "self", ".", "graph_encoder", "=", "Transformer", "(", "graph_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "\n", "with_external", "=", "True", ",", "weights_dropout", "=", "False", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "embed_scale", "=", "math", ".", "sqrt", "(", "embed_dim", ")", "\n", "self", ".", "embed_positions", "=", "SinusoidalPositionalEmbedding", "(", "embed_dim", ",", "device", "=", "device", ")", "\n", "self", ".", "word_embed_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "concept_embed_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "self_attn_mask", "=", "SelfAttentionMask", "(", "device", "=", "device", ")", "\n", "self", ".", "decoder", "=", "DecodeLayer", "(", "vocabs", ",", "inference_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "concept_dim", ",", "rel_dim", ",", "dropout", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "probe_generator", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "bert_encoder", "=", "bert_encoder", "\n", "if", "bert_encoder", "is", "not", "None", ":", "\n", "            ", "self", ".", "bert_adaptor", "=", "nn", ".", "Linear", "(", "768", ",", "embed_dim", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.parser.Parser.reset_parameters": [[45, 48], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "probe_generator", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "probe_generator", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.parser.Parser.encode_step": [[49, 60], ["parser.Parser.word_embed_layer_norm", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "parser.Parser.snt_encoder", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "parser.Parser.embed_positions", "parser.Parser.probe_generator", "parser.Parser.word_encoder"], "methods", ["None"], ["", "def", "encode_step", "(", "self", ",", "tok", ",", "lem", ",", "pos", ",", "ner", ",", "word_char", ")", ":", "\n", "        ", "word_repr", "=", "self", ".", "embed_scale", "*", "self", ".", "word_encoder", "(", "word_char", ",", "tok", ",", "lem", ",", "pos", ",", "ner", ")", "+", "self", ".", "embed_positions", "(", "tok", ")", "\n", "word_repr", "=", "self", ".", "word_embed_layer_norm", "(", "word_repr", ")", "\n", "word_mask", "=", "torch", ".", "eq", "(", "lem", ",", "self", ".", "vocabs", "[", "'lem'", "]", ".", "padding_idx", ")", "\n", "\n", "word_repr", "=", "self", ".", "snt_encoder", "(", "word_repr", ",", "self_padding_mask", "=", "word_mask", ")", "\n", "\n", "probe", "=", "torch", ".", "tanh", "(", "self", ".", "probe_generator", "(", "word_repr", "[", ":", "1", "]", ")", ")", "\n", "word_repr", "=", "word_repr", "[", "1", ":", "]", "\n", "word_mask", "=", "word_mask", "[", "1", ":", "]", "\n", "return", "word_repr", ",", "word_mask", ",", "probe", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.parser.Parser.encode_step_with_bert": [[61, 76], ["parser.Parser.bert_encoder", "parser.Parser.word_encoder", "bert_embed.transpose.transpose.transpose", "parser.Parser.word_embed_layer_norm", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "parser.Parser.snt_encoder", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "parser.Parser.bert_adaptor", "parser.Parser.embed_positions", "parser.Parser.probe_generator"], "methods", ["None"], ["", "def", "encode_step_with_bert", "(", "self", ",", "tok", ",", "lem", ",", "pos", ",", "ner", ",", "word_char", ",", "bert_token", ",", "token_subword_index", ")", ":", "\n", "        ", "bert_embed", ",", "_", "=", "self", ".", "bert_encoder", "(", "bert_token", ",", "token_subword_index", "=", "token_subword_index", ")", "\n", "word_repr", "=", "self", ".", "word_encoder", "(", "word_char", ",", "tok", ",", "lem", ",", "pos", ",", "ner", ")", "\n", "bert_embed", "=", "bert_embed", ".", "transpose", "(", "0", ",", "1", ")", "\n", "word_repr", "=", "word_repr", "+", "self", ".", "bert_adaptor", "(", "bert_embed", ")", "\n", "word_repr", "=", "self", ".", "embed_scale", "*", "word_repr", "+", "self", ".", "embed_positions", "(", "tok", ")", "\n", "word_repr", "=", "self", ".", "word_embed_layer_norm", "(", "word_repr", ")", "\n", "word_mask", "=", "torch", ".", "eq", "(", "lem", ",", "self", ".", "vocabs", "[", "'lem'", "]", ".", "padding_idx", ")", "\n", "\n", "word_repr", "=", "self", ".", "snt_encoder", "(", "word_repr", ",", "self_padding_mask", "=", "word_mask", ")", "\n", "\n", "probe", "=", "torch", ".", "tanh", "(", "self", ".", "probe_generator", "(", "word_repr", "[", ":", "1", "]", ")", ")", "\n", "word_repr", "=", "word_repr", "[", "1", ":", "]", "\n", "word_mask", "=", "word_mask", "[", "1", ":", "]", "\n", "return", "word_repr", ",", "word_mask", ",", "probe", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.parser.Parser.work": [[77, 96], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "search.Hypothesis", "word_repr.size", "search.search_by_batch", "parser.Parser.encode_step_with_bert", "parser.Parser.encode_step", "search.Beam", "range"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.search.search_by_batch", "home.repos.pwc.inspect_result.chenllliang_atp.modules.parser.Parser.encode_step_with_bert", "home.repos.pwc.inspect_result.chenllliang_atp.modules.parser.Parser.encode_step"], ["", "def", "work", "(", "self", ",", "data", ",", "beam_size", ",", "max_time_step", ",", "min_time_step", "=", "1", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "self", ".", "bert_encoder", "is", "not", "None", ":", "\n", "                ", "word_repr", ",", "word_mask", ",", "probe", "=", "self", ".", "encode_step_with_bert", "(", "data", "[", "'tok'", "]", ",", "data", "[", "'lem'", "]", ",", "\n", "data", "[", "'pos'", "]", ",", "data", "[", "'ner'", "]", ",", "data", "[", "'word_char'", "]", ",", "data", "[", "'bert_token'", "]", ",", "data", "[", "'token_subword_index'", "]", ")", "\n", "", "else", ":", "\n", "                ", "word_repr", ",", "word_mask", ",", "probe", "=", "self", ".", "encode_step", "(", "data", "[", "'tok'", "]", ",", "data", "[", "'lem'", "]", ",", "data", "[", "'pos'", "]", ",", "data", "[", "'ner'", "]", ",", "data", "[", "'word_char'", "]", ")", "\n", "\n", "", "mem_dict", "=", "{", "'snt_state'", ":", "word_repr", ",", "\n", "'snt_padding_mask'", ":", "word_mask", ",", "\n", "'probe'", ":", "probe", ",", "\n", "'local_idx2token'", ":", "data", "[", "'local_idx2token'", "]", ",", "\n", "'copy_seq'", ":", "data", "[", "'copy_seq'", "]", "}", "\n", "init_state_dict", "=", "{", "}", "\n", "init_hyp", "=", "Hypothesis", "(", "init_state_dict", ",", "[", "DUM", "]", ",", "0.", ")", "\n", "bsz", "=", "word_repr", ".", "size", "(", "1", ")", "\n", "beams", "=", "[", "Beam", "(", "beam_size", ",", "min_time_step", ",", "max_time_step", ",", "[", "init_hyp", "]", ")", "for", "i", "in", "range", "(", "bsz", ")", "]", "\n", "search_by_batch", "(", "self", ",", "beams", ",", "mem_dict", ")", "\n", "", "return", "beams", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.parser.Parser.prepare_incremental_input": [[97, 102], ["data_loader.ListsToTensor", "data_loader.ListsofStringToTensor", "utils.move_to_device", "utils.move_to_device"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ListsToTensor", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.data_loader.ListsofStringToTensor", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.utils.move_to_device", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.utils.move_to_device"], ["", "def", "prepare_incremental_input", "(", "self", ",", "step_seq", ")", ":", "\n", "        ", "conc", "=", "ListsToTensor", "(", "step_seq", ",", "self", ".", "vocabs", "[", "'concept'", "]", ")", "\n", "conc_char", "=", "ListsofStringToTensor", "(", "step_seq", ",", "self", ".", "vocabs", "[", "'concept_char'", "]", ")", "\n", "conc", ",", "conc_char", "=", "move_to_device", "(", "conc", ",", "self", ".", "device", ")", ",", "move_to_device", "(", "conc_char", ",", "self", ".", "device", ")", "\n", "return", "conc", ",", "conc_char", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.parser.Parser.decode_step": [[103, 167], ["word_repr.size", "parser.Parser.concept_embed_layer_norm", "enumerate", "parser.Parser.decoder", "range", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.log", "torch.log", "torch.log", "torch.log", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "zip", "parser.Parser.embed_positions", "layer", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max", "torch.max", "torch.max", "torch.max", "torch.log.sum", "torch.log.sum", "parser.Parser.vocabs[].idx2token", "LL.squeeze", "topk_scores.tolist", "topk_token.tolist", "zip", "results.append", "parser.Parser.concept_encoder", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "res.append", "parser.Parser.decode_step.idx2token"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.idx2token", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.idx2token"], ["", "def", "decode_step", "(", "self", ",", "inp", ",", "state_dict", ",", "mem_dict", ",", "offset", ",", "topk", ")", ":", "\n", "        ", "step_concept", ",", "step_concept_char", "=", "inp", "\n", "word_repr", "=", "snt_state", "=", "mem_dict", "[", "'snt_state'", "]", "\n", "word_mask", "=", "snt_padding_mask", "=", "mem_dict", "[", "'snt_padding_mask'", "]", "\n", "probe", "=", "mem_dict", "[", "'probe'", "]", "\n", "copy_seq", "=", "mem_dict", "[", "'copy_seq'", "]", "\n", "local_vocabs", "=", "mem_dict", "[", "'local_idx2token'", "]", "\n", "_", ",", "bsz", ",", "_", "=", "word_repr", ".", "size", "(", ")", "\n", "\n", "new_state_dict", "=", "{", "}", "\n", "\n", "concept_repr", "=", "self", ".", "embed_scale", "*", "self", ".", "concept_encoder", "(", "step_concept_char", ",", "step_concept", ")", "+", "self", ".", "embed_positions", "(", "step_concept", ",", "offset", ")", "\n", "concept_repr", "=", "self", ".", "concept_embed_layer_norm", "(", "concept_repr", ")", "\n", "for", "idx", ",", "layer", "in", "enumerate", "(", "self", ".", "graph_encoder", ".", "layers", ")", ":", "\n", "            ", "name_i", "=", "'concept_repr_%d'", "%", "idx", "\n", "if", "name_i", "in", "state_dict", ":", "\n", "                ", "prev_concept_repr", "=", "state_dict", "[", "name_i", "]", "\n", "new_concept_repr", "=", "torch", ".", "cat", "(", "[", "prev_concept_repr", ",", "concept_repr", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "                ", "new_concept_repr", "=", "concept_repr", "\n", "\n", "", "new_state_dict", "[", "name_i", "]", "=", "new_concept_repr", "\n", "concept_repr", ",", "_", ",", "_", "=", "layer", "(", "concept_repr", ",", "kv", "=", "new_concept_repr", ",", "external_memories", "=", "word_repr", ",", "external_padding_mask", "=", "word_mask", ")", "\n", "", "name", "=", "'graph_state'", "\n", "if", "name", "in", "state_dict", ":", "\n", "            ", "prev_graph_state", "=", "state_dict", "[", "name", "]", "\n", "new_graph_state", "=", "torch", ".", "cat", "(", "[", "prev_graph_state", ",", "concept_repr", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "new_graph_state", "=", "concept_repr", "\n", "", "new_state_dict", "[", "name", "]", "=", "new_graph_state", "\n", "conc_ll", ",", "arc_ll", ",", "rel_ll", "=", "self", ".", "decoder", "(", "probe", ",", "snt_state", ",", "new_graph_state", ",", "snt_padding_mask", ",", "None", ",", "None", ",", "copy_seq", ",", "work", "=", "True", ")", "\n", "for", "i", "in", "range", "(", "offset", ")", ":", "\n", "            ", "name", "=", "'arc_ll%d'", "%", "i", "\n", "new_state_dict", "[", "name", "]", "=", "state_dict", "[", "name", "]", "\n", "name", "=", "'rel_ll%d'", "%", "i", "\n", "new_state_dict", "[", "name", "]", "=", "state_dict", "[", "name", "]", "\n", "", "name", "=", "'arc_ll%d'", "%", "offset", "\n", "new_state_dict", "[", "name", "]", "=", "arc_ll", "\n", "name", "=", "'rel_ll%d'", "%", "offset", "\n", "new_state_dict", "[", "name", "]", "=", "rel_ll", "\n", "pred_arc_prob", "=", "torch", ".", "exp", "(", "arc_ll", ")", "\n", "arc_confidence", "=", "torch", ".", "log", "(", "torch", ".", "max", "(", "pred_arc_prob", ",", "1", "-", "pred_arc_prob", ")", ")", "\n", "arc_confidence", "[", ":", ",", ":", ",", "0", "]", "=", "0.", "\n", "#pred_arc = torch.lt(pred_arc_prob, 0.5)", "\n", "#pred_arc[:,:,0] = 1", "\n", "#rel_confidence = rel_ll.masked_fill(pred_arc, 0.).sum(-1, keepdim=True)", "\n", "LL", "=", "conc_ll", "+", "arc_confidence", ".", "sum", "(", "-", "1", ",", "keepdim", "=", "True", ")", "# + rel_confidence", "\n", "\n", "\n", "def", "idx2token", "(", "idx", ",", "local_vocab", ")", ":", "\n", "            ", "if", "idx", "in", "local_vocab", ":", "\n", "                ", "return", "local_vocab", "[", "idx", "]", "\n", "", "return", "self", ".", "vocabs", "[", "'predictable_concept'", "]", ".", "idx2token", "(", "idx", ")", "\n", "\n", "", "topk_scores", ",", "topk_token", "=", "torch", ".", "topk", "(", "LL", ".", "squeeze", "(", "0", ")", ",", "topk", ",", "1", ")", "# bsz x k", "\n", "\n", "results", "=", "[", "]", "\n", "for", "s", ",", "t", ",", "local_vocab", "in", "zip", "(", "topk_scores", ".", "tolist", "(", ")", ",", "topk_token", ".", "tolist", "(", ")", ",", "local_vocabs", ")", ":", "\n", "            ", "res", "=", "[", "]", "\n", "for", "score", ",", "token", "in", "zip", "(", "s", ",", "t", ")", ":", "\n", "                ", "res", ".", "append", "(", "(", "idx2token", "(", "token", ",", "local_vocab", ")", ",", "score", ")", ")", "\n", "", "results", ".", "append", "(", "res", ")", "\n", "\n", "", "return", "new_state_dict", ",", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.parser.Parser.forward": [[168, 203], ["parser.Parser.concept_embed_layer_norm", "torch.dropout", "torch.dropout", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "parser.Parser.self_attn_mask", "enumerate", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.binary_cross_entropy", "torch.binary_cross_entropy", "graph_arc_loss.masked_fill_().sum.masked_fill_().sum.masked_fill_().sum", "probe.expand_as.expand_as.expand_as", "parser.Parser.decoder", "parser.Parser.encode_step_with_bert", "parser.Parser.encode_step", "parser.Parser.embed_positions", "data[].size", "layer", "parser.Parser.vocabs[].token2idx", "parser.Parser.vocabs[].token2idx", "torch.ne.float", "torch.ne.float", "torch.eq.size", "torch.eq.size", "torch.eq.float().sum", "torch.eq.float().sum", "concept_loss.mean", "arc_loss.mean", "rel_loss.mean", "graph_arc_loss.masked_fill_().sum.masked_fill_().sum.mean", "parser.Parser.concept_encoder", "graph_arc_loss.masked_fill_().sum.masked_fill_().sum.masked_fill_", "torch.eq.float", "torch.eq.float"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.modules.parser.Parser.encode_step_with_bert", "home.repos.pwc.inspect_result.chenllliang_atp.modules.parser.Parser.encode_step", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.token2idx", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.token2idx", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "forward", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "self", ".", "bert_encoder", "is", "not", "None", ":", "\n", "            ", "word_repr", ",", "word_mask", ",", "probe", "=", "self", ".", "encode_step_with_bert", "(", "data", "[", "'tok'", "]", ",", "data", "[", "'lem'", "]", ",", "\n", "data", "[", "'pos'", "]", ",", "data", "[", "'ner'", "]", ",", "data", "[", "'word_char'", "]", ",", "data", "[", "'bert_token'", "]", ",", "data", "[", "'token_subword_index'", "]", ")", "\n", "", "else", ":", "\n", "            ", "word_repr", ",", "word_mask", ",", "probe", "=", "self", ".", "encode_step", "(", "data", "[", "'tok'", "]", ",", "data", "[", "'lem'", "]", ",", "data", "[", "'pos'", "]", ",", "data", "[", "'ner'", "]", ",", "data", "[", "'word_char'", "]", ")", "\n", "", "concept_repr", "=", "self", ".", "embed_scale", "*", "self", ".", "concept_encoder", "(", "data", "[", "'concept_char_in'", "]", ",", "data", "[", "'concept_in'", "]", ")", "+", "self", ".", "embed_positions", "(", "data", "[", "'concept_in'", "]", ")", "\n", "concept_repr", "=", "self", ".", "concept_embed_layer_norm", "(", "concept_repr", ")", "\n", "concept_repr", "=", "F", ".", "dropout", "(", "concept_repr", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "concept_mask", "=", "torch", ".", "eq", "(", "data", "[", "'concept_in'", "]", ",", "self", ".", "vocabs", "[", "'concept'", "]", ".", "padding_idx", ")", "\n", "attn_mask", "=", "self", ".", "self_attn_mask", "(", "data", "[", "'concept_in'", "]", ".", "size", "(", "0", ")", ")", "\n", "for", "idx", ",", "layer", "in", "enumerate", "(", "self", ".", "graph_encoder", ".", "layers", ")", ":", "\n", "            ", "concept_repr", ",", "arc_weight", ",", "_", "=", "layer", "(", "concept_repr", ",", "\n", "self_padding_mask", "=", "concept_mask", ",", "self_attn_mask", "=", "attn_mask", ",", "\n", "external_memories", "=", "word_repr", ",", "external_padding_mask", "=", "word_mask", ",", "\n", "need_weights", "=", "'max'", ")", "\n", "\n", "", "graph_target_rel", "=", "data", "[", "'rel'", "]", "[", ":", "-", "1", "]", "\n", "graph_target_arc", "=", "torch", ".", "ne", "(", "graph_target_rel", ",", "self", ".", "vocabs", "[", "'rel'", "]", ".", "token2idx", "(", "NIL", ")", ")", "# 0 or 1", "\n", "graph_arc_mask", "=", "torch", ".", "eq", "(", "graph_target_rel", ",", "self", ".", "vocabs", "[", "'rel'", "]", ".", "token2idx", "(", "PAD", ")", ")", "\n", "graph_arc_loss", "=", "F", ".", "binary_cross_entropy", "(", "arc_weight", ",", "graph_target_arc", ".", "float", "(", ")", ",", "reduction", "=", "'none'", ")", "\n", "graph_arc_loss", "=", "graph_arc_loss", ".", "masked_fill_", "(", "graph_arc_mask", ",", "0.", ")", ".", "sum", "(", "(", "0", ",", "2", ")", ")", "\n", "\n", "probe", "=", "probe", ".", "expand_as", "(", "concept_repr", ")", "# tgt_len x bsz x embed_dim", "\n", "concept_loss", ",", "arc_loss", ",", "rel_loss", "=", "self", ".", "decoder", "(", "probe", ",", "word_repr", ",", "concept_repr", ",", "word_mask", ",", "concept_mask", ",", "attn_mask", ",", "data", "[", "'copy_seq'", "]", ",", "target", "=", "data", "[", "'concept_out'", "]", ",", "target_rel", "=", "data", "[", "'rel'", "]", "[", "1", ":", "]", ")", "\n", "\n", "concept_tot", "=", "concept_mask", ".", "size", "(", "0", ")", "-", "concept_mask", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "concept_loss", "=", "concept_loss", "/", "concept_tot", "\n", "arc_loss", "=", "arc_loss", "/", "concept_tot", "\n", "rel_loss", "=", "rel_loss", "/", "concept_tot", "\n", "graph_arc_loss", "=", "graph_arc_loss", "/", "concept_tot", "\n", "\n", "return", "concept_loss", ".", "mean", "(", ")", ",", "arc_loss", ".", "mean", "(", ")", ",", "rel_loss", ".", "mean", "(", ")", ",", "graph_arc_loss", ".", "mean", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.decoder.ArcGenerator.__init__": [[12, 21], ["torch.nn.Module.__init__", "transformer.MultiheadAttention", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "ArcGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "self", ".", "arc_layer", "=", "MultiheadAttention", "(", "embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", "=", "False", ")", "\n", "self", ".", "arc_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "ff_embed_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "ff_embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "ff_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.decoder.ArcGenerator.forward": [[22, 47], ["decoder.ArcGenerator.arc_layer", "torch.dropout", "torch.dropout", "decoder.ArcGenerator.arc_layer_norm", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "decoder.ArcGenerator.fc2", "torch.dropout", "torch.dropout", "decoder.ArcGenerator.ff_layer_norm", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.ge", "torch.ge", "torch.ge", "torch.ge", "torch.binary_cross_entropy", "torch.binary_cross_entropy", "arc_loss.masked_fill_().sum.masked_fill_().sum.masked_fill_().sum", "decoder.ArcGenerator.fc1", "torch.log", "torch.log", "torch.log", "torch.log", "decoder.ArcGenerator.vocabs[].token2idx", "decoder.ArcGenerator.vocabs[].token2idx", "print", "torch.ne.float", "torch.ne.float", "arc_loss.masked_fill_().sum.masked_fill_().sum.masked_fill_", "utils.compute_f_by_tensor"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.token2idx", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.token2idx", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.utils.compute_f_by_tensor"], ["", "def", "forward", "(", "self", ",", "outs", ",", "graph_state", ",", "graph_padding_mask", ",", "attn_mask", ",", "target_rel", "=", "None", ",", "work", "=", "False", ")", ":", "\n", "        ", "x", ",", "arc_weight", "=", "self", ".", "arc_layer", "(", "outs", ",", "graph_state", ",", "graph_state", ",", "\n", "key_padding_mask", "=", "graph_padding_mask", ",", "\n", "attn_mask", "=", "attn_mask", ",", "\n", "need_weights", "=", "'max'", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "arc_layer_norm", "(", "outs", "+", "x", ")", "\n", "residual", "=", "x", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "outs", "=", "self", ".", "ff_layer_norm", "(", "residual", "+", "x", ")", "\n", "\n", "if", "work", ":", "\n", "            ", "arc_ll", "=", "torch", ".", "log", "(", "arc_weight", "+", "1e-12", ")", "\n", "return", "arc_ll", ",", "outs", "\n", "", "target_arc", "=", "torch", ".", "ne", "(", "target_rel", ",", "self", ".", "vocabs", "[", "'rel'", "]", ".", "token2idx", "(", "NIL", ")", ")", "# 0 or 1", "\n", "arc_mask", "=", "torch", ".", "eq", "(", "target_rel", ",", "self", ".", "vocabs", "[", "'rel'", "]", ".", "token2idx", "(", "PAD", ")", ")", "\n", "pred", "=", "torch", ".", "ge", "(", "arc_weight", ",", "0.5", ")", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "print", "(", "'arc p %.3f r %.3f f %.3f'", "%", "compute_f_by_tensor", "(", "pred", ",", "target_arc", ",", "arc_mask", ")", ")", "\n", "", "arc_loss", "=", "F", ".", "binary_cross_entropy", "(", "arc_weight", ",", "target_arc", ".", "float", "(", ")", ",", "reduction", "=", "'none'", ")", "\n", "arc_loss", "=", "arc_loss", ".", "masked_fill_", "(", "arc_mask", ",", "0.", ")", ".", "sum", "(", "(", "0", ",", "2", ")", ")", "\n", "return", "arc_loss", ",", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.decoder.ConceptGenerator.__init__": [[50, 63], ["torch.nn.Module.__init__", "transformer.MultiheadAttention", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "decoder.ConceptGenerator.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "embed_dim", ",", "ff_embed_dim", ",", "conc_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "ConceptGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "alignment_layer", "=", "MultiheadAttention", "(", "embed_dim", ",", "1", ",", "dropout", ",", "weights_dropout", "=", "False", ")", "\n", "self", ".", "alignment_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "ff_embed_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "ff_embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "ff_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "transfer", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "conc_size", ")", "\n", "self", ".", "generator", "=", "nn", ".", "Linear", "(", "conc_size", ",", "vocabs", "[", "'predictable_concept'", "]", ".", "size", ")", "\n", "self", ".", "diverter", "=", "nn", ".", "Linear", "(", "conc_size", ",", "3", ")", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.decoder.ConceptGenerator.reset_parameters": [[64, 71], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "transfer", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "diverter", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "generator", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "diverter", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "transfer", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "generator", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.decoder.ConceptGenerator.forward": [[72, 123], ["decoder.ConceptGenerator.alignment_layer", "torch.dropout", "torch.dropout", "decoder.ConceptGenerator.alignment_layer_norm", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "decoder.ConceptGenerator.fc2", "torch.dropout", "torch.dropout", "decoder.ConceptGenerator.ff_layer_norm", "decoder.ConceptGenerator.size", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.dropout", "torch.dropout", "torch.softmax().chunk", "torch.softmax().chunk", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.size", "torch.cat.size", "copy_seq.transpose().contiguous().view().expand", "torch.cat.scatter_add_", "torch.cat.scatter_add_", "torch.log", "torch.log", "torch.log", "torch.log", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "concept_loss.masked_fill_().sum.masked_fill_().sum.masked_fill_().sum", "decoder.ConceptGenerator.fc1", "decoder.ConceptGenerator.transfer", "torch.softmax", "torch.softmax", "copy_seq.max().item", "torch.cat.new_zeros().expand", "torch.cat.new_zeros().expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max", "torch.max", "torch.max", "torch.max", "torch.ne", "torch.ne", "torch.ne", "torch.ne", "torch.eq().masked_select().float().sum().item", "torch.eq().masked_select().float().sum().item", "torch.eq().masked_select().float().sum().item", "torch.eq().masked_select().float().sum().item", "torch.ne.sum().item", "torch.ne.sum().item", "print", "torch.log.gather().squeeze", "torch.log.gather().squeeze", "torch.softmax", "torch.softmax", "decoder.ConceptGenerator.generator", "copy_seq.transpose().contiguous().view", "concept_loss.masked_fill_().sum.masked_fill_().sum.masked_fill_", "decoder.ConceptGenerator.diverter", "copy_seq.max", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "alignment_weight.unsqueeze", "torch.eq().masked_select().float().sum", "torch.eq().masked_select().float().sum", "torch.eq().masked_select().float().sum", "torch.eq().masked_select().float().sum", "torch.ne.sum", "torch.ne.sum", "torch.log.gather", "torch.log.gather", "copy_seq.transpose().contiguous", "torch.eq().masked_select().float", "torch.eq().masked_select().float", "torch.eq().masked_select().float", "torch.eq().masked_select().float", "target.unsqueeze", "copy_seq.transpose", "torch.eq().masked_select", "torch.eq().masked_select", "torch.eq().masked_select", "torch.eq().masked_select", "torch.eq", "torch.eq", "torch.eq", "torch.eq"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view"], ["", "def", "forward", "(", "self", ",", "outs", ",", "snt_state", ",", "snt_padding_mask", ",", "copy_seq", ",", "\n", "target", "=", "None", ",", "work", "=", "False", ")", ":", "\n", "        ", "x", ",", "alignment_weight", "=", "self", ".", "alignment_layer", "(", "outs", ",", "snt_state", ",", "snt_state", ",", "\n", "key_padding_mask", "=", "snt_padding_mask", ",", "need_weights", "=", "'one'", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "alignment_layer_norm", "(", "outs", "+", "x", ")", "\n", "residual", "=", "x", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "outs", "=", "self", ".", "ff_layer_norm", "(", "residual", "+", "x", ")", "\n", "\n", "seq_len", ",", "bsz", ",", "_", "=", "outs", ".", "size", "(", ")", "\n", "outs_concept", "=", "torch", ".", "tanh", "(", "self", ".", "transfer", "(", "outs", ")", ")", "\n", "outs_concept", "=", "F", ".", "dropout", "(", "outs_concept", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "gen_gate", ",", "map_gate", ",", "copy_gate", "=", "F", ".", "softmax", "(", "self", ".", "diverter", "(", "outs_concept", ")", ",", "-", "1", ")", ".", "chunk", "(", "3", ",", "dim", "=", "-", "1", ")", "\n", "copy_gate", "=", "torch", ".", "cat", "(", "[", "copy_gate", ",", "map_gate", "]", ",", "-", "1", ")", "\n", "\n", "probs", "=", "gen_gate", "*", "F", ".", "softmax", "(", "self", ".", "generator", "(", "outs_concept", ")", ",", "-", "1", ")", "\n", "\n", "tot_ext", "=", "1", "+", "copy_seq", ".", "max", "(", ")", ".", "item", "(", ")", "\n", "vocab_size", "=", "probs", ".", "size", "(", "-", "1", ")", "\n", "\n", "if", "tot_ext", "-", "vocab_size", ">", "0", ":", "\n", "            ", "ext_probs", "=", "probs", ".", "new_zeros", "(", "(", "1", ",", "1", ",", "tot_ext", "-", "vocab_size", ")", ")", ".", "expand", "(", "seq_len", ",", "bsz", ",", "-", "1", ")", "\n", "probs", "=", "torch", ".", "cat", "(", "[", "probs", ",", "ext_probs", "]", ",", "-", "1", ")", "\n", "#copy_seq: src_len x bsz x 2", "\n", "#copy_gate: tgt_len x bsz x 2", "\n", "#alignment_weight: tgt_len x bsz x src_len", "\n", "#index: tgt_len x bsz x (src_len x 2)", "\n", "", "index", "=", "copy_seq", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "1", ",", "bsz", ",", "-", "1", ")", ".", "expand", "(", "seq_len", ",", "-", "1", ",", "-", "1", ")", "\n", "copy_probs", "=", "(", "copy_gate", ".", "unsqueeze", "(", "2", ")", "*", "alignment_weight", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "view", "(", "seq_len", ",", "bsz", ",", "-", "1", ")", "\n", "probs", "=", "probs", ".", "scatter_add_", "(", "-", "1", ",", "index", ",", "copy_probs", ")", "\n", "ll", "=", "torch", ".", "log", "(", "probs", "+", "1e-12", ")", "\n", "\n", "if", "work", ":", "\n", "            ", "return", "ll", ",", "outs", "\n", "\n", "", "if", "not", "self", ".", "training", ":", "\n", "            ", "_", ",", "pred", "=", "torch", ".", "max", "(", "ll", ",", "-", "1", ")", "\n", "total_concepts", "=", "torch", ".", "ne", "(", "target", ",", "self", ".", "vocabs", "[", "'predictable_concept'", "]", ".", "padding_idx", ")", "\n", "acc", "=", "torch", ".", "eq", "(", "pred", ",", "target", ")", ".", "masked_select", "(", "total_concepts", ")", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "tot", "=", "total_concepts", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "print", "(", "'conc acc'", ",", "acc", "/", "tot", ")", "\n", "\n", "", "concept_loss", "=", "-", "ll", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "target", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "concept_mask", "=", "torch", ".", "eq", "(", "target", ",", "self", ".", "vocabs", "[", "'predictable_concept'", "]", ".", "padding_idx", ")", "\n", "concept_loss", "=", "concept_loss", ".", "masked_fill_", "(", "concept_mask", ",", "0.", ")", ".", "sum", "(", "0", ")", "\n", "return", "concept_loss", ",", "outs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.decoder.RelationGenerator.__init__": [[126, 135], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "decoder.RelationGenerator.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "embed_dim", ",", "rel_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "RelationGenerator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "self", ".", "transfer_head", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "rel_size", ")", "\n", "self", ".", "transfer_dep", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "rel_size", ")", "\n", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "rel_size", "+", "1", ",", "vocabs", "[", "'rel'", "]", ".", "size", "*", "(", "rel_size", "+", "1", ")", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.decoder.RelationGenerator.reset_parameters": [[136, 144], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "transfer_head", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "transfer_dep", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "proj", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "transfer_head", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "transfer_dep", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.decoder.RelationGenerator.forward": [[145, 191], ["get_scores().permute().contiguous", "outs.size", "graph_state.size", "torch.log_softmax", "torch.log_softmax", "torch.max", "torch.max", "torch.max", "torch.max", "torch.eq().float().masked_fill_().sum().item", "torch.eq().float().masked_fill_().sum().item", "torch.eq().float().masked_fill_().sum().item", "torch.eq().float().masked_fill_().sum().item", "utils.label_smoothed_nll_loss().view", "rel_loss.masked_fill_().sum.masked_fill_().sum.masked_fill_().sum", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "decoder.RelationGenerator.size", "head.permute.permute.size", "decoder.RelationGenerator.new_ones", "head.permute.permute.new_ones", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "decoder.RelationGenerator.proj().view().transpose().contiguous", "head.permute.permute.permute", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "rel_mask.numel", "rel_mask.float().sum().item", "print", "decoder.RelationGenerator.transfer_head", "decoder.RelationGenerator.transfer_dep", "get_scores().permute", "decoder.RelationGenerator.vocabs[].token2idx", "decoder.RelationGenerator.vocabs[].token2idx", "torch.eq().float().masked_fill_().sum", "torch.eq().float().masked_fill_().sum", "torch.eq().float().masked_fill_().sum", "torch.eq().float().masked_fill_().sum", "utils.label_smoothed_nll_loss", "rel_loss.masked_fill_().sum.masked_fill_().sum.masked_fill_", "decoder.RelationGenerator.proj().view().transpose", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "rel_mask.float().sum", "torch.log_softmax.view", "target_rel.view", "decoder.RelationGenerator.view", "decoder.RelationGenerator.forward.get_scores"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.token2idx", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.vocabs.Vocab.token2idx", "home.repos.pwc.inspect_result.chenllliang_atp.parse_gsii.utils.label_smoothed_nll_loss", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view"], ["", "def", "forward", "(", "self", ",", "outs", ",", "graph_state", ",", "target_rel", "=", "None", ",", "work", "=", "False", ")", ":", "\n", "\n", "        ", "def", "get_scores", "(", "dep", ",", "head", ")", ":", "\n", "            ", "head", "=", "torch", ".", "tanh", "(", "self", ".", "transfer_head", "(", "head", ")", ")", "\n", "dep", "=", "torch", ".", "tanh", "(", "self", ".", "transfer_dep", "(", "dep", ")", ")", "\n", "\n", "head", "=", "F", ".", "dropout", "(", "head", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "dep", "=", "F", ".", "dropout", "(", "dep", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "dep_num", ",", "bsz", ",", "_", "=", "dep", ".", "size", "(", ")", "\n", "head_num", "=", "head", ".", "size", "(", "0", ")", "\n", "\n", "bias_dep", "=", "dep", ".", "new_ones", "(", "(", "dep_num", ",", "bsz", ",", "1", ")", ")", "\n", "bias_head", "=", "head", ".", "new_ones", "(", "(", "head_num", ",", "bsz", ",", "1", ")", ")", "\n", "\n", "# seq_len x bsz x dim", "\n", "dep", "=", "torch", ".", "cat", "(", "[", "dep", ",", "bias_dep", "]", ",", "2", ")", "\n", "head", "=", "torch", ".", "cat", "(", "[", "head", ",", "bias_head", "]", ",", "2", ")", "\n", "\n", "#bsz x dep_num x vocab_size x dim", "\n", "dep", "=", "self", ".", "proj", "(", "dep", ")", ".", "view", "(", "dep_num", ",", "bsz", ",", "self", ".", "vocabs", "[", "'rel'", "]", ".", "size", ",", "-", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "#bsz x dim x head_num", "\n", "head", "=", "head", ".", "permute", "(", "1", ",", "2", ",", "0", ")", "\n", "\n", "#bsz x dep_num x vocab_size x head_num", "\n", "scores", "=", "torch", ".", "bmm", "(", "dep", ".", "view", "(", "bsz", ",", "dep_num", "*", "self", ".", "vocabs", "[", "'rel'", "]", ".", "size", ",", "-", "1", ")", ",", "head", ")", ".", "view", "(", "bsz", ",", "dep_num", ",", "self", ".", "vocabs", "[", "'rel'", "]", ".", "size", ",", "head_num", ")", "\n", "return", "scores", "\n", "\n", "", "scores", "=", "get_scores", "(", "outs", ",", "graph_state", ")", ".", "permute", "(", "1", ",", "0", ",", "3", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "dep_num", ",", "bsz", ",", "_", "=", "outs", ".", "size", "(", ")", "\n", "head_num", "=", "graph_state", ".", "size", "(", "0", ")", "\n", "log_probs", "=", "F", ".", "log_softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "\n", "_", ",", "rel", "=", "torch", ".", "max", "(", "log_probs", ",", "-", "1", ")", "\n", "if", "work", ":", "\n", "#dep_num x bsz x head x vocab", "\n", "            ", "return", "log_probs", "\n", "\n", "", "rel_mask", "=", "torch", ".", "eq", "(", "target_rel", ",", "self", ".", "vocabs", "[", "'rel'", "]", ".", "token2idx", "(", "NIL", ")", ")", "+", "torch", ".", "eq", "(", "target_rel", ",", "self", ".", "vocabs", "[", "'rel'", "]", ".", "token2idx", "(", "PAD", ")", ")", "\n", "rel_acc", "=", "(", "torch", ".", "eq", "(", "rel", ",", "target_rel", ")", ".", "float", "(", ")", ".", "masked_fill_", "(", "rel_mask", ",", "0.", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "rel_tot", "=", "rel_mask", ".", "numel", "(", ")", "-", "rel_mask", ".", "float", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "print", "(", "'rel acc %.3f'", "%", "(", "rel_acc", "/", "rel_tot", ")", ")", "\n", "", "rel_loss", "=", "label_smoothed_nll_loss", "(", "log_probs", ".", "view", "(", "-", "1", ",", "self", ".", "vocabs", "[", "'rel'", "]", ".", "size", ")", ",", "target_rel", ".", "view", "(", "-", "1", ")", ",", "0.", ")", ".", "view", "(", "dep_num", ",", "bsz", ",", "head_num", ")", "\n", "rel_loss", "=", "rel_loss", ".", "masked_fill_", "(", "rel_mask", ",", "0.", ")", ".", "sum", "(", "(", "0", ",", "2", ")", ")", "\n", "return", "rel_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.decoder.DecodeLayer.__init__": [[194, 202], ["torch.nn.Module.__init__", "decoder.ArcGenerator", "decoder.ConceptGenerator", "decoder.RelationGenerator"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocabs", ",", "inference_layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "conc_size", ",", "rel_size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "DecodeLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inference_layers", "=", "inference_layers", "\n", "self", ".", "arc_generator", "=", "ArcGenerator", "(", "vocabs", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ")", "\n", "self", ".", "concept_generator", "=", "ConceptGenerator", "(", "vocabs", ",", "embed_dim", ",", "ff_embed_dim", ",", "conc_size", ",", "dropout", ")", "\n", "self", ".", "relation_generator", "=", "RelationGenerator", "(", "vocabs", ",", "embed_dim", ",", "rel_size", ",", "dropout", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "vocabs", "=", "vocabs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.decoder.DecodeLayer.forward": [[203, 227], ["torch.dropout", "torch.dropout", "range", "decoder.DecodeLayer.relation_generator", "range", "decoder.DecodeLayer.relation_generator", "decoder.DecodeLayer.arc_generator", "decoder.DecodeLayer.concept_generator", "arc_losses.append", "concept_losses.append", "decoder.DecodeLayer.arc_generator", "decoder.DecodeLayer.concept_generator"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "probe", ",", "snt_state", ",", "graph_state", ",", "snt_padding_mask", ",", "graph_padding_mask", ",", "\n", "attn_mask", ",", "copy_seq", ",", "target", "=", "None", ",", "target_rel", "=", "None", ",", "work", "=", "False", ")", ":", "\n", "# probe: tgt_len x bsz x embed_dim", "\n", "# snt_state, graph_state: seq_len x bsz x embed_dim", "\n", "        ", "outs", "=", "F", ".", "dropout", "(", "probe", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "if", "work", ":", "\n", "            ", "for", "i", "in", "range", "(", "self", ".", "inference_layers", ")", ":", "\n", "                ", "arc_ll", ",", "outs", "=", "self", ".", "arc_generator", "(", "outs", ",", "graph_state", ",", "graph_padding_mask", ",", "attn_mask", ",", "work", "=", "True", ")", "\n", "concept_ll", ",", "outs", "=", "self", ".", "concept_generator", "(", "outs", ",", "snt_state", ",", "snt_padding_mask", ",", "copy_seq", ",", "work", "=", "True", ")", "\n", "", "rel_ll", "=", "self", ".", "relation_generator", "(", "outs", ",", "graph_state", ",", "work", "=", "True", ")", "\n", "return", "concept_ll", ",", "arc_ll", ",", "rel_ll", "\n", "\n", "\n", "", "arc_losses", ",", "concept_losses", ",", "rel_losses", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "inference_layers", ")", ":", "\n", "            ", "arc_loss", ",", "outs", "=", "self", ".", "arc_generator", "(", "outs", ",", "graph_state", ",", "graph_padding_mask", ",", "attn_mask", ",", "target_rel", "=", "target_rel", ",", "work", "=", "False", ")", "\n", "concept_loss", ",", "outs", "=", "self", ".", "concept_generator", "(", "outs", ",", "snt_state", ",", "snt_padding_mask", ",", "copy_seq", ",", "target", "=", "target", ",", "work", "=", "False", ")", "\n", "arc_losses", ".", "append", "(", "arc_loss", ")", "\n", "concept_losses", ".", "append", "(", "concept_loss", ")", "\n", "", "rel_loss", "=", "self", ".", "relation_generator", "(", "outs", ",", "graph_state", ",", "target_rel", "=", "target_rel", ",", "work", "=", "False", ")", "\n", "arc_loss", "=", "arc_losses", "[", "-", "1", "]", "#torch.stack(arc_losses).mean(0)", "\n", "concept_loss", "=", "concept_losses", "[", "-", "1", "]", "#torch.stack(concept_losses).mean(0)", "\n", "return", "concept_loss", ",", "arc_loss", ",", "rel_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.TiedTransformer.__init__": [[9, 13], ["torch.nn.Module.__init__", "transformer.TransformerLayer"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", "=", "False", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "TiedTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer", "=", "TransformerLayer", "(", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", ",", "weights_dropout", ")", "\n", "self", ".", "layers", "=", "layers", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.TiedTransformer.forward": [[14, 20], ["range", "transformer.TiedTransformer.layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ",", "\n", "external_memories", "=", "None", ",", "external_padding_mask", "=", "None", ")", ":", "\n", "        ", "for", "idx", "in", "range", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", ",", "_", ",", "_", "=", "self", ".", "layer", "(", "x", ",", "kv", ",", "self_padding_mask", ",", "self_attn_mask", ",", "external_memories", ",", "external_padding_mask", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.Transformer.__init__": [[23, 28], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "transformer.Transformer.layers.append", "transformer.TransformerLayer"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", "=", "False", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "Transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "_", "in", "range", "(", "layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "TransformerLayer", "(", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", ",", "weights_dropout", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.Transformer.forward": [[29, 35], ["enumerate", "layer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ",", "\n", "external_memories", "=", "None", ",", "external_padding_mask", "=", "None", ")", ":", "\n", "        ", "for", "idx", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", ",", "_", ",", "_", "=", "layer", "(", "x", ",", "kv", ",", "self_padding_mask", ",", "self_attn_mask", ",", "external_memories", ",", "external_padding_mask", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.TransformerLayer.__init__": [[38, 51], ["torch.nn.Module.__init__", "transformer.MultiheadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "transformer.TransformerLayer.reset_parameters", "transformer.MultiheadAttention", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "ff_embed_dim", ",", "num_heads", ",", "dropout", ",", "with_external", "=", "False", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "TransformerLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "MultiheadAttention", "(", "embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "ff_embed_dim", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "ff_embed_dim", ",", "embed_dim", ")", "\n", "self", ".", "attn_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "ff_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "self", ".", "with_external", "=", "with_external", "\n", "self", ".", "dropout", "=", "dropout", "\n", "if", "self", ".", "with_external", ":", "\n", "            ", "self", ".", "external_attn", "=", "MultiheadAttention", "(", "embed_dim", ",", "num_heads", ",", "dropout", ",", "weights_dropout", ")", "\n", "self", ".", "external_layer_norm", "=", "nn", ".", "LayerNorm", "(", "embed_dim", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.TransformerLayer.reset_parameters": [[52, 57], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "fc1", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "fc2", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fc1", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "fc2", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.TransformerLayer.forward": [[58, 90], ["torch.dropout", "torch.dropout", "transformer.TransformerLayer.attn_layer_norm", "torch.relu", "torch.relu", "torch.dropout", "torch.dropout", "transformer.TransformerLayer.fc2", "torch.dropout", "torch.dropout", "transformer.TransformerLayer.ff_layer_norm", "transformer.TransformerLayer.self_attn", "transformer.TransformerLayer.self_attn", "transformer.TransformerLayer.external_attn", "torch.dropout", "torch.dropout", "transformer.TransformerLayer.external_layer_norm", "transformer.TransformerLayer.fc1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "kv", "=", "None", ",", "\n", "self_padding_mask", "=", "None", ",", "self_attn_mask", "=", "None", ",", "\n", "external_memories", "=", "None", ",", "external_padding_mask", "=", "None", ",", "\n", "need_weights", "=", "None", ")", ":", "\n", "# x: seq_len x bsz x embed_dim", "\n", "        ", "residual", "=", "x", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "x", ",", "self_attn", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "key_padding_mask", "=", "self_padding_mask", ",", "\n", "attn_mask", "=", "self_attn_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "", "else", ":", "\n", "            ", "x", ",", "self_attn", "=", "self", ".", "self_attn", "(", "query", "=", "x", ",", "key", "=", "kv", ",", "value", "=", "kv", ",", "key_padding_mask", "=", "self_padding_mask", ",", "\n", "attn_mask", "=", "self_attn_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "\n", "", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "attn_layer_norm", "(", "residual", "+", "x", ")", "\n", "\n", "if", "self", ".", "with_external", ":", "\n", "            ", "residual", "=", "x", "\n", "x", ",", "external_attn", "=", "self", ".", "external_attn", "(", "query", "=", "x", ",", "key", "=", "external_memories", ",", "value", "=", "external_memories", ",", "\n", "key_padding_mask", "=", "external_padding_mask", ",", "need_weights", "=", "need_weights", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "external_layer_norm", "(", "residual", "+", "x", ")", "\n", "", "else", ":", "\n", "            ", "external_attn", "=", "None", "\n", "\n", "", "residual", "=", "x", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "ff_layer_norm", "(", "residual", "+", "x", ")", "\n", "return", "x", ",", "self_attn", ",", "external_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention.__init__": [[93, 108], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Linear", "torch.nn.Linear", "transformer.MultiheadAttention.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.LearnedPositionalEmbedding.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "embed_dim", ",", "num_heads", ",", "dropout", "=", "0.", ",", "weights_dropout", "=", "True", ")", ":", "\n", "        ", "super", "(", "MultiheadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_dim", "=", "embed_dim", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "head_dim", "=", "embed_dim", "//", "num_heads", "\n", "assert", "self", ".", "head_dim", "*", "num_heads", "==", "self", ".", "embed_dim", ",", "\"embed_dim must be divisible by num_heads\"", "\n", "self", ".", "scaling", "=", "self", ".", "head_dim", "**", "-", "0.5", "\n", "\n", "self", ".", "in_proj_weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ",", "embed_dim", ")", ")", "\n", "self", ".", "in_proj_bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "3", "*", "embed_dim", ")", ")", "\n", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "embed_dim", ",", "embed_dim", ",", "bias", "=", "True", ")", "\n", "self", ".", "weights_dropout", "=", "weights_dropout", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention.reset_parameters": [[109, 114], ["torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "normal_", "(", "self", ".", "in_proj_weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "out_proj", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "in_proj_bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "out_proj", ".", "bias", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention.forward": [[115, 195], ["query.size", "transformer.MultiheadAttention.contiguous().view().transpose", "transformer.MultiheadAttention.contiguous().view().transpose", "transformer.MultiheadAttention.contiguous().view().transpose", "transformer.MultiheadAttention.size", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.dropout.transpose().contiguous().view", "transformer.MultiheadAttention.out_proj", "query.data_ptr", "key.data_ptr", "value.data_ptr", "key.data_ptr", "value.data_ptr", "key.size", "value.size", "transformer.MultiheadAttention.in_proj_qkv", "transformer.MultiheadAttention.transpose", "list", "attn_weights.transpose.transpose.masked_fill_", "attn_weights.transpose.transpose.view", "attn_weights.transpose.transpose.masked_fill_", "attn_weights.transpose.transpose.view", "torch.dropout", "torch.dropout", "torch.dropout", "torch.dropout", "list", "attn_weights.transpose.transpose.view", "attn_weights.transpose.transpose.transpose", "transformer.MultiheadAttention.in_proj_q", "transformer.MultiheadAttention.in_proj_kv", "transformer.MultiheadAttention.in_proj_q", "transformer.MultiheadAttention.in_proj_k", "transformer.MultiheadAttention.in_proj_v", "transformer.MultiheadAttention.contiguous().view", "transformer.MultiheadAttention.contiguous().view", "transformer.MultiheadAttention.contiguous().view", "attn_weights.transpose.transpose.size", "attn_mask.unsqueeze", "float", "key_padding_mask.transpose().unsqueeze().unsqueeze", "float", "torch.dropout.size", "torch.dropout.transpose().contiguous", "attn_weights.transpose.transpose.max", "transformer.MultiheadAttention.contiguous", "transformer.MultiheadAttention.contiguous", "transformer.MultiheadAttention.contiguous", "key_padding_mask.transpose().unsqueeze", "torch.dropout.transpose", "key_padding_mask.transpose"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention.in_proj_qkv", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention.in_proj_kv", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention.in_proj_q", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention.in_proj_k", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention.in_proj_v", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "key_padding_mask", "=", "None", ",", "attn_mask", "=", "None", ",", "need_weights", "=", "None", ")", ":", "\n", "        ", "\"\"\" Input shape: Time x Batch x Channel\n            key_padding_mask: Time x batch\n            attn_mask:  tgt_len x src_len\n        \"\"\"", "\n", "qkv_same", "=", "query", ".", "data_ptr", "(", ")", "==", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "kv_same", "=", "key", ".", "data_ptr", "(", ")", "==", "value", ".", "data_ptr", "(", ")", "\n", "\n", "tgt_len", ",", "bsz", ",", "embed_dim", "=", "query", ".", "size", "(", ")", "\n", "assert", "key", ".", "size", "(", ")", "==", "value", ".", "size", "(", ")", "\n", "\n", "if", "qkv_same", ":", "\n", "# self-attention", "\n", "            ", "q", ",", "k", ",", "v", "=", "self", ".", "in_proj_qkv", "(", "query", ")", "\n", "", "elif", "kv_same", ":", "\n", "# encoder-decoder attention", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", ",", "v", "=", "self", ".", "in_proj_kv", "(", "key", ")", "\n", "", "else", ":", "\n", "            ", "q", "=", "self", ".", "in_proj_q", "(", "query", ")", "\n", "k", "=", "self", ".", "in_proj_k", "(", "key", ")", "\n", "v", "=", "self", ".", "in_proj_v", "(", "value", ")", "\n", "", "q", "*=", "self", ".", "scaling", "\n", "\n", "\n", "q", "=", "q", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "k", "=", "k", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "v", "=", "v", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "bsz", "*", "self", ".", "num_heads", ",", "self", ".", "head_dim", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "\n", "src_len", "=", "k", ".", "size", "(", "1", ")", "\n", "# k,v: bsz*heads x src_len x dim", "\n", "# q: bsz*heads x tgt_len x dim", "\n", "\n", "attn_weights", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "assert", "list", "(", "attn_weights", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", "]", "\n", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_weights", ".", "masked_fill_", "(", "\n", "attn_mask", ".", "unsqueeze", "(", "0", ")", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", "\n", "\n", "", "if", "key_padding_mask", "is", "not", "None", ":", "\n", "# don't attend to padding symbols", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "attn_weights", ".", "masked_fill_", "(", "\n", "key_padding_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", ",", "\n", "float", "(", "'-inf'", ")", "\n", ")", "\n", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "\n", "\n", "", "attn_weights", "=", "F", ".", "softmax", "(", "attn_weights", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "self", ".", "weights_dropout", ":", "\n", "            ", "attn_weights", "=", "F", ".", "dropout", "(", "attn_weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "attn", "=", "torch", ".", "bmm", "(", "attn_weights", ",", "v", ")", "\n", "if", "not", "self", ".", "weights_dropout", ":", "\n", "            ", "attn", "=", "F", ".", "dropout", "(", "attn", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "assert", "list", "(", "attn", ".", "size", "(", ")", ")", "==", "[", "bsz", "*", "self", ".", "num_heads", ",", "tgt_len", ",", "self", ".", "head_dim", "]", "\n", "\n", "attn", "=", "attn", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "tgt_len", ",", "bsz", ",", "embed_dim", ")", "\n", "attn", "=", "self", ".", "out_proj", "(", "attn", ")", "\n", "\n", "if", "need_weights", ":", "\n", "# maximum attention weight over heads", "\n", "            ", "attn_weights", "=", "attn_weights", ".", "view", "(", "bsz", ",", "self", ".", "num_heads", ",", "tgt_len", ",", "src_len", ")", "\n", "if", "need_weights", "==", "'max'", ":", "\n", "                ", "attn_weights", ",", "_", "=", "attn_weights", ".", "max", "(", "dim", "=", "1", ")", "\n", "", "elif", "need_weights", "==", "\"one\"", ":", "\n", "                ", "attn_weights", "=", "attn_weights", "[", ":", ",", "0", ",", ":", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "assert", "False", ",", "\"need weights?\"", "\n", "", "attn_weights", "=", "attn_weights", ".", "transpose", "(", "0", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "attn_weights", "=", "None", "\n", "\n", "", "return", "attn", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention.in_proj_qkv": [[196, 203], ["transformer.MultiheadAttention._in_proj().unsafe_chunk", "transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_qkv", "(", "self", ",", "query", ")", ":", "\n", "#return self._in_proj(query).chunk(3, dim=-1)   # original code", "\n", "# Note: As of torch 1.7 this line is failing with...  RuntimeError: one of the variables needed for", "\n", "# gradient computation has been modified by an inplace operation: [torch.cuda.FloatTensor [24, 129, 1536]]", "\n", "# See release notes for v1.7 (torch.chunk) for an explanation.  A temporary fix is to use unsafe_chunk instead.", "\n", "# See https://discuss.pytorch.org/t/runtimeerror-for-chunk-inplace-operation-new-with-torch-1-7/105334", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ")", ".", "unsafe_chunk", "(", "3", ",", "dim", "=", "-", "1", ")", "\n", "# Possible solution...", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention.in_proj_kv": [[208, 210], ["transformer.MultiheadAttention._in_proj().chunk", "transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_kv", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ")", ".", "chunk", "(", "2", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention.in_proj_q": [[211, 213], ["transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_q", "(", "self", ",", "query", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "query", ",", "end", "=", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention.in_proj_k": [[214, 216], ["transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_k", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "key", ",", "start", "=", "self", ".", "embed_dim", ",", "end", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention.in_proj_v": [[217, 219], ["transformer.MultiheadAttention._in_proj"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention._in_proj"], ["", "def", "in_proj_v", "(", "self", ",", "value", ")", ":", "\n", "        ", "return", "self", ".", "_in_proj", "(", "value", ",", "start", "=", "2", "*", "self", ".", "embed_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.MultiheadAttention._in_proj": [[220, 227], ["torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "_in_proj", "(", "self", ",", "input", ",", "start", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "weight", "=", "self", ".", "in_proj_weight", "\n", "bias", "=", "self", ".", "in_proj_bias", "\n", "weight", "=", "weight", "[", "start", ":", "end", ",", ":", "]", "\n", "if", "bias", "is", "not", "None", ":", "\n", "            ", "bias", "=", "bias", "[", "start", ":", "end", "]", "\n", "", "return", "F", ".", "linear", "(", "input", ",", "weight", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.SelfAttentionMask.__init__": [[237, 241], ["torch.nn.Module.__init__", "transformer.SelfAttentionMask.get_mask"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.SelfAttentionMask.get_mask"], ["    ", "def", "__init__", "(", "self", ",", "init_size", "=", "100", ",", "device", "=", "0", ")", ":", "\n", "        ", "super", "(", "SelfAttentionMask", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weights", "=", "SelfAttentionMask", ".", "get_mask", "(", "init_size", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.SelfAttentionMask.get_mask": [[242, 246], ["torch.ones().triu_().bool", "torch.ones().triu_().bool", "torch.ones().triu_().bool", "torch.ones().triu_().bool", "torch.ones().triu_", "torch.ones().triu_", "torch.ones().triu_", "torch.ones().triu_", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_mask", "(", "size", ")", ":", "\n", "        ", "weights", "=", "torch", ".", "ones", "(", "(", "size", ",", "size", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ".", "triu_", "(", "1", ")", ".", "bool", "(", ")", "\n", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.SelfAttentionMask.forward": [[247, 252], ["transformer.SelfAttentionMask.weights[].to().detach", "transformer.SelfAttentionMask.get_mask", "transformer.SelfAttentionMask.weights.size", "transformer.SelfAttentionMask.weights[].to"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.SelfAttentionMask.get_mask", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "forward", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "self", ".", "weights", "is", "None", "or", "size", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "            ", "self", ".", "weights", "=", "SelfAttentionMask", ".", "get_mask", "(", "size", ")", "\n", "", "res", "=", "self", ".", "weights", "[", ":", "size", ",", ":", "size", "]", ".", "to", "(", "self", ".", "device", ")", ".", "detach", "(", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.LearnedPositionalEmbedding.__init__": [[257, 262], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "transformer.LearnedPositionalEmbedding.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.Embedding", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.Embedding", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.LearnedPositionalEmbedding.reset_parameters"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "init_size", "=", "512", ",", "device", "=", "0", ")", ":", "\n", "        ", "super", "(", "LearnedPositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weights", "=", "nn", ".", "Embedding", "(", "init_size", ",", "embedding_dim", ")", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.LearnedPositionalEmbedding.reset_parameters": [[263, 265], ["torch.nn.init.constant_", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "self", ".", "weights", ".", "weight", ",", "0.", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.LearnedPositionalEmbedding.forward": [[266, 272], ["input.size", "transformer.LearnedPositionalEmbedding.weights().unsqueeze", "transformer.LearnedPositionalEmbedding.weights", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "offset", "=", "0", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [seq_len x bsz].\"\"\"", "\n", "seq_len", ",", "bsz", "=", "input", ".", "size", "(", ")", "\n", "positions", "=", "(", "offset", "+", "torch", ".", "arange", "(", "seq_len", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "res", "=", "self", ".", "weights", "(", "positions", ")", ".", "unsqueeze", "(", "1", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.SinusoidalPositionalEmbedding.__init__": [[277, 285], ["torch.nn.Module.__init__", "transformer.SinusoidalPositionalEmbedding.get_embedding"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.SinusoidalPositionalEmbedding.get_embedding"], ["def", "__init__", "(", "self", ",", "embedding_dim", ",", "init_size", "=", "512", ",", "device", "=", "0", ")", ":", "\n", "        ", "super", "(", "SinusoidalPositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "init_size", ",", "\n", "embedding_dim", "\n", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.SinusoidalPositionalEmbedding.get_embedding": [[286, 301], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "math.log", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_plot.AMRPlot.view"], ["", "@", "staticmethod", "\n", "def", "get_embedding", "(", "num_embeddings", ",", "embedding_dim", ")", ":", "\n", "        ", "\"\"\"Build sinusoidal embeddings.\n        This matches the implementation in tensor2tensor, but differs slightly\n        from the description in Section 3.5 of \"Attention Is All You Need\".\n        \"\"\"", "\n", "half_dim", "=", "embedding_dim", "//", "2", "\n", "emb", "=", "math", ".", "log", "(", "10000", ")", "/", "(", "half_dim", "-", "1", ")", "\n", "emb", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "half_dim", ",", "dtype", "=", "torch", ".", "float", ")", "*", "-", "emb", ")", "\n", "emb", "=", "torch", ".", "arange", "(", "num_embeddings", ",", "dtype", "=", "torch", ".", "float", ")", ".", "unsqueeze", "(", "1", ")", "*", "emb", ".", "unsqueeze", "(", "0", ")", "\n", "emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "emb", ")", ",", "torch", ".", "cos", "(", "emb", ")", "]", ",", "dim", "=", "1", ")", ".", "view", "(", "num_embeddings", ",", "-", "1", ")", "\n", "if", "embedding_dim", "%", "2", "==", "1", ":", "\n", "# zero pad", "\n", "            ", "emb", "=", "torch", ".", "cat", "(", "[", "emb", ",", "torch", ".", "zeros", "(", "num_embeddings", ",", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.SinusoidalPositionalEmbedding.forward": [[302, 314], ["input.size", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().to().detach", "transformer.SinusoidalPositionalEmbedding.get_embedding", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "transformer.SinusoidalPositionalEmbedding.weights.size", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze().to", "transformer.SinusoidalPositionalEmbedding.weights.index_select().unsqueeze", "transformer.SinusoidalPositionalEmbedding.weights.index_select"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size", "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.SinusoidalPositionalEmbedding.get_embedding", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["", "def", "forward", "(", "self", ",", "input", ",", "offset", "=", "0", ")", ":", "\n", "        ", "\"\"\"Input is expected to be of size [seq_len x bsz].\"\"\"", "\n", "seq_len", ",", "bsz", "=", "input", ".", "size", "(", ")", "\n", "mx_position", "=", "seq_len", "+", "offset", "\n", "if", "self", ".", "weights", "is", "None", "or", "mx_position", ">", "self", ".", "weights", ".", "size", "(", "0", ")", ":", "\n", "# recompute/expand embeddings if needed", "\n", "            ", "self", ".", "weights", "=", "SinusoidalPositionalEmbedding", ".", "get_embedding", "(", "\n", "mx_position", ",", "self", ".", "embedding_dim", ")", "\n", "\n", "", "positions", "=", "offset", "+", "torch", ".", "arange", "(", "seq_len", ")", "\n", "res", "=", "self", ".", "weights", ".", "index_select", "(", "0", ",", "positions", ")", ".", "unsqueeze", "(", "1", ")", ".", "to", "(", "self", ".", "device", ")", ".", "detach", "(", ")", "\n", "return", "res", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.Embedding": [[229, 234], ["torch.nn.Embedding", "torch.nn.init.normal_", "torch.nn.init.constant_"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.modules.transformer.Embedding"], ["", "", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "std", "=", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", "[", "padding_idx", "]", ",", "0", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.ATP.generate_amrized_srl.SRL.__init__": [[7, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "snt", "=", "None", "\n", "self", ".", "semantic_roles", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.ATP.generate_amrized_srl.SRL.__str__": [[11, 13], ["str", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "return", "str", "(", "self", ".", "snt", ")", "+", "\"\\n\"", "+", "str", "(", "self", ".", "semantic_roles", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.ATP.generate_amrized_srl.SRL.get_word_sense": [[14, 16], ["None"], "methods", ["None"], ["", "def", "get_word_sense", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.ATP.generate_amrized_srl.SRL.isolated_srl_triples_amrization": [[17, 96], ["penman.graph.Graph", "penman.codec.PENMANCodec", "penman.codec.PENMANCodec.encode", "triples.append", "enumerate", "triples.append", "enumerate", "triples.append", "enumerate", "re.sub", "re.sub", "str", "range", "triples.append", "sorted", "triples.append", "triples.append", "sorted", "triples.append", "triples.append", "sorted", "triples.append", "triples.append", "triples.append", "triples.append", "triples.append", "triples.append", "triples.append", "t.keys", "str", "list", "t.keys", "str", "list", "t.keys", "list", "list", "i.keys", "list", "i.keys", "list", "i.keys", "x.keys", "list", "list", "x.keys", "list", "list", "x.keys", "list", "list", "i.values", "i.keys", "i.values", "i.keys", "i.values", "i.keys"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode"], ["", "def", "isolated_srl_triples_amrization", "(", "self", ",", "splitby", "=", "\"and\"", ",", "remove_alignment", "=", "True", ",", "remove_empty_relation", "=", "True", ")", ":", "\n", "# use \"and\" and \"op\" to connect the srls to a graph, no other process ", "\n", "# the top concept can be \"and\" , \"multi-sentence\" , or \"None\"", "\n", "        ", "penman_graph", "=", "Graph", "(", ")", "\n", "triples", "=", "[", "]", "\n", "\n", "instance_id", "=", "[", "\"a\"", "+", "str", "(", "i", ")", "for", "i", "in", "range", "(", "1000", ")", "]", "\n", "\n", "index", "=", "0", "\n", "\n", "\n", "\n", "if", "splitby", "==", "\"and\"", ":", "\n", "            ", "triples", ".", "append", "(", "(", "instance_id", "[", "index", "]", ",", "':instance'", ",", "'and'", ")", ")", "\n", "index", "+=", "1", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "self", ".", "semantic_roles", ")", ":", "\n", "                ", "predicate", "=", "[", "t", "[", "'V'", "]", "for", "t", "in", "j", "if", "\"V\"", "in", "t", ".", "keys", "(", ")", "]", "\n", "try", ":", "\n", "                    ", "triples", ".", "append", "(", "(", "instance_id", "[", "index", "]", ",", "':instance'", ",", "predicate", "[", "0", "]", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "continue", "\n", "", "triples", ".", "append", "(", "(", "instance_id", "[", "0", "]", ",", "':op'", "+", "str", "(", "i", "+", "1", ")", ",", "instance_id", "[", "index", "]", ")", ")", "\n", "predicate_index", "=", "0", "+", "index", "\n", "index", "+=", "1", "\n", "args", "=", "sorted", "(", "j", ",", "key", "=", "lambda", "x", ":", "list", "(", "x", ".", "keys", "(", ")", ")", "[", "0", "]", ")", "\n", "for", "i", "in", "args", ":", "\n", "                    ", "if", "list", "(", "i", ".", "keys", "(", ")", ")", "[", "0", "]", "!=", "\"V\"", ":", "\n", "                        ", "triples", ".", "append", "(", "(", "instance_id", "[", "index", "]", ",", "':instance'", ",", "list", "(", "i", ".", "values", "(", ")", ")", "[", "0", "]", ")", ")", "\n", "triples", ".", "append", "(", "(", "instance_id", "[", "predicate_index", "]", ",", "list", "(", "i", ".", "keys", "(", ")", ")", "[", "0", "]", ",", "instance_id", "[", "index", "]", ")", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "", "", "if", "splitby", "==", "\"multi-sentence\"", ":", "\n", "            ", "triples", ".", "append", "(", "(", "instance_id", "[", "index", "]", ",", "':instance'", ",", "'multi-sentence'", ")", ")", "\n", "index", "+=", "1", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "self", ".", "semantic_roles", ")", ":", "\n", "                ", "predicate", "=", "[", "t", "[", "'V'", "]", "for", "t", "in", "j", "if", "\"V\"", "in", "t", ".", "keys", "(", ")", "]", "\n", "triples", ".", "append", "(", "(", "instance_id", "[", "index", "]", ",", "':instance'", ",", "predicate", "[", "0", "]", ")", ")", "\n", "triples", ".", "append", "(", "(", "instance_id", "[", "0", "]", ",", "':snt'", "+", "str", "(", "i", "+", "1", ")", ",", "instance_id", "[", "index", "]", ")", ")", "\n", "predicate_index", "=", "0", "+", "index", "\n", "index", "+=", "1", "\n", "args", "=", "sorted", "(", "j", ",", "key", "=", "lambda", "x", ":", "list", "(", "x", ".", "keys", "(", ")", ")", "[", "0", "]", ")", "\n", "for", "i", "in", "args", ":", "\n", "                    ", "if", "list", "(", "i", ".", "keys", "(", ")", ")", "[", "0", "]", "!=", "\"V\"", ":", "\n", "                        ", "triples", ".", "append", "(", "(", "instance_id", "[", "index", "]", ",", "':instance'", ",", "list", "(", "i", ".", "values", "(", ")", ")", "[", "0", "]", ")", ")", "\n", "triples", ".", "append", "(", "(", "instance_id", "[", "predicate_index", "]", ",", "list", "(", "i", ".", "keys", "(", ")", ")", "[", "0", "]", ",", "instance_id", "[", "index", "]", ")", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "", "", "if", "splitby", "==", "\"None\"", ":", "\n", "            ", "instance_id", "[", "0", "]", "=", "' '", "\n", "triples", ".", "append", "(", "(", "instance_id", "[", "index", "]", ",", "':instance'", ",", "''", ")", ")", "\n", "index", "+=", "1", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "self", ".", "semantic_roles", ")", ":", "\n", "                ", "predicate", "=", "[", "t", "[", "'V'", "]", "for", "t", "in", "j", "if", "\"V\"", "in", "t", ".", "keys", "(", ")", "]", "\n", "triples", ".", "append", "(", "(", "instance_id", "[", "index", "]", ",", "':instance'", ",", "predicate", "[", "0", "]", ")", ")", "\n", "triples", ".", "append", "(", "(", "instance_id", "[", "0", "]", ",", "''", ",", "instance_id", "[", "index", "]", ")", ")", "\n", "predicate_index", "=", "0", "+", "index", "\n", "index", "+=", "1", "\n", "args", "=", "sorted", "(", "j", ",", "key", "=", "lambda", "x", ":", "list", "(", "x", ".", "keys", "(", ")", ")", "[", "0", "]", ")", "\n", "for", "i", "in", "args", ":", "\n", "                    ", "if", "list", "(", "i", ".", "keys", "(", ")", ")", "[", "0", "]", "!=", "\"V\"", ":", "\n", "                        ", "triples", ".", "append", "(", "(", "instance_id", "[", "index", "]", ",", "':instance'", ",", "list", "(", "i", ".", "values", "(", ")", ")", "[", "0", "]", ")", ")", "\n", "triples", ".", "append", "(", "(", "instance_id", "[", "predicate_index", "]", ",", "list", "(", "i", ".", "keys", "(", ")", ")", "[", "0", "]", ",", "instance_id", "[", "index", "]", ")", ")", "\n", "index", "+=", "1", "\n", "\n", "\n", "\n", "", "", "", "", "penman_graph", ".", "triples", "=", "triples", "\n", "\n", "\n", "penman_graph", ".", "metadata", "=", "{", "'snt'", ":", "\" \"", ".", "join", "(", "self", ".", "snt", ")", "}", "\n", "codec", "=", "PENMANCodec", "(", ")", "\n", "ret", "=", "codec", ".", "encode", "(", "penman_graph", ",", "compact", "=", "True", ")", "\n", "\n", "if", "remove_alignment", "==", "True", ":", "\n", "            ", "ret", "=", "re", ".", "sub", "(", "\"@@\\d*\"", ",", "\"\"", ",", "ret", ")", "\n", "", "if", "remove_empty_relation", "==", "True", ":", "\n", "            ", "ret", "=", "re", ".", "sub", "(", "\": \"", ",", "\"\"", ",", "ret", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.ATP.generate_amrized_srl.get_semantic_roles_from_BIO": [[101, 122], ["enumerate", "cur_tok.append", "j.split", "roles.append", "cur_tok.append", "str", "j.split", "cur_tok.append", "str", "roles.append", "str"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "", "def", "get_semantic_roles_from_BIO", "(", "tokens", ",", "bio", ")", ":", "\n", "    ", "roles", "=", "[", "]", "\n", "cur_role", "=", "''", "\n", "cur_tok", "=", "[", "]", "\n", "for", "i", ",", "j", "in", "enumerate", "(", "bio", ")", ":", "\n", "        ", "if", "\"B-\"", "in", "j", "and", "cur_role", "==", "''", ":", "\n", "            ", "cur_role", "=", "j", ".", "split", "(", "\"-\"", ",", "1", ")", "[", "1", "]", "\n", "cur_tok", ".", "append", "(", "tokens", "[", "i", "]", "+", "\"@@\"", "+", "str", "(", "i", ")", ")", "\n", "", "elif", "\"B-\"", "in", "j", "and", "cur_role", "!=", "''", ":", "\n", "            ", "roles", ".", "append", "(", "{", "cur_role", ":", "\" \"", ".", "join", "(", "cur_tok", ")", "}", ")", "\n", "cur_role", "=", "''", "\n", "cur_tok", "=", "[", "]", "\n", "cur_role", "=", "j", ".", "split", "(", "\"-\"", ",", "1", ")", "[", "1", "]", "\n", "cur_tok", ".", "append", "(", "tokens", "[", "i", "]", "+", "\"@@\"", "+", "str", "(", "i", ")", ")", "\n", "", "elif", "\"I-\"", "in", "j", ":", "\n", "            ", "cur_tok", ".", "append", "(", "tokens", "[", "i", "]", "+", "\"@@\"", "+", "str", "(", "i", ")", ")", "\n", "", "elif", "\"O\"", "in", "j", "and", "cur_role", "!=", "''", ":", "\n", "            ", "roles", ".", "append", "(", "{", "cur_role", ":", "\" \"", ".", "join", "(", "cur_tok", ")", "}", ")", "\n", "cur_role", "=", "''", "\n", "cur_tok", "=", "[", "]", "\n", "", "", "return", "roles", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.ATP.generate_amrized_srl.read_from_conll12": [[123, 155], ["open", "f.readlines", "i.split", "get_semantic_roles_from_BIO.strip().split", "generate_amrized_srl.get_semantic_roles_from_BIO", "snt.strip().split", "len", "len", "generate_amrized_srl.SRL", "get_semantic_roles_from_BIO.strip", "SRL.semantic_roles.append", "srls.append", "generate_amrized_srl.SRL", "snt.strip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.ATP.generate_amrized_srl.get_semantic_roles_from_BIO", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "def", "read_from_conll12", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "samples", "=", "f", ".", "readlines", "(", ")", "\n", "srls", "=", "[", "]", "\n", "\n", "cur_sent", "=", "''", "\n", "cur_srl", "=", "None", "\n", "\n", "for", "i", "in", "samples", ":", "\n", "            ", "if", "\"|||\"", "in", "i", ":", "\n", "                ", "snt", ",", "args", "=", "i", ".", "split", "(", "\"|||\"", ")", "\n", "words", "=", "snt", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "[", "1", ":", "]", "\n", "roles", "=", "args", ".", "strip", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "assert", "len", "(", "words", ")", "==", "len", "(", "roles", ")", "\n", "\n", "args", "=", "get_semantic_roles_from_BIO", "(", "words", ",", "roles", ")", "\n", "\n", "if", "cur_sent", "==", "''", ":", "\n", "                    ", "cur_srl", "=", "SRL", "(", ")", "\n", "cur_srl", ".", "snt", "=", "words", "\n", "cur_srl", ".", "semantic_roles", "=", "[", "args", "]", "\n", "cur_sent", "=", "words", "\n", "", "else", ":", "\n", "                    ", "if", "words", "==", "cur_sent", ":", "\n", "                        ", "cur_srl", ".", "semantic_roles", ".", "append", "(", "args", ")", "\n", "", "else", ":", "\n", "                        ", "srls", ".", "append", "(", "cur_srl", ")", "\n", "cur_srl", "=", "SRL", "(", ")", "\n", "cur_srl", ".", "snt", "=", "words", "\n", "cur_srl", ".", "semantic_roles", "=", "[", "args", "]", "\n", "cur_sent", "=", "words", "\n", "", "", "", "", "return", "srls", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.amr_trainer.AMRTrainer.__init__": [[22, 30], ["transformers.Trainer.__init__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model", "=", "None", ",", "args", "=", "None", ",", "data_collator", "=", "None", ",", "train_dataset", "=", "None", ",", "eval_dataset", "=", "None", ",", "\n", "tokenizer", "=", "None", ",", "model_init", "=", "None", ",", "compute_metrics", "=", "None", ",", "callbacks", "=", "None", ",", "\n", "optimizers", "=", "(", "None", ",", "None", ")", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "args", ",", "data_collator", ",", "train_dataset", ",", "eval_dataset", ",", "tokenizer", ",", "model_init", ",", "\n", "compute_metrics", ",", "callbacks", ",", "optimizers", ")", "\n", "self", ".", "gen_args", "=", "self", ".", "model", ".", "config", ".", "task_specific_params", "[", "'parse_amr'", "]", "\n", "self", ".", "eval_tokenizer", "=", "kwargs", "[", "'eval_tokenizer'", "]", "# passing \"tokenizer\" to trainer causing behavior changes", "\n", "self", ".", "eval_samples", "=", "kwargs", "[", "'eval_samples'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.amr_trainer.AMRTrainer.evaluate": [[32, 85], ["amr_trainer.AMRTrainer.gen_args.get", "print", "os.path.join", "os.makedirs", "os.path.join", "os.path.join", "inference.Inference.Inference", "inference.Inference.Inference.parse_sents", "open", "open", "zip", "open.close", "open.close", "print", "evaluate.smatch_enhanced.get_entries", "evaluate.smatch_enhanced.get_entries", "print", "round", "amr_trainer.AMRTrainer.log", "print", "len", "len", "open.write", "open.write", "evaluate.smatch_enhanced.compute_smatch", "amr_trainer.AMRTrainer.gen_args.get", "amr_trainer.AMRTrainer.gen_args.get", "logger.exception", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_sents", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.get_entries", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.get_entries", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.compute_smatch"], ["", "def", "evaluate", "(", "self", ",", "dataset", "=", "None", ",", "ignore_keys", "=", "None", ",", "metric_key_prefix", "=", "'eval'", ")", ":", "\n", "        ", "if", "self", ".", "eval_samples", "is", "None", ":", "\n", "            ", "return", "{", "}", "\n", "# Skip the evaluation on the first N epochs", "\n", "# self.state.epoch is a float so subract a little off in-case it's at 0.99 instead of 1.0", "\n", "", "first_eval_epoch", "=", "self", ".", "gen_args", ".", "get", "(", "'first_eval_epoch'", ",", "0", ")", "\n", "if", "self", ".", "state", ".", "epoch", "<", "(", "first_eval_epoch", "-", "0.1", ")", ":", "\n", "            ", "print", "(", "'Skipping evaluation'", ")", "\n", "return", "{", "}", "\n", "", "print", "(", "'Predicting AMRs and smatch scoring'", ")", "\n", "# Setup the paths", "\n", "checkpoint_folder", "=", "f\"{PREFIX_CHECKPOINT_DIR}-{self.state.global_step}\"", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output_dir", ",", "checkpoint_folder", ")", "\n", "os", ".", "makedirs", "(", "checkpoint_dir", ",", "exist_ok", "=", "True", ")", "# model checkpoint save happens after eval", "\n", "gold_out_fpath", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "'dev-gold.txt'", ")", "\n", "pred_out_fpath", "=", "os", ".", "path", ".", "join", "(", "checkpoint_dir", ",", "'dev-pred.txt'", ")", "\n", "# Separate the evaluation sample components", "\n", "ref_graphs", "=", "self", ".", "eval_samples", "[", "'graphs'", "]", "\n", "ref_sents", "=", "self", ".", "eval_samples", "[", "'sents'", "]", "\n", "# Run evaluation", "\n", "inference", "=", "Inference", "(", "model", "=", "self", ".", "model", ",", "tokenizer", "=", "self", ".", "eval_tokenizer", ",", "\n", "config", "=", "self", ".", "gen_args", ",", "\n", "batch_size", "=", "self", ".", "gen_args", ".", "get", "(", "'eval_batch_size'", ",", "12", ")", ",", "\n", "num_beams", "=", "self", ".", "gen_args", ".", "get", "(", "'eval_num_beams'", ",", "1", ")", ")", "\n", "gen_graphs", "=", "inference", ".", "parse_sents", "(", "ref_sents", ",", "disable_progress", "=", "False", ")", "\n", "assert", "len", "(", "gen_graphs", ")", "==", "len", "(", "ref_graphs", ")", "\n", "# Save the reference and generated graphs, omitting any that are None", "\n", "f_ref", "=", "open", "(", "gold_out_fpath", ",", "'w'", ")", "\n", "f_gen", "=", "open", "(", "pred_out_fpath", ",", "'w'", ")", "\n", "skipped", "=", "0", "\n", "for", "ref_graph", ",", "gen_graph", "in", "zip", "(", "ref_graphs", ",", "gen_graphs", ")", ":", "\n", "            ", "if", "gen_graph", "is", "None", ":", "\n", "                ", "skipped", "+=", "1", "\n", "continue", "\n", "", "f_ref", ".", "write", "(", "ref_graph", "+", "'\\n\\n'", ")", "\n", "f_gen", ".", "write", "(", "gen_graph", "+", "'\\n\\n'", ")", "\n", "", "f_ref", ".", "close", "(", ")", "\n", "f_gen", ".", "close", "(", ")", "\n", "print", "(", "'Out of %d graphs, skipped %d that did not deserialize properly.'", "%", "(", "len", "(", "ref_graphs", ")", ",", "skipped", ")", ")", "\n", "# Run smatch evaluation.", "\n", "# Technically would not need to reload from the file but the smatch loader does some cleaning", "\n", "# so use `get_entries` just to be sure it's correct or at least consistant.", "\n", "gold_entries", "=", "get_entries", "(", "gold_out_fpath", ")", "\n", "test_entries", "=", "get_entries", "(", "pred_out_fpath", ")", "\n", "try", ":", "\n", "            ", "precision", ",", "recall", ",", "f_score", "=", "compute_smatch", "(", "test_entries", ",", "gold_entries", ")", "\n", "", "except", ":", "\n", "            ", "logger", ".", "exception", "(", "'compute_smatch failed'", ")", "\n", "precision", ",", "recall", ",", "f_score", "=", "0", ",", "0", ",", "0", "\n", "", "print", "(", "'SMATCH -> P: %.3f,  R: %.3f,  F: %.3f'", "%", "(", "precision", ",", "recall", ",", "f_score", ")", ")", "\n", "f_score", "=", "round", "(", "f_score", ",", "6", ")", "\n", "self", ".", "log", "(", "{", "'smatch_f_score'", ":", "f_score", "}", ")", "\n", "return", "{", "'smatch_f_score'", ":", "f_score", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.amr_trainer.AMRTrainer._save_checkpoint": [[88, 116], ["amr_trainer.AMRTrainer.gen_args.get", "amr_trainer.AMRTrainer.store_flos", "metrics.get", "logger.warning", "super()._save_checkpoint", "os.path.join", "os.makedirs", "amr_trainer.AMRTrainer.save_model", "amr_trainer.AMRTrainer.state.save_to_json", "print", "str", "os.path.join", "pathlib.Path().glob", "shutil.rmtree", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.amr_trainer.AMRTrainer._save_checkpoint", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.save_model", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["", "def", "_save_checkpoint", "(", "self", ",", "model", ",", "trial", ",", "metrics", "=", "None", ")", ":", "\n", "        ", "custom_save", "=", "self", ".", "gen_args", ".", "get", "(", "'custom_save_checkpoint'", ",", "None", ")", "\n", "smatch_val", "=", "None", "if", "metrics", "is", "None", "else", "metrics", ".", "get", "(", "'smatch_f_score'", ",", "None", ")", "\n", "if", "custom_save", "and", "smatch_val", "is", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "'Custom Save requested but no smatch_f_score in metrics. Reverting to default save'", ")", "\n", "", "if", "not", "custom_save", "or", "smatch_val", "is", "None", ":", "\n", "            ", "return", "super", "(", ")", ".", "_save_checkpoint", "(", "model", ",", "trial", ",", "metrics", ")", "\n", "# Store the number of floating-point operations that went into the model", "\n", "", "self", ".", "store_flos", "(", ")", "\n", "# Determine the new best metric / best model checkpoint", "\n", "if", "self", ".", "state", ".", "best_metric", "is", "None", "or", "smatch_val", ">", "self", ".", "state", ".", "best_metric", ":", "\n", "# Create the new checkpoint folder", "\n", "            ", "checkpoint_folder", "=", "f\"{PREFIX_CHECKPOINT_DIR}-{self.state.global_step}\"", "\n", "new_chk_fpath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "output_dir", ",", "checkpoint_folder", ")", "\n", "os", ".", "makedirs", "(", "new_chk_fpath", ",", "exist_ok", "=", "True", ")", "# also created in evaluate()", "\n", "# Set internal state values", "\n", "self", ".", "state", ".", "best_metric", "=", "smatch_val", "\n", "self", ".", "state", ".", "best_model_checkpoint", "=", "new_chk_fpath", "\n", "# Save the model and trainer state", "\n", "self", ".", "save_model", "(", "new_chk_fpath", ",", "_internal_call", "=", "True", ")", "\n", "self", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "new_chk_fpath", ",", "TRAINER_STATE_NAME", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "f\"Checkpoint not saved. Smatch score lower than best.\"", ")", "\n", "# Delete older checkpoints (might be empty except for evaluation data)", "\n", "", "checkpoint_list", "=", "[", "str", "(", "x", ")", "for", "x", "in", "Path", "(", "self", ".", "args", ".", "output_dir", ")", ".", "glob", "(", "f\"{PREFIX_CHECKPOINT_DIR}-*\"", ")", "]", "\n", "for", "checkpoint", "in", "checkpoint_list", ":", "\n", "            ", "if", "checkpoint", "!=", "self", ".", "state", ".", "best_model_checkpoint", ":", "\n", "                ", "shutil", ".", "rmtree", "(", "checkpoint", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.inference.Inference.__init__": [[17, 46], ["torch.device", "kwargs.get", "kwargs.get", "kwargs.get", "transformers.AutoModelForSeq2SeqLM.from_pretrained().to.to", "torch.cuda.is_available", "kwargs.get", "transformers.AutoModelForSeq2SeqLM.from_pretrained().to", "transformers.AutoModelForSeq2SeqLM.from_pretrained().to.config.task_specific_params.get", "kwargs.get", "transformers.AutoTokenizer.from_pretrained", "logger.warning", "transformers.AutoModelForSeq2SeqLM.from_pretrained().to.config.task_specific_params.get", "ValueError", "transformers.AutoModelForSeq2SeqLM.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained"], ["xfm_logger", "=", "logging", ".", "getLogger", "(", "'transformers.modeling_utils'", ")", "\n", "original_level", "=", "xfm_logger", ".", "getEffectiveLevel", "(", ")", "\n", "xfm_logger", ".", "setLevel", "(", "logging", ".", "ERROR", ")", "\n", "self", ".", "model", "=", "T5ForConditionalGeneration", ".", "from_pretrained", "(", "model_dir", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "xfm_logger", ".", "setLevel", "(", "original_level", ")", "\n", "# End logger ignore warning", "\n", "self", ".", "max_graph_len", "=", "self", ".", "model", ".", "config", ".", "task_specific_params", "[", "'translation_amr_to_text'", "]", "[", "'max_in_len'", "]", "\n", "self", ".", "max_sent_len", "=", "self", ".", "model", ".", "config", ".", "task_specific_params", "[", "'translation_amr_to_text'", "]", "[", "'max_out_len'", "]", "\n", "tokenizer_name", "=", "kwargs", ".", "get", "(", "'tokenizer_name'", ",", "'t5-base'", ")", "# name or path", "\n", "self", ".", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "tokenizer_name", ")", "\n", "self", ".", "seq_ends", "=", "set", "(", "[", "self", ".", "tokenizer", ".", "eos_token_id", ",", "self", ".", "tokenizer", ".", "pad_token_id", "]", ")", "\n", "self", ".", "batch_size", "=", "kwargs", ".", "get", "(", "'batch_size'", ",", "32", ")", "\n", "self", ".", "num_beams", "=", "kwargs", ".", "get", "(", "'num_beams'", ",", "1", ")", "# 1 => greedy", "\n", "self", ".", "num_ret_seq", "=", "kwargs", ".", "get", "(", "'num_ret_seq'", ",", "1", ")", "\n", "if", "self", ".", "num_ret_seq", ">", "self", ".", "num_beams", ":", "\n", "            ", "logger", ".", "warn", "(", "'Need at least as many beams as returned sequences - increasing beam count'", ")", "\n", "self", ".", "num_beams", "=", "self", ".", "num_ret_seq", "\n", "\n", "# Generate sentences from a list of AMR text graphs", "\n", "# For generate params see https://huggingface.co/transformers/master/main_classes/model.html", "\n", "", "", "def", "generate", "(", "self", ",", "graphs", ",", "disable_progress", "=", "True", ")", ":", "\n", "        ", "assert", "isinstance", "(", "graphs", ",", "list", ")", "\n", "# Make sure the user isn't passing in meta-data, only the graph strings", "\n", "stripped_graphs", "=", "[", "]", "\n", "for", "graph", "in", "graphs", ":", "\n", "            ", "meta_lines", ",", "graph_lines", "=", "split_amr_meta", "(", "graph", ")", "\n", "stripped_graphs", ".", "append", "(", "' '", ".", "join", "(", "graph_lines", ")", ")", "\n", "# Loop though batches", "\n", "", "sents", "=", "[", "]", "\n", "clips", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.inference.Inference.parse_sents": [[48, 104], ["torch.no_grad", "isinstance", "sorted", "inference.Inference.model.eval", "tqdm.tqdm.tqdm", "inference.Inference._chunk", "tqdm.tqdm.tqdm.close", "range", "inference.Inference.tokenizer", "enumerate", "torch.LongTensor().to", "torch.LongTensor().to", "inference.Inference.model.generate", "range", "tqdm.tqdm.tqdm.update", "any", "len", "len", "enumerate", "enumerate", "len", "len", "inference.Inference.tokenizer.decode", "len", "len", "penman_serializer.PenmanDeSerializer().get_graph_string", "len", "logger.warning", "torch.LongTensor", "torch.LongTensor", "inference.Inference._group_slice", "logger.error", "zip", "len", "inference.Inference._group_slice", "inference.Inference._group_slice", "penman_serializer.PenmanDeSerializer"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.inference.Inference._chunk", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.inference.Inference.generate", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.get_graph_string", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.inference.Inference._group_slice", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.inference.Inference._group_slice", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.inference.Inference._group_slice"], ["for", "batch", "in", "tqdm", "(", "dataloader", ",", "disable", "=", "disable_progress", ")", ":", "\n", "# Form encodings and tokenize", "\n", "            ", "input_text", "=", "[", "'%s'", "%", "graph", "for", "graph", "in", "batch", "]", "\n", "input_encodings", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "input_text", ",", "padding", "=", "True", ",", "\n", "truncation", "=", "True", ",", "max_length", "=", "self", ".", "max_graph_len", ",", "\n", "return_overflowing_tokens", "=", "True", ")", "\n", "# Check if any graphs were truncated (requires return_overflowing_tokens=True)", "\n", "clip", "=", "[", "l", ">", "0", "for", "l", "in", "input_encodings", "[", "'num_truncated_tokens'", "]", "]", "\n", "clips", ".", "extend", "(", "clip", ")", "\n", "# Convert to tensors", "\n", "input_ids", "=", "torch", ".", "LongTensor", "(", "input_encodings", "[", "'input_ids'", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "attention_mask", "=", "torch", ".", "LongTensor", "(", "input_encodings", "[", "'attention_mask'", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "# Generate", "\n", "outs", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "\n", "max_length", "=", "self", ".", "max_sent_len", ",", "early_stopping", "=", "True", ",", "num_beams", "=", "self", ".", "num_beams", ",", "\n", "num_return_sequences", "=", "self", ".", "num_ret_seq", ")", "\n", "outs", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "ids", ",", "skip_special_tokens", "=", "True", ")", "for", "ids", "in", "outs", "]", "\n", "sents", ".", "extend", "(", "outs", ")", "\n", "", "return", "sents", ",", "clips", "\n", "\n", "# When num_ret_seq > 1, additional sentences are appended to the list, after the first", "\n", "# This is a simply extracts a group of them.  The length of the return is self.num_ret_seq", "\n", "", "def", "get_ans_group", "(", "self", ",", "answers", ",", "group_num", ")", ":", "\n", "        ", "return", "answers", "[", "group_num", "*", "self", ".", "num_ret_seq", ":", "(", "group_num", "+", "1", ")", "*", "self", ".", "num_ret_seq", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.inference.Inference._group_slice": [[107, 109], ["slice"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.inference.Inference._chunk": [[111, 115], ["range", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.inference.Inference.parse_spans": [[117, 121], ["inference.Inference.parse_sents", "s.text.strip"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_sents"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.trainer.Trainer.__init__": [[16, 22], ["args.get", "transformers.TrainingArguments", "transformers.set_seed"], "methods", ["None"], ["self", ".", "rev_params", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'rev_params'", ")", "\n", "self", ".", "fwd_err", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'fwd_err'", ")", "\n", "self", ".", "rev_err", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'rev_err'", ")", "\n", "self", ".", "param_fn", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'train_params.json'", ")", "\n", "fast_align", "=", "os", ".", "path", ".", "join", "(", "bin_dir", ",", "'fast_align'", ")", "\n", "atools", "=", "os", ".", "path", ".", "join", "(", "bin_dir", ",", "'atools'", ")", "\n", "p", "=", "{", "}", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.trainer.Trainer.train": [[23, 69], ["os.makedirs", "print", "amr_trainer.AMRTrainer.Trainer.gen_args.get", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSeq2SeqLM.from_pretrained", "amr_trainer.AMRTrainer.Trainer.gen_args.get", "print", "os.path.join", "amr_trainer.AMRTrainer.Trainer.build_dataset", "print", "amr_trainer.AMRTrainer.Trainer.gen_args.get", "print", "transformers.DataCollatorForSeq2Seq", "amr_trainer.AMRTrainer", "amr_trainer.AMRTrainer.train", "amr_trainer.AMRTrainer.Trainer.gen_args.get", "amr_trainer.AMRTrainer.Trainer.tokenizer.save_pretrained", "os.path.join", "penman_serializer.load_and_serialize", "print", "print", "amr_trainer.AMRTrainer.save_model", "len", "len", "len", "amr_trainer.AMRTrainer.CudaMemoryCB"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.trainer.Trainer.build_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.load_and_serialize", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.save_model"], ["p", "[", "'I'", "]", "=", "kwargs", ".", "get", "(", "'I'", ",", "5", ")", "\n", "p", "[", "'q'", "]", "=", "kwargs", ".", "get", "(", "'q'", ",", "0.08", ")", "\n", "p", "[", "'a'", "]", "=", "kwargs", ".", "get", "(", "'a'", ",", "0.01", ")", "\n", "p", "[", "'T'", "]", "=", "kwargs", ".", "get", "(", "'T'", ",", "4", ")", "\n", "p", "[", "'heuristic'", "]", "=", "kwargs", ".", "get", "(", "'heuristic'", ",", "'grow-diag-final-and'", ")", "\n", "self", ".", "params", "=", "p", "\n", "# Create the actual commands to execute", "\n", "fwd_cmd", "=", "'%s -i %s -d -o -v -I %d -q %f -a %f -T %d -p %s'", "%", "(", "fast_align", ",", "in_fpath", ",", "p", "[", "'I'", "]", ",", "p", "[", "'q'", "]", ",", "p", "[", "'a'", "]", ",", "p", "[", "'T'", "]", ",", "self", ".", "fwd_params", ")", "\n", "rev_cmd", "=", "'%s -i %s -d -o -v -I %d -q %f -a %f -T %d -p %s -r'", "%", "(", "fast_align", ",", "in_fpath", ",", "p", "[", "'I'", "]", ",", "p", "[", "'q'", "]", ",", "p", "[", "'a'", "]", ",", "p", "[", "'T'", "]", ",", "self", ".", "rev_params", ")", "\n", "tools_cmd", "=", "'%s -i %s -j %s -c %s'", "%", "(", "atools", ",", "self", ".", "fwd_out", ",", "self", ".", "rev_out", ",", "p", "[", "'heuristic'", "]", ")", "\n", "self", ".", "fwd_cmd", "=", "fwd_cmd", ".", "split", "(", ")", "\n", "self", ".", "rev_cmd", "=", "rev_cmd", ".", "split", "(", ")", "\n", "self", ".", "tools_cmd", "=", "tools_cmd", ".", "split", "(", ")", "\n", "\n", "", "def", "train", "(", "self", ")", ":", "\n", "# Run the training", "\n", "        ", "with", "open", "(", "self", ".", "fwd_out", ",", "'w'", ")", "as", "fout", ",", "open", "(", "self", ".", "fwd_err", ",", "'w'", ")", "as", "ferr", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "fwd_cmd", ",", "stdout", "=", "fout", ",", "stderr", "=", "ferr", ")", "\n", "", "with", "open", "(", "self", ".", "rev_out", ",", "'w'", ")", "as", "fout", ",", "open", "(", "self", ".", "rev_err", ",", "'w'", ")", "as", "ferr", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "rev_cmd", ",", "stdout", "=", "fout", ",", "stderr", "=", "ferr", ")", "\n", "", "with", "open", "(", "self", ".", "final_out", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "tools_cmd", ",", "stdout", "=", "fout", ")", "\n", "# Get a few final parameters", "\n", "", "self", ".", "params", "[", "'fwd_T'", "]", ",", "self", ".", "params", "[", "'fwd_m'", "]", "=", "self", ".", "read_err", "(", "self", ".", "fwd_err", ")", "\n", "self", ".", "params", "[", "'rev_T'", "]", ",", "self", ".", "params", "[", "'rev_m'", "]", "=", "self", ".", "read_err", "(", "self", ".", "rev_err", ")", "\n", "# Save the parameters for use during inference", "\n", "with", "open", "(", "self", ".", "param_fn", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "params", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n", "", "", "def", "read_err", "(", "self", ",", "err", ")", ":", "\n", "        ", "T", ",", "m", "=", "''", ",", "''", "\n", "with", "open", "(", "err", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "# expected target length = source length * N", "\n", "                ", "if", "'expected target length'", "in", "line", ":", "\n", "                    ", "m", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "# final tension: N", "\n", "", "elif", "'final tension'", "in", "line", ":", "\n", "                    ", "T", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "", "", "", "return", "float", "(", "T", ")", ",", "float", "(", "m", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.trainer.Trainer.build_dataset": [[71, 97], ["penman_serializer.load_and_serialize", "print", "trainer.Trainer.tokenizer", "trainer.Trainer.tokenizer", "trainer.Trainer.gen_args.get", "set", "set", "trainer.AMRDataset", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "len", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.load_and_serialize", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.trainer.AMRDataset.__init__": [[102, 105], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.trainer.AMRDataset.__len__": [[106, 108], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.trainer.AMRDataset.__getitem__": [[109, 111], ["trainer.AMRDataset.encodings.items"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.trainer.CudaMemoryCB.on_log": [[115, 124], ["trainer.CudaMemoryCB.cuda_memory_stats"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.trainer.CudaMemoryCB.cuda_memory_stats"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.trainer.CudaMemoryCB.on_epoch_begin": [[125, 128], ["torch.cuda.current_device", "torch.cuda.reset_peak_memory_stats"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.trainer.CudaMemoryCB.cuda_memory_stats": [[129, 138], ["torch.cuda.current_device", "torch.cuda.memory_stats", "trainer.CudaMemoryCB.format_bytes", "trainer.CudaMemoryCB.format_bytes", "trainer.CudaMemoryCB.format_bytes", "trainer.CudaMemoryCB.format_bytes"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.trainer.CudaMemoryCB.format_bytes", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.trainer.CudaMemoryCB.format_bytes", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.trainer.CudaMemoryCB.format_bytes", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.trainer.CudaMemoryCB.format_bytes"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.trainer.CudaMemoryCB.format_bytes": [[139, 147], ["power_labels.get"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanSerializer.__init__": [[34, 41], ["penman.decode", "set", "penman_serializer.PenmanSerializer.serialize", "penman_serializer.PenmanSerializer.elements_to_tokens", "penman.models.noop.NoOpModel"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanSerializer.serialize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanSerializer.elements_to_tokens"], ["def", "__init__", "(", "self", ",", "gstring", ")", ":", "\n", "        ", "self", ".", "graph", "=", "penman", ".", "decode", "(", "gstring", ",", "model", "=", "NoOpModel", "(", ")", ")", "\n", "# Run the serialization", "\n", "self", ".", "elements", "=", "[", "]", "# clear elements list", "\n", "self", ".", "nodes", "=", "set", "(", ")", "# nodes visited (to prevent recursion)", "\n", "self", ".", "serialize", "(", "self", ".", "graph", ".", "top", ")", "\n", "self", ".", "tokens", "=", "self", ".", "elements_to_tokens", "(", "self", ".", "elements", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanSerializer.get_graph_string": [[43, 45], ["None"], "methods", ["None"], ["", "def", "get_graph_string", "(", "self", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "self", ".", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanSerializer.get_meta": [[47, 49], ["None"], "methods", ["None"], ["", "def", "get_meta", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "graph", ".", "metadata", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanSerializer.serialize": [[53, 68], ["penman_serializer.PenmanSerializer.nodes.add", "penman_serializer.PenmanSerializer.elements.append", "penman_serializer.PenmanSerializer.elements.append", "penman_serializer.PenmanSerializer.serialize", "penman_serializer.PenmanSerializer.graph.variables"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanSerializer.serialize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.SemanticGraph.variables"], ["", "def", "serialize", "(", "self", ",", "node_var", ")", ":", "\n", "# Apply open paren if this is a variable (not an attrib/literal) and it's the first instance of it", "\n", "# If we've seen the variable before, don't insert a new node, just use the reference (ie.. no parens)", "\n", "        ", "if", "node_var", "in", "self", ".", "graph", ".", "variables", "(", ")", "and", "node_var", "not", "in", "self", ".", "nodes", ":", "\n", "            ", "self", ".", "elements", "+=", "[", "'('", ",", "node_var", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "elements", "+=", "[", "node_var", "]", "\n", "return", "# return if this isn't a variable or if it's the 2nd time we've see the variable", "\n", "", "self", ".", "nodes", ".", "add", "(", "node_var", ")", "\n", "# Loop through all the children of the node and recurse as needed", "\n", "children", "=", "[", "t", "for", "t", "in", "self", ".", "graph", ".", "triples", "if", "t", "[", "1", "]", "!=", "self", ".", "INSTANCE", "and", "t", "[", "0", "]", "==", "node_var", "]", "\n", "for", "t", "in", "children", ":", "\n", "            ", "self", ".", "elements", ".", "append", "(", "t", "[", "1", "]", ")", "# add the edge, t[1] is role aka edge", "\n", "self", ".", "serialize", "(", "t", "[", "2", "]", ")", "# recurse and add the child (node variable or attrib literal)", "\n", "", "self", ".", "elements", ".", "append", "(", "')'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanSerializer.elements_to_tokens": [[70, 77], ["var_dict.update", "penman_serializer.PenmanSerializer.get_uid_map", "var_dict.get", "penman_serializer.PenmanSerializer.graph.instances"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanSerializer.get_uid_map"], ["", "def", "elements_to_tokens", "(", "self", ",", "elements", ")", ":", "\n", "# Get the mapping from variables to concepts and then update it (replace)", "\n", "# with any enumerated concepts", "\n", "        ", "var_dict", "=", "{", "t", ".", "source", ":", "t", ".", "target", "for", "t", "in", "self", ".", "graph", ".", "instances", "(", ")", "}", "\n", "var_dict", ".", "update", "(", "self", ".", "get_uid_map", "(", ")", ")", "\n", "tokens", "=", "[", "var_dict", ".", "get", "(", "x", ",", "x", ")", "for", "x", "in", "self", ".", "elements", "]", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanSerializer.get_uid_map": [[79, 88], ["penman_serializer.PenmanSerializer.graph.instances", "collections.Counter", "enumerate", "collections.Counter.items"], "methods", ["None"], ["", "def", "get_uid_map", "(", "self", ")", ":", "\n", "        ", "instances", "=", "self", ".", "graph", ".", "instances", "(", ")", "\n", "counts", "=", "Counter", "(", "[", "t", ".", "target", "for", "t", "in", "instances", "]", ")", "\n", "non_unique", "=", "[", "k", "for", "k", ",", "c", "in", "counts", ".", "items", "(", ")", "if", "c", ">", "1", "]", "\n", "uid_map", "=", "{", "}", "\n", "for", "concept", "in", "non_unique", ":", "\n", "            ", "for", "i", ",", "var", "in", "enumerate", "(", "[", "t", ".", "source", "for", "t", "in", "instances", "if", "t", ".", "target", "==", "concept", "]", ")", ":", "\n", "                ", "uid_map", "[", "var", "]", "=", "'%s_%d'", "%", "(", "concept", ",", "i", ")", "\n", "", "", "return", "uid_map", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.__init__": [[100, 111], ["str", "collections.Counter", "penman_serializer.PenmanDeSerializer.deserialize", "logger.error"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.deserialize"], ["def", "__init__", "(", "self", ",", "gstring", ",", "gid", "=", "'x'", ")", ":", "\n", "        ", "self", ".", "gid", "=", "str", "(", "gid", ")", "\n", "self", ".", "enumerator", "=", "Counter", "(", ")", "\n", "self", ".", "var_dict", "=", "{", "}", "# concepts (with enumeration if needed) mapped to variables", "\n", "self", ".", "triples", "=", "[", "]", "\n", "try", ":", "\n", "            ", "self", ".", "deserialize", "(", "gstring", ")", "# sets self.pgraph and self.gstring", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "self", ".", "gstring", "=", "None", "\n", "self", ".", "pgraph", "=", "None", "\n", "logger", ".", "error", "(", "'Deserializer exception: %s'", "%", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.get_pen_graph": [[112, 114], ["None"], "methods", ["None"], ["", "", "def", "get_pen_graph", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pgraph", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.get_graph_string": [[115, 117], ["None"], "methods", ["None"], ["", "def", "get_graph_string", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "gstring", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.deserialize": [[121, 220], ["penman_serializer.PenmanDeSerializer.graph_tokenize", "enumerate", "enumerate", "penman.graph.Graph", "penman_serializer.PenmanDeSerializer.token_type", "penman.encode", "penman.decode", "len", "penman_serializer.PenmanDeSerializer.triples.append", "penman_serializer.PenmanDeSerializer.re_var.fullmatch", "penman_serializer.PenmanDeSerializer.re_ii.fullmatch", "tuple", "logger.warning", "logger.error", "penman_serializer.PenmanDeSerializer.get_var_concept", "triple.append", "tuple", "penman_serializer.PenmanDeSerializer.is_num", "penman.models.noop.NoOpModel", "penman.models.noop.NoOpModel", "len", "len", "logger.error", "node_stack.append", "logger.warning", "logger.warning", "triple.append", "triple.append", "target.startswith", "target.endswith", "set", "len", "triple.append", "target.replace", "len", "triple.append", "len", "penman_serializer.PenmanDeSerializer.get_var_concept", "triple.append", "len", "node_stack.append", "logger.warning", "logger.warning", "logger.warning", "len", "node_stack.pop", "logger.warning", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.graph_tokenize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.token_type", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.get_var_concept", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.is_num", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.get_var_concept"], ["", "def", "deserialize", "(", "self", ",", "gstring", ")", ":", "\n", "        ", "node_stack", "=", "[", "]", "# list of previously instantiated nodes", "\n", "node_depth", "=", "0", "# number of left parens encountered and not destacked", "\n", "triple", "=", "[", "]", "\n", "# Tokenize and some logging (the system has a lot of unbalanced parentheses)", "\n", "tokens", "=", "self", ".", "graph_tokenize", "(", "gstring", ")", "\n", "# left_parens  = tokens.count('(')", "\n", "# right_parens = tokens.count(')')", "\n", "# if left_parens != right_parens:", "\n", "#     logger.warning('gid=%s has %d left parens and %d right parens' % (self.gid, left_parens, right_parens))", "\n", "# Loop through all tokens and parse the string", "\n", "for", "tnum", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "#### Big case statement to classify parts of the graph string ####", "\n", "            ", "ttype", "=", "self", ".", "token_type", "(", "token", ")", "\n", "# Mostly ignored but can be used for error checking", "\n", "if", "token", "==", "'('", ":", "\n", "                ", "node_depth", "+=", "1", "\n", "# Find the source for the triple", "\n", "", "elif", "len", "(", "triple", ")", "==", "0", "and", "ttype", "==", "TType", ".", "concept", ":", "\n", "# This path should only happen for a new graph. For graphs with existing self.triples, the next", "\n", "# token should always be a role. See below for len(triple)==0 where both the variable and role", "\n", "# are appended to the triple.", "\n", "                ", "if", "len", "(", "self", ".", "triples", ")", ">", "0", ":", "\n", "                    ", "logger", ".", "error", "(", "'gid=%s Initial node constructed when triples not empty, ignoring token.'", "%", "(", "self", ".", "gid", ")", ")", "\n", "continue", "\n", "", "variable", ",", "concept", ",", "is_new_node", "=", "self", ".", "get_var_concept", "(", "token", ")", "\n", "triple", ".", "append", "(", "variable", ")", "\n", "if", "is_new_node", ":", "\n", "                    ", "node_stack", ".", "append", "(", "variable", ")", "\n", "# Some error logging", "\n", "", "if", "is_new_node", "and", "tokens", "[", "tnum", "-", "1", "]", "!=", "'('", ":", "\n", "                    ", "logger", ".", "warning", "(", "'gid=%s Missing starting paren for node %s/%s'", "%", "(", "self", ".", "gid", ",", "variable", ",", "concept", ")", ")", "\n", "", "if", "not", "is_new_node", "and", "tokens", "[", "tnum", "-", "1", "]", "==", "'('", ":", "\n", "                    ", "logger", ".", "warning", "(", "'gid=%s Start paren present but %s is not a new concept'", "%", "(", "self", ".", "gid", ",", "concept", ")", ")", "\n", "# Look for a role (aka edge) that attaches to the previous variable in the node stack", "\n", "", "", "elif", "len", "(", "triple", ")", "==", "0", "and", "ttype", "==", "TType", ".", "role", ":", "\n", "                ", "variable", "=", "node_stack", "[", "-", "1", "]", "\n", "triple", ".", "append", "(", "variable", ")", "\n", "triple", ".", "append", "(", "token", ")", "\n", "# Look for the role (aka edge) that attaches to the triple[0] (aka source)", "\n", "", "elif", "len", "(", "triple", ")", "==", "1", "and", "ttype", "==", "TType", ".", "role", ":", "\n", "                ", "triple", ".", "append", "(", "token", ")", "\n", "# Look for the attrib target", "\n", "", "elif", "len", "(", "triple", ")", "==", "2", "and", "(", "ttype", "==", "TType", ".", "attrib", "or", "token", "in", "(", "'interrogative'", ",", "'imperative'", ",", "'expressive'", ")", ")", ":", "\n", "                ", "triple", ".", "append", "(", "token", ")", "\n", "# Look for a node (concept) target", "\n", "", "elif", "len", "(", "triple", ")", "==", "2", "and", "ttype", "==", "TType", ".", "concept", ":", "\n", "                ", "variable", ",", "concept", ",", "is_new_node", "=", "self", ".", "get_var_concept", "(", "token", ")", "\n", "if", "is_new_node", ":", "\n", "                    ", "node_stack", ".", "append", "(", "variable", ")", "\n", "# Some error logging", "\n", "", "if", "is_new_node", "and", "tokens", "[", "tnum", "-", "1", "]", "!=", "'('", ":", "\n", "                    ", "logger", ".", "warning", "(", "'gid=%s Missing starting paren for node %s/%s'", "%", "(", "self", ".", "gid", ",", "variable", ",", "concept", ")", ")", "\n", "", "if", "not", "is_new_node", "and", "tokens", "[", "tnum", "-", "1", "]", "==", "'('", ":", "\n", "                    ", "logger", ".", "warning", "(", "'gid=%s Start paren present but %s is not a new concept'", "%", "(", "self", ".", "gid", ",", "concept", ")", ")", "\n", "", "triple", ".", "append", "(", "variable", ")", "\n", "# De-stack the root nodes based on closing parens, but don't destack past the top var", "\n", "# Log an error if we're trying to empty the stack and it's not the very last token", "\n", "", "elif", "token", "==", "')'", ":", "\n", "                ", "if", "len", "(", "node_stack", ")", ">", "1", ":", "\n", "                    ", "node_stack", ".", "pop", "(", ")", "\n", "node_depth", "-=", "1", "\n", "", "elif", "tnum", "<", "len", "(", "self", ".", "triples", ")", "-", "1", ":", "\n", "                    ", "logger", ".", "warning", "(", "'gid=%s Trying to destack past top node'", "%", "self", ".", "gid", ")", "\n", "# Unknown situation (should never get here)", "\n", "", "", "else", ":", "\n", "                ", "logger", ".", "warning", "(", "'gid=%s Unhandled token %s'", "%", "(", "self", ".", "gid", ",", "token", ")", ")", "\n", "#### Save the triple if complete ####", "\n", "", "if", "len", "(", "triple", ")", "==", "3", ":", "\n", "                ", "self", ".", "triples", ".", "append", "(", "tuple", "(", "triple", ")", ")", "\n", "triple", "=", "[", "]", "\n", "# Do a little post-processing check on the triples and fix attribs if needed", "\n", "# I haven't found instances that requires this but it could be useful", "\n", "", "", "for", "i", ",", "triple", "in", "enumerate", "(", "self", ".", "triples", ")", ":", "\n", "            ", "if", "triple", "[", "1", "]", "==", "self", ".", "INSTANCE", ":", "\n", "                ", "continue", "\n", "", "target", "=", "triple", "[", "2", "]", "\n", "# Check if this is a varible", "\n", "if", "self", ".", "re_var", ".", "fullmatch", "(", "target", ")", "or", "self", ".", "re_ii", ".", "fullmatch", "(", "target", ")", ":", "\n", "                ", "continue", "\n", "# If it's an attrib enforce attribute syntax", "\n", "", "else", ":", "\n", "                ", "if", "(", "target", ".", "startswith", "(", "'\"'", ")", "and", "target", ".", "endswith", "(", "'\"'", ")", ")", "or", "self", ".", "is_num", "(", "target", ")", "or", "(", "target", "in", "set", "(", "[", "'-'", ",", "'+'", ",", "'interrogative'", ",", "'imperative'", ",", "'expressive'", "]", ")", ")", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "new_target", "=", "'\"'", "+", "target", ".", "replace", "(", "'\"'", ",", "''", ")", "+", "'\"'", "\n", "", "self", ".", "triples", "[", "i", "]", "=", "tuple", "(", "[", "triple", "[", "0", "]", ",", "triple", "[", "1", "]", ",", "new_target", "]", ")", "\n", "logger", ".", "warning", "(", "'gid=%s Replacing attrib %s with %s'", "%", "(", "self", ".", "gid", ",", "target", ",", "new_target", ")", ")", "\n", "# Now convert to a penman graph and then back to a string", "\n", "", "", "pgraph", "=", "Graph", "(", "self", ".", "triples", ")", "\n", "# Catch malformed graphs, including disconnected ones, incorrectly quoted attibs, etc..", "\n", "try", ":", "\n", "            ", "self", ".", "gstring", "=", "penman", ".", "encode", "(", "pgraph", ",", "indent", "=", "6", ",", "model", "=", "NoOpModel", "(", ")", ")", "\n", "self", ".", "pgraph", "=", "penman", ".", "decode", "(", "self", ".", "gstring", ",", "model", "=", "NoOpModel", "(", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "self", ".", "gstring", "=", "None", "\n", "self", ".", "pgraph", "=", "None", "\n", "logger", ".", "error", "(", "'Penman encode/decode exception: %s'", "%", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.get_var_concept": [[224, 242], ["penman_serializer.PenmanDeSerializer.extract_uid", "unidecode.unidecode.unidecode", "penman_serializer.PenmanDeSerializer.triples.append", "concept_wuid[].isalpha", "concept_wuid[].lower"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.extract_uid"], ["", "", "def", "get_var_concept", "(", "self", ",", "concept_wuid", ")", ":", "\n", "        ", "if", "concept_wuid", "in", "self", ".", "var_dict", ":", "\n", "            ", "variable", "=", "self", ".", "var_dict", "[", "concept_wuid", "]", "\n", "is_first", "=", "False", "\n", "", "else", ":", "\n", "            ", "first", "=", "concept_wuid", "[", "0", "]", ".", "lower", "(", ")", "if", "concept_wuid", "[", "0", "]", ".", "isalpha", "(", ")", "else", "'x'", "\n", "first", "=", "'ii'", "if", "first", "==", "'i'", "else", "first", "# use ii to avoid issues with \"i\"", "\n", "first", "=", "unidecode", "(", "first", ")", "\n", "index", "=", "self", ".", "enumerator", "[", "first", "]", "\n", "self", ".", "enumerator", "[", "first", "]", "+=", "1", "\n", "variable", "=", "first", "if", "index", "==", "0", "else", "'%s%d'", "%", "(", "first", ",", "index", "+", "1", ")", "\n", "self", ".", "var_dict", "[", "concept_wuid", "]", "=", "variable", "\n", "is_first", "=", "True", "\n", "", "concept_only", ",", "_", "=", "self", ".", "extract_uid", "(", "concept_wuid", ")", "\n", "# add an instance definition to triples when the variable is first defined", "\n", "if", "is_first", ":", "\n", "            ", "self", ".", "triples", ".", "append", "(", "(", "variable", ",", "self", ".", "INSTANCE", ",", "concept_only", ")", ")", "\n", "", "return", "variable", ",", "concept_only", ",", "is_first", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.extract_uid": [[244, 252], ["cls.re_uid.search", "cls.re_uid.search.start", "cls.re_uid.search.end", "cls.re_uid.search.start"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "extract_uid", "(", "cls", ",", "concept", ")", ":", "\n", "        ", "match", "=", "cls", ".", "re_uid", ".", "search", "(", "concept", ")", "\n", "if", "match", "is", "None", ":", "\n", "            ", "return", "concept", ",", "None", "\n", "", "stripped", "=", "concept", "[", ":", "match", ".", "start", "(", ")", "]", "\n", "uid", "=", "concept", "[", "match", ".", "start", "(", ")", "+", "1", ":", "match", ".", "end", "(", ")", "]", "# keep uid as a string", "\n", "return", "stripped", ",", "uid", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.is_num": [[254, 261], ["float"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "is_num", "(", "val", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "x", "=", "float", "(", "val", ")", "\n", "return", "True", "\n", "", "except", "ValueError", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.token_type": [[263, 278], ["set", "token.startswith", "set", "token.startswith", "token.endswith", "token[].isdigit", "penman_serializer.PenmanDeSerializer.is_num"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.is_num"], ["", "", "def", "token_type", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "set", "(", "[", "'('", ",", "')'", "]", ")", ":", "\n", "            ", "return", "TType", ".", "paren", "\n", "", "elif", "token", ".", "startswith", "(", "':'", ")", ":", "\n", "            ", "return", "TType", ".", "role", "\n", "", "elif", "token", "in", "set", "(", "[", "'-'", ",", "'+'", "]", ")", ":", "# 'interrogative', 'imperative', 'expressive']): could be nodes", "\n", "            ", "return", "TType", ".", "attrib", "# instead of including here, test in logic above", "\n", "", "elif", "token", ".", "startswith", "(", "'\"'", ")", "or", "token", ".", "endswith", "(", "'\"'", ")", "or", "token", "[", "0", "]", ".", "isdigit", "(", ")", ":", "# fault tolerant def", "\n", "            ", "return", "TType", ".", "attrib", "\n", "", "elif", "self", ".", "is_num", "(", "token", ")", ":", "\n", "            ", "return", "TType", ".", "attrib", "\n", "", "elif", "token", "==", "'/'", ":", "\n", "            ", "return", "TType", ".", "sep", "\n", "", "else", ":", "\n", "            ", "return", "TType", ".", "concept", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.graph_tokenize": [[282, 311], ["gstring.strip.strip.strip", "enumerate", "t.strip", "tokens.append", "tokens.append", "set", "tokens.append", "tokens.append"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "graph_tokenize", "(", "gstring", ")", ":", "\n", "        ", "gstring", "=", "gstring", ".", "strip", "(", ")", "\n", "tokens", "=", "[", "]", "\n", "sptr", "=", "0", "\n", "in_quote", "=", "False", "\n", "for", "ptr", ",", "token", "in", "enumerate", "(", "gstring", ")", ":", "\n", "# Handle quoted literals", "\n", "            ", "if", "token", "==", "'\"'", ":", "\n", "                ", "if", "in_quote", ":", "# end quote", "\n", "                    ", "tokens", ".", "append", "(", "gstring", "[", "sptr", ":", "ptr", "+", "1", "]", ")", "\n", "sptr", "=", "ptr", "+", "1", "\n", "", "else", ":", "# begin quote", "\n", "                    ", "sptr", "=", "ptr", "\n", "", "in_quote", "=", "not", "in_quote", "\n", "", "if", "in_quote", ":", "\n", "                ", "continue", "\n", "# Break on other seperator characters", "\n", "", "if", "token", "==", "' '", ":", "\n", "                ", "tokens", ".", "append", "(", "gstring", "[", "sptr", ":", "ptr", "]", ")", "\n", "sptr", "=", "ptr", "+", "1", "\n", "", "elif", "token", "in", "set", "(", "[", "'('", ",", "')'", ",", "'/'", "]", ")", ":", "\n", "                ", "tokens", ".", "append", "(", "gstring", "[", "sptr", ":", "ptr", "]", ")", "\n", "tokens", ".", "append", "(", "token", ")", "\n", "sptr", "=", "ptr", "+", "1", "\n", "# Clean-up empty tokens", "\n", "", "", "tokens", "=", "[", "t", ".", "strip", "(", ")", "for", "t", "in", "tokens", "]", "\n", "tokens", "=", "[", "t", "for", "t", "in", "tokens", "if", "t", "]", "\n", "return", "tokens", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.load_and_serialize": [[16, 26], ["print", "tqdm.tqdm", "graph_processing.amr_loading.load_amr_entries", "penman_serializer.PenmanSerializer", "serials[].append", "serials[].append", "serials[].append", "penman_serializer.PenmanSerializer.get_graph_string", "PenmanSerializer.get_meta().strip", "penman_serializer.PenmanSerializer.get_meta"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading.load_amr_entries", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanDeSerializer.get_graph_string", "home.repos.pwc.inspect_result.chenllliang_atp.parse_xfm.penman_serializer.PenmanSerializer.get_meta"], ["def", "load_and_serialize", "(", "fpath", ",", "progress", "=", "True", ",", "max_entries", "=", "None", ")", ":", "\n", "    ", "entries", "=", "load_amr_entries", "(", "fpath", ")", "[", ":", "max_entries", "]", "\n", "serials", "=", "{", "'graphs'", ":", "[", "]", ",", "'sents'", ":", "[", "]", ",", "'serials'", ":", "[", "]", "}", "\n", "print", "(", "'Loading and converting'", ",", "fpath", ")", "\n", "for", "entry", "in", "tqdm", "(", "entries", ",", "ncols", "=", "100", ",", "disable", "=", "not", "progress", ")", ":", "\n", "        ", "serializer", "=", "PenmanSerializer", "(", "entry", ")", "\n", "serials", "[", "'graphs'", "]", ".", "append", "(", "entry", ")", "\n", "serials", "[", "'serials'", "]", ".", "append", "(", "serializer", ".", "get_graph_string", "(", ")", ")", "\n", "serials", "[", "'sents'", "]", ".", "append", "(", "serializer", ".", "get_meta", "(", "'snt'", ")", ".", "strip", "(", ")", ")", "\n", "", "return", "serials", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.inference.Inference.__init__": [[15, 36], ["kwargs.get", "torch.device", "logging.getLogger", "logging.getLogger.getEffectiveLevel", "logging.getLogger.setLevel", "transformers.T5ForConditionalGeneration.from_pretrained().to", "logging.getLogger.setLevel", "kwargs.get", "transformers.T5Tokenizer.from_pretrained", "kwargs.get", "kwargs.get", "kwargs.get", "torch.cuda.is_available", "logger.warn", "transformers.T5ForConditionalGeneration.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained"], ["self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "# The following produces a logger warning that we can ignore so eliminate temporarily set the level higher", "\n", "xfm_logger", "=", "logging", ".", "getLogger", "(", "'transformers.modeling_utils'", ")", "\n", "original_level", "=", "xfm_logger", ".", "getEffectiveLevel", "(", ")", "\n", "xfm_logger", ".", "setLevel", "(", "logging", ".", "ERROR", ")", "\n", "self", ".", "model", "=", "T5ForConditionalGeneration", ".", "from_pretrained", "(", "model_dir", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "xfm_logger", ".", "setLevel", "(", "original_level", ")", "\n", "# End logger ignore warning", "\n", "self", ".", "max_graph_len", "=", "self", ".", "model", ".", "config", ".", "task_specific_params", "[", "'translation_amr_to_text'", "]", "[", "'max_in_len'", "]", "\n", "self", ".", "max_sent_len", "=", "self", ".", "model", ".", "config", ".", "task_specific_params", "[", "'translation_amr_to_text'", "]", "[", "'max_out_len'", "]", "\n", "tokenizer_name", "=", "kwargs", ".", "get", "(", "'tokenizer_name'", ",", "'t5-base'", ")", "# name or path", "\n", "self", ".", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "tokenizer_name", ")", "\n", "self", ".", "seq_ends", "=", "set", "(", "[", "self", ".", "tokenizer", ".", "eos_token_id", ",", "self", ".", "tokenizer", ".", "pad_token_id", "]", ")", "\n", "self", ".", "batch_size", "=", "kwargs", ".", "get", "(", "'batch_size'", ",", "32", ")", "\n", "self", ".", "num_beams", "=", "kwargs", ".", "get", "(", "'num_beams'", ",", "1", ")", "# 1 => greedy", "\n", "self", ".", "num_ret_seq", "=", "kwargs", ".", "get", "(", "'num_ret_seq'", ",", "1", ")", "\n", "if", "self", ".", "num_ret_seq", ">", "self", ".", "num_beams", ":", "\n", "            ", "logger", ".", "warn", "(", "'Need at least as many beams as returned sequences - increasing beam count'", ")", "\n", "self", ".", "num_beams", "=", "self", ".", "num_ret_seq", "\n", "\n", "# Generate sentences from a list of AMR text graphs", "\n", "# For generate params see https://huggingface.co/transformers/master/main_classes/model.html", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.inference.Inference.generate": [[39, 80], ["isinstance", "torch.utils.data.DataLoader", "tqdm.tqdm.tqdm", "stripped_graphs.append", "inference.Inference.tokenizer.batch_encode_plus", "clips.extend", "torch.LongTensor().to", "torch.LongTensor().to", "inference.Inference.model.generate", "sents.extend", "model_input_helper.ModelInputHelper.gstring_to_oneline", "inference.Inference.tokenizer.decode", "model_input_helper.ModelInputHelper().get_tagged_oneline", "torch.LongTensor", "torch.LongTensor", "logger.error", "model_input_helper.ModelInputHelper.gstring_to_oneline", "model_input_helper.ModelInputHelper"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.inference.Inference.generate", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.model_input_helper.ModelInputHelper.gstring_to_oneline", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.model_input_helper.ModelInputHelper.get_tagged_oneline", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.model_input_helper.ModelInputHelper.gstring_to_oneline"], ["# Make sure the user isn't passing in meta-data, only the graph strings", "\n", "stripped_graphs", "=", "[", "]", "\n", "for", "graph", "in", "graphs", ":", "\n", "            ", "meta_lines", ",", "graph_lines", "=", "split_amr_meta", "(", "graph", ")", "\n", "stripped_graphs", ".", "append", "(", "' '", ".", "join", "(", "graph_lines", ")", ")", "\n", "# Loop though batches", "\n", "", "sents", "=", "[", "]", "\n", "clips", "=", "[", "]", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "stripped_graphs", ",", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "for", "batch", "in", "tqdm", "(", "dataloader", ",", "disable", "=", "disable_progress", ")", ":", "\n", "# Form encodings and tokenize", "\n", "            ", "input_text", "=", "[", "'%s'", "%", "graph", "for", "graph", "in", "batch", "]", "\n", "input_encodings", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "input_text", ",", "padding", "=", "True", ",", "\n", "truncation", "=", "True", ",", "max_length", "=", "self", ".", "max_graph_len", ",", "\n", "return_overflowing_tokens", "=", "True", ")", "\n", "# Check if any graphs were truncated (requires return_overflowing_tokens=True)", "\n", "clip", "=", "[", "l", ">", "0", "for", "l", "in", "input_encodings", "[", "'num_truncated_tokens'", "]", "]", "\n", "clips", ".", "extend", "(", "clip", ")", "\n", "# Convert to tensors", "\n", "input_ids", "=", "torch", ".", "LongTensor", "(", "input_encodings", "[", "'input_ids'", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "attention_mask", "=", "torch", ".", "LongTensor", "(", "input_encodings", "[", "'attention_mask'", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "# Generate", "\n", "outs", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "\n", "max_length", "=", "self", ".", "max_sent_len", ",", "early_stopping", "=", "True", ",", "num_beams", "=", "self", ".", "num_beams", ",", "\n", "num_return_sequences", "=", "self", ".", "num_ret_seq", ")", "\n", "outs", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "ids", ",", "skip_special_tokens", "=", "True", ")", "for", "ids", "in", "outs", "]", "\n", "sents", ".", "extend", "(", "outs", ")", "\n", "", "return", "sents", ",", "clips", "\n", "\n", "# When num_ret_seq > 1, additional sentences are appended to the list, after the first", "\n", "# This is a simply extracts a group of them.  The length of the return is self.num_ret_seq", "\n", "", "def", "get_ans_group", "(", "self", ",", "answers", ",", "group_num", ")", ":", "\n", "        ", "return", "answers", "[", "group_num", "*", "self", ".", "num_ret_seq", ":", "(", "group_num", "+", "1", ")", "*", "self", ".", "num_ret_seq", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.inference.Inference.get_ans_group": [[83, 85], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.trainer.AMRDataset.__init__": [[19, 23], ["None"], "methods", ["None"], ["self", ".", "param_fn", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'train_params.json'", ")", "\n", "fast_align", "=", "os", ".", "path", ".", "join", "(", "bin_dir", ",", "'fast_align'", ")", "\n", "atools", "=", "os", ".", "path", ".", "join", "(", "bin_dir", ",", "'atools'", ")", "\n", "p", "=", "{", "}", "\n", "p", "[", "'I'", "]", "=", "kwargs", ".", "get", "(", "'I'", ",", "5", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.trainer.AMRDataset.__len__": [[24, 26], ["len"], "methods", ["None"], ["p", "[", "'q'", "]", "=", "kwargs", ".", "get", "(", "'q'", ",", "0.08", ")", "\n", "p", "[", "'a'", "]", "=", "kwargs", ".", "get", "(", "'a'", ",", "0.01", ")", "\n", "p", "[", "'T'", "]", "=", "kwargs", ".", "get", "(", "'T'", ",", "4", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.trainer.AMRDataset.__getitem__": [[27, 29], ["trainer.AMRDataset.encodings.items"], "methods", ["None"], ["p", "[", "'heuristic'", "]", "=", "kwargs", ".", "get", "(", "'heuristic'", ",", "'grow-diag-final-and'", ")", "\n", "self", ".", "params", "=", "p", "\n", "# Create the actual commands to execute", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.trainer.T2TDataCollator.__call__": [[38, 46], ["torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["\n", "", "def", "train", "(", "self", ")", ":", "\n", "# Run the training", "\n", "        ", "with", "open", "(", "self", ".", "fwd_out", ",", "'w'", ")", "as", "fout", ",", "open", "(", "self", ".", "fwd_err", ",", "'w'", ")", "as", "ferr", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "fwd_cmd", ",", "stdout", "=", "fout", ",", "stderr", "=", "ferr", ")", "\n", "", "with", "open", "(", "self", ".", "rev_out", ",", "'w'", ")", "as", "fout", ",", "open", "(", "self", ".", "rev_err", ",", "'w'", ")", "as", "ferr", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "rev_cmd", ",", "stdout", "=", "fout", ",", "stderr", "=", "ferr", ")", "\n", "", "with", "open", "(", "self", ".", "final_out", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "tools_cmd", ",", "stdout", "=", "fout", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.trainer.Trainer.__init__": [[51, 64], ["transformers.TrainingArguments", "transformers.set_seed"], "methods", ["None"], ["with", "open", "(", "self", ".", "param_fn", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "params", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n", "", "", "def", "read_err", "(", "self", ",", "err", ")", ":", "\n", "        ", "T", ",", "m", "=", "''", ",", "''", "\n", "with", "open", "(", "err", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "# expected target length = source length * N", "\n", "                ", "if", "'expected target length'", "in", "line", ":", "\n", "                    ", "m", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "# final tension: N", "\n", "", "elif", "'final tension'", "in", "line", ":", "\n", "                    ", "T", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "", "", "", "return", "float", "(", "T", ")", ",", "float", "(", "m", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.trainer.Trainer.train": [[65, 95], ["os.makedirs", "print", "transformers.T5Tokenizer.from_pretrained", "transformers.T5ForConditionalGeneration.from_pretrained", "print", "os.path.join", "os.path.join", "transformers.Trainer.Trainer.build_dataset", "print", "transformers.Trainer.Trainer.build_dataset", "print", "print", "transformers.Trainer", "transformers.Trainer.train", "print", "transformers.Trainer.save_model", "len", "len", "len", "len", "transformers.Trainer.T2TDataCollator"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.trainer.Trainer.build_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.trainer.Trainer.build_dataset", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.crossencoder.crossencoder.CrossEncoderRanker.save_model"], ["", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.trainer.Trainer.build_dataset": [[98, 131], ["graph_processing.amr_loading.load_amr_graph_sent", "trainer.Trainer.tokenizer.batch_encode_plus", "trainer.Trainer.tokenizer.batch_encode_plus", "set", "enumerate", "trainer.AMRDataset", "zip", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "set.add", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading.load_amr_graph_sent", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], []], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.model_input_helper.ModelInputHelper.__init__": [[25, 55], ["isinstance", "all", "alignments.rbw_aligner.RBWAligner.from_penman_w_json().get_penman_graph", "copy.deepcopy.metadata.copy", "json.loads", "penman.encode", "model_input_helper.ModelInputHelper.tag", "penman.decode", "isinstance", "graph_processing.annotator.annotate_penman", "penman.surface.alignments", "penman.surface.role_alignments", "copy.deepcopy.epidata.items", "copy.deepcopy", "ValueError", "alignments.rbw_aligner.RBWAligner.from_penman_w_json", "penman.models.noop.NoOpModel", "penman.models.noop.NoOpModel", "isinstance"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.get_penman_graph", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.loads", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.model_input_helper.ModelInputHelper.tag", "home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.annotator.annotate_penman", "home.repos.pwc.inspect_result.chenllliang_atp.rbw_aligner.rbw_aligner.RBWAligner.from_penman_w_json"], ["def", "__init__", "(", "self", ",", "graph", ",", "force_annotate", "=", "False", ")", ":", "\n", "# Convert or copy the input graph to penman format", "\n", "        ", "if", "isinstance", "(", "graph", ",", "str", ")", ":", "\n", "            ", "pgraph", "=", "penman", ".", "decode", "(", "graph", ",", "model", "=", "NoOpModel", "(", ")", ")", "\n", "", "elif", "isinstance", "(", "graph", ",", "penman", ".", "graph", ".", "Graph", ")", ":", "\n", "            ", "pgraph", "=", "deepcopy", "(", "pgraph", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Code requires either a string a penman graph'", ")", "\n", "# Annotate if needed (aligner/tagging require annotation)", "\n", "", "is_annotated", "=", "all", "(", "[", "key", "in", "pgraph", ".", "metadata", "for", "key", "in", "(", "'tokens'", ",", "'lemmas'", ",", "'pos_tags'", ")", "]", ")", "\n", "if", "not", "is_annotated", "or", "force_annotate", ":", "\n", "            ", "sentence", "=", "pgraph", ".", "metadata", "[", "'snt'", "]", "# Sanity check required tag.  Throws KeyError if missing", "\n", "pgraph", "=", "annotate_penman", "(", "pgraph", ")", "\n", "self", ".", "annotation_performed", "=", "True", "# for unit-testing and debug", "\n", "", "else", ":", "\n", "            ", "self", ".", "annotation_performed", "=", "False", "\n", "# Align the graph.  For simplicity, always do this.", "\n", "# If there are existing alignments they need to be removed.", "\n", "# See https://penman.readthedocs.io/en/latest/api/penman.surface.html", "\n", "", "if", "penman", ".", "surface", ".", "alignments", "(", "pgraph", ")", "or", "penman", ".", "surface", ".", "role_alignments", "(", "pgraph", ")", ":", "\n", "            ", "for", "key", ",", "items", "in", "pgraph", ".", "epidata", ".", "items", "(", ")", ":", "\n", "                ", "pgraph", ".", "epidata", "[", "key", "]", "=", "[", "x", "for", "x", "in", "items", "if", "not", "isinstance", "(", "x", ",", "penman", ".", "surface", ".", "AlignmentMarker", ")", "]", "\n", "", "", "pgraph", "=", "RBWAligner", ".", "from_penman_w_json", "(", "pgraph", ")", ".", "get_penman_graph", "(", ")", "\n", "# get the graph string and pos tags for the tagger", "\n", "self", ".", "metadata", "=", "pgraph", ".", "metadata", ".", "copy", "(", ")", "\n", "pos_tags", "=", "json", ".", "loads", "(", "self", ".", "metadata", "[", "'pos_tags'", "]", ")", "\n", "pgraph", ".", "metadata", "=", "{", "}", "\n", "gstring", "=", "penman", ".", "encode", "(", "pgraph", ",", "model", "=", "NoOpModel", "(", ")", ",", "indent", "=", "6", ")", "\n", "# Tag the graph string", "\n", "self", ".", "gstring_tagged", "=", "self", ".", "tag", "(", "gstring", ",", "pos_tags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.model_input_helper.ModelInputHelper.get_tagged_with_meta": [[56, 62], ["model_input_helper.ModelInputHelper.metadata.items"], "methods", ["None"], ["", "def", "get_tagged_with_meta", "(", "self", ")", ":", "\n", "        ", "gstring", "=", "''", "\n", "for", "k", ",", "v", "in", "self", ".", "metadata", ".", "items", "(", ")", ":", "\n", "            ", "gstring", "+=", "'# ::%s %s\\n'", "%", "(", "k", ",", "v", ")", "\n", "", "gstring", "+=", "self", ".", "gstring_tagged", "\n", "return", "gstring", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.model_input_helper.ModelInputHelper.get_tagged_oneline": [[63, 67], ["model_input_helper.ModelInputHelper.gstring_tagged.replace", "re.sub"], "methods", ["None"], ["", "def", "get_tagged_oneline", "(", "self", ")", ":", "\n", "        ", "gstring", "=", "self", ".", "gstring_tagged", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "gstring", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "gstring", ")", "# squeeze multiple spaces into a single", "\n", "return", "gstring", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.model_input_helper.ModelInputHelper.tag": [[69, 86], ["model_input_helper.ModelInputHelper.align_re.finditer", "sorted", "match.group", "int", "sorted.append", "gstring.replace.replace.replace", "len"], "methods", ["None"], ["", "def", "tag", "(", "self", ",", "gstring", ",", "pos_tags", ")", ":", "\n", "# Find all matches and come up with a list of replacements", "\n", "        ", "replacements", "=", "[", "]", "\n", "for", "match", "in", "self", ".", "align_re", ".", "finditer", "(", "gstring", ")", ":", "\n", "#concept   = match.group(1)", "\n", "            ", "align_str", "=", "match", ".", "group", "(", "2", ")", "\n", "# the rbw_aligner should not produce comma separated alignments (it's 1:1)", "\n", "tnum", "=", "int", "(", "align_str", "[", "3", ":", "]", ")", "\n", "tag", "=", "pos_tags", "[", "tnum", "]", "\n", "repl", "=", "'~'", "+", "tag", "\n", "replacements", ".", "append", "(", "(", "align_str", ",", "repl", ")", ")", "# replace ~e.5 with ~NNP", "\n", "# Sort replacements by length so ~e.1 doesn't mess-up ~e.10", "\n", "", "replacements", "=", "sorted", "(", "replacements", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "0", "]", ")", ",", "reverse", "=", "True", ")", "\n", "# Make the replacements", "\n", "for", "(", "orig_str", ",", "new_str", ")", "in", "replacements", ":", "\n", "            ", "gstring", "=", "gstring", ".", "replace", "(", "orig_str", ",", "new_str", ")", "\n", "", "return", "gstring", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.model_input_helper.ModelInputHelper.untag": [[89, 93], ["re.sub"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "untag", "(", "gstring", ")", ":", "\n", "        ", "gstring", "=", "re", ".", "sub", "(", "r'~[A-Z$]+'", ",", "''", ",", "gstring", ")", "\n", "return", "gstring", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.model_input_helper.ModelInputHelper.gstring_to_oneline": [[95, 101], ["graph_processing.amr_loading.split_amr_meta", "re.sub"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.graph_processing.amr_loading.split_amr_meta"], ["", "@", "staticmethod", "\n", "def", "gstring_to_oneline", "(", "gstring", ")", ":", "\n", "        ", "meta_lines", ",", "graph_lines", "=", "split_amr_meta", "(", "gstring", ")", "\n", "gstring", "=", "' '", ".", "join", "(", "graph_lines", ")", "\n", "gstring", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "gstring", ")", "\n", "return", "gstring", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.token_processing": [[14, 28], ["tok.isdigit", "eval", "tok.startswith", "tok.endswith", "tok.endswith", "tok.startswith"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval"], ["penman", ".", "Triple", "(", "'b1'", ",", "':instance'", ",", "'bark-01'", ")", ",", "\n", "penman", ".", "Triple", "(", "'b1'", ",", "':ARG0'", ",", "'d2'", ")", ",", "]", ")", "\n", "\n", "def", "token_processing", "(", "tok", ")", ":", "\n", "    ", "if", "tok", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "elif", "tok", ".", "isdigit", "(", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "eval", "(", "tok", ")", "\n", "", "except", ":", "\n", "            ", "return", "tok", "\n", "", "", "elif", "tok", ".", "startswith", "(", "'\"'", ")", "and", "(", "not", "tok", ".", "endswith", "(", "'\"'", ")", ")", ":", "\n", "        ", "return", "tok", "+", "'\"'", "\n", "", "elif", "tok", ".", "endswith", "(", "'\"'", ")", "and", "(", "not", "tok", ".", "startswith", "(", "'\"'", ")", ")", ":", "\n", "        ", "return", "'\"'", "+", "tok", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.decode_into_node_and_backreferences": [[29, 183], ["re.compile", "re.compile", "zip", "enumerate", "tokenizer.decoder.get", "max", "zip", "postprocessing.token_processing", "tokens.pop", "backreferences.pop", "tokens.append", "backreferences.append", "isinstance", "tokenizer.convert_tokens_to_string().lstrip", "old_tokens.index", "enumerate", "min", "len", "subtok.lstrip", "tokens.append", "backreferences.append", "len", "enumerate", "zip", "isinstance", "re.compile.match", "tokens.append", "backreferences.append", "tokenizer.convert_tokens_to_string", "len", "isinstance", "range", "len", "subtok.lstrip", "re.compile.match", "subtok.startswith", "list", "len", "str", "range", "tokens.append", "backreferences.append", "tokens.append", "backreferences.append", "old_tok.startswith", "len", "str", "len", "subtok.lstrip", "isinstance", "tokens[].startswith", "[].isdigit", "tokens.append", "backreferences.append", "len", "subtok.lstrip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.token_processing"], ["", "else", ":", "\n", "        ", "return", "tok", "\n", "\n", "", "", "def", "decode_into_node_and_backreferences", "(", "subtoken_ids", ",", "tokenizer", ")", ":", "\n", "    ", "rex_arg", "=", "re", ".", "compile", "(", "f\"^{tokenizer.INIT}(op|snt|conj|prep)\"", ")", "\n", "rex_spc", "=", "re", ".", "compile", "(", "r\"<(s|/s|lit|/lit|stop|unk|pad|mask)>\"", ")", "\n", "\n", "# get strings", "\n", "subtokens", "=", "[", "tokenizer", ".", "decoder", ".", "get", "(", "t", ")", "for", "t", "in", "subtoken_ids", "]", "\n", "# fix backreferences", "\n", "subtoken_backreferences", "=", "[", "max", "(", "t", "-", "len", "(", "tokenizer", ".", "encoder", ")", ",", "-", "1", ")", "for", "t", "in", "subtoken_ids", "]", "\n", "# strip padding", "\n", "subtokens", ",", "subtoken_backreferences", "=", "zip", "(", "\n", "*", "[", "(", "s", ",", "b", ")", "for", "s", ",", "b", "in", "zip", "(", "subtokens", ",", "subtoken_backreferences", ")", "if", "s", "!=", "(", "tokenizer", ".", "INIT", "+", "'<pad>'", ")", "]", ")", "\n", "\n", "# subword collapse", "\n", "tokens", "=", "[", "]", "\n", "backreferences", "=", "[", "]", "\n", "subword_to_token_map", "=", "{", "}", "\n", "current_token_i", "=", "0", "\n", "\n", "\n", "\n", "\n", "for", "subw_i", ",", "(", "subw_backr", ",", "subtok", ")", "in", "enumerate", "(", "zip", "(", "subtoken_backreferences", ",", "subtokens", ")", ")", ":", "\n", "        ", "subword_to_token_map", "[", "subw_i", "]", "=", "current_token_i", "\n", "\n", "# if empty you cannot do anything but add a new word", "\n", "if", "not", "tokens", ":", "\n", "            ", "tokens", ".", "append", "(", "subtok", ".", "lstrip", "(", "tokenizer", ".", "INIT", ")", ")", "# '\u0120<s>' -> '<s>'", "\n", "backreferences", ".", "append", "(", "-", "1", ")", "\n", "current_token_i", "+=", "1", "\n", "\n", "# backref can't be splitted", "\n", "# elif subw_backr > -1:", "\n", "#     tokens.append(None)", "\n", "#     backreferences.append(subword_to_token_map[subw_backr])", "\n", "#     current_token_i += 1", "\n", "\n", "# after a special token release", "\n", "", "elif", "isinstance", "(", "tokens", "[", "-", "1", "]", ",", "str", ")", "and", "rex_spc", ".", "match", "(", "tokens", "[", "-", "1", "]", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "subtok", ".", "lstrip", "(", "tokenizer", ".", "INIT", ")", ")", "\n", "backreferences", ".", "append", "(", "-", "1", ")", "\n", "current_token_i", "+=", "1", "\n", "\n", "# after a subtoken ':' (which should be followed by the rest of the edge) ignore tokenizer.INIT", "\n", "# TODO: this is an ugly patch due to the fact that BART tokenizer splits after ':'", "\n", "", "elif", "(", "tokens", "[", "-", "1", "]", "==", "':'", ")", "and", "rex_arg", ".", "match", "(", "subtok", ")", ":", "\n", "            ", "tokens", "[", "-", "1", "]", "=", "tokens", "[", "-", "1", "]", "+", "subtok", "[", "1", ":", "]", "\n", "\n", "# leading tokenizer.INIT", "\n", "", "elif", "subtok", ".", "startswith", "(", "tokenizer", ".", "INIT", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "subtok", ".", "lstrip", "(", "tokenizer", ".", "INIT", ")", ")", "\n", "backreferences", ".", "append", "(", "-", "1", ")", "\n", "current_token_i", "+=", "1", "\n", "\n", "# very ugly patch for some cases in which tokenizer.INIT is not in the following token to the edge", "\n", "", "elif", "isinstance", "(", "tokens", "[", "-", "1", "]", ",", "str", ")", "and", "tokens", "[", "-", "1", "]", ".", "startswith", "(", "':'", ")", "and", "tokens", "[", "-", "1", "]", "[", "-", "1", "]", ".", "isdigit", "(", ")", "and", "(", "subtok", "!=", "'-of'", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "subtok", ".", "lstrip", "(", "tokenizer", ".", "INIT", ")", ")", "\n", "backreferences", ".", "append", "(", "-", "1", ")", "\n", "current_token_i", "+=", "1", "\n", "\n", "# in any other case attach to the previous", "\n", "", "else", ":", "\n", "            ", "tokens", "[", "-", "1", "]", "=", "tokens", "[", "-", "1", "]", "+", "subtok", "\n", "\n", "# strip INIT and fix byte-level", "\n", "", "", "tokens", "=", "[", "tokenizer", ".", "convert_tokens_to_string", "(", "list", "(", "t", ")", ")", ".", "lstrip", "(", ")", "if", "isinstance", "(", "t", ",", "str", ")", "else", "t", "for", "t", "in", "tokens", "]", "\n", "# tokens = [t.replace(tokenizer.INIT, '') if isinstance(t, str) else t for t in tokens]", "\n", "\n", "# unks are substituted with thing", "\n", "tokens", "=", "[", "t", "if", "t", "!=", "'<unk>'", "else", "'thing'", "for", "t", "in", "tokens", "]", "\n", "\n", "old_tokens", "=", "tokens", "\n", "old_backreferences", "=", "backreferences", "\n", "\n", "# <lit> Barack Obama </lit> -> \"Barack Obama\"", "\n", "tokens", "=", "[", "]", "\n", "backreferences", "=", "[", "]", "\n", "token_to_token_map", "=", "{", "}", "\n", "start_search", "=", "0", "\n", "removed", "=", "0", "\n", "while", "True", ":", "\n", "        ", "try", ":", "\n", "\n", "            ", "lit_start", "=", "old_tokens", ".", "index", "(", "'<lit>'", ",", "start_search", ")", "\n", "token_addition", "=", "old_tokens", "[", "start_search", ":", "lit_start", "]", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "token_addition", ",", "start", "=", "start_search", ")", ":", "\n", "                ", "token_to_token_map", "[", "i", "]", "=", "i", "-", "removed", "\n", "", "tokens", "+=", "token_addition", "\n", "\n", "backreferences_addition", "=", "[", "token_to_token_map", "[", "b", "]", "if", "b", ">", "-", "1", "else", "-", "1", "for", "b", "in", "\n", "old_backreferences", "[", "start_search", ":", "lit_start", "]", "]", "\n", "backreferences", "+=", "backreferences_addition", "\n", "\n", "lit_end", "=", "min", "(", "lit_start", "+", "2", ",", "len", "(", "old_tokens", ")", "-", "1", ")", "\n", "\n", "while", "lit_end", "<", "len", "(", "old_tokens", ")", ":", "\n", "                ", "old_tok", "=", "old_tokens", "[", "lit_end", "]", "\n", "\n", "if", "isinstance", "(", "old_tok", ",", "str", ")", "and", "(", "\n", "(", "old_tok", ".", "startswith", "(", "':'", ")", "and", "len", "(", "old_tok", ")", ">", "3", ")", "or", "(", "old_tok", "==", "'<stop>'", ")", ")", ":", "\n", "                    ", "res_tok", "=", "old_tokens", "[", "lit_start", "+", "1", ":", "lit_end", "]", "\n", "for", "i", "in", "range", "(", "lit_start", ",", "lit_end", ")", ":", "\n", "                        ", "token_to_token_map", "[", "i", "]", "=", "len", "(", "tokens", ")", "\n", "\n", "# Remove possible wrong None", "\n", "", "res", "=", "old_tokens", "[", "lit_start", "+", "1", ":", "lit_end", "]", "\n", "res", "=", "[", "str", "(", "r", ")", "for", "r", "in", "res", "if", "r", "is", "not", "None", "]", "\n", "res", "=", "'\"'", "+", "'_'", ".", "join", "(", "res", ")", "+", "'\"'", "\n", "\n", "removed", "+=", "len", "(", "res_tok", ")", "\n", "start_search", "=", "lit_end", "\n", "tokens", "+=", "[", "res", ",", "old_tok", "]", "\n", "backreferences", "+=", "[", "-", "1", ",", "-", "1", "]", "\n", "break", "\n", "\n", "", "elif", "old_tok", "==", "'</lit>'", ":", "\n", "                    ", "res_tok", "=", "old_tokens", "[", "lit_start", "+", "1", ":", "lit_end", "]", "\n", "for", "i", "in", "range", "(", "lit_start", ",", "lit_end", "+", "1", ")", ":", "\n", "                        ", "token_to_token_map", "[", "i", "]", "=", "len", "(", "tokens", ")", "\n", "\n", "# Remove possible wrong None", "\n", "", "res", "=", "old_tokens", "[", "lit_start", "+", "1", ":", "lit_end", "]", "\n", "res", "=", "[", "str", "(", "r", ")", "for", "r", "in", "res", "if", "r", "is", "not", "None", "]", "\n", "res", "=", "'\"'", "+", "'_'", ".", "join", "(", "res", ")", "+", "'\"'", "\n", "\n", "removed", "+=", "len", "(", "res_tok", ")", "+", "1", "\n", "start_search", "=", "lit_end", "+", "1", "\n", "tokens", ".", "append", "(", "res", ")", "\n", "backreferences", ".", "append", "(", "-", "1", ")", "\n", "break", "\n", "\n", "", "else", ":", "\n", "                    ", "lit_end", "+=", "1", "\n", "start_search", "=", "lit_end", "\n", "\n", "", "", "", "except", "ValueError", ":", "\n", "            ", "token_addition", "=", "old_tokens", "[", "start_search", ":", "]", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "token_addition", ",", "start", "=", "start_search", ")", ":", "\n", "                ", "token_to_token_map", "[", "i", "]", "=", "i", "-", "removed", "\n", "", "backreferences_addition", "=", "[", "token_to_token_map", "[", "b", "]", "if", "b", ">", "-", "1", "else", "b", "for", "b", "in", "\n", "old_backreferences", "[", "start_search", ":", "]", "]", "\n", "tokens", "+=", "token_addition", "\n", "backreferences", "+=", "backreferences_addition", "\n", "break", "\n", "\n", "", "", "tokens", "=", "[", "token_processing", "(", "t", ")", "for", "t", "in", "tokens", "]", "\n", "\n", "shift", "=", "1", "\n", "if", "tokens", "[", "1", "]", "==", "'<s>'", ":", "\n", "        ", "shift", "=", "2", "\n", "\n", "", "tokens", "=", "tokens", "[", "shift", ":", "]", "\n", "backreferences", "=", "[", "b", "if", "b", "==", "-", "1", "else", "b", "-", "shift", "for", "b", "in", "backreferences", "[", "shift", ":", "]", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.index_of": [[185, 201], ["callable", "len", "postprocessing.index_of.check"], "function", ["None"], ["if", "tokens", "[", "-", "1", "]", "==", "'</s>'", ":", "\n", "        ", "tokens", ".", "pop", "(", ")", "\n", "backreferences", ".", "pop", "(", ")", "\n", "\n", "", "return", "tokens", ",", "backreferences", "\n", "\n", "\n", "", "def", "index_of", "(", "element", ",", "iterable", ",", "default", "=", "None", ",", "start", "=", "None", ",", "end", "=", "None", ")", ":", "\n", "    ", "if", "not", "callable", "(", "element", ")", ":", "\n", "        ", "def", "check", "(", "x", ")", ":", "\n", "            ", "return", "element", "==", "x", "\n", "", "", "else", ":", "\n", "        ", "check", "=", "element", "\n", "", "if", "start", "is", "None", ":", "\n", "        ", "start", "=", "0", "\n", "", "if", "end", "is", "None", ":", "\n", "        ", "end", "=", "len", "(", "iterable", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.separate_edges_nodes": [[203, 228], ["len", "postprocessing.index_of", "is_arg", "edges.append", "nodes.append", "ret.append", "isinstance", "x.startswith"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.index_of"], ["while", "item", "<", "end", ":", "\n", "        ", "if", "check", "(", "iterable", "[", "item", "]", ")", ":", "\n", "            ", "return", "item", "\n", "", "item", "+=", "1", "\n", "", "return", "default", "\n", "\n", "\n", "", "def", "separate_edges_nodes", "(", "edges_nodes_slice", ",", "*", "other", ")", ":", "\n", "    ", "is_arg", "=", "lambda", "x", ":", "isinstance", "(", "x", ",", "str", ")", "and", "x", ".", "startswith", "(", "':'", ")", "\n", "start", "=", "0", "\n", "edges", "=", "[", "]", "\n", "nodes", "=", "[", "]", "\n", "l", "=", "len", "(", "edges_nodes_slice", ")", "\n", "while", "start", "<", "l", ":", "\n", "        ", "edge_index", "=", "index_of", "(", "\n", "is_arg", ",", "\n", "edges_nodes_slice", ",", "\n", "start", "=", "start", ")", "\n", "if", "edge_index", "is", "None", "or", "edge_index", "==", "(", "l", "-", "1", ")", ":", "\n", "            ", "break", "\n", "", "if", "is_arg", "(", "edges_nodes_slice", "[", "edge_index", "+", "1", "]", ")", ":", "\n", "            ", "start", "=", "edge_index", "+", "1", "\n", "continue", "\n", "", "edges", ".", "append", "(", "edge_index", ")", "\n", "nodes", ".", "append", "(", "edge_index", "+", "1", ")", "\n", "start", "=", "edge_index", "+", "2", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing._split_name_ops": [[229, 264], ["enumerate", "collections.defaultdict", "enumerate", "graph.triples.copy", "collections.defaultdict.items", "penman.Graph", "sorted", "zip", "enumerate", "rel.startswith", "name_vars_to_ops[].append", "tt.append", "isinstance", "lit.split", "str", "penman.Triple", "min", "v2.strip", "int"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["", "ret", "=", "[", "]", "\n", "for", "oth", "in", "other", ":", "\n", "        ", "edges_oth", "=", "[", "oth", "[", "i", "]", "for", "i", "in", "edges", "]", "\n", "nodes_oth", "=", "[", "oth", "[", "i", "]", "for", "i", "in", "nodes", "]", "\n", "ret", ".", "append", "(", "(", "edges_oth", ",", "nodes_oth", ")", ")", "\n", "", "return", "ret", "\n", "\n", "", "def", "_split_name_ops", "(", "graph", ")", ":", "\n", "# identify name triples", "\n", "    ", "name_vars", "=", "{", "}", "\n", "for", "i", ",", "(", "v1", ",", "rel", ",", "v2", ")", "in", "enumerate", "(", "graph", ".", "triples", ")", ":", "\n", "        ", "if", "rel", "==", "':instance'", "and", "v2", "==", "'name'", ":", "\n", "            ", "name_vars", "[", "v1", "]", "=", "1", "\n", "\n", "# check if they have ops", "\n", "", "", "name_vars_to_ops", "=", "defaultdict", "(", "list", ")", "\n", "for", "i", ",", "(", "v1", ",", "rel", ",", "v2", ")", "in", "enumerate", "(", "graph", ".", "triples", ")", ":", "\n", "        ", "if", "v1", "in", "name_vars", "and", "rel", ".", "startswith", "(", "':op'", ")", ":", "\n", "            ", "name_vars_to_ops", "[", "v1", "]", ".", "append", "(", "(", "i", ",", "rel", ",", "v2", ".", "strip", "(", "'\"'", ")", ")", ")", "\n", "\n", "", "", "triples", "=", "graph", ".", "triples", ".", "copy", "(", ")", "\n", "for", "nv", ",", "ops", "in", "name_vars_to_ops", ".", "items", "(", ")", ":", "\n", "        ", "ops", "=", "sorted", "(", "ops", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", "[", "1", "]", "[", "3", ":", "]", ")", ")", "\n", "idx", ",", "_", ",", "lits", "=", "zip", "(", "*", "ops", ")", "\n", "for", "i", "in", "idx", ":", "\n", "            ", "triples", "[", "i", "]", "=", "None", "\n", "\n", "", "lits", "=", "[", "'\"'", "+", "l", "+", "'\"'", "for", "lit", "in", "lits", "for", "l", "in", "lit", ".", "split", "(", "'_'", ")", "]", "\n", "\n", "tt", "=", "[", "]", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "lits", ",", "start", "=", "1", ")", ":", "\n", "            ", "rel", "=", "':op'", "+", "str", "(", "i", ")", "\n", "tt", ".", "append", "(", "penman", ".", "Triple", "(", "nv", ",", "rel", ",", "l", ")", ")", "\n", "\n", "", "triples", "[", "min", "(", "idx", ")", "]", "=", "tt", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing._reconstruct_graph_from_nodes": [[265, 383], ["set", "collections.defaultdict", "penman.Graph", "len", "postprocessing.index_of", "list", "isinstance", "postprocessing.separate_edges_nodes", "zip", "range", "str", "src_node[].lower", "penman.Triple", "penman.Triple", "triples.append", "set.add", "isinstance", "n.startswith", "isinstance", "n.startswith", "n.endswith", "triples.append", "set.add", "len", "len", "e.startswith", "e.startswith", "len", "e.startswith", "re.match", "str", "isinstance", "n.startswith", "n.endswith", "len", "n.replace", "n[].lower", "penman.Triple", "n.startswith", "n.endswith", "triples.append", "set.add", "n.endswith", "n.startswith", "n.replace", "len"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.index_of", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.separate_edges_nodes", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["", "triples", "=", "[", "t", "if", "isinstance", "(", "t", ",", "list", ")", "else", "[", "t", "]", "for", "t", "in", "triples", "if", "t", "is", "not", "None", "]", "\n", "triples", "=", "[", "t", "for", "tt", "in", "triples", "for", "t", "in", "tt", "]", "\n", "\n", "graph_", "=", "penman", ".", "Graph", "(", "triples", ")", "\n", "graph_", ".", "metadata", "=", "graph", ".", "metadata", "\n", "return", "graph_", "\n", "\n", "", "def", "_reconstruct_graph_from_nodes", "(", "nodes", ",", "backreferences", ")", ":", "\n", "    ", "triples", "=", "[", "]", "\n", "triples_added", "=", "set", "(", ")", "\n", "\n", "variable2index", "=", "{", "}", "\n", "index2variable", "=", "{", "}", "\n", "start_index", "=", "0", "\n", "\n", "cnt", "=", "defaultdict", "(", "Counter", ")", "\n", "\n", "while", "start_index", "<", "len", "(", "nodes", ")", ":", "\n", "        ", "stop_index", "=", "index_of", "(", "'<stop>'", ",", "nodes", ",", "default", "=", "len", "(", "nodes", ")", "+", "1", ",", "start", "=", "start_index", ")", "\n", "old_start_index", "=", "start_index", "\n", "start_index", "=", "stop_index", "+", "1", "\n", "\n", "src_node", ",", "src_backr", "=", "nodes", "[", "old_start_index", "]", ",", "backreferences", "[", "old_start_index", "]", "\n", "\n", "if", "src_node", "==", "'<stop>'", ":", "\n", "            ", "continue", "\n", "\n", "", "trg_nodes_edges", "=", "nodes", "[", "old_start_index", ":", "stop_index", "]", "\n", "trg_nodes_edges_backr", "=", "backreferences", "[", "old_start_index", ":", "stop_index", "]", "\n", "trg_nodes_edges_indices", "=", "list", "(", "range", "(", "old_start_index", ",", "stop_index", ")", ")", "\n", "\n", "if", "isinstance", "(", "src_node", ",", "str", ")", ":", "\n", "            ", "if", "src_node", "in", "(", "'<s>'", ",", "'</s>'", ",", "'<stop>'", ")", ":", "\n", "                ", "continue", "\n", "", "elif", "(", "'/'", "in", "src_node", ")", "or", "(", "':'", "in", "src_node", ")", "or", "(", "'('", "in", "src_node", ")", "or", "(", "')'", "in", "src_node", ")", ":", "\n", "                ", "src_node", "=", "'thing'", "\n", "\n", "", "", "if", "src_node", "is", "not", "None", ":", "\n", "            ", "src_node", "=", "str", "(", "src_node", ")", "\n", "src_var", "=", "src_node", "[", "0", "]", ".", "lower", "(", ")", "\n", "if", "not", "src_var", "not", "in", "'abcdefghijklmnopqrstuvwxyz'", ":", "\n", "                ", "src_var", "=", "'x'", "\n", "#src_var = f'{src_var}_{len(variable2index)}'", "\n", "", "src_var", "=", "f'{src_var}{len(variable2index)}'", "\n", "src_var_i", "=", "old_start_index", "\n", "variable2index", "[", "src_var", "]", "=", "src_var_i", "\n", "index2variable", "[", "src_var_i", "]", "=", "src_var", "\n", "triple", "=", "penman", ".", "Triple", "(", "src_var", ",", "':instance'", ",", "src_node", ")", "\n", "if", "triple", "not", "in", "triples_added", ":", "\n", "                ", "triples", ".", "append", "(", "triple", ")", "\n", "triples_added", ".", "add", "(", "triple", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "src_backr", "in", "index2variable", ":", "\n", "                ", "src_var", "=", "index2variable", "[", "src_backr", "]", "\n", "# more resilient logic here", "\n", "", "", "(", "trg_edges", ",", "trg_nodes", ")", ",", "(", "_", ",", "trg_nodes_backr", ")", ",", "(", "_", ",", "trg_nodes_indices", ")", "=", "separate_edges_nodes", "(", "\n", "trg_nodes_edges", ",", "\n", "trg_nodes_edges", ",", "\n", "trg_nodes_edges_backr", ",", "\n", "trg_nodes_edges_indices", ")", "\n", "\n", "for", "n", ",", "e", ",", "nb", ",", "ni", "in", "zip", "(", "trg_nodes", ",", "trg_edges", ",", "trg_nodes_backr", ",", "trg_nodes_indices", ")", ":", "\n", "\n", "            ", "if", "isinstance", "(", "n", ",", "str", ")", "and", "n", ".", "startswith", "(", "':'", ")", ":", "\n", "                ", "continue", "\n", "", "if", "isinstance", "(", "n", ",", "str", ")", "and", "n", ".", "startswith", "(", "'<'", ")", "and", "n", ".", "endswith", "(", "'>'", ")", ":", "\n", "                ", "continue", "\n", "", "if", "e", "==", "':li'", ":", "\n", "                ", "pass", "\n", "", "elif", "len", "(", "e", ")", "<", "4", "or", "(", "not", "e", ".", "startswith", "(", "':'", ")", ")", ":", "\n", "                ", "continue", "\n", "\n", "# same edge more than once", "\n", "", "num", "=", "cnt", "[", "src_var", "]", "[", "e", "]", "\n", "# num = 0", "\n", "if", "num", ":", "\n", "\n", "                ", "if", "e", ".", "startswith", "(", "':op'", ")", "or", "e", ".", "startswith", "(", "':snt'", ")", ":", "\n", "                    ", "continue", "\n", "#elif e.startswith(':ARG'):", "\n", "#    continue", "\n", "", "elif", "num", ">", "3", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "if", "n", "is", "None", ":", "\n", "                ", "if", "nb", "not", "in", "index2variable", ":", "\n", "                    ", "continue", "\n", "", "trg_var", "=", "index2variable", "[", "nb", "]", "\n", "trg", "=", "trg_var", "\n", "", "elif", "e", "==", "':mode'", ":", "\n", "                ", "trg", "=", "n", "\n", "", "elif", "(", "not", "isinstance", "(", "n", ",", "str", ")", ")", "or", "re", ".", "match", "(", "r\"^[+-]?\\d+\\.?\\d*$\"", ",", "n", ")", "or", "(", "n", "==", "'-'", ")", "or", "(", "n", "==", "'+'", ")", ":", "\n", "                ", "trg", "=", "str", "(", "n", ")", "\n", "", "elif", "(", "n", ".", "startswith", "(", "'\"'", ")", "and", "n", ".", "endswith", "(", "'\"'", ")", "and", "len", "(", "n", ")", ">", "2", ")", ":", "\n", "                ", "trg", "=", "'\"'", "+", "n", ".", "replace", "(", "'\"'", ",", "''", ")", "+", "'\"'", "\n", "", "elif", "(", "'/'", "in", "n", ")", "or", "(", "':'", "in", "n", ")", "or", "(", "'('", "in", "n", ")", "or", "(", "')'", "in", "n", ")", "or", "(", "'='", "in", "n", ")", ":", "\n", "                ", "trg", "=", "f'\"{n}\"'", "\n", "", "elif", "n", "==", "'\"'", ":", "\n", "                ", "continue", "\n", "", "elif", "(", "n", ".", "startswith", "(", "'\"'", ")", "and", "(", "not", "n", ".", "endswith", "(", "'\"'", ")", ")", ")", "or", "(", "not", "n", ".", "startswith", "(", "'\"'", ")", "and", "(", "n", ".", "endswith", "(", "'\"'", ")", ")", ")", "or", "(", "'\"'", "in", "n", ")", ":", "\n", "                ", "trg", "=", "'\"'", "+", "n", ".", "replace", "(", "'\"'", ",", "''", ")", "+", "'\"'", "\n", "", "else", ":", "\n", "                ", "trg_var", "=", "n", "[", "0", "]", ".", "lower", "(", ")", "\n", "if", "trg_var", "not", "in", "'abcdefghijklmnopqrstuvwxyz'", ":", "\n", "                    ", "trg_var", "=", "'x'", "\n", "#trg_var = f'{trg_var}_{len(variable2index)}'", "\n", "", "trg_var", "=", "f'{trg_var}{len(variable2index)}'", "\n", "trg_var_i", "=", "ni", "\n", "variable2index", "[", "trg_var", "]", "=", "trg_var_i", "\n", "index2variable", "[", "trg_var_i", "]", "=", "trg_var", "\n", "triple", "=", "penman", ".", "Triple", "(", "trg_var", ",", "':instance'", ",", "n", ")", "\n", "if", "triple", "not", "in", "triples_added", ":", "\n", "                    ", "triples", ".", "append", "(", "triple", ")", "\n", "triples_added", ".", "add", "(", "triple", ")", "\n", "", "trg", "=", "trg_var", "\n", "\n", "", "triple", "=", "penman", ".", "Triple", "(", "src_var", ",", "e", ",", "trg", ")", "\n", "if", "triple", "not", "in", "triples_added", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.build_graph": [[384, 389], ["postprocessing._reconstruct_graph_from_nodes", "postprocessing._split_name_ops"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing._reconstruct_graph_from_nodes", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing._split_name_ops"], ["                ", "triples", ".", "append", "(", "triple", ")", "\n", "triples_added", ".", "add", "(", "triple", ")", "\n", "\n", "", "cnt", "[", "src_var", "]", "[", "e", "]", "+=", "1", "\n", "\n", "", "", "return", "penman", ".", "Graph", "(", "triples", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.connect_graph_if_not_connected": [[395, 428], ["networkx.MultiGraph", "penman.Graph.variables", "penman.Graph.triples.copy", "graph.triples.copy.append", "enumerate", "penman.Graph", "penman.Graph.metadata.update", "penman.encode", "penman.encode", "penman.Triple", "networkx.connected_components", "sorted", "new_triples.append", "nx.MultiGraph.add_edge", "penman.Triple", "nx.MultiGraph.add_edge", "len", "int"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.SemanticGraph.variables", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode"], ["", "return", "graph", "\n", "\n", "", "class", "ParsedStatus", "(", "enum", ".", "Enum", ")", ":", "\n", "    ", "OK", "=", "0", "\n", "FIXED", "=", "1", "\n", "BACKOFF", "=", "2", "\n", "\n", "", "def", "connect_graph_if_not_connected", "(", "graph", ")", ":", "\n", "\n", "    ", "try", ":", "\n", "        ", "encoded", "=", "encode", "(", "graph", ")", "\n", "return", "graph", ",", "ParsedStatus", ".", "OK", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "\n", "", "nxgraph", "=", "nx", ".", "MultiGraph", "(", ")", "\n", "variables", "=", "graph", ".", "variables", "(", ")", "\n", "for", "v1", ",", "_", ",", "v2", "in", "graph", ".", "triples", ":", "\n", "        ", "if", "v1", "in", "variables", "and", "v2", "in", "variables", ":", "\n", "            ", "nxgraph", ".", "add_edge", "(", "v1", ",", "v2", ")", "\n", "", "elif", "v1", "in", "variables", ":", "\n", "            ", "nxgraph", ".", "add_edge", "(", "v1", ",", "v1", ")", "\n", "\n", "", "", "triples", "=", "graph", ".", "triples", ".", "copy", "(", ")", "\n", "new_triples", "=", "[", "]", "\n", "addition", "=", "f'a{len(variables) + 1}'", "\n", "triples", ".", "append", "(", "penman", ".", "Triple", "(", "addition", ",", "':instance'", ",", "'and'", ")", ")", "\n", "for", "i", ",", "conn_set", "in", "enumerate", "(", "nx", ".", "connected_components", "(", "nxgraph", ")", ",", "start", "=", "1", ")", ":", "\n", "        ", "edge", "=", "f':op{i}'", "\n", "conn_set", "=", "sorted", "(", "conn_set", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", "[", "1", ":", "]", ")", ")", "\n", "conn_set", "=", "[", "c", "for", "c", "in", "conn_set", "if", "c", "in", "variables", "]", "\n", "node", "=", "conn_set", "[", "0", "]", "\n", "new_triples", ".", "append", "(", "penman", ".", "Triple", "(", "addition", ",", "edge", ",", "node", ")", ")", "\n", "", "triples", "=", "new_triples", "+", "triples", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.restore_backreferences_from_pointers": [[429, 456], ["isinstance", "n.startswith", "n.endswith", "new_nodes.append", "new_backreferences.append", "new_nodes.append", "new_backreferences.append", "new_nodes.append", "new_backreferences.append", "len", "new_nodes.append", "new_backreferences.append"], "function", ["None"], ["metadata", "=", "graph", ".", "metadata", "\n", "graph", "=", "penman", ".", "Graph", "(", "triples", ")", "\n", "graph", ".", "metadata", ".", "update", "(", "metadata", ")", "\n", "encode", "(", "graph", ")", "\n", "\n", "return", "graph", ",", "ParsedStatus", ".", "FIXED", "\n", "\n", "", "def", "restore_backreferences_from_pointers", "(", "nodes", ")", ":", "\n", "    ", "new_nodes", ",", "new_backreferences", "=", "[", "]", ",", "[", "]", "\n", "prev_pointer", "=", "None", "\n", "pointer2i", "=", "{", "}", "\n", "for", "n", "in", "nodes", ":", "\n", "        ", "is_pointer", "=", "isinstance", "(", "n", ",", "str", ")", "and", "n", ".", "startswith", "(", "'<pointer:'", ")", "and", "n", ".", "endswith", "(", "'>'", ")", "\n", "\n", "if", "not", "is_pointer", ":", "\n", "            ", "if", "prev_pointer", "is", "not", "None", ":", "\n", "                ", "if", "prev_pointer", "in", "pointer2i", ":", "\n", "                    ", "new_nodes", ".", "append", "(", "None", ")", "\n", "new_backreferences", ".", "append", "(", "pointer2i", "[", "prev_pointer", "]", ")", "\n", "new_nodes", ".", "append", "(", "n", ")", "\n", "new_backreferences", ".", "append", "(", "-", "1", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "pointer2i", "[", "prev_pointer", "]", "=", "len", "(", "new_nodes", ")", "\n", "new_nodes", ".", "append", "(", "n", ")", "\n", "new_backreferences", ".", "append", "(", "-", "1", ")", "\n", "", "", "else", ":", "\n", "                ", "new_nodes", ".", "append", "(", "n", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.model_utils.instantiate_model_and_tokenizer": [[10, 87], ["transformers.AutoConfig.from_pretrained", "transformers.BartForConditionalGeneration.from_pretrained", "BartForConditionalGeneration.from_pretrained.resize_token_embeddings", "tokenization_bart.PENMANBartTokenizer.from_pretrained", "tokenization_bart.AMRBartTokenizer.from_pretrained", "len", "AMRBartTokenizer.from_pretrained.encoder.items", "tok.lstrip.lstrip", "AMRBartTokenizer.from_pretrained.encoder.get", "torch.stack().mean", "torch.empty_like", "torch.empty_like.uniform_", "tok.lstrip.startswith", "tok.lstrip.endswith", "tok.lstrip.startswith", "tok.split.append", "tok.split.extend", "BartForConditionalGeneration.from_pretrained.model.shared.weight.data[].clone", "vecs.append", "str", "tok.lstrip.startswith", "AMRBartTokenizer.from_pretrained._tok_bpe", "torch.stack", "[].strip", "tok.lstrip.split", "tok.lstrip.startswith", "tok.lstrip.startswith", "tok.lstrip.split", "str", "tok.lstrip.startswith", "int", "str", "int", "str", "tok.lstrip.lstrip().split", "int", "tok.lstrip.lstrip"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.modeling_bart.AMRBartForConditionalGeneration.resize_token_embeddings", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["def", "instantiate_model_and_tokenizer", "(", "name", "=", "None", ",", "additional_tokens_smart_init", "=", "True", ",", "dropout", "=", "0.15", ",", "\n", "attention_dropout", "=", "0.15", ",", "collapse_name_ops", "=", "False", ",", "penman_linearization", "=", "False", ",", "\n", "use_pointer_tokens", "=", "False", ",", "raw_graph", "=", "False", ")", ":", "\n", "    ", "if", "raw_graph", ":", "\n", "        ", "assert", "penman_linearization", "\n", "", "skip_relations", "=", "False", "\n", "if", "name", "is", "None", ":", "\n", "        ", "name", "=", "'facebook/bart-large'", "\n", "", "if", "name", "==", "'facebook/bart-base'", ":", "\n", "        ", "tokenizer_name", "=", "'facebook/bart-large'", "\n", "", "else", ":", "\n", "        ", "tokenizer_name", "=", "name", "\n", "", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "name", ")", "\n", "config", ".", "output_past", "=", "False", "\n", "config", ".", "no_repeat_ngram_size", "=", "0", "\n", "config", ".", "prefix", "=", "\" \"", "\n", "config", ".", "output_attentions", "=", "True", "\n", "config", ".", "dropout", "=", "dropout", "\n", "config", ".", "attention_dropout", "=", "attention_dropout", "\n", "# Setup the tokenizer", "\n", "if", "penman_linearization", ":", "\n", "        ", "tokenizer", "=", "PENMANBartTokenizer", ".", "from_pretrained", "(", "tokenizer_name", ",", "collapse_name_ops", "=", "collapse_name_ops", ",", "\n", "use_pointer_tokens", "=", "use_pointer_tokens", ",", "raw_graph", "=", "raw_graph", ",", "config", "=", "config", ")", "\n", "", "else", ":", "\n", "        ", "tokenizer", "=", "AMRBartTokenizer", ".", "from_pretrained", "(", "tokenizer_name", ",", "collapse_name_ops", "=", "collapse_name_ops", ",", "\n", "use_pointer_tokens", "=", "use_pointer_tokens", ",", "config", "=", "config", ")", "\n", "# Load the transformers model from the base model (ie.. facebook/bart-large).", "\n", "# if .from_pretrained(model, state_dict=x) is passed the model's state dict it will load those weights", "\n", "# instead of the base model. However, since the emeddings have been resize, the reload has to happen later", "\n", "# or there will be an error.", "\n", "", "model", "=", "BartForConditionalGeneration", ".", "from_pretrained", "(", "name", ",", "config", "=", "config", ")", "\n", "# Add the new AMR specific tokens to the model and modify the embeddings", "\n", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ".", "encoder", ")", ")", "\n", "if", "additional_tokens_smart_init", ":", "\n", "        ", "modified", "=", "0", "\n", "for", "tok", ",", "idx", "in", "tokenizer", ".", "encoder", ".", "items", "(", ")", ":", "\n", "            ", "tok", "=", "tok", ".", "lstrip", "(", "tokenizer", ".", "INIT", ")", "\n", "if", "idx", "<", "tokenizer", ".", "old_enc_size", ":", "\n", "                ", "continue", "\n", "", "elif", "tok", ".", "startswith", "(", "'<pointer:'", ")", "and", "tok", ".", "endswith", "(", "'>'", ")", ":", "\n", "                ", "tok_split", "=", "[", "'pointer'", ",", "str", "(", "tok", ".", "split", "(", "':'", ")", "[", "1", "]", ".", "strip", "(", "'>'", ")", ")", "]", "\n", "", "elif", "tok", ".", "startswith", "(", "'<'", ")", ":", "\n", "                ", "continue", "\n", "", "elif", "tok", ".", "startswith", "(", "':'", ")", ":", "\n", "                ", "if", "skip_relations", ":", "\n", "                    ", "continue", "\n", "", "elif", "tok", ".", "startswith", "(", "':op'", ")", ":", "\n", "                    ", "tok_split", "=", "[", "'relation'", ",", "'operator'", ",", "str", "(", "int", "(", "tok", "[", "3", ":", "]", ")", ")", "]", "\n", "", "elif", "tok", ".", "startswith", "(", "':snt'", ")", ":", "\n", "                    ", "tok_split", "=", "[", "'relation'", ",", "'sentence'", ",", "str", "(", "int", "(", "tok", "[", "4", ":", "]", ")", ")", "]", "\n", "", "elif", "tok", ".", "startswith", "(", "':ARG'", ")", ":", "\n", "                    ", "tok_split", "=", "[", "'relation'", ",", "'argument'", ",", "str", "(", "int", "(", "tok", "[", "4", ":", "]", ")", ")", "]", "\n", "", "else", ":", "\n", "                    ", "tok_split", "=", "[", "'relation'", "]", "+", "tok", ".", "lstrip", "(", "':'", ")", ".", "split", "(", "'-'", ")", "\n", "", "", "else", ":", "\n", "                ", "tok_split", "=", "tok", ".", "split", "(", "'-'", ")", "\n", "", "tok_split_", "=", "tok_split", "\n", "tok_split", "=", "[", "]", "\n", "for", "s", "in", "tok_split_", ":", "\n", "                ", "s_", "=", "s", "+", "tokenizer", ".", "INIT", "\n", "if", "s_", "in", "tokenizer", ".", "encoder", ":", "\n", "                    ", "tok_split", ".", "append", "(", "s_", ")", "\n", "", "else", ":", "\n", "                    ", "tok_split", ".", "extend", "(", "tokenizer", ".", "_tok_bpe", "(", "s", ")", ")", "\n", "", "", "vecs", "=", "[", "]", "\n", "for", "s", "in", "tok_split", ":", "\n", "                ", "idx_split", "=", "tokenizer", ".", "encoder", ".", "get", "(", "s", ",", "-", "1", ")", "\n", "if", "idx_split", ">", "-", "1", ":", "\n", "                    ", "vec_split", "=", "model", ".", "model", ".", "shared", ".", "weight", ".", "data", "[", "idx_split", "]", ".", "clone", "(", ")", "\n", "vecs", ".", "append", "(", "vec_split", ")", "\n", "", "", "if", "vecs", ":", "\n", "                ", "vec", "=", "torch", ".", "stack", "(", "vecs", ",", "0", ")", ".", "mean", "(", "0", ")", "\n", "noise", "=", "torch", ".", "empty_like", "(", "vec", ")", "\n", "noise", ".", "uniform_", "(", "-", "0.1", ",", "+", "0.1", ")", "\n", "model", ".", "model", ".", "shared", ".", "weight", ".", "data", "[", "idx", "]", "=", "vec", "+", "noise", "\n", "modified", "+=", "1", "\n", "", "", "", "return", "model", ",", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.model_utils.load_state_dict_from_checkpoint": [[90, 97], ["torch.load", "model.load_state_dict", "optimizer.load_state_dict", "scheduler.load_state_dict"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["", "def", "load_state_dict_from_checkpoint", "(", "checkpoint_fn", ",", "model", ",", "optimizer", "=", "None", ",", "scheduler", "=", "None", ")", ":", "\n", "    ", "model_dict", "=", "torch", ".", "load", "(", "checkpoint_fn", ",", "map_location", "=", "'cpu'", ")", "\n", "model", ".", "load_state_dict", "(", "model_dict", "[", "'model'", "]", ")", "\n", "if", "optimizer", "is", "not", "None", "and", "'optimizer'", "in", "model_dict", ":", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "model_dict", "[", "'optimizer'", "]", ")", "\n", "", "if", "scheduler", "is", "not", "None", "and", "'scheduler'", "in", "model_dict", ":", "\n", "        ", "scheduler", ".", "load_state_dict", "(", "model_dict", "[", "'scheduler'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.model_utils.get_dataloader": [[100, 106], ["amr_rw.read_raw_amr_data", "dataset.AMRDataset", "dataset.AMRDatasetTokenBatcherAndLoader"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.amr_rw.read_raw_amr_data"], ["", "", "def", "get_dataloader", "(", "tokenizer", ",", "glob_pattern", ",", "batch_size", "=", "500", ",", "evaluation", "=", "True", ",", "use_recategorization", "=", "False", ",", "\n", "remove_longer_than", "=", "None", ",", "remove_wiki", "=", "False", ",", "dereify", "=", "True", ",", "device", "=", "'cpu'", ")", ":", "\n", "    ", "graphs", "=", "read_raw_amr_data", "(", "glob_pattern", ",", "use_recategorization", ",", "remove_wiki", "=", "remove_wiki", ",", "dereify", "=", "dereify", ")", "\n", "dataset", "=", "AMRDataset", "(", "tokenizer", ",", "graphs", ",", "remove_longer_than", "=", "remove_longer_than", ")", "\n", "loader", "=", "AMRDatasetTokenBatcherAndLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "not", "evaluation", ",", "device", "=", "device", ")", "\n", "return", "loader", "\n", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.__init__": [[17, 34], ["logging.getLogger().setLevel", "torch.device", "kwargs.get", "kwargs.get", "penman.models.amr.model.to", "torch.cuda.is_available", "kwargs.get", "inference.Inference.load_model", "logging.getLogger", "ValueError"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.load_model"], ["xfm_logger", "=", "logging", ".", "getLogger", "(", "'transformers.modeling_utils'", ")", "\n", "original_level", "=", "xfm_logger", ".", "getEffectiveLevel", "(", ")", "\n", "xfm_logger", ".", "setLevel", "(", "logging", ".", "ERROR", ")", "\n", "self", ".", "model", "=", "T5ForConditionalGeneration", ".", "from_pretrained", "(", "model_dir", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "xfm_logger", ".", "setLevel", "(", "original_level", ")", "\n", "# End logger ignore warning", "\n", "self", ".", "max_graph_len", "=", "self", ".", "model", ".", "config", ".", "task_specific_params", "[", "'translation_amr_to_text'", "]", "[", "'max_in_len'", "]", "\n", "self", ".", "max_sent_len", "=", "self", ".", "model", ".", "config", ".", "task_specific_params", "[", "'translation_amr_to_text'", "]", "[", "'max_out_len'", "]", "\n", "tokenizer_name", "=", "kwargs", ".", "get", "(", "'tokenizer_name'", ",", "'t5-base'", ")", "# name or path", "\n", "self", ".", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "tokenizer_name", ")", "\n", "self", ".", "seq_ends", "=", "set", "(", "[", "self", ".", "tokenizer", ".", "eos_token_id", ",", "self", ".", "tokenizer", ".", "pad_token_id", "]", ")", "\n", "self", ".", "batch_size", "=", "kwargs", ".", "get", "(", "'batch_size'", ",", "32", ")", "\n", "self", ".", "num_beams", "=", "kwargs", ".", "get", "(", "'num_beams'", ",", "1", ")", "# 1 => greedy", "\n", "self", ".", "num_ret_seq", "=", "kwargs", ".", "get", "(", "'num_ret_seq'", ",", "1", ")", "\n", "if", "self", ".", "num_ret_seq", ">", "self", ".", "num_beams", ":", "\n", "            ", "logger", ".", "warn", "(", "'Need at least as many beams as returned sequences - increasing beam count'", ")", "\n", "self", ".", "num_beams", "=", "self", ".", "num_ret_seq", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.load_model": [[36, 46], ["model_utils.instantiate_model_and_tokenizer", "model_utils.load_state_dict_from_checkpoint", "open", "json.load", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.model_utils.instantiate_model_and_tokenizer", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.model_utils.load_state_dict_from_checkpoint", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], ["# For generate params see https://huggingface.co/transformers/master/main_classes/model.html", "\n", "", "", "def", "generate", "(", "self", ",", "graphs", ",", "disable_progress", "=", "True", ")", ":", "\n", "        ", "assert", "isinstance", "(", "graphs", ",", "list", ")", "\n", "# Make sure the user isn't passing in meta-data, only the graph strings", "\n", "stripped_graphs", "=", "[", "]", "\n", "for", "graph", "in", "graphs", ":", "\n", "            ", "meta_lines", ",", "graph_lines", "=", "split_amr_meta", "(", "graph", ")", "\n", "stripped_graphs", ".", "append", "(", "' '", ".", "join", "(", "graph_lines", ")", ")", "\n", "# Loop though batches", "\n", "", "sents", "=", "[", "]", "\n", "clips", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_sents": [[48, 83], ["isinstance", "torch.utils.data.DataLoader", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm.close", "inference.Inference.tokenizer.batch_encode_sentences", "zip", "tqdm.tqdm.tqdm.update", "penman.encode", "len", "torch.no_grad", "inference.Inference.model.generate", "len", "len", "inference.Inference.tokenizer.decode_amr", "gen_graphs.append", "len", "tokk.tolist"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_sentences", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode", "home.repos.pwc.inspect_result.chenllliang_atp.generate_t5wtense.inference.Inference.generate", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer.decode_amr"], ["for", "batch", "in", "tqdm", "(", "dataloader", ",", "disable", "=", "disable_progress", ")", ":", "\n", "# Form encodings and tokenize", "\n", "            ", "input_text", "=", "[", "'%s'", "%", "graph", "for", "graph", "in", "batch", "]", "\n", "input_encodings", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "input_text", ",", "padding", "=", "True", ",", "\n", "truncation", "=", "True", ",", "max_length", "=", "self", ".", "max_graph_len", ",", "\n", "return_overflowing_tokens", "=", "True", ")", "\n", "# Check if any graphs were truncated (requires return_overflowing_tokens=True)", "\n", "clip", "=", "[", "l", ">", "0", "for", "l", "in", "input_encodings", "[", "'num_truncated_tokens'", "]", "]", "\n", "clips", ".", "extend", "(", "clip", ")", "\n", "# Convert to tensors", "\n", "input_ids", "=", "torch", ".", "LongTensor", "(", "input_encodings", "[", "'input_ids'", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "attention_mask", "=", "torch", ".", "LongTensor", "(", "input_encodings", "[", "'attention_mask'", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "# Generate", "\n", "outs", "=", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "\n", "max_length", "=", "self", ".", "max_sent_len", ",", "early_stopping", "=", "True", ",", "num_beams", "=", "self", ".", "num_beams", ",", "\n", "num_return_sequences", "=", "self", ".", "num_ret_seq", ")", "\n", "outs", "=", "[", "self", ".", "tokenizer", ".", "decode", "(", "ids", ",", "skip_special_tokens", "=", "True", ")", "for", "ids", "in", "outs", "]", "\n", "sents", ".", "extend", "(", "outs", ")", "\n", "", "return", "sents", ",", "clips", "\n", "\n", "# When num_ret_seq > 1, additional sentences are appended to the list, after the first", "\n", "# This is a simply extracts a group of them.  The length of the return is self.num_ret_seq", "\n", "", "def", "get_ans_group", "(", "self", ",", "answers", ",", "group_num", ")", ":", "\n", "        ", "return", "answers", "[", "group_num", "*", "self", ".", "num_ret_seq", ":", "(", "group_num", "+", "1", ")", "*", "self", ".", "num_ret_seq", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_spans": [[85, 89], ["inference.Inference.parse_sents", "s.text.strip"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_sents"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.__init__": [[28, 37], ["transformers.BartTokenizer.__init__", "regex.compile", "linearization.AMRLinearizer", "set"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["AMRTokens", ".", "LIT_END", ",", "\n", "AMRTokens", ".", "BACKR_SRC_N", ",", "\n", "AMRTokens", ".", "BACKR_TRG_N", ",", "]", "\n", "\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "use_pointer_tokens", "=", "False", ",", "collapse_name_ops", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "patterns", "=", "re", ".", "compile", "(", "\n", "r\"\"\" ?<[a-z]+:?\\d*>| ?:[^\\s]+|'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"", ")", "\n", "self", ".", "linearizer", "=", "AMRLinearizer", "(", "use_pointer_tokens", "=", "use_pointer_tokens", ",", "collapse_name_ops", "=", "collapse_name_ops", ")", "\n", "self", ".", "use_pointer_tokens", "=", "use_pointer_tokens", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained": [[38, 43], ["super().from_pretrained", "super().from_pretrained.init_amr_vocabulary"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.from_pretrained", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.init_amr_vocabulary"], ["self", ".", "collapse_name_ops", "=", "collapse_name_ops", "\n", "self", ".", "recategorizations", "=", "set", "(", ")", "\n", "self", ".", "modified", "=", "0", "\n", "\n", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_path", ",", "pred_min", "=", "5", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.init_amr_vocabulary": [[44, 85], ["pathlib.Path().read_text().strip().splitlines", "pathlib.Path().read_text().strip().splitlines", "pathlib.Path().read_text().strip().splitlines", "len", "enumerate", "len", "line.split", "tokens.append", "tokens.append", "range", "pathlib.Path().read_text().strip", "int", "tokens.append", "pathlib.Path().read_text().strip", "pathlib.Path().read_text().strip", "tok.startswith", "tokenization_bart.AMRBartTokenizer.recategorizations.add", "tokens.append", "enumerate", "sorted", "sorted", "tokenization_bart.AMRBartTokenizer.encoder.items", "pathlib.Path().read_text", "pathlib.Path().read_text", "pathlib.Path().read_text", "tokenization_bart.AMRBartTokenizer.encoder.items", "pathlib.Path", "pathlib.Path", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["        ", "inst", "=", "super", "(", ")", ".", "from_pretrained", "(", "pretrained_model_path", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "inst", ".", "init_amr_vocabulary", "(", "pred_min", "=", "pred_min", ")", "\n", "return", "inst", "\n", "\n", "", "def", "init_amr_vocabulary", "(", "self", ",", "pred_min", "=", "5", ")", ":", "\n", "        ", "for", "tok", "in", "[", "self", ".", "bos_token", ",", "self", ".", "eos_token", ",", "self", ".", "pad_token", ",", "'<mask>'", ",", "'<unk>'", "]", ":", "\n", "            ", "ntok", "=", "self", ".", "INIT", "+", "tok", "\n", "i", "=", "self", ".", "encoder", "[", "tok", "]", "\n", "self", ".", "decoder", "[", "i", "]", "=", "ntok", "\n", "del", "self", ".", "encoder", "[", "tok", "]", "\n", "self", ".", "encoder", "[", "ntok", "]", "=", "i", "\n", "\n", "", "tokens", "=", "[", "]", "\n", "for", "line", "in", "Path", "(", "ROOT", "/", "'data/vocab/predicates.txt'", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "tok", ",", "count", "=", "line", ".", "split", "(", ")", "\n", "if", "int", "(", "count", ")", ">=", "pred_min", ":", "\n", "                ", "tokens", ".", "append", "(", "tok", ")", "\n", "\n", "# add your vocab for one pretrain_task        ", "\n", "", "", "for", "tok", "in", "Path", "(", "\"../vocabs/dp_edges.txt\"", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "tok", ")", "\n", "\n", "", "for", "tok", "in", "Path", "(", "ROOT", "/", "'data/vocab/additions.txt'", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "tok", ")", "\n", "\n", "", "for", "tok", "in", "Path", "(", "ROOT", "/", "'data/vocab/recategorizations.txt'", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "if", "not", "tok", ".", "startswith", "(", "'_'", ")", ":", "\n", "                ", "self", ".", "recategorizations", ".", "add", "(", "tok", ")", "\n", "", "tokens", ".", "append", "(", "tok", ")", "\n", "\n", "", "if", "self", ".", "use_pointer_tokens", ":", "\n", "            ", "for", "cnt", "in", "range", "(", "512", ")", ":", "\n", "                ", "tokens", ".", "append", "(", "f\"<pointer:{cnt}>\"", ")", "\n", "\n", "", "", "tokens", "+=", "self", ".", "ADDITIONAL", "\n", "# HACK #", "\n", "# tokens += [self.INIT +\"S\",self.INIT +\"D\",self.INIT +\"A\"]", "\n", "\n", "self", ".", "add_special_tokens", "(", "{", "\"additional_special_tokens\"", ":", "[", "\"<amr>\"", ",", "\"<dp>\"", ",", "\"<srl>\"", "]", "}", ")", "\n", "\n", "\n", "tokens", "=", "[", "self", ".", "INIT", "+", "t", "if", "t", "[", "0", "]", "not", "in", "(", "'_'", ",", "'-'", ")", "else", "t", "for", "t", "in", "tokens", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.build_inputs_with_special_tokens": [[86, 91], ["None"], "methods", ["None"], ["tokens", "=", "[", "t", "for", "t", "in", "tokens", "if", "t", "not", "in", "self", ".", "encoder", "]", "\n", "self", ".", "old_enc_size", "=", "old_enc_size", "=", "len", "(", "self", ".", "encoder", ")", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "tokens", ",", "start", "=", "old_enc_size", ")", ":", "\n", "            ", "self", ".", "encoder", "[", "t", "]", "=", "i", "\n", "\n", "", "self", ".", "encoder", "=", "{", "k", ":", "i", "for", "i", ",", "(", "k", ",", "v", ")", "in", "enumerate", "(", "sorted", "(", "self", ".", "encoder", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ")", "}", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tokenize": [[92, 108], ["text.lstrip().split", "tok_span.strip.strip.strip", "tok_span.strip.strip.rsplit", "text.lstrip", "bpe_tokens.extend", "regex.findall", "len", "bpe_tokens.extend", "token.encode", "tokenization_bart.AMRBartTokenizer.bpe().split", "tokenization_bart.AMRBartTokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "sorted", "(", "self", ".", "encoder", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "}", "\n", "self", ".", "modified", "=", "len", "(", "tokens", ")", "\n", "\n", "self", ".", "bos_token", "=", "self", ".", "INIT", "+", "'<s>'", "\n", "self", ".", "pad_token", "=", "self", ".", "INIT", "+", "'<pad>'", "\n", "self", ".", "eos_token", "=", "self", ".", "INIT", "+", "'</s>'", "\n", "self", ".", "unk_token", "=", "self", ".", "INIT", "+", "'<unk>'", "\n", "\n", "", "def", "build_inputs_with_special_tokens_multi_task", "(", "self", ",", "type_token", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "output", "=", "[", "self", ".", "bos_token_id", "]", "+", "[", "type_token", "]", "+", "token_ids_0", "+", "[", "self", ".", "eos_token_id", "]", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "output", "\n", "", "return", "output", "+", "[", "self", ".", "eos_token_id", "]", "+", "token_ids_1", "+", "[", "self", ".", "eos_token_id", "]", "\n", "\n", "", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "output", "=", "[", "self", ".", "bos_token_id", "]", "+", "token_ids_0", "+", "[", "self", ".", "eos_token_id", "]", "\n", "if", "token_ids_1", "is", "None", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe": [[109, 124], ["token.strip", "token.strip.rsplit", "tokk.extend", "tokenization_bart.AMRBartTokenizer.patterns.findall", "len", "tokenization_bart.AMRBartTokenizer.bpe().split", "tokk.extend", "tokenization_bart.AMRBartTokenizer.bpe", "token.strip.encode"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode"], ["            ", "return", "output", "\n", "", "return", "output", "+", "[", "self", ".", "eos_token_id", "]", "+", "token_ids_1", "+", "[", "self", ".", "eos_token_id", "]", "\n", "\n", "", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. Modified in order to handle sentences with recategorization pointers\"\"\"", "\n", "bpe_tokens", "=", "[", "]", "\n", "for", "tok_span", "in", "text", ".", "lstrip", "(", ")", ".", "split", "(", "' '", ")", ":", "\n", "            ", "tok_span", "=", "tok_span", ".", "strip", "(", ")", "\n", "recats", "=", "tok_span", ".", "rsplit", "(", "'_'", ",", "1", ")", "\n", "if", "len", "(", "recats", ")", "==", "2", "and", "recats", "[", "0", "]", "in", "self", ".", "recategorizations", "and", "(", "'_'", "+", "recats", "[", "1", "]", ")", "in", "self", ".", "encoder", ":", "\n", "                ", "bpe_tokens", ".", "extend", "(", "[", "self", ".", "INIT", "+", "recats", "[", "0", "]", ",", "'_'", "+", "recats", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "for", "token", "in", "re", ".", "findall", "(", "self", ".", "pat", ",", "' '", "+", "tok_span", ")", ":", "\n", "                    ", "token", "=", "\"\"", ".", "join", "(", "\n", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "\"utf-8\"", ")", "\n", ")", "# Maps all our bytes to unicode strings, avoiding controle tokens of the BPE (spaces in our case)", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._get_nodes_and_backreferences": [[125, 129], ["tokenization_bart.AMRBartTokenizer.linearizer.linearize"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer.linearize"], ["bpe_tokens", ".", "extend", "(", "bpe_token", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "\" \"", ")", ")", "\n", "\n", "", "", "", "return", "bpe_tokens", "\n", "\n", "", "def", "_tok_bpe", "(", "self", ",", "token", ",", "add_space", "=", "True", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.tokenize_amr": [[130, 185], ["tokenization_bart.AMRBartTokenizer._get_nodes_and_backreferences", "enumerate", "zip", "bpe_tokens.append", "tokenization_bart.AMRBartTokenizer.encoder.get", "tokk[].replace.startswith", "tokk[].replace.startswith", "tokk[].replace.endswith", "tokk[].replace.startswith", "tokk[].replace.endswith", "regex.match", "tokk[].replace.startswith", "tokk[].replace.endswith", "tokk[].replace", "tokenization_bart.AMRBartTokenizer._tok_bpe", "tokenization_bart.AMRBartTokenizer.append", "list", "len", "bpe_backreferences.append", "bpe_backreferences.append", "len", "range", "tokenization_bart.AMRBartTokenizer._tok_bpe", "len", "tokenization_bart.AMRBartTokenizer._tok_bpe", "tokenization_bart.AMRBartTokenizer._tok_bpe", "tokenization_bart.AMRBartTokenizer._tok_bpe"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer._get_nodes_and_backreferences", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tok_bpe"], ["# if add_space:", "\n", "#     token = ' ' + token.lstrip()", "\n", "        ", "tokk", "=", "[", "]", "\n", "tok", "=", "token", ".", "strip", "(", ")", "\n", "recats", "=", "tok", ".", "rsplit", "(", "'_'", ",", "1", ")", "\n", "if", "len", "(", "recats", ")", "==", "2", "and", "recats", "[", "0", "]", "in", "self", ".", "recategorizations", "and", "(", "'_'", "+", "recats", "[", "1", "]", ")", "in", "self", ".", "encoder", ":", "\n", "            ", "tokk", ".", "extend", "(", "[", "self", ".", "INIT", "+", "recats", "[", "0", "]", ",", "'_'", "+", "recats", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "for", "tok", "in", "self", ".", "patterns", ".", "findall", "(", "' '", "+", "token", ")", ":", "\n", "                ", "tok", "=", "\"\"", ".", "join", "(", "\n", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "tok", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "toks", "=", "self", ".", "bpe", "(", "tok", ")", ".", "split", "(", "' '", ")", "\n", "tokk", ".", "extend", "(", "toks", ")", "\n", "", "", "return", "tokk", "\n", "\n", "", "def", "_get_nodes_and_backreferences", "(", "self", ",", "graph", ")", ":", "\n", "        ", "lin", "=", "self", ".", "linearizer", ".", "linearize", "(", "graph", ")", "\n", "linearized_nodes", ",", "backreferences", "=", "lin", ".", "nodes", ",", "lin", ".", "backreferences", "\n", "return", "linearized_nodes", ",", "backreferences", "\n", "\n", "", "def", "tokenize_amr", "(", "self", ",", "graph", ")", ":", "\n", "        ", "linearized_nodes", ",", "backreferences", "=", "self", ".", "_get_nodes_and_backreferences", "(", "graph", ")", "\n", "\n", "bpe_tokens", "=", "[", "]", "\n", "bpe_backreferences", "=", "[", "]", "\n", "counter", "=", "0", "\n", "\n", "for", "i", ",", "(", "backr", ",", "tokk", ")", "in", "enumerate", "(", "zip", "(", "backreferences", ",", "linearized_nodes", ")", ")", ":", "\n", "            ", "is_in_enc", "=", "self", ".", "INIT", "+", "tokk", "in", "self", ".", "encoder", "\n", "is_rel", "=", "tokk", ".", "startswith", "(", "':'", ")", "and", "len", "(", "tokk", ")", ">", "1", "\n", "is_spc", "=", "tokk", ".", "startswith", "(", "'<'", ")", "and", "tokk", ".", "endswith", "(", "'>'", ")", "\n", "is_of", "=", "tokk", ".", "startswith", "(", "':'", ")", "and", "tokk", ".", "endswith", "(", "'-of'", ")", "\n", "is_frame", "=", "re", ".", "match", "(", "r'.+-\\d\\d'", ",", "tokk", ")", "is", "not", "None", "\n", "\n", "if", "tokk", ".", "startswith", "(", "'\"'", ")", "and", "tokk", ".", "endswith", "(", "'\"'", ")", ":", "\n", "                ", "tokk", "=", "tokk", "[", "1", ":", "-", "1", "]", ".", "replace", "(", "'_'", ",", "' '", ")", "\n", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "AMRTokens", ".", "LIT_START", "]", "\n", "bpe_toks", "+=", "self", ".", "_tok_bpe", "(", "tokk", ",", "add_space", "=", "True", ")", "\n", "bpe_toks", ".", "append", "(", "self", ".", "INIT", "+", "AMRTokens", ".", "LIT_END", ")", "\n", "\n", "", "elif", "(", "is_rel", "or", "is_spc", "or", "is_frame", "or", "is_of", ")", ":", "\n", "                ", "if", "is_in_enc", ":", "\n", "                    ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "tokk", "]", "\n", "", "elif", "is_frame", ":", "\n", "                    ", "bpe_toks", "=", "self", ".", "_tok_bpe", "(", "tokk", "[", ":", "-", "3", "]", ",", "add_space", "=", "True", ")", "+", "[", "tokk", "[", "-", "3", ":", "]", "]", "\n", "", "elif", "is_of", ":", "\n", "                    ", "rel", "=", "tokk", "[", ":", "-", "3", "]", "\n", "if", "self", ".", "INIT", "+", "rel", "in", "self", ".", "encoder", ":", "\n", "                        ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "rel", ",", "'-of'", "]", "\n", "", "else", ":", "\n", "                        ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "':'", "]", "+", "self", ".", "_tok_bpe", "(", "rel", "[", "1", ":", "]", ",", "add_space", "=", "True", ")", "+", "[", "'-of'", "]", "\n", "", "", "elif", "is_rel", ":", "\n", "                    ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "':'", "]", "+", "self", ".", "_tok_bpe", "(", "tokk", "[", "1", ":", "]", ",", "add_space", "=", "True", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_sentences": [[186, 192], ["torch.device", "super().batch_encode_plus", "v.to", "super().batch_encode_plus.items"], "methods", ["None"], ["", "", "else", ":", "\n", "                ", "if", "is_in_enc", ":", "\n", "                    ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "tokk", "]", "\n", "", "else", ":", "\n", "                    ", "bpe_toks", "=", "self", ".", "_tok_bpe", "(", "tokk", ",", "add_space", "=", "True", ")", "\n", "\n", "", "", "bpe_tokens", ".", "append", "(", "bpe_toks", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.linearize": [[193, 205], ["len", "tokenization_bart.AMRBartTokenizer.tokenize_amr", "tokens.append", "token_ids.append", "token_uni_ids.append", "backreferences.append", "enumerate", "len", "zip"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer.tokenize_amr"], ["\n", "if", "i", "==", "backr", ":", "\n", "                ", "bpe_backr", "=", "list", "(", "range", "(", "counter", ",", "counter", "+", "len", "(", "bpe_toks", ")", ")", ")", "\n", "counter", "+=", "len", "(", "bpe_toks", ")", "\n", "bpe_backreferences", ".", "append", "(", "bpe_backr", ")", "\n", "", "else", ":", "\n", "                ", "bpe_backreferences", ".", "append", "(", "bpe_backreferences", "[", "backr", "]", "[", "0", ":", "1", "]", ")", "\n", "counter", "+=", "1", "\n", "", "", "bpe_tokens", "=", "[", "b", "for", "bb", "in", "bpe_tokens", "for", "b", "in", "bb", "]", "\n", "bpe_token_ids", "=", "[", "self", ".", "encoder", ".", "get", "(", "b", ",", "self", ".", "unk_token_id", ")", "for", "b", "in", "bpe_tokens", "]", "\n", "bpe_backreferences", "=", "[", "b", "for", "bb", "in", "bpe_backreferences", "for", "b", "in", "bb", "]", "\n", "return", "bpe_tokens", ",", "bpe_token_ids", ",", "bpe_backreferences", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_graphs": [[206, 209], ["torch.device", "zip", "tokenization_bart.AMRBartTokenizer.batch_encode_graphs_from_linearized", "tokenization_bart.AMRBartTokenizer.linearize"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_graphs_from_linearized", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer.linearize"], ["", "def", "tokenize_dp", "(", "self", ",", "dp", ")", ":", "\n", "# (  ROOT  :root  (  introduced  :nsubj  (  members  :amod  Influential  :prep  (  of  :pobj  (  Ways  :det  the  :nn  House  :cc  and  :conj  (  Committee  :nn  Means  )  )  )  )  :dobj  (  legislation  :rcmod  (  restrict  :nsubj  that  :aux  would  :ccomp  (  raise  :advmod  how  :nsubj  (  agency  :det  the  :amod  new  :nn  savings-and-loan  :nn  bailout  )  :aux  can  :dobj  capital  )  :punct  ,  :xcomp  (  creating  :dobj  (  obstacle  :det  another  :amod  potential  :prep  (  to  :pobj  (  sale  :poss  (  government  :det  the  :possessive  's  )  :prep  (  of  :pobj  (  thrifts  :amod  sick  )  )  )  )  )  )  )  )  :punct  .  )  ) ", "\n", "        ", "snt", "=", "[", "]", "\n", "for", "i", "in", "dp", ".", "split", "(", "\" \"", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_graphs_from_linearized": [[210, 229], ["torch.device", "torch.tensor().to", "max", "torch.tensor().to.append", "batch[].contiguous", "batch[].contiguous", "batch_extra[].append", "batch_extra[].append", "len", "torch.tensor", "len"], "methods", ["None"], ["            ", "if", "i", "in", "dp_edges", ":", "\n", "                ", "assert", "self", ".", "INIT", "+", "i", "in", "self", ".", "encoder", "\n", "snt", "+=", "[", "self", ".", "INIT", "+", "i", "]", "\n", "", "elif", "self", ".", "INIT", "+", "i", "in", "self", ".", "encoder", ":", "\n", "                ", "snt", "+=", "[", "self", ".", "INIT", "+", "i", "]", "\n", "", "else", ":", "\n", "                ", "snt", "+=", "self", ".", "_tok_bpe", "(", "i", ")", "\n", "\n", "", "", "snt", "=", "snt", "[", ":", "-", "1", "]", "\n", "snt", "=", "[", "self", ".", "INIT", "+", "'<s>'", "]", "+", "snt", "+", "[", "self", ".", "INIT", "+", "'</s>'", "]", "\n", "snt_ids", "=", "self", ".", "convert_tokens_to_ids", "(", "snt", ")", "\n", "assert", "len", "(", "snt", ")", "==", "len", "(", "snt_ids", ")", "\n", "return", "snt_ids", ",", "snt", "\n", "\n", "", "def", "batch_encode_sentences", "(", "self", ",", "sentences", ",", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", ":", "\n", "        ", "sentences", "=", "[", "s", "for", "s", "in", "sentences", "]", "\n", "extra", "=", "{", "'sentences'", ":", "sentences", "}", "\n", "batch", "=", "super", "(", ")", ".", "batch_encode_plus", "(", "sentences", ",", "return_tensors", "=", "'pt'", ",", "pad_to_max_length", "=", "True", ")", "\n", "batch", "=", "{", "k", ":", "v", ".", "to", "(", "device", ")", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", "}", "\n", "return", "batch", ",", "extra", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.decode_amr": [[230, 251], ["postprocessing.decode_into_node_and_backreferences", "postprocessing.restore_backreferences_from_pointers", "postprocessing.build_graph", "postprocessing.connect_graph_if_not_connected", "logger.warning", "logger.warning", "logger.warning", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.decode_into_node_and_backreferences", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.restore_backreferences_from_pointers", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.build_graph", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.connect_graph_if_not_connected"], ["\n", "", "def", "linearize", "(", "self", ",", "graph", ")", ":", "\n", "        ", "shift", "=", "len", "(", "self", ".", "encoder", ")", "\n", "tokens", ",", "token_ids", ",", "backreferences", "=", "self", ".", "tokenize_amr", "(", "graph", ")", "\n", "extra", "=", "{", "'linearized_graphs'", ":", "tokens", ",", "'graphs'", ":", "graph", "}", "\n", "token_uni_ids", "=", "[", "idx", "if", "i", "==", "b", "else", "b", "+", "shift", "for", "i", ",", "(", "idx", ",", "b", ")", "in", "enumerate", "(", "zip", "(", "token_ids", ",", "backreferences", ")", ")", "]", "\n", "if", "token_uni_ids", "[", "-", "1", "]", "!=", "(", "self", ".", "INIT", "+", "AMRTokens", ".", "EOS_N", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "self", ".", "INIT", "+", "AMRTokens", ".", "EOS_N", ")", "\n", "token_ids", ".", "append", "(", "self", ".", "eos_token_id", ")", "\n", "token_uni_ids", ".", "append", "(", "self", ".", "eos_token_id", ")", "\n", "backreferences", ".", "append", "(", "len", "(", "backreferences", ")", ")", "\n", "", "return", "token_uni_ids", ",", "extra", "\n", "\n", "", "def", "batch_encode_graphs", "(", "self", ",", "graphs", ",", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", ":", "\n", "        ", "linearized", ",", "extras", "=", "zip", "(", "*", "[", "self", ".", "linearize", "(", "g", ")", "for", "g", "in", "graphs", "]", ")", "\n", "return", "self", ".", "batch_encode_graphs_from_linearized", "(", "linearized", ",", "extras", ",", "device", "=", "device", ")", "\n", "\n", "", "def", "batch_encode_graphs_from_linearized", "(", "self", ",", "linearized", ",", "extras", "=", "None", ",", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", ":", "\n", "        ", "if", "extras", "is", "not", "None", ":", "\n", "            ", "batch_extra", "=", "{", "'linearized_graphs'", ":", "[", "]", ",", "'graphs'", ":", "[", "]", "}", "\n", "for", "extra", "in", "extras", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer.__init__": [[254, 259], ["tokenization_bart.AMRBartTokenizer.__init__"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__"], ["", "", "else", ":", "\n", "            ", "batch_extra", "=", "{", "}", "\n", "", "maxlen", "=", "0", "\n", "batch", "=", "[", "]", "\n", "for", "token_uni_ids", "in", "linearized", ":", "\n", "            ", "maxlen", "=", "max", "(", "len", "(", "token_uni_ids", ")", ",", "maxlen", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer._tokenize_encoded_graph": [[260, 276], ["regex.sub", "regex.sub().strip.split", "regex.sub().strip", "regex.sub().strip.split", "piece.strip.strip.startswith", "piece.strip.strip.endswith", "pieces.append", "piece.strip.strip.replace", "piece.strip.strip.replace", "piece.strip.strip.replace", "piece.strip.strip.replace", "piece.strip.strip.strip", "pieces.append", "regex.sub"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["batch", ".", "append", "(", "token_uni_ids", ")", "\n", "", "batch", "=", "[", "x", "+", "[", "self", ".", "pad_token_id", "]", "*", "(", "maxlen", "-", "len", "(", "x", ")", ")", "for", "x", "in", "batch", "]", "\n", "batch", "=", "torch", ".", "tensor", "(", "batch", ")", ".", "to", "(", "device", ")", "\n", "batch", "=", "{", "'decoder_input_ids'", ":", "batch", "[", ":", ",", ":", "-", "1", "]", ",", "'lm_labels'", ":", "batch", "[", ":", ",", "1", ":", "]", "}", "\n", "return", "batch", ",", "batch_extra", "\n", "\n", "", "def", "decode_amr", "(", "self", ",", "tokens", ",", "restore_name_ops", "=", "False", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "nodes", ",", "backreferences", "=", "postprocessing", ".", "decode_into_node_and_backreferences", "(", "tokens", ",", "self", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Decoding failure:'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "postprocessing", ".", "BACKOFF", ",", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ",", "(", "None", ",", "None", ")", "\n", "", "if", "self", ".", "use_pointer_tokens", ":", "\n", "            ", "nodes", ",", "backreferences", "=", "postprocessing", ".", "restore_backreferences_from_pointers", "(", "nodes", ")", "\n", "", "try", ":", "\n", "            ", "graph_", "=", "graph", "=", "postprocessing", ".", "build_graph", "(", "nodes", ",", "backreferences", ",", "restore_name_ops", "=", "restore_name_ops", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer.tokenize_amr": [[277, 289], ["copy.deepcopy", "penman.encode", "regex.sub", "list", "tokenization_bart.AMRBartTokenizer.tokenize_amr", "tokenization_bart.PENMANBartTokenizer.encoder.get", "range", "tokenization_bart.PENMANBartTokenizer._tokenize", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer.tokenize_amr", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer._tokenize"], ["", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Building failure:'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "nodes", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "backreferences", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "postprocessing", ".", "BACKOFF", ",", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ",", "(", "None", ",", "None", ")", "\n", "", "try", ":", "\n", "            ", "graph", ",", "status", "=", "postprocessing", ".", "connect_graph_if_not_connected", "(", "graph", ")", "\n", "if", "status", "==", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ":", "\n", "                ", "print", "(", "'Reconnection 1 failure:'", ")", "\n", "print", "(", "nodes", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "backreferences", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "graph_", ",", "file", "=", "sys", ".", "stderr", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer._get_nodes_and_backreferences": [[290, 321], ["copy.deepcopy", "penman.encode", "tokenization_bart.PENMANBartTokenizer._tokenize_encoded_graph", "list", "range", "range", "len", "len", "linearized_nodes_.append", "len", "lst.startswith", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer._tokenize_encoded_graph"], ["", "return", "graph", ",", "status", ",", "(", "nodes", ",", "backreferences", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Reconnction 2 failure:'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "nodes", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "backreferences", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "graph_", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "postprocessing", ".", "BACKOFF", ",", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ",", "(", "nodes", ",", "backreferences", ")", "\n", "\n", "\n", "", "", "", "class", "AMRBartTokenizer", "(", "BartTokenizer", ")", ":", "\n", "\n", "    ", "INIT", "=", "'\u0120'", "\n", "\n", "ADDITIONAL", "=", "[", "\n", "AMRTokens", ".", "PNTR_N", ",", "\n", "AMRTokens", ".", "STOP_N", ",", "\n", "AMRTokens", ".", "LIT_START", ",", "\n", "AMRTokens", ".", "LIT_END", ",", "\n", "AMRTokens", ".", "BACKR_SRC_N", ",", "\n", "AMRTokens", ".", "BACKR_TRG_N", ",", "]", "\n", "\n", "def", "__init__", "(", "self", ",", "*", "args", ",", "use_pointer_tokens", "=", "False", ",", "collapse_name_ops", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "patterns", "=", "re", ".", "compile", "(", "\n", "r\"\"\" ?<[a-z]+:?\\d*>| ?:[^\\s]+|'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"", ")", "\n", "self", ".", "linearizer", "=", "AMRLinearizer", "(", "use_pointer_tokens", "=", "use_pointer_tokens", ",", "collapse_name_ops", "=", "collapse_name_ops", ")", "\n", "self", ".", "use_pointer_tokens", "=", "use_pointer_tokens", "\n", "self", ".", "collapse_name_ops", "=", "collapse_name_ops", "\n", "self", ".", "recategorizations", "=", "set", "(", ")", "\n", "self", ".", "modified", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer._classify": [[322, 348], ["isinstance", "regex.match", "node[].isdigit", "node.startswith", "node.endswith", "node.startswith", "node[].isalpha"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_path", ",", "pred_min", "=", "5", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "inst", "=", "super", "(", ")", ".", "from_pretrained", "(", "pretrained_model_path", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "inst", ".", "init_amr_vocabulary", "(", "pred_min", "=", "pred_min", ")", "\n", "return", "inst", "\n", "\n", "", "def", "init_amr_vocabulary", "(", "self", ",", "pred_min", "=", "5", ")", ":", "\n", "        ", "for", "tok", "in", "[", "self", ".", "bos_token", ",", "self", ".", "eos_token", ",", "self", ".", "pad_token", ",", "'<mask>'", ",", "'<unk>'", "]", ":", "\n", "            ", "ntok", "=", "self", ".", "INIT", "+", "tok", "\n", "i", "=", "self", ".", "encoder", "[", "tok", "]", "\n", "self", ".", "decoder", "[", "i", "]", "=", "ntok", "\n", "del", "self", ".", "encoder", "[", "tok", "]", "\n", "self", ".", "encoder", "[", "ntok", "]", "=", "i", "\n", "\n", "", "tokens", "=", "[", "]", "\n", "for", "line", "in", "Path", "(", "ROOT", "/", "'data/vocab/predicates.txt'", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "tok", ",", "count", "=", "line", ".", "split", "(", ")", "\n", "if", "int", "(", "count", ")", ">=", "pred_min", ":", "\n", "                ", "tokens", ".", "append", "(", "tok", ")", "\n", "\n", "# add your vocab for one pretrain_task        ", "\n", "", "", "for", "tok", "in", "Path", "(", "\"../vocabs/dp_edges.txt\"", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "tok", ")", "\n", "\n", "", "for", "tok", "in", "Path", "(", "ROOT", "/", "'data/vocab/additions.txt'", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "tok", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer._fix_and_make_graph": [[349, 597], ["set", "regex.sub().strip", "penman.decode", "penman.Graph", "penman.encode", "tokenization_bart.PENMANBartTokenizer._fix_and_make_graph.fix_text"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.c_penman.encode"], ["", "for", "tok", "in", "Path", "(", "ROOT", "/", "'data/vocab/recategorizations.txt'", ")", ".", "read_text", "(", ")", ".", "strip", "(", ")", ".", "splitlines", "(", ")", ":", "\n", "            ", "if", "not", "tok", ".", "startswith", "(", "'_'", ")", ":", "\n", "                ", "self", ".", "recategorizations", ".", "add", "(", "tok", ")", "\n", "", "tokens", ".", "append", "(", "tok", ")", "\n", "\n", "", "if", "self", ".", "use_pointer_tokens", ":", "\n", "            ", "for", "cnt", "in", "range", "(", "512", ")", ":", "\n", "                ", "tokens", ".", "append", "(", "f\"<pointer:{cnt}>\"", ")", "\n", "\n", "", "", "tokens", "+=", "self", ".", "ADDITIONAL", "\n", "tokens", "=", "[", "self", ".", "INIT", "+", "t", "if", "t", "[", "0", "]", "not", "in", "(", "'_'", ",", "'-'", ")", "else", "t", "for", "t", "in", "tokens", "]", "\n", "tokens", "=", "[", "t", "for", "t", "in", "tokens", "if", "t", "not", "in", "self", ".", "encoder", "]", "\n", "self", ".", "old_enc_size", "=", "old_enc_size", "=", "len", "(", "self", ".", "encoder", ")", "\n", "for", "i", ",", "t", "in", "enumerate", "(", "tokens", ",", "start", "=", "old_enc_size", ")", ":", "\n", "            ", "self", ".", "encoder", "[", "t", "]", "=", "i", "\n", "\n", "", "self", ".", "encoder", "=", "{", "k", ":", "i", "for", "i", ",", "(", "k", ",", "v", ")", "in", "enumerate", "(", "sorted", "(", "self", ".", "encoder", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", ")", "}", "\n", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "sorted", "(", "self", ".", "encoder", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "}", "\n", "self", ".", "modified", "=", "len", "(", "tokens", ")", "\n", "\n", "self", ".", "bos_token", "=", "self", ".", "INIT", "+", "'<s>'", "\n", "self", ".", "pad_token", "=", "self", ".", "INIT", "+", "'<pad>'", "\n", "self", ".", "eos_token", "=", "self", ".", "INIT", "+", "'</s>'", "\n", "self", ".", "unk_token", "=", "self", ".", "INIT", "+", "'<unk>'", "\n", "\n", "", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "output", "=", "[", "self", ".", "bos_token_id", "]", "+", "token_ids_0", "+", "[", "self", ".", "eos_token_id", "]", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "output", "\n", "", "return", "output", "+", "[", "self", ".", "eos_token_id", "]", "+", "token_ids_1", "+", "[", "self", ".", "eos_token_id", "]", "\n", "\n", "", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. Modified in order to handle sentences with recategorization pointers\"\"\"", "\n", "bpe_tokens", "=", "[", "]", "\n", "for", "tok_span", "in", "text", ".", "lstrip", "(", ")", ".", "split", "(", "' '", ")", ":", "\n", "            ", "tok_span", "=", "tok_span", ".", "strip", "(", ")", "\n", "recats", "=", "tok_span", ".", "rsplit", "(", "'_'", ",", "1", ")", "\n", "if", "len", "(", "recats", ")", "==", "2", "and", "recats", "[", "0", "]", "in", "self", ".", "recategorizations", "and", "(", "'_'", "+", "recats", "[", "1", "]", ")", "in", "self", ".", "encoder", ":", "\n", "                ", "bpe_tokens", ".", "extend", "(", "[", "self", ".", "INIT", "+", "recats", "[", "0", "]", ",", "'_'", "+", "recats", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "for", "token", "in", "re", ".", "findall", "(", "self", ".", "pat", ",", "' '", "+", "tok_span", ")", ":", "\n", "                    ", "token", "=", "\"\"", ".", "join", "(", "\n", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "\"utf-8\"", ")", "\n", ")", "# Maps all our bytes to unicode strings, avoiding controle tokens of the BPE (spaces in our case)", "\n", "bpe_tokens", ".", "extend", "(", "bpe_token", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "\" \"", ")", ")", "\n", "\n", "", "", "", "return", "bpe_tokens", "\n", "\n", "", "def", "_tok_bpe", "(", "self", ",", "token", ",", "add_space", "=", "True", ")", ":", "\n", "# if add_space:", "\n", "#     token = ' ' + token.lstrip()", "\n", "        ", "tokk", "=", "[", "]", "\n", "tok", "=", "token", ".", "strip", "(", ")", "\n", "recats", "=", "tok", ".", "rsplit", "(", "'_'", ",", "1", ")", "\n", "if", "len", "(", "recats", ")", "==", "2", "and", "recats", "[", "0", "]", "in", "self", ".", "recategorizations", "and", "(", "'_'", "+", "recats", "[", "1", "]", ")", "in", "self", ".", "encoder", ":", "\n", "            ", "tokk", ".", "extend", "(", "[", "self", ".", "INIT", "+", "recats", "[", "0", "]", ",", "'_'", "+", "recats", "[", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "for", "tok", "in", "self", ".", "patterns", ".", "findall", "(", "' '", "+", "token", ")", ":", "# \u5982\u679c\u786e\u5b9a\u662f\u4e00\u4e2a\u5355\u8bcd\uff0c\u524d\u9762\u52a0\u7a7a\u683c\uff0c\u662f\u4e00\u4e2a\u7279\u70b9", "\n", "# BART \u4f7f\u7528\u7684\u662f byte-pair BPE \u8981\u8f6c\u6362\u6210\u7f16\u7801", "\n", "                ", "tok", "=", "\"\"", ".", "join", "(", "\n", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "tok", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "toks", "=", "self", ".", "bpe", "(", "tok", ")", ".", "split", "(", "' '", ")", "\n", "tokk", ".", "extend", "(", "toks", ")", "\n", "", "", "return", "tokk", "\n", "\n", "", "def", "_get_nodes_and_backreferences", "(", "self", ",", "graph", ")", ":", "\n", "        ", "lin", "=", "self", ".", "linearizer", ".", "linearize", "(", "graph", ")", "\n", "linearized_nodes", ",", "backreferences", "=", "lin", ".", "nodes", ",", "lin", ".", "backreferences", "\n", "return", "linearized_nodes", ",", "backreferences", "\n", "\n", "", "def", "tokenize_amr", "(", "self", ",", "graph", ")", ":", "\n", "        ", "linearized_nodes", ",", "backreferences", "=", "self", ".", "_get_nodes_and_backreferences", "(", "graph", ")", "\n", "\n", "bpe_tokens", "=", "[", "]", "\n", "bpe_backreferences", "=", "[", "]", "\n", "counter", "=", "0", "\n", "\n", "for", "i", ",", "(", "backr", ",", "tokk", ")", "in", "enumerate", "(", "zip", "(", "backreferences", ",", "linearized_nodes", ")", ")", ":", "\n", "            ", "is_in_enc", "=", "self", ".", "INIT", "+", "tokk", "in", "self", ".", "encoder", "\n", "is_rel", "=", "tokk", ".", "startswith", "(", "':'", ")", "and", "len", "(", "tokk", ")", ">", "1", "\n", "is_spc", "=", "tokk", ".", "startswith", "(", "'<'", ")", "and", "tokk", ".", "endswith", "(", "'>'", ")", "\n", "is_of", "=", "tokk", ".", "startswith", "(", "':'", ")", "and", "tokk", ".", "endswith", "(", "'-of'", ")", "\n", "is_frame", "=", "re", ".", "match", "(", "r'.+-\\d\\d'", ",", "tokk", ")", "is", "not", "None", "\n", "\n", "if", "tokk", ".", "startswith", "(", "'\"'", ")", "and", "tokk", ".", "endswith", "(", "'\"'", ")", ":", "# \u5e26\u5f15\u53f7\u7684\u53bb\u6389 \"United_States\" -> United_States", "\n", "                ", "tokk", "=", "tokk", "[", "1", ":", "-", "1", "]", ".", "replace", "(", "'_'", ",", "' '", ")", "# wiki\u5206\u8bcd  United_States -> United States", "\n", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "AMRTokens", ".", "LIT_START", "]", "# \u52a0\u5de6\u62ec\u53f7", "\n", "bpe_toks", "+=", "self", ".", "_tok_bpe", "(", "tokk", ",", "add_space", "=", "True", ")", "# bpe\u5206\u8bcd", "\n", "bpe_toks", ".", "append", "(", "self", ".", "INIT", "+", "AMRTokens", ".", "LIT_END", ")", "# \u52a0\u53f3\u62ec\u53f7", "\n", "\n", "", "elif", "(", "is_rel", "or", "is_spc", "or", "is_frame", "or", "is_of", ")", ":", "\n", "                ", "if", "is_in_enc", ":", "\n", "                    ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "tokk", "]", "\n", "", "elif", "is_frame", ":", "# go-05 \u5206\u8bcd\u6210 bpe(go) + \"-05\"", "\n", "                    ", "bpe_toks", "=", "self", ".", "_tok_bpe", "(", "tokk", "[", ":", "-", "3", "]", ",", "add_space", "=", "True", ")", "+", "[", "tokk", "[", "-", "3", ":", "]", "]", "\n", "", "elif", "is_of", ":", "\n", "                    ", "rel", "=", "tokk", "[", ":", "-", "3", "]", "\n", "if", "self", ".", "INIT", "+", "rel", "in", "self", ".", "encoder", ":", "\n", "                        ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "rel", ",", "'-of'", "]", "\n", "", "else", ":", "\n", "                        ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "':'", "]", "+", "self", ".", "_tok_bpe", "(", "rel", "[", "1", ":", "]", ",", "add_space", "=", "True", ")", "+", "[", "'-of'", "]", "\n", "", "", "elif", "is_rel", ":", "\n", "                    ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "':'", "]", "+", "self", ".", "_tok_bpe", "(", "tokk", "[", "1", ":", "]", ",", "add_space", "=", "True", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "\n", "\n", "", "", "else", ":", "\n", "                ", "if", "is_in_enc", ":", "\n", "                    ", "bpe_toks", "=", "[", "self", ".", "INIT", "+", "tokk", "]", "\n", "", "else", ":", "\n", "                    ", "bpe_toks", "=", "self", ".", "_tok_bpe", "(", "tokk", ",", "add_space", "=", "True", ")", "\n", "\n", "", "", "bpe_tokens", ".", "append", "(", "bpe_toks", ")", "\n", "\n", "if", "i", "==", "backr", ":", "\n", "                ", "bpe_backr", "=", "list", "(", "range", "(", "counter", ",", "counter", "+", "len", "(", "bpe_toks", ")", ")", ")", "\n", "counter", "+=", "len", "(", "bpe_toks", ")", "\n", "bpe_backreferences", ".", "append", "(", "bpe_backr", ")", "\n", "", "else", ":", "\n", "                ", "bpe_backreferences", ".", "append", "(", "bpe_backreferences", "[", "backr", "]", "[", "0", ":", "1", "]", ")", "\n", "counter", "+=", "1", "\n", "", "", "bpe_tokens", "=", "[", "b", "for", "bb", "in", "bpe_tokens", "for", "b", "in", "bb", "]", "\n", "bpe_token_ids", "=", "[", "self", ".", "encoder", ".", "get", "(", "b", ",", "self", ".", "unk_token_id", ")", "for", "b", "in", "bpe_tokens", "]", "\n", "bpe_backreferences", "=", "[", "b", "for", "bb", "in", "bpe_backreferences", "for", "b", "in", "bb", "]", "\n", "return", "bpe_tokens", ",", "bpe_token_ids", ",", "bpe_backreferences", "\n", "\n", "", "def", "tokenize_dp", "(", "self", ",", "dp", ")", ":", "\n", "# (  ROOT  :root  (  introduced  :nsubj  (  members  :amod  Influential  :prep  (  of  :pobj  (  Ways  :det  the  :nn  House  :cc  and  :conj  (  Committee  :nn  Means  )  )  )  )  :dobj  (  legislation  :rcmod  (  restrict  :nsubj  that  :aux  would  :ccomp  (  raise  :advmod  how  :nsubj  (  agency  :det  the  :amod  new  :nn  savings-and-loan  :nn  bailout  )  :aux  can  :dobj  capital  )  :punct  ,  :xcomp  (  creating  :dobj  (  obstacle  :det  another  :amod  potential  :prep  (  to  :pobj  (  sale  :poss  (  government  :det  the  :possessive  's  )  :prep  (  of  :pobj  (  thrifts  :amod  sick  )  )  )  )  )  )  )  )  :punct  .  )  ) ", "\n", "\n", "# srl", "\n", "#( <pointer:0> multi-sentence :snt0 <pointer:1> be.03 :snt1 ( <pointer:2> close.01 :ARG1 <pointer:3> session ) :snt2 <pointer:4> session.01 :snt3 ( <pointer:5> need.01 :ARG1 <pointer:6> today 's rare closed session ) :snt4 ( <pointer:7> guard.01 :ARG0 <pointer:6> :ARG1 <pointer:8> national secrets ) ", "\n", "\n", "        ", "snt", "=", "[", "]", "\n", "for", "i", "in", "dp", ".", "split", "(", "\" \"", ")", ":", "\n", "            ", "if", "i", "in", "dp_edges", ":", "\n", "                ", "assert", "self", ".", "INIT", "+", "i", "in", "self", ".", "encoder", "\n", "snt", "+=", "[", "self", ".", "INIT", "+", "i", "]", "\n", "\n", "#HACK New From ARR Nov , is frame", "\n", "", "elif", "len", "(", "i", ")", ">", "3", "and", "i", "[", "-", "3", "]", "==", "\".\"", ":", "\n", "                ", "i", "=", "i", ".", "replace", "(", "\".\"", ",", "\"-\"", ")", "\n", "\n", "if", "self", ".", "INIT", "+", "i", "in", "self", ".", "encoder", ":", "\n", "                    ", "snt", "+=", "[", "self", ".", "INIT", "+", "i", "]", "\n", "", "else", ":", "\n", "                    ", "bpe_toks", "=", "self", ".", "_tok_bpe", "(", "i", "[", ":", "-", "3", "]", ",", "add_space", "=", "True", ")", "+", "[", "i", "[", "-", "3", ":", "]", "]", "\n", "snt", "+=", "bpe_toks", "\n", "\n", "\n", "", "", "elif", "self", ".", "INIT", "+", "i", "in", "self", ".", "encoder", ":", "\n", "                ", "snt", "+=", "[", "self", ".", "INIT", "+", "i", "]", "\n", "", "else", ":", "\n", "                ", "snt", "+=", "self", ".", "_tok_bpe", "(", "i", ")", "\n", "\n", "# HACK New From ARR Nov", "\n", "# snt = snt[:-1]", "\n", "\n", "", "", "snt", "=", "[", "self", ".", "INIT", "+", "'<s>'", "]", "+", "snt", "+", "[", "self", ".", "INIT", "+", "'</s>'", "]", "\n", "snt_ids", "=", "self", ".", "convert_tokens_to_ids", "(", "snt", ")", "\n", "assert", "len", "(", "snt", ")", "==", "len", "(", "snt_ids", ")", "\n", "return", "snt_ids", ",", "snt", "\n", "\n", "\n", "# def batch_encode_sentences(self, sentences, device=torch.device('cpu')):", "\n", "#     sentences = [s for s in sentences]", "\n", "#     extra = {'sentences': sentences}", "\n", "#     batch = super().batch_encode_plus(sentences, return_tensors='pt', pad_to_max_length=False,max_length=1024)", "\n", "#     batch = {k: v.to(device) for k, v in batch.items()}", "\n", "#     return batch, extra", "\n", "\n", "\n", "", "def", "batch_encode_sentences", "(", "self", ",", "sentences", ",", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", ":", "\n", "        ", "sentences", "=", "[", "s", "for", "s", "in", "sentences", "]", "\n", "extra", "=", "{", "'sentences'", ":", "sentences", "}", "\n", "batch", "=", "super", "(", ")", ".", "batch_encode_plus", "(", "sentences", ",", "return_tensors", "=", "'pt'", ",", "pad_to_max_length", "=", "True", ")", "\n", "batch", "=", "{", "k", ":", "v", ".", "to", "(", "device", ")", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", "}", "\n", "return", "batch", ",", "extra", "\n", "\n", "#used for AMRization", "\n", "\n", "", "def", "linearize", "(", "self", ",", "graph", ")", ":", "\n", "        ", "shift", "=", "len", "(", "self", ".", "encoder", ")", "\n", "tokens", ",", "token_ids", ",", "backreferences", "=", "self", ".", "tokenize_amr", "(", "graph", ")", "\n", "extra", "=", "{", "'linearized_graphs'", ":", "tokens", ",", "'graphs'", ":", "graph", "}", "\n", "token_uni_ids", "=", "[", "idx", "if", "i", "==", "b", "else", "b", "+", "shift", "for", "i", ",", "(", "idx", ",", "b", ")", "in", "enumerate", "(", "zip", "(", "token_ids", ",", "backreferences", ")", ")", "]", "\n", "if", "token_uni_ids", "[", "-", "1", "]", "!=", "(", "self", ".", "INIT", "+", "AMRTokens", ".", "EOS_N", ")", ":", "\n", "            ", "tokens", ".", "append", "(", "self", ".", "INIT", "+", "AMRTokens", ".", "EOS_N", ")", "\n", "token_ids", ".", "append", "(", "self", ".", "eos_token_id", ")", "\n", "token_uni_ids", ".", "append", "(", "self", ".", "eos_token_id", ")", "\n", "backreferences", ".", "append", "(", "len", "(", "backreferences", ")", ")", "\n", "", "return", "token_uni_ids", ",", "extra", "\n", "\n", "", "def", "batch_encode_graphs", "(", "self", ",", "graphs", ",", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", ":", "\n", "        ", "linearized", ",", "extras", "=", "zip", "(", "*", "[", "self", ".", "linearize", "(", "g", ")", "for", "g", "in", "graphs", "]", ")", "\n", "return", "self", ".", "batch_encode_graphs_from_linearized", "(", "linearized", ",", "extras", ",", "device", "=", "device", ")", "\n", "\n", "", "def", "batch_encode_graphs_from_linearized", "(", "self", ",", "linearized", ",", "extras", "=", "None", ",", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", ":", "\n", "        ", "if", "extras", "is", "not", "None", ":", "\n", "            ", "batch_extra", "=", "{", "'linearized_graphs'", ":", "[", "]", ",", "'graphs'", ":", "[", "]", "}", "\n", "for", "extra", "in", "extras", ":", "\n", "                ", "batch_extra", "[", "'graphs'", "]", ".", "append", "(", "extra", "[", "'graphs'", "]", ")", "\n", "batch_extra", "[", "'linearized_graphs'", "]", ".", "append", "(", "extra", "[", "'linearized_graphs'", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "batch_extra", "=", "{", "}", "\n", "", "maxlen", "=", "0", "\n", "batch", "=", "[", "]", "\n", "for", "token_uni_ids", "in", "linearized", ":", "\n", "            ", "maxlen", "=", "max", "(", "len", "(", "token_uni_ids", ")", ",", "maxlen", ")", "\n", "batch", ".", "append", "(", "token_uni_ids", ")", "\n", "", "batch", "=", "[", "x", "+", "[", "self", ".", "pad_token_id", "]", "*", "(", "maxlen", "-", "len", "(", "x", ")", ")", "for", "x", "in", "batch", "]", "\n", "batch", "=", "torch", ".", "tensor", "(", "batch", ")", ".", "to", "(", "device", ")", "\n", "batch", "=", "{", "'decoder_input_ids'", ":", "batch", "[", ":", ",", ":", "-", "1", "]", ",", "'lm_labels'", ":", "batch", "[", ":", ",", "1", ":", "]", "}", "\n", "\n", "return", "batch", ",", "batch_extra", "\n", "\n", "", "def", "decode_amr", "(", "self", ",", "tokens", ",", "restore_name_ops", "=", "False", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "nodes", ",", "backreferences", "=", "postprocessing", ".", "decode_into_node_and_backreferences", "(", "tokens", ",", "self", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Decoding failure:'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "postprocessing", ".", "BACKOFF", ",", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ",", "(", "None", ",", "None", ")", "\n", "", "if", "self", ".", "use_pointer_tokens", ":", "\n", "            ", "nodes", ",", "backreferences", "=", "postprocessing", ".", "restore_backreferences_from_pointers", "(", "nodes", ")", "\n", "", "try", ":", "\n", "            ", "graph_", "=", "graph", "=", "postprocessing", ".", "build_graph", "(", "nodes", ",", "backreferences", ",", "restore_name_ops", "=", "restore_name_ops", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Building failure:'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "nodes", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "backreferences", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "postprocessing", ".", "BACKOFF", ",", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ",", "(", "None", ",", "None", ")", "\n", "", "try", ":", "\n", "            ", "graph", ",", "status", "=", "postprocessing", ".", "connect_graph_if_not_connected", "(", "graph", ")", "\n", "if", "status", "==", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ":", "\n", "                ", "print", "(", "'Reconnection 1 failure:'", ")", "\n", "print", "(", "nodes", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "backreferences", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "graph_", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "", "return", "graph", ",", "status", ",", "(", "nodes", ",", "backreferences", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Reconnction 2 failure:'", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "e", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "nodes", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "backreferences", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "print", "(", "graph_", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "return", "postprocessing", ".", "BACKOFF", ",", "postprocessing", ".", "ParsedStatus", ".", "BACKOFF", ",", "(", "nodes", ",", "backreferences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer.decode_amr": [[598, 624], ["tokenization_bart.PENMANBartTokenizer._fix_and_make_graph", "postprocessing.connect_graph_if_not_connected", "tokenization_bart.PENMANBartTokenizer._tokenize_encoded_graph", "list", "postprocessing.decode_into_node_and_backreferences", "logger.warning", "postprocessing._split_name_ops", "logger.warning", "logger.warning", "logger.warning", "tokenization_bart.PENMANBartTokenizer.decode", "range", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer._fix_and_make_graph", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.connect_graph_if_not_connected", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.PENMANBartTokenizer._tokenize_encoded_graph", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing.decode_into_node_and_backreferences", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.postprocessing._split_name_ops"], ["", "", "", "class", "PENMANBartTokenizer", "(", "AMRBartTokenizer", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "raw_graph", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "linearizer", "=", "None", "\n", "self", ".", "remove_pars", "=", "False", "\n", "self", ".", "raw_graph", "=", "raw_graph", "\n", "\n", "", "def", "_tokenize_encoded_graph", "(", "self", ",", "encoded", ")", ":", "\n", "        ", "linearized", "=", "re", ".", "sub", "(", "r\"(\\\".+?\\\")\"", ",", "r' \\1 '", ",", "encoded", ")", "\n", "pieces", "=", "[", "]", "\n", "for", "piece", "in", "linearized", ".", "split", "(", ")", ":", "\n", "            ", "if", "piece", ".", "startswith", "(", "'\"'", ")", "and", "piece", ".", "endswith", "(", "'\"'", ")", ":", "\n", "                ", "pieces", ".", "append", "(", "piece", ")", "\n", "", "else", ":", "\n", "                ", "piece", "=", "piece", ".", "replace", "(", "'('", ",", "' ( '", ")", "\n", "piece", "=", "piece", ".", "replace", "(", "')'", ",", "' ) '", ")", "\n", "piece", "=", "piece", ".", "replace", "(", "':'", ",", "' :'", ")", "\n", "piece", "=", "piece", ".", "replace", "(", "'/'", ",", "' / '", ")", "\n", "piece", "=", "piece", ".", "strip", "(", ")", "\n", "pieces", ".", "append", "(", "piece", ")", "\n", "", "", "linearized", "=", "re", ".", "sub", "(", "r'\\s+'", ",", "' '", ",", "' '", ".", "join", "(", "pieces", ")", ")", ".", "strip", "(", ")", "\n", "linearized_nodes", "=", "[", "AMRTokens", ".", "BOS_N", "]", "+", "linearized", ".", "split", "(", "' '", ")", "\n", "return", "linearized_nodes", "\n", "\n", "", "def", "tokenize_amr", "(", "self", ",", "graph", ")", ":", "\n", "        ", "if", "self", ".", "raw_graph", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.SemanticGraph.variables": [[35, 40], ["v.startswith"], "methods", ["None"], ["\n", "@", "cached_property", "\n", "def", "variables", "(", "self", ")", "->", "Set", "[", "str", "]", ":", "\n", "        ", "\"\"\"Set of variables in this semantic graph\"\"\"", "\n", "variables", "=", "{", "v", "for", "v", "in", "self", ".", "nodes_var", "if", "not", "v", ".", "startswith", "(", "'<'", ")", "}", "\n", "return", "variables", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.SemanticGraph.resolved_nodes_var": [[41, 44], ["None"], "methods", ["None"], ["\n", "", "@", "property", "\n", "def", "resolved_nodes_var", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "return", "[", "self", ".", "nodes_var", "[", "b", "]", "for", "b", "in", "self", ".", "backreferences", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.SemanticGraph.nodes": [[45, 49], ["linearization.SemanticGraph.var2instance.get"], "methods", ["None"], ["\n", "", "@", "cached_property", "\n", "def", "nodes", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"Linearized nodes with varids replaced by instances\"\"\"", "\n", "return", "[", "self", ".", "var2instance", ".", "get", "(", "node", ",", "node", ")", "for", "node", "in", "self", ".", "nodes_var", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.SemanticGraph.resolved_nodes": [[50, 53], ["None"], "methods", ["None"], ["\n", "", "@", "property", "\n", "def", "resolved_nodes", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "return", "[", "self", ".", "nodes", "[", "b", "]", "for", "b", "in", "self", ".", "backreferences", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.SemanticGraph.src_occurrence": [[54, 56], ["None"], "methods", ["None"], ["\n", "", "def", "src_occurrence", "(", "self", ",", "var", ":", "str", ")", "->", "int", ":", "\n", "        ", "pass", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.BaseLinearizer.linearize": [[60, 63], ["None"], "methods", ["None"], ["\n", "    ", "@", "abc", ".", "abstractmethod", "\n", "def", "linearize", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "SemanticGraph", ":", "\n", "        ", "pass", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRTokens.is_node": [[96, 103], ["isinstance", "string.startswith"], "methods", ["None"], ["\n", "@", "classmethod", "\n", "def", "is_node", "(", "cls", ",", "string", ":", "str", ")", "->", "bool", ":", "\n", "        ", "if", "isinstance", "(", "string", ",", "str", ")", "and", "string", ".", "startswith", "(", "':'", ")", ":", "\n", "            ", "return", "False", "\n", "", "elif", "string", "in", "cls", ".", "_FIXED_SPECIAL_TOKENS_E", ":", "\n", "            ", "return", "False", "\n", "", "return", "True", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRTokens.read_backr": [[104, 113], ["cls._re_BACKR_SRC_N.search", "cls._re_BACKR_TRG_N.search"], "methods", ["None"], ["\n", "", "@", "classmethod", "\n", "def", "read_backr", "(", "cls", ",", "string", ":", "str", ")", "->", "Optional", ":", "\n", "        ", "m_src", "=", "cls", ".", "_re_BACKR_SRC_N", ".", "search", "(", "string", ")", "\n", "if", "m_src", "is", "not", "None", ":", "\n", "            ", "return", "m_src", "\n", "", "m_trg", "=", "cls", ".", "_re_BACKR_TRG_N", ".", "search", "(", "string", ")", "\n", "if", "m_trg", "is", "not", "None", ":", "\n", "            ", "return", "m_trg", "\n", "", "return", "None", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer.__init__": [[132, 140], ["None"], "methods", ["None"], ["\n", "    ", "def", "__init__", "(", "\n", "self", ",", "\n", "use_pointer_tokens", ":", "bool", "=", "True", ",", "\n", "collapse_name_ops", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "collapse_name_ops", "=", "collapse_name_ops", "\n", "self", ".", "interleave_edges", "=", "False", "\n", "self", ".", "use_pointer_tokens", "=", "use_pointer_tokens", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer._collapse_name_ops": [[141, 167], ["enumerate", "collections.defaultdict", "enumerate", "amr.triples.copy", "collections.defaultdict.items", "penman.Graph", "sorted", "zip", "penman.Triple", "rel.startswith", "name_vars_to_ops[].append", "min", "v2.strip", "int"], "methods", ["None"], ["\n", "", "def", "_collapse_name_ops", "(", "self", ",", "amr", ")", ":", "\n", "# identify name triples", "\n", "        ", "name_vars", "=", "{", "}", "\n", "for", "i", ",", "(", "v1", ",", "rel", ",", "v2", ")", "in", "enumerate", "(", "amr", ".", "triples", ")", ":", "\n", "            ", "if", "rel", "==", "':instance'", "and", "v2", "==", "'name'", ":", "\n", "                ", "name_vars", "[", "v1", "]", "=", "1", "\n", "\n", "# check if they have ops", "\n", "", "", "name_vars_to_ops", "=", "defaultdict", "(", "list", ")", "\n", "for", "i", ",", "(", "v1", ",", "rel", ",", "v2", ")", "in", "enumerate", "(", "amr", ".", "triples", ")", ":", "\n", "            ", "if", "v1", "in", "name_vars", "and", "rel", ".", "startswith", "(", "':op'", ")", ":", "\n", "                ", "name_vars_to_ops", "[", "v1", "]", ".", "append", "(", "(", "i", ",", "rel", ",", "v2", ".", "strip", "(", "'\"'", ")", ")", ")", "\n", "\n", "", "", "triples", "=", "amr", ".", "triples", ".", "copy", "(", ")", "\n", "for", "nv", ",", "ops", "in", "name_vars_to_ops", ".", "items", "(", ")", ":", "\n", "            ", "ops", "=", "sorted", "(", "ops", ",", "key", "=", "lambda", "x", ":", "int", "(", "x", "[", "1", "]", "[", "3", ":", "]", ")", ")", "\n", "idx", ",", "_", ",", "lits", "=", "zip", "(", "*", "ops", ")", "\n", "for", "i", "in", "idx", ":", "\n", "                ", "triples", "[", "i", "]", "=", "None", "\n", "", "lit", "=", "'\"'", "+", "'_'", ".", "join", "(", "lits", ")", "+", "'\"'", "\n", "triples", "[", "min", "(", "idx", ")", "]", "=", "penman", ".", "Triple", "(", "nv", ",", "':op1'", ",", "lit", ")", "\n", "\n", "", "triples", "=", "[", "t", "for", "t", "in", "triples", "if", "t", "is", "not", "None", "]", "\n", "amr_", "=", "penman", ".", "Graph", "(", "triples", ")", "\n", "amr_", ".", "metadata", "=", "amr", ".", "metadata", "\n", "return", "amr_", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer.linearize": [[169, 177], ["linearization.AMRLinearizer._linearize", "linearization.AMRLinearizer._interleave", "linearization.AMRLinearizer._collapse_name_ops", "linearization.AMRLinearizer._add_pointer_tokens"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer._linearize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer._interleave", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer._collapse_name_ops", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer._add_pointer_tokens"], ["\n", "", "def", "linearize", "(", "self", ",", "amr", ":", "penman", ".", "Graph", ")", "->", "SemanticGraph", ":", "\n", "        ", "if", "self", ".", "collapse_name_ops", ":", "\n", "            ", "amr", "=", "self", ".", "_collapse_name_ops", "(", "amr", ")", "\n", "", "linearized", "=", "self", ".", "_linearize", "(", "amr", ")", "\n", "linearized", "=", "self", ".", "_interleave", "(", "linearized", ")", "\n", "if", "self", ".", "use_pointer_tokens", ":", "\n", "            ", "linearized", "=", "self", ".", "_add_pointer_tokens", "(", "linearized", ")", "\n", "", "return", "linearized", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer._linearize": [[178, 317], ["set", "networkx.MultiDiGraph", "amr.edges", "amr.attributes", "collections.deque", "set", "set", "collections.deque", "collections.deque.append", "backreferences.append", "nodes_visit.append", "edges_visit.append", "linearization.SemanticGraph", "amr.variables", "itertools.chain", "networkx.MultiDiGraph.add_node", "networkx.MultiDiGraph.add_edge", "networkx.MultiDiGraph.add_edge", "sorted", "len", "len", "len", "len", "enumerate", "range", "range", "collections.deque.popleft", "collections.deque.popleft", "edges_visit.append", "networkx.MultiDiGraph.successors", "sorted", "backreferences.append", "nodes_visit.append", "edges_visit.append", "set.add", "backreferences.append", "nodes_visit.append", "set.add", "len", "list", "nodes_visit.append", "backreferences.append", "backreferences.append", "len", "nodes_visit.append", "networkx.MultiDiGraph.get_edge_data().values", "edges_visit.append", "len", "len", "networkx.MultiDiGraph.successors", "len", "sorted.append", "backreferences.append", "nodes_visit.append", "networkx.get_node_attributes", "networkx.MultiDiGraph.get_edge_data", "nodes_visit.append", "backreferences.append", "backreferences.append", "len", "nodes_visit.append", "list", "collections.deque.append", "set.add", "len", "len", "networkx.MultiDiGraph.successors", "networkx.get_node_attributes"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.SemanticGraph.variables", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add", "home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.add"], ["\n", "", "def", "_linearize", "(", "self", ",", "amr", ":", "penman", ".", "Graph", ")", "->", "SemanticGraph", ":", "\n", "        ", "variables", "=", "set", "(", "amr", ".", "variables", "(", ")", ")", "\n", "variables", "=", "{", "'var:'", "+", "v", "for", "v", "in", "variables", "}", "\n", "var2instance", "=", "{", "}", "\n", "\n", "graph", "=", "nx", ".", "MultiDiGraph", "(", ")", "\n", "\n", "triples2order", "=", "{", "k", ":", "i", "for", "i", ",", "k", "in", "enumerate", "(", "amr", ".", "triples", ")", "}", "\n", "\n", "for", "triple", "in", "amr", ".", "triples", ":", "\n", "            ", "var", ",", "rel", ",", "instance", "=", "triple", "\n", "order", "=", "triples2order", "[", "triple", "]", "\n", "if", "rel", "!=", "':instance'", ":", "\n", "                ", "continue", "\n", "", "for", "expansion_candidate", "in", "itertools", ".", "chain", "(", "range", "(", "order", "-", "1", ",", "-", "1", ")", ",", "range", "(", "order", "+", "1", ",", "len", "(", "amr", ".", "triples", ")", ")", ")", ":", "\n", "                ", "if", "var", "==", "amr", ".", "triples", "[", "expansion_candidate", "]", "[", "2", "]", ":", "\n", "                    ", "expansion", "=", "expansion_candidate", "\n", "break", "\n", "", "", "else", ":", "\n", "                ", "expansion", "=", "0", "\n", "", "var", "=", "'var:'", "+", "var", "\n", "var2instance", "[", "var", "]", "=", "instance", "\n", "graph", ".", "add_node", "(", "var", ",", "instance", "=", "instance", ",", "order", "=", "order", ",", "expansion", "=", "expansion", ")", "\n", "\n", "", "for", "triple", "in", "amr", ".", "edges", "(", ")", ":", "\n", "            ", "var1", ",", "rel", ",", "var2", "=", "triple", "\n", "order", "=", "triples2order", "[", "triple", "]", "\n", "if", "rel", "==", "':instance'", ":", "\n", "                ", "continue", "\n", "", "var1", "=", "'var:'", "+", "var1", "\n", "var2", "=", "'var:'", "+", "var2", "\n", "graph", ".", "add_edge", "(", "var1", ",", "var2", ",", "rel", "=", "rel", ",", "order", "=", "order", ")", "\n", "\n", "", "for", "triple", "in", "amr", ".", "attributes", "(", ")", ":", "\n", "            ", "var", ",", "rel", ",", "attr", "=", "triple", "\n", "order", "=", "triples2order", "[", "triple", "]", "\n", "if", "rel", "==", "':instance'", ":", "\n", "                ", "continue", "\n", "", "var", "=", "'var:'", "+", "var", "\n", "graph", ".", "add_edge", "(", "var", ",", "attr", ",", "rel", "=", "rel", ",", "order", "=", "order", ")", "\n", "\n", "# nodes that are not reachable from the root (e.g. because of reification)", "\n", "# will be present in the not_explored queue", "\n", "# undirected_graph = graph.to_undirected()", "\n", "# print(amr.variables())", "\n", "", "not_explored", "=", "deque", "(", "sorted", "(", "variables", ",", "key", "=", "lambda", "x", ":", "nx", ".", "get_node_attributes", "(", "graph", ",", "'order'", ")", "[", "x", "]", ")", ")", "\n", "# (", "\n", "#     len(nx.shortest_path(undirected_graph, 'var:' + amr.top, x)),", "\n", "#     -graph.out_degree(x),", "\n", "# )", "\n", "\n", "first_index", "=", "{", "}", "\n", "explored", "=", "set", "(", ")", "\n", "added_to_queue", "=", "set", "(", ")", "\n", "nodes_visit", "=", "[", "AMRTokens", ".", "BOS_N", "]", "\n", "edges_visit", "=", "[", "AMRTokens", ".", "BOS_E", "]", "\n", "backreferences", "=", "[", "0", "]", "\n", "queue", "=", "deque", "(", ")", "\n", "queue", ".", "append", "(", "'var:'", "+", "amr", ".", "top", ")", "\n", "\n", "while", "queue", "or", "not_explored", ":", "\n", "\n", "            ", "if", "queue", ":", "\n", "                ", "node1", "=", "queue", ".", "popleft", "(", ")", "\n", "", "else", ":", "\n", "                ", "node1", "=", "not_explored", ".", "popleft", "(", ")", "\n", "if", "node1", "in", "added_to_queue", ":", "\n", "                    ", "continue", "\n", "", "if", "not", "list", "(", "graph", ".", "successors", "(", "node1", ")", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "", "if", "node1", "in", "variables", ":", "\n", "                ", "if", "node1", "in", "explored", ":", "\n", "                    ", "continue", "\n", "", "if", "node1", "in", "first_index", ":", "\n", "                    ", "nodes_visit", ".", "append", "(", "AMRTokens", ".", "BACKR_TRG_N", ")", "\n", "backreferences", ".", "append", "(", "first_index", "[", "node1", "]", ")", "\n", "", "else", ":", "\n", "                    ", "backreferences", ".", "append", "(", "len", "(", "nodes_visit", ")", ")", "\n", "first_index", "[", "node1", "]", "=", "len", "(", "nodes_visit", ")", "\n", "nodes_visit", ".", "append", "(", "node1", ")", "\n", "", "edges_visit", ".", "append", "(", "AMRTokens", ".", "START_E", ")", "\n", "\n", "successors", "=", "[", "]", "\n", "for", "node2", "in", "graph", ".", "successors", "(", "node1", ")", ":", "\n", "                    ", "for", "edge_data", "in", "graph", ".", "get_edge_data", "(", "node1", ",", "node2", ")", ".", "values", "(", ")", ":", "\n", "                        ", "rel", "=", "edge_data", "[", "'rel'", "]", "\n", "order", "=", "edge_data", "[", "'order'", "]", "\n", "successors", ".", "append", "(", "(", "order", ",", "rel", ",", "node2", ")", ")", "\n", "", "", "successors", "=", "sorted", "(", "successors", ")", "\n", "\n", "for", "order", ",", "rel", ",", "node2", "in", "successors", ":", "\n", "                    ", "edges_visit", ".", "append", "(", "rel", ")", "\n", "\n", "# node2 is a variable", "\n", "if", "node2", "in", "variables", ":", "\n", "# ... which was mentioned before", "\n", "                        ", "if", "node2", "in", "first_index", ":", "\n", "                            ", "nodes_visit", ".", "append", "(", "AMRTokens", ".", "BACKR_TRG_N", ")", "\n", "backreferences", ".", "append", "(", "first_index", "[", "node2", "]", ")", "\n", "\n", "# .. which is mentioned for the first time", "\n", "", "else", ":", "\n", "                            ", "backreferences", ".", "append", "(", "len", "(", "nodes_visit", ")", ")", "\n", "first_index", "[", "node2", "]", "=", "len", "(", "nodes_visit", ")", "\n", "nodes_visit", ".", "append", "(", "node2", ")", "\n", "\n", "# 1) not already in Q", "\n", "# 2) has children", "\n", "# 3) the edge right before its expansion has been encountered", "\n", "", "if", "(", "node2", "not", "in", "added_to_queue", ")", "and", "list", "(", "graph", ".", "successors", "(", "node2", ")", ")", "and", "(", "nx", ".", "get_node_attributes", "(", "graph", ",", "'expansion'", ")", "[", "node2", "]", "<=", "order", ")", ":", "\n", "                            ", "queue", ".", "append", "(", "node2", ")", "\n", "added_to_queue", ".", "add", "(", "node2", ")", "\n", "\n", "# node2 is a constant", "\n", "", "", "else", ":", "\n", "                        ", "backreferences", ".", "append", "(", "len", "(", "nodes_visit", ")", ")", "\n", "nodes_visit", ".", "append", "(", "node2", ")", "\n", "\n", "", "", "backreferences", ".", "append", "(", "len", "(", "nodes_visit", ")", ")", "\n", "nodes_visit", ".", "append", "(", "AMRTokens", ".", "STOP_N", ")", "\n", "edges_visit", ".", "append", "(", "AMRTokens", ".", "STOP_E", ")", "\n", "explored", ".", "add", "(", "node1", ")", "\n", "\n", "", "else", ":", "\n", "                ", "backreferences", ".", "append", "(", "len", "(", "nodes_visit", ")", ")", "\n", "nodes_visit", ".", "append", "(", "node1", ")", "\n", "explored", ".", "add", "(", "node1", ")", "\n", "\n", "", "", "backreferences", ".", "append", "(", "len", "(", "nodes_visit", ")", ")", "\n", "nodes_visit", ".", "append", "(", "AMRTokens", ".", "EOS_N", ")", "\n", "edges_visit", ".", "append", "(", "AMRTokens", ".", "EOS_E", ")", "\n", "assert", "len", "(", "nodes_visit", ")", "==", "len", "(", "edges_visit", ")", "==", "len", "(", "backreferences", ")", "\n", "return", "SemanticGraph", "(", "\n", "nodes_visit", ",", "\n", "edges_visit", ",", "\n", "backreferences", ",", "\n", "var2instance", ",", "\n", "extra", "=", "{", "'graph'", ":", "graph", ",", "'amr'", ":", "amr", "}", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer._interleave": [[319, 379], ["linearization.index_default", "linearization.AMRLinearizer._interleave.add_node"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.index_default"], ["\n", "", "def", "_interleave", "(", "self", ",", "graph", ":", "SemanticGraph", ")", "->", "SemanticGraph", ":", "\n", "\n", "        ", "new_backreferences_map", "=", "[", "]", "\n", "new_nodes", "=", "[", "]", "\n", "new_edges", "=", "None", "\n", "new_backreferences", "=", "[", "]", "\n", "\n", "# to isolate sublist to the stop token", "\n", "start_i", "=", "1", "\n", "end_i", "=", "index_default", "(", "AMRTokens", ".", "STOP_N", ",", "graph", ".", "nodes_var", ",", "start_i", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "def", "add_node", "(", "node", ",", "backr", "=", "None", ")", ":", "\n", "            ", "old_n_node", "=", "len", "(", "new_backreferences_map", ")", "\n", "new_n_node", "=", "len", "(", "new_nodes", ")", "\n", "\n", "if", "backr", "is", "None", ":", "\n", "                ", "backr", "=", "old_n_node", "\n", "\n", "", "new_backreferences_map", ".", "append", "(", "new_n_node", ")", "\n", "new_nodes", ".", "append", "(", "node", ")", "\n", "if", "old_n_node", "==", "backr", ":", "\n", "                ", "new_backreferences", ".", "append", "(", "new_n_node", ")", "\n", "", "else", ":", "\n", "                ", "new_backreferences", ".", "append", "(", "new_backreferences_map", "[", "backr", "]", ")", "\n", "\n", "", "", "def", "add_edge", "(", "edge", ")", ":", "\n", "            ", "new_nodes", ".", "append", "(", "edge", ")", "\n", "new_backreferences", ".", "append", "(", "len", "(", "new_backreferences", ")", ")", "\n", "\n", "", "add_node", "(", "AMRTokens", ".", "BOS_N", ")", "\n", "\n", "while", "end_i", ">", "-", "1", ":", "\n", "\n", "# src node", "\n", "            ", "add_node", "(", "graph", ".", "nodes_var", "[", "start_i", "]", ",", "graph", ".", "backreferences", "[", "start_i", "]", ")", "\n", "\n", "# edges and trg nodes, interleaved", "\n", "nodes", "=", "graph", ".", "nodes_var", "[", "start_i", "+", "1", ":", "end_i", "]", "\n", "edges", "=", "graph", ".", "edges", "[", "start_i", "+", "1", ":", "end_i", "]", "\n", "backr", "=", "graph", ".", "backreferences", "[", "start_i", "+", "1", ":", "end_i", "]", "\n", "for", "n", ",", "e", ",", "b", "in", "zip", "(", "nodes", ",", "edges", ",", "backr", ")", ":", "\n", "                ", "add_edge", "(", "e", ")", "\n", "add_node", "(", "n", ",", "b", ")", "\n", "\n", "# stop", "\n", "", "add_node", "(", "graph", ".", "nodes_var", "[", "end_i", "]", ",", "graph", ".", "backreferences", "[", "end_i", "]", ")", "\n", "\n", "start_i", "=", "end_i", "+", "1", "\n", "end_i", "=", "index_default", "(", "AMRTokens", ".", "STOP_N", ",", "graph", ".", "nodes_var", ",", "start_i", ",", "-", "1", ",", "-", "1", ")", "\n", "\n", "", "add_node", "(", "AMRTokens", ".", "EOS_N", ")", "\n", "\n", "new_graph", "=", "SemanticGraph", "(", "\n", "new_nodes", ",", "\n", "None", ",", "\n", "new_backreferences", ",", "\n", "graph", ".", "var2instance", ",", "\n", "extra", "=", "graph", ".", "extra", ",", "\n", ")", "\n", "return", "new_graph", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer._add_pointer_tokens": [[380, 405], ["zip", "list", "linearization.SemanticGraph", "range", "new_nodes.append", "len", "var2pointer.setdefault", "new_nodes.append", "new_nodes.append", "new_nodes.append", "len"], "methods", ["None"], ["\n", "", "def", "_add_pointer_tokens", "(", "self", ",", "graph", ":", "SemanticGraph", ")", "->", "SemanticGraph", ":", "\n", "        ", "new_nodes", "=", "[", "]", "\n", "var2pointer", "=", "{", "}", "\n", "for", "node", ",", "backr", "in", "zip", "(", "graph", ".", "nodes_var", ",", "graph", ".", "backreferences", ")", ":", "\n", "\n", "            ", "if", "node", "==", "AMRTokens", ".", "BACKR_TRG_N", ":", "\n", "                ", "node", "=", "graph", ".", "nodes_var", "[", "backr", "]", "\n", "pointer", "=", "var2pointer", "[", "node", "]", "\n", "new_nodes", ".", "append", "(", "pointer", ")", "\n", "", "elif", "node", "in", "graph", ".", "var2instance", ":", "\n", "                ", "pointer", "=", "var2pointer", ".", "setdefault", "(", "node", ",", "f\"<pointer:{len(var2pointer)}>\"", ")", "\n", "new_nodes", ".", "append", "(", "pointer", ")", "\n", "new_nodes", ".", "append", "(", "node", ")", "\n", "", "else", ":", "\n", "                ", "new_nodes", ".", "append", "(", "node", ")", "\n", "\n", "", "", "new_backreferences", "=", "list", "(", "range", "(", "len", "(", "new_nodes", ")", ")", ")", "\n", "new_graph", "=", "SemanticGraph", "(", "\n", "new_nodes", ",", "\n", "None", ",", "\n", "new_backreferences", ",", "\n", "graph", ".", "var2instance", ",", "\n", "extra", "=", "graph", ".", "extra", ",", "\n", ")", "\n", "return", "new_graph", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.index_default": [[118, 129], ["next", "len", "enumerate"], "function", ["None"], ["\n", "def", "index_default", "(", "\n", "item", ":", "T", ",", "list_", ":", "List", "[", "T", "]", ",", "\n", "start", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "stop", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "default", ":", "Optional", "[", "int", "]", "=", "None", "\n", ")", ":", "\n", "    ", "if", "start", "is", "None", ":", "\n", "        ", "start", "=", "0", "\n", "", "if", "stop", "is", "None", ":", "\n", "        ", "stop", "=", "len", "(", "list_", ")", "\n", "", "return", "next", "(", "(", "i", "for", "i", ",", "x", "in", "enumerate", "(", "list_", "[", "start", ":", "stop", "]", ",", "start", "=", "start", ")", "if", "x", "==", "item", ")", ",", "default", ")", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.__init__": [[21, 30], ["torch.device", "os.path.join", "os.path.join", "os.makedirs"], "methods", ["None"], ["atools", "=", "os", ".", "path", ".", "join", "(", "bin_dir", ",", "'atools'", ")", "\n", "p", "=", "{", "}", "\n", "p", "[", "'I'", "]", "=", "kwargs", ".", "get", "(", "'I'", ",", "5", ")", "\n", "p", "[", "'q'", "]", "=", "kwargs", ".", "get", "(", "'q'", ",", "0.08", ")", "\n", "p", "[", "'a'", "]", "=", "kwargs", ".", "get", "(", "'a'", ",", "0.01", ")", "\n", "p", "[", "'T'", "]", "=", "kwargs", ".", "get", "(", "'T'", ",", "4", ")", "\n", "p", "[", "'heuristic'", "]", "=", "kwargs", ".", "get", "(", "'heuristic'", ",", "'grow-diag-final-and'", ")", "\n", "self", ".", "params", "=", "p", "\n", "# Create the actual commands to execute", "\n", "fwd_cmd", "=", "'%s -i %s -d -o -v -I %d -q %f -a %f -T %d -p %s'", "%"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train": [[31, 73], ["trainer.Trainer.load_model", "trainer.Trainer.load_training_data", "trainer.Trainer.load_eval_data", "range", "print", "trainer.RunningAverage", "trainer.Trainer.optimizer.zero_grad", "tqdm.tqdm.tqdm", "trainer.Trainer.set_pbar_desc_train", "trainer.Trainer.model.train", "enumerate", "tqdm.tqdm.tqdm.close", "print", "trainer.Trainer.scaler.scale().backward", "trainer.RunningAverage.update", "tqdm.tqdm.tqdm.update", "trainer.Trainer.set_pbar_desc_train", "trainer.Trainer.step_otimizer", "trainer.Trainer.evaluate", "len", "torch.cuda.amp.autocast", "trainer.Trainer.model", "loss.item", "trainer.Trainer.step_otimizer", "trainer.Trainer.save_and_remove_checkpoints", "print", "logger.exception", "trainer.Trainer.scaler.scale"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.load_model", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.load_training_data", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.load_eval_data", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.set_pbar_desc_train", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.train", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.close", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.set_pbar_desc_train", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.step_otimizer", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.evaluate", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.step_otimizer", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.save_and_remove_checkpoints", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], ["(", "fast_align", ",", "in_fpath", ",", "p", "[", "'I'", "]", ",", "p", "[", "'q'", "]", ",", "p", "[", "'a'", "]", ",", "p", "[", "'T'", "]", ",", "self", ".", "fwd_params", ")", "\n", "rev_cmd", "=", "'%s -i %s -d -o -v -I %d -q %f -a %f -T %d -p %s -r'", "%", "(", "fast_align", ",", "in_fpath", ",", "p", "[", "'I'", "]", ",", "p", "[", "'q'", "]", ",", "p", "[", "'a'", "]", ",", "p", "[", "'T'", "]", ",", "self", ".", "rev_params", ")", "\n", "tools_cmd", "=", "'%s -i %s -j %s -c %s'", "%", "(", "atools", ",", "self", ".", "fwd_out", ",", "self", ".", "rev_out", ",", "p", "[", "'heuristic'", "]", ")", "\n", "self", ".", "fwd_cmd", "=", "fwd_cmd", ".", "split", "(", ")", "\n", "self", ".", "rev_cmd", "=", "rev_cmd", ".", "split", "(", ")", "\n", "self", ".", "tools_cmd", "=", "tools_cmd", ".", "split", "(", ")", "\n", "\n", "", "def", "train", "(", "self", ")", ":", "\n", "# Run the training", "\n", "        ", "with", "open", "(", "self", ".", "fwd_out", ",", "'w'", ")", "as", "fout", ",", "open", "(", "self", ".", "fwd_err", ",", "'w'", ")", "as", "ferr", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "fwd_cmd", ",", "stdout", "=", "fout", ",", "stderr", "=", "ferr", ")", "\n", "", "with", "open", "(", "self", ".", "rev_out", ",", "'w'", ")", "as", "fout", ",", "open", "(", "self", ".", "rev_err", ",", "'w'", ")", "as", "ferr", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "rev_cmd", ",", "stdout", "=", "fout", ",", "stderr", "=", "ferr", ")", "\n", "", "with", "open", "(", "self", ".", "final_out", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "subprocess", ".", "run", "(", "self", ".", "tools_cmd", ",", "stdout", "=", "fout", ")", "\n", "# Get a few final parameters", "\n", "", "self", ".", "params", "[", "'fwd_T'", "]", ",", "self", ".", "params", "[", "'fwd_m'", "]", "=", "self", ".", "read_err", "(", "self", ".", "fwd_err", ")", "\n", "self", ".", "params", "[", "'rev_T'", "]", ",", "self", ".", "params", "[", "'rev_m'", "]", "=", "self", ".", "read_err", "(", "self", ".", "rev_err", ")", "\n", "# Save the parameters for use during inference", "\n", "with", "open", "(", "self", ".", "param_fn", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "params", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n", "", "", "def", "read_err", "(", "self", ",", "err", ")", ":", "\n", "        ", "T", ",", "m", "=", "''", ",", "''", "\n", "with", "open", "(", "err", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "# expected target length = source length * N", "\n", "                ", "if", "'expected target length'", "in", "line", ":", "\n", "                    ", "m", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "# final tension: N", "\n", "", "elif", "'final tension'", "in", "line", ":", "\n", "                    ", "T", "=", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "", "", "", "return", "float", "(", "T", ")", ",", "float", "(", "m", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.evaluate": [[75, 97], ["trainer.Trainer.model.eval", "trainer.Trainer.inference.parse_sents", "sum", "print", "print", "penman.dump", "len", "len", "evaluate.smatch_enhanced.get_entries", "evaluate.smatch_enhanced.get_entries", "evaluate.smatch_enhanced.compute_smatch", "print", "logger.exception", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.inference.Inference.parse_sents", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.get_entries", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.get_entries", "home.repos.pwc.inspect_result.chenllliang_atp.evaluate.smatch_enhanced.compute_smatch", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.save_and_remove_checkpoints": [[99, 118], ["os.path.join", "print", "trainer.Trainer.config.get", "torch.save", "trainer.Trainer.model.state_dict", "trainer.Trainer.optimizer.state_dict", "trainer.Trainer.scheduler.state_dict", "open", "json.dump", "os.remove", "os.listdir", "fn.endswith", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.faa_aligner.proc_data.ProcData.save"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.load_model": [[120, 149], ["print", "model_utils.instantiate_model_and_tokenizer", "trainer.Trainer.model.to", "torch.optim.AdamW", "transformers.get_constant_schedule_with_warmup", "torch.cuda.amp.grad_scaler.GradScaler", "trainer.Trainer.model.parameters", "print", "model_utils.load_state_dict_from_checkpoint", "open", "json.load", "logger.exception", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.model_utils.instantiate_model_and_tokenizer", "home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.model_utils.load_state_dict_from_checkpoint", "home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.load_training_data": [[151, 162], ["print", "model_utils.get_dataloader"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.model_utils.get_dataloader"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.load_eval_data": [[164, 175], ["print", "inference.Inference", "amr_rw.read_raw_amr_data", "penman.dump"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.log_splitter.LogSplitter.print", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.amr_rw.read_raw_amr_data"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.step_otimizer": [[177, 184], ["trainer.Trainer.scaler.unscale_", "torch.nn.utils.clip_grad_norm_", "trainer.Trainer.scaler.step", "trainer.Trainer.scaler.update", "trainer.Trainer.optimizer.zero_grad", "trainer.Trainer.scheduler.step", "trainer.Trainer.model.parameters"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update", "home.repos.pwc.inspect_result.chenllliang_atp.spring_amr.optim.RAdam.step"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.Trainer.set_pbar_desc_train": [[186, 194], ["pbar.set_description"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.__init__": [[198, 201], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update": [[201, 206], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.__init__": [[9, 13], ["dataset.AMRDataset.load_graphs"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.load_graphs"], ["import", "os", "\n", "import", "time", "\n", "import", "numpy", "as", "np", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.load_graphs": [[14, 34], ["dataset.AMRDataset.tokenizer.linearize", "dataset.AMRDataset.sentences.append", "dataset.AMRDataset.graphs.append", "dataset.AMRDataset.linearized.append", "dataset.AMRDataset.linearized_extra.append", "dataset.AMRDataset.tokenizer.batch_encode_sentences", "len", "logging.warning", "logging.warning", "len"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.linearization.AMRLinearizer.linearize", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_sentences"], ["\n", "\n", "\n", "def", "read_csv_file", "(", "path", ",", "added_params", ")", ":", "\n", "    ", "data", "=", "{", "}", "\n", "info", "=", "True", "\n", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "comps", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "doc_name", "=", "comps", "[", "0", "]", "+", "\" \"", "+", "comps", "[", "1", "]", "\n", "mention", "=", "comps", "[", "2", "]", "\n", "lctx", "=", "comps", "[", "3", "]", "\n", "rctx", "=", "comps", "[", "4", "]", "\n", "\n", "if", "comps", "[", "6", "]", "!=", "\"EMPTYCAND\"", ":", "\n", "                ", "cands", "=", "[", "c", ".", "split", "(", "\",\"", ")", "for", "c", "in", "comps", "[", "6", ":", "-", "2", "]", "]", "\n", "cands", "=", "[", "\n", "(", "\",\"", ".", "join", "(", "c", "[", "2", ":", "]", ")", ".", "replace", "(", "'\"'", ",", "\"%22\"", ")", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ",", "float", "(", "c", "[", "1", "]", ")", ")", "\n", "for", "c", "in", "cands", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.__len__": [[35, 37], ["len"], "methods", ["None"], ["", "else", ":", "\n", "                ", "cands", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.__getitem__": [[38, 46], ["sample.update"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update"], ["", "gold", "=", "comps", "[", "-", "1", "]", ".", "split", "(", "\",\"", ")", "\n", "if", "gold", "[", "0", "]", "==", "\"-1\"", ":", "\n", "                ", "gold", "=", "(", "\n", "\",\"", ".", "join", "(", "gold", "[", "2", ":", "]", ")", ".", "replace", "(", "'\"'", ",", "\"%22\"", ")", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ",", "\n", "1e-5", ",", "\n", "-", "1", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "gold", "=", "(", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size": [[47, 49], ["len"], "methods", ["None"], ["\",\"", ".", "join", "(", "gold", "[", "3", ":", "]", ")", ".", "replace", "(", "'\"'", ",", "\"%22\"", ")", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", ",", "\n", "1e-5", ",", "\n", "-", "1", ",", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.collate_fn": [[50, 61], ["dataset.AMRDataset.tokenizer.batch_encode_sentences", "dataset.AMRDataset.tokenizer.batch_encode_graphs_from_linearized", "extra.update"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_sentences", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.tokenization_bart.AMRBartTokenizer.batch_encode_graphs_from_linearized", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.trainer.RunningAverage.update"], [")", "\n", "\n", "", "if", "added_params", "[", "\"generate_cands\"", "]", ":", "\n", "                ", "if", "info", ":", "\n", "                    ", "print", "(", "\"Generating candidates\"", ")", "\n", "info", "=", "False", "\n", "", "cands", "=", "added_params", "[", "\"cand_generator\"", "]", ".", "process", "(", "mention", ")", "\n", "\n", "", "if", "doc_name", "not", "in", "data", ":", "\n", "                ", "data", "[", "doc_name", "]", "=", "[", "]", "\n", "\n", "", "data", "[", "doc_name", "]", ".", "append", "(", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__init__": [[64, 72], ["torch.device"], "methods", ["None"], ["\"context\"", ":", "(", "lctx", ",", "rctx", ")", ",", "\n", "\"candidates\"", ":", "cands", ",", "\n", "\"gold\"", ":", "gold", ",", "\n", "}", "\n", ")", "\n", "", "", "return", "data", "\n", "\n", "\n", "### Adds original textual data to pregenerated data", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.set_device": [[73, 75], ["torch.device"], "methods", ["None"], ["", "def", "read_conll_file", "(", "data", ",", "path", ")", ":", "\n", "    ", "conll", "=", "{", "}", "\n", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.__iter__": [[76, 81], ["dataset.AMRDatasetTokenBatcherAndLoader.sampler", "dataset.AMRDatasetTokenBatcherAndLoader.dataset.collate_fn"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.sampler", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.collate_fn"], ["        ", "cur_sent", "=", "None", "\n", "cur_doc", "=", "None", "\n", "\n", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", ".", "startswith", "(", "\"-DOCSTART-\"", ")", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.sort_ids": [[82, 88], ["zip", "list", "len", "s.split", "sorted", "enumerate"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.perform_and_evaluate_candidate_retrieval_multithreaded.split"], ["                ", "docname", "=", "line", ".", "split", "(", ")", "[", "1", "]", "[", "1", ":", "]", "\n", "conll", "[", "docname", "]", "=", "{", "\"sentences\"", ":", "[", "]", ",", "\"mentions\"", ":", "[", "]", "}", "\n", "cur_doc", "=", "conll", "[", "docname", "]", "\n", "cur_sent", "=", "[", "]", "\n", "\n", "", "else", ":", "\n", "                ", "if", "line", "==", "\"\"", ":", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDatasetTokenBatcherAndLoader.sampler": [[89, 129], ["list", "random.shuffle", "dataset.AMRDatasetTokenBatcherAndLoader.sort_ids.copy", "batch_ids.copy", "dataset.AMRDatasetTokenBatcherAndLoader.pop", "dataset.AMRDatasetTokenBatcherAndLoader.dataset.size", "max", "batch_ids.append", "range", "max", "dataset.AMRDatasetTokenBatcherAndLoader.sampler.discharge"], "methods", ["home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.dataset.AMRDataset.size"], ["                    ", "cur_doc", "[", "\"sentences\"", "]", ".", "append", "(", "cur_sent", ")", "\n", "cur_sent", "=", "[", "]", "\n", "\n", "", "else", ":", "\n", "                    ", "comps", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "tok", "=", "comps", "[", "0", "]", "\n", "cur_sent", ".", "append", "(", "tok", ")", "\n", "\n", "if", "len", "(", "comps", ")", ">=", "6", ":", "\n", "                        ", "bi", "=", "comps", "[", "1", "]", "\n", "wikilink", "=", "comps", "[", "4", "]", "\n", "if", "bi", "==", "\"I\"", ":", "\n", "                            ", "cur_doc", "[", "\"mentions\"", "]", "[", "-", "1", "]", "[", "\"end\"", "]", "+=", "1", "\n", "", "else", ":", "\n", "                            ", "new_ment", "=", "{", "\n", "\"sent_id\"", ":", "len", "(", "cur_doc", "[", "\"sentences\"", "]", ")", ",", "\n", "\"start\"", ":", "len", "(", "cur_sent", ")", "-", "1", ",", "\n", "\"end\"", ":", "len", "(", "cur_sent", ")", ",", "\n", "\"wikilink\"", ":", "wikilink", ",", "\n", "}", "\n", "cur_doc", "[", "\"mentions\"", "]", ".", "append", "(", "new_ment", ")", "\n", "\n", "# merge with data", "\n", "", "", "", "", "", "", "rmpunc", "=", "re", ".", "compile", "(", "\"[\\W]+\"", ")", "\n", "for", "doc_name", ",", "content", "in", "data", ".", "items", "(", ")", ":", "\n", "        ", "conll_doc", "=", "conll", "[", "doc_name", ".", "split", "(", ")", "[", "0", "]", "]", "\n", "content", "[", "0", "]", "[", "\"conll_doc\"", "]", "=", "conll_doc", "\n", "\n", "cur_conll_m_id", "=", "0", "\n", "for", "m", "in", "content", ":", "\n", "            ", "mention", "=", "m", "[", "\"mention\"", "]", "\n", "gold", "=", "m", "[", "\"gold\"", "]", "\n", "\n", "while", "True", ":", "\n", "                ", "cur_conll_m", "=", "conll_doc", "[", "\"mentions\"", "]", "[", "cur_conll_m_id", "]", "\n", "cur_conll_mention", "=", "\" \"", ".", "join", "(", "\n", "conll_doc", "[", "\"sentences\"", "]", "[", "cur_conll_m", "[", "\"sent_id\"", "]", "]", "[", "\n", "cur_conll_m", "[", "\"start\"", "]", ":", "cur_conll_m", "[", "\"end\"", "]", "\n", "]", "\n", ")", "\n", "if", "rmpunc", ".", "sub", "(", "\"\"", ",", "cur_conll_mention", ".", "lower", "(", ")", ")", "==", "rmpunc", ".", "sub", "(", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.amr_rw.read_raw_amr_data": [[8, 20], ["sorted", "glob.glob", "graphs.extend", "amr_rw.load_amr_file", "eval", "t.endswith", "t.startswith", "t.startswith"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.biencoder.zeshel_utils.Stats.extend", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.amr_rw.load_amr_file", "home.repos.pwc.inspect_result.chenllliang_atp.candidate_retrieval.dataset.eval"], ["def", "read_raw_amr_data", "(", "glob_pattern", ",", "use_recategorization", "=", "False", ",", "dereify", "=", "True", ",", "remove_wiki", "=", "False", ")", ":", "\n", "    ", "graphs", "=", "[", "]", "\n", "for", "path", "in", "sorted", "(", "glob", "(", "glob_pattern", ")", ")", ":", "\n", "        ", "graphs", ".", "extend", "(", "load_amr_file", "(", "path", ",", "dereify", "=", "dereify", ",", "remove_wiki", "=", "remove_wiki", ")", ")", "\n", "", "assert", "graphs", "\n", "if", "use_recategorization", ":", "\n", "        ", "for", "g", "in", "graphs", ":", "\n", "            ", "metadata", "=", "g", ".", "metadata", "\n", "metadata", "[", "'snt_orig'", "]", "=", "metadata", "[", "'snt'", "]", "\n", "tokens", "=", "eval", "(", "metadata", "[", "'tokens'", "]", ")", "\n", "metadata", "[", "'snt'", "]", "=", "' '", ".", "join", "(", "[", "t", "for", "t", "in", "tokens", "if", "not", "(", "(", "t", ".", "startswith", "(", "'-L'", ")", "or", "t", ".", "startswith", "(", "'-R'", ")", ")", "and", "t", ".", "endswith", "(", "'-'", ")", ")", "]", ")", "\n", "", "", "return", "graphs", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.amr_rw.load_amr_file": [[24, 41], ["penman.load", "penman.model.Model", "range", "len", "amr_rw._remove_wiki", "range", "len", "amr_rw._replace_wiki"], "function", ["home.repos.pwc.inspect_result.chenllliang_atp.utils.config.Config.load", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.amr_rw._remove_wiki", "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.amr_rw._replace_wiki"], ["", "def", "load_amr_file", "(", "source", ",", "dereify", "=", "None", ",", "remove_wiki", "=", "False", ")", ":", "\n", "    ", "assert", "remove_wiki", "in", "(", "False", ",", "'replace'", ",", "'remove'", ")", "\n", "# Select the model to use", "\n", "if", "dereify", "is", "None", "or", "dereify", ":", "# None or True (odd way to do default logic)", "\n", "        ", "model", "=", "Model", "(", ")", "# default penman model, same as load(..., model=None)", "\n", "", "else", ":", "# False", "\n", "        ", "model", "=", "noop_model", "\n", "# Load the data", "\n", "", "out", "=", "penman", ".", "load", "(", "source", "=", "source", ",", "model", "=", "model", ")", "\n", "# Remove or replace the wiki tags", "\n", "if", "remove_wiki", "==", "'remove'", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "out", ")", ")", ":", "\n", "            ", "out", "[", "i", "]", "=", "_remove_wiki", "(", "out", "[", "i", "]", ")", "\n", "", "", "elif", "remove_wiki", "==", "'replace'", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "out", ")", ")", ":", "\n", "            ", "out", "[", "i", "]", "=", "_replace_wiki", "(", "out", "[", "i", "]", ")", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.amr_rw._replace_wiki": [[43, 54], ["penman.Graph", "triples.append", "penman.Triple"], "function", ["None"], ["", "def", "_replace_wiki", "(", "graph", ")", ":", "\n", "    ", "metadata", "=", "graph", ".", "metadata", "\n", "triples", "=", "[", "]", "\n", "for", "t", "in", "graph", ".", "triples", ":", "\n", "        ", "v1", ",", "rel", ",", "v2", "=", "t", "\n", "if", "rel", "==", "':wiki'", ":", "\n", "            ", "t", "=", "penman", ".", "Triple", "(", "v1", ",", "rel", ",", "'+'", ")", "\n", "", "triples", ".", "append", "(", "t", ")", "\n", "", "graph", "=", "penman", ".", "Graph", "(", "triples", ")", "\n", "graph", ".", "metadata", "=", "metadata", "\n", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.chenllliang_atp.parse_spring.amr_rw._remove_wiki": [[56, 67], ["penman.Graph", "triples.append"], "function", ["None"], ["", "def", "_remove_wiki", "(", "graph", ")", ":", "\n", "    ", "metadata", "=", "graph", ".", "metadata", "\n", "triples", "=", "[", "]", "\n", "for", "t", "in", "graph", ".", "triples", ":", "\n", "        ", "v1", ",", "rel", ",", "v2", "=", "t", "\n", "if", "rel", "==", "':wiki'", ":", "\n", "            ", "continue", "\n", "", "triples", ".", "append", "(", "t", ")", "\n", "", "graph", "=", "penman", ".", "Graph", "(", "triples", ")", "\n", "graph", ".", "metadata", "=", "metadata", "\n", "return", "graph", "\n", "", ""]]}