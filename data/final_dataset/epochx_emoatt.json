{"home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.elongated": [[30, 33], ["re.compile", "bool", "re.compile.search"], "function", ["None"], ["def", "elongated", "(", "token", ")", ":", "\n", "    ", "regex", "=", "re", ".", "compile", "(", "r\"(.)\\1{2}\"", ")", "\n", "return", "bool", "(", "regex", ".", "search", "(", "token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.START_VOCAB": [[34, 38], ["None"], "function", ["None"], ["", "def", "START_VOCAB", "(", "add_padding", "=", "False", ")", ":", "\n", "    ", "if", "add_padding", ":", "\n", "        ", "return", "[", "_PAD", ",", "_UNK", "]", "\n", "", "return", "[", "_UNK", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.process_token": [[40, 56], ["token.string.lower", "re.match"], "function", ["None"], ["", "def", "process_token", "(", "token", ")", ":", "\n", "    ", "\"\"\"Pre-processing for each token.\n\n    As Liu et al. 2015 we lowercase all words\n    and replace numbers with 'DIGIT'.\n\n    Args:\n        token (Token): Token\n\n    Returns:\n        str: processed token\n    \"\"\"", "\n", "ptoken", "=", "token", ".", "string", ".", "lower", "(", ")", "\n", "if", "re", ".", "match", "(", "\"\\\\d+\"", ",", "ptoken", ")", ":", "\n", "        ", "ptoken", "=", "\"\"", ".", "join", "(", "\"DIGIT\"", "for", "_", "in", "ptoken", ")", "\n", "", "return", "ptoken", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.sent_to_bin_feats": [[59, 82], ["numpy.zeros", "enumerate", "np.zeros.tolist", "Exception", "enumerate", "len", "len", "func"], "function", ["None"], ["", "def", "sent_to_bin_feats", "(", "sentence", ",", "funcs", ")", ":", "\n", "    ", "\"\"\"Generates binary one-hot features from a sentence.\n    Applies each function in funcs to each token\n    in the provided sentence.\n\n    Args:\n        sentence (Sentence):\n            Sentence object\n        funcs (list):\n            list of functions to apply to\n            each token in the sentence\n\n    Returns:\n        numpy.array : dim=(len(sentence), len(feat_funcs)\n    \"\"\"", "\n", "if", "not", "sentence", ".", "is_tokenized", ":", "\n", "        ", "raise", "Exception", "(", "\"Sentence not tokenized\"", ")", "\n", "", "matrix", "=", "np", ".", "zeros", "(", "(", "len", "(", "sentence", ")", ",", "len", "(", "funcs", ")", ")", ")", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "sentence", ")", ":", "\n", "        ", "for", "j", ",", "func", "in", "enumerate", "(", "funcs", ")", ":", "\n", "            ", "if", "func", "(", "token", ")", ":", "\n", "                ", "matrix", "[", "i", ",", "j", "]", "=", "1", "\n", "", "", "", "return", "matrix", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_token_vocab": [[84, 105], ["collections.defaultdict", "sentence_seqs.append", "sentence_seq.append", "collections.defaultdict.iteritems", "enumerate", "generate_json.START_VOCAB", "list", "generate_json.process_token"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.START_VOCAB", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.process_token"], ["", "def", "build_token_vocab", "(", "sentences", ",", "process_token_func", ",", "min_freq", "=", "1", ",", "add_padding", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    TODO\n    \"\"\"", "\n", "counts", "=", "defaultdict", "(", "int", ")", "\n", "sentence_seqs", "=", "[", "]", "\n", "\n", "for", "sentence", "in", "sentences", ":", "\n", "        ", "sentence_seq", "=", "[", "]", "\n", "for", "word", "in", "sentence", ".", "tokens", ":", "\n", "            ", "processed_token", "=", "process_token_func", "(", "word", ")", "\n", "counts", "[", "processed_token", "]", "+=", "1", "\n", "sentence_seq", ".", "append", "(", "processed_token", ")", "\n", "", "sentence_seqs", ".", "append", "(", "sentence_seq", ")", "\n", "\n", "# get words with low counts but not labeled as aspects", "\n", "", "highcounts", "=", "{", "word", "for", "word", ",", "count", "in", "counts", ".", "iteritems", "(", ")", "if", "count", ">", "min_freq", "}", "\n", "\n", "word2idx", "=", "{", "token", ":", "i", "for", "i", ",", "token", "in", "enumerate", "(", "START_VOCAB", "(", "add_padding", ")", "+", "list", "(", "highcounts", ")", ")", "}", "\n", "\n", "return", "word2idx", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_intensity_values": [[106, 108], ["None"], "function", ["None"], ["", "def", "build_intensity_values", "(", "sentences", ")", ":", "\n", "    ", "return", "[", "s", ".", "intensity", "for", "s", "in", "sentences", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_class_vocab": [[109, 113], ["set", "enumerate"], "function", ["None"], ["", "def", "build_class_vocab", "(", "sentences", ")", ":", "\n", "    ", "labels", "=", "set", "(", "[", "s", ".", "sentiment", "for", "s", "in", "sentences", "]", ")", "\n", "class2idx", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", "}", "\n", "return", "class2idx", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_sequences": [[115, 124], ["sentence_seqs.append", "sentence_seq.append", "token2idx.get", "generate_json.process_token", "generate_json.process_token", "generate_json.process_token"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.process_token", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.process_token", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.process_token"], ["", "def", "build_sequences", "(", "sentences", ",", "token2idx", ",", "process_token_func", ")", ":", "\n", "    ", "sentence_seqs", "=", "[", "]", "\n", "for", "sentence", "in", "sentences", ":", "\n", "        ", "sentence_seq", "=", "[", "]", "\n", "for", "token", "in", "sentence", ".", "tokens", ":", "\n", "            ", "processed_token", "=", "process_token_func", "(", "token", ")", "\n", "sentence_seq", ".", "append", "(", "token2idx", ".", "get", "(", "processed_token", ",", "token2idx", "[", "_UNK", "]", ")", ")", "\n", "", "sentence_seqs", ".", "append", "(", "sentence_seq", ")", "\n", "", "return", "sentence_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_sequence_classes": [[126, 128], ["None"], "function", ["None"], ["", "def", "build_sequence_classes", "(", "sentences", ",", "class2idx", ")", ":", "\n", "    ", "return", "[", "class2idx", "[", "s", ".", "sentiment", "]", "for", "s", "in", "sentences", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_sequence_ids": [[130, 132], ["None"], "function", ["None"], ["", "def", "build_sequence_ids", "(", "sentences", ")", ":", "\n", "    ", "return", "[", "s", ".", "id", "for", "s", "in", "sentences", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.split_list": [[134, 167], ["int", "int", "int", "random.random", "random.random", "len", "random.random", "test.append", "len", "train.append", "valid.append", "train.append", "valid.append", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], ["", "def", "split_list", "(", "examples", ",", "dev_ratio", "=", "0.9", ",", "test_ratio", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    :param examples: list\n    :param dev_ratio: 0.9\n    :param test_ratio: to split train/test\n    :param generate_test: (otherwise valid=test)\n    :return:\n    \"\"\"", "\n", "if", "test_ratio", ":", "\n", "        ", "train", ",", "valid", ",", "test", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "dev_size", "=", "int", "(", "len", "(", "examples", ")", "*", "test_ratio", ")", "\n", "train_size", "=", "int", "(", "dev_size", "*", "dev_ratio", ")", "\n", "for", "example", "in", "examples", ":", "\n", "            ", "r", "=", "random", ".", "random", "(", ")", "\n", "if", "r", "<=", "test_ratio", "and", "len", "(", "train", ")", "+", "len", "(", "valid", ")", "<", "dev_size", ":", "\n", "                ", "rr", "=", "random", ".", "random", "(", ")", "\n", "if", "rr", "<", "dev_ratio", "and", "len", "(", "train", ")", "<", "train_size", ":", "\n", "                    ", "train", ".", "append", "(", "example", ")", "\n", "", "else", ":", "\n", "                    ", "valid", ".", "append", "(", "example", ")", "\n", "", "", "else", ":", "\n", "                ", "test", ".", "append", "(", "example", ")", "\n", "", "", "return", "train", ",", "valid", ",", "test", "\n", "", "else", ":", "\n", "        ", "train", ",", "valid", "=", "[", "]", ",", "[", "]", "\n", "train_size", "=", "int", "(", "len", "(", "examples", ")", "*", "dev_ratio", ")", "\n", "for", "example", "in", "examples", ":", "\n", "            ", "r", "=", "random", ".", "random", "(", ")", "\n", "if", "r", "<=", "dev_ratio", "and", "len", "(", "train", ")", "<", "train_size", ":", "\n", "                ", "train", ".", "append", "(", "example", ")", "\n", "", "else", ":", "\n", "                ", "valid", ".", "append", "(", "example", ")", "\n", "", "", "return", "train", ",", "valid", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.kfolds_split_list": [[169, 199], ["range", "enumerate", "result.append", "len", "len", "test.append", "random.random", "train.append", "valid.append", "len"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.range", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], ["", "", "def", "kfolds_split_list", "(", "dataset", ",", "folds", ")", ":", "\n", "    ", "\"\"\"\n\n    :param dataset:\n    :param folds:\n    :return: List of tuples.\n    \"\"\"", "\n", "result", "=", "[", "]", "\n", "foldsize", "=", "1.0", "*", "len", "(", "dataset", ")", "/", "folds", "\n", "rest", "=", "1.0", "*", "len", "(", "dataset", ")", "%", "folds", "\n", "for", "f", "in", "range", "(", "1", ",", "folds", "+", "1", ")", ":", "\n", "        ", "start", "=", "(", "f", "-", "1", ")", "*", "foldsize", "\n", "end", "=", "f", "*", "foldsize", "\n", "train_size", "=", "foldsize", "*", "(", "folds", "-", "1", ")", "\n", "if", "f", "==", "folds", ":", "\n", "            ", "end", "+=", "rest", "\n", "", "train", ",", "valid", ",", "test", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "example", "in", "enumerate", "(", "dataset", ")", ":", "\n", "# test", "\n", "            ", "if", "start", "<=", "i", "<", "end", ":", "\n", "                ", "test", ".", "append", "(", "example", ")", "\n", "# development", "\n", "", "else", ":", "\n", "                ", "rr", "=", "random", ".", "random", "(", ")", "\n", "if", "rr", "<", "0.9", "and", "len", "(", "train", ")", "<", "train_size", ":", "\n", "                    ", "train", ".", "append", "(", "example", ")", "\n", "", "else", ":", "\n", "                    ", "valid", ".", "append", "(", "example", ")", "\n", "", "", "", "result", ".", "append", "(", "(", "train", ",", "valid", ",", "test", ")", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_json_dataset": [[201, 391], ["enumerate", "generate_json.kfolds_split_list", "dict", "generate_json.build_token_vocab", "generate_json.build_sequences", "generate_json.build_intensity_values", "generate_json.build_sequence_ids", "generate_json.build_sequences", "generate_json.build_intensity_values", "generate_json.build_sequence_ids", "generate_json.build_sequences", "generate_json.build_intensity_values", "generate_json.build_sequence_ids", "generate_json.build_class_vocab", "len", "NotImplementedError", "len", "generate_json.build_sequence_classes", "generate_json.build_sequence_classes", "generate_json.build_sequence_classes", "len", "numpy.zeros", "embeddings.unseen", "build_token_vocab.items", "np.zeros.tolist", "len", "build_class_vocab.keys", "os.path.join", "generate_json.split_list", "generate_json.sent_to_bin_feats", "generate_json.sent_to_bin_feats", "generate_json.sent_to_bin_feats", "numpy.random.random", "os.path.isdir", "os.makedirs", "open", "os.path.isdir", "os.makedirs", "str", "open", "generate_json.split_list", "generate_json.split_list", "generate_json.split_list", "embeddings.unseen", "os.path.join", "json.dump", "print", "os.path.join", "json.dump", "print", "warnings.warn", "warnings.warn", "str", "str"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.kfolds_split_list", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_token_vocab", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_sequences", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_intensity_values", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_sequence_ids", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_sequences", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_intensity_values", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_sequence_ids", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_sequences", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_intensity_values", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_sequence_ids", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_class_vocab", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_sequence_classes", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_sequence_classes", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.build_sequence_classes", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.split_list", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.sent_to_bin_feats", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.sent_to_bin_feats", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.sent_to_bin_feats", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.split_list", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.split_list", "home.repos.pwc.inspect_result.epochx_emoatt.None.generate_json.split_list"], ["", "def", "build_json_dataset", "(", "json_path", ",", "train_corpora", ",", "valid_corpora", "=", "None", ",", "test_corpora", "=", "None", ",", "min_freq", "=", "1", ",", "feat_funcs", "=", "(", ")", ",", "\n", "add_padding", "=", "True", ",", "embeddings", "=", "None", ",", "test_ratio", "=", "0.8", ",", "folds", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    Generates JSON file/s for training a model on the provided corpus. If using folds,\n    it generates a folder with the one JSON per fold.\n\n    Args:\n        json_path (str):\n            Json path\n        train_corpus (Corpus):\n            Corpus object\n        test_corpus (Corpus):\n            Corpus object\n        min_freq (int)\n            Min frequency to add the token to the vocabulary.\n        feat_funcs (list):\n            list of functions to extract binary features from tokens, None if no\n            binary features should be extracted (default=None)\n        add_padding (bool)\n            True to add the padding to the vocabulary.\n        embeddings (Embeddings):\n            Embeddings object\n        test_ratio (float):\n            Development/Test ratio when test set not given (default=0.8)\n        folds (int)\n            Use folds\n        sentiment (bool):\n            True if add sentiment (-1, 0 or 1) label to the aspect\n        joint (bool)\n            True if separate\n\n    Returns:\n        name (str) of the processed corpus if successful,\n        or None if it fails\n    \"\"\"", "\n", "only", "=", "True", "\n", "\n", "all_train", "=", "[", "]", "\n", "for", "train_corpus", "in", "train_corpora", ":", "\n", "        ", "all_train", "+=", "train_corpus", ".", "sentences", "\n", "\n", "", "if", "folds", "==", "1", ":", "\n", "\n", "        ", "if", "not", "valid_corpora", "and", "not", "test_corpora", ":", "\n", "            ", "partitions", "=", "[", "split_list", "(", "all_train", ",", "test_ratio", "=", "test_ratio", ")", "]", "\n", "", "else", ":", "\n", "            ", "if", "test_corpora", ":", "\n", "                ", "all_test", "=", "[", "]", "\n", "for", "test_corpus", "in", "test_corpora", ":", "\n", "                    ", "all_test", "+=", "test_corpus", ".", "sentences", "\n", "", "if", "valid_corpora", ":", "\n", "                    ", "all_valid", "=", "[", "]", "\n", "for", "valid_corpus", "in", "valid_corpora", ":", "\n", "                        ", "all_valid", "+=", "valid_corpus", ".", "sentences", "\n", "", "", "else", ":", "\n", "                    ", "all_train", ",", "all_valid", "=", "split_list", "(", "all_train", ")", "\n", "\n", "", "", "else", ":", "\n", "                ", "if", "valid_corpora", ":", "\n", "                    ", "_", ",", "___", ",", "all_test", "=", "split_list", "(", "all_train", ",", "test_ratio", "=", "test_ratio", ")", "\n", "all_valid", "=", "[", "]", "\n", "for", "valid_corpus", "in", "valid_corpora", ":", "\n", "                        ", "all_valid", "+=", "valid_corpus", ".", "sentences", "\n", "", "", "else", ":", "\n", "                    ", "all_train", ",", "all_valid", ",", "all_test", "=", "split_list", "(", "all_train", ",", "\n", "test_ratio", "=", "test_ratio", ")", "\n", "", "", "partitions", "=", "[", "(", "all_train", ",", "all_valid", ",", "all_test", ")", "]", "\n", "", "", "else", ":", "\n", "        ", "partitions", "=", "kfolds_split_list", "(", "all_train", ",", "folds", "=", "folds", ")", "\n", "only", "=", "False", "\n", "\n", "", "for", "f", ",", "partition", "in", "enumerate", "(", "partitions", ")", ":", "\n", "\n", "        ", "if", "\"TwiboParser\"", "in", "train_corpus", ".", "pipeline", ":", "\n", "            ", "pipeline", "=", "\"TwiboParser\"", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Pipeline not supported\"", ")", "\n", "\n", "", "jsondic", "=", "dict", "(", ")", "\n", "train_sentences", ",", "valid_sentences", ",", "test_sentences", "=", "partition", "\n", "\n", "token2idx", "=", "build_token_vocab", "(", "train_sentences", ",", "process_token", ",", "min_freq", "=", "min_freq", ")", "\n", "\n", "train_x", "=", "build_sequences", "(", "train_sentences", ",", "token2idx", ",", "process_token", ")", "\n", "train_y", "=", "build_intensity_values", "(", "train_sentences", ")", "\n", "train_ids", "=", "build_sequence_ids", "(", "train_sentences", ")", "\n", "\n", "valid_x", "=", "build_sequences", "(", "valid_sentences", ",", "token2idx", ",", "process_token", ")", "\n", "valid_y", "=", "build_intensity_values", "(", "valid_sentences", ")", "\n", "valid_ids", "=", "build_sequence_ids", "(", "valid_sentences", ")", "\n", "\n", "test_x", "=", "build_sequences", "(", "test_sentences", ",", "token2idx", ",", "process_token", ")", "\n", "test_y", "=", "build_intensity_values", "(", "test_sentences", ")", "\n", "test_ids", "=", "build_sequence_ids", "(", "test_sentences", ")", "\n", "\n", "class2idx", "=", "build_class_vocab", "(", "train_sentences", ")", "\n", "classes", "=", "False", "\n", "if", "len", "(", "class2idx", ")", ">", "1", ":", "\n", "            ", "classes", "=", "True", "\n", "train_z", "=", "build_sequence_classes", "(", "train_sentences", ",", "class2idx", ")", "\n", "valid_z", "=", "build_sequence_classes", "(", "valid_sentences", ",", "class2idx", ")", "\n", "test_z", "=", "build_sequence_classes", "(", "test_sentences", ",", "class2idx", ")", "\n", "\n", "", "if", "feat_funcs", ":", "\n", "            ", "train_feat_x", "=", "[", "sent_to_bin_feats", "(", "s", ",", "feat_funcs", ")", "for", "s", "in", "train_sentences", "]", "\n", "valid_feat_x", "=", "[", "sent_to_bin_feats", "(", "s", ",", "feat_funcs", ")", "for", "s", "in", "valid_sentences", "]", "\n", "test_feat_x", "=", "[", "sent_to_bin_feats", "(", "s", ",", "feat_funcs", ")", "for", "s", "in", "test_sentences", "]", "\n", "\n", "", "if", "embeddings", ":", "\n", "            ", "vocab_size", "=", "len", "(", "token2idx", ")", "\n", "vector_size", "=", "embeddings", ".", "vector_size", "\n", "matrix", "=", "np", ".", "zeros", "(", "(", "vocab_size", ",", "vector_size", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "# set the the unseen/unknown token embedding", "\n", "matrix", "[", "token2idx", "[", "_UNK", "]", "]", "=", "embeddings", ".", "unseen", "(", ")", "\n", "\n", "# set the the padding embedding", "\n", "if", "add_padding", ":", "\n", "                ", "matrix", "[", "token2idx", "[", "_PAD", "]", "]", "=", "np", ".", "random", ".", "random", "(", "(", "vector_size", ",", ")", ")", "\n", "\n", "", "for", "token", ",", "idx", "in", "token2idx", ".", "items", "(", ")", ":", "\n", "                ", "if", "token", "in", "embeddings", ":", "\n", "                    ", "matrix", "[", "idx", "]", "=", "embeddings", "[", "token", "]", "\n", "", "else", ":", "\n", "                    ", "matrix", "[", "idx", "]", "=", "embeddings", ".", "unseen", "(", ")", "\n", "\n", "", "", "jsondic", "[", "\"embeddings\"", "]", "=", "matrix", ".", "tolist", "(", ")", "\n", "embeddings_name", "=", "embeddings", ".", "name", "\n", "", "else", ":", "\n", "            ", "embeddings_name", "=", "\"RandomEmbeddings\"", "\n", "\n", "", "jsondic", "[", "\"train_x\"", "]", ",", "jsondic", "[", "\"train_y\"", "]", ",", "jsondic", "[", "\"train_ids\"", "]", "=", "train_x", ",", "train_y", ",", "train_ids", "\n", "jsondic", "[", "\"valid_x\"", "]", ",", "jsondic", "[", "\"valid_y\"", "]", ",", "jsondic", "[", "\"valid_ids\"", "]", "=", "valid_x", ",", "valid_y", ",", "valid_ids", "\n", "jsondic", "[", "\"test_x\"", "]", ",", "jsondic", "[", "\"test_y\"", "]", ",", "jsondic", "[", "\"test_ids\"", "]", "=", "test_x", ",", "test_y", ",", "test_ids", "\n", "jsondic", "[", "\"token2idx\"", "]", "=", "token2idx", "\n", "\n", "if", "feat_funcs", ":", "\n", "            ", "jsondic", "[", "\"featdim\"", "]", "=", "len", "(", "feat_funcs", ")", "\n", "jsondic", "[", "\"train_feat_x\"", "]", "=", "train_feat_x", "\n", "jsondic", "[", "\"valid_feat_x\"", "]", "=", "valid_feat_x", "\n", "jsondic", "[", "\"test_feat_x\"", "]", "=", "test_feat_x", "\n", "\n", "", "jsondic", "[", "\"class2idx\"", "]", "=", "class2idx", "\n", "jsondic", "[", "\"classdim\"", "]", "=", "len", "(", "class2idx", ".", "keys", "(", ")", ")", "\n", "\n", "if", "classes", ":", "\n", "            ", "jsondic", "[", "\"train_z\"", "]", "=", "train_z", "\n", "jsondic", "[", "\"valid_z\"", "]", "=", "valid_z", "\n", "jsondic", "[", "\"test_z\"", "]", "=", "test_z", "\n", "\n", "", "if", "only", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "isdir", "(", "json_path", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "json_path", ")", "\n", "\n", "", "json_filename", "=", "pipeline", "+", "\".\"", "+", "\"\"", ".", "join", "(", "[", "train_corpus", ".", "name", "for", "train_corpus", "in", "train_corpora", "]", ")", "\n", "\n", "if", "valid_corpora", ":", "\n", "                ", "json_filename", "+=", "\"\"", ".", "join", "(", "[", "valid_corpus", ".", "name", "for", "valid_corpus", "in", "valid_corpora", "]", ")", "\n", "\n", "", "if", "test_corpora", ":", "\n", "                ", "json_filename", "+=", "\"\"", ".", "join", "(", "[", "test_corpus", ".", "name", "for", "test_corpus", "in", "test_corpora", "]", ")", "\n", "", "json_filename", "+=", "\".\"", "+", "embeddings_name", "\n", "json_filename", "+=", "\".json\"", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "json_path", ",", "json_filename", ")", ",", "\"wb\"", ")", "as", "json_file", ":", "\n", "                ", "try", ":", "\n", "                    ", "json", ".", "dump", "(", "jsondic", ",", "json_file", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "warnings", ".", "warn", "(", "str", "(", "e", ")", ")", "\n", "return", "None", "\n", "", "finally", ":", "\n", "                    ", "print", "(", "\"Written \"", "+", "json_filename", ")", "\n", "", "", "", "else", ":", "\n", "            ", "jsondic", "[", "\"fold\"", "]", "=", "f", "\n", "json_path_name", "=", "pipeline", "+", "\".\"", "+", "\"\"", ".", "join", "(", "[", "train_corpus", ".", "name", "for", "train_corpus", "in", "train_corpora", "]", ")", "+", "\".\"", "+", "embeddings_name", "\n", "\n", "current_json_path", "=", "os", ".", "path", ".", "join", "(", "json_path", ",", "json_path_name", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "current_json_path", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "current_json_path", ")", "\n", "\n", "", "json_filename", "=", "str", "(", "f", ")", "+", "\".json\"", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "current_json_path", ",", "json_filename", ")", ",", "\"wb\"", ")", "as", "json_file", ":", "\n", "                ", "try", ":", "\n", "                    ", "json", ".", "dump", "(", "jsondic", ",", "json_file", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "warnings", ".", "warn", "(", "str", "(", "e", ")", "+", "\" in \"", "+", "train_corpus", ".", "name", ")", "\n", "", "finally", ":", "\n", "                    ", "print", "(", "\"Written \"", "+", "json_filename", ")", "\n", "", "", "", "", "", "if", "__name__", "==", "\"__main__\"", ":", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.run.str2bool": [[27, 34], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["def", "str2bool", "(", "v", ")", ":", "\n", "  ", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "    ", "return", "True", "\n", "", "if", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "    ", "return", "False", "\n", "", "else", ":", "\n", "    ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.run.main": [[36, 431], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "dict", "os.environ.get", "os.environ.get", "os.path.isdir", "print", "exit", "print", "exit", "print", "exit", "os.path.join", "os.path.join", "copy.copy.json_path.endswith", "os.path.split", "os.path.isfile", "copy.copy", "run.get_model_id", "os.path.join", "os.path.join", "print", "vars().iteritems", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "tensorflow.ConfigProto", "tensorflow.reset_default_graph", "os.path.split", "print", "exit", "os.path.isdir", "os.makedirs", "print", "os.path.isdir", "os.makedirs", "open", "json.dump", "tensorflow.Session", "print", "run.read_data", "print", "print", "print", "run.generate_buckets", "run.generate_buckets", "run.generate_buckets", "float", "print", "print", "run.create_model", "print", "sorted", "vars", "print", "print", "os.path.join", "vars", "len", "len", "len", "len", "sum", "len", "len", "model.global_step.eval", "numpy.random.random_sample", "min", "time.time", "model.get_batch", "os.listdir", "six.moves.xrange", "sum", "six.moves.xrange", "model.joint_step", "print", "sys.stdout.flush", "os.path.join", "run.run_valid_test", "print", "sys.stdout.flush", "log.append", "str", "len", "len", "len", "len", "model.regression_step", "time.time", "subprocess.call", "model.saver.save", "print", "sys.stdout.flush", "run.run_valid_test", "open", "json.dump", "six.moves.xrange", "model.classification_step", "subprocess.call", "map", "os.path.join", "len", "model.global_step.eval"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.copy", "home.repos.pwc.inspect_result.epochx_emoatt.None.run.get_model_id", "home.repos.pwc.inspect_result.epochx_emoatt.None.run.read_data", "home.repos.pwc.inspect_result.epochx_emoatt.None.run.generate_buckets", "home.repos.pwc.inspect_result.epochx_emoatt.None.run.generate_buckets", "home.repos.pwc.inspect_result.epochx_emoatt.None.run.generate_buckets", "home.repos.pwc.inspect_result.epochx_emoatt.None.run.create_model", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.__init__.MultiTaskModel.get_batch", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.__init__.MultiTaskModel.joint_step", "home.repos.pwc.inspect_result.epochx_emoatt.None.run.run_valid_test", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.__init__.MultiTaskModel.regression_step", "home.repos.pwc.inspect_result.epochx_emoatt.None.run.run_valid_test", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.__init__.MultiTaskModel.classification_step"], ["", "", "def", "main", "(", ")", ":", "\n", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.5", ",", "\n", "help", "=", "\"(initial) Learning rate.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--decay_factor\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.9", ",", "\n", "help", "=", "\"Learning rate decay factor\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--decay_end\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "5000", ",", "\n", "help", "=", "\"Learning rate decay final step, when using sgd\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--early_stopping\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "2000", ",", "\n", "help", "=", "\"Stop training if no improvement\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--optimizer\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"sgd\"", ",", "\n", "choices", "=", "[", "\"adam\"", ",", "\"sgd\"", "]", ",", "\n", "help", "=", "\"Optimizer\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_gradient_norm\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "5.0", ",", "\n", "help", "=", "\"Clip gradients to this norm.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "8", ",", "\n", "help", "=", "\"Batch size to use during training.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Batch size to use during evaluation.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--size\"", ",", "\n", "default", "=", "100", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Size of each model layer.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--word_embedding_size\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Size of the word embedding. Use 0 to use json data provided.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--train_word_embeddings\"", ",", "\n", "default", "=", "True", ",", "\n", "type", "=", "str2bool", ",", "\n", "help", "=", "\"Train word embeddings\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--num_layers\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Number of layers in the model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--regularization_lambda\"", ",", "\n", "default", "=", "0.2", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Coefficient of L2 regularization (set 0 for no regularization).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--json_path\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"JSON Data dir (for folds) or file path. Checks JSON_DIR first.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--results_path\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "help", "=", "\"Path to save trained model and outputs. Checks RESULTS_DIR first\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint_path\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Path to load trained model\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--steps_per_checkpoint\"", ",", "\n", "default", "=", "100", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"How many training steps to do per checkpoint.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--steps_per_eval\"", ",", "\n", "default", "=", "100", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"How many training steps to do before evaluation.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_training_steps\"", ",", "\n", "default", "=", "5000", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Max training steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--use_attention\"", ",", "\n", "default", "=", "True", ",", "\n", "type", "=", "str2bool", ",", "\n", "help", "=", "\"Use attention based RNN\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_sequence_length\"", ",", "\n", "default", "=", "50", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Max sequence length.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--context_win_size\"", ",", "\n", "default", "=", "3", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Context window size.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--dropout_keep_prob\"", ",", "\n", "default", "=", "0.9", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"dropout keep cell input and output prob.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--zoneout_keep_prob\"", ",", "\n", "default", "=", "1", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"zoneout keep cell input and output prob.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--bidirectional_rnn\"", ",", "\n", "default", "=", "True", ",", "\n", "type", "=", "str2bool", ",", "\n", "help", "=", "\"Use bidirectional RNN\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--task\"", ",", "\n", "default", "=", "\"regression\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "[", "\"joint\"", ",", "\"regression\"", "]", ",", "\n", "help", "=", "\"Task\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--use_binary_features\"", ",", "\n", "default", "=", "True", ",", "\n", "type", "=", "str2bool", ",", "\n", "help", "=", "\"Use binary features\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "\n", "default", "=", "False", ",", "\n", "type", "=", "str2bool", ",", "\n", "help", "=", "\"Rewrite trained model\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--rnn\"", ",", "\n", "default", "=", "\"lstm\"", ",", "\n", "choices", "=", "[", "\"lstm\"", ",", "\"gru\"", ",", "\"bnlstm\"", "]", ",", "\n", "help", "=", "\"Rnn cell type\"", ",", "\n", "type", "=", "str", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--loss\"", ",", "\n", "default", "=", "\"pc\"", ",", "\n", "choices", "=", "[", "\"mse\"", ",", "\"pc\"", "]", ",", "\n", "help", "=", "\"Loss function\"", ",", "\n", "type", "=", "str", ")", "\n", "\n", "FLAGS", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "_buckets", "=", "[", "(", "FLAGS", ".", "max_sequence_length", ",", ")", "]", "\n", "\n", "\n", "if", "FLAGS", ".", "max_sequence_length", "==", "0", ":", "\n", "      ", "print", "(", "'Please indicate max sequence length. Exit'", ")", "\n", "exit", "(", ")", "\n", "\n", "", "if", "FLAGS", ".", "zoneout_keep_prob", "<", "1", "and", "FLAGS", ".", "dropout_keep_prob", "<", "1", ":", "\n", "      ", "print", "(", "'Please choose dropout ore zoneout. Exit'", ")", "\n", "exit", "(", ")", "\n", "\n", "", "if", "FLAGS", ".", "task", "is", "None", ":", "\n", "      ", "print", "(", "'Please indicate task to run. Available options: intent; tagging; joint'", ")", "\n", "exit", "(", ")", "\n", "\n", "", "task", "=", "dict", "(", "{", "'classification'", ":", "0", ",", "'regression'", ":", "0", ",", "'joint'", ":", "0", "}", ")", "\n", "if", "FLAGS", ".", "task", "==", "'classification'", ":", "\n", "      ", "task", "[", "'classification'", "]", "=", "1", "\n", "", "elif", "FLAGS", ".", "task", "==", "'regression'", ":", "\n", "      ", "task", "[", "'regression'", "]", "=", "1", "\n", "", "elif", "FLAGS", ".", "task", "==", "'joint'", ":", "\n", "      ", "task", "[", "'regression'", "]", "=", "1", "\n", "task", "[", "'classification'", "]", "=", "1", "\n", "task", "[", "'joint'", "]", "=", "1", "\n", "\n", "", "FLAGS", ".", "task", "=", "task", "\n", "\n", "json_dir", "=", "os", ".", "environ", ".", "get", "(", "'JSON_DIR'", ",", "None", ")", "\n", "results_dir", "=", "os", ".", "environ", ".", "get", "(", "'RESULTS_DIR'", ",", "None", ")", "\n", "\n", "if", "json_dir", ":", "\n", "    ", "FLAGS", ".", "json_path", "=", "os", ".", "path", ".", "join", "(", "json_dir", ",", "FLAGS", ".", "json_path", ")", "\n", "\n", "", "if", "results_dir", ":", "\n", "    ", "FLAGS", ".", "results_path", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "FLAGS", ".", "results_path", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "isdir", "(", "FLAGS", ".", "json_path", ")", ":", "\n", "    ", "if", "FLAGS", ".", "json_path", ".", "endswith", "(", "\"/\"", ")", ":", "\n", "      ", "FLAGS", ".", "json_path", "=", "FLAGS", ".", "json_path", "[", ":", "-", "1", "]", "\n", "", "json_base_path", ",", "json_path", "=", "os", ".", "path", ".", "split", "(", "FLAGS", ".", "json_path", ")", "\n", "\n", "paths", "=", "[", "(", "json_base_path", ",", "json_path", ",", "json_filename", ")", "\n", "for", "json_filename", "in", "sorted", "(", "os", ".", "listdir", "(", "FLAGS", ".", "json_path", ")", ")", "]", "\n", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "FLAGS", ".", "json_path", ")", ":", "\n", "    ", "json_base_dir", ",", "json_filename", "=", "os", ".", "path", ".", "split", "(", "FLAGS", ".", "json_path", ")", "\n", "paths", "=", "[", "(", "json_base_dir", ",", "\"\"", ",", "json_filename", ")", "]", "\n", "", "else", ":", "\n", "    ", "print", "(", "\"Not valid JSON path\"", ")", "\n", "exit", "(", ")", "\n", "\n", "", "BASE_FLAGS", "=", "FLAGS", "\n", "\n", "base_results_path", "=", "FLAGS", ".", "results_path", "\n", "\n", "for", "json_base_path", ",", "json_path", ",", "json_filename", "in", "paths", ":", "\n", "\n", "    ", "FLAGS", "=", "copy", ".", "copy", "(", "FLAGS", ")", "\n", "# we obtain model_id before modifying paths, so the same model keeps the id for different folds", "\n", "model_id", "=", "get_model_id", "(", "FLAGS", ")", "\n", "\n", "# if folds this is json_path/", "\n", "FLAGS", ".", "json_path", "=", "os", ".", "path", ".", "join", "(", "*", "(", "json_base_path", ",", "\n", "json_path", ",", "\n", "json_filename", ")", ")", "\n", "\n", "FLAGS", ".", "results_path", "=", "os", ".", "path", ".", "join", "(", "*", "(", "base_results_path", ",", "\n", "json_path", ",", "\n", "json_filename", ")", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "FLAGS", ".", "results_path", ")", ":", "\n", "      ", "os", ".", "makedirs", "(", "FLAGS", ".", "results_path", ")", "\n", "\n", "", "print", "(", "'Applying Parameters:'", ")", "\n", "for", "k", ",", "v", "in", "vars", "(", "FLAGS", ")", ".", "iteritems", "(", ")", ":", "\n", "      ", "print", "(", "'%s: %s'", "%", "(", "k", ",", "str", "(", "v", ")", ")", ")", "\n", "\n", "", "results_dir", "=", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "results_path", ",", "model_id", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "results_dir", ")", ":", "\n", "      ", "os", ".", "makedirs", "(", "results_dir", ")", "\n", "", "else", ":", "\n", "      ", "if", "FLAGS", ".", "overwrite", ":", "\n", "        ", "print", "(", "\"Model already trained, overwriting\"", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Model already trained. Set overwrite=True to overwrite\\n\"", ")", "\n", "continue", "\n", "\n", "# store parameters", "\n", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "results_dir", ",", "\"params.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "      ", "json", ".", "dump", "(", "vars", "(", "FLAGS", ")", ",", "f", ")", "\n", "\n", "", "log", "=", "[", "]", "\n", "\n", "class_valid_out_file", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "'classification.valid.hyp.txt'", ")", "\n", "class_test_out_file", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "'classification.test.hyp.txt'", ")", "\n", "\n", "reg_valid_out_file", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "'regression.valid.txt'", ")", "\n", "reg_test_out_file", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "'regression.test.txt'", ")", "\n", "\n", "att_valid_out_file", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "'attentions.valid.hyp.json'", ")", "\n", "att_test_out_file", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "'attentions.test.hyp.json'", ")", "\n", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "\n", "with", "tf", ".", "Session", "(", "config", "=", "config", ")", "as", "sess", ":", "\n", "# Read data into buckets and compute their sizes.", "\n", "      ", "print", "(", "\"Reading train/valid/test data\"", ")", "\n", "train", ",", "valid", ",", "test", ",", "vocabs", ",", "rev_vocabs", ",", "binary_feat_dim", ",", "class_dim", ",", "embeddings_matrix", "=", "read_data", "(", "FLAGS", ")", "\n", "\n", "train_x", ",", "train_feat_x", ",", "train_y", ",", "train_z", ",", "train_ids", "=", "train", "\n", "valid_x", ",", "valid_feat_x", ",", "valid_y", ",", "valid_z", ",", "valid_ids", "=", "valid", "\n", "test_x", ",", "test_feat_x", ",", "test_y", ",", "test_z", ",", "test_ids", "=", "test", "\n", "vocab", ",", "label_vocab", "=", "vocabs", "\n", "rev_vocab", ",", "rev_label_vocab", "=", "rev_vocabs", "\n", "\n", "print", "(", "len", "(", "train_x", ")", ")", "\n", "print", "(", "len", "(", "valid_x", ")", ")", "\n", "print", "(", "len", "(", "test_x", ")", ")", "\n", "\n", "train_set", "=", "generate_buckets", "(", "_buckets", ",", "train_x", ",", "train_y", ",", "train_z", ",", "\n", "train_ids", ",", "extra_x", "=", "train_feat_x", ")", "\n", "dev_set", "=", "generate_buckets", "(", "_buckets", ",", "valid_x", ",", "valid_y", ",", "valid_z", ",", "\n", "valid_ids", ",", "extra_x", "=", "valid_feat_x", ")", "\n", "test_set", "=", "generate_buckets", "(", "_buckets", ",", "test_x", ",", "test_y", ",", "test_z", ",", "\n", "test_ids", ",", "extra_x", "=", "test_feat_x", ")", "\n", "\n", "train_bucket_sizes", "=", "[", "len", "(", "train_set", "[", "b", "]", ")", "for", "b", "in", "xrange", "(", "len", "(", "_buckets", ")", ")", "]", "\n", "train_total_size", "=", "float", "(", "sum", "(", "train_bucket_sizes", ")", ")", "\n", "\n", "train_buckets_scale", "=", "[", "sum", "(", "train_bucket_sizes", "[", ":", "i", "+", "1", "]", ")", "/", "train_total_size", "\n", "for", "i", "in", "xrange", "(", "len", "(", "train_bucket_sizes", ")", ")", "]", "\n", "\n", "# Create model.", "\n", "print", "(", "\"Max sequence length: %d.\"", "%", "_buckets", "[", "0", "]", "[", "0", "]", ")", "\n", "print", "(", "\"Creating %d layers of %d units.\"", "%", "(", "FLAGS", ".", "num_layers", ",", "FLAGS", ".", "size", ")", ")", "\n", "\n", "model", ",", "model_test", "=", "create_model", "(", "sess", ",", "len", "(", "vocab", ")", ",", "len", "(", "label_vocab", ")", ",", "\n", "embeddings_matrix", ",", "binary_feat_dim", ",", "\n", "class_dim", ",", "FLAGS", ",", "_buckets", ")", "\n", "\n", "# train_writer = tf.summary.FileWriter(results_dir, sess.graph)", "\n", "print", "(", "\"Creating model with source_vocab_size=%d and label_vocab_size=%d.\"", "%", "\n", "(", "len", "(", "vocab", ")", ",", "len", "(", "label_vocab", ")", ")", ")", "\n", "\n", "# This is the training loop.", "\n", "step_time", ",", "loss", "=", "0.0", ",", "0.0", "\n", "current_step", "=", "0", "\n", "best_step", "=", "0", "\n", "\n", "best_valid_regression_result", "=", "0", "\n", "best_test_regression_result", "=", "0", "\n", "best_valid_class_score", "=", "0", "\n", "best_test_class_score", "=", "0", "\n", "\n", "while", "model", ".", "global_step", ".", "eval", "(", ")", "<", "FLAGS", ".", "max_training_steps", ":", "\n", "        ", "random_number_01", "=", "np", ".", "random", ".", "random_sample", "(", ")", "\n", "bucket_id", "=", "min", "(", "[", "i", "for", "i", "in", "xrange", "(", "len", "(", "train_buckets_scale", ")", ")", "\n", "if", "train_buckets_scale", "[", "i", "]", ">", "random_number_01", "]", ")", "\n", "\n", "# Get a batch and make a step.", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "encoder_inputs", ",", "_", ",", "encoder_extra_inputs", ",", "batch_sequence_length", ",", "values", ",", "labels", ",", "ids", "=", "model", ".", "get_batch", "(", "train_set", ",", "bucket_id", ")", "\n", "\n", "if", "task", "[", "'joint'", "]", "==", "1", ":", "\n", "          ", "output", "=", "model", ".", "joint_step", "(", "sess", ",", "encoder_inputs", ",", "encoder_extra_inputs", ",", "values", ",", "labels", ",", "\n", "batch_sequence_length", ",", "bucket_id", ",", "False", ")", "\n", "_", ",", "step_loss", ",", "tagging_logits", ",", "tagging_att", ",", "class_logits", ",", "class_att", "=", "output", "\n", "\n", "", "elif", "task", "[", "'regression'", "]", "==", "1", ":", "\n", "          ", "output", "=", "model", ".", "regression_step", "(", "sess", ",", "encoder_inputs", ",", "encoder_extra_inputs", ",", "values", ",", "labels", ",", "\n", "batch_sequence_length", ",", "bucket_id", ",", "False", ")", "\n", "_", ",", "step_loss", ",", "tagging_logits", ",", "tagging_att", "=", "output", "\n", "", "elif", "task", "[", "'classification'", "]", "==", "1", ":", "\n", "          ", "output", "=", "model", ".", "classification_step", "(", "sess", ",", "encoder_inputs", ",", "encoder_extra_inputs", ",", "\n", "labels", ",", "batch_sequence_length", ",", "bucket_id", ",", "False", ")", "\n", "_", ",", "step_loss", ",", "class_logits", ",", "class_att", "=", "output", "\n", "\n", "", "step_time", "+=", "(", "time", ".", "time", "(", ")", "-", "start_time", ")", "/", "FLAGS", ".", "steps_per_checkpoint", "\n", "loss", "+=", "step_loss", "/", "FLAGS", ".", "steps_per_checkpoint", "\n", "current_step", "+=", "1", "\n", "\n", "# Once in a while, we save checkpoint, print statistics, and run evals.", "\n", "if", "current_step", "%", "FLAGS", ".", "steps_per_checkpoint", "==", "0", ":", "\n", "          ", "print", "(", "\"global step %d step-time %.2f. Training loss %.2f\"", "\n", "%", "(", "model", ".", "global_step", ".", "eval", "(", ")", ",", "step_time", ",", "loss", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "# Save checkpoint and zero timer and loss.", "\n", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "\"model.ckpt\"", ")", "\n", "step_time", ",", "loss", "=", "0.0", ",", "0.0", "\n", "\n", "# Once in a while, we run evals", "\n", "", "if", "current_step", "%", "FLAGS", ".", "steps_per_eval", "==", "0", ":", "\n", "# valid", "\n", "          ", "valid_regression_result", ",", "valid_class_result", "=", "run_valid_test", "(", "model_test", ",", "sess", ",", "dev_set", ",", "'Valid'", ",", "task", ",", "\n", "rev_vocab", ",", "rev_label_vocab", ",", "FLAGS", ",", "_buckets", ",", "\n", "regression_out_file", "=", "reg_valid_out_file", ",", "\n", "classification_out_file", "=", "reg_test_out_file", ",", "\n", "attentions_out_file", "=", "att_valid_out_file", ")", "\n", "\n", "# use pearson correlation as validation metric", "\n", "if", "valid_regression_result", "[", "1", "]", ">", "best_valid_regression_result", ":", "\n", "            ", "best_valid_regression_result", "=", "valid_regression_result", "[", "1", "]", "\n", "subprocess", ".", "call", "(", "[", "'mv'", ",", "reg_valid_out_file", "+", "\".hyp\"", ",", "reg_valid_out_file", "+", "'.hyp.best'", "]", ")", "\n", "\n", "if", "task", "[", "'joint'", "]", "==", "1", "and", "valid_class_result", "[", "\"all\"", "]", "[", "\"a\"", "]", ">", "best_valid_class_score", ":", "\n", "              ", "best_valid_class_score", "=", "valid_class_result", "[", "\"all\"", "]", "[", "\"a\"", "]", "\n", "subprocess", ".", "call", "(", "[", "'mv'", ",", "class_valid_out_file", ",", "class_valid_out_file", "+", "'.best'", "]", ")", "\n", "\n", "", "model", ".", "saver", ".", "save", "(", "sess", ",", "checkpoint_path", ")", "\n", "best_step", "=", "current_step", "\n", "print", "(", "\"  New Best!\"", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "# test", "\n", "test_regression_result", ",", "test_class_result", "=", "run_valid_test", "(", "model_test", ",", "sess", ",", "test_set", ",", "'Test'", ",", "task", ",", "\n", "rev_vocab", ",", "rev_label_vocab", ",", "FLAGS", ",", "_buckets", ",", "\n", "regression_out_file", "=", "reg_test_out_file", ",", "\n", "classification_out_file", "=", "class_test_out_file", ",", "\n", "attentions_out_file", "=", "att_test_out_file", ")", "\n", "\n", "", "print", "(", "\"\"", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "log", ".", "append", "(", "[", "map", "(", "float", ",", "valid_regression_result", ")", ",", "valid_class_result", "]", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "results_dir", ",", "\"log.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "              ", "json", ".", "dump", "(", "log", ",", "f", ")", "\n", "\n", "", "if", "FLAGS", ".", "early_stopping", "and", "current_step", "-", "best_step", ">", "FLAGS", ".", "early_stopping", ":", "\n", "              ", "break", "\n", "\n", "", "", "", "", "tf", ".", "reset_default_graph", "(", ")", "\n", "FLAGS", "=", "BASE_FLAGS", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.run.get_model_id": [[434, 438], ["vars", "hashlib.sha1().hexdigest", "hashlib.sha1", "str"], "function", ["None"], ["", "", "def", "get_model_id", "(", "FLAGS", ")", ":", "\n", "  ", "params", "=", "vars", "(", "FLAGS", ")", "\n", "sha", "=", "hashlib", ".", "sha1", "(", "str", "(", "params", ")", ")", ".", "hexdigest", "(", ")", "\n", "return", "sha", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.run.generate_buckets": [[440, 451], ["enumerate", "zip", "enumerate", "len", "data_set[].append", "data_set[].append"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], ["", "def", "generate_buckets", "(", "_buckets", ",", "x", ",", "y", ",", "z", ",", "example_ids", ",", "extra_x", "=", "None", ")", ":", "\n", "  ", "data_set", "=", "[", "[", "]", "for", "_", "in", "_buckets", "]", "\n", "for", "i", ",", "(", "source", ",", "target", ",", "label", ",", "idx", ")", "in", "enumerate", "(", "zip", "(", "x", ",", "y", ",", "z", ",", "example_ids", ")", ")", ":", "\n", "    ", "for", "bucket_id", ",", "(", "source_size", ",", ")", "in", "enumerate", "(", "_buckets", ")", ":", "\n", "      ", "if", "len", "(", "source", ")", "<", "source_size", ":", "\n", "        ", "if", "extra_x", ":", "\n", "            ", "data_set", "[", "bucket_id", "]", ".", "append", "(", "[", "source", ",", "extra_x", "[", "i", "]", ",", "target", ",", "label", ",", "idx", "]", ")", "\n", "", "else", ":", "\n", "            ", "data_set", "[", "bucket_id", "]", ".", "append", "(", "[", "source", ",", "None", ",", "target", ",", "label", ",", "idx", "]", ")", "\n", "", "break", "\n", "", "", "", "return", "data_set", "# 4 outputs in each unit: source_ids, source_matrix, target_ids, label_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.run.read_data": [[454, 556], ["open", "json.load", "len", "len", "len", "print", "print", "print", "print", "print", "json.load.get", "str", "str", "str", "print", "numpy.asarray", "print", "exit", "print", "print", "exit", "vocab.items", "str", "str", "label_vocab.items", "len", "len", "len", "label_vocab.items", "label_vocab.items"], "function", ["None"], ["", "def", "read_data", "(", "FLAGS", ")", ":", "\n", "  ", "\"\"\"\n  Reads the json and extracts the coresponding data\n\n  :param json_path:\n  :param task:\n  :param FLAGS:\n  :return:\n  \"\"\"", "\n", "with", "open", "(", "FLAGS", ".", "json_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "\n", "    ", "jsondic", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "len_train_x", "=", "len", "(", "jsondic", "[", "\"train_x\"", "]", ")", "\n", "len_valid_x", "=", "len", "(", "jsondic", "[", "\"valid_x\"", "]", ")", "\n", "len_test_x", "=", "len", "(", "jsondic", "[", "\"test_x\"", "]", ")", "\n", "\n", "print", "(", "\"Train examples: \"", "+", "str", "(", "len_train_x", ")", ")", "\n", "print", "(", "\"Valid examples: \"", "+", "str", "(", "len_valid_x", ")", ")", "\n", "print", "(", "\"Test examples: \"", "+", "str", "(", "len_test_x", ")", ")", "\n", "\n", "if", "len_test_x", "%", "FLAGS", ".", "eval_batch_size", ":", "\n", "# print(\"Reseting eval_batch_size to 1\")", "\n", "# FLAGS.eval_batch_size = 1", "\n", "      ", "test_limit", "=", "len_test_x", "-", "(", "len_test_x", "%", "FLAGS", ".", "eval_batch_size", ")", "\n", "print", "(", "\"Incompatible eval_batch_size for testing, reseting to \"", "+", "str", "(", "test_limit", ")", ")", "\n", "", "else", ":", "\n", "      ", "test_limit", "=", "len_test_x", "\n", "\n", "", "if", "len_valid_x", "%", "FLAGS", ".", "eval_batch_size", ":", "\n", "      ", "valid_limit", "=", "len_valid_x", "-", "(", "len_valid_x", "%", "FLAGS", ".", "eval_batch_size", ")", "\n", "print", "(", "\"Incompatible eval_batch_size for validation, reseting to \"", "+", "str", "(", "valid_limit", ")", ")", "\n", "", "else", ":", "\n", "      ", "valid_limit", "=", "len_valid_x", "\n", "\n", "", "train_x", ",", "train_y", "=", "jsondic", "[", "\"train_x\"", "]", ",", "jsondic", "[", "\"train_y\"", "]", "\n", "valid_x", ",", "valid_y", "=", "jsondic", "[", "\"valid_x\"", "]", "[", ":", "valid_limit", "]", ",", "jsondic", "[", "\"valid_y\"", "]", "[", ":", "valid_limit", "]", "\n", "test_x", ",", "test_y", "=", "jsondic", "[", "\"test_x\"", "]", "[", ":", "test_limit", "]", ",", "jsondic", "[", "\"test_y\"", "]", "[", ":", "test_limit", "]", "\n", "\n", "train_ids", "=", "jsondic", "[", "\"train_ids\"", "]", "\n", "valid_ids", "=", "jsondic", "[", "\"valid_ids\"", "]", "[", ":", "valid_limit", "]", "\n", "test_ids", "=", "jsondic", "[", "\"test_ids\"", "]", "[", ":", "test_limit", "]", "\n", "\n", "class_dim", "=", "jsondic", "[", "\"classdim\"", "]", "\n", "\n", "if", "FLAGS", ".", "task", "[", "'classification'", "]", "==", "1", ":", "\n", "      ", "train_z", "=", "jsondic", "[", "\"train_z\"", "]", "\n", "valid_z", "=", "jsondic", "[", "\"valid_z\"", "]", "[", ":", "valid_limit", "]", "\n", "test_z", "=", "jsondic", "[", "\"test_z\"", "]", "[", ":", "test_limit", "]", "\n", "\n", "label_vocab", "=", "jsondic", "[", "\"class2idx\"", "]", "\n", "rev_label_vocab", "=", "{", "idx", ":", "token", "for", "token", ",", "idx", "in", "label_vocab", ".", "items", "(", ")", "}", "\n", "\n", "", "else", ":", "\n", "      ", "if", "class_dim", ">", "1", ":", "\n", "        ", "train_z", "=", "jsondic", "[", "\"train_z\"", "]", "\n", "valid_z", "=", "jsondic", "[", "\"valid_z\"", "]", "[", ":", "valid_limit", "]", "\n", "test_z", "=", "jsondic", "[", "\"test_z\"", "]", "[", ":", "test_limit", "]", "\n", "label_vocab", "=", "jsondic", "[", "\"class2idx\"", "]", "\n", "rev_label_vocab", "=", "{", "idx", ":", "token", "for", "token", ",", "idx", "in", "label_vocab", ".", "items", "(", ")", "}", "\n", "", "else", ":", "\n", "# generating \"fake\" labels", "\n", "        ", "train_z", "=", "[", "0", "]", "*", "len", "(", "train_x", ")", "\n", "valid_z", "=", "[", "0", "]", "*", "len", "(", "valid_x", ")", "\n", "test_z", "=", "[", "0", "]", "*", "len", "(", "test_x", ")", "\n", "label_vocab", "=", "jsondic", "[", "\"class2idx\"", "]", "\n", "rev_label_vocab", "=", "{", "idx", ":", "token", "for", "token", ",", "idx", "in", "label_vocab", ".", "items", "(", ")", "}", "\n", "\n", "", "", "if", "FLAGS", ".", "word_embedding_size", "==", "0", ":", "\n", "      ", "if", "\"embeddings\"", "in", "jsondic", ":", "\n", "        ", "print", "(", "\"Loading embeddings from JSON data...\"", ")", "\n", "embeddings_matrix", "=", "np", ".", "asarray", "(", "jsondic", "[", "\"embeddings\"", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'No embeddings in JSON data, please indicate word embedding size'", ")", "\n", "exit", "(", ")", "\n", "", "", "else", ":", "\n", "      ", "embeddings_matrix", "=", "None", "\n", "\n", "", "if", "FLAGS", ".", "use_binary_features", ":", "\n", "      ", "if", "jsondic", ".", "get", "(", "\"featdim\"", ",", "None", ")", ":", "\n", "        ", "print", "(", "\"Found binary features, adding them.\"", ")", "\n", "train_feat_x", "=", "jsondic", "[", "\"train_feat_x\"", "]", "\n", "valid_feat_x", "=", "jsondic", "[", "\"valid_feat_x\"", "]", "[", ":", "valid_limit", "]", "\n", "test_feat_x", "=", "jsondic", "[", "\"test_feat_x\"", "]", "[", ":", "test_limit", "]", "\n", "binary_feat_dim", "=", "jsondic", "[", "\"featdim\"", "]", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"No binary feats found in JSON data, please change flag an re run.\"", ")", "\n", "exit", "(", ")", "\n", "", "", "else", ":", "\n", "      ", "train_feat_x", "=", "valid_feat_x", "=", "test_feat_x", "=", "None", "\n", "binary_feat_dim", "=", "0", "\n", "\n", "", "vocab", "=", "jsondic", "[", "\"token2idx\"", "]", "\n", "rev_vocab", "=", "{", "idx", ":", "token", "for", "token", ",", "idx", "in", "vocab", ".", "items", "(", ")", "}", "\n", "\n", "train", "=", "[", "train_x", ",", "train_feat_x", ",", "train_y", ",", "train_z", ",", "train_ids", "]", "\n", "valid", "=", "[", "valid_x", ",", "valid_feat_x", ",", "valid_y", ",", "valid_z", ",", "valid_ids", "]", "\n", "test", "=", "[", "test_x", ",", "test_feat_x", ",", "test_y", ",", "test_z", ",", "test_ids", "]", "\n", "vocabs", "=", "[", "vocab", ",", "label_vocab", "]", "\n", "rev_vocabs", "=", "[", "rev_vocab", ",", "rev_label_vocab", "]", "\n", "\n", "return", "[", "train", ",", "valid", ",", "test", ",", "vocabs", ",", "rev_vocabs", ",", "binary_feat_dim", ",", "class_dim", ",", "embeddings_matrix", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.run.create_model": [[558, 619], ["tensorflow.train.get_checkpoint_state", "tensorflow.variable_scope", "enlp.multi_task_rnn.MultiTaskModel", "tensorflow.variable_scope", "enlp.multi_task_rnn.MultiTaskModel", "tensorflow.gfile.Exists", "print", "enlp.multi_task_rnn.MultiTaskModel.saver.restore", "print", "session.run", "tensorflow.global_variables_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "session.run", "tf.get_variable.assign"], "function", ["None"], ["", "", "def", "create_model", "(", "session", ",", "source_vocab_size", ",", "label_vocab_size", ",", "\n", "word_embedding_matrix", ",", "binary_feat_dim", ",", "class_dim", ",", "FLAGS", ",", "_buckets", ")", ":", "\n", "  ", "\"\"\"Create model and initialize or load parameters in session.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "\"model\"", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "model_train", "=", "MultiTaskModel", "(", "source_vocab_size", ",", "label_vocab_size", ",", "_buckets", ",", "\n", "FLAGS", ".", "word_embedding_size", ",", "FLAGS", ".", "size", ",", "FLAGS", ".", "num_layers", ",", "\n", "FLAGS", ".", "max_gradient_norm", ",", "FLAGS", ".", "batch_size", ",", "\n", "dropout_keep_prob", "=", "FLAGS", ".", "dropout_keep_prob", ",", "\n", "zoneout_keep_prob", "=", "FLAGS", ".", "zoneout_keep_prob", ",", "\n", "rnn", "=", "FLAGS", ".", "rnn", ",", "\n", "forward_only", "=", "False", ",", "use_attention", "=", "FLAGS", ".", "use_attention", ",", "\n", "bidirectional_rnn", "=", "FLAGS", ".", "bidirectional_rnn", ",", "task", "=", "FLAGS", ".", "task", ",", "\n", "context_win_size", "=", "FLAGS", ".", "context_win_size", ",", "\n", "word_embedding_matrix", "=", "word_embedding_matrix", ",", "\n", "learning_rate", "=", "FLAGS", ".", "learning_rate", ",", "\n", "decay_factor", "=", "FLAGS", ".", "decay_factor", ",", "\n", "decay_end", "=", "FLAGS", ".", "decay_end", ",", "\n", "use_binary_features", "=", "FLAGS", ".", "use_binary_features", ",", "\n", "binary_feat_dim", "=", "binary_feat_dim", ",", "\n", "class_dim", "=", "class_dim", ",", "\n", "optimizer", "=", "FLAGS", ".", "optimizer", ",", "\n", "loss", "=", "FLAGS", ".", "loss", ",", "\n", "train_embeddings", "=", "FLAGS", ".", "train_word_embeddings", ",", "\n", "regularization_lambda", "=", "FLAGS", ".", "regularization_lambda", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"model\"", ",", "reuse", "=", "True", ")", ":", "\n", "    ", "model_test", "=", "MultiTaskModel", "(", "source_vocab_size", ",", "label_vocab_size", ",", "_buckets", ",", "\n", "FLAGS", ".", "word_embedding_size", ",", "FLAGS", ".", "size", ",", "FLAGS", ".", "num_layers", ",", "\n", "FLAGS", ".", "max_gradient_norm", ",", "FLAGS", ".", "eval_batch_size", ",", "\n", "dropout_keep_prob", "=", "FLAGS", ".", "dropout_keep_prob", ",", "\n", "zoneout_keep_prob", "=", "FLAGS", ".", "zoneout_keep_prob", ",", "\n", "rnn", "=", "FLAGS", ".", "rnn", ",", "\n", "forward_only", "=", "True", ",", "use_attention", "=", "FLAGS", ".", "use_attention", ",", "\n", "bidirectional_rnn", "=", "FLAGS", ".", "bidirectional_rnn", ",", "task", "=", "FLAGS", ".", "task", ",", "\n", "context_win_size", "=", "FLAGS", ".", "context_win_size", ",", "\n", "word_embedding_matrix", "=", "word_embedding_matrix", ",", "\n", "learning_rate", "=", "FLAGS", ".", "learning_rate", ",", "\n", "decay_factor", "=", "FLAGS", ".", "decay_factor", ",", "\n", "decay_end", "=", "FLAGS", ".", "decay_end", ",", "\n", "use_binary_features", "=", "FLAGS", ".", "use_binary_features", ",", "\n", "binary_feat_dim", "=", "binary_feat_dim", ",", "\n", "class_dim", "=", "class_dim", ",", "\n", "optimizer", "=", "FLAGS", ".", "optimizer", ",", "\n", "loss", "=", "FLAGS", ".", "loss", ",", "\n", "train_embeddings", "=", "FLAGS", ".", "train_word_embeddings", ",", "\n", "regularization_lambda", "=", "FLAGS", ".", "regularization_lambda", ")", "\n", "\n", "", "ckpt", "=", "tf", ".", "train", ".", "get_checkpoint_state", "(", "FLAGS", ".", "checkpoint_path", ")", "\n", "\n", "if", "ckpt", "and", "tf", ".", "gfile", ".", "Exists", "(", "ckpt", ".", "model_checkpoint_path", ")", ":", "\n", "    ", "print", "(", "\"Reading model parameters from %s\"", "%", "ckpt", ".", "model_checkpoint_path", ")", "\n", "model_train", ".", "saver", ".", "restore", "(", "session", ",", "ckpt", ".", "model_checkpoint_path", ")", "\n", "", "else", ":", "\n", "    ", "print", "(", "\"Created model with fresh parameters.\"", ")", "\n", "session", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "if", "FLAGS", ".", "word_embedding_size", "==", "0", "and", "word_embedding_matrix", "is", "not", "None", ":", "\n", "      ", "with", "tf", ".", "variable_scope", "(", "\"model\"", ",", "reuse", "=", "True", ")", ":", "\n", "        ", "embedding", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ")", "\n", "session", ".", "run", "(", "embedding", ".", "assign", "(", "word_embedding_matrix", ")", ")", "\n", "", "", "", "return", "model_train", ",", "model_test", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.None.run.run_valid_test": [[621, 732], ["six.moves.xrange", "len", "numpy.mean", "print", "enlp.eval.regeval", "print", "print", "sys.stdout.flush", "print", "enlp.eval.classeval", "enlp.eval.classeval.items", "sys.stdout.flush", "len", "model_test.get_batch", "enumerate", "range", "rev_label_vocab.values", "print", "open", "json.dump", "model_test.joint_step", "len", "six.moves.xrange", "word_idx_list.append", "range", "len", "ref_label_list.append", "abs", "float", "model_test.classification_step", "current_word_idx_list.append", "reg_attentions.append", "class_attentions.append", "len", "hyp_values_list.append", "numpy.argmax", "hyp_label_list.append", "zip", "float", "model_test.regression_step", "[].tolist", "[].tolist", "ref_values_list.append"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.enlp.eval.regeval", "home.repos.pwc.inspect_result.epochx_emoatt.enlp.eval.classeval", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.__init__.MultiTaskModel.get_batch", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.range", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.__init__.MultiTaskModel.joint_step", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.range", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.__init__.MultiTaskModel.classification_step", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.__init__.MultiTaskModel.regression_step", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], ["", "def", "run_valid_test", "(", "model_test", ",", "sess", ",", "data_set", ",", "mode", ",", "task", ",", "\n", "rev_vocab", ",", "rev_label_vocab", ",", "FLAGS", ",", "_buckets", ",", "\n", "classification_out_file", "=", "None", ",", "regression_out_file", "=", "None", ",", "\n", "attentions_out_file", "=", "None", ")", ":", "\n", "# Run evals on development/test set and print the accuracy.", "\n", "    ", "ref_values_list", ",", "hyp_values_list", "=", "[", "]", ",", "[", "]", "\n", "ref_label_list", ",", "hyp_label_list", "=", "[", "]", ",", "[", "]", "\n", "word_idx_list", "=", "[", "]", "\n", "class_attentions", "=", "[", "]", "\n", "reg_attentions", "=", "[", "]", "\n", "example_ids", "=", "[", "]", "\n", "correct_count", "=", "0", "\n", "accuracy", "=", "0.0", "\n", "\n", "model_batch_size", "=", "model_test", ".", "batch_size", "\n", "for", "bucket_id", "in", "xrange", "(", "len", "(", "_buckets", ")", ")", ":", "\n", "        ", "eval_loss", "=", "0.0", "\n", "count", "=", "0", "\n", "while", "count", "<", "len", "(", "data_set", "[", "bucket_id", "]", ")", ":", "\n", "#if model_batch_size == 1:", "\n", "#  model_inputs = model_test.get_one(data_set, bucket_id, count)", "\n", "#else:", "\n", "            ", "model_inputs", "=", "model_test", ".", "get_batch", "(", "data_set", ",", "bucket_id", ",", "count", ")", "\n", "\n", "encoder_inputs", ",", "simple_encoder_inputs", ",", "encoder_extra_inputs", ",", "sequence_lengths", ",", "values", ",", "labels", ",", "ids", "=", "model_inputs", "\n", "\n", "reg_values", "=", "[", "]", "\n", "class_logits", "=", "[", "]", "\n", "\n", "if", "task", "[", "'joint'", "]", "==", "1", ":", "\n", "              ", "output", "=", "model_test", ".", "joint_step", "(", "sess", ",", "encoder_inputs", ",", "encoder_extra_inputs", ",", "\n", "values", ",", "labels", ",", "sequence_lengths", ",", "bucket_id", ",", "True", ")", "\n", "_", ",", "step_loss", ",", "reg_values", ",", "reg_att", ",", "class_logits", ",", "class_att", "=", "output", "\n", "\n", "", "elif", "task", "[", "'classification'", "]", "==", "1", ":", "\n", "              ", "output", "=", "model_test", ".", "classification_step", "(", "sess", ",", "encoder_inputs", ",", "encoder_extra_inputs", ",", "\n", "labels", ",", "sequence_lengths", ",", "bucket_id", ",", "True", ")", "\n", "_", ",", "step_loss", ",", "class_logits", ",", "class_att", "=", "output", "\n", "\n", "", "elif", "task", "[", "'regression'", "]", "==", "1", ":", "\n", "                ", "output", "=", "model_test", ".", "regression_step", "(", "sess", ",", "encoder_inputs", ",", "encoder_extra_inputs", ",", "\n", "values", ",", "labels", ",", "sequence_lengths", ",", "bucket_id", ",", "True", ")", "\n", "_", ",", "step_loss", ",", "reg_values", ",", "reg_att", "=", "output", "\n", "\n", "", "eval_loss", "+=", "step_loss", "/", "len", "(", "data_set", "[", "bucket_id", "]", ")", "\n", "\n", "example_ids", "+=", "ids", "\n", "\n", "for", "seq_id", ",", "sequence_length", "in", "enumerate", "(", "sequence_lengths", ")", ":", "\n", "              ", "current_word_idx_list", "=", "[", "]", "\n", "for", "token_id", "in", "xrange", "(", "sequence_length", ")", ":", "\n", "                ", "current_word_idx_list", ".", "append", "(", "simple_encoder_inputs", "[", "token_id", "]", "[", "seq_id", "]", ")", "\n", "", "word_idx_list", ".", "append", "(", "current_word_idx_list", ")", "\n", "if", "task", "[", "'regression'", "]", "==", "1", ":", "\n", "                ", "reg_attentions", ".", "append", "(", "reg_att", "[", "seq_id", "]", "[", ":", "sequence_length", "]", ".", "tolist", "(", ")", ")", "\n", "", "if", "task", "[", "'classification'", "]", "==", "1", ":", "\n", "                ", "class_attentions", ".", "append", "(", "class_att", "[", "seq_id", "]", "[", ":", "sequence_length", "]", ".", "tolist", "(", ")", ")", "\n", "\n", "", "", "if", "task", "[", "'regression'", "]", "==", "1", ":", "\n", "              ", "for", "seq_id", "in", "range", "(", "len", "(", "sequence_lengths", ")", ")", ":", "\n", "                ", "hyp_value", "=", "reg_values", "[", "seq_id", "]", "\n", "hyp_values_list", ".", "append", "(", "hyp_value", ")", "\n", "if", "mode", "!=", "\"Test\"", ":", "\n", "                  ", "ref_value", "=", "values", "[", "0", "]", "[", "seq_id", "]", "\n", "ref_values_list", ".", "append", "(", "ref_value", ")", "\n", "\n", "", "", "", "for", "seq_id", "in", "range", "(", "len", "(", "sequence_lengths", ")", ")", ":", "\n", "              ", "ref_label", "=", "rev_label_vocab", "[", "labels", "[", "0", "]", "[", "seq_id", "]", "]", "\n", "ref_label_list", ".", "append", "(", "ref_label", ")", "\n", "if", "task", "[", "'classification'", "]", "==", "1", ":", "\n", "                ", "hyp_class", "=", "np", ".", "argmax", "(", "class_logits", "[", "seq_id", "]", ")", "\n", "hyp_label", "=", "rev_label_vocab", "[", "hyp_class", "]", "\n", "hyp_label_list", ".", "append", "(", "hyp_label", ")", "\n", "if", "ref_label", "==", "hyp_label", ":", "\n", "                  ", "correct_count", "+=", "1", "\n", "\n", "", "", "", "count", "+=", "model_batch_size", "\n", "\n", "", "", "word_list", "=", "[", "[", "rev_vocab", "[", "idx", "]", "for", "idx", "in", "sequence", "]", "for", "sequence", "in", "word_idx_list", "]", "\n", "if", "mode", "!=", "\"Test\"", ":", "\n", "      ", "regression_mean_error", "=", "np", ".", "mean", "(", "[", "abs", "(", "ref", "-", "hyp", ")", "for", "ref", ",", "hyp", "in", "zip", "(", "ref_values_list", ",", "hyp_values_list", ")", "]", ")", "\n", "", "else", ":", "\n", "      ", "regression_mean_error", "=", "0", "\n", "", "if", "FLAGS", ".", "task", "[", "'regression'", "]", "==", "1", ":", "\n", "        ", "print", "(", "\"  %s regression mean error: %.2f\"", "%", "(", "mode", ",", "float", "(", "regression_mean_error", ")", ")", ")", "\n", "regression_eval_result", "=", "regeval", "(", "word_list", ",", "hyp_values_list", ",", "ref_values_list", ",", "ref_label_list", ",", "\n", "example_ids", ",", "regression_out_file", "=", "regression_out_file", ")", "\n", "pear", ",", "spear", ",", "pear_05", ",", "spear_05", "=", "regression_eval_result", "\n", "print", "(", "\"  %s regression mean pearson: %.2f  regression mean spearman: %.2f \"", "%", "(", "mode", ",", "pear", ",", "spear", ")", ")", "\n", "print", "(", "\"  %s regression top 0.5 mean pearson: %.2f  regression top 0.5 mean spearman: %.2f \"", "%", "(", "mode", ",", "pear_05", ",", "spear_05", ")", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "if", "FLAGS", ".", "task", "[", "'classification'", "]", "==", "1", ":", "\n", "        ", "accuracy", "=", "float", "(", "correct_count", ")", "*", "100", "/", "count", "\n", "print", "(", "\"  %s classification accuracy: %.2f %d/%d\"", "%", "(", "mode", ",", "accuracy", ",", "correct_count", ",", "count", ")", ")", "\n", "classification_eval_result", "=", "classeval", "(", "hyp_label_list", ",", "ref_label_list", ",", "rev_label_vocab", ".", "values", "(", ")", ",", "\n", "classification_out_file", ")", "\n", "for", "label", ",", "cm", "in", "classification_eval_result", ".", "items", "(", ")", ":", "\n", "          ", "print", "(", "\"  \\t%s accuracy: %.2f  precision: %.2f  recall: %.2f  f1-score: %.2f\"", "%", "(", "\n", "label", ",", "100", "*", "cm", "[", "\"a\"", "]", ",", "100", "*", "cm", "[", "\"p\"", "]", ",", "100", "*", "cm", "[", "\"r\"", "]", ",", "100", "*", "cm", "[", "\"f1\"", "]", ")", ")", "\n", "", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "if", "attentions_out_file", ":", "\n", "      ", "json_att_dic", "=", "{", "\"regression_atts\"", ":", "reg_attentions", ",", "\n", "\"sequences\"", ":", "word_list", "}", "\n", "\n", "with", "open", "(", "attentions_out_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "json_att_dic", ",", "f", ")", "\n", "\n", "", "", "return", "(", "regression_mean_error", ",", "pear", ",", "spear", ",", "pear_05", ",", "spear_05", ")", ",", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.eval.ConfusionMatrix.__init__": [[10, 17], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "label", ",", "true_positives", "=", "None", ",", "false_positives", "=", "None", ",", "true_negatives", "=", "None", ",", "\n", "false_negatives", "=", "None", ")", ":", "\n", "        ", "self", ".", "label", "=", "label", "\n", "self", ".", "tp", "=", "self", ".", "true_positives", "=", "true_positives", "if", "true_positives", "else", "[", "]", "\n", "self", ".", "fp", "=", "self", ".", "false_positives", "=", "false_positives", "if", "false_positives", "else", "[", "]", "\n", "self", ".", "tn", "=", "self", ".", "true_negatives", "=", "true_negatives", "if", "true_negatives", "else", "[", "]", "\n", "self", ".", "fn", "=", "self", ".", "false_negatives", "=", "false_negatives", "if", "false_negatives", "else", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.eval.ConfusionMatrix.__repr__": [[18, 25], ["str", "str", "str", "str", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "string", "=", "''", "\n", "string", "+=", "\"True Positives: \"", "+", "str", "(", "len", "(", "self", ".", "tp", ")", ")", "+", "'\\n'", "\n", "string", "+=", "\"False Positives: \"", "+", "str", "(", "len", "(", "self", ".", "fp", ")", ")", "+", "'\\n'", "\n", "string", "+=", "\"True Negatives: \"", "+", "str", "(", "len", "(", "self", ".", "tn", ")", ")", "+", "'\\n'", "\n", "string", "+=", "\"False negatives: \"", "+", "str", "(", "len", "(", "self", ".", "fn", ")", ")", "+", "'\\n'", "\n", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.eval.ConfusionMatrix.precision": [[26, 32], ["len", "len", "len"], "methods", ["None"], ["", "@", "property", "\n", "def", "precision", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "1.0", "*", "len", "(", "self", ".", "tp", ")", "/", "(", "len", "(", "self", ".", "tp", ")", "+", "len", "(", "self", ".", "fp", ")", ")", "\n", "", "except", "ZeroDivisionError", ":", "\n", "            ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.eval.ConfusionMatrix.recall": [[33, 39], ["len", "len", "len"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "recall", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "1.0", "*", "len", "(", "self", ".", "tp", ")", "/", "(", "len", "(", "self", ".", "tp", ")", "+", "len", "(", "self", ".", "fn", ")", ")", "\n", "", "except", "ZeroDivisionError", ":", "\n", "            ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.eval.ConfusionMatrix.fmeasure": [[40, 48], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "fmeasure", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "precision", "=", "self", ".", "precision", "\n", "recall", "=", "self", ".", "recall", "\n", "return", "2", "*", "(", "(", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", ")", "\n", "", "except", "ZeroDivisionError", ":", "\n", "            ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.eval.ConfusionMatrix.accuracy": [[49, 55], ["len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "accuracy", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "1.0", "*", "(", "len", "(", "self", ".", "tp", ")", "+", "len", "(", "self", ".", "tn", ")", ")", "/", "(", "len", "(", "self", ".", "tp", ")", "+", "len", "(", "self", ".", "tn", ")", "+", "len", "(", "self", ".", "fn", ")", "+", "len", "(", "self", ".", "fp", ")", ")", "\n", "", "except", "ZeroDivisionError", ":", "\n", "            ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.eval.ConfusionMatrix.measures": [[56, 61], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "measures", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"p\"", ":", "self", ".", "precision", ",", "\n", "\"r\"", ":", "self", ".", "recall", ",", "\n", "\"f1\"", ":", "self", ".", "fmeasure", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.eval.classeval": [[68, 95], ["eval.ConfusionMatrix", "enumerate", "len", "len", "eval.ConfusionMatrix", "zip", "cm[].tp.append", "cm[].tp.append", "cm[].fn.append", "cm[].fp.append", "cm[].fp.append", "open", "zip", "cm.items", "f.write", "cm[].tn.append"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], ["", "def", "classeval", "(", "predicted_labels", ",", "reference_labels", ",", "labels", ",", "classification_out_file", "=", "None", ")", ":", "\n", "    ", "assert", "len", "(", "predicted_labels", ")", "==", "len", "(", "reference_labels", ")", "\n", "\n", "cm", "=", "{", "}", "\n", "for", "label", "in", "labels", ":", "\n", "        ", "cm", "[", "label", "]", "=", "ConfusionMatrix", "(", "label", ")", "\n", "\n", "", "cm", "[", "\"all\"", "]", "=", "ConfusionMatrix", "(", "\"all\"", ")", "\n", "\n", "for", "i", ",", "(", "pred_label", ",", "ref_label", ")", "in", "enumerate", "(", "zip", "(", "predicted_labels", ",", "reference_labels", ")", ")", ":", "\n", "        ", "if", "pred_label", "==", "ref_label", ":", "\n", "            ", "cm", "[", "ref_label", "]", ".", "tp", ".", "append", "(", "i", ")", "\n", "cm", "[", "\"all\"", "]", ".", "tp", ".", "append", "(", "i", ")", "\n", "for", "label", "in", "labels", ":", "\n", "                ", "if", "label", "!=", "ref_label", ":", "\n", "                    ", "cm", "[", "label", "]", ".", "tn", ".", "append", "(", "i", ")", "\n", "", "", "", "else", ":", "\n", "            ", "cm", "[", "ref_label", "]", ".", "fn", ".", "append", "(", "i", ")", "\n", "cm", "[", "pred_label", "]", ".", "fp", ".", "append", "(", "i", ")", "\n", "cm", "[", "\"all\"", "]", ".", "fp", ".", "append", "(", "i", ")", "\n", "\n", "", "", "if", "classification_out_file", ":", "\n", "        ", "with", "open", "(", "classification_out_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "pred_label", ",", "ref_label", "in", "zip", "(", "predicted_labels", ",", "reference_labels", ")", ":", "\n", "                ", "f", ".", "write", "(", "\"{0} {1}\\n\"", ".", "format", "(", "pred_label", ",", "ref_label", ")", ")", "\n", "\n", "", "", "", "return", "{", "key", ":", "value", ".", "measures", "for", "key", ",", "value", "in", "cm", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.eval.regeval": [[97, 140], ["open", "zip", "eval.correval", "pear_results.append", "spear_results.append", "pear_results_range_05_1.append", "spear_results_range_05_1.append", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "f.write", "open", "zip", "string.encode", "f.write", "string.encode", "str", "str"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.enlp.eval.correval", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], ["", "def", "regeval", "(", "words_list", ",", "hyp_values", ",", "ref_values", ",", "ref_labels", ",", "ids", ",", "regression_out_file", ")", ":", "\n", "#  id[tab]tweet[tab]emotion[tab]score", "\n", "    ", "tweets", "=", "[", "\" \"", ".", "join", "(", "tweet_list", ")", "for", "tweet_list", "in", "words_list", "]", "\n", "ref_file_path", "=", "regression_out_file", "+", "\".ref\"", "\n", "hyp_file_path", "=", "regression_out_file", "+", "\".hyp\"", "\n", "\n", "with", "open", "(", "hyp_file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "(", "idx", ",", "tweet", ",", "ref_label", ",", "hyp_value", ")", "in", "zip", "(", "ids", ",", "tweets", ",", "ref_labels", ",", "hyp_values", ")", ":", "\n", "            ", "string", "=", "\"\\t\"", ".", "join", "(", "(", "idx", ",", "tweet", ",", "ref_label", ",", "str", "(", "hyp_value", "[", "0", "]", ")", ")", ")", "+", "\"\\n\"", "\n", "f", ".", "write", "(", "string", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "\n", "", "", "if", "ref_values", ":", "\n", "        ", "with", "open", "(", "ref_file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "(", "idx", ",", "tweet", ",", "ref_label", ",", "ref_value", ")", "in", "zip", "(", "ids", ",", "tweets", ",", "ref_labels", ",", "ref_values", ")", ":", "\n", "                ", "string", "=", "\"\\t\"", ".", "join", "(", "(", "idx", ",", "tweet", ",", "ref_label", ",", "str", "(", "ref_value", ")", ")", ")", "+", "\"\\n\"", "\n", "f", ".", "write", "(", "string", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "\n", "\n", "", "", "result", "=", "correval", "(", "hyp_file_path", ",", "ref_file_path", ")", "\n", "\n", "pear_results", "=", "[", "]", "\n", "spear_results", "=", "[", "]", "\n", "\n", "pear_results_range_05_1", "=", "[", "]", "\n", "spear_results_range_05_1", "=", "[", "]", "\n", "\n", "pear_results", ".", "append", "(", "result", "[", "0", "]", ")", "\n", "spear_results", ".", "append", "(", "result", "[", "1", "]", ")", "\n", "\n", "pear_results_range_05_1", ".", "append", "(", "result", "[", "2", "]", ")", "\n", "spear_results_range_05_1", ".", "append", "(", "result", "[", "3", "]", ")", "\n", "\n", "avg_pear", "=", "numpy", ".", "mean", "(", "pear_results", ")", "\n", "avg_spear", "=", "numpy", ".", "mean", "(", "spear_results", ")", "\n", "\n", "avg_pear_range_05_1", "=", "numpy", ".", "mean", "(", "pear_results_range_05_1", ")", "\n", "avg_spear_range_05_1", "=", "numpy", ".", "mean", "(", "spear_results_range_05_1", ")", "\n", "\n", "\n", "return", "avg_pear", ",", "avg_spear", ",", "avg_pear_range_05_1", ",", "avg_spear_range_05_1", "\n", "\n", "", "else", ":", "\n", "        ", "return", "0", ",", "0", ",", "0", ",", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.eval.correval": [[141, 207], ["open", "open.readlines", "open.close", "open", "open.readlines", "open.close", "len", "len", "ValueError", "line.split", "line.split", "scipy.stats.pearsonr", "scipy.stats.spearmanr", "scipy.stats.pearsonr", "scipy.stats.spearmanr", "len", "ValueError", "len", "ValueError", "len", "gold_scores.append", "pred_scores.append", "ValueError", "numpy.std", "numpy.std", "float", "int", "ValueError", "gold_scores_range_05_1.append", "pred_scores_range_05_1.append", "int", "data_dic[].append", "line.split", "float", "data_dic[].append", "line.split", "int", "int"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], ["", "", "def", "correval", "(", "pred", ",", "gold", ")", ":", "\n", "    ", "f", "=", "open", "(", "pred", ",", "\"rb\"", ")", "\n", "pred_lines", "=", "f", ".", "readlines", "(", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n", "f", "=", "open", "(", "gold", ",", "\"rb\"", ")", "\n", "gold_lines", "=", "f", ".", "readlines", "(", ")", "\n", "f", ".", "close", "(", ")", "\n", "\n", "if", "(", "len", "(", "pred_lines", ")", "==", "len", "(", "gold_lines", ")", ")", ":", "\n", "# align tweets ids with gold scores and predictions", "\n", "        ", "data_dic", "=", "{", "}", "\n", "\n", "for", "line", "in", "gold_lines", ":", "\n", "            ", "parts", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "if", "len", "(", "parts", ")", "==", "4", ":", "\n", "                ", "data_dic", "[", "int", "(", "parts", "[", "0", "]", ")", "]", "=", "[", "float", "(", "line", ".", "split", "(", "'\\t'", ")", "[", "3", "]", ")", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Format problem.'", ")", "\n", "\n", "", "", "for", "line", "in", "pred_lines", ":", "\n", "            ", "parts", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "if", "len", "(", "parts", ")", "==", "4", ":", "\n", "                ", "if", "int", "(", "parts", "[", "0", "]", ")", "in", "data_dic", ":", "\n", "                    ", "try", ":", "\n", "                        ", "data_dic", "[", "int", "(", "parts", "[", "0", "]", ")", "]", ".", "append", "(", "float", "(", "line", ".", "split", "(", "'\\t'", ")", "[", "3", "]", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "# Invalid predictions are replaced by a default value", "\n", "                        ", "data_dic", "[", "int", "(", "parts", "[", "0", "]", ")", "]", ".", "append", "(", "0.5", ")", "\n", "", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "'Invalid tweet id.'", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Format problem.'", ")", "\n", "\n", "# lists storing gold and prediction scores", "\n", "", "", "gold_scores", "=", "[", "]", "\n", "pred_scores", "=", "[", "]", "\n", "\n", "# lists storing gold and prediction scores where gold score >= 0.5", "\n", "gold_scores_range_05_1", "=", "[", "]", "\n", "pred_scores_range_05_1", "=", "[", "]", "\n", "\n", "for", "id", "in", "data_dic", ":", "\n", "            ", "if", "(", "len", "(", "data_dic", "[", "id", "]", ")", "==", "2", ")", ":", "\n", "                ", "gold_scores", ".", "append", "(", "data_dic", "[", "id", "]", "[", "0", "]", ")", "\n", "pred_scores", ".", "append", "(", "data_dic", "[", "id", "]", "[", "1", "]", ")", "\n", "if", "(", "data_dic", "[", "id", "]", "[", "0", "]", ">=", "0.5", ")", ":", "\n", "                    ", "gold_scores_range_05_1", ".", "append", "(", "data_dic", "[", "id", "]", "[", "0", "]", ")", "\n", "pred_scores_range_05_1", ".", "append", "(", "data_dic", "[", "id", "]", "[", "1", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'Repeated id in test data.'", ")", "\n", "\n", "# return zero correlation if predictions are constant", "\n", "", "", "if", "numpy", ".", "std", "(", "pred_scores", ")", "==", "0", "or", "numpy", ".", "std", "(", "gold_scores", ")", "==", "0", ":", "\n", "            ", "return", "(", "0", ",", "0", ",", "0", ",", "0", ")", "\n", "\n", "", "pears_corr", "=", "scipy", ".", "stats", ".", "pearsonr", "(", "pred_scores", ",", "gold_scores", ")", "[", "0", "]", "\n", "spear_corr", "=", "scipy", ".", "stats", ".", "spearmanr", "(", "pred_scores", ",", "gold_scores", ")", "[", "0", "]", "\n", "\n", "pears_corr_range_05_1", "=", "scipy", ".", "stats", ".", "pearsonr", "(", "pred_scores_range_05_1", ",", "gold_scores_range_05_1", ")", "[", "0", "]", "\n", "spear_corr_range_05_1", "=", "scipy", ".", "stats", ".", "spearmanr", "(", "pred_scores_range_05_1", ",", "gold_scores_range_05_1", ")", "[", "0", "]", "\n", "\n", "return", "(", "pears_corr", ",", "spear_corr", ",", "pears_corr_range_05_1", ",", "spear_corr_range_05_1", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Predictions and gold data have different number of lines.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.Vocab.__init__": [[47, 50], ["embeddings.Vocab.__dict__.update"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "count", "=", "0", "\n", "self", ".", "__dict__", ".", "update", "(", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.Vocab.__lt__": [[51, 53], ["None"], "methods", ["None"], ["", "def", "__lt__", "(", "self", ",", "other", ")", ":", "# used for sorting in a priority queue", "\n", "        ", "return", "self", ".", "count", "<", "other", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.Vocab.__str__": [[54, 59], ["sorted", "key.startswith"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "vals", "=", "[", "'%s:%r'", "%", "(", "key", ",", "self", ".", "__dict__", "[", "key", "]", ")", "\n", "for", "key", "in", "sorted", "(", "self", ".", "__dict__", ")", "\n", "if", "not", "key", ".", "startswith", "(", "'_'", ")", "]", "\n", "return", "\"%s(%s)\"", "%", "(", "self", ".", "__class__", ".", "__name__", ",", "', '", ".", "join", "(", "vals", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.Embeddings.name": [[67, 70], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.Embeddings.__init__": [[71, 194], ["len", "embeddings.Embeddings.index2word.append", "embeddings.smart_open", "fin.readlines", "unicode", "int", "int", "numpy.zeros", "embeddings.smart_open", "len", "numpy.ascontiguousarray", "embeddings.Vocab", "open", "map", "min", "fin.readline", "xrange", "xrange", "len", "embeddings.Embeddings._gen_unseen_mikolov", "embeddings.Vocab", "embeddings.Vocab", "unicode().strip().split", "int", "unicode.split", "len", "unicode", "numpy.fromstring", "embeddings.Embeddings.__init__.add_word"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.smart_open", "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.smart_open", "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.Embeddings._gen_unseen_mikolov", "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.fromstring"], ["", "def", "__init__", "(", "self", ",", "filepath", "=", "None", ",", "fvocab", "=", "None", ",", "binary", "=", "False", ",", "\n", "encoding", "=", "'utf8'", ",", "unicode_errors", "=", "'strict'", ",", "\n", "limit", "=", "None", ",", "datatype", "=", "np", ".", "float32", ",", "unseen", "=", "'mikolov'", ")", ":", "\n", "\n", "        ", "def", "add_word", "(", "word", ",", "weights", ")", ":", "\n", "                ", "word_id", "=", "len", "(", "self", ".", "vocab", ")", "\n", "if", "word", "in", "self", ".", "vocab", ":", "\n", "# logger.warning(\"duplicate word '%s' in %s, ignoring all but first\", word, fname)", "\n", "                    ", "return", "\n", "", "if", "counts", "is", "None", ":", "\n", "# most common scenario: no vocab file given", "\n", "# just make up some bogus counts, in descending order", "\n", "                    ", "self", ".", "vocab", "[", "word", "]", "=", "Vocab", "(", "index", "=", "word_id", ",", "\n", "count", "=", "vocab_size", "-", "word_id", ")", "\n", "", "elif", "word", "in", "counts", ":", "\n", "# use count from the vocab file", "\n", "                    ", "self", ".", "vocab", "[", "word", "]", "=", "Vocab", "(", "index", "=", "word_id", ",", "\n", "count", "=", "counts", "[", "word", "]", ")", "\n", "", "else", ":", "\n", "# vocab file given, but word is missing -- set count to None", "\n", "# logger.warning(\"vocabulary file is incomplete: '%s' is missing\", word)", "\n", "                    ", "self", ".", "vocab", "[", "word", "]", "=", "Vocab", "(", "index", "=", "word_id", ",", "count", "=", "None", ")", "\n", "", "self", ".", "syn0", "[", "word_id", "]", "=", "weights", "\n", "self", ".", "index2word", ".", "append", "(", "word", ")", "\n", "\n", "", "if", "self", ".", "binary", ":", "\n", "            ", "binary", "=", "self", ".", "binary", "\n", "\n", "", "self", ".", "vocab", "=", "{", "}", "# mapping from a word (string) to a Vocab object", "\n", "self", ".", "index2word", "=", "[", "]", "# map from a word's matrix index (int) to word (string)", "\n", "self", ".", "unseen_vocab", "=", "{", "}", "\n", "\n", "counts", "=", "None", "\n", "if", "fvocab", "is", "not", "None", ":", "\n", "            ", "counts", "=", "{", "}", "\n", "with", "open", "(", "fvocab", ")", "as", "fin", ":", "\n", "                ", "for", "line", "in", "fin", ":", "\n", "                    ", "word", ",", "count", "=", "unicode", "(", "line", ")", ".", "strip", "(", ")", ".", "split", "(", ")", "\n", "counts", "[", "word", "]", "=", "int", "(", "count", ")", "\n", "\n", "", "", "", "if", "filepath", "is", "None", "and", "self", ".", "filepath", ":", "\n", "            ", "filepath", "=", "self", ".", "filepath", "\n", "\n", "# logger.info(\"loading projection weights from %s\", fname)", "\n", "", "with", "smart_open", "(", "filepath", ")", "as", "fin", ":", "\n", "            ", "lines", "=", "fin", ".", "readlines", "(", ")", "\n", "header", "=", "unicode", "(", "lines", "[", "0", "]", ",", "encoding", ")", "\n", "\n", "# throws for invalid file format", "\n", "try", ":", "\n", "                ", "vocab_size", ",", "vector_size", "=", "map", "(", "int", ",", "header", ".", "split", "(", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "vocab_size", "=", "len", "(", "lines", ")", "\n", "vector_size", "=", "len", "(", "header", ".", "split", "(", ")", ")", "-", "1", "\n", "binary", "=", "False", "\n", "\n", "", "if", "limit", ":", "\n", "                ", "vocab_size", "=", "min", "(", "vocab_size", ",", "limit", ")", "\n", "\n", "", "self", ".", "vector_size", "=", "int", "(", "vector_size", ")", "\n", "self", ".", "layer1_size", "=", "int", "(", "vector_size", ")", "\n", "self", ".", "syn0", "=", "np", ".", "zeros", "(", "(", "vocab_size", ",", "vector_size", ")", ",", "dtype", "=", "datatype", ")", "\n", "\n", "", "with", "smart_open", "(", "filepath", ")", "as", "fin", ":", "\n", "            ", "if", "binary", ":", "\n", "# skip first line *header*", "\n", "                ", "fin", ".", "readline", "(", ")", "\n", "binary_len", "=", "np", ".", "dtype", "(", "np", ".", "float32", ")", ".", "itemsize", "*", "vector_size", "\n", "for", "line_no", "in", "xrange", "(", "vocab_size", ")", ":", "\n", "# mixed text and binary: read text first, then binary", "\n", "                    ", "word", "=", "[", "]", "\n", "while", "True", ":", "\n", "                        ", "ch", "=", "fin", ".", "read", "(", "1", ")", "\n", "if", "ch", "==", "b' '", ":", "\n", "                            ", "break", "\n", "", "if", "ch", "==", "b''", ":", "\n", "                            ", "raise", "EOFError", "(", "\"\"\"\n                                           Unexpected end of input; is count\n                                           incorrect or file otherwise damaged?\n                                           \"\"\"", ")", "\n", "# ignore newlines in front of words (some binary files have)", "\n", "", "if", "ch", "!=", "b'\\n'", ":", "\n", "                            ", "word", ".", "append", "(", "ch", ")", "\n", "", "", "word", "=", "unicode", "(", "b''", ".", "join", "(", "word", ")", ",", "encoding", ",", "errors", "=", "unicode_errors", ")", "\n", "weights", "=", "np", ".", "fromstring", "(", "fin", ".", "read", "(", "binary_len", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "add_word", "(", "word", ",", "weights", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "line_no", "in", "xrange", "(", "vocab_size", ")", ":", "\n", "                    ", "line", "=", "fin", ".", "readline", "(", ")", "\n", "if", "line", "==", "b''", ":", "\n", "                        ", "raise", "EOFError", "(", "\"\"\"\n                                       Unexpected end of input; is count\n                                       incorrect or file otherwise damaged?\n                                       \"\"\"", ")", "\n", "", "parts", "=", "unicode", "(", "line", ".", "rstrip", "(", ")", ",", "encoding", ",", "\n", "errors", "=", "unicode_errors", ")", ".", "split", "(", "\" \"", ")", "\n", "if", "len", "(", "parts", ")", "!=", "vector_size", "+", "1", ":", "\n", "                        ", "raise", "ValueError", "(", "\"\"\"\n                                         invalid vector on line %s\n                                          (is this really the text format?)\n                                         \"\"\"", "%", "(", "line_no", ")", ")", "\n", "", "word", ",", "weights", "=", "parts", "[", "0", "]", ",", "list", "(", "map", "(", "np", ".", "float32", ",", "parts", "[", "1", ":", "]", ")", ")", "\n", "add_word", "(", "word", ",", "weights", ")", "\n", "", "", "", "if", "self", ".", "syn0", ".", "shape", "[", "0", "]", "!=", "len", "(", "self", ".", "vocab", ")", ":", "\n", "# logger.info(", "\n", "#    \"duplicate words detected, shrinking matrix size from %i to %i\",", "\n", "#    result.syn0.shape[0], len(result.vocab)", "\n", "# )", "\n", "            ", "self", ".", "syn0", "=", "np", ".", "ascontiguousarray", "(", "self", ".", "syn0", "[", ":", "len", "(", "self", ".", "vocab", ")", "]", ")", "\n", "", "assert", "(", "len", "(", "self", ".", "vocab", ")", ",", "self", ".", "vector_size", ")", "==", "self", ".", "syn0", ".", "shape", "\n", "# logger.info(\"loaded %s matrix from %s\" % (result.syn0.shape, fname))", "\n", "\n", "if", "self", ".", "unseen", ":", "\n", "            ", "unseen", "=", "self", ".", "unseen", "\n", "\n", "", "if", "unseen", ":", "\n", "            ", "if", "unseen", "==", "'mikolov'", ":", "\n", "                ", "self", ".", "unseen", "=", "self", ".", "_gen_unseen_mikolov", "(", ")", "\n", "", "elif", "unseen", "==", "'kim'", ":", "\n", "                ", "self", ".", "unseen", "=", "self", ".", "_gen_unseen_kim", "(", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "unseen", "=", "self", ".", "_gen_unseen_string", "(", "unseen", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.Embeddings.__getitem__": [[195, 209], ["isinstance", "isinstance", "warnings.warn", "embeddings.Embeddings.unseen", "numpy.vstack", "TypeError"], "methods", ["None"], ["", "", "", "def", "__getitem__", "(", "self", ",", "words", ")", ":", "\n", "        ", "if", "isinstance", "(", "words", ",", "basestring", ")", ":", "\n", "# allow calls like trained_model['office']", "\n", "# as a shorthand for trained_model[['office']]", "\n", "            ", "word", "=", "words", "\n", "if", "word", "in", "self", ":", "\n", "                ", "return", "self", ".", "syn0", "[", "self", ".", "vocab", "[", "word", "]", ".", "index", "]", "\n", "", "else", ":", "\n", "                ", "warnings", ".", "warn", "(", "\"Returning unseen word\"", ")", "\n", "return", "self", ".", "unseen", "(", ")", "\n", "", "", "elif", "isinstance", "(", "words", ",", "list", ")", ":", "\n", "            ", "return", "np", ".", "vstack", "(", "[", "self", "[", "word", "]", "for", "word", "in", "words", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "\"Use list or string\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.Embeddings.__contains__": [[210, 212], ["None"], "methods", ["None"], ["", "", "def", "__contains__", "(", "self", ",", "word", ")", ":", "\n", "        ", "return", "word", "in", "self", ".", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.Embeddings.__str__": [[213, 218], ["len"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"%s(vocab=%s, size=%s, alpha=%s)\"", "%", "(", "self", ".", "__class__", ".", "__name__", ",", "\n", "len", "(", "self", ".", "index2word", ")", ",", "\n", "self", ".", "vector_size", ",", "\n", "self", ".", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.Embeddings._gen_unseen_mikolov": [[219, 258], ["zip", "numpy.vstack", "numpy.mean", "numpy.mean", "numpy.random.rand", "numpy.linalg.norm", "embeddings.Embeddings._get_low_frequency_words", "embeddings.dist", "numpy.random.uniform"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.Embeddings._get_low_frequency_words", "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.dist"], ["", "def", "_gen_unseen_mikolov", "(", "self", ",", "rate", "=", "0.01", ")", ":", "\n", "        ", "\"\"\"\n        Based on an answer by Mikolov itself: you can initialize the vector\n        based on the space described by the infrequent words.\n        In his answer he mentions that you should average the\n        infrequent words and in that way build the unknown token.\n\n        Here we uniformly sample a sphere centered in the centroid of low\n        frequency words which radius is the mean distance between the centroid\n        and all the words in the low frequency set.\n        rate\n        Based on:\n        http://math.stackexchange.com/questions/87230/picking-random-points-in-the-volume-of-sphere-with-uniform-probability\n        \"\"\"", "\n", "low_freq_list", ",", "low_freq_count", "=", "zip", "(", "*", "self", ".", "_get_low_frequency_words", "(", "rate", ")", ")", "\n", "low_freq_matrix", "=", "np", ".", "vstack", "(", "[", "self", "[", "word", "]", "for", "word", "in", "low_freq_list", "]", ")", "\n", "vector_size", "=", "self", ".", "vector_size", "\n", "\n", "# aproximating the centroid of the low frequency terms", "\n", "center", "=", "np", ".", "mean", "(", "low_freq_matrix", ",", "axis", "=", "0", ")", "\n", "\n", "# getting the average distance of the centroid", "\n", "# to low frequency terms (radius of the n-shpere)", "\n", "radius", "=", "np", ".", "mean", "(", "[", "dist", "(", "center", ",", "self", "[", "word", "]", ")", "\n", "for", "word", "in", "low_freq_list", "]", ")", "\n", "\n", "# generate a random vect", "\n", "random_vec", "=", "np", ".", "random", ".", "rand", "(", "vector_size", ",", ")", "\n", "\n", "# normalizing the random vect", "\n", "random_vec", "/=", "np", ".", "linalg", ".", "norm", "(", "random_vec", ")", "\n", "\n", "# generate the output", "\n", "unseen_vector", "=", "(", "radius", "*", "(", "np", ".", "random", ".", "uniform", "(", "0", ",", "1", ")", "**", "(", "1", "/", "vector_size", ")", ")", "*", "random_vec", ")", "+", "center", "\n", "\n", "def", "unseen", "(", ")", ":", "\n", "            ", "return", "unseen_vector", "\n", "\n", "", "return", "unseen", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.Embeddings._gen_unseen_kim": [[259, 273], ["numpy.random.uniform"], "methods", ["None"], ["", "def", "_gen_unseen_kim", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        For words that occur in at least min_df documents, create a separate word vector.\n        0.25 is chosen so the unknown vectors have (approximately) same\n        variance as pre-trained ones (this value is for GoogleNews dataset)\n        From https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n        \"\"\"", "\n", "vector_size", "=", "self", ".", "vector_size", "\n", "unseen_vector", "=", "np", ".", "random", ".", "uniform", "(", "-", "0.25", ",", "0.25", ",", "(", "vector_size", ",", ")", ")", "\n", "\n", "def", "unseen", "(", ")", ":", "\n", "            ", "return", "unseen_vector", "\n", "\n", "", "return", "unseen", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.Embeddings._get_low_frequency_words": [[274, 284], ["sorted", "int", "embeddings.Embeddings.vocab.items", "len"], "methods", ["None"], ["", "def", "_get_low_frequency_words", "(", "self", ",", "rate", "=", "0.001", ")", ":", "\n", "        ", "\"\"\"\n        Vocab is a  dict where words are keys and values\n        are frequency counts\n        \"\"\"", "\n", "counts", "=", "[", "(", "key", ",", "value", ".", "count", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "vocab", ".", "items", "(", ")", "]", "\n", "sorted", "(", "counts", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "index", "=", "int", "(", "len", "(", "counts", ")", "*", "rate", ")", "\n", "return", "counts", "[", "-", "index", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.Embeddings._gen_unseen_string": [[285, 289], ["None"], "methods", ["None"], ["", "def", "_gen_unseen_string", "(", "self", ",", "unseen_word", ")", ":", "\n", "        ", "def", "unseen", "(", ")", ":", "\n", "            ", "return", "self", "[", "unseen_word", "]", "\n", "", "return", "unseen", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.make_closing": [[14, 29], ["type", "hasattr", "hasattr", "embeddings..close"], "function", ["None"], ["def", "make_closing", "(", "base", ",", "**", "attrs", ")", ":", "\n", "    ", "\"\"\"\n    Add support for `with Base(attrs) as fout:` to the base class if it's \n    missing. The base class' `close()` method will be called on context exit,\n    to always close the file properly.\n\n    This is needed for gzip.GzipFile, bz2.BZ2File etc in older Pythons (<=2.6),\n    which otherwise raise \"AttributeError: GzipFile instance has no attribute\n    '__exit__'\".\n    \"\"\"", "\n", "if", "not", "hasattr", "(", "base", ",", "'__enter__'", ")", ":", "\n", "        ", "attrs", "[", "'__enter__'", "]", "=", "lambda", "self", ":", "self", "\n", "", "if", "not", "hasattr", "(", "base", ",", "'__exit__'", ")", ":", "\n", "        ", "attrs", "[", "'__exit__'", "]", "=", "lambda", "self", ",", "type", ",", "value", ",", "traceback", ":", "self", ".", "close", "(", ")", "\n", "", "return", "type", "(", "'Closing'", "+", "base", ".", "__name__", ",", "(", "base", ",", "object", ")", ",", "attrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.smart_open": [[31, 40], ["os.path.splitext", "open", "embeddings.make_closing", "embeddings.make_closing"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.make_closing", "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.make_closing"], ["", "def", "smart_open", "(", "fname", ",", "mode", "=", "'rb'", ")", ":", "\n", "    ", "_", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "fname", ")", "\n", "if", "ext", "==", "'.bz2'", ":", "\n", "        ", "from", "bz2", "import", "BZ2File", "\n", "return", "make_closing", "(", "BZ2File", ")", "(", "fname", ",", "mode", ")", "\n", "", "if", "ext", "==", "'.gz'", ":", "\n", "        ", "from", "gzip", "import", "GzipFile", "\n", "return", "make_closing", "(", "GzipFile", ")", "(", "fname", ",", "mode", ")", "\n", "", "return", "open", "(", "fname", ",", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.enlp.embeddings.dist": [[291, 293], ["numpy.sqrt", "numpy.sum"], "function", ["None"], ["", "", "def", "dist", "(", "x", ",", "y", ")", ":", "\n", "    ", "return", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "(", "x", "-", "y", ")", "**", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.corpus.emoint.EmointCorpus.__init__": [[16, 23], ["emoint.EmointCorpus._check", "emoint.EmointCorpus._read", "utils.CorpusError"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.corpus.emoint.EmointCorpus._check", "home.repos.pwc.inspect_result.epochx_emoatt.corpus.emoint.EmointCorpus._read"], ["def", "__init__", "(", "self", ",", "filepath", "=", "None", ")", ":", "\n", "        ", "if", "filepath", ":", "\n", "            ", "self", ".", "filepath", "=", "filepath", "\n", "", "if", "self", ".", "_check", "(", ")", ":", "\n", "            ", "self", ".", "_read", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "CorpusError", "(", "\"Corpus was not properly built. Check for consistency\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.corpus.emoint.EmointCorpus.sentences": [[24, 27], ["emoint.EmointCorpus._sentences.values"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "sentences", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_sentences", ".", "values", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.corpus.emoint.EmointCorpus.documents": [[28, 31], ["emoint.EmointCorpus._documents.values"], "methods", ["None"], ["", "@", "property", "\n", "def", "documents", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_documents", ".", "values", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.corpus.emoint.EmointCorpus._check": [[32, 34], ["None"], "methods", ["None"], ["", "def", "_check", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.corpus.emoint.EmointCorpus._read": [[35, 55], ["collections.OrderedDict", "collections.OrderedDict", "rep.Document", "open", "f.readlines", "line.decode().split", "rep.Sentence", "int.strip.strip.strip", "float", "line.decode"], "methods", ["None"], ["", "def", "_read", "(", "self", ")", ":", "\n", "        ", "self", ".", "_counter", "=", "1", "\n", "self", ".", "_sentences", "=", "OrderedDict", "(", ")", "\n", "self", ".", "_documents", "=", "OrderedDict", "(", ")", "\n", "\n", "# add the single fake review", "\n", "document", "=", "Document", "(", "id", "=", "1", ")", "\n", "self", ".", "_documents", "[", "1", "]", "=", "document", "\n", "\n", "with", "open", "(", "self", ".", "filepath", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ".", "readlines", "(", ")", ":", "\n", "                ", "idx", ",", "text", ",", "sent", ",", "int", "=", "line", ".", "decode", "(", "\"utf-8\"", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "sentence", "=", "Sentence", "(", "string", "=", "text", ",", "id", "=", "idx", ",", "document", "=", "document", ")", "\n", "sentence", ".", "sentiment", "=", "sent", "\n", "int", "=", "int", ".", "strip", "(", ")", "\n", "if", "int", "==", "\"NONE\"", ":", "\n", "                  ", "sentence", ".", "intensity", "=", "None", "\n", "", "else", ":", "\n", "                  ", "sentence", ".", "intensity", "=", "float", "(", "int", ")", "\n", "", "self", ".", "_sentences", "[", "idx", "]", "=", "sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.document.Document.__init__": [[9, 12], ["utils._uid"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.utils._uid"], ["    ", "def", "__init__", "(", "self", ",", "id", "=", "None", ")", ":", "\n", "        ", "self", ".", "id", "=", "id", "if", "id", "else", "_uid", "(", ")", "\n", "self", ".", "sentences", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.document.Document.expand": [[13, 16], ["document.Document.append"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], ["", "def", "expand", "(", "self", ",", "sentences", ")", ":", "\n", "        ", "for", "sentence", "in", "sentences", ":", "\n", "            ", "self", ".", "append", "(", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.document.Document.append": [[17, 20], ["document.Document.sentences.append"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], ["", "", "def", "append", "(", "self", ",", "s", ")", ":", "\n", "        ", "s", ".", "_document", "=", "self", "\n", "self", ".", "sentences", ".", "append", "(", "s", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token.__init__": [[11, 37], ["isinstance", "string.decode.decode.decode"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "sentence", ",", "string", ",", "\n", "start", "=", "None", ",", "end", "=", "None", ",", "\n", "lemma", "=", "None", ",", "pos_tag", "=", "None", ",", "\n", "iob_tag", "=", "None", ",", "chunk", "=", "None", ",", "index", "=", "0", ")", ":", "\n", "        ", "\"\"\" A token in a sentence.\n            - sentence: the sentence object the Token belongs to \n            - lemma: base form of the Token; \"was\" => \"be\".\n            - pos_tag: the part-of-speech tag of the Token; \"NN\" => a noun.\n            - iob_tag: the chunk tag of the Token.\n            - chunk: the chunk (or phrase) this Token belongs to.\n            - index: the index (position) of the Token in the sentence.\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "string", ",", "unicode", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "string", "=", "string", ".", "decode", "(", "\"utf-8\"", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "", "", "self", ".", "sentence", "=", "sentence", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "string", "=", "string", "\n", "self", ".", "start", "=", "start", "\n", "self", ".", "end", "=", "end", "\n", "self", ".", "_lemma", "=", "lemma", "\n", "self", ".", "_type", "=", "pos_tag", "\n", "self", ".", "_iob", "=", "iob_tag", "\n", "self", ".", "chunk", "=", "chunk", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token.is_lemmatized": [[38, 41], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "is_lemmatized", "(", "self", ")", ":", "\n", "        ", "return", "True", "if", "self", ".", "lemma", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token.is_tagged": [[42, 45], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "is_tagged", "(", "self", ")", ":", "\n", "        ", "return", "True", "if", "self", ".", "pos", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token.is_chunked": [[46, 49], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "is_chunked", "(", "self", ")", ":", "\n", "        ", "return", "True", "if", "self", ".", "iob", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token.relations": [[50, 54], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "relations", "(", "self", ")", ":", "\n", "        ", "return", "[", "relation", "for", "relation", "in", "self", ".", "sentence", ".", "relations", "\n", "if", "self", "in", "relation", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token.head": [[55, 74], ["len", "len"], "methods", ["None"], ["", "@", "property", "\n", "def", "head", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the head token and the relation label\n        as a tuple.\n        \"\"\"", "\n", "heads", "=", "[", "(", "relation", ".", "head", ",", "relation", ".", "label", ")", "\n", "for", "relation", "in", "self", ".", "sentence", ".", "relations", "\n", "if", "relation", ".", "dependent", "==", "self", "]", "\n", "if", "len", "(", "heads", ")", ">", "0", ":", "\n", "            ", "if", "len", "(", "heads", ")", ">", "1", ":", "\n", "                ", "pass", "\n", "# print \"Two heads:\"", "\n", "# print self", "\n", "# print heads", "\n", "", "return", "heads", "[", "0", "]", "\n", "# print \"No head\"", "\n", "# print self", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token.dependents": [[75, 84], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "dependents", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the dependent tokens and their\n        relation labels as a list of tuples.\n        \"\"\"", "\n", "return", "[", "(", "relation", ".", "dependent", ",", "relation", ".", "label", ")", "\n", "for", "relation", "in", "self", ".", "sentence", ".", "relations", "\n", "if", "relation", ".", "head", "==", "self", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token.copy": [[85, 94], ["token.Token"], "methods", ["None"], ["", "def", "copy", "(", "self", ",", "chunk", "=", "None", ")", ":", "\n", "        ", "w", "=", "Token", "(", "self", ".", "sentence", ",", "\n", "self", ".", "string", ",", "\n", "lemma", "=", "self", ".", "_lemma", ",", "\n", "pos_tag", "=", "self", ".", "_type", ",", "\n", "iob_tag", "=", "self", ".", "_iob", ",", "\n", "chunk", "=", "self", ".", "chunk", ",", "\n", "index", "=", "self", ".", "index", ")", "\n", "return", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token._get_pos_tag": [[95, 97], ["None"], "methods", ["None"], ["", "def", "_get_pos_tag", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_type", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token._set_pos_tag": [[98, 100], ["None"], "methods", ["None"], ["", "def", "_set_pos_tag", "(", "self", ",", "pos_tag", ")", ":", "\n", "        ", "self", ".", "_type", "=", "pos_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token._get_iob_tag": [[103, 105], ["None"], "methods", ["None"], ["def", "_get_iob_tag", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_iob", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token._set_iob_tag": [[106, 108], ["None"], "methods", ["None"], ["", "def", "_set_iob_tag", "(", "self", ",", "iob_tag", ")", ":", "\n", "        ", "self", ".", "_iob", "=", "iob_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token._set_lemma": [[111, 113], ["None"], "methods", ["None"], ["def", "_set_lemma", "(", "self", ",", "lemma", ")", ":", "\n", "        ", "self", ".", "_lemma", "=", "lemma", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token._get_lemma": [[114, 116], ["None"], "methods", ["None"], ["", "def", "_get_lemma", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_lemma", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token.next": [[119, 128], ["len"], "methods", ["None"], ["def", "next", "(", "self", ",", "pos_tag", "=", "None", ")", ":", "\n", "        ", "\"\"\" Returns the next Token in the sentence with the given type.\n        \"\"\"", "\n", "i", "=", "self", ".", "index", "+", "1", "\n", "s", "=", "self", ".", "sentence", "\n", "while", "i", "<", "len", "(", "s", ")", ":", "\n", "            ", "if", "pos_tag", "in", "(", "s", "[", "i", "]", ".", "pos", ",", "None", ")", ":", "\n", "                ", "return", "s", "[", "i", "]", "\n", "", "i", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token.previous": [[129, 138], ["None"], "methods", ["None"], ["", "", "def", "previous", "(", "self", ",", "pos_tag", "=", "None", ")", ":", "\n", "        ", "\"\"\" Returns the next previous Token in the sentence with the given type.\n        \"\"\"", "\n", "i", "=", "self", ".", "index", "-", "1", "\n", "s", "=", "self", ".", "sentence", "\n", "while", "i", ">", "0", ":", "\n", "            ", "if", "pos_tag", "in", "(", "s", "[", "i", "]", ".", "pos", ",", "None", ")", ":", "\n", "                ", "return", "s", "[", "i", "]", "\n", "", "i", "-=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token.__unicode__": [[141, 143], ["None"], "methods", ["None"], ["", "", "def", "__unicode__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token.__repr__": [[144, 151], ["repr", "utils.encode_entities"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "is_tagged", ":", "\n", "            ", "return", "\"Token(%s)\"", "%", "repr", "(", "\"%s/%s\"", "%", "(", "\n", "encode_entities", "(", "self", ".", "string", ")", ",", "\n", "self", ".", "pos", "is", "not", "None", "and", "self", ".", "pos", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"Token(%s)\"", "%", "self", ".", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token.__eq__": [[152, 154], ["id", "id"], "methods", ["None"], ["", "", "def", "__eq__", "(", "self", ",", "token", ")", ":", "\n", "        ", "return", "id", "(", "self", ")", "==", "id", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.token.Token.__ne__": [[155, 157], ["id", "id"], "methods", ["None"], ["", "def", "__ne__", "(", "self", ",", "token", ")", ":", "\n", "        ", "return", "id", "(", "self", ")", "!=", "id", "(", "token", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.dependency.Relation.__init__": [[9, 13], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "head", ",", "label", ",", "dependent", ")", ":", "\n", "        ", "self", ".", "head", "=", "head", "\n", "self", ".", "label", "=", "label", "\n", "self", ".", "dependent", "=", "dependent", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.dependency.Relation.__repr__": [[14, 18], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "\"{0}({1},{2})\"", ".", "format", "(", "self", ".", "label", ",", "\n", "self", ".", "head", ".", "string", ",", "\n", "self", ".", "dependent", ".", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.dependency.Relation.__contains__": [[19, 23], ["None"], "methods", ["None"], ["", "def", "__contains__", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "[", "self", ".", "head", ",", "self", ".", "dependent", "]", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.dependency.Relation.is_head": [[24, 28], ["None"], "methods", ["None"], ["", "def", "is_head", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "is", "self", ".", "head", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.__init__": [[11, 20], ["chunk.Chunk.extend"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.extend"], ["    ", "def", "__init__", "(", "self", ",", "sentence", ",", "tokens", "=", "[", "]", ",", "chunk_tag", "=", "None", ")", ":", "\n", "        ", "\"\"\" A list of Tokens that make up a phrase in the sentence.\n            - chunk_tag: the phrase tag; \"NP\"\n              => a noun phrase (e.g., \"the black cat\").\n        \"\"\"", "\n", "self", ".", "sentence", "=", "sentence", "\n", "self", ".", "tokens", "=", "[", "]", "\n", "self", ".", "type", "=", "chunk_tag", "# NP, VP, ADJP ...", "\n", "self", ".", "extend", "(", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.extend": [[21, 24], ["chunk.Chunk.append"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], ["", "def", "extend", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "for", "token", "in", "tokens", ":", "\n", "            ", "self", ".", "append", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append": [[25, 28], ["chunk.Chunk.tokens.append"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], ["", "", "def", "append", "(", "self", ",", "token", ")", ":", "\n", "        ", "self", ".", "tokens", ".", "append", "(", "token", ")", "\n", "token", ".", "chunk", "=", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.__getitem__": [[29, 31], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "tokens", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.__len__": [[32, 34], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.__iter__": [[35, 37], ["chunk.Chunk.tokens.__iter__"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.__iter__"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tokens", ".", "__iter__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk._get_tag": [[38, 40], ["None"], "methods", ["None"], ["", "def", "_get_tag", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "type", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk._set_tag": [[41, 43], ["None"], "methods", ["None"], ["", "def", "_set_tag", "(", "self", ",", "v", ")", ":", "\n", "        ", "self", ".", "type", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.start": [[46, 49], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "start", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tokens", "[", "0", "]", ".", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.stop": [[50, 53], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "stop", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tokens", "[", "-", "1", "]", ".", "index", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.range": [[54, 57], ["chunk.Chunk.range"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.range"], ["", "@", "property", "\n", "def", "range", "(", "self", ")", ":", "\n", "        ", "return", "range", "(", "self", ".", "start", ",", "self", ".", "stop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.span": [[58, 61], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "span", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "start", ",", "self", ".", "stop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.lemmata": [[64, 67], ["None"], "methods", ["None"], ["@", "property", "\n", "def", "lemmata", "(", "self", ")", ":", "\n", "        ", "return", "[", "token", ".", "lemma", "for", "token", "in", "self", ".", "tokens", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.tagged": [[68, 71], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "tagged", "(", "self", ")", ":", "\n", "        ", "return", "[", "(", "token", ".", "string", ",", "token", ".", "pos", ")", "for", "token", "in", "self", ".", "token", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.nearest": [[72, 83], ["chunk.Chunk.sentence.chunks.index", "enumerate", "len", "chunk.type.startswith", "abs", "abs"], "methods", ["None"], ["", "def", "nearest", "(", "self", ",", "type", "=", "\"NP\"", ")", ":", "\n", "        ", "\"\"\" Returns the nearest chunk in the sentence with the given type.\n            This can be used (for example) to find adverbs and adjectives related to verbs,\n            as in: \"the cat is ravenous\" => is what? => \"ravenous\".\n        \"\"\"", "\n", "candidate", ",", "d", "=", "None", ",", "len", "(", "self", ".", "sentence", ".", "chunks", ")", "\n", "i", "=", "self", ".", "sentence", ".", "chunks", ".", "index", "(", "self", ")", "\n", "for", "j", ",", "chunk", "in", "enumerate", "(", "self", ".", "sentence", ".", "chunks", ")", ":", "\n", "            ", "if", "chunk", ".", "type", ".", "startswith", "(", "type", ")", "and", "abs", "(", "i", "-", "j", ")", "<", "d", ":", "\n", "                ", "candidate", ",", "d", "=", "chunk", ",", "abs", "(", "i", "-", "j", ")", "\n", "", "", "return", "candidate", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.next": [[84, 93], ["len"], "methods", ["None"], ["", "def", "next", "(", "self", ",", "type", "=", "None", ")", ":", "\n", "        ", "\"\"\" Returns the next chunk in the sentence with the given type.\n        \"\"\"", "\n", "i", "=", "self", ".", "stop", "\n", "s", "=", "self", ".", "sentence", "\n", "while", "i", "<", "len", "(", "s", ")", ":", "\n", "            ", "if", "s", "[", "i", "]", ".", "chunk", "is", "not", "None", "and", "type", "in", "(", "s", "[", "i", "]", ".", "chunk", ".", "type", ",", "None", ")", ":", "\n", "                ", "return", "s", "[", "i", "]", ".", "chunk", "\n", "", "i", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.previous": [[94, 103], ["None"], "methods", ["None"], ["", "", "def", "previous", "(", "self", ",", "type", "=", "None", ")", ":", "\n", "        ", "\"\"\" Returns the next previous chunk in the sentence with the given type.\n        \"\"\"", "\n", "i", "=", "self", ".", "start", "-", "1", "\n", "s", "=", "self", ".", "sentence", "\n", "while", "i", ">", "0", ":", "\n", "            ", "if", "s", "[", "i", "]", ".", "chunk", "is", "not", "None", "and", "type", "in", "(", "s", "[", "i", "]", ".", "chunk", ".", "type", ",", "None", ")", ":", "\n", "                ", "return", "s", "[", "i", "]", ".", "chunk", "\n", "", "i", "-=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.string": [[107, 110], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "string", "(", "self", ")", ":", "\n", "        ", "return", "u\" \"", ".", "join", "(", "token", ".", "string", "for", "token", "in", "self", ".", "tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.__unicode__": [[111, 113], ["None"], "methods", ["None"], ["", "def", "__unicode__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.__repr__": [[114, 118], ["repr"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"Chunk(%s)\"", "%", "repr", "(", "\"%s/%s\"", ")", "%", "(", "\n", "self", ".", "string", ",", "\n", "self", ".", "type", "is", "not", "None", "and", "self", ".", "type", "or", "OUTSIDE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.__eq__": [[119, 121], ["id", "id"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "chunk", ")", ":", "\n", "        ", "return", "id", "(", "self", ")", "==", "id", "(", "chunk", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.__ne__": [[122, 124], ["id", "id"], "methods", ["None"], ["", "def", "__ne__", "(", "self", ",", "chunk", ")", ":", "\n", "        ", "return", "id", "(", "self", ")", "!=", "id", "(", "chunk", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.utils._uid": [[7, 11], ["None"], "function", ["None"], ["\n", "# unpickle speedup trick", "\n", "import", "gc", "\n", "\n", "from", "enlp", ".", "settings", "import", "PICKLE_PATH", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__init__": [[106, 116], ["TypeError", "isinstance", "TypeError", "list.__init__", "type", "type"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.__init__.MultiTaskModel.__init__"], ["def", "__init__", "(", "self", ",", "node", ",", "children", "=", "None", ")", ":", "\n", "        ", "if", "children", "is", "None", ":", "\n", "            ", "raise", "TypeError", "(", "\"%s: Expected a node value and child list \"", "\n", "%", "type", "(", "self", ")", ".", "__name__", ")", "\n", "", "elif", "isinstance", "(", "children", ",", "string_types", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"%s() argument 2 should be a list, not a \"", "\n", "\"string\"", "%", "type", "(", "self", ")", ".", "__name__", ")", "\n", "", "else", ":", "\n", "            ", "list", ".", "__init__", "(", "self", ",", "children", ")", "\n", "self", ".", "_label", "=", "node", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__eq__": [[121, 124], ["list", "list"], "methods", ["None"], ["", "", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "(", "self", ".", "__class__", "is", "other", ".", "__class__", "and", "\n", "(", "self", ".", "_label", ",", "list", "(", "self", ")", ")", "==", "(", "other", ".", "_label", ",", "list", "(", "other", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__lt__": [[125, 135], ["isinstance", "list", "list"], "methods", ["None"], ["", "def", "__lt__", "(", "self", ",", "other", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "other", ",", "Tree", ")", ":", "\n", "# raise_unorderable_types(\"<\", self, other)", "\n", "# Sometimes children can be pure strings,", "\n", "# so we need to be able to compare with non-trees:", "\n", "            ", "return", "self", ".", "__class__", ".", "__name__", "<", "other", ".", "__class__", ".", "__name__", "\n", "", "elif", "self", ".", "__class__", "is", "other", ".", "__class__", ":", "\n", "            ", "return", "(", "self", ".", "_label", ",", "list", "(", "self", ")", ")", "<", "(", "other", ".", "_label", ",", "list", "(", "other", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "__class__", ".", "__name__", "<", "other", ".", "__class__", ".", "__name__", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__mul__": [[146, 148], ["TypeError"], "methods", ["None"], ["def", "__mul__", "(", "self", ",", "v", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'Tree does not support multiplication'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__rmul__": [[149, 151], ["TypeError"], "methods", ["None"], ["", "def", "__rmul__", "(", "self", ",", "v", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'Tree does not support multiplication'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__add__": [[152, 154], ["TypeError"], "methods", ["None"], ["", "def", "__add__", "(", "self", ",", "v", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'Tree does not support addition'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__radd__": [[155, 157], ["TypeError"], "methods", ["None"], ["", "def", "__radd__", "(", "self", ",", "v", ")", ":", "\n", "        ", "raise", "TypeError", "(", "'Tree does not support addition'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__getitem__": [[162, 175], ["isinstance", "list.__getitem__", "isinstance", "TypeError", "len", "len", "type", "type"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__getitem__"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "isinstance", "(", "index", ",", "(", "int", ",", "slice", ")", ")", ":", "\n", "            ", "return", "list", ".", "__getitem__", "(", "self", ",", "index", ")", "\n", "", "elif", "isinstance", "(", "index", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "if", "len", "(", "index", ")", "==", "0", ":", "\n", "                ", "return", "self", "\n", "", "elif", "len", "(", "index", ")", "==", "1", ":", "\n", "                ", "return", "self", "[", "index", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "                ", "return", "self", "[", "index", "[", "0", "]", "]", "[", "index", "[", "1", ":", "]", "]", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "\"%s indices must be integers, not %s\"", "%", "\n", "(", "type", "(", "self", ")", ".", "__name__", ",", "type", "(", "index", ")", ".", "__name__", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__setitem__": [[176, 190], ["isinstance", "list.__setitem__", "isinstance", "TypeError", "len", "IndexError", "len", "type", "type"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__setitem__"], ["", "", "def", "__setitem__", "(", "self", ",", "index", ",", "value", ")", ":", "\n", "        ", "if", "isinstance", "(", "index", ",", "(", "int", ",", "slice", ")", ")", ":", "\n", "            ", "return", "list", ".", "__setitem__", "(", "self", ",", "index", ",", "value", ")", "\n", "", "elif", "isinstance", "(", "index", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "if", "len", "(", "index", ")", "==", "0", ":", "\n", "                ", "raise", "IndexError", "(", "'The tree position () may not be '", "\n", "'assigned to.'", ")", "\n", "", "elif", "len", "(", "index", ")", "==", "1", ":", "\n", "                ", "self", "[", "index", "[", "0", "]", "]", "=", "value", "\n", "", "else", ":", "\n", "                ", "self", "[", "index", "[", "0", "]", "]", "[", "index", "[", "1", ":", "]", "]", "=", "value", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "\"%s indices must be integers, not %s\"", "%", "\n", "(", "type", "(", "self", ")", ".", "__name__", ",", "type", "(", "index", ")", ".", "__name__", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__delitem__": [[191, 204], ["isinstance", "list.__delitem__", "isinstance", "TypeError", "len", "IndexError", "len", "type", "type"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__delitem__"], ["", "", "def", "__delitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "isinstance", "(", "index", ",", "(", "int", ",", "slice", ")", ")", ":", "\n", "            ", "return", "list", ".", "__delitem__", "(", "self", ",", "index", ")", "\n", "", "elif", "isinstance", "(", "index", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "if", "len", "(", "index", ")", "==", "0", ":", "\n", "                ", "raise", "IndexError", "(", "'The tree position () may not be deleted.'", ")", "\n", "", "elif", "len", "(", "index", ")", "==", "1", ":", "\n", "                ", "del", "self", "[", "index", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "                ", "del", "self", "[", "index", "[", "0", "]", "]", "[", "index", "[", "1", ":", "]", "]", "\n", "", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "\"%s indices must be integers, not %s\"", "%", "\n", "(", "type", "(", "self", ")", ".", "__name__", ",", "type", "(", "index", ")", ".", "__name__", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree._get_node": [[209, 212], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "_get_node", "(", "self", ")", ":", "\n", "        ", "\"\"\"Outdated method to access the node value; use the label() method instead.\"\"\"", "\n", "raise", "NotImplementedError", "(", "\"Use label() to access a node label.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree._set_node": [[213, 216], ["NotImplementedError"], "methods", ["None"], ["", "def", "_set_node", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\"Outdated method to set the node value; use the set_label() method instead.\"\"\"", "\n", "raise", "NotImplementedError", "(", "\"Use set_label() method to set a node label.\"", ")", "\n", "", "node", "=", "property", "(", "_get_node", ",", "_set_node", ")", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.label": [[218, 230], ["None"], "methods", ["None"], ["def", "label", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return the node label of the tree.\n\n            >>> t = Tree.fromstring('(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))')\n            >>> t.label()\n            'S'\n\n        :return: the node label (typically a string)\n        :rtype: any\n        \"\"\"", "\n", "return", "self", ".", "_label", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.set_label": [[231, 244], ["None"], "methods", ["None"], ["", "def", "set_label", "(", "self", ",", "label", ")", ":", "\n", "        ", "\"\"\"\n        Set the node label of the tree.\n\n            >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n            >>> t.set_label(\"T\")\n            >>> print(t)\n            (T (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\n\n        :param label: the node label (typically a string)\n        :type label: any\n        \"\"\"", "\n", "self", ".", "_label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.leaves": [[245, 265], ["isinstance", "leaves.extend", "leaves.append", "child.leaves"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.extend", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.leaves"], ["", "def", "leaves", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return the leaves of the tree.\n\n            >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n            >>> t.leaves()\n            ['the', 'dog', 'chased', 'the', 'cat']\n\n        :return: a list containing this tree's leaves.\n            The order reflects the order of the\n            leaves in the tree's hierarchical structure.\n        :rtype: list\n        \"\"\"", "\n", "leaves", "=", "[", "]", "\n", "for", "child", "in", "self", ":", "\n", "            ", "if", "isinstance", "(", "child", ",", "Tree", ")", ":", "\n", "                ", "leaves", ".", "extend", "(", "child", ".", "leaves", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "leaves", ".", "append", "(", "child", ")", "\n", "", "", "return", "leaves", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.flatten": [[266, 279], ["tree.Tree", "tree.Tree.label", "tree.Tree.leaves"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.label", "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.leaves"], ["", "def", "flatten", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a flat version of the tree, with all non-root non-terminals removed.\n\n            >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n            >>> print(t.flatten())\n            (S the dog chased the cat)\n\n        :return: a tree consisting of this tree's root connected directly to\n            its leaves, omitting all intervening non-terminal nodes.\n        :rtype: Tree\n        \"\"\"", "\n", "return", "Tree", "(", "self", ".", "label", "(", ")", ",", "self", ".", "leaves", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.height": [[280, 306], ["isinstance", "max", "max", "child.height"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.height"], ["", "def", "height", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return the height of the tree.\n\n            >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n            >>> t.height()\n            5\n            >>> print(t[0,0])\n            (D the)\n            >>> t[0,0].height()\n            2\n\n        :return: The height of this tree.  The height of a tree\n            containing no children is 1; the height of a tree\n            containing only leaves is 2; and the height of any other\n            tree is one plus the maximum of its children's\n            heights.\n        :rtype: int\n        \"\"\"", "\n", "max_child_height", "=", "0", "\n", "for", "child", "in", "self", ":", "\n", "            ", "if", "isinstance", "(", "child", ",", "Tree", ")", ":", "\n", "                ", "max_child_height", "=", "max", "(", "max_child_height", ",", "child", ".", "height", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "max_child_height", "=", "max", "(", "max_child_height", ",", "1", ")", "\n", "", "", "return", "1", "+", "max_child_height", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.treepositions": [[307, 330], ["enumerate", "positions.append", "isinstance", "positions.append", "child.treepositions", "positions.extend", "positions.append"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.treepositions", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.extend", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], ["", "def", "treepositions", "(", "self", ",", "order", "=", "'preorder'", ")", ":", "\n", "        ", "\"\"\"\n            >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n            >>> t.treepositions() # doctest: +ELLIPSIS\n            [(), (0,), (0, 0), (0, 0, 0), (0, 1), (0, 1, 0), (1,), (1, 0), (1, 0, 0), ...]\n            >>> for pos in t.treepositions('leaves'):\n            ...     t[pos] = t[pos][::-1].upper()\n            >>> print(t)\n            (S (NP (D EHT) (N GOD)) (VP (V DESAHC) (NP (D EHT) (N TAC))))\n\n        :param order: One of: ``preorder``, ``postorder``, ``bothorder``,\n            ``leaves``.\n        \"\"\"", "\n", "positions", "=", "[", "]", "\n", "if", "order", "in", "(", "'preorder'", ",", "'bothorder'", ")", ":", "positions", ".", "append", "(", "(", ")", ")", "\n", "for", "i", ",", "child", "in", "enumerate", "(", "self", ")", ":", "\n", "            ", "if", "isinstance", "(", "child", ",", "Tree", ")", ":", "\n", "                ", "childpos", "=", "child", ".", "treepositions", "(", "order", ")", "\n", "positions", ".", "extend", "(", "(", "i", ",", ")", "+", "p", "for", "p", "in", "childpos", ")", "\n", "", "else", ":", "\n", "                ", "positions", ".", "append", "(", "(", "i", ",", ")", ")", "\n", "", "", "if", "order", "in", "(", "'postorder'", ",", "'bothorder'", ")", ":", "positions", ".", "append", "(", "(", ")", ")", "\n", "return", "positions", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.subtrees": [[331, 354], ["filter", "isinstance", "child.subtrees"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.subtrees"], ["", "def", "subtrees", "(", "self", ",", "filter", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Generate all the subtrees of this tree, optionally restricted\n        to trees matching the filter function.\n\n            >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n            >>> for s in t.subtrees(lambda t: t.height() == 2):\n            ...     print(s)\n            (D the)\n            (N dog)\n            (V chased)\n            (D the)\n            (N cat)\n\n        :type filter: function\n        :param filter: the function to filter all local trees\n        \"\"\"", "\n", "if", "not", "filter", "or", "filter", "(", "self", ")", ":", "\n", "            ", "yield", "self", "\n", "", "for", "child", "in", "self", ":", "\n", "            ", "if", "isinstance", "(", "child", ",", "Tree", ")", ":", "\n", "                ", "for", "subtree", "in", "child", ".", "subtrees", "(", "filter", ")", ":", "\n", "                    ", "yield", "subtree", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.pos": [[355, 374], ["isinstance", "pos.extend", "pos.append", "child.pos"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.extend", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.pos"], ["", "", "", "", "def", "pos", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return a sequence of pos-tagged words extracted from the tree.\n\n            >>> t = Tree.fromstring(\"(S (NP (D the) (N dog)) (VP (V chased) (NP (D the) (N cat))))\")\n            >>> t.pos()\n            [('the', 'D'), ('dog', 'N'), ('chased', 'V'), ('the', 'D'), ('cat', 'N')]\n\n        :return: a list of tuples containing leaves and pre-terminals (part-of-speech tags).\n            The order reflects the order of the leaves in the tree's hierarchical structure.\n        :rtype: list(tuple)\n        \"\"\"", "\n", "pos", "=", "[", "]", "\n", "for", "child", "in", "self", ":", "\n", "            ", "if", "isinstance", "(", "child", ",", "Tree", ")", ":", "\n", "                ", "pos", ".", "extend", "(", "child", ".", "pos", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "pos", ".", "append", "(", "(", "child", ",", "self", ".", "_label", ")", ")", "\n", "", "", "return", "pos", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.leaf_treeposition": [[375, 400], ["IndexError", "IndexError", "stack.pop", "isinstance", "range", "stack.append", "len"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.range", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], ["", "def", "leaf_treeposition", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        :return: The tree position of the ``index``-th leaf in this\n            tree.  I.e., if ``tp=self.leaf_treeposition(i)``, then\n            ``self[tp]==self.leaves()[i]``.\n\n        :raise IndexError: If this tree contains fewer than ``index+1``\n            leaves, or if ``index<0``.\n        \"\"\"", "\n", "if", "index", "<", "0", ":", "\n", "            ", "raise", "IndexError", "(", "'index must be non-negative'", ")", "\n", "\n", "", "stack", "=", "[", "(", "self", ",", "(", ")", ")", "]", "\n", "while", "stack", ":", "\n", "            ", "value", ",", "treepos", "=", "stack", ".", "pop", "(", ")", "\n", "if", "not", "isinstance", "(", "value", ",", "Tree", ")", ":", "\n", "                ", "if", "index", "==", "0", ":", "\n", "                    ", "return", "treepos", "\n", "", "else", ":", "\n", "                    ", "index", "-=", "1", "\n", "", "", "else", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "value", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "                    ", "stack", ".", "append", "(", "(", "value", "[", "i", "]", ",", "treepos", "+", "(", "i", ",", ")", ")", ")", "\n", "\n", "", "", "", "raise", "IndexError", "(", "'index must be less than or equal to len(self)'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.treeposition_spanning_leaves": [[401, 418], ["tree.Tree.leaf_treeposition", "tree.Tree.leaf_treeposition", "range", "ValueError", "len", "len"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.leaf_treeposition", "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.leaf_treeposition", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.range"], ["", "def", "treeposition_spanning_leaves", "(", "self", ",", "start", ",", "end", ")", ":", "\n", "        ", "\"\"\"\n        :return: The tree position of the lowest descendant of this\n            tree that dominates ``self.leaves()[start:end]``.\n        :raise ValueError: if ``end <= start``\n        \"\"\"", "\n", "if", "end", "<=", "start", ":", "\n", "            ", "raise", "ValueError", "(", "'end must be greater than start'", ")", "\n", "# Find the tree positions of the start & end leaves, and", "\n", "# take the longest common subsequence.", "\n", "", "start_treepos", "=", "self", ".", "leaf_treeposition", "(", "start", ")", "\n", "end_treepos", "=", "self", ".", "leaf_treeposition", "(", "end", "-", "1", ")", "\n", "# Find the first index where they mismatch:", "\n", "for", "i", "in", "range", "(", "len", "(", "start_treepos", ")", ")", ":", "\n", "            ", "if", "i", "==", "len", "(", "end_treepos", ")", "or", "start_treepos", "[", "i", "]", "!=", "end_treepos", "[", "i", "]", ":", "\n", "                ", "return", "start_treepos", "[", ":", "i", "]", "\n", "", "", "return", "start_treepos", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.convert": [[424, 439], ["isinstance", "cls", "cls.convert"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.convert"], ["", "@", "classmethod", "\n", "def", "convert", "(", "cls", ",", "tree", ")", ":", "\n", "        ", "\"\"\"\n        Convert a tree between different subtypes of Tree.  ``cls`` determines\n        which class will be used to encode the new tree.\n\n        :type tree: Tree\n        :param tree: The tree that should be converted.\n        :return: The new Tree.\n        \"\"\"", "\n", "if", "isinstance", "(", "tree", ",", "Tree", ")", ":", "\n", "            ", "children", "=", "[", "cls", ".", "convert", "(", "child", ")", "for", "child", "in", "tree", "]", "\n", "return", "cls", "(", "tree", ".", "_label", ",", "children", ")", "\n", "", "else", ":", "\n", "            ", "return", "tree", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.copy": [[440, 445], ["type().convert", "type", "type"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.convert"], ["", "", "def", "copy", "(", "self", ",", "deep", "=", "False", ")", ":", "\n", "        ", "if", "not", "deep", ":", "\n", "            ", "return", "type", "(", "self", ")", "(", "self", ".", "_label", ",", "self", ")", "\n", "", "else", ":", "\n", "            ", "return", "type", "(", "self", ")", ".", "convert", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.fromstring": [[450, 561], ["re.search", "re.compile", "re.compile.finditer", "TypeError", "TypeError", "re.escape", "re.escape", "match.group", "len", "cls._parse_error", "isinstance", "len", "token[].lstrip", "stack.append", "len", "cls._parse_error", "len", "cls._parse_error", "read_node", "stack.pop", "[].append", "[].append", "len", "len", "len", "len", "cls", "len", "cls._parse_error", "read_leaf", "len", "cls._parse_error", "cls._parse_error"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree._parse_error", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree._parse_error", "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree._parse_error", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree._parse_error", "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree._parse_error", "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree._parse_error"], ["", "", "@", "classmethod", "\n", "def", "fromstring", "(", "cls", ",", "s", ",", "brackets", "=", "'()'", ",", "read_node", "=", "None", ",", "read_leaf", "=", "None", ",", "\n", "node_pattern", "=", "None", ",", "leaf_pattern", "=", "None", ",", "\n", "remove_empty_top_bracketing", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Read a bracketed tree string and return the resulting tree.\n        Trees are represented as nested brackettings, such as::\n\n          (S (NP (NNP John)) (VP (V runs)))\n\n        :type s: str\n        :param s: The string to read\n\n        :type brackets: str (length=2)\n        :param brackets: The bracket characters used to mark the\n            beginning and end of trees and subtrees.\n\n        :type read_node: function\n        :type read_leaf: function\n        :param read_node, read_leaf: If specified, these functions\n            are applied to the substrings of ``s`` corresponding to\n            nodes and leaves (respectively) to obtain the values for\n            those nodes and leaves.  They should have the following\n            signature:\n\n               read_node(str) -> value\n\n            For example, these functions could be used to process nodes\n            and leaves whose values should be some type other than\n            string (such as ``FeatStruct``).\n            Note that by default, node strings and leaf strings are\n            delimited by whitespace and brackets; to override this\n            default, use the ``node_pattern`` and ``leaf_pattern``\n            arguments.\n\n        :type node_pattern: str\n        :type leaf_pattern: str\n        :param node_pattern, leaf_pattern: Regular expression patterns\n            used to find node and leaf substrings in ``s``.  By\n            default, both nodes patterns are defined to match any\n            sequence of non-whitespace non-bracket characters.\n\n        :type remove_empty_top_bracketing: bool\n        :param remove_empty_top_bracketing: If the resulting tree has\n            an empty node label, and is length one, then return its\n            single child instead.  This is useful for treebank trees,\n            which sometimes contain an extra level of bracketing.\n\n        :return: A tree corresponding to the string representation ``s``.\n            If this class method is called using a subclass of Tree,\n            then it will return a tree of that type.\n        :rtype: Tree\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "brackets", ",", "string_types", ")", "or", "len", "(", "brackets", ")", "!=", "2", ":", "\n", "            ", "raise", "TypeError", "(", "'brackets must be a length-2 string'", ")", "\n", "", "if", "re", ".", "search", "(", "'\\s'", ",", "brackets", ")", ":", "\n", "            ", "raise", "TypeError", "(", "'whitespace brackets not allowed'", ")", "\n", "# Construct a regexp that will tokenize the string.", "\n", "", "open_b", ",", "close_b", "=", "brackets", "\n", "open_pattern", ",", "close_pattern", "=", "(", "re", ".", "escape", "(", "open_b", ")", ",", "re", ".", "escape", "(", "close_b", ")", ")", "\n", "if", "node_pattern", "is", "None", ":", "\n", "            ", "node_pattern", "=", "'[^\\s%s%s]+'", "%", "(", "open_pattern", ",", "close_pattern", ")", "\n", "", "if", "leaf_pattern", "is", "None", ":", "\n", "            ", "leaf_pattern", "=", "'[^\\s%s%s]+'", "%", "(", "open_pattern", ",", "close_pattern", ")", "\n", "", "token_re", "=", "re", ".", "compile", "(", "'%s\\s*(%s)?|%s|(%s)'", "%", "(", "\n", "open_pattern", ",", "node_pattern", ",", "close_pattern", ",", "leaf_pattern", ")", ")", "\n", "# Walk through each token, updating a stack of trees.", "\n", "stack", "=", "[", "(", "None", ",", "[", "]", ")", "]", "# list of (node, children) tuples", "\n", "for", "match", "in", "token_re", ".", "finditer", "(", "s", ")", ":", "\n", "            ", "token", "=", "match", ".", "group", "(", ")", "\n", "# Beginning of a tree/subtree", "\n", "if", "token", "[", "0", "]", "==", "open_b", ":", "\n", "                ", "if", "len", "(", "stack", ")", "==", "1", "and", "len", "(", "stack", "[", "0", "]", "[", "1", "]", ")", ">", "0", ":", "\n", "                    ", "cls", ".", "_parse_error", "(", "s", ",", "match", ",", "'end-of-string'", ")", "\n", "", "label", "=", "token", "[", "1", ":", "]", ".", "lstrip", "(", ")", "\n", "if", "read_node", "is", "not", "None", ":", "\n", "                    ", "label", "=", "read_node", "(", "label", ")", "\n", "", "stack", ".", "append", "(", "(", "label", ",", "[", "]", ")", ")", "\n", "# End of a tree/subtree", "\n", "", "elif", "token", "==", "close_b", ":", "\n", "                ", "if", "len", "(", "stack", ")", "==", "1", ":", "\n", "                    ", "if", "len", "(", "stack", "[", "0", "]", "[", "1", "]", ")", "==", "0", ":", "\n", "                        ", "cls", ".", "_parse_error", "(", "s", ",", "match", ",", "open_b", ")", "\n", "", "else", ":", "\n", "                        ", "cls", ".", "_parse_error", "(", "s", ",", "match", ",", "'end-of-string'", ")", "\n", "", "", "label", ",", "children", "=", "stack", ".", "pop", "(", ")", "\n", "stack", "[", "-", "1", "]", "[", "1", "]", ".", "append", "(", "cls", "(", "label", ",", "children", ")", ")", "\n", "# Leaf node", "\n", "", "else", ":", "\n", "                ", "if", "len", "(", "stack", ")", "==", "1", ":", "\n", "                    ", "cls", ".", "_parse_error", "(", "s", ",", "match", ",", "open_b", ")", "\n", "", "if", "read_leaf", "is", "not", "None", ":", "\n", "                    ", "token", "=", "read_leaf", "(", "token", ")", "\n", "", "stack", "[", "-", "1", "]", "[", "1", "]", ".", "append", "(", "token", ")", "\n", "\n", "# check that we got exactly one complete tree.", "\n", "", "", "if", "len", "(", "stack", ")", ">", "1", ":", "\n", "            ", "cls", ".", "_parse_error", "(", "s", ",", "'end-of-string'", ",", "close_b", ")", "\n", "", "elif", "len", "(", "stack", "[", "0", "]", "[", "1", "]", ")", "==", "0", ":", "\n", "            ", "cls", ".", "_parse_error", "(", "s", ",", "'end-of-string'", ",", "open_b", ")", "\n", "", "else", ":", "\n", "            ", "assert", "stack", "[", "0", "]", "[", "0", "]", "is", "None", "\n", "assert", "len", "(", "stack", "[", "0", "]", "[", "1", "]", ")", "==", "1", "\n", "", "tree", "=", "stack", "[", "0", "]", "[", "1", "]", "[", "0", "]", "\n", "\n", "# If the tree has an extra level with node='', then get rid of", "\n", "# it.  E.g.: \"((S (NP ...) (VP ...)))\"", "\n", "if", "remove_empty_top_bracketing", "and", "tree", ".", "_label", "==", "''", "and", "len", "(", "tree", ")", "==", "1", ":", "\n", "            ", "tree", "=", "tree", "[", "0", "]", "\n", "# return the tree.", "\n", "", "return", "tree", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree._parse_error": [[562, 587], ["s.replace().replace.replace().replace.replace().replace", "ValueError", "len", "len", "match.start", "match.group", "s.replace().replace.replace().replace.replace"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.start"], ["", "@", "classmethod", "\n", "def", "_parse_error", "(", "cls", ",", "s", ",", "match", ",", "expecting", ")", ":", "\n", "        ", "\"\"\"\n        Display a friendly error message when parsing a tree string fails.\n        :param s: The string we're parsing.\n        :param match: regexp match of the problem token.\n        :param expecting: what we expected to see instead.\n        \"\"\"", "\n", "# Construct a basic error message", "\n", "if", "match", "==", "'end-of-string'", ":", "\n", "            ", "pos", ",", "token", "=", "len", "(", "s", ")", ",", "'end-of-string'", "\n", "", "else", ":", "\n", "            ", "pos", ",", "token", "=", "match", ".", "start", "(", ")", ",", "match", ".", "group", "(", ")", "\n", "", "msg", "=", "'%s.read(): expected %r but got %r\\n%sat index %d.'", "%", "(", "\n", "cls", ".", "__name__", ",", "expecting", ",", "token", ",", "' '", "*", "12", ",", "pos", ")", "\n", "# Add a display showing the error token itsels:", "\n", "s", "=", "s", ".", "replace", "(", "'\\n'", ",", "' '", ")", ".", "replace", "(", "'\\t'", ",", "' '", ")", "\n", "offset", "=", "pos", "\n", "if", "len", "(", "s", ")", ">", "pos", "+", "10", ":", "\n", "            ", "s", "=", "s", "[", ":", "pos", "+", "10", "]", "+", "'...'", "\n", "", "if", "pos", ">", "10", ":", "\n", "            ", "s", "=", "'...'", "+", "s", "[", "pos", "-", "10", ":", "]", "\n", "offset", "=", "13", "\n", "", "msg", "+=", "'\\n%s\"%s\"\\n%s^'", "%", "(", "' '", "*", "16", ",", "s", ",", "' '", "*", "(", "17", "+", "offset", ")", ")", "\n", "raise", "ValueError", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__repr__": [[592, 595], ["tree.unicode_repr", "tree.unicode_repr", "type"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.unicode_repr", "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.unicode_repr"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "childstr", "=", "\", \"", ".", "join", "(", "unicode_repr", "(", "c", ")", "for", "c", "in", "self", ")", "\n", "return", "'%s(%s, [%s])'", "%", "(", "type", "(", "self", ")", ".", "__name__", ",", "unicode_repr", "(", "self", ".", "_label", ")", ",", "childstr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree._repr_png_": [[596, 603], ["None"], "methods", ["None"], ["", "def", "_repr_png_", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Draws and outputs in PNG for ipython.\n        PNG is used instead of PDF, since it can be displayed in the qt console and\n        has wider browser support.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__str__": [[604, 606], ["tree.Tree.__repr__"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.Tree.__repr__"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__repr__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.rep.tree.unicode_repr": [[31, 41], ["repr"], "function", ["None"], ["def", "unicode_repr", "(", "obj", ")", ":", "\n", "    ", "\"\"\"\n    For classes that was fixed with @python_2_unicode_compatible\n    ``unicode_repr`` returns ``obj.unicode_repr()``; for unicode strings\n    the result is returned without \"u\" letter (to make output the\n    same under Python 2.x and Python 3.x); for other variables\n    it is the same as ``repr``.\n    \"\"\"", "\n", "# return repr(obj)[1:] # strip \"u\" letter from output", "\n", "return", "repr", "(", "obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.LSTMCell.__init__": [[15, 17], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_units", ")", ":", "\n", "        ", "self", ".", "num_units", "=", "num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.LSTMCell.state_size": [[18, 21], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "num_units", ",", "self", ".", "num_units", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.LSTMCell.output_size": [[22, 25], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.LSTMCell.__call__": [[26, 52], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.concat", "tensorflow.concat", "tensorflow.split", "x.get_shape().as_list", "tensorflow.matmul", "tensorflow.tanh", "tensorflow.sigmoid", "cells.orthogonal_initializer", "cells.bn_lstm_identity_initializer", "tensorflow.sigmoid", "tensorflow.sigmoid", "tensorflow.tanh", "type", "x.get_shape"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.orthogonal_initializer", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.bn_lstm_identity_initializer"], ["", "def", "__call__", "(", "self", ",", "x", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "scope", "or", "type", "(", "self", ")", ".", "__name__", ")", ":", "\n", "            ", "c", ",", "h", "=", "state", "\n", "\n", "# Keep W_xh and W_hh separate here as well to reuse initialization methods", "\n", "x_size", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "W_xh", "=", "tf", ".", "get_variable", "(", "'W_xh'", ",", "\n", "[", "x_size", ",", "4", "*", "self", ".", "num_units", "]", ",", "\n", "initializer", "=", "orthogonal_initializer", "(", ")", ")", "\n", "W_hh", "=", "tf", ".", "get_variable", "(", "'W_hh'", ",", "\n", "[", "self", ".", "num_units", ",", "4", "*", "self", ".", "num_units", "]", ",", "\n", "initializer", "=", "bn_lstm_identity_initializer", "(", "0.95", ")", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "4", "*", "self", ".", "num_units", "]", ")", "\n", "\n", "# hidden = tf.matmul(x, W_xh) + tf.matmul(h, W_hh) + bias", "\n", "# improve speed by concat.", "\n", "concat", "=", "tf", ".", "concat", "(", "1", ",", "[", "x", ",", "h", "]", ")", "\n", "W_both", "=", "tf", ".", "concat", "(", "0", ",", "[", "W_xh", ",", "W_hh", "]", ")", "\n", "hidden", "=", "tf", ".", "matmul", "(", "concat", ",", "W_both", ")", "+", "bias", "\n", "\n", "i", ",", "j", ",", "f", ",", "o", "=", "tf", ".", "split", "(", "1", ",", "4", ",", "hidden", ")", "\n", "\n", "new_c", "=", "c", "*", "tf", ".", "sigmoid", "(", "f", ")", "+", "tf", ".", "sigmoid", "(", "i", ")", "*", "tf", ".", "tanh", "(", "j", ")", "\n", "new_h", "=", "tf", ".", "tanh", "(", "new_c", ")", "*", "tf", ".", "sigmoid", "(", "o", ")", "\n", "\n", "return", "new_h", ",", "(", "new_c", ",", "new_h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.BNLSTMCell.__init__": [[56, 59], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_units", ",", "training", ")", ":", "\n", "        ", "self", ".", "num_units", "=", "num_units", "\n", "self", ".", "training", "=", "training", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.BNLSTMCell.state_size": [[60, 63], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "num_units", ",", "self", ".", "num_units", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.BNLSTMCell.output_size": [[64, 67], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_units", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.BNLSTMCell.__call__": [[68, 101], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.matmul", "cells.batch_norm", "cells.batch_norm", "tensorflow.split", "cells.batch_norm", "x.get_shape().as_list", "tensorflow.tanh", "tensorflow.sigmoid", "cells.orthogonal_initializer", "cells.bn_lstm_identity_initializer", "tensorflow.sigmoid", "tensorflow.sigmoid", "tensorflow.tanh", "type", "x.get_shape"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.batch_norm", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.batch_norm", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.batch_norm", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.orthogonal_initializer", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.bn_lstm_identity_initializer"], ["", "def", "__call__", "(", "self", ",", "x", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "scope", "or", "type", "(", "self", ")", ".", "__name__", ")", ":", "\n", "            ", "c", ",", "h", "=", "state", "\n", "\n", "x_size", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "W_xh", "=", "tf", ".", "get_variable", "(", "'W_xh'", ",", "\n", "[", "x_size", ",", "4", "*", "self", ".", "num_units", "]", ",", "\n", "initializer", "=", "orthogonal_initializer", "(", ")", ")", "\n", "W_hh", "=", "tf", ".", "get_variable", "(", "'W_hh'", ",", "\n", "[", "self", ".", "num_units", ",", "4", "*", "self", ".", "num_units", "]", ",", "\n", "initializer", "=", "bn_lstm_identity_initializer", "(", "0.95", ")", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "4", "*", "self", ".", "num_units", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "xh", "=", "tf", ".", "matmul", "(", "x", ",", "W_xh", ")", "\n", "hh", "=", "tf", ".", "matmul", "(", "h", ",", "W_hh", ")", "\n", "\n", "bn_xh", "=", "batch_norm", "(", "xh", ",", "'xh'", ",", "self", ".", "training", ")", "\n", "bn_hh", "=", "batch_norm", "(", "hh", ",", "'hh'", ",", "self", ".", "training", ")", "\n", "\n", "#print(bn_xh)", "\n", "#print(bn_hh)", "\n", "#print(bias)", "\n", "\n", "hidden", "=", "bn_xh", "+", "bn_hh", "+", "bias", "\n", "\n", "i", ",", "j", ",", "f", ",", "o", "=", "tf", ".", "split", "(", "hidden", ",", "4", ",", "axis", "=", "1", ")", "\n", "\n", "new_c", "=", "c", "*", "tf", ".", "sigmoid", "(", "f", ")", "+", "tf", ".", "sigmoid", "(", "i", ")", "*", "tf", ".", "tanh", "(", "j", ")", "\n", "bn_new_c", "=", "batch_norm", "(", "new_c", ",", "'c'", ",", "self", ".", "training", ")", "\n", "\n", "new_h", "=", "tf", ".", "tanh", "(", "bn_new_c", ")", "*", "tf", ".", "sigmoid", "(", "o", ")", "\n", "\n", "return", "new_h", ",", "(", "new_c", ",", "new_h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.ZoneoutWrapper.__init__": [[174, 188], ["isinstance", "isinstance", "TypeError", "isinstance", "ValueError", "tensorflow.contrib.rnn.LSTMStateTuple", "tuple"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "cell", ",", "zoneout_prob", ",", "is_training", "=", "True", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "cell", ",", "RNNCell", ")", ":", "\n", "      ", "raise", "TypeError", "(", "\"The parameter cell is not an RNNCell.\"", ")", "\n", "", "if", "isinstance", "(", "cell", ",", "BasicLSTMCell", ")", ":", "\n", "      ", "self", ".", "_tuple", "=", "lambda", "x", ":", "LSTMStateTuple", "(", "*", "x", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "_tuple", "=", "lambda", "x", ":", "tuple", "(", "x", ")", "\n", "", "if", "(", "isinstance", "(", "zoneout_prob", ",", "float", ")", "and", "\n", "not", "(", "zoneout_prob", ">=", "0.0", "and", "zoneout_prob", "<=", "1.0", ")", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"Parameter zoneout_prob must be between 0 and 1: %d\"", "\n", "%", "zoneout_prob", ")", "\n", "", "self", ".", "_cell", "=", "cell", "\n", "self", ".", "_zoneout_prob", "=", "zoneout_prob", "\n", "self", ".", "is_training", "=", "is_training", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.ZoneoutWrapper.state_size": [[190, 193], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "state_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_cell", ".", "state_size", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.ZoneoutWrapper.output_size": [[195, 198], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_size", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_cell", ".", "output_size", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.ZoneoutWrapper.__call__": [[200, 223], ["cells.ZoneoutWrapper._cell", "isinstance", "isinstance", "isinstance", "TypeError", "isinstance", "ValueError", "len", "len", "cells.ZoneoutWrapper._tuple", "cells.ZoneoutWrapper._tuple", "tuple", "tuple", "tensorflow.contrib.layers.dropout", "zip", "zip", "tensorflow.contrib.layers.dropout"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "    ", "if", "isinstance", "(", "self", ".", "state_size", ",", "tuple", ")", "!=", "isinstance", "(", "self", ".", "_zoneout_prob", ",", "tuple", ")", ":", "\n", "      ", "raise", "TypeError", "(", "\"Subdivided states need subdivided zoneouts.\"", ")", "\n", "", "if", "isinstance", "(", "self", ".", "state_size", ",", "tuple", ")", "and", "len", "(", "tuple", "(", "self", ".", "state_size", ")", ")", "!=", "len", "(", "tuple", "(", "self", ".", "_zoneout_prob", ")", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"State and zoneout need equally many parts.\"", ")", "\n", "", "output", ",", "new_state", "=", "self", ".", "_cell", "(", "inputs", ",", "state", ",", "scope", ")", "\n", "if", "isinstance", "(", "self", ".", "state_size", ",", "tuple", ")", ":", "\n", "      ", "if", "self", ".", "is_training", ":", "\n", "        ", "new_state", "=", "self", ".", "_tuple", "(", "[", "(", "1", "-", "state_part_zoneout_prob", ")", "*", "dropout", "(", "\n", "new_state_part", "-", "state_part", ",", "(", "1", "-", "state_part_zoneout_prob", ")", ")", "+", "state_part", "\n", "for", "new_state_part", ",", "state_part", ",", "state_part_zoneout_prob", "in", "\n", "zip", "(", "new_state", ",", "state", ",", "self", ".", "_zoneout_prob", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "new_state", "=", "self", ".", "_tuple", "(", "[", "state_part_zoneout_prob", "*", "state_part", "+", "(", "1", "-", "state_part_zoneout_prob", ")", "*", "new_state_part", "\n", "for", "new_state_part", ",", "state_part", ",", "state_part_zoneout_prob", "in", "\n", "zip", "(", "new_state", ",", "state", ",", "self", ".", "_zoneout_prob", ")", "]", ")", "\n", "", "", "else", ":", "\n", "      ", "if", "self", ".", "is_training", ":", "\n", "        ", "new_state", "=", "(", "1", "-", "state_part_zoneout_prob", ")", "*", "dropout", "(", "\n", "new_state_part", "-", "state_part", ",", "(", "1", "-", "state_part_zoneout_prob", ")", ")", "+", "state_part", "\n", "", "else", ":", "\n", "        ", "new_state", "=", "state_part_zoneout_prob", "*", "state_part", "+", "(", "1", "-", "state_part_zoneout_prob", ")", "*", "new_state_part", "\n", "", "", "return", "output", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.orthogonal": [[102, 108], ["numpy.random.normal", "numpy.linalg.svd", "q.reshape", "numpy.prod"], "function", ["None"], ["", "", "", "def", "orthogonal", "(", "shape", ")", ":", "\n", "    ", "flat_shape", "=", "(", "shape", "[", "0", "]", ",", "np", ".", "prod", "(", "shape", "[", "1", ":", "]", ")", ")", "\n", "a", "=", "np", ".", "random", ".", "normal", "(", "0.0", ",", "1.0", ",", "flat_shape", ")", "\n", "u", ",", "_", ",", "v", "=", "np", ".", "linalg", ".", "svd", "(", "a", ",", "full_matrices", "=", "False", ")", "\n", "q", "=", "u", "if", "u", ".", "shape", "==", "flat_shape", "else", "v", "\n", "return", "q", ".", "reshape", "(", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.bn_lstm_identity_initializer": [[109, 122], ["numpy.zeros", "cells.orthogonal", "cells.orthogonal", "cells.orthogonal", "tensorflow.constant", "numpy.identity"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.orthogonal", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.orthogonal", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.orthogonal"], ["", "def", "bn_lstm_identity_initializer", "(", "scale", ")", ":", "\n", "    ", "def", "_initializer", "(", "shape", ",", "dtype", "=", "tf", ".", "float32", ",", "partition_info", "=", "None", ")", ":", "\n", "        ", "'''Ugly cause LSTM params calculated in one matrix multiply'''", "\n", "size", "=", "shape", "[", "0", "]", "\n", "# gate (j) is identity", "\n", "t", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "t", "[", ":", ",", "size", ":", "size", "*", "2", "]", "=", "np", ".", "identity", "(", "size", ")", "*", "scale", "\n", "t", "[", ":", ",", ":", "size", "]", "=", "orthogonal", "(", "[", "size", ",", "size", "]", ")", "\n", "t", "[", ":", ",", "size", "*", "2", ":", "size", "*", "3", "]", "=", "orthogonal", "(", "[", "size", ",", "size", "]", ")", "\n", "t", "[", ":", ",", "size", "*", "3", ":", "]", "=", "orthogonal", "(", "[", "size", ",", "size", "]", ")", "\n", "return", "tf", ".", "constant", "(", "t", ",", "dtype", ")", "\n", "\n", "", "return", "_initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.orthogonal_initializer": [[123, 127], ["tensorflow.constant", "cells.orthogonal"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.orthogonal"], ["", "def", "orthogonal_initializer", "(", ")", ":", "\n", "    ", "def", "_initializer", "(", "shape", ",", "dtype", "=", "tf", ".", "float32", ",", "partition_info", "=", "None", ")", ":", "\n", "        ", "return", "tf", ".", "constant", "(", "orthogonal", "(", "shape", ")", ",", "dtype", ")", "\n", "", "return", "_initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.cells.batch_norm": [[128, 157], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.moments", "tensorflow.assign", "tensorflow.assign", "tensorflow.cond", "x.get_shape().as_list", "tensorflow.nn.batch_normalization", "tensorflow.constant_initializer", "tensorflow.zeros_initializer", "tensorflow.ones_initializer", "tensorflow.control_dependencies", "tensorflow.nn.batch_normalization", "x.get_shape"], "function", ["None"], ["", "def", "batch_norm", "(", "x", ",", "name_scope", ",", "training", ",", "epsilon", "=", "1e-3", ",", "decay", "=", "0.999", ")", ":", "\n", "    ", "'''Assume 2d [batch, values] tensor'''", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "name_scope", ")", ":", "\n", "        ", "size", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "\n", "scale", "=", "tf", ".", "get_variable", "(", "'scale'", ",", "shape", "=", "[", "size", "]", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ",", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "offset", "=", "tf", ".", "get_variable", "(", "'offset'", ",", "shape", "=", "[", "size", "]", ")", "\n", "\n", "pop_mean", "=", "tf", ".", "get_variable", "(", "'pop_mean'", ",", "shape", "=", "[", "size", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "pop_var", "=", "tf", ".", "get_variable", "(", "'pop_var'", ",", "shape", "=", "[", "size", "]", ",", "\n", "initializer", "=", "tf", ".", "ones_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ")", "\n", "batch_mean", ",", "batch_var", "=", "tf", ".", "nn", ".", "moments", "(", "x", ",", "[", "0", "]", ")", "\n", "\n", "train_mean_op", "=", "tf", ".", "assign", "(", "pop_mean", ",", "pop_mean", "*", "decay", "+", "batch_mean", "*", "(", "1", "-", "decay", ")", ")", "\n", "train_var_op", "=", "tf", ".", "assign", "(", "pop_var", ",", "pop_var", "*", "decay", "+", "batch_var", "*", "(", "1", "-", "decay", ")", ")", "\n", "\n", "def", "batch_statistics", "(", ")", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "[", "train_mean_op", ",", "train_var_op", "]", ")", ":", "\n", "                ", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "x", ",", "batch_mean", ",", "batch_var", ",", "offset", ",", "scale", ",", "epsilon", ")", "\n", "\n", "", "", "def", "population_statistics", "(", ")", ":", "\n", "            ", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "x", ",", "pop_mean", ",", "pop_var", ",", "offset", ",", "scale", ",", "epsilon", ")", "\n", "\n", "", "return", "tf", ".", "cond", "(", "training", ",", "batch_statistics", ",", "population_statistics", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.models.dep_attention_RNN_linear": [[11, 77], ["encoders.encoder_RNN_embed", "xrange", "decoders.seq_regression_decoder_attention", "decoders.seq_classification_decoder_linear", "tnsr.set_shape", "len", "extended_encoder_outputs.append", "tensorflow.python.ops.array_ops.concat"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.encoders.encoder_RNN_embed", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.decoders.seq_regression_decoder_attention", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.decoders.seq_classification_decoder_linear", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], ["def", "dep_attention_RNN_linear", "(", "encoder_inputs", ",", "\n", "encoder_extra_inputs", ",", "\n", "cell", ",", "\n", "num_encoder_symbols", ",", "\n", "num_decoder_symbols", ",", "\n", "word_embedding_size", ",", "\n", "batch_size", ",", "\n", "task", ",", "\n", "decoder_inputs", "=", "None", ",", "\n", "binary_feat_dim", "=", "0", ",", "\n", "class_dim", "=", "1", ",", "\n", "sequence_length", "=", "None", ",", "\n", "loop_function", "=", "None", ",", "\n", "context_win_size", "=", "1", ",", "\n", "train_embeddings", "=", "True", ",", "\n", "backwards_cell", "=", "None", ",", "\n", "dtype", "=", "dtypes", ".", "float32", ")", ":", "\n", "  ", "\"\"\"\n  Encoder and decoder share weights.\n  \"\"\"", "\n", "enc_outputs", "=", "encoder_RNN_embed", "(", "cell", ",", "encoder_inputs", ",", "num_encoder_symbols", ",", "word_embedding_size", ",", "\n", "sequence_length", ",", "batch_size", ",", "context_win_size", "=", "context_win_size", ",", "\n", "train_embeddings", "=", "train_embeddings", ",", "dtype", "=", "dtype", ",", "\n", "backwards_cell", "=", "backwards_cell", ")", "\n", "# num_decoder_symbols=num_labeling_decoder_symbols,", "\n", "\n", "encoder_embedded_inputs", ",", "encoder_outputs", ",", "encoder_state", "=", "enc_outputs", "\n", "\n", "if", "binary_feat_dim", ":", "\n", "#print(encoder_inputs[0].get_shape())", "\n", "#print(encoder_outputs[0].get_shape())", "\n", "# set shape for extra inputs", "\n", "    ", "[", "tnsr", ".", "set_shape", "(", "(", "batch_size", ",", "binary_feat_dim", ")", ")", "for", "tnsr", "in", "encoder_extra_inputs", "]", "\n", "#print(encoder_extra_inputs[0].get_shape())", "\n", "#print(type(encoder_extra_inputs[0]))", "\n", "extended_encoder_outputs", "=", "[", "]", "\n", "for", "i", "in", "xrange", "(", "len", "(", "encoder_outputs", ")", ")", ":", "\n", "      ", "extended_encoder_outputs", ".", "append", "(", "array_ops", ".", "concat", "(", "[", "encoder_outputs", "[", "i", "]", ",", "\n", "encoder_extra_inputs", "[", "i", "]", "]", ",", "\n", "1", ")", ")", "\n", "", "", "else", ":", "\n", "    ", "extended_encoder_outputs", "=", "encoder_outputs", "\n", "\n", "", "if", "task", "[", "\"regression\"", "]", ":", "\n", "#seq_regression_decoder_linear", "\n", "\n", "    ", "reg_dec_outputs", "=", "seq_regression_decoder_attention", "(", "extended_encoder_outputs", ",", "\n", "encoder_state", ",", "batch_size", ",", "\n", "decoder_inputs", "=", "decoder_inputs", ",", "\n", "class_dim", "=", "class_dim", ",", "\n", "sequence_length", "=", "sequence_length", ")", "\n", "reg_decoder_outputs", ",", "reg_attention_weights", "=", "reg_dec_outputs", "\n", "", "else", ":", "\n", "    ", "reg_decoder_outputs", ",", "reg_attention_weights", "=", "None", ",", "None", "\n", "\n", "", "if", "task", "[", "'classification'", "]", ":", "\n", "    ", "class_dec_outputs", "=", "seq_classification_decoder_linear", "(", "num_decoder_symbols", ",", "\n", "extended_encoder_outputs", ",", "\n", "encoder_state", ",", "batch_size", ")", "\n", "\n", "class_decoder_outputs", ",", "class_attention_weights", "=", "class_dec_outputs", "\n", "", "else", ":", "\n", "    ", "class_decoder_outputs", ",", "class_attention_weights", "=", "None", ",", "None", "\n", "\n", "", "return", "reg_decoder_outputs", ",", "reg_attention_weights", ",", "class_decoder_outputs", ",", "class_attention_weights", "\n", "", ""]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.attentions.get_vinyals_attention_function": [[11, 61], ["tensorflow.variable_scope", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.array_ops.reshape", "xrange", "tensorflow.python.ops.array_ops.reshape", "[].is_fully_defined", "ValueError", "tensorflow.get_variable", "hidden_features.append", "v.append", "xrange", "array_ops.concat.get_shape", "array_ops.concat.get_shape", "tensorflow.python.ops.nn_ops.conv2d", "tensorflow.get_variable", "array_ops.concat.get_shape", "tensorflow.variable_scope", "utils._linear", "tensorflow.python.ops.array_ops.reshape", "tensorflow.python.ops.math_ops.reduce_sum", "tensorflow.python.ops.nn_ops.softmax", "attn_weights.append", "tensorflow.python.ops.math_ops.reduce_sum", "ds.append", "array_ops.concat.get_shape", "tensorflow.python.ops.array_ops.reshape", "tensorflow.python.ops.math_ops.tanh", "tensorflow.python.ops.array_ops.reshape"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._linear", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], ["def", "get_vinyals_attention_function", "(", "attention_inputs", ",", "output_size", ",", "num_heads", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n  This is the attention approach as defined by Vinyals and Kaiser on\n  the paer 'Grammar as a Foreign Language'\n\n  :param attention_inputs:\n  :param output_size:\n  :param num_heads:\n  :return:\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"vinyals_attention\"", ",", "reuse", "=", "None", ")", "as", "attention_scope", ":", "\n", "\n", "    ", "top_states", "=", "[", "array_ops", ".", "reshape", "(", "e", ",", "[", "-", "1", ",", "1", ",", "output_size", "]", ")", "\n", "for", "e", "in", "attention_inputs", "]", "\n", "attention_states", "=", "array_ops", ".", "concat", "(", "top_states", ",", "1", ")", "\n", "if", "not", "attention_states", ".", "get_shape", "(", ")", "[", "1", ":", "2", "]", ".", "is_fully_defined", "(", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\"Shape[1] and [2] of attention_states must be known: %s\"", "%", "attention_states", ".", "get_shape", "(", ")", ")", "\n", "\n", "", "attn_length", "=", "attention_states", ".", "get_shape", "(", ")", "[", "1", "]", ".", "value", "\n", "attn_size", "=", "attention_states", ".", "get_shape", "(", ")", "[", "2", "]", ".", "value", "\n", "\n", "# To calculate W1 * h_t we use a 1-by-1 convolution, need to reshape before.", "\n", "hidden", "=", "array_ops", ".", "reshape", "(", "attention_states", ",", "[", "-", "1", ",", "attn_length", ",", "1", ",", "attn_size", "]", ")", "\n", "hidden_features", "=", "[", "]", "\n", "v", "=", "[", "]", "\n", "attention_vec_size", "=", "attn_size", "# Size of query vectors for attention.", "\n", "for", "a", "in", "xrange", "(", "num_heads", ")", ":", "\n", "      ", "k", "=", "tf", ".", "get_variable", "(", "\"AttnW_%d\"", "%", "a", ",", "[", "1", ",", "1", ",", "attn_size", ",", "attention_vec_size", "]", ")", "\n", "hidden_features", ".", "append", "(", "nn_ops", ".", "conv2d", "(", "hidden", ",", "k", ",", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "\"SAME\"", ")", ")", "\n", "v", ".", "append", "(", "tf", ".", "get_variable", "(", "\"AttnV_%d\"", "%", "a", ",", "[", "attention_vec_size", "]", ")", ")", "\n", "\n", "", "def", "attention", "(", "query", ")", ":", "\n", "      ", "\"\"\"Put attention masks on hidden using hidden_features and query.\"\"\"", "\n", "attn_weights", "=", "[", "]", "\n", "ds", "=", "[", "]", "# Results of attention reads will be stored here.", "\n", "for", "i", "in", "xrange", "(", "num_heads", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "\"Attention_%d\"", "%", "i", ")", ":", "\n", "          ", "y", "=", "_linear", "(", "query", ",", "attention_vec_size", ",", "True", ")", "\n", "y", "=", "array_ops", ".", "reshape", "(", "y", ",", "[", "-", "1", ",", "1", ",", "1", ",", "attention_vec_size", "]", ")", "\n", "# Attention mask is a softmax of v^T * tanh(...).", "\n", "s", "=", "math_ops", ".", "reduce_sum", "(", "v", "[", "i", "]", "*", "math_ops", ".", "tanh", "(", "hidden_features", "[", "i", "]", "+", "y", ")", ",", "[", "2", ",", "3", "]", ")", "\n", "a", "=", "nn_ops", ".", "softmax", "(", "s", ")", "\n", "attn_weights", ".", "append", "(", "a", ")", "\n", "# Now calculate the attention-weighted vector d.", "\n", "d", "=", "math_ops", ".", "reduce_sum", "(", "\n", "array_ops", ".", "reshape", "(", "a", ",", "[", "-", "1", ",", "attn_length", ",", "1", ",", "1", "]", ")", "*", "hidden", ",", "[", "1", ",", "2", "]", ")", "\n", "ds", ".", "append", "(", "array_ops", ".", "reshape", "(", "d", ",", "[", "-", "1", ",", "attn_size", "]", ")", ")", "\n", "", "", "return", "attn_weights", ",", "ds", "\n", "\n", "", "return", "attention", "\n", "", "", ""]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.encoders.encoder_RNN_embed": [[15, 92], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.concat", "tensorflow.python.ops.embedding_ops.embedding_lookup", "tensorflow.zeros", "tf.zeros.set_shape", "tensorflow.variable_scope", "tensorflow.contrib.rnn.static_bidirectional_rnn", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.python.ops.embedding_ops.embedding_lookup", "tensorflow.zeros", "tf.zeros.set_shape", "tensorflow.variable_scope", "tensorflow.contrib.rnn.static_rnn", "tensorflow.reshape", "tensorflow.concat", "tensorflow.reshape", "tensorflow.concat"], "function", ["None"], ["def", "encoder_RNN_embed", "(", "cell", ",", "encoder_inputs", ",", "num_encoder_symbols", ",", "word_embedding_size", ",", "sequence_length", ",", "\n", "batch_size", ",", "context_win_size", "=", "1", ",", "scope", "=", "None", ",", "train_embeddings", "=", "False", ",", "\n", "num_decoder_symbols", "=", "None", ",", "dtype", "=", "tf", ".", "float32", ",", "backwards_cell", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n\n  Embedds input and applies the RNN cell\n\n  :return:\n  \"\"\"", "\n", "if", "backwards_cell", ":", "\n", "    ", "encoder_cell_fw", "=", "cell", "\n", "encoder_cell_bw", "=", "backwards_cell", "\n", "\n", "embedding", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "[", "num_encoder_symbols", ",", "word_embedding_size", "]", ",", "\n", "trainable", "=", "train_embeddings", ")", "\n", "\n", "encoder_embedded_inputs", "=", "[", "embedding_ops", ".", "embedding_lookup", "(", "embedding", ",", "encoder_input", ")", "\n", "for", "encoder_input", "in", "encoder_inputs", "]", "\n", "\n", "if", "context_win_size", ">", "1", ":", "\n", "      ", "context_encoder_embedded_inputs", "=", "[", "tf", ".", "reshape", "(", "tensor", ",", "(", "-", "1", ",", "context_win_size", "*", "word_embedding_size", ")", ")", "\n", "for", "tensor", "in", "encoder_embedded_inputs", "]", "\n", "", "else", ":", "\n", "      ", "context_encoder_embedded_inputs", "=", "encoder_embedded_inputs", "\n", "\n", "", "if", "num_decoder_symbols", ":", "\n", "      ", "zeros", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "2", "*", "cell", ".", "output_size", "+", "num_decoder_symbols", "]", ",", "dtype", "=", "dtype", ")", "\n", "zeros", ".", "set_shape", "(", "[", "None", ",", "2", "*", "cell", ".", "output_size", "+", "num_decoder_symbols", "]", ")", "\n", "_inputs", "=", "[", "tf", ".", "concat", "(", "1", ",", "[", "embedded_input", ",", "zeros", "]", ")", "\n", "for", "embedded_input", "in", "context_encoder_embedded_inputs", "]", "\n", "", "else", ":", "\n", "      ", "_inputs", "=", "context_encoder_embedded_inputs", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"encoder_rnn\"", ")", "as", "internal_rnn_scope", ":", "\n", "      ", "encoder_outputs", ",", "encoder_state_fw", ",", "encoder_state_bw", "=", "rnn", ".", "static_bidirectional_rnn", "(", "encoder_cell_fw", ",", "\n", "encoder_cell_bw", ",", "\n", "_inputs", ",", "\n", "sequence_length", "=", "sequence_length", ",", "\n", "dtype", "=", "dtype", ",", "\n", "scope", "=", "internal_rnn_scope", ")", "\n", "\n", "all_fw", "=", "tf", ".", "concat", "(", "encoder_state_fw", ",", "1", ")", "\n", "all_bw", "=", "tf", ".", "concat", "(", "encoder_state_bw", ",", "1", ")", "\n", "encoder_state", "=", "tf", ".", "concat", "(", "[", "all_fw", ",", "all_bw", "]", ",", "1", ")", "\n", "\n", "", "", "else", ":", "\n", "    ", "encoder_cell_fw", "=", "cell", "\n", "\n", "embedding", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "[", "num_encoder_symbols", ",", "word_embedding_size", "]", ",", "\n", "trainable", "=", "train_embeddings", ")", "\n", "\n", "encoder_embedded_inputs", "=", "[", "embedding_ops", ".", "embedding_lookup", "(", "embedding", ",", "encoder_input", ")", "\n", "for", "encoder_input", "in", "encoder_inputs", "]", "\n", "\n", "if", "context_win_size", ">", "1", ":", "\n", "      ", "context_encoder_embedded_inputs", "=", "[", "tf", ".", "reshape", "(", "tensor", ",", "(", "-", "1", ",", "context_win_size", "*", "word_embedding_size", ")", ")", "\n", "for", "tensor", "in", "encoder_embedded_inputs", "]", "\n", "", "else", ":", "\n", "      ", "context_encoder_embedded_inputs", "=", "encoder_embedded_inputs", "\n", "\n", "", "if", "num_decoder_symbols", ":", "\n", "      ", "zeros", "=", "tf", ".", "zeros", "(", "[", "batch_size", ",", "cell", ".", "output_size", "+", "num_decoder_symbols", "]", ",", "dtype", "=", "dtype", ")", "\n", "zeros", ".", "set_shape", "(", "[", "None", ",", "cell", ".", "output_size", "+", "num_decoder_symbols", "]", ")", "\n", "\n", "_inputs", "=", "[", "tf", ".", "concat", "(", "[", "embedded_input", ",", "zeros", "]", ",", "1", ")", "\n", "for", "embedded_input", "in", "context_encoder_embedded_inputs", "]", "\n", "", "else", ":", "\n", "      ", "_inputs", "=", "context_encoder_embedded_inputs", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", "or", "\"encoder_rnn\"", ")", "as", "internal_rnn_scope", ":", "\n", "      ", "encoder_outputs", ",", "encoder_state", "=", "rnn", ".", "static_rnn", "(", "encoder_cell_fw", ",", "_inputs", ",", "\n", "sequence_length", "=", "sequence_length", ",", "dtype", "=", "dtype", ",", "\n", "scope", "=", "internal_rnn_scope", ")", "\n", "\n", "", "encoder_state", "=", "tf", ".", "concat", "(", "encoder_state", ",", "1", ")", "\n", "\n", "", "return", "context_encoder_embedded_inputs", ",", "encoder_outputs", ",", "encoder_state", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.encoders.encoder_embed": [[94, 112], ["tensorflow.get_variable", "tensorflow.python.ops.embedding_ops.embedding_lookup", "tensorflow.reshape"], "function", ["None"], ["", "def", "encoder_embed", "(", "encoder_inputs", ",", "num_encoder_symbols", ",", "word_embedding_size", ",", "context_win_size", "=", "1", ",", "\n", "train_embeddings", "=", "False", ")", ":", "\n", "  ", "\"\"\"\n  Just embedds inputs and returns the embedded sequence\n  :return:\n  \"\"\"", "\n", "embedding", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "[", "num_encoder_symbols", ",", "word_embedding_size", "]", ",", "\n", "trainable", "=", "train_embeddings", ")", "\n", "encoder_embedded_inputs", "=", "[", "embedding_ops", ".", "embedding_lookup", "(", "embedding", ",", "encoder_input", ")", "\n", "for", "encoder_input", "in", "encoder_inputs", "]", "\n", "\n", "if", "context_win_size", ">", "1", ":", "\n", "    ", "context_encoder_embedded_inputs", "=", "[", "tf", ".", "reshape", "(", "tensor", ",", "(", "-", "1", ",", "context_win_size", "*", "word_embedding_size", ")", ")", "\n", "for", "tensor", "in", "encoder_embedded_inputs", "]", "\n", "", "else", ":", "\n", "    ", "context_encoder_embedded_inputs", "=", "encoder_embedded_inputs", "\n", "\n", "", "return", "context_encoder_embedded_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.decoders.seq_classification_decoder_linear": [[16, 40], ["tensorflow.variable_scope", "attentions.get_vinyals_attention_function", "attentions.get_vinyals_attention_function.", "utils._linear", "encoder_outputs[].get_shape"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.attentions.get_vinyals_attention_function", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._linear"], ["def", "seq_classification_decoder_linear", "(", "num_decoder_symbols", ",", "encoder_outputs", ",", "\n", "att_initial_state", ",", "batch_size", ",", "\n", "sequence_length", "=", "None", ",", "scope", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n\n  Simple linear decoder,\n\n\n  :param num_decoder_symbols:\n  :param decoder_inputs:\n  :param loop_function:\n  :param sequence_length:\n  :param scope:\n  :return:\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "\"seq_classification_decoder_linear\"", ",", "reuse", "=", "None", ")", "as", "scope", ":", "\n", "    ", "output_size", "=", "encoder_outputs", "[", "0", "]", ".", "get_shape", "(", ")", "[", "1", "]", ".", "value", "\n", "attention", "=", "get_vinyals_attention_function", "(", "encoder_outputs", ",", "output_size", ",", "1", ",", "scope", "=", "scope", ")", "\n", "attn_weights", ",", "attns", "=", "attention", "(", "att_initial_state", ")", "\n", "\n", "# with variable_scope.variable_scope(scope or \"Linear\"):", "\n", "output", "=", "_linear", "(", "attns", "[", "0", "]", ",", "num_decoder_symbols", ",", "True", ")", "\n", "\n", "return", "[", "output", "]", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.decoders.seq_regression_decoder_attention": [[42, 99], ["tensorflow.variable_scope", "attentions.get_vinyals_attention_function", "attentions.get_vinyals_attention_function.", "tensorflow.concat", "tf.concat.set_shape", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.sigmoid", "tensorflow.variable_scope", "tensorflow.sigmoid", "tensorflow.variable_scope", "utils._linear", "encoder_outputs[].get_shape", "tensorflow.one_hot", "utils._linear", "utils._linear"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.attentions.get_vinyals_attention_function", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._linear", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._linear", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._linear"], ["", "", "def", "seq_regression_decoder_attention", "(", "encoder_outputs", ",", "att_initial_state", ",", "batch_size", ",", "\n", "sequence_length", "=", "None", ",", "scope", "=", "None", ",", "\n", "class_dim", "=", "1", ",", "decoder_inputs", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n\n  Simple linear decoder,\n\n\n  :param num_decoder_symbols:\n  :param decoder_inputs:\n  :param loop_function:\n  :param sequence_length:\n  :param scope:\n  :return:\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "\"seq_regression_decoder_linear\"", ",", "reuse", "=", "None", ")", "as", "scope", ":", "\n", "    ", "output_size", "=", "encoder_outputs", "[", "0", "]", ".", "get_shape", "(", ")", "[", "1", "]", ".", "value", "\n", "attention", "=", "get_vinyals_attention_function", "(", "encoder_outputs", ",", "output_size", ",", "1", ",", "scope", "=", "scope", ")", "\n", "attn_weights", ",", "attns", "=", "attention", "(", "att_initial_state", ")", "\n", "regression_input", "=", "attns", "[", "0", "]", "\n", "#print(regression_input)", "\n", "#print(decoder_inputs)", "\n", "\n", "if", "decoder_inputs", "is", "not", "None", "and", "class_dim", ">", "1", ":", "\n", "\n", "      ", "one_hot_decoder_inputs", "=", "[", "tf", ".", "one_hot", "(", "decoder_input", ",", "class_dim", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "for", "decoder_input", "in", "decoder_inputs", "]", "\n", "\n", "concat_decoder_inputs", "=", "tf", ".", "concat", "(", "one_hot_decoder_inputs", ",", "1", ")", "\n", "concat_decoder_inputs", ".", "set_shape", "(", "[", "None", ",", "class_dim", "]", ")", "\n", "\n", "#print(concat_decoder_inputs)", "\n", "extended_regression_input", "=", "tf", ".", "concat", "(", "[", "regression_input", ",", "\n", "concat_decoder_inputs", "]", ",", "\n", "1", ")", "\n", "\n", "", "else", ":", "\n", "      ", "extended_regression_input", "=", "regression_input", "\n", "\n", "#print(extended_regression_input)", "\n", "#import ipdb; ipdb.set_trace()", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"Linear_1\"", ")", "as", "scope", ":", "\n", "      ", "output_1", "=", "tf", ".", "sigmoid", "(", "_linear", "(", "extended_regression_input", ",", "200", ",", "True", ",", "scope", "=", "scope", ")", ")", "\n", "\n", "#with tf.variable_scope(\"Linear_2\") as scope:", "\n", "#  output_1= tf.sigmoid(_linear(output_1, 100, True, scope=scope))", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"Linear_3\"", ")", "as", "scope", ":", "\n", "      ", "output_1", "=", "tf", ".", "sigmoid", "(", "_linear", "(", "output_1", ",", "50", ",", "True", ",", "scope", "=", "scope", ")", ")", "\n", "\n", "#with tf.variable_scope(\"Linear_4\") as scope:", "\n", "#  output_1= tf.sigmoid(_linear(output_1, 25, True, scope=scope))", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"Linear_5\"", ")", "as", "scope", ":", "\n", "      ", "output", "=", "_linear", "(", "output_1", ",", "1", ",", "True", ",", "scope", "=", "scope", ")", "\n", "\n", "", "return", "[", "output", "]", ",", "attn_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.decoders.seq_regression_decoder_linear": [[100, 153], ["tensorflow.variable_scope", "tensorflow.concat", "tf.concat.set_shape", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.sigmoid", "tensorflow.variable_scope", "tensorflow.sigmoid", "tensorflow.variable_scope", "tensorflow.sigmoid", "tensorflow.variable_scope", "tensorflow.sigmoid", "tensorflow.variable_scope", "tensorflow.sigmoid", "tensorflow.one_hot", "utils._linear", "utils._linear", "utils._linear", "utils._linear", "tensorflow.sigmoid", "utils._linear"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._linear", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._linear", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._linear", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._linear", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._linear"], ["", "", "def", "seq_regression_decoder_linear", "(", "encoder_outputs", ",", "att_initial_state", ",", "batch_size", ",", "\n", "sequence_length", "=", "None", ",", "scope", "=", "None", ",", "\n", "class_dim", "=", "1", ",", "decoder_inputs", "=", "None", ")", ":", "\n", "  ", "\"\"\"\n\n  Simple linear decoder,\n\n\n  :param num_decoder_symbols:\n  :param decoder_inputs:\n  :param loop_function:\n  :param sequence_length:\n  :param scope:\n  :return:\n  \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "\"seq_regression_decoder_simple\"", ",", "reuse", "=", "None", ")", "as", "scope", ":", "\n", "\n", "    ", "regression_input", "=", "att_initial_state", "\n", "\n", "if", "decoder_inputs", "is", "not", "None", "and", "class_dim", ">", "1", ":", "\n", "\n", "      ", "one_hot_decoder_inputs", "=", "[", "tf", ".", "one_hot", "(", "decoder_input", ",", "class_dim", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "for", "decoder_input", "in", "decoder_inputs", "]", "\n", "\n", "concat_decoder_inputs", "=", "tf", ".", "concat", "(", "one_hot_decoder_inputs", ",", "1", ")", "\n", "concat_decoder_inputs", ".", "set_shape", "(", "[", "None", ",", "class_dim", "]", ")", "\n", "\n", "#print(concat_decoder_inputs)", "\n", "extended_regression_input", "=", "tf", ".", "concat", "(", "[", "regression_input", ",", "\n", "concat_decoder_inputs", "]", ",", "\n", "1", ")", "\n", "\n", "", "else", ":", "\n", "      ", "extended_regression_input", "=", "regression_input", "\n", "\n", "#print(extended_regression_input)", "\n", "#import ipdb; ipdb.set_trace()", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"Linear_1\"", ")", "as", "scope", ":", "\n", "      ", "output_1", "=", "tf", ".", "sigmoid", "(", "_linear", "(", "extended_regression_input", ",", "200", ",", "True", ",", "scope", "=", "scope", ")", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"Linear_2\"", ")", "as", "scope", ":", "\n", "      ", "output_1", "=", "tf", ".", "sigmoid", "(", "_linear", "(", "output_1", ",", "100", ",", "True", ",", "scope", "=", "scope", ")", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"Linear_3\"", ")", "as", "scope", ":", "\n", "      ", "output_1", "=", "tf", ".", "sigmoid", "(", "_linear", "(", "output_1", ",", "50", ",", "True", ",", "scope", "=", "scope", ")", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"Linear_4\"", ")", "as", "scope", ":", "\n", "      ", "output_1", "=", "tf", ".", "sigmoid", "(", "_linear", "(", "output_1", ",", "25", ",", "True", ",", "scope", "=", "scope", ")", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"Linear_5\"", ")", "as", "scope", ":", "\n", "      ", "output", "=", "tf", ".", "sigmoid", "(", "tf", ".", "sigmoid", "(", "_linear", "(", "output_1", ",", "1", ",", "True", ",", "scope", "=", "scope", ")", ")", ")", "\n", "\n", "", "return", "[", "output", "]", ",", "None", "", "", "", ""]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.__init__.MultiTaskModel.__init__": [[23, 184], ["tensorflow.Variable", "tensorflow.placeholder", "xrange", "__init__.MultiTaskModel.values.append", "__init__.MultiTaskModel.labels.append", "models.dep_attention_RNN_linear", "tensorflow.trainable_variables", "tensorflow.train.Saver", "tensorflow.train.exponential_decay", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.DropoutWrapper", "__init__.MultiTaskModel.encoder_extra_inputs.append", "tensorflow.placeholder", "tensorflow.placeholder", "losses.get_classification_loss", "print", "tensorflow.contrib.layers.l2_regularizer", "tensorflow.contrib.layers.apply_regularization", "tensorflow.clip_by_global_norm", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.global_variables", "tensorflow.contrib.rnn.GRUCell", "cells.ZoneoutWrapper", "tensorflow.contrib.rnn.BasicLSTMCell", "tensorflow.contrib.rnn.MultiRNNCell", "tensorflow.contrib.rnn.DropoutWrapper", "__init__.MultiTaskModel.encoder_inputs.append", "__init__.MultiTaskModel.encoder_inputs.append", "tensorflow.placeholder", "losses.get_regression_squared_loss", "losses.get_regression_pearson_loss", "tensorflow.train.GradientDescentOptimizer", "tensorflow.gradients", "zip", "cells.BNLSTMCell", "tensorflow.contrib.rnn.GRUCell", "cells.ZoneoutWrapper", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.train.AdamOptimizer", "tensorflow.gradients", "tensorflow.cast", "cells.BNLSTMCell", "tensorflow.gradients", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.models.dep_attention_RNN_linear", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.losses.get_classification_loss", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.losses.get_regression_squared_loss", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.losses.get_regression_pearson_loss"], []], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.__init__.MultiTaskModel.joint_step": [[185, 263], ["xrange", "session.run", "session.run", "len", "ValueError", "len", "ValueError", "len", "ValueError", "output_feed.append", "output_feed.append", "output_feed.append", "output_feed.append", "output_feed.append", "output_feed.append", "output_feed.append", "output_feed.append", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], []], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.__init__.MultiTaskModel.regression_step": [[265, 327], ["xrange", "session.run", "len", "ValueError", "len", "ValueError", "len", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.__init__.MultiTaskModel.classification_step": [[329, 380], ["xrange", "session.run", "len", "ValueError", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.__init__.MultiTaskModel.get_batch": [[382, 486], ["list", "xrange", "xrange", "batch_values.append", "batch_labels.append", "numpy.array", "list.append", "encoder_inputs.append", "encoder_extra_inputs.append", "values.append", "labels.append", "ids.append", "batch_encoder_inputs.append", "numpy.array", "numpy.array", "random.choice", "len", "len", "list", "utils.contextwin", "context_encoder_inputs.append", "list", "numpy.array", "batch_context_encoder_inputs.append", "batch_encoder_extra_inputs.append", "list", "numpy.asarray", "numpy.asarray", "xrange", "xrange", "xrange", "xrange", "xrange"], "methods", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils.contextwin", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append", "home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.append"], []], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._state_size_with_prefix": [[24, 41], ["tensorflow.python.framework.tensor_shape.as_shape().as_list", "tensorflow.python.framework.tensor_shape.as_shape", "isinstance", "TypeError"], "function", ["None"], ["\n", "    ", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ")", "\n", "\n", "", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ")", "\n", "\n", "", "@", "property", "\n", "def", "pipeline", "(", "self", ")", ":", "\n", "        ", "pipeline", "=", "self", ".", "sentences", "[", "0", "]", ".", "pipeline", "\n", "assert", "all", "(", "sentence", ".", "pipeline", "==", "pipeline", "\n", "for", "sentence", "in", "self", ".", "sentences", ")", "\n", "return", "pipeline", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._linear": [[43, 91], ["ValueError", "tensorflow.python.util.nest.is_sequence", "a.get_shape().as_list", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.python.util.nest.is_sequence", "len", "ValueError", "ValueError", "len", "tensorflow.python.ops.math_ops.matmul", "tensorflow.python.ops.math_ops.matmul", "a.get_shape", "tensorflow.python.ops.array_ops.concat", "tensorflow.python.ops.init_ops.constant_initializer", "str", "str"], "function", ["None"], ["        ", "\"\"\"\n        Save a processed corpus.\n        \"\"\"", "\n", "if", "self", ".", "pipeline", ":", "\n", "            ", "try", ":", "\n", "                ", "filename", "=", "\".\"", ".", "join", "(", "self", ".", "pipeline", "+", "[", "self", ".", "name", "]", ")", "\n", "filename", "=", "\"{0}.pickle\"", ".", "format", "(", "filename", ")", "\n", "f", "=", "open", "(", "path", ".", "join", "(", "PICKLE_PATH", ",", "filename", ")", ",", "\"wb\"", ")", "\n", "pickle", ".", "dump", "(", "self", ",", "f", ")", "\n", "f", ".", "close", "(", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "if", "f", ":", "\n", "                    ", "f", ".", "close", "(", ")", "\n", "", "remove", "(", "path", ".", "join", "(", "PICKLE_PATH", ",", "filename", ")", ")", "\n", "print", "e", "\n", "\n", "", "", "", "@", "classmethod", "\n", "def", "list_frozen", "(", "cls", ")", ":", "\n", "        ", "return", "[", "filename", ".", "replace", "(", "\".\"", "+", "cls", ".", "__name__", "+", "\".pickle\"", ",", "\"\"", ")", ".", "split", "(", "\".\"", ")", "\n", "for", "filename", "in", "listdir", "(", "PICKLE_PATH", ")", "\n", "if", "cls", ".", "__name__", "in", "filename", "]", "\n", "\n", "", "@", "classmethod", "\n", "def", "unfreeze", "(", "cls", ",", "pipeline", ")", ":", "\n", "        ", "\"\"\"\n        TO DO\n        \"\"\"", "\n", "try", ":", "\n", "            ", "filename", "=", "\".\"", ".", "join", "(", "pipeline", "+", "[", "cls", ".", "__name__", "]", ")", "\n", "f", "=", "open", "(", "path", ".", "join", "(", "PICKLE_PATH", ",", "\"{0}.pickle\"", ".", "format", "(", "filename", ")", ")", ",", "\"rb\"", ")", "\n", "gc", ".", "disable", "(", ")", "\n", "corpus", "=", "pickle", ".", "load", "(", "f", ")", "\n", "gc", ".", "enable", "(", ")", "\n", "return", "corpus", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "e", "\n", "return", "None", "", "", "", "", ""]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils.contextwin": [[98, 115], ["list", "len", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.rep.chunk.Chunk.range"], []], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._extract_argmax_and_embed": [[117, 144], ["tensorflow.python.ops.math_ops.argmax", "tensorflow.python.ops.embedding_ops.embedding_lookup", "tensorflow.python.ops.nn_ops.xw_plus_b", "tensorflow.python.ops.array_ops.stop_gradient"], "function", ["None"], []], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._extract_argmax_and_one_hot": [[146, 170], ["tensorflow.python.ops.math_ops.argmax", "tensorflow.one_hot", "tensorflow.python.ops.nn_ops.xw_plus_b"], "function", ["None"], []], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._step": [[172, 192], ["tensorflow.python.ops.control_flow_ops.cond", "tensorflow.python.ops.control_flow_ops.cond", "control_flow_ops.cond.set_shape", "tensorflow.python.ops.math_ops.select", "control_flow_ops.cond.get_shape"], "function", ["None"], []], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils.zero_state": [[194, 210], ["utils._state_size_with_prefix", "tensorflow.zeros", "tf.zeros.set_shape", "tensorflow.stack", "utils._state_size_with_prefix"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._state_size_with_prefix", "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.utils._state_size_with_prefix"], []], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.losses.get_classification_loss": [[16, 31], ["tensorflow.python.ops.array_ops.reshape", "tensorflow.python.ops.nn_ops.sparse_softmax_cross_entropy_with_logits", "softmax_loss_function", "tensorflow.python.ops.array_ops.shape", "tensorflow.reduce_sum", "tensorflow.python.ops.math_ops.cast", "len", "len", "tensorflow.python.ops.math_ops.to_int64", "len", "len"], "function", ["None"], ["def", "get_classification_loss", "(", "logits", ",", "targets", ",", "softmax_loss_function", "=", "None", ")", ":", "\n", "  ", "bucket_outputs", "=", "logits", "\n", "if", "softmax_loss_function", "is", "None", ":", "\n", "    ", "assert", "len", "(", "bucket_outputs", ")", "==", "len", "(", "targets", ")", "==", "1", "\n", "# We need to make target an int64-tensor and set its shape.", "\n", "bucket_target", "=", "array_ops", ".", "reshape", "(", "math_ops", ".", "to_int64", "(", "targets", "[", "0", "]", ")", ",", "[", "-", "1", "]", ")", "\n", "crossent", "=", "nn_ops", ".", "sparse_softmax_cross_entropy_with_logits", "(", "bucket_outputs", "[", "0", "]", ",", "bucket_target", ")", "\n", "", "else", ":", "\n", "    ", "assert", "len", "(", "bucket_outputs", ")", "==", "len", "(", "targets", ")", "==", "1", "\n", "crossent", "=", "softmax_loss_function", "(", "bucket_outputs", "[", "0", "]", ",", "targets", "[", "0", "]", ")", "\n", "\n", "", "batch_size", "=", "array_ops", ".", "shape", "(", "targets", "[", "0", "]", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "crossent", ")", "/", "math_ops", ".", "cast", "(", "batch_size", ",", "dtypes", ".", "float32", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.losses.get_regression_squared_loss": [[34, 40], ["tensorflow.nn.l2_loss", "len", "len", "tensorflow.python.ops.array_ops.shape", "tensorflow.reduce_sum", "tensorflow.python.ops.math_ops.cast", "tensorflow.python.ops.math_ops.to_float", "tensorflow.python.ops.math_ops.to_float"], "function", ["None"], ["", "def", "get_regression_squared_loss", "(", "predicts", ",", "targets", ")", ":", "\n", "    ", "assert", "len", "(", "predicts", ")", "==", "len", "(", "targets", ")", "==", "1", "\n", "sqared_error", "=", "tf", ".", "nn", ".", "l2_loss", "(", "math_ops", ".", "to_float", "(", "predicts", ")", "-", "math_ops", ".", "to_float", "(", "targets", ")", ")", "\n", "batch_size", "=", "array_ops", ".", "shape", "(", "targets", "[", "0", "]", ")", "[", "0", "]", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "sqared_error", ")", "/", "math_ops", ".", "cast", "(", "batch_size", ",", "dtypes", ".", "float32", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.losses.get_regression_pearson_loss": [[42, 50], ["tensorflow.reshape", "tensorflow.reshape", "tensorflow.negative", "len", "len", "losses.PearsonCorrelationTF"], "function", ["home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.losses.PearsonCorrelationTF"], ["", "def", "get_regression_pearson_loss", "(", "predicts", ",", "targets", ")", ":", "\n", "  ", "assert", "len", "(", "predicts", ")", "==", "len", "(", "targets", ")", "==", "1", "\n", "\n", "flat_predicts", "=", "tf", ".", "reshape", "(", "predicts", ",", "[", "-", "1", "]", ")", "\n", "flat_targets", "=", "tf", ".", "reshape", "(", "targets", ",", "[", "-", "1", "]", ")", "\n", "\n", "loss", "=", "tf", ".", "negative", "(", "PearsonCorrelationTF", "(", "flat_targets", ",", "flat_predicts", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.epochx_emoatt.multi_task_rnn.losses.PearsonCorrelationTF": [[54, 70], ["tensorflow.name_scope", "tensorflow.to_float", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.subtract", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.div", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.subtract", "tensorflow.subtract", "tensorflow.multiply", "tensorflow.shape", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply"], "function", ["None"], ["", "def", "PearsonCorrelationTF", "(", "x", ",", "y", ",", "prefix", "=", "'pearson'", ")", ":", "\n", "  ", "'''Create a TF network that calculates the Pearson Correlation on two input\n  vectors.  Returns a scalar tensor with the correlation [-1:1].'''", "\n", "with", "tf", ".", "name_scope", "(", "prefix", ")", ":", "\n", "    ", "n", "=", "tf", ".", "to_float", "(", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", ")", "\n", "x_sum", "=", "tf", ".", "reduce_sum", "(", "x", ")", "\n", "y_sum", "=", "tf", ".", "reduce_sum", "(", "y", ")", "\n", "xy_sum", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "x", ",", "y", ")", ")", "\n", "x2_sum", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "x", ",", "x", ")", ")", "\n", "y2_sum", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "multiply", "(", "y", ",", "y", ")", ")", "\n", "\n", "r_num", "=", "tf", ".", "subtract", "(", "tf", ".", "multiply", "(", "n", ",", "xy_sum", ")", ",", "tf", ".", "multiply", "(", "x_sum", ",", "y_sum", ")", ")", "\n", "r_den_x", "=", "tf", ".", "sqrt", "(", "tf", ".", "subtract", "(", "tf", ".", "multiply", "(", "n", ",", "x2_sum", ")", ",", "tf", ".", "multiply", "(", "x_sum", ",", "x_sum", ")", ")", ")", "\n", "r_den_y", "=", "tf", ".", "sqrt", "(", "tf", ".", "subtract", "(", "tf", ".", "multiply", "(", "n", ",", "y2_sum", ")", ",", "tf", ".", "multiply", "(", "y_sum", ",", "y_sum", ")", ")", ")", "\n", "r", "=", "tf", ".", "div", "(", "r_num", ",", "tf", ".", "multiply", "(", "r_den_x", ",", "r_den_y", ")", ",", "name", "=", "'r'", ")", "\n", "", "return", "r", "", "", ""]]}