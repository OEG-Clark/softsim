{"home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.main.main": [[24, 197], ["preprocess.normalize_for_train", "preprocess.normalize_for_train", "pandas.DataFrame", "pd.DataFrame.to_csv", "int", "model.generator", "model.discriminator", "model.real_fake", "model.prediction", "tensorflow.contrib.keras.api.keras.optimizers.Adam", "tensorflow.contrib.keras.api.keras.optimizers.Adam", "tensorflow.contrib.keras.api.keras.layers.Input", "model.discriminator.", "model.real_fake.", "model.prediction.", "tensorflow.contrib.keras.api.keras.layers.Input", "model.generator.", "model.discriminator.", "model.real_fake.", "model.discriminator.", "model.real_fake.", "functools.partial", "tensorflow.contrib.keras.api.keras.models.Model", "tensorflow.contrib.keras.api.keras.models.Model.compile", "tensorflow.contrib.keras.api.keras.layers.Input", "model.generator.", "model.discriminator.", "model.real_fake.", "model.prediction.", "tensorflow.contrib.keras.api.keras.models.Model", "tensorflow.contrib.keras.api.keras.models.Model.compile", "tensorflow.contrib.keras.api.keras.utils.Progbar", "numpy.zeros", "range", "evaluation.save", "tensorflow.contrib.keras.api.keras.backend.clear_session", "os.path.isfile", "download_data.get_data", "preprocess.compute_bag_of_atom_vector", "numpy.concatenate", "pandas.DataFrame", "pd.DataFrame.to_csv", "pandas.read_csv", "numpy.array", "numpy.split", "numpy.concatenate", "model.RandomWeightedAverage", "range", "tensorflow.contrib.keras.api.keras.utils.Progbar.add", "numpy.concatenate", "preprocess.paired_shuffle", "range", "numpy.random.uniform().astype", "range", "tensorflow.contrib.keras.api.keras.models.Model.train_on_batch", "numpy.random.uniform().astype", "range", "tensorflow.contrib.keras.api.keras.models.Model.train_on_batch", "len", "numpy.hstack", "len", "numpy.hstack", "numpy.random.uniform", "numpy.random.uniform"], "function", ["home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.preprocess.normalize_for_train", "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.preprocess.normalize_for_train", "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.model.generator", "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.model.discriminator", "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.model.real_fake", "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.model.prediction", "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.evaluation.save", "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.download_data.get_data", "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.preprocess.compute_bag_of_atom_vector", "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.preprocess.paired_shuffle"], ["def", "main", "(", ")", ":", "\n", "\n", "\t", "if", "os", ".", "path", ".", "isfile", "(", "macro", ".", "_LOCAL_SAVE_DATA", ")", "==", "0", ":", "\n", "\n", "# download data and compute featuers (see \"download_data.py\")", "\n", "# atomic_numbers use to compute composition vector", "\n", "# labels is target properties (formation energy)", "\n", "\t\t", "train_labels", ",", "compositions", ",", "features", ",", "atomic_numbers", "=", "dl", ".", "get_data", "(", ")", "\n", "\n", "# compute bag-of-atom vector that trains GAN (see \"preprocess.py\")", "\n", "boa_vectors", "=", "pre", ".", "compute_bag_of_atom_vector", "(", "compositions", ",", "atomic_numbers", ")", "\n", "train_data", "=", "np", ".", "concatenate", "(", "[", "boa_vectors", ",", "features", "]", ",", "axis", "=", "1", ")", "\n", "\n", "save_data", "=", "pd", ".", "DataFrame", "(", "np", ".", "concatenate", "(", "[", "train_labels", ",", "train_data", "]", ",", "axis", "=", "1", ")", ")", "\n", "save_data", ".", "to_csv", "(", "macro", ".", "_LOCAL_SAVE_DATA", ",", "index", "=", "False", ",", "header", "=", "False", ")", "\n", "\n", "", "else", ":", "\n", "\t\t", "data", "=", "pd", ".", "read_csv", "(", "macro", ".", "_LOCAL_SAVE_DATA", ",", "delimiter", "=", "','", ",", "engine", "=", "\"python\"", ",", "header", "=", "None", ")", "\n", "data", "=", "np", ".", "array", "(", "data", ")", "\n", "train_labels", ",", "train_data", "=", "np", ".", "split", "(", "data", ",", "[", "1", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# normalization of training data such that min is 0 and max is 1 (see \"preprocess.py\")", "\n", "", "normalized_train_data", ",", "data_max", ",", "data_min", "=", "pre", ".", "normalize_for_train", "(", "train_data", ")", "\n", "normalized_train_labels", ",", "max_train_prop", ",", "min_train_prop", "=", "pre", ".", "normalize_for_train", "(", "train_labels", ")", "\n", "\n", "# Save normalization parameter to .csv to use generation", "\n", "save_data", "=", "pd", ".", "DataFrame", "(", "np", ".", "concatenate", "(", "[", "max_train_prop", ",", "min_train_prop", ",", "data_max", ",", "data_min", "]", ",", "axis", "=", "0", ")", ")", "\n", "save_data", ".", "to_csv", "(", "macro", ".", "_SAVE_NORMALIZATION_PARAM", ",", "index", "=", "False", ",", "header", "=", "False", ")", "\n", "\n", "### start initialization of training GAN ###", "\n", "\n", "# set hyperparameters", "\n", "batch_size", "=", "macro", ".", "_BATCH_SIZE", "# batch size", "\n", "noise_dim", "=", "macro", ".", "_NOISE_DIM", "# dimension of noise to input generator", "\n", "property_dim", "=", "macro", ".", "_PROP_DIM", "# the number of properties", "\n", "lamb", "=", "macro", ".", "_LAMB", "# hyperparameter for W-GAN-GP", "\n", "max_epoch", "=", "macro", ".", "_MAX_EPOCH", "# maximum iteration of outer loop", "\n", "max_train_only_dis", "=", "macro", ".", "_MAX_EPOCH_TRAIN_DISCRIMINATOR", "# maximum iteration of inner loop defined by W-GAN-GP paper (https://arxiv.org/pdf/1704.00028.pdf)", "\n", "max_loop", "=", "int", "(", "train_data", ".", "shape", "[", "0", "]", "/", "batch_size", ")", "\n", "\n", "# set model (see \"model.py\")", "\n", "# in this code, we apply AC-GAN based network architecture (https://arxiv.org/abs/1610.09585)", "\n", "# difference between AC-GAN is that our model is the regression, not classification", "\n", "gen", "=", "model", ".", "generator", "(", "normalized_train_data", ".", "shape", "[", "1", "]", ")", "\n", "dis", "=", "model", ".", "discriminator", "(", "normalized_train_data", ".", "shape", "[", "1", "]", ")", "\n", "\n", "# rf is the output layer of discriminator that discriminates real or fake", "\n", "rf", "=", "model", ".", "real_fake", "(", ")", "\n", "\n", "# pred is the output layer of discriminator that predicts target property", "\n", "pred", "=", "model", ".", "prediction", "(", ")", "\n", "\n", "# set optimization method", "\n", "dis_opt", "=", "Adam", "(", "lr", "=", "1.0e-4", ",", "beta_1", "=", "0.0", ",", "beta_2", "=", "0.9", ")", "\n", "gen_opt", "=", "Adam", "(", "lr", "=", "1.0e-4", ",", "beta_1", "=", "0.0", ",", "beta_2", "=", "0.9", ")", "\n", "\n", "# first set discriminator's parameters for training", "\n", "gen", ".", "trainable", "=", "False", "# generator's parameter does not update", "\n", "dis", ".", "trainable", "=", "True", "\n", "rf", ".", "trainable", "=", "True", "\n", "pred", ".", "trainable", "=", "True", "\n", "\n", "# set variables when inputting real data", "\n", "real_inputs", "=", "Input", "(", "shape", "=", "normalized_train_data", ".", "shape", "[", "1", ":", "]", ")", "\n", "dis_real_outputs", "=", "dis", "(", "real_inputs", ")", "\n", "real_fake_from_real", "=", "rf", "(", "dis_real_outputs", ")", "\n", "predictions_from_real", "=", "pred", "(", "dis_real_outputs", ")", "\n", "\n", "# set variables when inputting fake data", "\n", "fake_inputs", "=", "Input", "(", "shape", "=", "(", "noise_dim", "+", "property_dim", ",", ")", ")", "\n", "gen_fake_outputs", "=", "gen", "(", "fake_inputs", ")", "\n", "dis_fake_outputs", "=", "dis", "(", "gen_fake_outputs", ")", "\n", "real_fake_from_fake", "=", "rf", "(", "dis_fake_outputs", ")", "\n", "\n", "# set loss function for discriminator", "\n", "# in this case, we apply W-GAN-GP based loss function because of improving stability", "\n", "# W-GAN-GP (https://arxiv.org/pdf/1704.00028.pdf)", "\n", "# W-GAN-GP is unsupervised training, on the other hand, our model is supervised (conditional).", "\n", "# So, we apply wasserstein_loss to real_fake part and apply mean_squared_error to prediction part", "\n", "interpolate", "=", "model", ".", "RandomWeightedAverage", "(", ")", "(", "[", "real_inputs", ",", "gen_fake_outputs", "]", ")", "\n", "dis_interpolate_outputs", "=", "dis", "(", "interpolate", ")", "\n", "real_fake_interpolate", "=", "rf", "(", "dis_interpolate_outputs", ")", "\n", "\n", "# gradient penalty of W-GAN-GP", "\n", "gp_reg", "=", "partial", "(", "model", ".", "gradient_penalty", ",", "interpolate", "=", "interpolate", ",", "lamb", "=", "lamb", ")", "\n", "gp_reg", ".", "__name__", "=", "'gradient_penalty'", "\n", "\n", "# connect inputs and outputs of the discriminator", "\n", "# prediction part is trained by only using training dataset (i.e., predict part is not trained by generated samples)", "\n", "dis_model", "=", "Model", "(", "inputs", "=", "[", "real_inputs", ",", "fake_inputs", "]", ",", "outputs", "=", "[", "real_fake_from_real", ",", "real_fake_from_fake", ",", "real_fake_interpolate", ",", "predictions_from_real", "]", ")", "\n", "\n", "# compile", "\n", "dis_model", ".", "compile", "(", "loss", "=", "[", "model", ".", "wasserstein_loss", ",", "model", ".", "wasserstein_loss", ",", "gp_reg", ",", "'mean_squared_error'", "]", ",", "optimizer", "=", "dis_opt", ")", "\n", "\n", "\n", "# second set generator's parameters for training", "\n", "gen", ".", "trainable", "=", "True", "# generator's parameters only update", "\n", "dis", ".", "trainable", "=", "False", "\n", "rf", ".", "trainable", "=", "False", "\n", "pred", ".", "trainable", "=", "False", "\n", "\n", "# set variables when inputting noise and target property", "\n", "gen_inputs", "=", "Input", "(", "shape", "=", "(", "noise_dim", "+", "property_dim", ",", ")", ")", "\n", "gen_outputs", "=", "gen", "(", "gen_inputs", ")", "\n", "\n", "# set variables for discriminator when inputting fake data", "\n", "dis_outputs", "=", "dis", "(", "gen_outputs", ")", "\n", "real_fake", "=", "rf", "(", "dis_outputs", ")", "\n", "predictions", "=", "pred", "(", "dis_outputs", ")", "\n", "\n", "# connect inputs and outputs of the discriminator", "\n", "gen_model", "=", "Model", "(", "inputs", "=", "[", "gen_inputs", "]", ",", "outputs", "=", "[", "real_fake", ",", "predictions", "]", ")", "\n", "\n", "# compile", "\n", "# generator is trained by real_fake classification and prediction of target property", "\n", "gen_model", ".", "compile", "(", "loss", "=", "[", "model", ".", "wasserstein_loss", ",", "'mean_squared_error'", "]", ",", "optimizer", "=", "gen_opt", ")", "\n", "\n", "\n", "# if you need progress bar", "\n", "progbar", "=", "Progbar", "(", "target", "=", "max_epoch", ")", "\n", "\n", "# set the answer to train each model", "\n", "real_label", "=", "[", "-", "1", "]", "*", "batch_size", "\n", "fake_label", "=", "[", "1", "]", "*", "batch_size", "\n", "dummy_label", "=", "[", "0", "]", "*", "batch_size", "\n", "\n", "#real = np.zeros((batch_size,train_data.shape[1]), dtype=np.float32)", "\n", "inputs", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "noise_dim", "+", "property_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "# epoch", "\n", "for", "epoch", "in", "range", "(", "max_epoch", ")", ":", "\n", "\n", "# iteration", "\n", "\t\t", "for", "loop", "in", "range", "(", "max_loop", ")", ":", "\n", "\n", "# shuffle to change the trainng order and select data", "\n", "\t\t\t", "sdata", ",", "slabels", ",", "bak", "=", "pre", ".", "paired_shuffle", "(", "normalized_train_data", ",", "normalized_train_labels", ")", "\n", "real", "=", "sdata", "[", "loop", "*", "batch_size", ":", "(", "loop", "+", "1", ")", "*", "batch_size", "]", "\n", "properties", "=", "slabels", "[", "loop", "*", "batch_size", ":", "(", "loop", "+", "1", ")", "*", "batch_size", "]", "\n", "\n", "# generator's parameters does not update", "\n", "gen", ".", "trainable", "=", "False", "\n", "dis", ".", "trainable", "=", "True", "\n", "rf", ".", "trainable", "=", "True", "\n", "pred", ".", "trainable", "=", "True", "\n", "\n", "# train discriminator", "\n", "for", "train_only_dis", "in", "range", "(", "max_train_only_dis", ")", ":", "\n", "\t\t\t\t", "noise", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "(", "batch_size", ",", "noise_dim", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "noise", ")", ")", ":", "\n", "\t\t\t\t\t", "inputs", "[", "i", "]", "=", "np", ".", "hstack", "(", "(", "noise", "[", "i", "]", ",", "properties", "[", "i", "]", ")", ")", "\n", "", "dis_loss", "=", "dis_model", ".", "train_on_batch", "(", "[", "real", ",", "inputs", "]", ",", "[", "real_label", ",", "fake_label", ",", "dummy_label", ",", "properties", "]", ")", "\n", "\n", "# second train only generator", "\n", "", "gen", ".", "trainable", "=", "True", "\n", "dis", ".", "trainable", "=", "False", "\n", "rf", ".", "trainable", "=", "False", "\n", "pred", ".", "trainable", "=", "False", "\n", "noise", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "(", "batch_size", ",", "noise_dim", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "noise", ")", ")", ":", "\n", "\t\t\t\t", "inputs", "[", "i", "]", "=", "np", ".", "hstack", "(", "(", "noise", "[", "i", "]", ",", "properties", "[", "i", "]", ")", ")", "\n", "", "gen_loss", "=", "gen_model", ".", "train_on_batch", "(", "[", "inputs", "]", ",", "[", "real_label", ",", "properties", "]", ")", "\n", "\n", "# if you need progress bar", "\n", "", "progbar", ".", "add", "(", "1", ",", "values", "=", "[", "(", "\"dis_loss\"", ",", "dis_loss", "[", "0", "]", ")", ",", "(", "\"gen_loss\"", ",", "gen_loss", "[", "0", "]", ")", "]", ")", "\n", "\n", "\n", "# save generated samples and models", "\n", "", "eval", ".", "save", "(", "normalized_train_data", ",", "gen", ",", "dis", ",", "pred", ",", "rf", ")", "\n", "\n", "backend", ".", "clear_session", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.preprocess.normalize_for_train": [[10, 18], ["numpy.max", "numpy.min"], "function", ["None"], ["def", "normalize_for_train", "(", "data", ")", ":", "\n", "\n", "\t", "data_max", "=", "np", ".", "max", "(", "data", ",", "axis", "=", "0", ")", "\n", "data_min", "=", "np", ".", "min", "(", "data", ",", "axis", "=", "0", ")", "\n", "\n", "normalized_data", "=", "(", "data", "-", "data_min", ")", "/", "(", "data_max", "-", "data_min", "+", "macro", ".", "_EPS", ")", "\n", "\n", "return", "normalized_data", ",", "data_max", ",", "data_min", "\n", "\n"]], "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.preprocess.paired_shuffle": [[21, 37], ["numpy.zeros", "range", "numpy.random.shuffle", "len", "numpy.hstack"], "function", ["None"], ["", "def", "paired_shuffle", "(", "data", ",", "labels", ")", ":", "\n", "\n", "# concatenate", "\n", "\t", "zips", "=", "np", ".", "zeros", "(", "(", "data", ".", "shape", "[", "0", "]", ",", "data", ".", "shape", "[", "1", "]", "+", "labels", ".", "shape", "[", "1", "]", "+", "1", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "\t\t", "zips", "[", "i", "]", "=", "np", ".", "hstack", "(", "(", "labels", "[", "i", "]", ",", "i", ",", "data", "[", "i", "]", ")", ")", "\n", "\n", "# shuffle", "\n", "", "np", ".", "random", ".", "shuffle", "(", "zips", ")", "\n", "\n", "# separate", "\n", "slabels", "=", "zips", "[", ":", ",", "0", ":", "1", "]", "\n", "sidx", "=", "zips", "[", ":", ",", "1", ":", "2", "]", "\n", "sdata", "=", "zips", "[", ":", ",", "2", ":", "]", "\n", "\n", "return", "sdata", ",", "slabels", ",", "sidx", "\n", "\n"]], "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.preprocess.compute_bag_of_atom_vector": [[40, 63], ["numpy.zeros", "pymatgen.Composition", "len", "len", "pymatgen.Composition.get_atomic_fraction", "range", "len", "len"], "function", ["None"], ["", "def", "compute_bag_of_atom_vector", "(", "compositions", ",", "atomic_numbers", ")", ":", "\n", "\n", "\t", "i", "=", "0", "\n", "boa_vectors", "=", "np", ".", "zeros", "(", "(", "len", "(", "compositions", ")", ",", "len", "(", "atomic_numbers", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "line", "in", "compositions", ":", "\n", "\t\t", "if", "line", "==", "'nan'", ":", "\n", "\t\t\t", "line", "=", "'NaN'", "\n", "# get atom information from composition", "\n", "", "atoms", "=", "Composition", "(", "line", "[", "0", "]", ")", "\n", "for", "element", "in", "atoms", ":", "\n", "# get ratio of each atom of composition", "\n", "\t\t\t", "ratio", "=", "atoms", ".", "get_atomic_fraction", "(", "element", ")", "\n", "if", "element", ".", "Z", "-", "1", "<", "len", "(", "atomic_numbers", ")", "and", "element", ".", "Z", "-", "1", "==", "atomic_numbers", "[", "element", ".", "Z", "-", "1", "]", ":", "\n", "\t\t\t\t\t", "idx", "=", "element", ".", "Z", "-", "1", "\n", "", "else", ":", "\n", "\t\t\t\t", "for", "j", "in", "range", "(", "len", "(", "atomic_numbers", ")", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "\t\t\t\t\t", "if", "element", ".", "Z", "-", "1", "==", "atomic_numbers", "[", "j", "]", ":", "\n", "\t\t\t\t\t\t", "idx", "=", "j", "\n", "break", "\n", "", "", "", "boa_vectors", "[", "i", "]", "[", "idx", "]", "=", "ratio", "\n", "", "i", "=", "i", "+", "1", "\n", "", "return", "boa_vectors", "\n", "", ""]], "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.model.RandomWeightedAverage._merge_function": [[20, 23], ["tensorflow.contrib.keras.backend.random_uniform"], "methods", ["None"], ["    ", "def", "_merge_function", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "eps", "=", "K", ".", "random_uniform", "(", "(", "macro", ".", "_BATCH_SIZE", ",", "1", ",", "1", ",", "1", ")", ")", "\n", "return", "(", "eps", "*", "inputs", "[", "0", "]", "+", "(", "1", "-", "eps", ")", "*", "inputs", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.model.wasserstein_loss": [[25, 27], ["tensorflow.contrib.keras.backend.mean"], "function", ["None"], ["", "", "def", "wasserstein_loss", "(", "y_true", ",", "y_pred", ")", ":", "\n", "    ", "return", "K", ".", "mean", "(", "y_true", "*", "y_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.model.gradient_penalty": [[29, 36], ["tensorflow.contrib.keras.backend.square", "tensorflow.contrib.keras.backend.sum", "tensorflow.contrib.keras.backend.sqrt", "tensorflow.contrib.keras.backend.mean", "tensorflow.contrib.keras.backend.gradients", "tensorflow.contrib.keras.backend.square", "numpy.arange", "len"], "function", ["None"], ["", "def", "gradient_penalty", "(", "y_true", ",", "y_pred", ",", "interpolate", ",", "lamb", ")", ":", "\n", "    ", "grad", "=", "K", ".", "gradients", "(", "y_pred", ",", "interpolate", ")", "[", "0", "]", "\n", "norm", "=", "K", ".", "square", "(", "grad", ")", "\n", "norm_sum", "=", "K", ".", "sum", "(", "norm", ",", "axis", "=", "np", ".", "arange", "(", "1", ",", "len", "(", "norm", ".", "shape", ")", ")", ")", "\n", "l2_norm", "=", "K", ".", "sqrt", "(", "norm_sum", ")", "\n", "gp_reg", "=", "lamb", "*", "K", ".", "square", "(", "1", "-", "l2_norm", ")", "\n", "return", "K", ".", "mean", "(", "gp_reg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.model.generator": [[38, 49], ["tensorflow.contrib.keras.api.keras.models.Sequential", "tensorflow.contrib.keras.api.keras.models.Sequential.add", "tensorflow.contrib.keras.api.keras.models.Sequential.add", "tensorflow.contrib.keras.api.keras.models.Sequential.add", "tensorflow.contrib.keras.api.keras.layers.Dense", "tensorflow.contrib.keras.api.keras.layers.Dense", "tensorflow.contrib.keras.api.keras.layers.Dense"], "function", ["None"], ["", "def", "generator", "(", "data_shape", ")", ":", "\n", "    ", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "Dense", "(", "macro", ".", "_LAYER_DIM", ",", "activation", "=", "'relu'", ",", "input_shape", "=", "(", "macro", ".", "_NOISE_DIM", "+", "macro", ".", "_PROP_DIM", ",", ")", ")", ")", "\n", "#model.add(Dropout(0.2))", "\n", "model", ".", "add", "(", "Dense", "(", "2", "*", "macro", ".", "_LAYER_DIM", ",", "activation", "=", "'relu'", ")", ")", "\n", "#model.add(Dropout(0.2))", "\n", "#model.add(Dense(3*macro._LAYER_DIM, activation='relu'))", "\n", "#model.add(Dropout(0.2))", "\n", "# use sigmoid function to constrain output from 0 to 1.", "\n", "model", ".", "add", "(", "Dense", "(", "data_shape", ",", "activation", "=", "'sigmoid'", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.model.discriminator": [[51, 62], ["tensorflow.contrib.keras.api.keras.models.Sequential", "tensorflow.contrib.keras.api.keras.models.Sequential.add", "tensorflow.contrib.keras.api.keras.models.Sequential.add", "tensorflow.contrib.keras.api.keras.layers.Dense", "tensorflow.contrib.keras.api.keras.layers.Dense"], "function", ["None"], ["", "def", "discriminator", "(", "data_shape", ")", ":", "\n", "    ", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "Dense", "(", "2", "*", "macro", ".", "_LAYER_DIM", ",", "activation", "=", "'relu'", ",", "input_shape", "=", "(", "data_shape", ",", ")", ")", ")", "\n", "#model.add(Dropout(0.2))", "\n", "#model.add(Dense(3*macro._LAYER_DIM, activation='relu', input_shape=(data_shape,)))", "\n", "#model.add(Dropout(0.2))", "\n", "#model.add(Dense(2*macro._LAYER_DIM, activation='relu'))", "\n", "#model.add(Dropout(0.2))", "\n", "model", ".", "add", "(", "Dense", "(", "macro", ".", "_LAYER_DIM", ",", "activation", "=", "'relu'", ")", ")", "\n", "#model.add(Dropout(0.2))", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.model.real_fake": [[64, 68], ["tensorflow.contrib.keras.api.keras.models.Sequential", "tensorflow.contrib.keras.api.keras.models.Sequential.add", "tensorflow.contrib.keras.api.keras.layers.Dense"], "function", ["None"], ["", "def", "real_fake", "(", ")", ":", "\n", "    ", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "Dense", "(", "1", ",", "name", "=", "'real_fake'", ",", "input_shape", "=", "(", "macro", ".", "_LAYER_DIM", ",", ")", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.model.prediction": [[70, 74], ["tensorflow.contrib.keras.api.keras.models.Sequential", "tensorflow.contrib.keras.api.keras.models.Sequential.add", "tensorflow.contrib.keras.api.keras.layers.Dense"], "function", ["None"], ["", "def", "prediction", "(", ")", ":", "\n", "    ", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "Dense", "(", "macro", ".", "_PROP_DIM", ",", "name", "=", "'predictions'", ",", "input_shape", "=", "(", "macro", ".", "_LAYER_DIM", ",", ")", ")", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.mcmc.metropolis_hastings": [[8, 89], ["numpy.sum", "numpy.round", "range", "numpy.array", "numpy.zeros", "range", "range", "numpy.dot", "numpy.min", "numpy.zeros", "range", "range", "len", "len", "np.array.append", "np.array.max", "len", "len", "len", "numpy.dot", "range", "numpy.random.multivariate_normal", "np.round.clip", "range", "numpy.round", "numpy.dot", "numpy.zeros", "range", "numpy.max", "numpy.unravel_index", "numpy.random.random", "len", "len", "len", "len", "len", "len", "numpy.exp", "numpy.exp", "numpy.argmax", "range", "abs", "numpy.sum", "len", "numpy.sum", "len"], "function", ["None"], ["def", "metropolis_hastings", "(", "valences", ",", "chemical_formula", ",", "iteration", ")", ":", "\n", "\n", "# normalize and rounding", "\n", "    ", "mean_vect", "=", "chemical_formula", "[", "chemical_formula", ">", "1.0e-6", "]", "\n", "mean_sum", "=", "np", ".", "sum", "(", "mean_vect", ")", "\n", "mean_vect", "=", "mean_vect", "/", "mean_sum", "\n", "mean_vect", "=", "np", ".", "round", "(", "mean_vect", ",", "decimals", "=", "macro", ".", "_ROUND", ")", "\n", "\n", "# if composition includes only one atom, return", "\n", "if", "len", "(", "mean_vect", ")", "==", "1", ":", "\n", "        ", "return", "mean_vect", ",", "0", "\n", "\n", "", "cnt", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "valences", ")", ")", ":", "\n", "        ", "cnt", ".", "append", "(", "len", "(", "valences", "[", "i", "]", ")", ")", "\n", "", "cnt", "=", "np", ".", "array", "(", "cnt", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "buf", "=", "np", ".", "zeros", "(", "cnt", ".", "max", "(", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "cnt", ")", ")", ":", "\n", "        ", "buf", "[", "cnt", "[", "i", "]", "-", "1", "]", "=", "1", "\n", "# if there is not valence array, return", "\n", "if", "cnt", "[", "i", "]", "==", "0", ":", "\n", "            ", "return", "mean_vect", ",", "1", "\n", "\n", "# To reduce the complexity, if len(valence) has several values, return (must improve)", "\n", "", "", "num", "=", "0", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "buf", ")", ")", ":", "\n", "        ", "if", "buf", "[", "i", "]", "!=", "0", ":", "\n", "            ", "num", "=", "num", "+", "1", "\n", "", "", "if", "num", ">", "1", ":", "\n", "        ", "return", "mean_vect", ",", "1", "\n", "\n", "", "y_now", "=", "np", ".", "dot", "(", "mean_vect", ",", "valences", ")", "\n", "y_min", "=", "np", ".", "min", "(", "y_now", ")", "\n", "\n", "# if mean_vect is already balance, return", "\n", "if", "iteration", "==", "0", ":", "\n", "        ", "return", "mean_vect", ",", "0", "\n", "\n", "# set the covariance of gaussian (proposal distribution)", "\n", "", "cov", "=", "np", ".", "zeros", "(", "(", "len", "(", "mean_vect", ")", ",", "len", "(", "mean_vect", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "mean_vect", ")", ")", ":", "\n", "        ", "cov", "[", "i", "]", "[", "i", "]", "=", "macro", ".", "_SIGMA", "\n", "\n", "", "before_y_min", "=", "y_min", "\n", "before_mean_vect", "=", "mean_vect", "\n", "for", "ite", "in", "range", "(", "iteration", ")", ":", "\n", "\n", "        ", "y_now", "=", "np", ".", "dot", "(", "mean_vect", ",", "valences", ")", "\n", "\n", "# if balance, return", "\n", "for", "i", "in", "range", "(", "len", "(", "y_now", ")", ")", ":", "\n", "            ", "if", "abs", "(", "y_now", "[", "i", "]", ")", "<", "1.0e-6", ":", "\n", "                ", "return", "mean_vect", ",", "0", "\n", "\n", "", "", "x_star", "=", "np", ".", "random", ".", "multivariate_normal", "(", "mean_vect", ",", "cov", ",", "macro", ".", "_SAMPLING", ")", "\n", "x_star", "=", "x_star", ".", "clip", "(", "min", "=", "1.0e-6", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "x_star", ")", ")", ":", "\n", "            ", "x_star", "[", "i", "]", "=", "x_star", "[", "i", "]", "/", "np", ".", "sum", "(", "x_star", "[", "i", "]", ")", "\n", "", "x_star", "=", "np", ".", "round", "(", "x_star", ",", "macro", ".", "_ROUND", ")", "\n", "\n", "# expand array list", "\n", "bak", "=", "np", ".", "dot", "(", "x_star", ",", "valences", ")", "\n", "y_star", "=", "np", ".", "zeros", "(", "(", "macro", ".", "_SAMPLING", ",", "len", "(", "y_now", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "y_star", ")", ")", ":", "\n", "            ", "y_star", "[", "i", "]", "=", "bak", "[", "i", "]", "\n", "\n", "", "A", "=", "np", ".", "exp", "(", "-", "y_star", "*", "y_star", ")", "/", "np", ".", "exp", "(", "-", "y_now", "*", "y_now", ")", "\n", "max_A", "=", "np", ".", "max", "(", "A", ")", "\n", "arg_A_x", ",", "arg_A_y", "=", "np", ".", "unravel_index", "(", "np", ".", "argmax", "(", "A", ")", ",", "A", ".", "shape", ")", "\n", "\n", "if", "max_A", ">", "1.0", ":", "\n", "            ", "max_A", "=", "1.0", "\n", "", "p", "=", "np", ".", "random", ".", "random", "(", ")", "\n", "if", "p", "<", "max_A", "and", "np", ".", "sum", "(", "mean_vect", ")", ">", "1.0e-6", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "mean_vect", ")", ")", ":", "\n", "                ", "mean_vect", "[", "i", "]", "=", "x_star", "[", "arg_A_x", "]", "[", "i", "]", "\n", "", "", "if", "y_star", "[", "arg_A_x", "]", "[", "arg_A_y", "]", "<", "1.0e-6", ":", "\n", "            ", "break", "\n", "\n", "", "", "return", "mean_vect", ",", "0", "\n", "", ""]], "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.download_data.get_atomic_lists_and_numbers": [[15, 35], ["numpy.empty", "numpy.array", "numpy.sort", "pymatgen.Composition", "list", "atomic_numbers_duplicated.append", "set"], "function", ["None"], ["def", "get_atomic_lists_and_numbers", "(", "compositions", ")", ":", "\n", "\n", "# get atom number", "\n", "\t", "atom_lists", "=", "np", ".", "empty", "(", "118", ",", "dtype", "=", "object", ")", "\n", "atoms_duplicated", "=", "[", "]", "\n", "atomic_numbers_duplicated", "=", "[", "]", "\n", "for", "line", "in", "compositions", ":", "\n", "\t\t", "if", "line", "==", "'nan'", ":", "\n", "\t\t\t", "line", "=", "'NaN'", "\n", "", "atom_list", "=", "Composition", "(", "line", "[", "0", "]", ")", "\n", "#atom_list = Composition(line)", "\n", "for", "element", "in", "atom_list", ":", "\n", "\t\t\t", "atomic_numbers_duplicated", ".", "append", "(", "element", ".", "Z", "-", "1", ")", "\n", "atom_lists", "[", "element", ".", "Z", "-", "1", "]", "=", "element", ".", "symbol", "\n", "\n", "# reduce duplicate", "\n", "", "", "atomic_numbers", "=", "np", ".", "array", "(", "list", "(", "set", "(", "atomic_numbers_duplicated", ")", ")", ")", "\n", "atomic_numbers", "=", "np", ".", "sort", "(", "atomic_numbers", ",", "axis", "=", "0", ")", "\n", "\n", "return", "atom_lists", ",", "atomic_numbers", "\n", "\n"]], "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.download_data.download_file": [[37, 53], ["pandas.read_csv", "data[].map", "numpy.array", "numpy.split", "numpy.array", "numpy.split", "numpy.array", "numpy.array", "x.as_dict", "xenonpy.descriptor.Compositions.transform", "pymatgen.Composition", "numpy.array", "xenonpy.descriptor.Compositions", "xenonpy.datatools.preset.elements_completed.head"], "function", ["None"], ["", "def", "download_file", "(", ")", ":", "\n", "\n", "\t", "data", "=", "pd", ".", "read_csv", "(", "macro", ".", "_INORGANIC_DATA", ",", "delimiter", "=", "','", ",", "engine", "=", "\"python\"", ")", "\n", "\n", "composition_lists", "=", "data", "[", "'Composition'", "]", ".", "map", "(", "lambda", "x", ":", "Composition", "(", "x", ")", ")", "\n", "composition_lists", "=", "[", "x", ".", "as_dict", "(", ")", "for", "x", "in", "composition_lists", "]", "\n", "features", "=", "np", ".", "array", "(", "comp", "(", ")", ".", "transform", "(", "composition_lists", ")", ")", "\n", "feature_num", "=", "np", ".", "array", "(", "preset", ".", "elements_completed", ".", "head", "(", "1", ")", ")", ".", "shape", "[", "1", "]", "\n", "features", ",", "_", "=", "np", ".", "split", "(", "features", ",", "[", "feature_num", "]", ",", "axis", "=", "1", ")", "\n", "\n", "data", "=", "np", ".", "array", "(", "data", ")", "\n", "ids", ",", "compositions", ",", "labels", "=", "np", ".", "split", "(", "data", ",", "[", "1", ",", "2", "]", ",", "axis", "=", "1", ")", "\n", "compositions", "=", "np", ".", "array", "(", "compositions", ",", "dtype", "=", "str", ")", "\n", "labels", "=", "np", ".", "array", "(", "labels", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "return", "compositions", ",", "labels", ",", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.download_data.get_data": [[55, 68], ["download_data.download_file", "download_data.get_atomic_lists_and_numbers", "pandas.DataFrame().dropna", "pd.DataFrame().dropna.to_csv", "pandas.DataFrame"], "function", ["home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.download_data.download_file", "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.download_data.get_atomic_lists_and_numbers"], ["", "def", "get_data", "(", ")", ":", "\n", "\n", "# load materials project data", "\n", "\t", "compositions", ",", "labels", ",", "features", "=", "download_file", "(", ")", "\n", "\n", "# Get atomic numbers and atom lists using this dataset", "\n", "atom_lists", ",", "atomic_numbers", "=", "get_atomic_lists_and_numbers", "(", "compositions", ")", "\n", "\n", "# By checking this list, we can reconstruct the composition (i-th variable correponds to i-th atom)", "\n", "save_data", "=", "pd", ".", "DataFrame", "(", "atom_lists", ")", ".", "dropna", "(", ")", "\n", "save_data", ".", "to_csv", "(", "macro", ".", "_ATOM_LIST", ",", "index", "=", "False", ",", "header", "=", "False", ")", "\n", "\n", "return", "labels", ",", "compositions", ",", "features", ",", "atomic_numbers", "\n", "", ""]], "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.evaluation.save": [[11, 86], ["numpy.array", "numpy.array", "numpy.split", "numpy.random.uniform().astype", "numpy.zeros", "range", "numpy.array", "dis.predict", "range", "numpy.array", "range", "open", "range", "open.close", "gen.save", "dis.save", "rf.save", "pred.save", "pandas.read_csv", "pandas.read_csv", "len", "numpy.hstack", "gen.predict", "len", "range", "np.array.append", "len", "range", "numpy.array", "mcmc.metropolis_hastings", "range", "generated_compositions.append", "flags.append", "len", "numpy.random.uniform", "len", "numpy.sum", "len", "len", "open.write", "numpy.sum", "range", "np.array.append", "len", "len", "valence.append", "numpy.array", "float", "pymatgen.Element", "pymatgen.Element"], "function", ["home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.evaluation.save", "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.evaluation.save", "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.evaluation.save", "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.evaluation.save", "home.repos.pwc.inspect_result.yoshihidesawada_CompGAN.src.mcmc.metropolis_hastings"], ["def", "save", "(", "normalized_data", ",", "gen", ",", "dis", ",", "pred", ",", "rf", ")", ":", "\n", "\n", "# load parameters", "\n", "    ", "atom_list", "=", "np", ".", "array", "(", "pd", ".", "read_csv", "(", "macro", ".", "_ATOM_LIST", ",", "delimiter", "=", "','", ",", "engine", "=", "\"python\"", ",", "header", "=", "None", ")", ")", "\n", "data", "=", "np", ".", "array", "(", "pd", ".", "read_csv", "(", "macro", ".", "_SAVE_NORMALIZATION_PARAM", ",", "delimiter", "=", "','", ",", "engine", "=", "\"python\"", ",", "header", "=", "None", ")", ")", "\n", "max_train_prop", ",", "min_train_prop", ",", "data_max", ",", "data_min", "=", "np", ".", "split", "(", "data", ",", "[", "1", ",", "2", ",", "normalized_data", ".", "shape", "[", "1", "]", "+", "2", "]", ",", "axis", "=", "0", ")", "\n", "\n", "batch_size", "=", "macro", ".", "_TEST_BATCH_SIZE", "# the number of generated samples of each input target property", "\n", "noise_dim", "=", "macro", ".", "_NOISE_DIM", "# nosie dimenstion", "\n", "property_dim", "=", "macro", ".", "_PROP_DIM", "# target property dimension", "\n", "property", "=", "(", "macro", ".", "_TARGET_PROP", "-", "min_train_prop", ")", "/", "(", "max_train_prop", "-", "min_train_prop", "+", "macro", ".", "_EPS", ")", "# normalized target property", "\n", "\n", "# evaluation", "\n", "# feed all target properties in test data into generator", "\n", "# compute nearest neighbor method between generate sample and test data", "\n", "# save generated composition, corresponding nearest composition, and corresponding target property", "\n", "# generate samples based on the test target property", "\n", "noise", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "(", "batch_size", ",", "noise_dim", ")", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "inputs", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "noise_dim", "+", "property_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "noise", ")", ")", ":", "\n", "        ", "inputs", "[", "i", "]", "=", "np", ".", "hstack", "(", "(", "noise", "[", "i", "]", ",", "property", "[", "0", "]", "[", "0", "]", ")", ")", "\n", "", "fake", "=", "np", ".", "array", "(", "gen", ".", "predict", "(", "inputs", ")", ")", "\n", "fake_last_layer", "=", "dis", ".", "predict", "(", "fake", ")", "\n", "\n", "# renormalized generated samples", "\n", "renormalized_fake", "=", "fake", "*", "(", "data_max", ".", "T", "-", "data_min", ".", "T", "+", "macro", ".", "_EPS", ")", "+", "data_min", ".", "T", "\n", "\n", "# thresholding composition vector", "\n", "# if value of composition vector is lower than macro._TH, set 0 (to guarantee sparsity)", "\n", "boa_vectors", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "noise", ")", ")", ":", "\n", "        ", "boa_vector", "=", "renormalized_fake", "[", "i", ",", ":", "len", "(", "atom_list", ")", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "boa_vector", ")", ")", ":", "\n", "            ", "if", "boa_vector", "[", "j", "]", "<", "macro", ".", "_TH", ":", "\n", "                ", "boa_vector", "[", "j", "]", "=", "0.0", "\n", "", "", "if", "np", ".", "sum", "(", "boa_vector", ")", "!=", "0.0", ":", "\n", "            ", "boa_vector", "=", "boa_vector", "/", "np", ".", "sum", "(", "boa_vector", ")", "\n", "", "boa_vectors", ".", "append", "(", "boa_vector", ")", "\n", "", "boa_vectors", "=", "np", ".", "array", "(", "boa_vectors", ")", "\n", "\n", "# convert composition vector to chemical composition", "\n", "generated_compositions", "=", "[", "]", "\n", "flags", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "boa_vectors", ")", ")", ":", "\n", "\n", "        ", "valences", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "boa_vectors", "[", "0", "]", ")", ")", ":", "\n", "            ", "if", "boa_vectors", "[", "i", "]", "[", "j", "]", ">", "1.0e-6", ":", "\n", "                ", "valence", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "len", "(", "Element", "(", "atom_list", "[", "j", "]", "[", "0", "]", ")", ".", "common_oxidation_states", ")", ")", ":", "\n", "                    ", "valence", ".", "append", "(", "float", "(", "Element", "(", "atom_list", "[", "j", "]", "[", "0", "]", ")", ".", "common_oxidation_states", "[", "k", "]", ")", ")", "\n", "", "valences", ".", "append", "(", "np", ".", "array", "(", "valence", ")", ")", "\n", "", "", "valences", "=", "np", ".", "array", "(", "valences", ")", "\n", "mcmc_vectors", ",", "flag", "=", "mcmc", ".", "metropolis_hastings", "(", "valences", ",", "boa_vectors", "[", "i", "]", ",", "macro", ".", "_ITERATION", ")", "\n", "\n", "generated_composition", "=", "''", "\n", "for", "j", "in", "range", "(", "len", "(", "mcmc_vectors", ")", ")", ":", "\n", "            ", "if", "mcmc_vectors", "[", "j", "]", ">", "1.0e-6", ":", "\n", "                ", "generated_composition", "=", "generated_composition", "+", "atom_list", "[", "j", "]", "+", "\"%.2f\"", "%", "(", "mcmc_vectors", "[", "j", "]", ")", "\n", "\n", "", "", "generated_compositions", ".", "append", "(", "generated_composition", ")", "\n", "flags", ".", "append", "(", "flag", ")", "\n", "\n", "# save generated result", "\n", "", "fp", "=", "open", "(", "'%s/%s'", "%", "(", "macro", ".", "_FILEPATH", ",", "macro", ".", "_SAVE_FILE", ")", ",", "'w'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "generated_compositions", ")", ")", ":", "\n", "        ", "if", "flags", "[", "i", "]", "==", "0", ":", "\n", "            ", "fp", ".", "write", "(", "'%s\\n'", "%", "(", "generated_compositions", "[", "i", "]", "[", "0", "]", ")", ")", "\n", "", "", "fp", ".", "close", "(", ")", "\n", "\n", "# save models", "\n", "gen", ".", "save", "(", "'%s/generator.h5'", "%", "(", "macro", ".", "_FILEPATH", ")", ")", "\n", "dis", ".", "save", "(", "'%s/discriminator.h5'", "%", "(", "macro", ".", "_FILEPATH", ")", ")", "\n", "rf", ".", "save", "(", "'%s/real_fake_classifier.h5'", "%", "(", "macro", ".", "_FILEPATH", ")", ")", "\n", "pred", ".", "save", "(", "'%s/prediction.h5'", "%", "(", "macro", ".", "_FILEPATH", ")", ")", "\n", "", ""]]}