{"home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_local.set_seed": [[22, 30], ["random.seed", "numpy.random.seed", "torch.manual_seed", "opt.device.startswith", "print", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.current_device"], "function", ["None"], ["def", "set_seed", "(", "opt", ",", "seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "opt", ".", "device", ".", "startswith", "(", "\"cuda\"", ")", ":", "\n", "        ", "print", "(", "\"using GPU...\"", ",", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_local.parse_arguments": [[32, 73], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.parse_args", "print", "str"], "function", ["None"], ["", "", "def", "parse_arguments", "(", "parser", ")", ":", "\n", "###Training Hyperparameters", "\n", "    ", "parser", ".", "add_argument", "(", "'--device'", ",", "type", "=", "str", ",", "default", "=", "\"cuda:0\"", ",", "help", "=", "\"GPU/CPU devices\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"random seed\"", ")", "\n", "parser", ".", "add_argument", "(", "'--digit2zero'", ",", "action", "=", "\"store_true\"", ",", "default", "=", "True", ",", "\n", "help", "=", "\"convert the number to 0, make it true is better\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "type", "=", "str", ",", "default", "=", "\"eng_r0.5p0.9\"", ")", "\n", "parser", ".", "add_argument", "(", "'--embedding_file'", ",", "type", "=", "str", ",", "default", "=", "\"./data/glove.6B.50d.txt\"", ",", "\n", "help", "=", "\"we will be using random embeddings if file do not exist\"", ")", "\n", "parser", ".", "add_argument", "(", "'--embedding_dim'", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "parser", ".", "add_argument", "(", "'--optimizer'", ",", "type", "=", "str", ",", "default", "=", "\"sgd\"", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "##only for sgd now", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--l2'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_decay'", ",", "type", "=", "float", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "\"default batch size is 10 (works well)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_epochs'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "help", "=", "\"Usually we set to 10.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--train_num'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"-1 means all the data\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_num'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"-1 means all the data\"", ")", "\n", "parser", ".", "add_argument", "(", "'--test_num'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"-1 means all the data\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_outer_iterations'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "\"Number of outer iterations for cross validation\"", ")", "\n", "\n", "##model hyperparameter", "\n", "parser", ".", "add_argument", "(", "'--model_folder'", ",", "type", "=", "str", ",", "default", "=", "\"model_eng_local\"", ",", "help", "=", "\"The name to save the model files\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--res_folder'", ",", "type", "=", "str", ",", "default", "=", "\"results_eng_local\"", ",", "help", "=", "\"The name to save the res files\"", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden_dim'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "\"hidden size of the LSTM\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "\"dropout for embedding\"", ")", "\n", "parser", ".", "add_argument", "(", "'--use_char_rnn'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "choices", "=", "[", "0", ",", "1", "]", ",", "help", "=", "\"use character-level lstm, 0 or 1\"", ")", "\n", "parser", ".", "add_argument", "(", "'--context_emb'", ",", "type", "=", "str", ",", "default", "=", "\"none\"", ",", "choices", "=", "[", "\"none\"", ",", "\"elmo\"", "]", ",", "\n", "help", "=", "\"contextual word embedding\"", ")", "\n", "parser", ".", "add_argument", "(", "'--neg_noise_rate'", ",", "default", "=", "0.09", ",", "type", "=", "float", ",", "help", "=", "\"The estimated noise rate of negatives in the first iteration, -1.0 means golden noise rate\"", ")", "\n", "parser", ".", "add_argument", "(", "'--pos_noise_rate'", ",", "default", "=", "0.14", ",", "type", "=", "float", ",", "help", "=", "\"The estimated noise rate of positives in the first iteration, -1.0 means golden noise rate\"", ")", "\n", "parser", ".", "add_argument", "(", "'--warm_up_num'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"The number of epochs during which the estimated noise rates are set as 0\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_gradual_neg'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "help", "=", "\"hyper-parameter K for negatives\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_gradual_pos'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "help", "=", "\"hyper-parameter K for positives\"", ")", "\n", "parser", ".", "add_argument", "(", "'--is_constrain'", ",", "default", "=", "True", ",", "type", "=", "bool", ",", "help", "=", "\"Whether use constrained partial CRF or vanilla partial CRF\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "for", "k", "in", "args", ".", "__dict__", ":", "\n", "        ", "print", "(", "k", "+", "\": \"", "+", "str", "(", "args", ".", "__dict__", "[", "k", "]", ")", ")", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_local.gen_forget_rate": [[74, 88], ["numpy.linspace", "numpy.linspace", "numpy.ones", "numpy.ones"], "function", ["None"], ["", "def", "gen_forget_rate", "(", "num_epochs", ",", "neg_noise_rate", "=", "0.0", ",", "pos_noise_rate", "=", "0.0", ",", "num_gradual_neg", "=", "10", ",", "num_gradual_pos", "=", "10", ")", ":", "\n", "\n", "    ", "overlap", "=", "[", "0.0", "]", "*", "num_epochs", "\n", "\n", "\n", "forget_rate_neg", "=", "neg_noise_rate", "\n", "rate_schedule_neg", "=", "np", ".", "ones", "(", "num_epochs", ")", "*", "forget_rate_neg", "\n", "rate_schedule_neg", "[", ":", "num_gradual_neg", "]", "=", "np", ".", "linspace", "(", "0", ",", "forget_rate_neg", ",", "num_gradual_neg", ")", "\n", "\n", "forget_rate_pos", "=", "pos_noise_rate", "\n", "rate_schedule_pos", "=", "np", ".", "ones", "(", "num_epochs", ")", "*", "forget_rate_pos", "\n", "rate_schedule_pos", "[", ":", "num_gradual_pos", "]", "=", "np", ".", "linspace", "(", "0", ",", "forget_rate_pos", ",", "num_gradual_pos", ")", "\n", "\n", "return", "rate_schedule_neg", ",", "rate_schedule_pos", "\n", "", "def", "gen_forget_rate_warmup", "(", "num_epochs", ",", "neg_noise_rate", ",", "pos_noise_rate", ",", "warm_up_num", ",", "num_gradual_neg", ",", "num_gradual_pos", ")", ":", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_local.gen_forget_rate_warmup": [[88, 104], ["numpy.linspace", "numpy.linspace", "numpy.ones", "list", "numpy.ones", "list"], "function", ["None"], ["", "def", "gen_forget_rate_warmup", "(", "num_epochs", ",", "neg_noise_rate", ",", "pos_noise_rate", ",", "warm_up_num", ",", "num_gradual_neg", ",", "num_gradual_pos", ")", ":", "\n", "\n", "    ", "warm_up", "=", "[", "0.0", "]", "*", "warm_up_num", "\n", "\n", "\n", "forget_rate_neg", "=", "neg_noise_rate", "\n", "rate_schedule_neg", "=", "np", ".", "ones", "(", "num_epochs", "-", "warm_up_num", ")", "*", "forget_rate_neg", "\n", "rate_schedule_neg", "[", ":", "num_gradual_neg", "]", "=", "np", ".", "linspace", "(", "0", ",", "forget_rate_neg", ",", "num_gradual_neg", ")", "\n", "rate_schedule_neg", "=", "warm_up", "+", "list", "(", "rate_schedule_neg", ")", "\n", "\n", "forget_rate_pos", "=", "pos_noise_rate", "\n", "rate_schedule_pos", "=", "np", ".", "ones", "(", "num_epochs", "-", "warm_up_num", ")", "*", "forget_rate_pos", "\n", "rate_schedule_pos", "[", ":", "num_gradual_pos", "]", "=", "np", ".", "linspace", "(", "0", ",", "forget_rate_pos", ",", "num_gradual_pos", ")", "\n", "rate_schedule_pos", "=", "warm_up", "+", "list", "(", "rate_schedule_pos", ")", "\n", "\n", "return", "rate_schedule_neg", ",", "rate_schedule_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_local.ratio_estimation": [[106, 130], ["zip", "float", "float", "float", "float"], "function", ["None"], ["", "def", "ratio_estimation", "(", "config", ",", "insts", ")", ":", "\n", "\n", "    ", "insts", "=", "insts", "[", "0", "]", "+", "insts", "[", "1", "]", "\n", "neg_total", "=", "0", "\n", "pos_total", "=", "0", "\n", "neg_noise", "=", "0", "\n", "pos_noise", "=", "0", "\n", "O_index", "=", "config", ".", "label2idx", "[", "'O'", "]", "\n", "for", "inst", "in", "insts", ":", "\n", "\n", "        ", "for", "n1", ",", "n2", "in", "zip", "(", "inst", ".", "output_ids", ",", "inst", ".", "gold_output_ids", ")", ":", "\n", "            ", "if", "(", "n1", "==", "O_index", ")", ":", "\n", "                ", "neg_total", "+=", "1", "\n", "if", "(", "n1", "!=", "n2", ")", ":", "\n", "                    ", "neg_noise", "+=", "1", "\n", "", "", "else", ":", "\n", "                ", "pos_total", "+=", "1", "\n", "if", "(", "n1", "!=", "n2", ")", ":", "\n", "\n", "                    ", "pos_noise", "+=", "1", "\n", "", "", "", "", "neg_noise_rate", "=", "float", "(", "neg_noise", ")", "/", "(", "float", "(", "neg_total", ")", "+", "1e-8", ")", "\n", "pos_noise_rate", "=", "float", "(", "pos_noise", ")", "/", "(", "float", "(", "pos_total", ")", "+", "1e-8", ")", "\n", "\n", "return", "neg_noise_rate", ",", "pos_noise_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_local.train_model": [[132, 240], ["sum", "print", "config.batching_list_instances", "config.batching_list_instances", "os.path.exists", "print", "range", "FileExistsError", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "print", "confidence_estimation_local.ratio_estimation", "print", "print", "enumerate", "print", "enumerate", "print", "print", "list", "config.batching_list_instances", "confidence_estimation_local.ratio_estimation", "numpy.zeros", "numpy.zeros", "confidence_estimation_local.train_one", "print", "model.neuralcrf_small_loss_constrain_local.NNCRF_sl.load_state_dict", "model.neuralcrf_small_loss_constrain_local.NNCRF_sl.eval", "confidence_estimation_local.evaluate_model", "config.write_results", "len", "random.shuffle", "math.ceil", "config.batching_list_instances", "confidence_estimation_local.gen_forget_rate", "confidence_estimation_local.gen_forget_rate_warmup", "print", "model_names.append", "confidence_estimation_local.train_one", "model.neuralcrf_small_loss_constrain_local.NNCRF_sl", "model.neuralcrf_small_loss_constrain_local.NNCRF_sl.load_state_dict", "confidence_estimation_local.hard_constraint_predict", "itertools.chain.from_iterable", "tarfile.open", "tar.add", "torch.load", "str", "str", "torch.load", "len", "range", "os.path.basename", "str"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.batching_list_instances", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.batching_list_instances", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.ratio_estimation", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.batching_list_instances", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.ratio_estimation", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.train_one", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.evaluate_model", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.write_results", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.batching_list_instances", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.gen_forget_rate", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.gen_forget_rate_warmup", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.train_one", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.hard_constraint_predict"], ["", "def", "train_model", "(", "config", ":", "Config", ",", "train_insts", ":", "List", "[", "List", "[", "Instance", "]", "]", ",", "dev_insts", ":", "List", "[", "Instance", "]", ",", "test_insts", ":", "List", "[", "Instance", "]", ")", ":", "\n", "    ", "train_num", "=", "sum", "(", "[", "len", "(", "insts", ")", "for", "insts", "in", "train_insts", "]", ")", "\n", "print", "(", "\"[Training Info] number of instances: %d\"", "%", "(", "train_num", ")", ")", "\n", "\n", "dev_batches", "=", "batching_list_instances", "(", "config", ",", "dev_insts", ")", "\n", "test_batches", "=", "batching_list_instances", "(", "config", ",", "test_insts", ")", "\n", "\n", "best_dev", "=", "[", "-", "1", ",", "0", "]", "\n", "best_test", "=", "[", "-", "1", ",", "0", "]", "\n", "\n", "model_folder", "=", "config", ".", "model_folder", "\n", "res_folder", "=", "config", ".", "res_folder", "\n", "if", "os", ".", "path", ".", "exists", "(", "model_folder", ")", ":", "\n", "        ", "raise", "FileExistsError", "(", "f\"The folder {model_folder} exists. Please either delete it or create a new one \"", "\n", "f\"to avoid override.\"", ")", "\n", "\n", "", "print", "(", "\"[Training Info] The model will be saved to: %s.tar.gz\"", "%", "(", "model_folder", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_folder", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_folder", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "res_folder", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "res_folder", ")", "\n", "\n", "", "num_outer_iterations", "=", "config", ".", "num_outer_iterations", "\n", "\n", "SL_warmup", "=", "2", "\n", "\n", "for", "iter", "in", "range", "(", "num_outer_iterations", ")", ":", "\n", "        ", "print", "(", "f\"[Training Info] Running for {iter}th large iterations.\"", ")", "\n", "\n", "\n", "#change fold devision every two iter", "\n", "\n", "if", "(", "iter", ">", "0", "and", "iter", "//", "2", "!=", "(", "iter", "-", "1", ")", "//", "2", ")", ":", "\n", "            ", "train_insts", "=", "train_insts", "[", "0", "]", "+", "train_insts", "[", "1", "]", "\n", "random", ".", "shuffle", "(", "train_insts", ")", "\n", "num_insts_in_fold", "=", "math", ".", "ceil", "(", "len", "(", "train_insts", ")", "/", "config", ".", "num_folds", ")", "\n", "train_insts", "=", "[", "train_insts", "[", "i", "*", "num_insts_in_fold", ":", "(", "i", "+", "1", ")", "*", "num_insts_in_fold", "]", "for", "i", "in", "range", "(", "config", ".", "num_folds", ")", "]", "\n", "\n", "\n", "", "model_names", "=", "[", "]", "#model names for each fold", "\n", "train_batches", "=", "[", "batching_list_instances", "(", "config", ",", "insts", ")", "for", "insts", "in", "train_insts", "]", "\n", "\n", "\n", "\n", "neg_noise_rate_gold", ",", "pos_noise_rate_gold", "=", "ratio_estimation", "(", "config", ",", "train_insts", ")", "\n", "if", "(", "config", ".", "neg_noise_rate", ">=", "0", ")", ":", "\n", "            ", "neg_noise_rate", "=", "config", ".", "neg_noise_rate", "\n", "", "else", ":", "\n", "            ", "neg_noise_rate", "=", "neg_noise_rate_gold", "\n", "", "if", "(", "config", ".", "pos_noise_rate", ">=", "0", ")", ":", "\n", "            ", "pos_noise_rate", "=", "config", ".", "pos_noise_rate", "\n", "", "else", ":", "\n", "            ", "pos_noise_rate", "=", "pos_noise_rate_gold", "\n", "\n", "\n", "", "if", "(", "iter", ">", "0", ")", ":", "\n", "            ", "neg_noise_rate", "=", "0.005", "\n", "pos_noise_rate", "=", "0.15", "\n", "\n", "", "print", "(", "'negative noise rate: '", "+", "str", "(", "neg_noise_rate", ")", ")", "\n", "print", "(", "'positve noise rate: '", "+", "str", "(", "pos_noise_rate", ")", ")", "\n", "\n", "if", "(", "config", ".", "warm_up_num", "==", "0", ")", ":", "\n", "            ", "rate_schedule_neg", ",", "rate_schedule_pos", "=", "gen_forget_rate", "(", "config", ".", "num_epochs", ",", "neg_noise_rate", ",", "pos_noise_rate", ",", "config", ".", "num_gradual_neg", ",", "config", ".", "num_gradual_pos", ")", "\n", "", "else", ":", "\n", "            ", "rate_schedule_neg", ",", "rate_schedule_pos", "=", "gen_forget_rate_warmup", "(", "config", ".", "num_epochs", ",", "neg_noise_rate", ",", "pos_noise_rate", ",", "config", ".", "warm_up_num", ",", "config", ".", "num_gradual_neg", ",", "config", ".", "num_gradual_pos", ")", "\n", "\n", "", "for", "fold_id", ",", "folded_train_insts", "in", "enumerate", "(", "train_insts", ")", ":", "\n", "            ", "print", "(", "f\"[Training Info] Training fold {fold_id}.\"", ")", "\n", "model_name", "=", "model_folder", "+", "f\"/lstm_crf_{fold_id}.m\"", "\n", "model_names", ".", "append", "(", "model_name", ")", "\n", "train_one", "(", "config", "=", "config", ",", "train_batches", "=", "train_batches", "[", "fold_id", "]", ",", "\n", "dev_insts", "=", "dev_insts", ",", "dev_batches", "=", "dev_batches", ",", "model_name", "=", "model_name", ",", "rate_schedule_neg", "=", "rate_schedule_neg", ",", "rate_schedule_pos", "=", "rate_schedule_pos", ")", "\n", "\n", "# assign hard prediction to other folds", "\n", "", "print", "(", "\"\\n\\n[Data Info] Assigning labels for the HARD approach\"", ")", "\n", "\n", "for", "fold_id", ",", "folded_train_insts", "in", "enumerate", "(", "train_insts", ")", ":", "\n", "            ", "model", "=", "NNCRF_sl", "(", "config", ")", "\n", "model_name", "=", "model_names", "[", "fold_id", "]", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_name", ")", ")", "\n", "hard_constraint_predict", "(", "config", "=", "config", ",", "model", "=", "model", ",", "\n", "fold_batches", "=", "train_batches", "[", "1", "-", "fold_id", "]", ",", "\n", "folded_insts", "=", "train_insts", "[", "1", "-", "fold_id", "]", ")", "## set a new label id", "\n", "", "print", "(", "\"\\n\\n\"", ")", "\n", "\n", "print", "(", "\"[Training Info] Training the final model\"", ")", "\n", "all_train_insts", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "train_insts", ")", ")", "\n", "model_name", "=", "model_folder", "+", "\"/num_outer_iterations_final_lstm_crf.m\"", "\n", "config_name", "=", "model_folder", "+", "\"/num_outer_iterations_config.conf\"", "\n", "res_name", "=", "res_folder", "+", "\"/num_outer_iterations_lstm_crf.results\"", ".", "format", "(", ")", "\n", "all_train_batches", "=", "batching_list_instances", "(", "config", "=", "config", ",", "insts", "=", "all_train_insts", ")", "\n", "\n", "neg_noise_rate", ",", "pos_noise_rate", "=", "ratio_estimation", "(", "config", ",", "train_insts", ")", "\n", "\n", "rate_schedule_neg", "=", "np", ".", "zeros", "(", "config", ".", "num_epochs", ")", "\n", "rate_schedule_pos", "=", "np", ".", "zeros", "(", "config", ".", "num_epochs", ")", "\n", "\n", "model", "=", "train_one", "(", "config", "=", "config", ",", "train_batches", "=", "all_train_batches", ",", "dev_insts", "=", "dev_insts", ",", "dev_batches", "=", "dev_batches", ",", "\n", "model_name", "=", "model_name", ",", "config_name", "=", "config_name", ",", "test_insts", "=", "test_insts", ",", "test_batches", "=", "test_batches", ",", "result_filename", "=", "res_name", ",", "rate_schedule_neg", "=", "rate_schedule_neg", ",", "rate_schedule_pos", "=", "rate_schedule_pos", ")", "\n", "print", "(", "\"Archiving the best Model...\"", ")", "\n", "with", "tarfile", ".", "open", "(", "model_folder", "+", "\"/\"", "+", "str", "(", "num_outer_iterations", ")", "+", "model_folder", "+", "\".tar.gz\"", ",", "\"w:gz\"", ")", "as", "tar", ":", "\n", "            ", "tar", ".", "add", "(", "model_folder", ",", "arcname", "=", "os", ".", "path", ".", "basename", "(", "model_folder", ")", ")", "\n", "\n", "", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_name", ")", ")", "\n", "model", ".", "eval", "(", ")", "\n", "evaluate_model", "(", "config", ",", "model", ",", "test_batches", ",", "\"test\"", ",", "test_insts", ")", "\n", "write_results", "(", "res_name", ",", "test_insts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_local.hard_constraint_predict": [[242, 257], ["model.eval", "model.decode", "batch_max_ids.cpu().numpy.cpu().numpy", "batch[].cpu().numpy", "range", "len", "[].tolist", "batch_max_ids.cpu().numpy.cpu", "batch[].cpu"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.decode"], ["", "", "def", "hard_constraint_predict", "(", "config", ":", "Config", ",", "model", ":", "NNCRF_sl", ",", "fold_batches", ":", "List", "[", "Tuple", "]", ",", "folded_insts", ":", "List", "[", "Instance", "]", ",", "model_type", ":", "str", "=", "\"hard\"", ")", ":", "\n", "    ", "batch_id", "=", "0", "\n", "batch_size", "=", "config", ".", "batch_size", "\n", "model", ".", "eval", "(", ")", "\n", "for", "batch", "in", "fold_batches", ":", "\n", "        ", "one_batch_insts", "=", "folded_insts", "[", "batch_id", "*", "batch_size", ":", "(", "batch_id", "+", "1", ")", "*", "batch_size", "]", "\n", "batch_max_scores", ",", "batch_max_ids", "=", "model", ".", "decode", "(", "batch", ")", "\n", "batch_max_ids", "=", "batch_max_ids", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "word_seq_lens", "=", "batch", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "batch_max_ids", ")", ")", ":", "\n", "            ", "length", "=", "word_seq_lens", "[", "idx", "]", "\n", "prediction", "=", "batch_max_ids", "[", "idx", "]", "[", ":", "length", "]", ".", "tolist", "(", ")", "\n", "prediction", "=", "prediction", "[", ":", ":", "-", "1", "]", "#reverse list", "\n", "one_batch_insts", "[", "idx", "]", ".", "output_ids", "=", "prediction", "\n", "", "batch_id", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_local.train_one": [[259, 318], ["model.neuralcrf_small_loss_constrain_local.NNCRF_sl", "model.neuralcrf_small_loss_constrain_local.NNCRF_sl.train", "config.get_optimizer", "range", "time.time", "model.neuralcrf_small_loss_constrain_local.NNCRF_sl.zero_grad", "numpy.random.permutation", "time.time", "print", "print", "model.neuralcrf_small_loss_constrain_local.NNCRF_sl.eval", "confidence_estimation_local.evaluate_model", "model.neuralcrf_small_loss_constrain_local.NNCRF_sl.zero_grad", "print", "print", "config.optimizer.lower", "config.lr_decay", "len", "model.neuralcrf_small_loss_constrain_local.NNCRF_sl.train", "tuple", "model.neuralcrf_small_loss_constrain_local.NNCRF_sl.", "loss.item", "loss_neg.item", "loss_pos.item", "loss.backward", "config.lr_decay.step", "model.neuralcrf_small_loss_constrain_local.NNCRF_sl.zero_grad", "confidence_estimation_local.evaluate_model", "print", "torch.save", "str", "model.neuralcrf_small_loss_constrain_local.NNCRF_sl.state_dict", "open", "pickle.dump", "open.close", "config.write_results", "list", "range", "str", "len", "str"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.get_optimizer", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.evaluate_model", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.lr_decay", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.evaluate_model", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.write_results"], ["", "", "def", "train_one", "(", "config", ":", "Config", ",", "train_batches", ":", "List", "[", "Tuple", "]", ",", "dev_insts", ":", "List", "[", "Instance", "]", ",", "\n", "dev_batches", ":", "List", "[", "Tuple", "]", ",", "model_name", ":", "str", ",", "test_insts", ":", "List", "[", "Instance", "]", "=", "None", ",", "\n", "test_batches", ":", "List", "[", "Tuple", "]", "=", "None", ",", "config_name", ":", "str", "=", "None", ",", "result_filename", ":", "str", "=", "None", ",", "rate_schedule_neg", "=", "None", ",", "rate_schedule_pos", "=", "None", ")", "->", "NNCRF_sl", ":", "\n", "    ", "model", "=", "NNCRF_sl", "(", "config", ")", "\n", "model", ".", "train", "(", ")", "\n", "optimizer", "=", "get_optimizer", "(", "config", ",", "model", ")", "\n", "epoch", "=", "config", ".", "num_epochs", "\n", "best_dev_f1", "=", "-", "1", "\n", "saved_test_metrics", "=", "None", "\n", "for", "i", "in", "range", "(", "1", ",", "epoch", "+", "1", ")", ":", "\n", "        ", "ratios_sum", "=", "[", "0", "]", "*", "6", "\n", "forget_rate_neg", "=", "rate_schedule_neg", "[", "i", "-", "1", "]", "\n", "forget_rate_pos", "=", "rate_schedule_pos", "[", "i", "-", "1", "]", "\n", "epoch_loss", "=", "0", "\n", "epoch_loss_neg", "=", "0", "\n", "epoch_loss_pos", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "if", "config", ".", "optimizer", ".", "lower", "(", ")", "==", "\"sgd\"", ":", "\n", "            ", "optimizer", "=", "lr_decay", "(", "config", ",", "optimizer", ",", "i", ")", "\n", "", "is_constrain", "=", "config", ".", "is_constrain", "\n", "for", "index", "in", "np", ".", "random", ".", "permutation", "(", "len", "(", "train_batches", ")", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "tmp", "=", "tuple", "(", "list", "(", "train_batches", "[", "index", "]", ")", "+", "[", "forget_rate_neg", ",", "forget_rate_pos", ",", "is_constrain", "]", ")", "\n", "\n", "loss", ",", "ratios", ",", "loss_neg", ",", "loss_pos", "=", "model", "(", "*", "tmp", ")", "\n", "ratios_sum", "=", "[", "ratios_sum", "[", "i", "]", "+", "ratios", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "ratios", ")", ")", "]", "\n", "epoch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "epoch_loss_neg", "+=", "loss_neg", ".", "item", "(", ")", "\n", "epoch_loss_pos", "+=", "loss_pos", ".", "item", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "", "end_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Epoch %d: %.5f, Time is %.2fs\"", "%", "(", "i", ",", "epoch_loss", "/", "epoch", ",", "end_time", "-", "start_time", ")", ",", "flush", "=", "True", ")", "\n", "print", "(", "'avg neg NLL: '", "+", "str", "(", "epoch_loss_neg", "/", "epoch", ")", "+", "' avg pos NLL: '", "+", "str", "(", "epoch_loss_pos", "/", "epoch", ")", ")", "\n", "model", ".", "eval", "(", ")", "\n", "# metric is [precision, recall, f_score]", "\n", "dev_metrics", "=", "evaluate_model", "(", "config", ",", "model", ",", "dev_batches", ",", "\"dev\"", ",", "dev_insts", ")", "\n", "if", "test_insts", "is", "not", "None", ":", "\n", "            ", "test_metrics", "=", "evaluate_model", "(", "config", ",", "model", ",", "test_batches", ",", "\"test\"", ",", "test_insts", ")", "\n", "", "if", "dev_metrics", "[", "2", "]", ">", "best_dev_f1", ":", "\n", "            ", "print", "(", "\"saving the best model...\"", "+", "' epoch'", "+", "str", "(", "i", ")", ")", "\n", "best_dev_f1", "=", "dev_metrics", "[", "2", "]", "\n", "if", "test_insts", "is", "not", "None", ":", "\n", "                ", "saved_test_metrics", "=", "test_metrics", "\n", "", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "model_name", ")", "\n", "# # Save the corresponding config as well.", "\n", "if", "config_name", ":", "\n", "                ", "f", "=", "open", "(", "config_name", ",", "'wb'", ")", "\n", "pickle", ".", "dump", "(", "config", ",", "f", ")", "\n", "f", ".", "close", "(", ")", "\n", "", "if", "result_filename", ":", "\n", "                ", "write_results", "(", "result_filename", ",", "test_insts", ")", "\n", "", "", "model", ".", "zero_grad", "(", ")", "\n", "", "if", "test_insts", "is", "not", "None", ":", "\n", "        ", "print", "(", "f\"The best dev F1: {best_dev_f1}\"", ")", "\n", "print", "(", "f\"The corresponding test: {saved_test_metrics}\"", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_local.evaluate_model": [[322, 342], ["numpy.asarray", "print", "model.decode", "config.evaluate_batch_insts"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.decode", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.eval.evaluate_batch_insts"], ["", "def", "evaluate_model", "(", "config", ":", "Config", ",", "model", ":", "NNCRF_sl", ",", "batch_insts_ids", ",", "name", ":", "str", ",", "insts", ":", "List", "[", "Instance", "]", ")", ":", "\n", "## evaluation", "\n", "    ", "metrics", "=", "np", ".", "asarray", "(", "[", "0", ",", "0", ",", "0", "]", ",", "dtype", "=", "int", ")", "\n", "batch_id", "=", "0", "\n", "batch_size", "=", "config", ".", "batch_size", "\n", "for", "batch", "in", "batch_insts_ids", ":", "\n", "\n", "        ", "one_batch_insts", "=", "insts", "[", "batch_id", "*", "batch_size", ":", "(", "batch_id", "+", "1", ")", "*", "batch_size", "]", "\n", "batch_max_scores", ",", "batch_max_ids", "=", "model", ".", "decode", "(", "batch", ")", "\n", "metrics", "+=", "evaluate_batch_insts", "(", "batch_insts", "=", "one_batch_insts", ",", "\n", "batch_pred_ids", "=", "batch_max_ids", ",", "\n", "batch_gold_ids", "=", "batch", "[", "-", "2", "]", ",", "\n", "word_seq_lens", "=", "batch", "[", "1", "]", ",", "idx2label", "=", "config", ".", "idx2labels", ")", "\n", "batch_id", "+=", "1", "\n", "", "p", ",", "total_predict", ",", "total_entity", "=", "metrics", "[", "0", "]", ",", "metrics", "[", "1", "]", ",", "metrics", "[", "2", "]", "\n", "precision", "=", "p", "*", "1.0", "/", "total_predict", "*", "100", "if", "total_predict", "!=", "0", "else", "0", "\n", "recall", "=", "p", "*", "1.0", "/", "total_entity", "*", "100", "if", "total_entity", "!=", "0", "else", "0", "\n", "fscore", "=", "2.0", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "if", "precision", "!=", "0", "or", "recall", "!=", "0", "else", "0", "\n", "print", "(", "\"[%s set] Precision: %.2f, Recall: %.2f, F1: %.2f\"", "%", "(", "name", ",", "precision", ",", "recall", ",", "fscore", ")", ",", "flush", "=", "True", ")", "\n", "return", "[", "precision", ",", "recall", ",", "fscore", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_local.main": [[346, 388], ["argparse.ArgumentParser", "confidence_estimation_local.parse_arguments", "config.Config", "config.Reader", "config.Reader.read_txt", "config.Reader.read_txt", "config.Reader.read_txt", "config.Config.use_iobes", "config.Config.use_iobes_gold", "config.Config.build_label_idx", "config.Config.build_word_idx", "config.Config.build_emb_table", "config.Config.map_insts_ids", "print", "print", "config.Config.map_insts_ids", "config.Config.get_gold_label_ids", "random.shuffle", "math.ceil", "confidence_estimation_local.train_model", "print", "config.utils.load_elmo_vec", "config.utils.load_elmo_vec", "config.utils.load_elmo_vec", "enumerate", "str", "str", "len", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.parse_arguments", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.reader.Reader.read_txt", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.reader.Reader.read_txt", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.reader.Reader.read_txt", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.use_iobes", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.use_iobes_gold", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.build_label_idx", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.build_word_idx", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.build_emb_table", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.map_insts_ids", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.map_insts_ids", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.get_gold_label_ids", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.train_model", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.load_elmo_vec", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.load_elmo_vec", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.load_elmo_vec"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"LSTM CRF implementation\"", ")", "\n", "opt", "=", "parse_arguments", "(", "parser", ")", "\n", "conf", "=", "Config", "(", "opt", ")", "\n", "\n", "reader", "=", "Reader", "(", "conf", ".", "digit2zero", ")", "\n", "#set_seed(opt, conf.seed)", "\n", "\n", "trains", "=", "reader", ".", "read_txt", "(", "conf", ".", "train_file", ",", "conf", ".", "train_num", ")", "\n", "devs", "=", "reader", ".", "read_txt", "(", "conf", ".", "dev_file", ",", "conf", ".", "dev_num", ")", "\n", "tests", "=", "reader", ".", "read_txt", "(", "conf", ".", "test_file", ",", "conf", ".", "test_num", ")", "\n", "\n", "if", "conf", ".", "context_emb", "!=", "ContextEmb", ".", "none", ":", "\n", "        ", "print", "(", "'[Data Info] Loading the ELMo vectors for all datasets.'", ")", "\n", "conf", ".", "context_emb_size", "=", "load_elmo_vec", "(", "conf", ".", "train_file", "+", "\".\"", "+", "conf", ".", "context_emb", ".", "name", "+", "\".vec\"", ",", "trains", ")", "\n", "\n", "load_elmo_vec", "(", "conf", ".", "dev_file", "+", "\".\"", "+", "conf", ".", "context_emb", ".", "name", "+", "\".vec\"", ",", "devs", ")", "\n", "load_elmo_vec", "(", "conf", ".", "test_file", "+", "\".\"", "+", "conf", ".", "context_emb", ".", "name", "+", "\".vec\"", ",", "tests", ")", "\n", "\n", "", "conf", ".", "use_iobes", "(", "trains", "+", "devs", "+", "tests", ")", "\n", "conf", ".", "use_iobes_gold", "(", "trains", ")", "\n", "conf", ".", "build_label_idx", "(", "trains", "+", "devs", "+", "tests", ")", "\n", "\n", "conf", ".", "build_word_idx", "(", "trains", ",", "devs", ",", "tests", ")", "\n", "conf", ".", "build_emb_table", "(", ")", "\n", "conf", ".", "map_insts_ids", "(", "devs", "+", "tests", ")", "\n", "print", "(", "\"[Data Info] num chars: \"", "+", "str", "(", "conf", ".", "num_char", ")", ")", "\n", "print", "(", "\"[Data Info] num words: \"", "+", "str", "(", "len", "(", "conf", ".", "word2idx", ")", ")", ")", "\n", "\n", "conf", ".", "map_insts_ids", "(", "trains", ")", "\n", "conf", ".", "get_gold_label_ids", "(", "trains", ")", "\n", "random", ".", "shuffle", "(", "trains", ")", "\n", "\n", "for", "inst", "in", "trains", ":", "\n", "        ", "inst", ".", "is_prediction", "=", "[", "False", "]", "*", "len", "(", "inst", ".", "input", ")", "\n", "for", "pos", ",", "label", "in", "enumerate", "(", "inst", ".", "output", ")", ":", "\n", "            ", "if", "label", "==", "conf", ".", "O", ":", "\n", "                ", "inst", ".", "is_prediction", "[", "pos", "]", "=", "True", "\n", "\n", "", "", "", "num_insts_in_fold", "=", "math", ".", "ceil", "(", "len", "(", "trains", ")", "/", "conf", ".", "num_folds", ")", "\n", "trains", "=", "[", "trains", "[", "i", "*", "num_insts_in_fold", ":", "(", "i", "+", "1", ")", "*", "num_insts_in_fold", "]", "for", "i", "in", "range", "(", "conf", ".", "num_folds", ")", "]", "\n", "train_model", "(", "config", "=", "conf", ",", "train_insts", "=", "trains", ",", "dev_insts", "=", "devs", ",", "test_insts", "=", "tests", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.InputExample.__init__": [[8, 23], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "label", "=", "None", ",", "gold_label", "=", "None", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n        Args:\n            guid: Unique id for the example.\n            text_a: string. The untokenized text of the first sequence. For single\n            sequence tasks, only this sequence must be specified.\n            text_b: (Optional) string. The untokenized text of the second sequence.\n            Only must be specified for sequence pair tasks.\n            label: (Optional) string. The label of the example. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "label", "=", "label", "\n", "self", ".", "gold_label", "=", "gold_label", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.InputFeatures.__init__": [[28, 37], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", ",", "gold_label_ids", ",", "gather_ids", ",", "gather_masks", ",", "annotation_mask", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "label_ids", "=", "label_ids", "\n", "self", ".", "gold_label_ids", "=", "gold_label_ids", "\n", "self", ".", "gather_ids", "=", "gather_ids", "\n", "self", ".", "gather_masks", "=", "gather_masks", "\n", "self", ".", "annotation_mask", "=", "annotation_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.DataProcessor.__init__": [[43, 45], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "logger", ")", ":", "\n", "        ", "self", ".", "logger", "=", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.DataProcessor.get_train_examples": [[46, 49], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.DataProcessor.get_dev_examples": [[50, 53], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.DataProcessor.get_labels": [[54, 57], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"Gets the list of labels for this data set.\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.DataProcessor._read": [[58, 66], ["open", "lines.append", "line.strip"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_read", "(", "cls", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "                ", "lines", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.Processor.__init__": [[71, 75], ["list", "utils_ner.Processor.labels.append"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "logger", ")", ":", "\n", "        ", "self", ".", "logger", "=", "logger", "\n", "self", ".", "labels", "=", "list", "(", ")", "\n", "self", ".", "labels", ".", "append", "(", "\"O\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.Processor.get_train_examples": [[76, 81], ["utils_ner.Processor.logger.info", "utils_ner.Processor._create_examples", "utils_ner.Processor._read"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.Processor._create_examples", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.DataProcessor._read"], ["", "def", "get_train_examples", "(", "self", ",", "input_file", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "self", ".", "logger", ".", "info", "(", "\"LOOKING AT {}\"", ".", "format", "(", "input_file", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read", "(", "input_file", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.Processor.get_dev_examples": [[82, 87], ["utils_ner.Processor.logger.info", "utils_ner.Processor._create_examples", "utils_ner.Processor._read"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.Processor._create_examples", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.DataProcessor._read"], ["", "def", "get_dev_examples", "(", "self", ",", "input_file", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "self", ".", "logger", ".", "info", "(", "\"LOOKING AT {}\"", ".", "format", "(", "input_file", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "\n", "self", ".", "_read", "(", "input_file", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.Processor.get_labels": [[88, 91], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.Processor._create_examples_ori": [[92, 116], ["enumerate", "len", "examples.append", "examples.append", "line.split", "tokens.append", "labels.append", "utils_ner.InputExample", "utils_ner.InputExample", "utils_ner.Processor.labels.append", "len", "len"], "methods", ["None"], ["", "def", "_create_examples_ori", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "\n", "tokens", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "not", "line", ":", "\n", "                ", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "len", "(", "examples", ")", ",", "text_a", "=", "tokens", ",", "text_b", "=", "None", ",", "label", "=", "labels", ")", ")", "\n", "tokens", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "", "else", ":", "\n", "                ", "sp", "=", "line", ".", "split", "(", "' '", ")", "\n", "tokens", ".", "append", "(", "sp", "[", "0", "]", ")", "\n", "label", "=", "sp", "[", "-", "1", "]", "\n", "labels", ".", "append", "(", "label", ")", "\n", "if", "label", "not", "in", "self", ".", "labels", ":", "\n", "                    ", "self", ".", "labels", ".", "append", "(", "label", ")", "\n", "\n", "", "", "", "if", "len", "(", "tokens", ")", ">", "0", ":", "\n", "            ", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "len", "(", "examples", ")", ",", "text_a", "=", "tokens", ",", "text_b", "=", "None", ",", "label", "=", "labels", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.Processor._create_examples": [[118, 146], ["enumerate", "len", "examples.append", "examples.append", "line.split", "tokens.append", "labels.append", "utils_ner.InputExample", "utils_ner.InputExample", "len", "gold_labels.append", "utils_ner.Processor.labels.append", "len", "len"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "\n", "tokens", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "gold_labels", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "not", "line", ":", "\n", "                ", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "len", "(", "examples", ")", ",", "text_a", "=", "tokens", ",", "label", "=", "labels", ",", "gold_label", "=", "gold_labels", ")", ")", "\n", "tokens", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "gold_labels", "=", "[", "]", "\n", "", "else", ":", "\n", "                ", "sp", "=", "line", ".", "split", "(", "' '", ")", "\n", "tokens", ".", "append", "(", "sp", "[", "0", "]", ")", "\n", "label", "=", "sp", "[", "1", "]", "\n", "if", "(", "len", "(", "sp", ")", ">", "2", ")", ":", "\n", "                    ", "gold_labels", ".", "append", "(", "sp", "[", "2", "]", ")", "\n", "", "labels", ".", "append", "(", "label", ")", "\n", "if", "label", "not", "in", "self", ".", "labels", ":", "\n", "                    ", "self", ".", "labels", ".", "append", "(", "label", ")", "\n", "\n", "", "", "", "if", "len", "(", "tokens", ")", ">", "0", ":", "\n", "            ", "examples", ".", "append", "(", "\n", "InputExample", "(", "guid", "=", "len", "(", "examples", ")", ",", "text_a", "=", "tokens", ",", "label", "=", "labels", ",", "gold_label", "=", "gold_labels", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.Processor.BIO2BIOES": [[147, 166], ["range", "len", "curr_entity.startswith", "curr_entity.startswith", "len", "curr_entity.startswith", "curr_entity.startswith", "next_entity.startswith", "next_entity.startswith", "next_entity.startswith", "next_entity.startswith"], "methods", ["None"], ["", "def", "BIO2BIOES", "(", "self", ",", "output", ")", ":", "\n", "        ", "for", "pos", "in", "range", "(", "len", "(", "output", ")", ")", ":", "\n", "\n", "            ", "curr_entity", "=", "output", "[", "pos", "]", "\n", "if", "pos", "==", "len", "(", "output", ")", "-", "1", ":", "\n", "                ", "if", "curr_entity", ".", "startswith", "(", "'B'", ")", ":", "\n", "                    ", "output", "[", "pos", "]", "=", "'S'", "+", "curr_entity", "[", "1", ":", "]", "\n", "", "elif", "curr_entity", ".", "startswith", "(", "'I'", ")", ":", "\n", "                    ", "output", "[", "pos", "]", "=", "'E'", "+", "curr_entity", "[", "1", ":", "]", "\n", "", "", "else", ":", "\n", "                ", "next_entity", "=", "output", "[", "pos", "+", "1", "]", "\n", "if", "curr_entity", ".", "startswith", "(", "'B'", ")", ":", "\n", "                    ", "if", "next_entity", ".", "startswith", "(", "'O'", ")", "or", "next_entity", ".", "startswith", "(", "'B'", ")", ":", "\n", "                        ", "output", "[", "pos", "]", "=", "'S'", "+", "curr_entity", "[", "1", ":", "]", "\n", "", "", "elif", "curr_entity", ".", "startswith", "(", "'I'", ")", ":", "\n", "                    ", "if", "next_entity", ".", "startswith", "(", "'O'", ")", "or", "next_entity", ".", "startswith", "(", "'B'", ")", ":", "\n", "                        ", "output", "[", "pos", "]", "=", "'E'", "+", "curr_entity", "[", "1", ":", "]", "\n", "\n", "", "", "", "", "return", "output", "\n", "", "def", "convert_examples_to_features", "(", "self", ",", "examples", ",", "label_list", ",", "max_seq_length", ",", "tokenizer", ",", "is_train", ")", ":", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.Processor.convert_examples_to_features": [[166, 254], ["enumerate", "tokenizer.tokenize", "utils_ner.Processor.BIO2BIOES", "utils_ner.Processor.BIO2BIOES", "list", "enumerate", "torch.ones", "tokenizer.convert_tokens_to_ids", "features.append", "enumerate", "len", "print", "torch.zeros", "enumerate", "len", "len", "len", "len", "len", "len", "len", "len", "utils_ner.Processor.logger.info", "utils_ner.Processor.logger.info", "utils_ner.Processor.logger.info", "utils_ner.Processor.logger.info", "utils_ner.Processor.logger.info", "utils_ner.Processor.logger.info", "utils_ner.Processor.logger.info", "utils_ner.Processor.logger.info", "utils_ner.Processor.logger.info", "utils_ner.Processor.logger.info", "utils_ner.InputFeatures", "list.append", "len", "len", "len", "len", "len", "token.startswith", "len", "len", "str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.Processor.BIO2BIOES", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.Processor.BIO2BIOES"], ["", "def", "convert_examples_to_features", "(", "self", ",", "examples", ",", "label_list", ",", "max_seq_length", ",", "tokenizer", ",", "is_train", ")", ":", "\n", "        ", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "features", "=", "[", "]", "\n", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "\n", "            ", "tokens", "=", "tokenizer", ".", "tokenize", "(", "' '", ".", "join", "(", "example", ".", "text_a", ")", ")", "\n", "\n", "if", "(", "len", "(", "tokens", ")", ">", "max_seq_length", ")", ":", "\n", "                ", "print", "(", "\"remove \"", "+", "' '", ".", "join", "(", "example", ".", "text_a", ")", ")", "\n", "continue", "\n", "\n", "", "labels", "=", "self", ".", "BIO2BIOES", "(", "example", ".", "label", ")", "\n", "gold_labels", "=", "self", ".", "BIO2BIOES", "(", "example", ".", "gold_label", ")", "\n", "gather_ids", "=", "list", "(", ")", "\n", "\n", "for", "(", "idx", ",", "token", ")", "in", "enumerate", "(", "tokens", ")", ":", "\n", "                ", "if", "(", "not", "token", ".", "startswith", "(", "\"##\"", ")", "and", "idx", "<", "max_seq_length", "-", "2", ")", ":", "\n", "                    ", "gather_ids", ".", "append", "(", "idx", "+", "1", ")", "\n", "", "", "annotation_mask", "=", "torch", ".", "ones", "(", "(", "max_seq_length", ",", "len", "(", "label_list", ")", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "(", "is_train", ")", ":", "\n", "                ", "annotation_mask", "=", "torch", ".", "zeros", "(", "(", "max_seq_length", ",", "len", "(", "label_list", ")", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "for", "pos", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "                    ", "if", "(", "label", "==", "'O'", ")", ":", "\n", "\n", "                        ", "annotation_mask", "[", "pos", ",", ":", "]", "=", "1", "\n", "annotation_mask", "[", "pos", ",", "label_map", "[", "\"<START>\"", "]", "]", "=", "0", "\n", "annotation_mask", "[", "pos", ",", "label_map", "[", "\"<STOP>\"", "]", "]", "=", "0", "\n", "", "else", ":", "\n", "                        ", "annotation_mask", "[", "pos", ",", "label_map", "[", "label", "]", "]", "=", "1", "\n", "", "", "annotation_mask", "[", "len", "(", "labels", ")", ":", ",", ":", "]", "=", "1", "\n", "\n", "# Account for [CLS] and [SEP] with \"- 2\"", "\n", "", "if", "len", "(", "tokens", ")", ">", "max_seq_length", "-", "2", ":", "\n", "                ", "tokens", "=", "tokens", "[", ":", "max_seq_length", "-", "2", "]", "\n", "\n", "", "tokens", "=", "[", "\"[CLS]\"", "]", "+", "tokens", "+", "[", "\"[SEP]\"", "]", "\n", "label_ids", "=", "[", "label_map", "[", "label", "]", "for", "label", "in", "labels", "]", "\n", "gold_label_ids", "=", "[", "label_map", "[", "label", "]", "for", "label", "in", "gold_labels", "]", "\n", "segment_ids", "=", "[", "0", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "input_mask", "=", "[", "1", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding", "=", "[", "0", "]", "*", "(", "max_seq_length", "-", "len", "(", "input_ids", ")", ")", "\n", "input_ids", "+=", "padding", "\n", "input_mask", "+=", "padding", "\n", "segment_ids", "+=", "padding", "\n", "\n", "\n", "label_padding", "=", "[", "label_map", "[", "\"<PAD>\"", "]", "]", "*", "(", "max_seq_length", "-", "len", "(", "label_ids", ")", ")", "\n", "label_ids", "+=", "label_padding", "\n", "gold_label_ids", "+=", "label_padding", "\n", "\n", "gather_padding", "=", "[", "0", "]", "*", "(", "max_seq_length", "-", "len", "(", "gather_ids", ")", ")", "\n", "gather_masks", "=", "[", "1", "]", "*", "len", "(", "gather_ids", ")", "+", "gather_padding", "\n", "gather_ids", "+=", "gather_padding", "\n", "\n", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "gather_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "gather_masks", ")", "==", "max_seq_length", "\n", "\n", "if", "ex_index", "<", "2", ":", "\n", "                ", "self", ".", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "\n", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"label_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "label_ids", "]", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"gold_label_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "gold_label_ids", "]", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"gather_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "gather_ids", "]", ")", ")", "\n", "self", ".", "logger", ".", "info", "(", "\n", "\"gather_masks: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "gather_masks", "]", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "input_mask", "=", "input_mask", ",", "segment_ids", "=", "segment_ids", ",", "label_ids", "=", "label_ids", ",", "gold_label_ids", "=", "gold_label_ids", ",", "gather_ids", "=", "gather_ids", ",", "gather_masks", "=", "gather_masks", ",", "annotation_mask", "=", "annotation_mask", ")", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.Processor._truncate_seq_pair": [[255, 270], ["len", "len", "len", "len", "tokens_a.pop", "tokens_b.pop"], "methods", ["None"], ["", "def", "_truncate_seq_pair", "(", "self", ",", "tokens_a", ",", "tokens_b", ",", "max_length", ")", ":", "\n", "        ", "\"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"", "\n", "\n", "# This is a simple heuristic which will always truncate the longer sequence", "\n", "# one token at a time. This makes more sense than truncating an equal percent", "\n", "# of tokens from each, since if one sequence is very short then each token", "\n", "# that's truncated likely contains more information than a longer sequence.", "\n", "while", "True", ":", "\n", "            ", "total_length", "=", "len", "(", "tokens_a", ")", "+", "len", "(", "tokens_b", ")", "\n", "if", "total_length", "<=", "max_length", ":", "\n", "                ", "break", "\n", "", "if", "len", "(", "tokens_a", ")", ">", "len", "(", "tokens_b", ")", ":", "\n", "                ", "tokens_a", ".", "pop", "(", ")", "\n", "", "else", ":", "\n", "                ", "tokens_b", ".", "pop", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.get_result": [[272, 354], ["list", "list", "list", "enumerate", "output_str.append", "utils_ner.get_result.get_spans"], "function", ["None"], ["", "", "", "", "def", "get_result", "(", "results", ",", "step", "=", "None", ")", ":", "\n", "\n", "    ", "correct", ",", "precision_all", ",", "recall_all", "=", "0", ",", "0", ",", "0", "\n", "output_str", "=", "[", "]", "\n", "predict_spans", "=", "[", "]", "\n", "for", "item", "in", "results", ":", "\n", "\n", "        ", "tokens", "=", "item", "[", "\"token\"", "]", "\n", "golds", "=", "item", "[", "\"gold\"", "]", "\n", "preds", "=", "item", "[", "\"pred\"", "]", "\n", "new_words", "=", "list", "(", ")", "\n", "new_golds", "=", "list", "(", ")", "\n", "new_preds", "=", "list", "(", ")", "\n", "for", "idx", ",", "word", "in", "enumerate", "(", "tokens", ")", ":", "\n", "            ", "if", "(", "word", "==", "\"[CLS]\"", "or", "word", "==", "\"[SEP]\"", ")", ":", "\n", "                ", "continue", "\n", "", "if", "(", "not", "word", ".", "startswith", "(", "\"##\"", ")", ")", ":", "\n", "                ", "new_words", ".", "append", "(", "word", ")", "\n", "", "", "new_golds", "=", "golds", "\n", "new_preds", "=", "preds", "\n", "\n", "output_str", ".", "append", "(", "\"\\n\"", ".", "join", "(", "\n", "[", "word", "+", "\" \"", "+", "gold", "+", "\" \"", "+", "pred", "+", "\" \"", "for", "word", ",", "gold", ",", "pred", "in", "\n", "zip", "(", "new_words", ",", "new_golds", ",", "new_preds", ")", "]", ")", ")", "\n", "\n", "def", "get_spans_ori", "(", "labels", ")", ":", "\n", "            ", "spans", "=", "set", "(", ")", "\n", "i", "=", "0", "\n", "while", "True", ":", "\n", "                ", "if", "i", "==", "len", "(", "labels", ")", ":", "\n", "                    ", "break", "\n", "", "if", "labels", "[", "i", "]", ".", "startswith", "(", "'B'", ")", ":", "\n", "                    ", "label", "=", "labels", "[", "i", "]", "[", "2", ":", "]", "\n", "j", "=", "i", "\n", "while", "True", ":", "\n", "                        ", "j", "=", "j", "+", "1", "\n", "if", "j", "==", "len", "(", "labels", ")", "or", "labels", "[", "j", "]", ".", "startswith", "(", "'B'", ")", "or", "labels", "[", "j", "]", ".", "startswith", "(", "'O'", ")", ":", "\n", "                            ", "spans", ".", "add", "(", "str", "(", "i", ")", "+", "\"_\"", "+", "str", "(", "j", "-", "1", ")", "+", "\"_\"", "+", "label", ")", "\n", "break", "\n", "", "else", ":", "\n", "                            ", "if", "labels", "[", "j", "]", "[", "2", ":", "]", "==", "label", ":", "\n", "                                ", "continue", "\n", "", "else", ":", "\n", "                                ", "break", "\n", "", "", "", "i", "=", "j", "\n", "", "else", ":", "\n", "                    ", "i", "+=", "1", "\n", "", "", "return", "spans", "\n", "", "def", "get_spans", "(", "output", ")", ":", "\n", "            ", "output_spans", "=", "set", "(", ")", "\n", "start", "=", "-", "1", "\n", "for", "i", "in", "range", "(", "len", "(", "output", ")", ")", ":", "\n", "                ", "if", "output", "[", "i", "]", ".", "startswith", "(", "\"B-\"", ")", ":", "\n", "                    ", "start", "=", "i", "\n", "", "if", "output", "[", "i", "]", ".", "startswith", "(", "\"E-\"", ")", ":", "\n", "                    ", "end", "=", "i", "\n", "output_spans", ".", "add", "(", "str", "(", "start", ")", "+", "\"_\"", "+", "str", "(", "end", ")", "+", "\"_\"", "+", "output", "[", "i", "]", "[", "2", ":", "]", ")", "\n", "", "if", "output", "[", "i", "]", ".", "startswith", "(", "\"S-\"", ")", ":", "\n", "                    ", "output_spans", ".", "add", "(", "str", "(", "i", ")", "+", "\"_\"", "+", "str", "(", "i", ")", "+", "\"_\"", "+", "output", "[", "i", "]", "[", "2", ":", "]", ")", "\n", "", "", "return", "output_spans", "\n", "\n", "", "gold_set", "=", "get_spans", "(", "new_golds", ")", "\n", "predict_set", "=", "get_spans", "(", "new_preds", ")", "\n", "predict_spans", ".", "append", "(", "predict_set", ")", "\n", "correct_set", "=", "predict_set", ".", "intersection", "(", "gold_set", ")", "\n", "correct", "+=", "len", "(", "correct_set", ")", "\n", "precision_all", "+=", "len", "(", "predict_set", ")", "\n", "recall_all", "+=", "len", "(", "gold_set", ")", "\n", "\n", "", "precision", "=", "recall", "=", "0", "\n", "if", "precision_all", ">", "0", ":", "\n", "        ", "precision", "=", "correct", "/", "precision_all", "\n", "", "if", "recall_all", ">", "0", ":", "\n", "        ", "recall", "=", "correct", "/", "recall_all", "\n", "\n", "", "if", "precision", "==", "0", "or", "recall", "==", "0", ":", "\n", "        ", "F", "=", "0", "\n", "", "else", ":", "\n", "        ", "F", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "\n", "", "return", "precision", ",", "recall", ",", "F", ",", "output_str", ",", "predict_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.utils_ner.categoricalAccuracy": [[356, 403], ["predictions.view.size", "predictions.view.view", "gold_labels.view().long.view().long", "max_predictions_mask[].float.sum", "gold_labels.view().long.dim", "ValueError", "ValueError", "[].unsqueeze.eq().float", "predictions.view.eq", "max_predictions_mask[].float", "predictions.eq.sum", "max_predictions_mask.sum.float", "max_predictions_mask[].float.unsqueeze_", "mask.view().float", "mask.sum", "gold_labels.view().long.numel", "float", "float", "predictions.view.dim", "gold_labels.view().long.view", "[].unsqueeze", "predictions.view.max", "max_predictions.unsqueeze", "predictions.view.size", "predictions.view.topk", "[].unsqueeze.eq", "mask.view", "min", "gold_labels.view().long.unsqueeze", "predictions.view.max", "torch.arange().long", "torch.arange", "gold_labels.view().long.numel"], "function", ["None"], ["", "def", "categoricalAccuracy", "(", "predictions", ":", "torch", ".", "Tensor", ",", "\n", "gold_labels", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "tie_break", "=", "False", ",", "\n", "top_k", "=", "1", ")", ":", "\n", "    ", "total_count", "=", "0", "\n", "correct_count", "=", "0", "\n", "\n", "num_classes", "=", "predictions", ".", "size", "(", "-", "1", ")", "\n", "if", "gold_labels", ".", "dim", "(", ")", "!=", "predictions", ".", "dim", "(", ")", "-", "1", ":", "\n", "        ", "raise", "ValueError", "(", "\"gold_labels must have dimension == predictions.size() - 1 but \"", "\n", "\"found tensor of shape: {}\"", ".", "format", "(", "predictions", ".", "size", "(", ")", ")", ")", "\n", "", "if", "(", "gold_labels", ">=", "num_classes", ")", ".", "any", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"A gold label passed to Categorical Accuracy contains an id >= {}, \"", "\n", "\"the number of classes.\"", ".", "format", "(", "num_classes", ")", ")", "\n", "\n", "", "predictions", "=", "predictions", ".", "view", "(", "(", "-", "1", ",", "num_classes", ")", ")", "\n", "gold_labels", "=", "gold_labels", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", "\n", "if", "not", "tie_break", ":", "\n", "# Top K indexes of the predictions (or fewer, if there aren't K of them).", "\n", "# Special case topk == 1, because it's common and .max() is much faster than .topk().", "\n", "        ", "if", "top_k", "==", "1", ":", "\n", "            ", "top_k", "=", "predictions", ".", "max", "(", "-", "1", ")", "[", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "top_k", "=", "predictions", ".", "topk", "(", "min", "(", "top_k", ",", "predictions", ".", "shape", "[", "-", "1", "]", ")", ",", "-", "1", ")", "[", "1", "]", "\n", "\n", "# This is of shape (batch_size, ..., top_k).", "\n", "", "correct", "=", "top_k", ".", "eq", "(", "gold_labels", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "float", "(", ")", "\n", "", "else", ":", "\n", "# prediction is correct if gold label falls on any of the max scores. distribute score by tie_counts", "\n", "        ", "max_predictions", "=", "predictions", ".", "max", "(", "-", "1", ")", "[", "0", "]", "\n", "max_predictions_mask", "=", "predictions", ".", "eq", "(", "max_predictions", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "# max_predictions_mask is (rows X num_classes) and gold_labels is (batch_size)", "\n", "# ith entry in gold_labels points to index (0-num_classes) for ith row in max_predictions", "\n", "# For each row check if index pointed by gold_label is was 1 or not (among max scored classes)", "\n", "correct", "=", "max_predictions_mask", "[", "torch", ".", "arange", "(", "gold_labels", ".", "numel", "(", ")", ")", ".", "long", "(", ")", ",", "gold_labels", "]", ".", "float", "(", ")", "\n", "tie_counts", "=", "max_predictions_mask", ".", "sum", "(", "-", "1", ")", "\n", "correct", "/=", "tie_counts", ".", "float", "(", ")", "\n", "correct", ".", "unsqueeze_", "(", "-", "1", ")", "\n", "\n", "", "if", "mask", "is", "not", "None", ":", "\n", "        ", "correct", "*=", "mask", ".", "view", "(", "-", "1", ",", "1", ")", ".", "float", "(", ")", "\n", "total_count", "+=", "mask", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "        ", "total_count", "+=", "gold_labels", ".", "numel", "(", ")", "\n", "", "correct_count", "+=", "correct", ".", "sum", "(", ")", "\n", "return", "float", "(", "correct_count", ")", ",", "float", "(", "total_count", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.set_seed": [[22, 30], ["random.seed", "numpy.random.seed", "torch.manual_seed", "opt.device.startswith", "print", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.current_device"], "function", ["None"], ["def", "set_seed", "(", "opt", ",", "seed", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "opt", ".", "device", ".", "startswith", "(", "\"cuda\"", ")", ":", "\n", "        ", "print", "(", "\"using GPU...\"", ",", "torch", ".", "cuda", ".", "current_device", "(", ")", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.parse_arguments": [[32, 74], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.parse_args", "print", "str"], "function", ["None"], ["", "", "def", "parse_arguments", "(", "parser", ")", ":", "\n", "###Training Hyperparameters", "\n", "    ", "parser", ".", "add_argument", "(", "'--device'", ",", "type", "=", "str", ",", "default", "=", "\"cuda:1\"", ",", "help", "=", "\"GPU/CPU devices\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"random seed\"", ")", "\n", "parser", ".", "add_argument", "(", "'--digit2zero'", ",", "action", "=", "\"store_true\"", ",", "default", "=", "True", ",", "\n", "help", "=", "\"convert the number to 0, make it true is better\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "type", "=", "str", ",", "default", "=", "\"eng_r0.5p0.9\"", ")", "\n", "parser", ".", "add_argument", "(", "'--embedding_file'", ",", "type", "=", "str", ",", "default", "=", "\"./data/glove.6B.50d.txt\"", ",", "\n", "help", "=", "\"we will be using random embeddings if file do not exist\"", ")", "\n", "parser", ".", "add_argument", "(", "'--embedding_dim'", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "parser", ".", "add_argument", "(", "'--optimizer'", ",", "type", "=", "str", ",", "default", "=", "\"sgd\"", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "##only for sgd now", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "'--l2'", ",", "type", "=", "float", ",", "default", "=", "1e-8", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_decay'", ",", "type", "=", "float", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "\"default batch size is 10 (works well)\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_epochs'", ",", "type", "=", "int", ",", "default", "=", "30", ",", "help", "=", "\"Usually we set to 10.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--train_num'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"-1 means all the data\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dev_num'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"-1 means all the data\"", ")", "\n", "parser", ".", "add_argument", "(", "'--test_num'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"-1 means all the data\"", ")", "\n", "parser", ".", "add_argument", "(", "'--num_outer_iterations'", ",", "type", "=", "int", ",", "default", "=", "16", ",", "help", "=", "\"Number of outer iterations for cross validation\"", ")", "\n", "\n", "\n", "##model hyperparameter", "\n", "parser", ".", "add_argument", "(", "'--model_folder'", ",", "type", "=", "str", ",", "default", "=", "\"model_eng_global\"", ",", "help", "=", "\"The name to save the model files\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--res_folder'", ",", "type", "=", "str", ",", "default", "=", "\"results_eng_global\"", ",", "help", "=", "\"The name to save the res files\"", ")", "\n", "parser", ".", "add_argument", "(", "'--hidden_dim'", ",", "type", "=", "int", ",", "default", "=", "200", ",", "help", "=", "\"hidden size of the LSTM\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "\"dropout for embedding\"", ")", "\n", "parser", ".", "add_argument", "(", "'--use_char_rnn'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "choices", "=", "[", "0", ",", "1", "]", ",", "help", "=", "\"use character-level lstm, 0 or 1\"", ")", "\n", "parser", ".", "add_argument", "(", "'--context_emb'", ",", "type", "=", "str", ",", "default", "=", "\"none\"", ",", "choices", "=", "[", "\"elmo\"", ",", "\"elmo\"", "]", ",", "\n", "help", "=", "\"contextual word embedding\"", ")", "\n", "parser", ".", "add_argument", "(", "'--neg_noise_rate'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "\"The estimated noise rate of negatives in the first iteration, -1.0 means golden noise rate\"", ")", "\n", "parser", ".", "add_argument", "(", "'--pos_noise_rate'", ",", "default", "=", "0.13", ",", "type", "=", "float", ",", "help", "=", "\"The estimated noise rate of positives in the first iteration, -1.0 means golden noise rate\"", ")", "\n", "parser", ".", "add_argument", "(", "'--warm_up_num'", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--num_gradual_neg'", ",", "default", "=", "10", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--num_gradual_pos'", ",", "default", "=", "10", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--is_constrain'", ",", "default", "=", "True", ",", "type", "=", "bool", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "for", "k", "in", "args", ".", "__dict__", ":", "\n", "        ", "print", "(", "k", "+", "\": \"", "+", "str", "(", "args", ".", "__dict__", "[", "k", "]", ")", ")", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.gen_forget_rate": [[75, 86], ["numpy.linspace", "numpy.linspace", "numpy.ones", "numpy.ones"], "function", ["None"], ["", "def", "gen_forget_rate", "(", "num_epochs", ",", "neg_noise_rate", ",", "pos_noise_rate", ",", "num_gradual_neg", ",", "num_gradual_pos", ")", ":", "\n", "\n", "    ", "forget_rate_neg", "=", "neg_noise_rate", "\n", "rate_schedule_neg", "=", "np", ".", "ones", "(", "num_epochs", ")", "*", "forget_rate_neg", "\n", "rate_schedule_neg", "[", ":", "num_gradual_neg", "]", "=", "np", ".", "linspace", "(", "0", ",", "forget_rate_neg", ",", "num_gradual_neg", ")", "\n", "\n", "forget_rate_pos", "=", "pos_noise_rate", "\n", "rate_schedule_pos", "=", "np", ".", "ones", "(", "num_epochs", ")", "*", "forget_rate_pos", "\n", "rate_schedule_pos", "[", ":", "num_gradual_pos", "]", "=", "np", ".", "linspace", "(", "0", ",", "forget_rate_pos", ",", "num_gradual_pos", ")", "\n", "\n", "return", "rate_schedule_neg", ",", "rate_schedule_pos", "\n", "", "def", "gen_forget_rate_warmup", "(", "num_epochs", ",", "neg_noise_rate", ",", "pos_noise_rate", ",", "warm_up_num", ",", "num_gradual_neg", ",", "num_gradual_pos", ")", ":", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.gen_forget_rate_warmup": [[86, 102], ["numpy.linspace", "numpy.linspace", "numpy.ones", "list", "numpy.ones", "list"], "function", ["None"], ["", "def", "gen_forget_rate_warmup", "(", "num_epochs", ",", "neg_noise_rate", ",", "pos_noise_rate", ",", "warm_up_num", ",", "num_gradual_neg", ",", "num_gradual_pos", ")", ":", "\n", "\n", "    ", "warm_up", "=", "[", "0.0", "]", "*", "warm_up_num", "\n", "\n", "\n", "forget_rate_neg", "=", "neg_noise_rate", "\n", "rate_schedule_neg", "=", "np", ".", "ones", "(", "num_epochs", "-", "warm_up_num", ")", "*", "forget_rate_neg", "\n", "rate_schedule_neg", "[", ":", "num_gradual_neg", "]", "=", "np", ".", "linspace", "(", "0", ",", "forget_rate_neg", ",", "num_gradual_neg", ")", "\n", "rate_schedule_neg", "=", "warm_up", "+", "list", "(", "rate_schedule_neg", ")", "\n", "\n", "forget_rate_pos", "=", "pos_noise_rate", "\n", "rate_schedule_pos", "=", "np", ".", "ones", "(", "num_epochs", "-", "warm_up_num", ")", "*", "forget_rate_pos", "\n", "rate_schedule_pos", "[", ":", "num_gradual_pos", "]", "=", "np", ".", "linspace", "(", "0", ",", "forget_rate_pos", ",", "num_gradual_pos", ")", "\n", "rate_schedule_pos", "=", "warm_up", "+", "list", "(", "rate_schedule_pos", ")", "\n", "\n", "return", "rate_schedule_neg", ",", "rate_schedule_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.ratio_estimation": [[103, 127], ["zip", "float", "float", "float", "float"], "function", ["None"], ["", "def", "ratio_estimation", "(", "config", ",", "insts", ")", ":", "\n", "\n", "    ", "insts", "=", "insts", "[", "0", "]", "+", "insts", "[", "1", "]", "\n", "neg_total", "=", "0", "\n", "pos_total", "=", "0", "\n", "neg_noise", "=", "0", "\n", "pos_noise", "=", "0", "\n", "O_index", "=", "config", ".", "label2idx", "[", "'O'", "]", "\n", "for", "inst", "in", "insts", ":", "\n", "\n", "        ", "for", "n1", ",", "n2", "in", "zip", "(", "inst", ".", "output_ids", ",", "inst", ".", "gold_output_ids", ")", ":", "\n", "            ", "if", "(", "n1", "==", "O_index", ")", ":", "\n", "                ", "neg_total", "+=", "1", "\n", "if", "(", "n1", "!=", "n2", ")", ":", "\n", "                    ", "neg_noise", "+=", "1", "\n", "", "", "else", ":", "\n", "                ", "pos_total", "+=", "1", "\n", "if", "(", "n1", "!=", "n2", ")", ":", "\n", "\n", "                    ", "pos_noise", "+=", "1", "\n", "", "", "", "", "neg_noise_rate", "=", "float", "(", "neg_noise", ")", "/", "(", "float", "(", "neg_total", ")", "+", "1e-8", ")", "\n", "pos_noise_rate", "=", "float", "(", "pos_noise", ")", "/", "(", "float", "(", "pos_total", ")", "+", "1e-8", ")", "\n", "\n", "return", "neg_noise_rate", ",", "pos_noise_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.train_model": [[129, 237], ["sum", "print", "config.batching_list_instances", "config.batching_list_instances", "os.path.exists", "print", "range", "FileExistsError", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "print", "confidence_estimation_global.ratio_estimation", "print", "print", "enumerate", "print", "enumerate", "print", "print", "list", "config.batching_list_instances", "confidence_estimation_global.ratio_estimation", "numpy.zeros", "numpy.zeros", "confidence_estimation_global.train_one", "print", "model.neuralcrf_small_loss_constrain_global.NNCRF_sl.load_state_dict", "model.neuralcrf_small_loss_constrain_global.NNCRF_sl.eval", "confidence_estimation_global.evaluate_model", "config.write_results", "len", "random.shuffle", "math.ceil", "config.batching_list_instances", "confidence_estimation_global.gen_forget_rate", "confidence_estimation_global.gen_forget_rate_warmup", "print", "model_names.append", "confidence_estimation_global.train_one", "model.neuralcrf_small_loss_constrain_global.NNCRF_sl", "model.neuralcrf_small_loss_constrain_global.NNCRF_sl.load_state_dict", "confidence_estimation_global.hard_constraint_predict", "itertools.chain.from_iterable", "tarfile.open", "tar.add", "torch.load", "str", "str", "torch.load", "len", "range", "os.path.basename", "str"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.batching_list_instances", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.batching_list_instances", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.ratio_estimation", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.batching_list_instances", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.ratio_estimation", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.train_one", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.evaluate_model", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.write_results", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.batching_list_instances", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.gen_forget_rate", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.gen_forget_rate_warmup", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.train_one", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.hard_constraint_predict"], ["", "def", "train_model", "(", "config", ":", "Config", ",", "train_insts", ":", "List", "[", "List", "[", "Instance", "]", "]", ",", "dev_insts", ":", "List", "[", "Instance", "]", ",", "test_insts", ":", "List", "[", "Instance", "]", ")", ":", "\n", "    ", "train_num", "=", "sum", "(", "[", "len", "(", "insts", ")", "for", "insts", "in", "train_insts", "]", ")", "\n", "print", "(", "\"[Training Info] number of instances: %d\"", "%", "(", "train_num", ")", ")", "\n", "\n", "dev_batches", "=", "batching_list_instances", "(", "config", ",", "dev_insts", ")", "\n", "test_batches", "=", "batching_list_instances", "(", "config", ",", "test_insts", ")", "\n", "\n", "best_dev", "=", "[", "-", "1", ",", "0", "]", "\n", "best_test", "=", "[", "-", "1", ",", "0", "]", "\n", "\n", "model_folder", "=", "config", ".", "model_folder", "\n", "\n", "res_folder", "=", "config", ".", "res_folder", "\n", "if", "os", ".", "path", ".", "exists", "(", "model_folder", ")", ":", "\n", "        ", "raise", "FileExistsError", "(", "f\"The folder {model_folder} exists. Please either delete it or create a new one \"", "\n", "f\"to avoid override.\"", ")", "\n", "\n", "", "print", "(", "\"[Training Info] The model will be saved to: %s.tar.gz\"", "%", "(", "model_folder", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_folder", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "model_folder", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "res_folder", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "res_folder", ")", "\n", "\n", "", "num_outer_iterations", "=", "config", ".", "num_outer_iterations", "\n", "\n", "SL_warmup", "=", "2", "\n", "for", "iter", "in", "range", "(", "num_outer_iterations", ")", ":", "\n", "        ", "print", "(", "f\"[Training Info] Running for {iter}th large iterations.\"", ")", "\n", "\n", "\n", "#change fold devision each iter", "\n", "if", "(", "iter", ">", "0", "and", "iter", "//", "2", "!=", "(", "iter", "-", "1", ")", "//", "2", ")", ":", "\n", "            ", "train_insts", "=", "train_insts", "[", "0", "]", "+", "train_insts", "[", "1", "]", "\n", "random", ".", "shuffle", "(", "train_insts", ")", "\n", "num_insts_in_fold", "=", "math", ".", "ceil", "(", "len", "(", "train_insts", ")", "/", "config", ".", "num_folds", ")", "\n", "train_insts", "=", "[", "train_insts", "[", "i", "*", "num_insts_in_fold", ":", "(", "i", "+", "1", ")", "*", "num_insts_in_fold", "]", "for", "i", "in", "range", "(", "config", ".", "num_folds", ")", "]", "\n", "\n", "\n", "", "model_names", "=", "[", "]", "#model names for each fold", "\n", "train_batches", "=", "[", "batching_list_instances", "(", "config", ",", "insts", ")", "for", "insts", "in", "train_insts", "]", "\n", "\n", "\n", "\n", "neg_noise_rate_gold", ",", "pos_noise_rate_gold", "=", "ratio_estimation", "(", "config", ",", "train_insts", ")", "\n", "if", "(", "config", ".", "neg_noise_rate", ">=", "0", ")", ":", "\n", "            ", "neg_noise_rate", "=", "config", ".", "neg_noise_rate", "\n", "", "else", ":", "\n", "            ", "neg_noise_rate", "=", "neg_noise_rate_gold", "\n", "", "if", "(", "config", ".", "pos_noise_rate", ">=", "0", ")", ":", "\n", "            ", "pos_noise_rate", "=", "config", ".", "pos_noise_rate", "\n", "", "else", ":", "\n", "            ", "pos_noise_rate", "=", "pos_noise_rate_gold", "\n", "\n", "", "if", "(", "iter", ">", "0", ")", ":", "\n", "            ", "neg_noise_rate", "=", "0.005", "\n", "pos_noise_rate", "=", "0.15", "\n", "\n", "\n", "", "print", "(", "'negative noise rate: '", "+", "str", "(", "neg_noise_rate", ")", ")", "\n", "print", "(", "'positve noise rate: '", "+", "str", "(", "pos_noise_rate", ")", ")", "\n", "\n", "if", "(", "config", ".", "warm_up_num", "==", "0", ")", ":", "\n", "            ", "rate_schedule_neg", ",", "rate_schedule_pos", "=", "gen_forget_rate", "(", "config", ".", "num_epochs", ",", "neg_noise_rate", ",", "pos_noise_rate", ",", "config", ".", "num_gradual_neg", ",", "config", ".", "num_gradual_pos", ")", "\n", "", "else", ":", "\n", "            ", "rate_schedule_neg", ",", "rate_schedule_pos", "=", "gen_forget_rate_warmup", "(", "config", ".", "num_epochs", ",", "neg_noise_rate", ",", "pos_noise_rate", ",", "config", ".", "warm_up_num", ",", "config", ".", "num_gradual_neg", ",", "config", ".", "num_gradual_pos", ")", "\n", "\n", "\n", "", "for", "fold_id", ",", "folded_train_insts", "in", "enumerate", "(", "train_insts", ")", ":", "\n", "            ", "print", "(", "f\"[Training Info] Training fold {fold_id}.\"", ")", "\n", "model_name", "=", "model_folder", "+", "f\"/lstm_crf_{fold_id}.m\"", "\n", "model_names", ".", "append", "(", "model_name", ")", "\n", "train_one", "(", "config", "=", "config", ",", "train_batches", "=", "train_batches", "[", "fold_id", "]", ",", "\n", "dev_insts", "=", "dev_insts", ",", "dev_batches", "=", "dev_batches", ",", "model_name", "=", "model_name", ",", "rate_schedule_neg", "=", "rate_schedule_neg", ",", "rate_schedule_pos", "=", "rate_schedule_pos", ")", "\n", "\n", "# assign hard prediction to other folds", "\n", "", "print", "(", "\"\\n\\n[Data Info] Assigning labels for the HARD approach\"", ")", "\n", "\n", "for", "fold_id", ",", "folded_train_insts", "in", "enumerate", "(", "train_insts", ")", ":", "\n", "            ", "model", "=", "NNCRF_sl", "(", "config", ")", "\n", "model_name", "=", "model_names", "[", "fold_id", "]", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_name", ")", ")", "\n", "hard_constraint_predict", "(", "config", "=", "config", ",", "model", "=", "model", ",", "\n", "fold_batches", "=", "train_batches", "[", "1", "-", "fold_id", "]", ",", "\n", "folded_insts", "=", "train_insts", "[", "1", "-", "fold_id", "]", ")", "## set a new label id", "\n", "", "print", "(", "\"\\n\\n\"", ")", "\n", "\n", "print", "(", "\"[Training Info] Training the final model\"", ")", "\n", "all_train_insts", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "train_insts", ")", ")", "\n", "model_name", "=", "model_folder", "+", "\"/num_outer_iterations_final_lstm_crf.m\"", "\n", "config_name", "=", "model_folder", "+", "\"/num_outer_iterations_config.conf\"", "\n", "res_name", "=", "res_folder", "+", "\"/num_outer_iterations_lstm_crf.results\"", ".", "format", "(", ")", "\n", "all_train_batches", "=", "batching_list_instances", "(", "config", "=", "config", ",", "insts", "=", "all_train_insts", ")", "\n", "\n", "neg_noise_rate", ",", "pos_noise_rate", "=", "ratio_estimation", "(", "config", ",", "train_insts", ")", "\n", "\n", "rate_schedule_neg", "=", "np", ".", "zeros", "(", "config", ".", "num_epochs", ")", "\n", "rate_schedule_pos", "=", "np", ".", "zeros", "(", "config", ".", "num_epochs", ")", "\n", "\n", "model", "=", "train_one", "(", "config", "=", "config", ",", "train_batches", "=", "all_train_batches", ",", "dev_insts", "=", "dev_insts", ",", "dev_batches", "=", "dev_batches", ",", "\n", "model_name", "=", "model_name", ",", "config_name", "=", "config_name", ",", "test_insts", "=", "test_insts", ",", "test_batches", "=", "test_batches", ",", "result_filename", "=", "res_name", ",", "rate_schedule_neg", "=", "rate_schedule_neg", ",", "rate_schedule_pos", "=", "rate_schedule_pos", ")", "\n", "print", "(", "\"Archiving the best Model...\"", ")", "\n", "with", "tarfile", ".", "open", "(", "model_folder", "+", "\"/\"", "+", "str", "(", "num_outer_iterations", ")", "+", "model_folder", "+", "\".tar.gz\"", ",", "\"w:gz\"", ")", "as", "tar", ":", "\n", "            ", "tar", ".", "add", "(", "model_folder", ",", "arcname", "=", "os", ".", "path", ".", "basename", "(", "model_folder", ")", ")", "\n", "\n", "", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_name", ")", ")", "\n", "model", ".", "eval", "(", ")", "\n", "evaluate_model", "(", "config", ",", "model", ",", "test_batches", ",", "\"test\"", ",", "test_insts", ")", "\n", "write_results", "(", "res_name", ",", "test_insts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.hard_constraint_predict": [[239, 254], ["model.eval", "model.decode", "batch_max_ids.cpu().numpy.cpu().numpy", "batch[].cpu().numpy", "range", "len", "[].tolist", "batch_max_ids.cpu().numpy.cpu", "batch[].cpu"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.decode"], ["", "", "def", "hard_constraint_predict", "(", "config", ":", "Config", ",", "model", ":", "NNCRF_sl", ",", "fold_batches", ":", "List", "[", "Tuple", "]", ",", "folded_insts", ":", "List", "[", "Instance", "]", ",", "model_type", ":", "str", "=", "\"hard\"", ")", ":", "\n", "    ", "batch_id", "=", "0", "\n", "batch_size", "=", "config", ".", "batch_size", "\n", "model", ".", "eval", "(", ")", "\n", "for", "batch", "in", "fold_batches", ":", "\n", "        ", "one_batch_insts", "=", "folded_insts", "[", "batch_id", "*", "batch_size", ":", "(", "batch_id", "+", "1", ")", "*", "batch_size", "]", "\n", "batch_max_scores", ",", "batch_max_ids", "=", "model", ".", "decode", "(", "batch", ")", "\n", "batch_max_ids", "=", "batch_max_ids", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "word_seq_lens", "=", "batch", "[", "1", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "batch_max_ids", ")", ")", ":", "\n", "            ", "length", "=", "word_seq_lens", "[", "idx", "]", "\n", "prediction", "=", "batch_max_ids", "[", "idx", "]", "[", ":", "length", "]", ".", "tolist", "(", ")", "\n", "prediction", "=", "prediction", "[", ":", ":", "-", "1", "]", "#reverse list", "\n", "one_batch_insts", "[", "idx", "]", ".", "output_ids", "=", "prediction", "\n", "", "batch_id", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.train_one": [[256, 315], ["model.neuralcrf_small_loss_constrain_global.NNCRF_sl", "model.neuralcrf_small_loss_constrain_global.NNCRF_sl.train", "config.get_optimizer", "range", "time.time", "model.neuralcrf_small_loss_constrain_global.NNCRF_sl.zero_grad", "numpy.random.permutation", "time.time", "print", "print", "model.neuralcrf_small_loss_constrain_global.NNCRF_sl.eval", "confidence_estimation_global.evaluate_model", "model.neuralcrf_small_loss_constrain_global.NNCRF_sl.zero_grad", "print", "print", "config.optimizer.lower", "config.lr_decay", "len", "model.neuralcrf_small_loss_constrain_global.NNCRF_sl.train", "tuple", "model.neuralcrf_small_loss_constrain_global.NNCRF_sl.", "loss.item", "loss_neg.item", "loss_pos.item", "loss.backward", "config.lr_decay.step", "model.neuralcrf_small_loss_constrain_global.NNCRF_sl.zero_grad", "confidence_estimation_global.evaluate_model", "print", "torch.save", "str", "model.neuralcrf_small_loss_constrain_global.NNCRF_sl.state_dict", "open", "pickle.dump", "open.close", "config.write_results", "list", "range", "str", "len", "str"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.get_optimizer", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.evaluate_model", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.lr_decay", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.evaluate_model", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.write_results"], ["", "", "def", "train_one", "(", "config", ":", "Config", ",", "train_batches", ":", "List", "[", "Tuple", "]", ",", "dev_insts", ":", "List", "[", "Instance", "]", ",", "\n", "dev_batches", ":", "List", "[", "Tuple", "]", ",", "model_name", ":", "str", ",", "test_insts", ":", "List", "[", "Instance", "]", "=", "None", ",", "\n", "test_batches", ":", "List", "[", "Tuple", "]", "=", "None", ",", "config_name", ":", "str", "=", "None", ",", "result_filename", ":", "str", "=", "None", ",", "rate_schedule_neg", "=", "None", ",", "rate_schedule_pos", "=", "None", ")", "->", "NNCRF_sl", ":", "\n", "    ", "model", "=", "NNCRF_sl", "(", "config", ")", "\n", "model", ".", "train", "(", ")", "\n", "optimizer", "=", "get_optimizer", "(", "config", ",", "model", ")", "\n", "epoch", "=", "config", ".", "num_epochs", "\n", "best_dev_f1", "=", "-", "1", "\n", "saved_test_metrics", "=", "None", "\n", "for", "i", "in", "range", "(", "1", ",", "epoch", "+", "1", ")", ":", "\n", "        ", "ratios_sum", "=", "[", "0", "]", "*", "6", "\n", "forget_rate_neg", "=", "rate_schedule_neg", "[", "i", "-", "1", "]", "\n", "forget_rate_pos", "=", "rate_schedule_pos", "[", "i", "-", "1", "]", "\n", "epoch_loss", "=", "0", "\n", "epoch_loss_neg", "=", "0", "\n", "epoch_loss_pos", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "if", "config", ".", "optimizer", ".", "lower", "(", ")", "==", "\"sgd\"", ":", "\n", "            ", "optimizer", "=", "lr_decay", "(", "config", ",", "optimizer", ",", "i", ")", "\n", "", "is_constrain", "=", "config", ".", "is_constrain", "\n", "for", "index", "in", "np", ".", "random", ".", "permutation", "(", "len", "(", "train_batches", ")", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "tmp", "=", "tuple", "(", "list", "(", "train_batches", "[", "index", "]", ")", "+", "[", "forget_rate_neg", ",", "forget_rate_pos", ",", "is_constrain", "]", ")", "\n", "\n", "loss", ",", "ratios", ",", "loss_neg", ",", "loss_pos", "=", "model", "(", "*", "tmp", ")", "\n", "ratios_sum", "=", "[", "ratios_sum", "[", "i", "]", "+", "ratios", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "ratios", ")", ")", "]", "\n", "epoch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "epoch_loss_neg", "+=", "loss_neg", ".", "item", "(", ")", "\n", "epoch_loss_pos", "+=", "loss_pos", ".", "item", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "", "end_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Epoch %d: %.5f, Time is %.2fs\"", "%", "(", "i", ",", "epoch_loss", "/", "epoch", ",", "end_time", "-", "start_time", ")", ",", "flush", "=", "True", ")", "\n", "print", "(", "'avg neg NLL: '", "+", "str", "(", "epoch_loss_neg", "/", "epoch", ")", "+", "'  avg pos NLL: '", "+", "str", "(", "epoch_loss_pos", "/", "epoch", ")", ")", "\n", "model", ".", "eval", "(", ")", "\n", "# metric is [precision, recall, f_score]", "\n", "dev_metrics", "=", "evaluate_model", "(", "config", ",", "model", ",", "dev_batches", ",", "\"dev\"", ",", "dev_insts", ")", "\n", "if", "test_insts", "is", "not", "None", ":", "\n", "            ", "test_metrics", "=", "evaluate_model", "(", "config", ",", "model", ",", "test_batches", ",", "\"test\"", ",", "test_insts", ")", "\n", "", "if", "dev_metrics", "[", "2", "]", ">", "best_dev_f1", ":", "\n", "            ", "print", "(", "\"saving the best model...\"", "+", "' epoch'", "+", "str", "(", "i", ")", ")", "\n", "best_dev_f1", "=", "dev_metrics", "[", "2", "]", "\n", "if", "test_insts", "is", "not", "None", ":", "\n", "                ", "saved_test_metrics", "=", "test_metrics", "\n", "", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "model_name", ")", "\n", "# # Save the corresponding config as well.", "\n", "if", "config_name", ":", "\n", "                ", "f", "=", "open", "(", "config_name", ",", "'wb'", ")", "\n", "pickle", ".", "dump", "(", "config", ",", "f", ")", "\n", "f", ".", "close", "(", ")", "\n", "", "if", "result_filename", ":", "\n", "                ", "write_results", "(", "result_filename", ",", "test_insts", ")", "\n", "", "", "model", ".", "zero_grad", "(", ")", "\n", "", "if", "test_insts", "is", "not", "None", ":", "\n", "        ", "print", "(", "f\"The best dev F1: {best_dev_f1}\"", ")", "\n", "print", "(", "f\"The corresponding test: {saved_test_metrics}\"", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.evaluate_model": [[319, 339], ["numpy.asarray", "print", "model.decode", "config.evaluate_batch_insts"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.decode", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.eval.evaluate_batch_insts"], ["", "def", "evaluate_model", "(", "config", ":", "Config", ",", "model", ":", "NNCRF_sl", ",", "batch_insts_ids", ",", "name", ":", "str", ",", "insts", ":", "List", "[", "Instance", "]", ")", ":", "\n", "## evaluation", "\n", "    ", "metrics", "=", "np", ".", "asarray", "(", "[", "0", ",", "0", ",", "0", "]", ",", "dtype", "=", "int", ")", "\n", "batch_id", "=", "0", "\n", "batch_size", "=", "config", ".", "batch_size", "\n", "for", "batch", "in", "batch_insts_ids", ":", "\n", "\n", "        ", "one_batch_insts", "=", "insts", "[", "batch_id", "*", "batch_size", ":", "(", "batch_id", "+", "1", ")", "*", "batch_size", "]", "\n", "batch_max_scores", ",", "batch_max_ids", "=", "model", ".", "decode", "(", "batch", ")", "\n", "metrics", "+=", "evaluate_batch_insts", "(", "batch_insts", "=", "one_batch_insts", ",", "\n", "batch_pred_ids", "=", "batch_max_ids", ",", "\n", "batch_gold_ids", "=", "batch", "[", "-", "2", "]", ",", "\n", "word_seq_lens", "=", "batch", "[", "1", "]", ",", "idx2label", "=", "config", ".", "idx2labels", ")", "\n", "batch_id", "+=", "1", "\n", "", "p", ",", "total_predict", ",", "total_entity", "=", "metrics", "[", "0", "]", ",", "metrics", "[", "1", "]", ",", "metrics", "[", "2", "]", "\n", "precision", "=", "p", "*", "1.0", "/", "total_predict", "*", "100", "if", "total_predict", "!=", "0", "else", "0", "\n", "recall", "=", "p", "*", "1.0", "/", "total_entity", "*", "100", "if", "total_entity", "!=", "0", "else", "0", "\n", "fscore", "=", "2.0", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "if", "precision", "!=", "0", "or", "recall", "!=", "0", "else", "0", "\n", "print", "(", "\"[%s set] Precision: %.2f, Recall: %.2f, F1: %.2f\"", "%", "(", "name", ",", "precision", ",", "recall", ",", "fscore", ")", ",", "flush", "=", "True", ")", "\n", "return", "[", "precision", ",", "recall", ",", "fscore", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.main": [[343, 385], ["argparse.ArgumentParser", "confidence_estimation_global.parse_arguments", "config.Config", "config.Reader", "config.Reader.read_txt", "config.Reader.read_txt", "config.Reader.read_txt", "config.Config.use_iobes", "config.Config.use_iobes_gold", "config.Config.build_label_idx", "config.Config.build_word_idx", "config.Config.build_emb_table", "config.Config.map_insts_ids", "print", "print", "config.Config.map_insts_ids", "config.Config.get_gold_label_ids", "random.shuffle", "math.ceil", "confidence_estimation_global.train_model", "print", "config.utils.load_elmo_vec", "config.utils.load_elmo_vec", "config.utils.load_elmo_vec", "enumerate", "str", "str", "len", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.parse_arguments", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.reader.Reader.read_txt", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.reader.Reader.read_txt", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.reader.Reader.read_txt", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.use_iobes", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.use_iobes_gold", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.build_label_idx", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.build_word_idx", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.build_emb_table", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.map_insts_ids", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.map_insts_ids", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.get_gold_label_ids", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.None.confidence_estimation_global.train_model", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.load_elmo_vec", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.load_elmo_vec", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.load_elmo_vec"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"LSTM CRF implementation\"", ")", "\n", "opt", "=", "parse_arguments", "(", "parser", ")", "\n", "conf", "=", "Config", "(", "opt", ")", "\n", "\n", "reader", "=", "Reader", "(", "conf", ".", "digit2zero", ")", "\n", "#set_seed(opt, conf.seed)", "\n", "\n", "trains", "=", "reader", ".", "read_txt", "(", "conf", ".", "train_file", ",", "conf", ".", "train_num", ")", "\n", "devs", "=", "reader", ".", "read_txt", "(", "conf", ".", "dev_file", ",", "conf", ".", "dev_num", ")", "\n", "tests", "=", "reader", ".", "read_txt", "(", "conf", ".", "test_file", ",", "conf", ".", "test_num", ")", "\n", "\n", "if", "conf", ".", "context_emb", "!=", "ContextEmb", ".", "none", ":", "\n", "        ", "print", "(", "'[Data Info] Loading the ELMo vectors for all datasets.'", ")", "\n", "conf", ".", "context_emb_size", "=", "load_elmo_vec", "(", "conf", ".", "train_file", "+", "\".\"", "+", "conf", ".", "context_emb", ".", "name", "+", "\".vec\"", ",", "trains", ")", "\n", "\n", "load_elmo_vec", "(", "conf", ".", "dev_file", "+", "\".\"", "+", "conf", ".", "context_emb", ".", "name", "+", "\".vec\"", ",", "devs", ")", "\n", "load_elmo_vec", "(", "conf", ".", "test_file", "+", "\".\"", "+", "conf", ".", "context_emb", ".", "name", "+", "\".vec\"", ",", "tests", ")", "\n", "\n", "", "conf", ".", "use_iobes", "(", "trains", "+", "devs", "+", "tests", ")", "\n", "conf", ".", "use_iobes_gold", "(", "trains", ")", "\n", "conf", ".", "build_label_idx", "(", "trains", "+", "devs", "+", "tests", ")", "\n", "\n", "conf", ".", "build_word_idx", "(", "trains", ",", "devs", ",", "tests", ")", "\n", "conf", ".", "build_emb_table", "(", ")", "\n", "conf", ".", "map_insts_ids", "(", "devs", "+", "tests", ")", "\n", "print", "(", "\"[Data Info] num chars: \"", "+", "str", "(", "conf", ".", "num_char", ")", ")", "\n", "print", "(", "\"[Data Info] num words: \"", "+", "str", "(", "len", "(", "conf", ".", "word2idx", ")", ")", ")", "\n", "\n", "\n", "conf", ".", "map_insts_ids", "(", "trains", ")", "\n", "conf", ".", "get_gold_label_ids", "(", "trains", ")", "\n", "random", ".", "shuffle", "(", "trains", ")", "\n", "for", "inst", "in", "trains", ":", "\n", "        ", "inst", ".", "is_prediction", "=", "[", "False", "]", "*", "len", "(", "inst", ".", "input", ")", "\n", "for", "pos", ",", "label", "in", "enumerate", "(", "inst", ".", "output", ")", ":", "\n", "            ", "if", "label", "==", "conf", ".", "O", ":", "\n", "                ", "inst", ".", "is_prediction", "[", "pos", "]", "=", "True", "\n", "\n", "", "", "", "num_insts_in_fold", "=", "math", ".", "ceil", "(", "len", "(", "trains", ")", "/", "conf", ".", "num_folds", ")", "\n", "trains", "=", "[", "trains", "[", "i", "*", "num_insts_in_fold", ":", "(", "i", "+", "1", ")", "*", "num_insts_in_fold", "]", "for", "i", "in", "range", "(", "conf", ".", "num_folds", ")", "]", "\n", "train_model", "(", "config", "=", "conf", ",", "train_insts", "=", "trains", ",", "dev_insts", "=", "devs", ",", "test_insts", "=", "tests", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.bilstm_encoder.BiLSTMEncoder.__init__": [[12, 48], ["torch.Module.__init__", "torch.Embedding.from_pretrained().to", "torch.Embedding.from_pretrained().to", "torch.Dropout().to", "torch.Dropout().to", "torch.LSTM().to", "torch.LSTM().to", "torch.Dropout().to", "torch.Dropout().to", "torch.Linear().to", "torch.Linear().to", "torch.Sigmoid().to", "torch.Sigmoid().to", "model.charbilstm.CharBiLSTM", "print", "print", "print", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Dropout", "torch.Dropout", "torch.LSTM", "torch.LSTM", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.instance.Instance.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "print_info", ":", "bool", "=", "True", ")", ":", "\n", "        ", "super", "(", "BiLSTMEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "label_size", "=", "config", ".", "label_size", "\n", "self", ".", "device", "=", "config", ".", "device", "\n", "self", ".", "use_char", "=", "config", ".", "use_char_rnn", "\n", "self", ".", "context_emb", "=", "config", ".", "context_emb", "\n", "\n", "self", ".", "label2idx", "=", "config", ".", "label2idx", "\n", "self", ".", "labels", "=", "config", ".", "idx2labels", "\n", "\n", "self", ".", "input_size", "=", "config", ".", "embedding_dim", "\n", "if", "self", ".", "context_emb", "!=", "ContextEmb", ".", "none", ":", "\n", "            ", "self", ".", "input_size", "+=", "config", ".", "context_emb_size", "\n", "", "if", "self", ".", "use_char", ":", "\n", "            ", "self", ".", "char_feature", "=", "CharBiLSTM", "(", "config", ",", "print_info", "=", "print_info", ")", "\n", "self", ".", "input_size", "+=", "config", ".", "charlstm_hidden_dim", "\n", "\n", "", "self", ".", "word_embedding", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "torch", ".", "FloatTensor", "(", "config", ".", "word_embedding", ")", ",", "freeze", "=", "False", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "word_drop", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "if", "print_info", ":", "\n", "            ", "print", "(", "\"[Model Info] Input size to LSTM: {}\"", ".", "format", "(", "self", ".", "input_size", ")", ")", "\n", "print", "(", "\"[Model Info] LSTM Hidden Size: {}\"", ".", "format", "(", "config", ".", "hidden_dim", ")", ")", "\n", "\n", "", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "self", ".", "input_size", ",", "config", ".", "hidden_dim", "//", "2", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "drop_lstm", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "final_hidden_dim", "=", "config", ".", "hidden_dim", "\n", "\n", "if", "print_info", ":", "\n", "            ", "print", "(", "\"[Model Info] Final Hidden Size: {}\"", ".", "format", "(", "final_hidden_dim", ")", ")", "\n", "\n", "", "self", ".", "hidden2tag", "=", "nn", ".", "Linear", "(", "final_hidden_dim", ",", "self", ".", "label_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.bilstm_encoder.BiLSTMEncoder.forward": [[49, 85], ["bilstm_encoder.BiLSTMEncoder.word_embedding", "bilstm_encoder.BiLSTMEncoder.word_drop", "word_seq_lens.sort", "permIdx.sort", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "bilstm_encoder.BiLSTMEncoder.lstm", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "bilstm_encoder.BiLSTMEncoder.drop_lstm", "bilstm_encoder.BiLSTMEncoder.hidden2tag", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "bilstm_encoder.BiLSTMEncoder.char_feature", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "batch_context_emb.to"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "word_seq_tensor", ":", "torch", ".", "Tensor", ",", "\n", "word_seq_lens", ":", "torch", ".", "Tensor", ",", "\n", "batch_context_emb", ":", "torch", ".", "Tensor", ",", "\n", "char_inputs", ":", "torch", ".", "Tensor", ",", "\n", "char_seq_lens", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Encoding the input with BiLSTM\n        :param word_seq_tensor: (batch_size, sent_len)   NOTE: The word seq actually is already ordered before come here.\n        :param word_seq_lens: (batch_size, 1)\n        :param batch_context_emb: (batch_size, sent_len, context embedding) ELMo embedings\n        :param char_inputs: (batch_size * sent_len * word_length)\n        :param char_seq_lens: numpy (batch_size * sent_len , 1)\n        :return: emission scores (batch_size, sent_len, hidden_dim)\n        \"\"\"", "\n", "\n", "word_emb", "=", "self", ".", "word_embedding", "(", "word_seq_tensor", ")", "\n", "if", "self", ".", "context_emb", "!=", "ContextEmb", ".", "none", ":", "\n", "            ", "word_emb", "=", "torch", ".", "cat", "(", "[", "word_emb", ",", "batch_context_emb", ".", "to", "(", "self", ".", "device", ")", "]", ",", "2", ")", "\n", "", "if", "self", ".", "use_char", ":", "\n", "            ", "char_features", "=", "self", ".", "char_feature", "(", "char_inputs", ",", "char_seq_lens", ")", "\n", "word_emb", "=", "torch", ".", "cat", "(", "[", "word_emb", ",", "char_features", "]", ",", "2", ")", "\n", "\n", "", "word_rep", "=", "self", ".", "word_drop", "(", "word_emb", ")", "\n", "\n", "\n", "sorted_seq_len", ",", "permIdx", "=", "word_seq_lens", ".", "sort", "(", "0", ",", "descending", "=", "True", ")", "\n", "_", ",", "recover_idx", "=", "permIdx", ".", "sort", "(", "0", ",", "descending", "=", "False", ")", "\n", "sorted_seq_tensor", "=", "word_rep", "[", "permIdx", "]", "\n", "\n", "packed_words", "=", "pack_padded_sequence", "(", "sorted_seq_tensor", ",", "sorted_seq_len", ",", "True", ")", "\n", "lstm_out", ",", "_", "=", "self", ".", "lstm", "(", "packed_words", ",", "None", ")", "\n", "lstm_out", ",", "_", "=", "pad_packed_sequence", "(", "lstm_out", ",", "batch_first", "=", "True", ")", "\n", "feature_out", "=", "self", ".", "drop_lstm", "(", "lstm_out", ")", "\n", "outputs", "=", "self", ".", "hidden2tag", "(", "feature_out", ")", "\n", "return", "outputs", "[", "recover_idx", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_global.NNCRF_sl.__init__": [[90, 110], ["torch.Module.__init__", "model.bilstm_encoder.BiLSTMEncoder", "model.linear_partial_crf_inferencer.LinearCRF", "neuralcrf_small_loss_constrain_global.gen_dic", "len", "neuralcrf_small_loss_constrain_global.gen_embedding_table", "torch.nn.Embedding().from_pretrained().cuda", "torch.nn.Embedding().from_pretrained().cuda", "torch.nn.Embedding().from_pretrained().cuda", "torch.nn.Embedding().from_pretrained().cuda", "torch.nn.Embedding().from_pretrained().cuda", "torch.nn.Embedding().from_pretrained().cuda", "torch.nn.Embedding().from_pretrained().cuda", "torch.nn.Embedding().from_pretrained().cuda", "config.label2idx.keys", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.instance.Instance.__init__", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_local.gen_dic", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_local.gen_embedding_table"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "print_info", ":", "bool", "=", "True", ")", ":", "\n", "        ", "super", "(", "NNCRF_sl", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "config", ".", "device", "\n", "self", ".", "encoder", "=", "BiLSTMEncoder", "(", "config", ",", "print_info", "=", "print_info", ")", "\n", "self", ".", "inferencer", "=", "LinearCRF", "(", "config", ",", "print_info", "=", "print_info", ")", "\n", "self", ".", "label2idx", "=", "config", ".", "label2idx", "\n", "self", ".", "idx2word", "=", "config", ".", "idx2word", "\n", "self", ".", "idx2labels", "=", "config", ".", "idx2labels", "\n", "self", ".", "Oid", "=", "self", ".", "label2idx", "[", "'O'", "]", "\n", "self", ".", "padid", "=", "self", ".", "label2idx", "[", "'<PAD>'", "]", "\n", "self", ".", "startid", "=", "self", ".", "label2idx", "[", "'<START>'", "]", "\n", "self", ".", "stopid", "=", "self", ".", "label2idx", "[", "'<STOP>'", "]", "\n", "\n", "\n", "self", ".", "pos_dic", ",", "self", ".", "type_dic", "=", "gen_dic", "(", "config", ".", "label2idx", ".", "keys", "(", ")", ",", "self", ".", "label2idx", ")", "\n", "\n", "self", ".", "tags_num", "=", "len", "(", "self", ".", "idx2labels", ")", "\n", "e_type", ",", "pos", "=", "gen_embedding_table", "(", "self", ".", "idx2labels", ",", "self", ".", "type_dic", ",", "self", ".", "pos_dic", ")", "\n", "self", ".", "type_embedding", "=", "torch", ".", "nn", ".", "Embedding", "(", "self", ".", "tags_num", ",", "self", ".", "tags_num", ")", ".", "from_pretrained", "(", "e_type", ",", "freeze", "=", "True", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "self", ".", "pos_embedding", "=", "torch", ".", "nn", ".", "Embedding", "(", "self", ".", "tags_num", ",", "self", ".", "tags_num", ")", ".", "from_pretrained", "(", "pos", ",", "freeze", "=", "True", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_global.NNCRF_sl.forward": [[111, 215], ["neuralcrf_small_loss_constrain_global.NNCRF_sl.encoder", "words.size", "words.size", "torch.arange().view().expand().to", "torch.arange().view().expand().to", "torch.arange().view().expand().to", "torch.arange().view().expand().to", "torch.le().to().float", "torch.le().to().float", "torch.le().to().float", "torch.le().to().float", "torch.zeros_like().scatter_", "torch.zeros_like().scatter_", "torch.zeros_like().scatter_", "torch.zeros_like().scatter_", "neuralcrf_small_loss_constrain_global.NNCRF_sl.inferencer.marginal", "forward_loss.detach.detach.detach", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "int", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "small_loss_mask_neg.view.view.view", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "int", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "small_loss_mask_pos.view.view.view", "small_loss_mask.detach.detach.detach", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "neuralcrf_small_loss_constrain_global.NNCRF_sl.type_embedding", "neuralcrf_small_loss_constrain_global.NNCRF_sl.pos_embedding", "neuralcrf_small_loss_constrain_global.NNCRF_sl.exp", "prob.detach.detach.detach", "label_tag_mask.detach.detach.detach", "neuralcrf_small_loss_constrain_global.NNCRF_sl.inferencer", "tags.unsqueeze", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.le().to().float.float", "torch.le().to().float.float", "torch.le().to().float.float", "torch.le().to().float.float", "negative_mask.sum", "small_loss_mask_neg.view.view.sum", "neuralcrf_small_loss_constrain_global.check_remove_ratio", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.le().to", "torch.le().to", "torch.le().to", "torch.le().to", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "forward_loss.detach.detach.view", "positive_mask.view", "negative_mask.sum", "forward_loss.detach.detach.view", "negative_mask.view", "positive_mask.sum", "negative_mask.sum", "positive_mask.sum", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "small_loss_mask_pos.view.view.bool", "small_loss_mask_neg.view.view.bool", "type_change_mask.unsqueeze", "pos_change_mask.unsqueeze", "small_loss_mask.detach.detach.unsqueeze", "small_loss_mask.detach.detach.unsqueeze", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.le", "torch.le", "torch.le", "torch.le", "word_seq_lens.view().expand", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "word_seq_lens.view"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.marginal", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_local.check_remove_ratio"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "words", ":", "torch", ".", "Tensor", ",", "\n", "word_seq_lens", ":", "torch", ".", "Tensor", ",", "\n", "batch_context_emb", ":", "torch", ".", "Tensor", ",", "\n", "chars", ":", "torch", ".", "Tensor", ",", "\n", "char_seq_lens", ":", "torch", ".", "Tensor", ",", "\n", "annotation_mask", ":", "torch", ".", "Tensor", ",", "\n", "tags", ":", "torch", ".", "Tensor", ",", "\n", "gold_tags", "=", "None", ",", "\n", "forget_rate_neg", "=", "0", ",", "forget_rate_pos", "=", "0", ",", "is_constrain", "=", "False", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Calculate the negative loglikelihood.\n        :param words: (batch_size x max_seq_len)\n        :param word_seq_lens: (batch_size)\n        :param batch_context_emb: (batch_size x max_seq_len x context_emb_size)\n        :param chars: (batch_size x max_seq_len x max_char_len)\n        :param char_seq_lens: (batch_size x max_seq_len)\n        :param tags: (batch_size x max_seq_len)\n        :return: the loss with shape (batch_size)\n        \"\"\"", "\n", "\n", "lstm_scores", "=", "self", ".", "encoder", "(", "words", ",", "word_seq_lens", ",", "batch_context_emb", ",", "chars", ",", "char_seq_lens", ")", "\n", "batch_size", "=", "words", ".", "size", "(", "0", ")", "\n", "sent_len", "=", "words", ".", "size", "(", "1", ")", "\n", "maskTemp", "=", "torch", ".", "arange", "(", "1", ",", "sent_len", "+", "1", ",", "dtype", "=", "torch", ".", "long", ")", ".", "view", "(", "1", ",", "sent_len", ")", ".", "expand", "(", "batch_size", ",", "sent_len", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "mask", "=", "torch", ".", "le", "(", "maskTemp", ",", "word_seq_lens", ".", "view", "(", "batch_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "sent_len", ")", ")", ".", "to", "(", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "\n", "onehot_label", "=", "torch", ".", "zeros_like", "(", "lstm_scores", ")", ".", "scatter_", "(", "-", "1", ",", "tags", ".", "unsqueeze", "(", "-", "1", ")", ",", "1", ")", "\n", "log_marginals", "=", "self", ".", "inferencer", ".", "marginal", "(", "lstm_scores", ",", "word_seq_lens", ")", "\n", "token_prob", "=", "log_marginals", "\n", "forward_loss", "=", "-", "(", "onehot_label", "*", "token_prob", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "*", "mask", "\n", "forward_loss", "=", "forward_loss", ".", "detach", "(", ")", "\n", "negative_mask", "=", "torch", ".", "eq", "(", "tags", ",", "self", ".", "Oid", ")", ".", "float", "(", ")", "*", "mask", ".", "float", "(", ")", "\n", "positive_mask", "=", "(", "1", "-", "negative_mask", ")", "*", "mask", ".", "float", "(", ")", "\n", "\n", "\n", "tmp", "=", "forward_loss", ".", "view", "(", "batch_size", "*", "sent_len", ")", "+", "(", "1000", "*", "(", "1", "-", "mask", ")", ".", "view", "(", "batch_size", "*", "sent_len", ")", ")", "+", "(", "\n", "1000", "*", "(", "positive_mask", ".", "view", "(", "batch_size", "*", "sent_len", ")", ")", ")", "\n", "\n", "index", "=", "torch", ".", "argsort", "(", "tmp", ",", "dim", "=", "-", "1", ")", "\n", "remember_rate_neg", "=", "1.0", "-", "forget_rate_neg", "\n", "\n", "num_remember", "=", "int", "(", "remember_rate_neg", "*", "(", "negative_mask", ".", "sum", "(", ")", ")", ")", "\n", "small_loss_index", "=", "index", "[", ":", "num_remember", "]", "\n", "small_loss_mask_neg", "=", "torch", ".", "zeros_like", "(", "tmp", ")", "\n", "for", "num", "in", "small_loss_index", ":", "\n", "            ", "small_loss_mask_neg", "[", "num", "]", "=", "1", "\n", "", "small_loss_mask_neg", "=", "small_loss_mask_neg", ".", "view", "(", "(", "batch_size", ",", "sent_len", ")", ")", "\n", "if", "num_remember", "==", "0", ":", "\n", "            ", "small_loss_mask_neg", "=", "negative_mask", "\n", "", "remove_num_neg", "=", "negative_mask", ".", "sum", "(", ")", "-", "small_loss_mask_neg", ".", "sum", "(", ")", "\n", "\n", "tmp", "=", "forward_loss", ".", "view", "(", "batch_size", "*", "sent_len", ")", "+", "(", "1000", "*", "(", "1", "-", "mask", ")", ".", "view", "(", "batch_size", "*", "sent_len", ")", ")", "+", "(", "\n", "1000", "*", "(", "negative_mask", ".", "view", "(", "batch_size", "*", "sent_len", ")", ")", ")", "\n", "\n", "index", "=", "torch", ".", "argsort", "(", "tmp", ",", "dim", "=", "-", "1", ")", "\n", "remember_rate_pos", "=", "1.0", "-", "forget_rate_pos", "\n", "\n", "num_remember", "=", "int", "(", "remember_rate_pos", "*", "(", "positive_mask", ".", "sum", "(", ")", ")", ")", "\n", "small_loss_index", "=", "index", "[", ":", "num_remember", "]", "\n", "small_loss_mask_pos", "=", "torch", ".", "zeros_like", "(", "tmp", ")", "\n", "for", "num", "in", "small_loss_index", ":", "\n", "            ", "small_loss_mask_pos", "[", "num", "]", "=", "1", "\n", "", "small_loss_mask_pos", "=", "small_loss_mask_pos", ".", "view", "(", "(", "batch_size", ",", "sent_len", ")", ")", "\n", "if", "num_remember", "==", "0", ":", "\n", "            ", "small_loss_mask_pos", "=", "positive_mask", "\n", "\n", "", "small_loss_mask", "=", "(", "small_loss_mask_pos", ".", "bool", "(", ")", "+", "small_loss_mask_neg", ".", "bool", "(", ")", ")", ".", "float", "(", ")", "\n", "small_loss_mask", "=", "small_loss_mask", ".", "detach", "(", ")", "\n", "\n", "if", "(", "gold_tags", "!=", "None", ")", ":", "\n", "            ", "neg_recall", ",", "pos_recall", ",", "neg_precision", ",", "pos_precision", ",", "neg_f1", ",", "pos_f1", "=", "check_remove_ratio", "(", "gold_tags", ",", "tags", ",", "small_loss_mask", ",", "mask", ",", "negative_mask", ")", "\n", "\n", "\n", "", "partial_label", "=", "torch", ".", "ones_like", "(", "onehot_label", ")", "\n", "\n", "\n", "type_lookup", "=", "self", ".", "type_embedding", "(", "tags", ")", "\n", "pos_lookup", "=", "self", ".", "pos_embedding", "(", "tags", ")", "\n", "\n", "prob", "=", "log_marginals", ".", "exp", "(", ")", "\n", "prob", "=", "prob", ".", "detach", "(", ")", "\n", "type_prob", "=", "(", "prob", "*", "type_lookup", ")", ".", "mean", "(", "dim", "=", "-", "1", ")", "\n", "pos_prob", "=", "(", "prob", "*", "pos_lookup", ")", ".", "mean", "(", "dim", "=", "-", "1", ")", "\n", "type_change_mask", "=", "(", "type_prob", ">", "pos_prob", ")", "*", "mask", "*", "(", "1", "-", "small_loss_mask", ")", "\n", "pos_change_mask", "=", "(", "type_prob", "<", "pos_prob", ")", "*", "mask", "*", "(", "1", "-", "small_loss_mask", ")", "\n", "\n", "change_label", "=", "(", "(", "type_change_mask", ".", "unsqueeze", "(", "-", "1", ")", "*", "type_lookup", ")", "+", "(", "pos_change_mask", ".", "unsqueeze", "(", "-", "1", ")", "*", "pos_lookup", ")", ")", "+", "(", "(", "1", "-", "small_loss_mask", ")", "*", "(", "1", "-", "type_change_mask", ")", "*", "(", "1", "-", "pos_change_mask", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", "*", "partial_label", "\n", "\n", "if", "(", "is_constrain", ")", ":", "\n", "            ", "label_tag_mask", "=", "(", "small_loss_mask", ".", "unsqueeze", "(", "-", "1", ")", "*", "onehot_label", ")", "+", "(", "(", "1", "-", "small_loss_mask", ")", ".", "unsqueeze", "(", "-", "1", ")", "*", "change_label", ")", "\n", "", "else", ":", "\n", "            ", "label_tag_mask", "=", "small_loss_mask", ".", "unsqueeze", "(", "-", "1", ")", "*", "onehot_label", "+", "(", "1", "-", "small_loss_mask", ")", ".", "unsqueeze", "(", "-", "1", ")", "*", "partial_label", "\n", "\n", "", "label_tag_mask", "=", "label_tag_mask", ".", "detach", "(", ")", "\n", "unlabed_score", ",", "labeled_score", "=", "self", ".", "inferencer", "(", "lstm_scores", ",", "word_seq_lens", ",", "label_tag_mask", ")", "\n", "\n", "loss_neg", "=", "(", "forward_loss", "*", "negative_mask", ")", ".", "sum", "(", ")", "/", "(", "negative_mask", ".", "sum", "(", ")", "+", "1e-6", ")", "\n", "loss_pos", "=", "(", "forward_loss", "*", "positive_mask", ")", ".", "sum", "(", ")", "/", "(", "positive_mask", ".", "sum", "(", ")", "+", "1e-6", ")", "\n", "\n", "if", "(", "gold_tags", "!=", "None", ")", ":", "\n", "            ", "return", "unlabed_score", "-", "labeled_score", ",", "[", "neg_recall", ",", "pos_recall", ",", "neg_precision", ",", "pos_precision", ",", "neg_f1", ",", "pos_f1", "]", ",", "loss_neg", ",", "loss_pos", "\n", "", "else", ":", "\n", "            ", "return", "unlabed_score", "-", "labeled_score", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_global.NNCRF_sl.decode": [[216, 228], ["neuralcrf_small_loss_constrain_global.NNCRF_sl.encoder", "neuralcrf_small_loss_constrain_global.NNCRF_sl.inferencer.decode"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.decode"], ["", "", "def", "decode", "(", "self", ",", "batchInput", ":", "Tuple", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Decode the batch input\n        :param batchInput:\n        :return:\n        \"\"\"", "\n", "wordSeqTensor", ",", "wordSeqLengths", ",", "batch_context_emb", ",", "charSeqTensor", ",", "charSeqLengths", ",", "annotation_mask", ",", "tagSeqTensor", ",", "_", "=", "batchInput", "\n", "\n", "features", "=", "self", ".", "encoder", "(", "wordSeqTensor", ",", "wordSeqLengths", ",", "batch_context_emb", ",", "charSeqTensor", ",", "charSeqLengths", ")", "\n", "bestScores", ",", "decodeIdx", "=", "self", ".", "inferencer", ".", "decode", "(", "features", ",", "wordSeqLengths", ",", "annotation_mask", ")", "\n", "\n", "return", "bestScores", ",", "decodeIdx", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_global.check_remove_ratio": [[13, 33], ["torch.eq().float", "torch.eq().float", "mask.float", "remove_right_neg.sum", "remove_right_pos.sum", "remove_right_neg.sum", "remove_right_pos.sum", "neg_recall.item", "pos_recall.item", "neg_precision.item", "pos_precision.item", "neg_f1.item", "pos_f1.item", "noise_negative.sum", "noise_positive.sum", "remove_neg.sum", "remove_pos.sum", "torch.eq", "torch.eq"], "function", ["None"], ["def", "check_remove_ratio", "(", "gold_tags", ",", "tags", ",", "small_loss_mask", ",", "mask", ",", "negative_mask", ")", ":", "\n", "    ", "remove_mask", "=", "(", "1", "-", "small_loss_mask", ")", "*", "mask", "\n", "positive_mask", "=", "(", "1", "-", "negative_mask", ")", "*", "mask", "\n", "clean_mask", "=", "torch", ".", "eq", "(", "gold_tags", ",", "tags", ")", ".", "float", "(", ")", "*", "mask", "\n", "noise_mask", "=", "(", "1", "-", "clean_mask", ")", "*", "mask", ".", "float", "(", ")", "\n", "remove_neg", "=", "remove_mask", "*", "negative_mask", "\n", "remove_right_neg", "=", "noise_mask", "*", "remove_neg", "\n", "remove_pos", "=", "remove_mask", "*", "(", "1", "-", "negative_mask", ")", "*", "mask", "\n", "remove_right_pos", "=", "noise_mask", "*", "remove_pos", "\n", "noise_positive", "=", "noise_mask", "*", "positive_mask", "*", "mask", "\n", "noise_negative", "=", "noise_mask", "*", "negative_mask", "*", "mask", "\n", "neg_recall", "=", "remove_right_neg", ".", "sum", "(", ")", "/", "(", "noise_negative", ".", "sum", "(", ")", "+", "1e-8", ")", "\n", "pos_recall", "=", "remove_right_pos", ".", "sum", "(", ")", "/", "(", "noise_positive", ".", "sum", "(", ")", "+", "1e-8", ")", "\n", "neg_precision", "=", "remove_right_neg", ".", "sum", "(", ")", "/", "(", "remove_neg", ".", "sum", "(", ")", "+", "1e-8", ")", "\n", "pos_precision", "=", "remove_right_pos", ".", "sum", "(", ")", "/", "(", "remove_pos", ".", "sum", "(", ")", "+", "1e-8", ")", "\n", "neg_f1", "=", "2", "*", "neg_recall", "*", "neg_precision", "/", "(", "neg_recall", "+", "neg_precision", "+", "1e-8", ")", "\n", "pos_f1", "=", "2", "*", "pos_recall", "*", "pos_precision", "/", "(", "pos_recall", "+", "pos_precision", "+", "1e-8", ")", "\n", "\n", "\n", "return", "neg_recall", ".", "item", "(", ")", ",", "pos_recall", ".", "item", "(", ")", ",", "neg_precision", ".", "item", "(", ")", ",", "pos_precision", ".", "item", "(", ")", ",", "neg_f1", ".", "item", "(", ")", ",", "pos_f1", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_global.gen_dic": [[34, 59], ["set", "type_dic[].append", "pos_dic[].append", "label.startswith", "label.startswith", "label.startswith", "label.startswith", "set.add", "label.startswith", "pos_dic[].append", "type_dic[].append", "label.split", "label.split", "label.split"], "function", ["None"], ["", "def", "gen_dic", "(", "labels", ",", "label2idx", ")", ":", "\n", "    ", "types", "=", "set", "(", ")", "\n", "for", "label", "in", "labels", ":", "\n", "        ", "if", "(", "label", ".", "startswith", "(", "'B'", ")", "or", "label", ".", "startswith", "(", "'S'", ")", "or", "label", ".", "startswith", "(", "'E'", ")", "or", "label", ".", "startswith", "(", "'I'", ")", ")", ":", "\n", "            ", "tp", "=", "label", ".", "split", "(", "'-'", ")", "[", "1", "]", "\n", "types", ".", "add", "(", "tp", ")", "\n", "", "", "pos_dic", "=", "{", "'O'", ":", "[", "label2idx", "[", "'O'", "]", "]", "}", "\n", "type_dic", "=", "{", "'O'", ":", "[", "label2idx", "[", "'O'", "]", "]", "}", "\n", "for", "label", "in", "labels", ":", "\n", "        ", "if", "(", "label", "==", "'O'", "or", "label", ".", "startswith", "(", "'<'", ")", ")", ":", "\n", "            ", "continue", "\n", "", "pos", ",", "type", "=", "label", ".", "split", "(", "'-'", ")", "[", "0", "]", ",", "label", ".", "split", "(", "'-'", ")", "[", "1", "]", "\n", "if", "(", "pos", "in", "pos_dic", ")", ":", "\n", "            ", "pos_dic", "[", "pos", "]", ".", "append", "(", "label2idx", "[", "label", "]", ")", "\n", "", "else", ":", "\n", "            ", "pos_dic", "[", "pos", "]", "=", "[", "label2idx", "[", "label", "]", "]", "\n", "", "if", "(", "type", "in", "type_dic", ")", ":", "\n", "            ", "type_dic", "[", "type", "]", ".", "append", "(", "label2idx", "[", "label", "]", ")", "\n", "", "else", ":", "\n", "            ", "type_dic", "[", "type", "]", "=", "[", "label2idx", "[", "label", "]", "]", "\n", "", "", "for", "tp", "in", "types", ":", "\n", "        ", "type_dic", "[", "tp", "]", ".", "append", "(", "label2idx", "[", "'O'", "]", ")", "\n", "", "for", "pos", "in", "[", "'B'", ",", "'I'", ",", "'E'", ",", "'S'", "]", ":", "\n", "        ", "pos_dic", "[", "pos", "]", ".", "append", "(", "label2idx", "[", "'O'", "]", ")", "\n", "", "return", "pos_dic", ",", "type_dic", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_global.gen_embedding_table": [[60, 85], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "enumerate", "len", "len", "len", "len", "label.startswith", "label.startswith", "label.startswith", "label.startswith", "label.startswith", "label.startswith", "label.startswith", "label.startswith", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "label.split", "label.split"], "function", ["None"], ["", "def", "gen_embedding_table", "(", "idx2label", ",", "type_dic", ",", "pos_dic", ")", ":", "\n", "    ", "type_embedding", "=", "torch", ".", "zeros", "(", "len", "(", "idx2label", ")", ",", "len", "(", "idx2label", ")", ")", "\n", "pos_embedding", "=", "torch", ".", "zeros", "(", "len", "(", "idx2label", ")", ",", "len", "(", "idx2label", ")", ")", "\n", "#type_embedding", "\n", "for", "id", ",", "label", "in", "enumerate", "(", "idx2label", ")", ":", "\n", "\n", "        ", "if", "(", "label", ".", "startswith", "(", "'B'", ")", "or", "label", ".", "startswith", "(", "'S'", ")", "or", "label", ".", "startswith", "(", "'E'", ")", "or", "label", ".", "startswith", "(", "'I'", ")", ")", ":", "\n", "            ", "indexes", "=", "type_dic", "[", "label", ".", "split", "(", "'-'", ")", "[", "1", "]", "]", "\n", "for", "index", "in", "indexes", ":", "\n", "                ", "type_embedding", "[", "id", "]", "[", "index", "]", "=", "1", "\n", "", "", "elif", "(", "label", "==", "'O'", ")", ":", "\n", "            ", "type_embedding", "[", "id", "]", "=", "torch", ".", "ones_like", "(", "type_embedding", "[", "id", "]", ")", "\n", "\n", "#pos_embedding", "\n", "", "", "for", "id", ",", "label", "in", "enumerate", "(", "idx2label", ")", ":", "\n", "\n", "        ", "if", "(", "label", ".", "startswith", "(", "'B'", ")", "or", "label", ".", "startswith", "(", "'S'", ")", "or", "label", ".", "startswith", "(", "'E'", ")", "or", "label", ".", "startswith", "(", "'I'", ")", ")", ":", "\n", "            ", "indexes", "=", "pos_dic", "[", "label", ".", "split", "(", "'-'", ")", "[", "0", "]", "]", "\n", "for", "index", "in", "indexes", ":", "\n", "                ", "pos_embedding", "[", "id", "]", "[", "index", "]", "=", "1", "\n", "", "", "elif", "(", "label", "==", "'O'", ")", ":", "\n", "            ", "pos_embedding", "[", "id", "]", "=", "torch", ".", "ones_like", "(", "pos_embedding", "[", "id", "]", ")", "\n", "\n", "", "", "type_embedding", ",", "pos_embedding", "=", "pos_embedding", ",", "type_embedding", "\n", "return", "type_embedding", ",", "pos_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.to_np": [[43, 46], ["x.detach().cpu().numpy", "x.detach().cpu", "x.detach"], "function", ["None"], ["def", "to_np", "(", "x", ")", ":", "\n", "  ", "\"\"\"Export a tensor to numpy\"\"\"", "\n", "return", "x", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.length_to_mask": [[47, 63], ["torch.arange().expand().to", "torch.arange().expand().to", "length.unsqueeze", "torch.arange().expand", "torch.arange().expand", "torch.arange", "torch.arange"], "function", ["None"], ["", "def", "length_to_mask", "(", "length", ",", "max_len", ")", ":", "\n", "  ", "\"\"\"\n  True = 1 = not masked, False = 0 = masked\n\n  Args:\n    length: type=torch.tensor(int), size=[batch]\n    max_len: type=int\n\n  Returns:\n    mask: type=torch.tensor(bool), size=[batch, max_len]\n  \"\"\"", "\n", "batch_size", "=", "length", ".", "shape", "[", "0", "]", "\n", "device", "=", "length", ".", "device", "\n", "mask", "=", "torch", ".", "arange", "(", "max_len", ",", "dtype", "=", "length", ".", "dtype", ")", ".", "expand", "(", "batch_size", ",", "max_len", ")", ".", "to", "(", "device", ")", "<", "length", ".", "unsqueeze", "(", "1", ")", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.mask_by_length": [[64, 82], ["torch_model_utils.length_to_mask", "mask.view.view", "A.size", "list", "mask.view.size", "A.float", "mask.view.float", "len", "A.float", "A.size", "mask.view.float"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.length_to_mask"], ["", "def", "mask_by_length", "(", "A", ",", "lens", ",", "mask_id", "=", "0.", ")", ":", "\n", "  ", "\"\"\"mask a batch of seq tensor by length\n  \n  Args:\n    A: type=torch.tensor(), size=[batch, max_len, *]\n    lens: type=torch.tensor(ing), size=[batch]\n    mask_id: type=float\n\n  Returns\n    A_masked: type=torch.tensor(float), note the for whatever input, the output \n      type would be casted to float\n  \"\"\"", "\n", "mask", "=", "length_to_mask", "(", "lens", ",", "A", ".", "size", "(", "1", ")", ")", "\n", "target_size", "=", "list", "(", "mask", ".", "size", "(", ")", ")", "+", "[", "1", "]", "*", "(", "len", "(", "A", ".", "size", "(", ")", ")", "-", "2", ")", "\n", "mask", "=", "mask", ".", "view", "(", "target_size", ")", "\n", "\n", "A_masked", "=", "A", ".", "float", "(", ")", "*", "mask", ".", "float", "(", ")", "+", "A", ".", "float", "(", ")", "*", "(", "1", "-", "mask", ".", "float", "(", ")", ")", "*", "mask_id", "\n", "return", "A_masked", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.ind_to_one_hot": [[83, 102], ["torch.arange().expand().to", "torch.arange().expand().to", "ind.unsqueeze", "torch.arange().expand", "torch.arange().expand", "torch.arange", "torch.arange"], "function", ["None"], ["", "def", "ind_to_one_hot", "(", "ind", ",", "max_len", ")", ":", "\n", "  ", "\"\"\"Index to one hot representation\n\n  Args:\n    length: type=torch.tensor(int), size=[batch]\n    max_len: type=int\n\n  Returns:\n    one_hot: type=torch.tensor(bool), size=[batch, max_len]\n\n  Note: \n    by default, `one_hot.dtype = ind.dtype`, and there is no constraint on \n    `ind.dtype`. So it is also possible to pass `ind` with float type \n  \"\"\"", "\n", "device", "=", "ind", ".", "device", "\n", "batch_size", "=", "ind", ".", "shape", "[", "0", "]", "\n", "one_hot", "=", "torch", ".", "arange", "(", "max_len", ",", "dtype", "=", "ind", ".", "dtype", ")", ".", "expand", "(", "batch_size", ",", "max_len", ")", ".", "to", "(", "device", ")", "==", "(", "ind", ")", ".", "unsqueeze", "(", "1", ")", "\n", "return", "one_hot", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.bow_to_one_hot": [[103, 124], ["bow.view().unsqueeze.view().unsqueeze", "one_hot.sum.view", "one_hot.sum.index_fill_", "one_hot.sum.sum", "bow.view().unsqueeze.view", "torch.tensor().to", "torch.tensor().to", "torch.arange().to().reshape", "torch.arange().to().reshape", "torch.tensor", "torch.tensor", "torch.arange().to", "torch.arange().to", "torch.arange", "torch.arange"], "function", ["None"], ["", "def", "bow_to_one_hot", "(", "bow", ",", "vocab_size", ",", "pad_id", "=", "0", ")", ":", "\n", "  ", "\"\"\"Bag of words to one hot representation\n\n  Args:\n    bow: type=torch.tensor(int), size=[batch, max_bow]\n    vocab_size: type=int\n    pad_id: type=int\n\n  Returns:\n    one_hot: type=torch.tensor(int), size=[batch, vocab_size]\n  \"\"\"", "\n", "device", "=", "bow", ".", "device", "\n", "batch_size", "=", "bow", ".", "shape", "[", "0", "]", "\n", "bow", "=", "bow", ".", "view", "(", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "# [batch * bow, 1]", "\n", "one_hot", "=", "(", "bow", "==", "torch", ".", "arange", "(", "vocab_size", ")", ".", "to", "(", "device", ")", ".", "reshape", "(", "1", ",", "vocab_size", ")", ")", ".", "float", "(", ")", "\n", "one_hot", "=", "one_hot", ".", "view", "(", "batch_size", ",", "-", "1", ",", "vocab_size", ")", "\n", "one_hot", ".", "index_fill_", "(", "\n", "dim", "=", "2", ",", "index", "=", "torch", ".", "tensor", "(", "[", "pad_id", "]", ")", ".", "to", "(", "device", ")", ",", "value", "=", "0", ")", "\n", "one_hot", "=", "one_hot", ".", "sum", "(", "dim", "=", "1", ")", "\n", "return", "one_hot", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.seq_to_lens": [[125, 137], ["None"], "function", ["None"], ["", "def", "seq_to_lens", "(", "seq", ",", "pad_id", "=", "0", ")", ":", "\n", "  ", "\"\"\"Calculate sequence length\n  \n  Args:\n    seq: type=torch.tensor(long), shape=[*, max_len]\n    pad_id: pad index. \n\n  Returns:\n    lens: type=torch.tensor(long), shape=[*]\n  \"\"\"", "\n", "lens", "=", "(", "seq", "!=", "pad_id", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", ".", "type", "(", "torch", ".", "long", ")", "\n", "return", "lens", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.find_index": [[138, 160], ["seq.size", "ind_.to().float.to().float", "torch.min", "torch.min", "index.long.long", "index.long.masked_fill_", "torch.arange().view", "torch.arange().view", "s_.sum", "ind_.to().float.to", "torch.arange", "torch.arange"], "function", ["None"], ["", "def", "find_index", "(", "seq", ",", "val", ")", ":", "\n", "  ", "\"\"\"Find the first location index of a value \n  if there is no such value, return -1\n  \n  Args:\n    seq: type=torch.tensor(long), shape=[batch, max_len]\n    val: type=int \n\n  Returns:\n    lens: type=torch.tensor(long), shape=[batch]\n  \"\"\"", "\n", "device", "=", "seq", ".", "device", "\n", "s_", "=", "(", "seq", "==", "val", ")", ".", "float", "(", ")", "\n", "seq_len", "=", "seq", ".", "size", "(", "-", "1", ")", "\n", "ind_", "=", "torch", ".", "arange", "(", "seq_len", ")", ".", "view", "(", "1", ",", "seq_len", ")", "+", "1", "\n", "ind_", "=", "ind_", ".", "to", "(", "device", ")", ".", "float", "(", ")", "\n", "s", "=", "(", "1", "-", "s_", ")", "*", "1e10", "+", "s_", "*", "ind_", "\n", "_", ",", "index", "=", "torch", ".", "min", "(", "s", ",", "dim", "=", "-", "1", ")", "\n", "index", "=", "index", ".", "long", "(", ")", "\n", "not_find", "=", "(", "s_", ".", "sum", "(", "-", "1", ")", "==", "0", ")", "\n", "index", ".", "masked_fill_", "(", "not_find", ",", "-", "1", ")", "\n", "return", "index", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.seq_ends": [[161, 176], ["torch_model_utils.find_index", "seq.size"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.find_index"], ["", "def", "seq_ends", "(", "seq", ",", "end_id", ")", ":", "\n", "  ", "\"\"\"Calculate where the sequence ends\n  if there is not end_id, return the last index \n  \n  Args:\n    seq: type=torch.tensor(long), shape=[batch, max_len]\n    end_id: end index. \n\n  Returns:\n    ends_at: type=torch.tensor(long), shape=[batch]\n  \"\"\"", "\n", "ends_at", "=", "find_index", "(", "seq", ",", "end_id", ")", "\n", "max_len", "=", "seq", ".", "size", "(", "1", ")", "-", "1", "\n", "ends_at", "[", "ends_at", "==", "-", "1", "]", "=", "max_len", "\n", "return", "ends_at", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.reverse_sequence": [[177, 206], ["seq.size", "seq.clone", "range", "list", "list.reverse", "range"], "function", ["None"], ["", "def", "reverse_sequence", "(", "seq", ",", "seq_lens", ")", ":", "\n", "  ", "\"\"\"Reverse the sequence\n\n  Examples:\n\n  seq = [[1, 2, 3, 4, 5], [6, 7 ,8, 9, 0]], seq_lens = [3, 4]\n  reverse_sequence(seq, seq_lens) = [[3, 2, 1, 4, 5], [9, 8, 7, 6, 0]]\n\n  seq = [[[1, 1], [2, 2], [3, 3], [4, 4], [5, 5]], \n         [[6, 6], [7, 7], [8, 8], [9, 9], [0, 0]]], \n  seq_lens = [3, 4]\n  reverse_sequence(seq, seq_lens) = \n    [[[3, 3], [2, 2], [1, 1], [4, 4], [5, 5]], \n     [[9, 9], [8, 8], [7, 7], [6, 6], [0, 0]]]\n  \n  Args: \n    seq: size=[batch, max_len, *]\n    seq_lens: size=[batch]\n\n  Returns:\n    reversed_seq\n  \"\"\"", "\n", "batch", "=", "seq", ".", "size", "(", "0", ")", "\n", "reversed_seq", "=", "seq", ".", "clone", "(", ")", "\n", "for", "i", "in", "range", "(", "batch", ")", ":", "\n", "    ", "ind", "=", "list", "(", "range", "(", "seq_lens", "[", "i", "]", ")", ")", "\n", "ind", ".", "reverse", "(", ")", "\n", "reversed_seq", "[", "i", ",", ":", "seq_lens", "[", "i", "]", "]", "=", "seq", "[", "i", ",", "ind", "]", "\n", "", "return", "reversed_seq", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.gather_last": [[207, 210], ["torch_model_utils.batch_index_select"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.batch_index_select"], ["", "def", "gather_last", "(", "seq", ",", "seq_lens", ")", ":", "\n", "  ", "\"\"\"Gather the last element of a given sequence\"\"\"", "\n", "return", "batch_index_select", "(", "seq", ",", "seq_lens", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.batch_index_select": [[211, 241], ["A.size", "A.size", "list", "A.clone().reshape", "A.size", "len", "torch.index_select().view", "torch.index_select().view", "ind.size", "batch_ind.view.view", "torch.index_select().view", "torch.index_select().view", "A.clone", "ind.size", "torch.index_select", "torch.index_select", "torch.index_select", "torch.index_select", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "function", ["None"], ["", "def", "batch_index_select", "(", "A", ",", "ind", ")", ":", "\n", "  ", "\"\"\"Batched index select\n  \n  Args:\n    A: size=[batch, num_class, *] \n    ind: size=[batch, num_select] or [batch]\n\n  Returns:\n    A_selected: size=[batch, num_select, *] or [batch, *]\n  \"\"\"", "\n", "batch_size", "=", "A", ".", "size", "(", "0", ")", "\n", "num_class", "=", "A", ".", "size", "(", "1", ")", "\n", "A_size", "=", "list", "(", "A", ".", "size", "(", ")", ")", "\n", "device", "=", "A", ".", "device", "\n", "A_", "=", "A", ".", "clone", "(", ")", ".", "reshape", "(", "batch_size", "*", "num_class", ",", "-", "1", ")", "\n", "if", "(", "len", "(", "ind", ".", "size", "(", ")", ")", "==", "1", ")", ":", "\n", "    ", "batch_ind", "=", "(", "torch", ".", "arange", "(", "batch_size", ")", "*", "num_class", ")", ".", "type", "(", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "ind_", "=", "ind", "+", "batch_ind", "\n", "A_selected", "=", "torch", ".", "index_select", "(", "A_", ",", "0", ",", "ind_", ")", ".", "view", "(", "[", "batch_size", "]", "+", "A_size", "[", "2", ":", "]", ")", "\n", "", "else", ":", "\n", "    ", "batch_ind", "=", "(", "torch", ".", "arange", "(", "batch_size", ")", "*", "num_class", ")", ".", "type", "(", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "num_select", "=", "ind", ".", "size", "(", "1", ")", "\n", "batch_ind", "=", "batch_ind", ".", "view", "(", "batch_size", ",", "1", ")", "\n", "ind_", "=", "(", "ind", "+", "batch_ind", ")", ".", "view", "(", "batch_size", "*", "num_select", ")", "\n", "A_selected", "=", "torch", ".", "index_select", "(", "A_", ",", "0", ",", "ind_", ")", ".", "view", "(", "[", "batch_size", ",", "num_select", "]", "+", "A_size", "[", "2", ":", "]", ")", "\n", "", "return", "A_selected", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.batch_index_put": [[242, 274], ["A.size", "A.size", "list", "torch.zeros().to", "torch.zeros().to", "ind_.expand().flatten().to.expand().flatten().to", "ind.flatten", "A.view", "A_put.view.view", "torch.arange().view", "torch.arange().view", "A.size", "torch.zeros", "torch.zeros", "ind_.expand().flatten().to.expand().flatten", "torch.arange", "torch.arange", "ind_.expand().flatten().to.expand"], "function", ["None"], ["", "def", "batch_index_put", "(", "A", ",", "ind", ",", "N", ")", ":", "\n", "  ", "\"\"\"distribute a batch of values to given locations\n\n  Example:\n    A = tensor([[0.1000, 0.9000],\n                [0.2000, 0.8000]])\n    ind = tensor([[1, 2],\n                  [0, 3]])\n    N = 5\n  then:\n    A_put = tensor([[0.0000, 0.1000, 0.9000, 0.0000, 0.0000],\n                    [0.2000, 0.0000, 0.0000, 0.8000, 0.0000]])\n\n  Args:\n    A: size=[batch, M, *], * can be any list of dimensions\n    ind: size=[batch, M]\n    N: type=int\n\n  Returns:\n    A_put: size=[batch, N, *]\n  \"\"\"", "\n", "batch_size", "=", "A", ".", "size", "(", "0", ")", "\n", "M", "=", "A", ".", "size", "(", "1", ")", "\n", "As", "=", "list", "(", "A", ".", "size", "(", ")", "[", "2", ":", "]", ")", "\n", "device", "=", "A", ".", "device", "\n", "A_put", "=", "torch", ".", "zeros", "(", "[", "batch_size", "*", "N", "]", "+", "As", ")", ".", "to", "(", "device", ")", "\n", "ind_", "=", "torch", ".", "arange", "(", "batch_size", ")", ".", "view", "(", "batch_size", ",", "1", ")", "*", "N", "\n", "ind_", "=", "ind_", ".", "expand", "(", "batch_size", ",", "M", ")", ".", "flatten", "(", ")", ".", "to", "(", "device", ")", "\n", "ind_", "+=", "ind", ".", "flatten", "(", ")", "\n", "A_put", "[", "ind_", "]", "+=", "A", ".", "view", "(", "[", "batch_size", "*", "M", "]", "+", "As", ")", "\n", "A_put", "=", "A_put", ".", "view", "(", "[", "batch_size", ",", "N", "]", "+", "As", ")", "\n", "return", "A_put", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.batch_repeat": [[275, 290], ["A.size", "list", "A.view", "A_.view.repeat", "A_.view.view", "A.size", "len"], "function", ["None"], ["", "def", "batch_repeat", "(", "A", ",", "n", ")", ":", "\n", "  ", "\"\"\"\n  Args:\n    A: size=[batch, *], * can be any list of dimensions\n    n: type=int\n\n  Returns:\n    A: size=[batch * n, *]\n  \"\"\"", "\n", "batch_size", "=", "A", ".", "size", "(", "0", ")", "\n", "As", "=", "list", "(", "A", ".", "size", "(", ")", "[", "1", ":", "]", ")", "\n", "A_", "=", "A", ".", "view", "(", "[", "batch_size", ",", "1", "]", "+", "As", ")", "\n", "A_", "=", "A_", ".", "repeat", "(", "[", "1", ",", "n", "]", "+", "[", "1", "]", "*", "len", "(", "As", ")", ")", "\n", "A_", "=", "A_", ".", "view", "(", "[", "batch_size", "*", "n", "]", "+", "As", ")", "\n", "return", "A_", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.sample_gumbel": [[291, 295], ["torch.rand", "torch.rand", "torch.log", "torch.log", "torch.log", "torch.log"], "function", ["None"], ["", "def", "sample_gumbel", "(", "shape", ",", "eps", "=", "1e-20", ")", ":", "\n", "  ", "\"\"\"Sample from a standard gumbel distribution\"\"\"", "\n", "U", "=", "torch", ".", "rand", "(", "shape", ")", "\n", "return", "-", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "U", "+", "eps", ")", "+", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.reparameterize_gumbel": [[296, 311], ["torch.softmax", "sample_gumbel().to", "torch_model_utils.sample_gumbel", "logits.size"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.sample_gumbel"], ["", "def", "reparameterize_gumbel", "(", "logits", ",", "tau", ")", ":", "\n", "  ", "\"\"\"Reparameterize gumbel sampling\n\n  Note: gumbel reparameterization will give you sample no matter tau. tau just \n  controls how close the sample is to one-hot \n  \n  Args: \n    logits: shape=[*, vocab_size]\n    tau: the temperature, typically start from 1.0 and anneal to 0.01\n\n  Returns:\n    y: shape=[*, vocab_size]\n  \"\"\"", "\n", "y", "=", "logits", "+", "sample_gumbel", "(", "logits", ".", "size", "(", ")", ")", ".", "to", "(", "logits", ".", "device", ")", "\n", "return", "F", ".", "softmax", "(", "y", "/", "tau", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.seq_gumbel_encode": [[312, 346], ["sample.size", "sample.size", "sample.size", "embeddings", "torch_model_utils.ind_to_one_hot", "sample_one_hot.view.view", "sample.masked_select", "sample_soft.view.view", "torch.matmul", "torch.matmul", "sample_emb.view.size", "sample_emb.view.view", "sample_ids.view", "sample.view"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.ind_to_one_hot"], ["", "def", "seq_gumbel_encode", "(", "sample", ",", "sample_ids", ",", "embeddings", ",", "gumbel_st", ")", ":", "\n", "  ", "\"\"\"Encoding of gumbel sample. Given a sequence of relaxed one-hot \n  representations, return a sequence of corresponding embeddings\n\n  TODO: drop `probs`, only use `sample`\n\n  Args:\n    sample: type=torch.tensor(torch.float), shape=[batch, max_len, vocab_size]\n    sample_ids: type=torch.tensor(torch.long), shape=[batch, max_len]\n    embeddings: type=torch.nn.Embeddings\n    gumbel_st: type=bool, if use gumbel straight through estimator\n  \"\"\"", "\n", "batch_size", "=", "sample", ".", "size", "(", "0", ")", "\n", "max_len", "=", "sample", ".", "size", "(", "1", ")", "\n", "vocab_size", "=", "sample", ".", "size", "(", "2", ")", "\n", "if", "(", "gumbel_st", ")", ":", "\n", "# straight-through version, to avoid training-inference gap ", "\n", "    ", "sample_emb", "=", "embeddings", "(", "sample_ids", ")", "\n", "sample_one_hot", "=", "ind_to_one_hot", "(", "\n", "sample_ids", ".", "view", "(", "-", "1", ")", ",", "vocab_size", ")", "\n", "sample_one_hot", "=", "sample_one_hot", ".", "view", "(", "batch_size", ",", "max_len", ",", "vocab_size", ")", "\n", "sample_soft", "=", "sample", ".", "masked_select", "(", "sample_one_hot", ")", "\n", "sample_soft", "=", "sample_soft", ".", "view", "(", "batch_size", ",", "max_len", ",", "1", ")", "\n", "sample_emb", "*=", "(", "1", "-", "sample_soft", ")", ".", "detach", "(", ")", "+", "sample_soft", "\n", "", "else", ":", "\n", "# original version, requires annealing in the end of training", "\n", "    ", "sample_emb", "=", "torch", ".", "matmul", "(", "\n", "sample", ".", "view", "(", "-", "1", ",", "vocab_size", ")", ",", "embeddings", ".", "weight", ")", "\n", "embedding_size", "=", "sample_emb", ".", "size", "(", "-", "1", ")", "\n", "# [batch * max_len, embedding_size] -> [batch, max_len, embedding_size]", "\n", "sample_emb", "=", "sample_emb", ".", "view", "(", "\n", "batch_size", ",", "max_len", ",", "embedding_size", ")", "\n", "", "return", "sample_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.reparameterize_gaussian": [[347, 352], ["torch.exp", "torch.exp", "torch.randn_like", "torch.randn_like"], "function", ["None"], ["", "def", "reparameterize_gaussian", "(", "mu", ",", "logvar", ")", ":", "\n", "  ", "\"\"\"Reparameterize the gaussian sample\"\"\"", "\n", "std", "=", "torch", ".", "exp", "(", "0.5", "*", "logvar", ")", "\n", "eps", "=", "torch", ".", "randn_like", "(", "std", ")", "\n", "return", "mu", "+", "eps", "*", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.entropy": [[353, 362], ["ent.mean", "torch.log", "torch.log"], "function", ["None"], ["", "def", "entropy", "(", "p", ",", "eps", "=", "1e-10", ",", "keepdim", "=", "False", ")", ":", "\n", "  ", "\"\"\"Calculate the entropy of a discrete distribution\n  \n  Args: \n    p: shape = [*, support_size]\n  \"\"\"", "\n", "ent", "=", "(", "-", "p", "*", "torch", ".", "log", "(", "p", "+", "eps", ")", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "if", "(", "keepdim", ")", ":", "return", "ent", "\n", "else", ":", "return", "ent", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.kl_divergence": [[364, 374], ["kld.sum.sum", "torch.log", "torch.log"], "function", ["None"], ["", "def", "kl_divergence", "(", "p0", ",", "p1", ",", "eps", "=", "1e-10", ")", ":", "\n", "  ", "\"\"\"Calculate the kl divergence between two distributions\n\n  Args: \n    p0: size=[*, support_size]\n    p1: size=[*, support_size]\n  \"\"\"", "\n", "kld", "=", "p0", "*", "torch", ".", "log", "(", "p0", "/", "(", "p1", "+", "eps", ")", "+", "eps", ")", "\n", "kld", "=", "kld", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "return", "kld", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.js_divergence": [[375, 385], ["torch_model_utils.kl_divergence", "torch_model_utils.kl_divergence"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.kl_divergence", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.kl_divergence"], ["", "def", "js_divergence", "(", "p0", ",", "p1", ")", ":", "\n", "  ", "\"\"\"Calculate the Jensen-Shannon divergence between two distributions\n  \n  Args: \n    p0: size=[*, support_size]\n    p1: size=[*, support_size]\n  \"\"\"", "\n", "p_", "=", "(", "p0", "+", "p1", ")", "/", "2", "\n", "jsd", "=", "(", "kl_divergence", "(", "p0", ",", "p_", ")", "+", "kl_divergence", "(", "p1", ",", "p_", ")", ")", "/", "2", "\n", "return", "jsd", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.load_partial_state_dict": [[386, 410], ["print", "model.state_dict", "set", "state_dict.items", "print", "model.state_dict.keys", "isinstance", "print", "set", "own_state[].copy_", "print", "print", "len"], "function", ["None"], ["", "def", "load_partial_state_dict", "(", "model", ",", "state_dict", ")", ":", "\n", "  ", "\"\"\"Load part of the model\n\n  NOTE: NEED TESTING!!!\n\n  Args:\n    model: the model \n    state_dict: partial state dict\n  \"\"\"", "\n", "print", "(", "'Loading partial state dict ... '", ")", "\n", "own_state", "=", "model", ".", "state_dict", "(", ")", "\n", "own_params", "=", "set", "(", "own_state", ".", "keys", "(", ")", ")", "\n", "for", "name", ",", "param", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "    ", "if", "name", "not", "in", "own_state", ":", "\n", "      ", "print", "(", "'%s passed'", "%", "name", ")", "\n", "continue", "\n", "", "if", "isinstance", "(", "param", ",", "Parameter", ")", ":", "\n", "# backwards compatibility for serialized parameters", "\n", "      ", "param", "=", "param", ".", "data", "\n", "", "print", "(", "'loading: %s '", "%", "name", ")", "\n", "own_params", "-=", "set", "(", "name", ")", "\n", "own_state", "[", "name", "]", ".", "copy_", "(", "param", ")", "\n", "", "print", "(", "'%d parameters not initialized: '", "%", "len", "(", "own_params", ")", ")", "\n", "for", "n", "in", "own_params", ":", "print", "(", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.print_params": [[411, 416], ["model.named_parameters", "print"], "function", ["None"], ["", "def", "print_params", "(", "model", ")", ":", "\n", "  ", "\"\"\"Print the model parameters\"\"\"", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "     ", "print", "(", "'  '", ",", "name", ",", "param", ".", "data", ".", "shape", ",", "'requires_grad'", ",", "param", ".", "requires_grad", ")", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.print_grad": [[417, 428], ["torch_model_utils.print_grad_first_level", "torch_model_utils.print_grad_second_level", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.print_grad_first_level", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.print_grad_second_level"], ["", "def", "print_grad", "(", "model", ",", "level", "=", "'first'", ")", ":", "\n", "  ", "\"\"\"Print the gradient norm and std, for inspect training\n\n  Note: the variance of gradient printed here is not the variance of a gradient \n  estimator\n  \"\"\"", "\n", "if", "(", "level", "==", "'first'", ")", ":", "print_grad_first_level", "(", "model", ")", "\n", "elif", "(", "level", "==", "'second'", ")", ":", "print_grad_second_level", "(", "model", ")", "\n", "else", ":", "\n", "    ", "raise", "NotImplementedError", "(", "\n", "'higher level gradient inpection not implemented!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.print_grad_first_level": [[429, 457], ["print", "collections.OrderedDict", "collections.OrderedDict", "model.named_parameters", "print", "name.split", "isinstance", "grad_norms[].append", "grad_std[].append", "print", "torch_model_utils.to_np", "torch_model_utils.to_np", "numpy.average", "numpy.average", "param.grad.norm", "param.grad.var"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.to_np", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.to_np"], ["", "", "def", "print_grad_first_level", "(", "model", ")", ":", "\n", "  ", "\"\"\"Print the gradient norm of model parameters, up to the first level name \n  hierarchy \n  \"\"\"", "\n", "print", "(", "'gradient of the model parameters:'", ")", "\n", "\n", "grad_norms", "=", "OrderedDict", "(", ")", "\n", "grad_std", "=", "OrderedDict", "(", ")", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "    ", "splitted_name", "=", "name", ".", "split", "(", "'.'", ")", "\n", "first_level_name", "=", "splitted_name", "[", "0", "]", "\n", "\n", "if", "(", "first_level_name", "not", "in", "grad_norms", ")", ":", "\n", "      ", "grad_norms", "[", "first_level_name", "]", "=", "[", "]", "\n", "grad_std", "[", "first_level_name", "]", "=", "[", "]", "\n", "\n", "", "if", "(", "param", ".", "requires_grad", "and", "param", ".", "grad", "is", "not", "None", ")", ":", "\n", "      ", "grad_norms", "[", "first_level_name", "]", ".", "append", "(", "\n", "to_np", "(", "param", ".", "grad", ".", "norm", "(", ")", ")", ")", "\n", "grad_std", "[", "first_level_name", "]", ".", "append", "(", "\n", "to_np", "(", "param", ".", "grad", ".", "var", "(", "unbiased", "=", "False", ")", ")", ")", "\n", "\n", "", "", "for", "fn", "in", "grad_norms", ":", "\n", "    ", "if", "(", "isinstance", "(", "grad_norms", "[", "fn", "]", ",", "list", ")", ")", ":", "\n", "      ", "print", "(", "fn", ",", "np", ".", "average", "(", "grad_norms", "[", "fn", "]", ")", ",", "np", ".", "average", "(", "grad_std", "[", "fn", "]", ")", ")", "\n", "\n", "", "", "print", "(", "''", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.print_grad_second_level": [[458, 509], ["print", "collections.OrderedDict", "collections.OrderedDict", "model.named_parameters", "print", "print", "name.split", "collections.OrderedDict.keys", "isinstance", "len", "print", "len", "len", "grad_norms[].append", "grad_std[].append", "[].append", "[].append", "numpy.average", "numpy.average", "print", "param.grad.norm().detach().cpu().numpy", "param.grad.std().detach().cpu().numpy", "param.grad.norm().detach().cpu().numpy", "param.grad.std().detach().cpu().numpy", "numpy.average", "numpy.average", "param.grad.norm().detach().cpu", "param.grad.std().detach().cpu", "param.grad.norm().detach().cpu", "param.grad.std().detach().cpu", "param.grad.norm().detach", "param.grad.std().detach", "param.grad.norm().detach", "param.grad.std().detach", "param.grad.norm", "param.grad.std", "param.grad.norm", "param.grad.std"], "function", ["None"], ["", "def", "print_grad_second_level", "(", "model", ")", ":", "\n", "  ", "\"\"\"Print the gradient norm of model parameters, up to the second level name \n  hierarchy \n  \"\"\"", "\n", "print", "(", "'gradient of the model parameters:'", ")", "\n", "\n", "grad_norms", "=", "OrderedDict", "(", ")", "\n", "grad_std", "=", "OrderedDict", "(", ")", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "    ", "splitted_name", "=", "name", ".", "split", "(", "'.'", ")", "\n", "first_level_name", "=", "splitted_name", "[", "0", "]", "\n", "\n", "if", "(", "first_level_name", "not", "in", "grad_norms", ")", ":", "\n", "      ", "if", "(", "len", "(", "splitted_name", ")", "==", "1", ")", ":", "\n", "        ", "grad_norms", "[", "first_level_name", "]", "=", "[", "]", "\n", "grad_std", "[", "first_level_name", "]", "=", "[", "]", "\n", "", "else", ":", "\n", "        ", "grad_norms", "[", "first_level_name", "]", "=", "{", "}", "\n", "grad_std", "[", "first_level_name", "]", "=", "{", "}", "\n", "\n", "", "", "if", "(", "len", "(", "splitted_name", ")", ">", "1", ")", ":", "\n", "      ", "second_level_name", "=", "splitted_name", "[", "1", "]", "\n", "if", "(", "second_level_name", "not", "in", "grad_norms", "[", "first_level_name", "]", ")", ":", "\n", "        ", "grad_norms", "[", "first_level_name", "]", "[", "second_level_name", "]", "=", "[", "]", "\n", "grad_std", "[", "first_level_name", "]", "[", "second_level_name", "]", "=", "[", "]", "\n", "\n", "", "", "if", "(", "param", ".", "requires_grad", "and", "param", ".", "grad", "is", "not", "None", ")", ":", "\n", "      ", "if", "(", "len", "(", "splitted_name", ")", "==", "1", ")", ":", "\n", "        ", "grad_norms", "[", "first_level_name", "]", ".", "append", "(", "\n", "param", ".", "grad", ".", "norm", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "grad_std", "[", "first_level_name", "]", ".", "append", "(", "\n", "param", ".", "grad", ".", "std", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "grad_norms", "[", "first_level_name", "]", "[", "second_level_name", "]", ".", "append", "(", "\n", "param", ".", "grad", ".", "norm", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "grad_std", "[", "first_level_name", "]", "[", "second_level_name", "]", ".", "append", "(", "\n", "param", ".", "grad", ".", "std", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "", "print", "(", "grad_norms", ".", "keys", "(", ")", ")", "\n", "for", "fn", "in", "grad_norms", ":", "\n", "    ", "if", "(", "isinstance", "(", "grad_norms", "[", "fn", "]", ",", "list", ")", ")", ":", "\n", "      ", "print", "(", "fn", ",", "np", ".", "average", "(", "grad_norms", "[", "fn", "]", ")", ",", "\n", "np", ".", "average", "(", "grad_std", "[", "fn", "]", ")", ")", "\n", "", "else", ":", "\n", "      ", "for", "sn", "in", "grad_norms", "[", "fn", "]", ":", "\n", "        ", "print", "(", "fn", ",", "sn", ",", "\n", "np", ".", "average", "(", "grad_norms", "[", "fn", "]", "[", "sn", "]", ")", ",", "\n", "np", ".", "average", "(", "grad_std", "[", "fn", "]", "[", "sn", "]", ")", ")", "\n", "\n", "", "", "", "print", "(", "''", ")", "\n", "return", "\n", "", ""]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_crf_inferencer.LinearCRF.__init__": [[10, 33], ["torch.Module.__init__", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.Parameter", "torch.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.instance.Instance.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "print_info", ":", "bool", "=", "True", ")", ":", "\n", "        ", "super", "(", "LinearCRF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "label_size", "=", "config", ".", "label_size", "\n", "self", ".", "device", "=", "config", ".", "device", "\n", "self", ".", "use_char", "=", "config", ".", "use_char_rnn", "\n", "self", ".", "context_emb", "=", "config", ".", "context_emb", "\n", "\n", "self", ".", "label2idx", "=", "config", ".", "label2idx", "\n", "self", ".", "labels", "=", "config", ".", "idx2labels", "\n", "self", ".", "start_idx", "=", "self", ".", "label2idx", "[", "START", "]", "\n", "self", ".", "end_idx", "=", "self", ".", "label2idx", "[", "STOP", "]", "\n", "self", ".", "pad_idx", "=", "self", ".", "label2idx", "[", "PAD", "]", "\n", "\n", "# initialize the following transition (anything never -> start. end never -> anything. Same thing for the padding label)", "\n", "init_transition", "=", "torch", ".", "randn", "(", "self", ".", "label_size", ",", "self", ".", "label_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "init_transition", "[", ":", ",", "self", ".", "start_idx", "]", "=", "-", "10000.0", "\n", "init_transition", "[", "self", ".", "end_idx", ",", ":", "]", "=", "-", "10000.0", "\n", "init_transition", "[", ":", ",", "self", ".", "pad_idx", "]", "=", "-", "10000.0", "\n", "init_transition", "[", "self", ".", "pad_idx", ",", ":", "]", "=", "-", "10000.0", "\n", "\n", "self", ".", "transition", "=", "nn", ".", "Parameter", "(", "init_transition", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_crf_inferencer.LinearCRF.forward": [[34, 48], ["linear_crf_inferencer.LinearCRF.calculate_all_scores", "linear_crf_inferencer.LinearCRF.forward_unlabeled", "linear_crf_inferencer.LinearCRF.forward_labeled"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.calculate_all_scores", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.forward_unlabeled", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.forward_labeled"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "lstm_scores", ",", "word_seq_lens", ",", "tags", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        Calculate the negative log-likelihood\n        :param lstm_scores:\n        :param word_seq_lens:\n        :param tags:\n        :param mask:\n        :return:\n        \"\"\"", "\n", "all_scores", "=", "self", ".", "calculate_all_scores", "(", "lstm_scores", "=", "lstm_scores", ")", "\n", "unlabed_score", "=", "self", ".", "forward_unlabeled", "(", "all_scores", ",", "word_seq_lens", ")", "\n", "labeled_score", "=", "self", ".", "forward_labeled", "(", "all_scores", ",", "word_seq_lens", ",", "tags", ",", "mask", ")", "\n", "return", "unlabed_score", ",", "labeled_score", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_crf_inferencer.LinearCRF.forward_unlabeled": [[49, 73], ["all_scores.size", "all_scores.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "linear_crf_inferencer.LinearCRF.transition[].view().expand", "config.log_sum_exp_pytorch().view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "config.log_sum_exp_pytorch", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "alpha[].view().expand", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "linear_crf_inferencer.LinearCRF.transition[].view", "config.log_sum_exp_pytorch", "config.log_sum_exp_pytorch().view.view", "alpha[].view", "word_seq_lens.view().expand", "word_seq_lens.view"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.log_sum_exp_pytorch", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.log_sum_exp_pytorch"], ["", "def", "forward_unlabeled", "(", "self", ",", "all_scores", ":", "torch", ".", "Tensor", ",", "word_seq_lens", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Calculate the scores with the forward algorithm. Basically calculating the normalization term\n        :param all_scores: (batch_size x max_seq_len x num_labels x num_labels) from (lstm scores + transition scores).\n        :param word_seq_lens: (batch_size)\n        :return: (batch_size) for the normalization scores\n        \"\"\"", "\n", "batch_size", "=", "all_scores", ".", "size", "(", "0", ")", "\n", "seq_len", "=", "all_scores", ".", "size", "(", "1", ")", "\n", "alpha", "=", "torch", ".", "zeros", "(", "batch_size", ",", "seq_len", ",", "self", ".", "label_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "alpha", "[", ":", ",", "0", ",", ":", "]", "=", "all_scores", "[", ":", ",", "0", ",", "self", ".", "start_idx", ",", ":", "]", "## the first position of all labels = (the transition from start - > all labels) + current emission.", "\n", "\n", "for", "word_idx", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "## batch_size, self.label_size, self.label_size", "\n", "            ", "before_log_sum_exp", "=", "alpha", "[", ":", ",", "word_idx", "-", "1", ",", ":", "]", ".", "view", "(", "batch_size", ",", "self", ".", "label_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "self", ".", "label_size", ",", "self", ".", "label_size", ")", "+", "all_scores", "[", ":", ",", "word_idx", ",", ":", ",", ":", "]", "\n", "alpha", "[", ":", ",", "word_idx", ",", ":", "]", "=", "log_sum_exp_pytorch", "(", "before_log_sum_exp", ")", "\n", "\n", "### batch_size x label_size", "\n", "", "last_alpha", "=", "torch", ".", "gather", "(", "alpha", ",", "1", ",", "word_seq_lens", ".", "view", "(", "batch_size", ",", "1", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "1", ",", "self", ".", "label_size", ")", "-", "1", ")", ".", "view", "(", "batch_size", ",", "self", ".", "label_size", ")", "\n", "last_alpha", "+=", "self", ".", "transition", "[", ":", ",", "self", ".", "end_idx", "]", ".", "view", "(", "1", ",", "self", ".", "label_size", ")", ".", "expand", "(", "batch_size", ",", "self", ".", "label_size", ")", "\n", "last_alpha", "=", "log_sum_exp_pytorch", "(", "last_alpha", ".", "view", "(", "batch_size", ",", "self", ".", "label_size", ",", "1", ")", ")", ".", "view", "(", "batch_size", ")", "\n", "\n", "return", "torch", ".", "sum", "(", "last_alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_crf_inferencer.LinearCRF.forward_labeled": [[74, 97], ["torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "word_seq_lens.view", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather().view.masked_select", "torch.gather().view.masked_select", "tags.view().expand", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "linear_crf_inferencer.LinearCRF.transition[].view().expand", "tags[].view", "tags.view", "linear_crf_inferencer.LinearCRF.transition[].view"], "methods", ["None"], ["", "def", "forward_labeled", "(", "self", ",", "all_scores", ":", "torch", ".", "Tensor", ",", "word_seq_lens", ":", "torch", ".", "Tensor", ",", "tags", ":", "torch", ".", "Tensor", ",", "masks", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "'''\n        Calculate the scores for the gold instances.\n        :param all_scores: (batch, seq_len, label_size, label_size)\n        :param word_seq_lens: (batch, seq_len)\n        :param tags: (batch, seq_len)\n        :param masks: batch, seq_len\n        :return: sum of score for the gold sequences Shape: (batch_size)\n        '''", "\n", "batchSize", "=", "all_scores", ".", "shape", "[", "0", "]", "\n", "sentLength", "=", "all_scores", ".", "shape", "[", "1", "]", "\n", "\n", "## all the scores to current labels: batch, seq_len, all_from_label?", "\n", "currentTagScores", "=", "torch", ".", "gather", "(", "all_scores", ",", "3", ",", "tags", ".", "view", "(", "batchSize", ",", "sentLength", ",", "1", ",", "1", ")", ".", "expand", "(", "batchSize", ",", "sentLength", ",", "self", ".", "label_size", ",", "1", ")", ")", ".", "view", "(", "batchSize", ",", "-", "1", ",", "self", ".", "label_size", ")", "\n", "if", "sentLength", "!=", "1", ":", "\n", "            ", "tagTransScoresMiddle", "=", "torch", ".", "gather", "(", "currentTagScores", "[", ":", ",", "1", ":", ",", ":", "]", ",", "2", ",", "tags", "[", ":", ",", ":", "sentLength", "-", "1", "]", ".", "view", "(", "batchSize", ",", "sentLength", "-", "1", ",", "1", ")", ")", ".", "view", "(", "batchSize", ",", "-", "1", ")", "\n", "", "tagTransScoresBegin", "=", "currentTagScores", "[", ":", ",", "0", ",", "self", ".", "start_idx", "]", "\n", "endTagIds", "=", "torch", ".", "gather", "(", "tags", ",", "1", ",", "word_seq_lens", ".", "view", "(", "batchSize", ",", "1", ")", "-", "1", ")", "\n", "tagTransScoresEnd", "=", "torch", ".", "gather", "(", "self", ".", "transition", "[", ":", ",", "self", ".", "end_idx", "]", ".", "view", "(", "1", ",", "self", ".", "label_size", ")", ".", "expand", "(", "batchSize", ",", "self", ".", "label_size", ")", ",", "1", ",", "endTagIds", ")", ".", "view", "(", "batchSize", ")", "\n", "score", "=", "torch", ".", "sum", "(", "tagTransScoresBegin", ")", "+", "torch", ".", "sum", "(", "tagTransScoresEnd", ")", "\n", "if", "sentLength", "!=", "1", ":", "\n", "            ", "score", "+=", "torch", ".", "sum", "(", "tagTransScoresMiddle", ".", "masked_select", "(", "masks", "[", ":", ",", "1", ":", "]", ")", ")", "\n", "", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_crf_inferencer.LinearCRF.calculate_all_scores": [[98, 111], ["lstm_scores.size", "lstm_scores.size", "linear_crf_inferencer.LinearCRF.transition.view().expand", "lstm_scores.view().expand", "linear_crf_inferencer.LinearCRF.transition.view", "lstm_scores.view"], "methods", ["None"], ["", "def", "calculate_all_scores", "(", "self", ",", "lstm_scores", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Calculate all scores by adding up the transition scores and emissions (from lstm).\n        Basically, compute the scores for each edges between labels at adjacent positions.\n        This score is later be used for forward-backward inference\n        :param lstm_scores: emission scores.\n        :return:\n        \"\"\"", "\n", "batch_size", "=", "lstm_scores", ".", "size", "(", "0", ")", "\n", "seq_len", "=", "lstm_scores", ".", "size", "(", "1", ")", "\n", "scores", "=", "self", ".", "transition", ".", "view", "(", "1", ",", "1", ",", "self", ".", "label_size", ",", "self", ".", "label_size", ")", ".", "expand", "(", "batch_size", ",", "seq_len", ",", "self", ".", "label_size", ",", "self", ".", "label_size", ")", "+", "lstm_scores", ".", "view", "(", "batch_size", ",", "seq_len", ",", "1", ",", "self", ".", "label_size", ")", ".", "expand", "(", "batch_size", ",", "seq_len", ",", "self", ".", "label_size", ",", "self", ".", "label_size", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_crf_inferencer.LinearCRF.decode": [[112, 121], ["linear_crf_inferencer.LinearCRF.calculate_all_scores", "linear_crf_inferencer.LinearCRF.constrainted_viterbi_decode"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.calculate_all_scores", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.constrainted_viterbi_decode"], ["", "def", "decode", "(", "self", ",", "features", ",", "wordSeqLengths", ",", "annotation_mask", "=", "None", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Decode the batch input\n        :param batchInput:\n        :return:\n        \"\"\"", "\n", "all_scores", "=", "self", ".", "calculate_all_scores", "(", "features", ")", "\n", "bestScores", ",", "decodeIdx", "=", "self", ".", "constrainted_viterbi_decode", "(", "all_scores", ",", "wordSeqLengths", ",", "annotation_mask", ")", "\n", "return", "bestScores", ",", "decodeIdx", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_crf_inferencer.LinearCRF.constrainted_viterbi_decode": [[122, 167], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.ones_like().to", "torch.ones_like().to", "torch.ones_like().to", "torch.ones_like().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "range", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "linear_crf_inferencer.LinearCRF.transition[].view().expand", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "range", "annotation_mask.float().log.float().log.float().log", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "decodeIdx[].view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.full", "torch.full", "torch.full", "torch.full", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "scoresRecord[].view().expand", "annotation_mask[].view().expand", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "linear_crf_inferencer.LinearCRF.transition[].view", "annotation_mask.float().log.float().log.float", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "scoresRecord[].view", "annotation_mask[].view", "idxRecord[].view", "word_seq_lens.view().expand", "torch.where().view().expand", "torch.where().view().expand", "torch.where().view().expand", "torch.where().view().expand", "decodeIdx[].view", "word_seq_lens.view", "torch.where().view", "torch.where().view", "torch.where().view", "torch.where().view", "torch.where", "torch.where", "torch.where", "torch.where"], "methods", ["None"], ["", "def", "constrainted_viterbi_decode", "(", "self", ",", "all_scores", ":", "torch", ".", "Tensor", ",", "word_seq_lens", ":", "torch", ".", "Tensor", ",", "annotation_mask", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Use viterbi to decode the instances given the scores and transition parameters\n        :param all_scores: (batch_size x max_seq_len x num_labels x num_labels)\n        :param word_seq_lens: (batch_size)\n        :return: the best scores as well as the predicted label ids.\n               (batch_size) and (batch_size x max_seq_len)\n        \"\"\"", "\n", "\n", "batchSize", "=", "all_scores", ".", "shape", "[", "0", "]", "\n", "sentLength", "=", "all_scores", ".", "shape", "[", "1", "]", "\n", "if", "annotation_mask", "is", "not", "None", ":", "\n", "            ", "annotation_mask", "=", "annotation_mask", ".", "float", "(", ")", ".", "log", "(", ")", "\n", "\n", "", "scoresRecord", "=", "torch", ".", "zeros", "(", "[", "batchSize", ",", "sentLength", ",", "self", ".", "label_size", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "idxRecord", "=", "torch", ".", "zeros", "(", "[", "batchSize", ",", "sentLength", ",", "self", ".", "label_size", "]", ",", "dtype", "=", "torch", ".", "int64", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "mask", "=", "torch", ".", "ones_like", "(", "word_seq_lens", ",", "dtype", "=", "torch", ".", "int64", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "startIds", "=", "torch", ".", "full", "(", "(", "batchSize", ",", "self", ".", "label_size", ")", ",", "self", ".", "start_idx", ",", "dtype", "=", "torch", ".", "int64", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "decodeIdx", "=", "torch", ".", "LongTensor", "(", "batchSize", ",", "sentLength", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "scores", "=", "all_scores", "\n", "scoresRecord", "[", ":", ",", "0", ",", ":", "]", "=", "scores", "[", ":", ",", "0", ",", "self", ".", "start_idx", ",", ":", "]", "## represent the best current score from the start, is the best", "\n", "if", "annotation_mask", "is", "not", "None", ":", "\n", "            ", "scoresRecord", "[", ":", ",", "0", ",", ":", "]", "+=", "annotation_mask", "[", ":", ",", "0", ",", ":", "]", "\n", "", "idxRecord", "[", ":", ",", "0", ",", ":", "]", "=", "startIds", "\n", "for", "wordIdx", "in", "range", "(", "1", ",", "sentLength", ")", ":", "\n", "### scoresIdx: batch x from_label x to_label at current index.", "\n", "            ", "scoresIdx", "=", "scoresRecord", "[", ":", ",", "wordIdx", "-", "1", ",", ":", "]", ".", "view", "(", "batchSize", ",", "self", ".", "label_size", ",", "1", ")", ".", "expand", "(", "batchSize", ",", "self", ".", "label_size", ",", "\n", "self", ".", "label_size", ")", "+", "scores", "[", ":", ",", "wordIdx", ",", ":", ",", ":", "]", "\n", "if", "annotation_mask", "is", "not", "None", ":", "\n", "                ", "scoresIdx", "+=", "annotation_mask", "[", ":", ",", "wordIdx", ",", ":", "]", ".", "view", "(", "batchSize", ",", "1", ",", "self", ".", "label_size", ")", ".", "expand", "(", "batchSize", ",", "self", ".", "label_size", ",", "self", ".", "label_size", ")", "\n", "\n", "", "idxRecord", "[", ":", ",", "wordIdx", ",", ":", "]", "=", "torch", ".", "argmax", "(", "scoresIdx", ",", "1", ")", "## the best previous label idx to crrent labels", "\n", "scoresRecord", "[", ":", ",", "wordIdx", ",", ":", "]", "=", "torch", ".", "gather", "(", "scoresIdx", ",", "1", ",", "idxRecord", "[", ":", ",", "wordIdx", ",", ":", "]", ".", "view", "(", "batchSize", ",", "1", ",", "self", ".", "label_size", ")", ")", ".", "view", "(", "batchSize", ",", "self", ".", "label_size", ")", "\n", "\n", "", "lastScores", "=", "torch", ".", "gather", "(", "scoresRecord", ",", "1", ",", "word_seq_lens", ".", "view", "(", "batchSize", ",", "1", ",", "1", ")", ".", "expand", "(", "batchSize", ",", "1", ",", "self", ".", "label_size", ")", "-", "1", ")", ".", "view", "(", "batchSize", ",", "self", ".", "label_size", ")", "##select position", "\n", "lastScores", "+=", "self", ".", "transition", "[", ":", ",", "self", ".", "end_idx", "]", ".", "view", "(", "1", ",", "self", ".", "label_size", ")", ".", "expand", "(", "batchSize", ",", "self", ".", "label_size", ")", "\n", "decodeIdx", "[", ":", ",", "0", "]", "=", "torch", ".", "argmax", "(", "lastScores", ",", "1", ")", "\n", "bestScores", "=", "torch", ".", "gather", "(", "lastScores", ",", "1", ",", "decodeIdx", "[", ":", ",", "0", "]", ".", "view", "(", "batchSize", ",", "1", ")", ")", "\n", "\n", "for", "distance2Last", "in", "range", "(", "sentLength", "-", "1", ")", ":", "\n", "            ", "lastNIdxRecord", "=", "torch", ".", "gather", "(", "idxRecord", ",", "1", ",", "torch", ".", "where", "(", "word_seq_lens", "-", "distance2Last", "-", "1", ">", "0", ",", "word_seq_lens", "-", "distance2Last", "-", "1", ",", "mask", ")", ".", "view", "(", "batchSize", ",", "1", ",", "1", ")", ".", "expand", "(", "batchSize", ",", "1", ",", "self", ".", "label_size", ")", ")", ".", "view", "(", "batchSize", ",", "self", ".", "label_size", ")", "\n", "decodeIdx", "[", ":", ",", "distance2Last", "+", "1", "]", "=", "torch", ".", "gather", "(", "lastNIdxRecord", ",", "1", ",", "decodeIdx", "[", ":", ",", "distance2Last", "]", ".", "view", "(", "batchSize", ",", "1", ")", ")", ".", "view", "(", "batchSize", ")", "\n", "\n", "", "return", "bestScores", ",", "decodeIdx", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_local.NNCRF_sl.__init__": [[89, 109], ["torch.Module.__init__", "model.bilstm_encoder.BiLSTMEncoder", "model.linear_partial_crf_inferencer.LinearCRF", "neuralcrf_small_loss_constrain_local.gen_dic", "len", "neuralcrf_small_loss_constrain_local.gen_embedding_table", "torch.nn.Embedding().from_pretrained().cuda", "torch.nn.Embedding().from_pretrained().cuda", "torch.nn.Embedding().from_pretrained().cuda", "torch.nn.Embedding().from_pretrained().cuda", "torch.nn.Embedding().from_pretrained().cuda", "torch.nn.Embedding().from_pretrained().cuda", "torch.nn.Embedding().from_pretrained().cuda", "torch.nn.Embedding().from_pretrained().cuda", "config.label2idx.keys", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding().from_pretrained", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.instance.Instance.__init__", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_local.gen_dic", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_local.gen_embedding_table"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "print_info", ":", "bool", "=", "True", ")", ":", "\n", "        ", "super", "(", "NNCRF_sl", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "device", "=", "config", ".", "device", "\n", "self", ".", "encoder", "=", "BiLSTMEncoder", "(", "config", ",", "print_info", "=", "print_info", ")", "\n", "self", ".", "inferencer", "=", "LinearCRF", "(", "config", ",", "print_info", "=", "print_info", ")", "\n", "self", ".", "label2idx", "=", "config", ".", "label2idx", "\n", "self", ".", "idx2word", "=", "config", ".", "idx2word", "\n", "self", ".", "idx2labels", "=", "config", ".", "idx2labels", "\n", "self", ".", "Oid", "=", "self", ".", "label2idx", "[", "'O'", "]", "\n", "self", ".", "padid", "=", "self", ".", "label2idx", "[", "'<PAD>'", "]", "\n", "self", ".", "startid", "=", "self", ".", "label2idx", "[", "'<START>'", "]", "\n", "self", ".", "stopid", "=", "self", ".", "label2idx", "[", "'<STOP>'", "]", "\n", "\n", "\n", "self", ".", "pos_dic", ",", "self", ".", "type_dic", "=", "gen_dic", "(", "config", ".", "label2idx", ".", "keys", "(", ")", ",", "self", ".", "label2idx", ")", "\n", "\n", "self", ".", "tags_num", "=", "len", "(", "self", ".", "idx2labels", ")", "\n", "e_type", ",", "pos", "=", "gen_embedding_table", "(", "self", ".", "idx2labels", ",", "self", ".", "type_dic", ",", "self", ".", "pos_dic", ")", "\n", "self", ".", "type_embedding", "=", "torch", ".", "nn", ".", "Embedding", "(", "self", ".", "tags_num", ",", "self", ".", "tags_num", ")", ".", "from_pretrained", "(", "e_type", ",", "freeze", "=", "True", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "self", ".", "pos_embedding", "=", "torch", ".", "nn", ".", "Embedding", "(", "self", ".", "tags_num", ",", "self", ".", "tags_num", ")", ".", "from_pretrained", "(", "pos", ",", "freeze", "=", "True", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_local.NNCRF_sl.forward": [[110, 216], ["neuralcrf_small_loss_constrain_local.NNCRF_sl.encoder", "words.size", "words.size", "torch.arange().view().expand().to", "torch.arange().view().expand().to", "torch.arange().view().expand().to", "torch.arange().view().expand().to", "torch.le().to().float", "torch.le().to().float", "torch.le().to().float", "torch.le().to().float", "torch.zeros_like().scatter_", "torch.zeros_like().scatter_", "torch.zeros_like().scatter_", "torch.zeros_like().scatter_", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "forward_loss.detach.detach.detach", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "int", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "small_loss_mask_neg.view.view.view", "torch.argsort", "torch.argsort", "torch.argsort", "torch.argsort", "int", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "small_loss_mask_pos.view.view.view", "small_loss_mask.detach.detach.detach", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "neuralcrf_small_loss_constrain_local.NNCRF_sl.type_embedding", "neuralcrf_small_loss_constrain_local.NNCRF_sl.pos_embedding", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "prob.detach.detach.detach", "label_tag_mask.detach.detach.detach", "neuralcrf_small_loss_constrain_local.NNCRF_sl.inferencer", "tags.unsqueeze", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.eq().float", "torch.le().to().float.float", "torch.le().to().float.float", "torch.le().to().float.float", "torch.le().to().float.float", "negative_mask.sum", "small_loss_mask_neg.view.view.sum", "neuralcrf_small_loss_constrain_local.check_remove_ratio", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.le().to", "torch.le().to", "torch.le().to", "torch.le().to", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "forward_loss.detach.detach.view", "positive_mask.view", "negative_mask.sum", "forward_loss.detach.detach.view", "negative_mask.view", "positive_mask.sum", "negative_mask.sum", "positive_mask.sum", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "small_loss_mask_pos.view.view.bool", "small_loss_mask_neg.view.view.bool", "type_change_mask.unsqueeze", "pos_change_mask.unsqueeze", "small_loss_mask.detach.detach.unsqueeze", "small_loss_mask.detach.detach.unsqueeze", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.le", "torch.le", "torch.le", "torch.le", "word_seq_lens.view().expand", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "word_seq_lens.view"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_local.check_remove_ratio"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "words", ":", "torch", ".", "Tensor", ",", "\n", "word_seq_lens", ":", "torch", ".", "Tensor", ",", "\n", "batch_context_emb", ":", "torch", ".", "Tensor", ",", "\n", "chars", ":", "torch", ".", "Tensor", ",", "\n", "char_seq_lens", ":", "torch", ".", "Tensor", ",", "\n", "annotation_mask", ":", "torch", ".", "Tensor", ",", "\n", "tags", ":", "torch", ".", "Tensor", ",", "\n", "gold_tags", "=", "None", ",", "\n", "forget_rate_neg", "=", "0", ",", "forget_rate_pos", "=", "0", ",", "is_constrain", "=", "False", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Calculate the negative loglikelihood.\n        :param words: (batch_size x max_seq_len)\n        :param word_seq_lens: (batch_size)\n        :param batch_context_emb: (batch_size x max_seq_len x context_emb_size)\n        :param chars: (batch_size x max_seq_len x max_char_len)\n        :param char_seq_lens: (batch_size x max_seq_len)\n        :param tags: (batch_size x max_seq_len)\n        :return: the loss with shape (batch_size)\n        \"\"\"", "\n", "\n", "lstm_scores", "=", "self", ".", "encoder", "(", "words", ",", "word_seq_lens", ",", "batch_context_emb", ",", "chars", ",", "char_seq_lens", ")", "\n", "batch_size", "=", "words", ".", "size", "(", "0", ")", "\n", "sent_len", "=", "words", ".", "size", "(", "1", ")", "\n", "maskTemp", "=", "torch", ".", "arange", "(", "1", ",", "sent_len", "+", "1", ",", "dtype", "=", "torch", ".", "long", ")", ".", "view", "(", "1", ",", "sent_len", ")", ".", "expand", "(", "batch_size", ",", "sent_len", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "mask", "=", "torch", ".", "le", "(", "maskTemp", ",", "word_seq_lens", ".", "view", "(", "batch_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "sent_len", ")", ")", ".", "to", "(", "self", ".", "device", ")", ".", "float", "(", ")", "\n", "\n", "onehot_label", "=", "torch", ".", "zeros_like", "(", "lstm_scores", ")", ".", "scatter_", "(", "-", "1", ",", "tags", ".", "unsqueeze", "(", "-", "1", ")", ",", "1", ")", "\n", "\n", "token_prob", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "lstm_scores", ",", "dim", "=", "-", "1", ")", "\n", "forward_loss", "=", "-", "(", "onehot_label", "*", "token_prob", ")", ".", "sum", "(", "dim", "=", "-", "1", ")", "*", "mask", "\n", "forward_loss", "=", "forward_loss", ".", "detach", "(", ")", "\n", "negative_mask", "=", "torch", ".", "eq", "(", "tags", ",", "self", ".", "Oid", ")", ".", "float", "(", ")", "*", "mask", ".", "float", "(", ")", "\n", "positive_mask", "=", "(", "1", "-", "negative_mask", ")", "*", "mask", ".", "float", "(", ")", "\n", "\n", "\n", "tmp", "=", "forward_loss", ".", "view", "(", "batch_size", "*", "sent_len", ")", "+", "(", "1000", "*", "(", "1", "-", "mask", ")", ".", "view", "(", "batch_size", "*", "sent_len", ")", ")", "+", "(", "\n", "1000", "*", "(", "positive_mask", ".", "view", "(", "batch_size", "*", "sent_len", ")", ")", ")", "\n", "\n", "index", "=", "torch", ".", "argsort", "(", "tmp", ",", "dim", "=", "-", "1", ")", "\n", "\n", "remember_rate_neg", "=", "1.0", "-", "forget_rate_neg", "\n", "\n", "num_remember", "=", "int", "(", "remember_rate_neg", "*", "(", "negative_mask", ".", "sum", "(", ")", ")", ")", "\n", "small_loss_index", "=", "index", "[", ":", "num_remember", "]", "\n", "small_loss_mask_neg", "=", "torch", ".", "zeros_like", "(", "tmp", ")", "\n", "for", "num", "in", "small_loss_index", ":", "\n", "            ", "small_loss_mask_neg", "[", "num", "]", "=", "1", "\n", "", "small_loss_mask_neg", "=", "small_loss_mask_neg", ".", "view", "(", "(", "batch_size", ",", "sent_len", ")", ")", "\n", "if", "num_remember", "==", "0", ":", "\n", "            ", "small_loss_mask_neg", "=", "negative_mask", "\n", "", "remove_num_neg", "=", "negative_mask", ".", "sum", "(", ")", "-", "small_loss_mask_neg", ".", "sum", "(", ")", "\n", "\n", "tmp", "=", "forward_loss", ".", "view", "(", "batch_size", "*", "sent_len", ")", "+", "(", "1000", "*", "(", "1", "-", "mask", ")", ".", "view", "(", "batch_size", "*", "sent_len", ")", ")", "+", "(", "\n", "1000", "*", "(", "negative_mask", ".", "view", "(", "batch_size", "*", "sent_len", ")", ")", ")", "\n", "\n", "index", "=", "torch", ".", "argsort", "(", "tmp", ",", "dim", "=", "-", "1", ")", "\n", "remember_rate_pos", "=", "1.0", "-", "forget_rate_pos", "\n", "\n", "num_remember", "=", "int", "(", "remember_rate_pos", "*", "(", "positive_mask", ".", "sum", "(", ")", ")", ")", "\n", "small_loss_index", "=", "index", "[", ":", "num_remember", "]", "\n", "small_loss_mask_pos", "=", "torch", ".", "zeros_like", "(", "tmp", ")", "\n", "for", "num", "in", "small_loss_index", ":", "\n", "            ", "small_loss_mask_pos", "[", "num", "]", "=", "1", "\n", "", "small_loss_mask_pos", "=", "small_loss_mask_pos", ".", "view", "(", "(", "batch_size", ",", "sent_len", ")", ")", "\n", "if", "num_remember", "==", "0", ":", "\n", "            ", "small_loss_mask_pos", "=", "positive_mask", "\n", "\n", "", "small_loss_mask", "=", "(", "small_loss_mask_pos", ".", "bool", "(", ")", "+", "small_loss_mask_neg", ".", "bool", "(", ")", ")", ".", "float", "(", ")", "\n", "small_loss_mask", "=", "small_loss_mask", ".", "detach", "(", ")", "\n", "\n", "if", "(", "gold_tags", "!=", "None", ")", ":", "\n", "            ", "neg_recall", ",", "pos_recall", ",", "neg_precision", ",", "pos_precision", ",", "neg_f1", ",", "pos_f1", "=", "check_remove_ratio", "(", "gold_tags", ",", "tags", ",", "small_loss_mask", ",", "mask", ",", "negative_mask", ")", "\n", "\n", "\n", "", "partial_label", "=", "torch", ".", "ones_like", "(", "onehot_label", ")", "\n", "\n", "\n", "type_lookup", "=", "self", ".", "type_embedding", "(", "tags", ")", "\n", "pos_lookup", "=", "self", ".", "pos_embedding", "(", "tags", ")", "\n", "\n", "\n", "prob", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "lstm_scores", ",", "dim", "=", "-", "1", ")", "\n", "prob", "=", "prob", ".", "detach", "(", ")", "\n", "\n", "\n", "type_prob", "=", "(", "prob", "*", "type_lookup", ")", ".", "mean", "(", "dim", "=", "-", "1", ")", "\n", "pos_prob", "=", "(", "prob", "*", "pos_lookup", ")", ".", "mean", "(", "dim", "=", "-", "1", ")", "\n", "type_change_mask", "=", "(", "type_prob", ">", "pos_prob", ")", "*", "mask", "*", "(", "1", "-", "small_loss_mask", ")", "\n", "pos_change_mask", "=", "(", "type_prob", "<", "pos_prob", ")", "*", "mask", "*", "(", "1", "-", "small_loss_mask", ")", "\n", "change_label", "=", "(", "(", "type_change_mask", ".", "unsqueeze", "(", "-", "1", ")", "*", "type_lookup", ")", "+", "(", "pos_change_mask", ".", "unsqueeze", "(", "-", "1", ")", "*", "pos_lookup", ")", ")", "+", "(", "(", "1", "-", "small_loss_mask", ")", "*", "(", "1", "-", "type_change_mask", ")", "*", "(", "1", "-", "pos_change_mask", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", "*", "partial_label", "\n", "\n", "if", "(", "is_constrain", ")", ":", "\n", "            ", "label_tag_mask", "=", "(", "small_loss_mask", ".", "unsqueeze", "(", "-", "1", ")", "*", "onehot_label", ")", "+", "(", "(", "1", "-", "small_loss_mask", ")", ".", "unsqueeze", "(", "-", "1", ")", "*", "change_label", ")", "\n", "", "else", ":", "\n", "            ", "label_tag_mask", "=", "small_loss_mask", ".", "unsqueeze", "(", "-", "1", ")", "*", "onehot_label", "+", "(", "1", "-", "small_loss_mask", ")", ".", "unsqueeze", "(", "-", "1", ")", "*", "partial_label", "\n", "", "label_tag_mask", "=", "label_tag_mask", ".", "detach", "(", ")", "\n", "unlabed_score", ",", "labeled_score", "=", "self", ".", "inferencer", "(", "lstm_scores", ",", "word_seq_lens", ",", "label_tag_mask", ")", "\n", "\n", "loss_neg", "=", "(", "forward_loss", "*", "negative_mask", ")", ".", "sum", "(", ")", "/", "(", "negative_mask", ".", "sum", "(", ")", "+", "1e-6", ")", "\n", "loss_pos", "=", "(", "forward_loss", "*", "positive_mask", ")", ".", "sum", "(", ")", "/", "(", "positive_mask", ".", "sum", "(", ")", "+", "1e-6", ")", "\n", "\n", "if", "(", "gold_tags", "!=", "None", ")", ":", "\n", "            ", "return", "unlabed_score", "-", "labeled_score", ",", "[", "neg_recall", ",", "pos_recall", ",", "neg_precision", ",", "pos_precision", ",", "neg_f1", ",", "pos_f1", "]", ",", "loss_neg", ",", "loss_pos", "\n", "", "else", ":", "\n", "            ", "return", "unlabed_score", "-", "labeled_score", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_local.NNCRF_sl.decode": [[217, 229], ["neuralcrf_small_loss_constrain_local.NNCRF_sl.encoder", "neuralcrf_small_loss_constrain_local.NNCRF_sl.inferencer.decode"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.decode"], ["", "", "def", "decode", "(", "self", ",", "batchInput", ":", "Tuple", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Decode the batch input\n        :param batchInput:\n        :return:\n        \"\"\"", "\n", "wordSeqTensor", ",", "wordSeqLengths", ",", "batch_context_emb", ",", "charSeqTensor", ",", "charSeqLengths", ",", "annotation_mask", ",", "tagSeqTensor", ",", "_", "=", "batchInput", "\n", "\n", "features", "=", "self", ".", "encoder", "(", "wordSeqTensor", ",", "wordSeqLengths", ",", "batch_context_emb", ",", "charSeqTensor", ",", "charSeqLengths", ")", "\n", "bestScores", ",", "decodeIdx", "=", "self", ".", "inferencer", ".", "decode", "(", "features", ",", "wordSeqLengths", ",", "annotation_mask", ")", "\n", "\n", "return", "bestScores", ",", "decodeIdx", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_local.check_remove_ratio": [[14, 33], ["torch.eq().float", "torch.eq().float", "mask.float", "remove_right_neg.sum", "remove_right_pos.sum", "remove_right_neg.sum", "remove_right_pos.sum", "neg_recall.item", "pos_recall.item", "neg_precision.item", "pos_precision.item", "neg_f1.item", "pos_f1.item", "noise_negative.sum", "noise_positive.sum", "remove_neg.sum", "remove_pos.sum", "torch.eq", "torch.eq"], "function", ["None"], ["def", "check_remove_ratio", "(", "gold_tags", ",", "tags", ",", "small_loss_mask", ",", "mask", ",", "negative_mask", ")", ":", "\n", "    ", "remove_mask", "=", "(", "1", "-", "small_loss_mask", ")", "*", "mask", "\n", "positive_mask", "=", "(", "1", "-", "negative_mask", ")", "*", "mask", "\n", "clean_mask", "=", "torch", ".", "eq", "(", "gold_tags", ",", "tags", ")", ".", "float", "(", ")", "*", "mask", "\n", "noise_mask", "=", "(", "1", "-", "clean_mask", ")", "*", "mask", ".", "float", "(", ")", "\n", "remove_neg", "=", "remove_mask", "*", "negative_mask", "\n", "remove_right_neg", "=", "noise_mask", "*", "remove_neg", "\n", "remove_pos", "=", "remove_mask", "*", "(", "1", "-", "negative_mask", ")", "*", "mask", "\n", "remove_right_pos", "=", "noise_mask", "*", "remove_pos", "\n", "noise_positive", "=", "noise_mask", "*", "positive_mask", "*", "mask", "\n", "noise_negative", "=", "noise_mask", "*", "negative_mask", "*", "mask", "\n", "neg_recall", "=", "remove_right_neg", ".", "sum", "(", ")", "/", "(", "noise_negative", ".", "sum", "(", ")", "+", "1e-8", ")", "\n", "pos_recall", "=", "remove_right_pos", ".", "sum", "(", ")", "/", "(", "noise_positive", ".", "sum", "(", ")", "+", "1e-8", ")", "\n", "neg_precision", "=", "remove_right_neg", ".", "sum", "(", ")", "/", "(", "remove_neg", ".", "sum", "(", ")", "+", "1e-8", ")", "\n", "pos_precision", "=", "remove_right_pos", ".", "sum", "(", ")", "/", "(", "remove_pos", ".", "sum", "(", ")", "+", "1e-8", ")", "\n", "neg_f1", "=", "2", "*", "neg_recall", "*", "neg_precision", "/", "(", "neg_recall", "+", "neg_precision", "+", "1e-8", ")", "\n", "pos_f1", "=", "2", "*", "pos_recall", "*", "pos_precision", "/", "(", "pos_recall", "+", "pos_precision", "+", "1e-8", ")", "\n", "\n", "return", "neg_recall", ".", "item", "(", ")", ",", "pos_recall", ".", "item", "(", ")", ",", "neg_precision", ".", "item", "(", ")", ",", "pos_precision", ".", "item", "(", ")", ",", "neg_f1", ".", "item", "(", ")", ",", "pos_f1", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_local.gen_embedding_table": [[34, 59], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "enumerate", "len", "len", "len", "len", "label.startswith", "label.startswith", "label.startswith", "label.startswith", "label.startswith", "label.startswith", "label.startswith", "label.startswith", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "label.split", "label.split"], "function", ["None"], ["", "def", "gen_embedding_table", "(", "idx2label", ",", "type_dic", ",", "pos_dic", ")", ":", "\n", "    ", "type_embedding", "=", "torch", ".", "zeros", "(", "len", "(", "idx2label", ")", ",", "len", "(", "idx2label", ")", ")", "\n", "pos_embedding", "=", "torch", ".", "zeros", "(", "len", "(", "idx2label", ")", ",", "len", "(", "idx2label", ")", ")", "\n", "#type_embedding", "\n", "for", "id", ",", "label", "in", "enumerate", "(", "idx2label", ")", ":", "\n", "\n", "        ", "if", "(", "label", ".", "startswith", "(", "'B'", ")", "or", "label", ".", "startswith", "(", "'S'", ")", "or", "label", ".", "startswith", "(", "'E'", ")", "or", "label", ".", "startswith", "(", "'I'", ")", ")", ":", "\n", "            ", "indexes", "=", "type_dic", "[", "label", ".", "split", "(", "'-'", ")", "[", "1", "]", "]", "\n", "for", "index", "in", "indexes", ":", "\n", "\n", "                ", "type_embedding", "[", "id", "]", "[", "index", "]", "=", "1", "\n", "", "", "elif", "(", "label", "==", "'O'", ")", ":", "\n", "            ", "type_embedding", "[", "id", "]", "=", "torch", ".", "ones_like", "(", "type_embedding", "[", "id", "]", ")", "\n", "\n", "#pos_embedding", "\n", "", "", "for", "id", ",", "label", "in", "enumerate", "(", "idx2label", ")", ":", "\n", "        ", "if", "(", "label", ".", "startswith", "(", "'B'", ")", "or", "label", ".", "startswith", "(", "'S'", ")", "or", "label", ".", "startswith", "(", "'E'", ")", "or", "label", ".", "startswith", "(", "'I'", ")", ")", ":", "\n", "            ", "indexes", "=", "pos_dic", "[", "label", ".", "split", "(", "'-'", ")", "[", "0", "]", "]", "\n", "for", "index", "in", "indexes", ":", "\n", "                ", "pos_embedding", "[", "id", "]", "[", "index", "]", "=", "1", "\n", "", "", "elif", "(", "label", "==", "'O'", ")", ":", "\n", "            ", "pos_embedding", "[", "id", "]", "=", "torch", ".", "ones_like", "(", "pos_embedding", "[", "id", "]", ")", "\n", "\n", "", "", "type_embedding", ",", "pos_embedding", "=", "pos_embedding", ",", "type_embedding", "\n", "return", "type_embedding", ",", "pos_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.neuralcrf_small_loss_constrain_local.gen_dic": [[60, 86], ["set", "type_dic[].append", "pos_dic[].append", "label.startswith", "label.startswith", "label.startswith", "label.startswith", "set.add", "label.startswith", "pos_dic[].append", "type_dic[].append", "label.split", "label.split", "label.split"], "function", ["None"], ["", "def", "gen_dic", "(", "labels", ",", "label2idx", ")", ":", "\n", "\n", "    ", "types", "=", "set", "(", ")", "\n", "for", "label", "in", "labels", ":", "\n", "        ", "if", "(", "label", ".", "startswith", "(", "'B'", ")", "or", "label", ".", "startswith", "(", "'S'", ")", "or", "label", ".", "startswith", "(", "'E'", ")", "or", "label", ".", "startswith", "(", "'I'", ")", ")", ":", "\n", "            ", "tp", "=", "label", ".", "split", "(", "'-'", ")", "[", "1", "]", "\n", "types", ".", "add", "(", "tp", ")", "\n", "", "", "pos_dic", "=", "{", "'O'", ":", "[", "label2idx", "[", "'O'", "]", "]", "}", "\n", "type_dic", "=", "{", "'O'", ":", "[", "label2idx", "[", "'O'", "]", "]", "}", "\n", "for", "label", "in", "labels", ":", "\n", "        ", "if", "(", "label", "==", "'O'", "or", "label", ".", "startswith", "(", "'<'", ")", ")", ":", "\n", "            ", "continue", "\n", "", "pos", ",", "type", "=", "label", ".", "split", "(", "'-'", ")", "[", "0", "]", ",", "label", ".", "split", "(", "'-'", ")", "[", "1", "]", "\n", "if", "(", "pos", "in", "pos_dic", ")", ":", "\n", "            ", "pos_dic", "[", "pos", "]", ".", "append", "(", "label2idx", "[", "label", "]", ")", "\n", "", "else", ":", "\n", "            ", "pos_dic", "[", "pos", "]", "=", "[", "label2idx", "[", "label", "]", "]", "\n", "", "if", "(", "type", "in", "type_dic", ")", ":", "\n", "            ", "type_dic", "[", "type", "]", ".", "append", "(", "label2idx", "[", "label", "]", ")", "\n", "", "else", ":", "\n", "            ", "type_dic", "[", "type", "]", "=", "[", "label2idx", "[", "label", "]", "]", "\n", "", "", "for", "tp", "in", "types", ":", "\n", "        ", "type_dic", "[", "tp", "]", ".", "append", "(", "label2idx", "[", "'O'", "]", ")", "\n", "", "for", "pos", "in", "[", "'B'", ",", "'I'", ",", "'E'", ",", "'S'", "]", ":", "\n", "        ", "pos_dic", "[", "pos", "]", ".", "append", "(", "label2idx", "[", "'O'", "]", ")", "\n", "", "return", "pos_dic", ",", "type_dic", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.charbilstm.CharBiLSTM.__init__": [[9, 23], ["torch.Module.__init__", "len", "torch.Dropout().to", "torch.Dropout().to", "torch.Embedding", "torch.Embedding", "charbilstm.CharBiLSTM.char_embeddings.to", "torch.LSTM().to", "torch.LSTM().to", "print", "torch.Dropout", "torch.Dropout", "torch.LSTM", "torch.LSTM"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.instance.Instance.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "print_info", ":", "bool", "=", "True", ")", ":", "\n", "        ", "super", "(", "CharBiLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "print_info", ":", "\n", "            ", "print", "(", "\"[Info] Building character-level LSTM\"", ")", "\n", "", "self", ".", "char_emb_size", "=", "config", ".", "char_emb_size", "\n", "self", ".", "char2idx", "=", "config", ".", "char2idx", "\n", "self", ".", "chars", "=", "config", ".", "idx2char", "\n", "self", ".", "char_size", "=", "len", "(", "self", ".", "chars", ")", "\n", "self", ".", "device", "=", "config", ".", "device", "\n", "self", ".", "hidden", "=", "config", ".", "charlstm_hidden_dim", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "char_embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "char_size", ",", "self", ".", "char_emb_size", ")", "\n", "self", ".", "char_embeddings", "=", "self", ".", "char_embeddings", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "char_lstm", "=", "nn", ".", "LSTM", "(", "self", ".", "char_emb_size", ",", "self", ".", "hidden", "//", "2", ",", "num_layers", "=", "1", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "True", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.charbilstm.CharBiLSTM.forward": [[24, 49], ["char_seq_tensor.view.view.size", "char_seq_tensor.view.view.size", "char_seq_tensor.view.view.view", "char_seq_len.view.view.view", "char_seq_len.view.view.sort", "permIdx.sort", "charbilstm.CharBiLSTM.dropout", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "charbilstm.CharBiLSTM.char_lstm", "char_hidden[].transpose().contiguous().view", "hidden[].view", "charbilstm.CharBiLSTM.char_embeddings", "char_hidden[].transpose().contiguous", "char_hidden[].transpose"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "char_seq_tensor", ":", "torch", ".", "Tensor", ",", "char_seq_len", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Get the last hidden states of the LSTM\n            input:\n                char_seq_tensor: (batch_size, sent_len, word_length)\n                char_seq_len: (batch_size, sent_len)\n            output:\n                Variable(batch_size, sent_len, char_hidden_dim )\n        \"\"\"", "\n", "batch_size", "=", "char_seq_tensor", ".", "size", "(", "0", ")", "\n", "sent_len", "=", "char_seq_tensor", ".", "size", "(", "1", ")", "\n", "char_seq_tensor", "=", "char_seq_tensor", ".", "view", "(", "batch_size", "*", "sent_len", ",", "-", "1", ")", "\n", "char_seq_len", "=", "char_seq_len", ".", "view", "(", "batch_size", "*", "sent_len", ")", "\n", "sorted_seq_len", ",", "permIdx", "=", "char_seq_len", ".", "sort", "(", "0", ",", "descending", "=", "True", ")", "\n", "_", ",", "recover_idx", "=", "permIdx", ".", "sort", "(", "0", ",", "descending", "=", "False", ")", "\n", "sorted_seq_tensor", "=", "char_seq_tensor", "[", "permIdx", "]", "\n", "\n", "char_embeds", "=", "self", ".", "dropout", "(", "self", ".", "char_embeddings", "(", "sorted_seq_tensor", ")", ")", "\n", "pack_input", "=", "pack_padded_sequence", "(", "char_embeds", ",", "sorted_seq_len", ",", "batch_first", "=", "True", ")", "\n", "\n", "_", ",", "char_hidden", "=", "self", ".", "char_lstm", "(", "pack_input", ",", "None", ")", "\n", "\n", "hidden", "=", "char_hidden", "[", "0", "]", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", "*", "sent_len", ",", "1", ",", "-", "1", ")", "\n", "return", "hidden", "[", "recover_idx", "]", ".", "view", "(", "batch_size", ",", "sent_len", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.__init__": [[13, 34], ["torch.Module.__init__", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.Parameter", "torch.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.instance.Instance.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "print_info", ":", "bool", "=", "True", ")", ":", "\n", "        ", "super", "(", "LinearCRF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "label_size", "=", "config", ".", "label_size", "\n", "self", ".", "device", "=", "config", ".", "device", "\n", "\n", "\n", "self", ".", "label2idx", "=", "config", ".", "label2idx", "\n", "self", ".", "labels", "=", "config", ".", "idx2labels", "\n", "self", ".", "start_idx", "=", "self", ".", "label2idx", "[", "START", "]", "\n", "self", ".", "end_idx", "=", "self", ".", "label2idx", "[", "STOP", "]", "\n", "self", ".", "pad_idx", "=", "self", ".", "label2idx", "[", "PAD", "]", "\n", "\n", "# initialize the following transition (anything never -> start. end never -> anything. Same thing for the padding label)", "\n", "init_transition", "=", "torch", ".", "randn", "(", "self", ".", "label_size", ",", "self", ".", "label_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "init_transition", "[", ":", ",", "self", ".", "start_idx", "]", "=", "-", "10000.0", "\n", "init_transition", "[", "self", ".", "end_idx", ",", ":", "]", "=", "-", "10000.0", "\n", "init_transition", "[", ":", ",", "self", ".", "pad_idx", "]", "=", "-", "10000.0", "\n", "init_transition", "[", "self", ".", "pad_idx", ",", ":", "]", "=", "-", "10000.0", "\n", "\n", "self", ".", "transition", "=", "nn", ".", "Parameter", "(", "init_transition", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.forward": [[35, 49], ["linear_partial_crf_inferencer.LinearCRF.calculate_all_scores", "linear_partial_crf_inferencer.LinearCRF.forward_unlabeled", "linear_partial_crf_inferencer.LinearCRF.forward_labeled"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.calculate_all_scores", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.forward_unlabeled", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.forward_labeled"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "lstm_scores", ",", "word_seq_lens", ",", "label_tag_mask", ")", ":", "\n", "        ", "\"\"\"\n        Calculate the negative log-likelihood\n        :param lstm_scores:\n        :param word_seq_lens:\n        :param tags:\n        :param mask:\n        :return:\n        \"\"\"", "\n", "all_scores", "=", "self", ".", "calculate_all_scores", "(", "lstm_scores", "=", "lstm_scores", ")", "\n", "unlabed_score", "=", "self", ".", "forward_unlabeled", "(", "all_scores", ",", "word_seq_lens", ")", "\n", "labeled_score", "=", "self", ".", "forward_labeled", "(", "all_scores", ",", "word_seq_lens", ",", "label_tag_mask", ")", "\n", "return", "unlabed_score", ",", "labeled_score", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.backward_score": [[50, 78], ["linear_partial_crf_inferencer.LinearCRF.calculate_all_scores", "torch_model_utils.reverse_sequence.size", "torch_model_utils.reverse_sequence.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "linear_partial_crf_inferencer.LinearCRF.transition[].view", "torch_model_utils.reverse_sequence", "range", "torch_model_utils.reverse_sequence", "beta[].view().expand", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "beta[].view"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.calculate_all_scores", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.reverse_sequence", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.torch_model_utils.reverse_sequence"], ["", "def", "backward_score", "(", "self", ",", "emission_scores", ",", "seq_lens", ")", ":", "\n", "        ", "\"\"\"backward algorithm\"\"\"", "\n", "device", "=", "emission_scores", ".", "device", "\n", "all_scores", "=", "self", ".", "calculate_all_scores", "(", "emission_scores", ")", "\n", "\n", "batch_size", "=", "all_scores", ".", "size", "(", "0", ")", "\n", "seq_len", "=", "all_scores", ".", "size", "(", "1", ")", "\n", "\n", "# beta[T] initialized as 0", "\n", "beta", "=", "torch", ".", "zeros", "(", "batch_size", ",", "seq_len", ",", "self", ".", "label_size", ")", ".", "to", "(", "device", ")", "\n", "beta", "[", ":", ",", "0", ",", ":", "]", "+=", "self", ".", "transition", "[", ":", ",", "self", ".", "end_idx", "]", ".", "view", "(", "1", ",", "self", ".", "label_size", ")", "\n", "\n", "# beta stored in reverse order", "\n", "# all score at i: phi(from class at L - i - 1, to class at L - i)", "\n", "all_scores", "=", "tmu", ".", "reverse_sequence", "(", "all_scores", ",", "seq_lens", ")", "\n", "for", "word_idx", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "# beta[t + 1]: batch_size, t + 1, to label_size", "\n", "# indexing tricky here !! and different than the forward algo", "\n", "            ", "beta_t_", "=", "beta", "[", ":", ",", "word_idx", "-", "1", ",", ":", "]", ".", "view", "(", "batch_size", ",", "1", ",", "self", ".", "label_size", ")", ".", "expand", "(", "batch_size", ",", "self", ".", "label_size", ",", "self", ".", "label_size", ")", "\n", "before_log_sum_exp", "=", "beta_t_", "+", "all_scores", "[", ":", ",", "word_idx", "-", "1", ",", ":", ",", ":", "]", "\n", "beta", "[", ":", ",", "word_idx", ",", ":", "]", "=", "torch", ".", "logsumexp", "(", "before_log_sum_exp", ",", "2", ")", "\n", "\n", "# reverse beta:", "\n", "", "beta", "=", "tmu", ".", "reverse_sequence", "(", "beta", ",", "seq_lens", ")", "\n", "return", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.marginal": [[79, 86], ["linear_partial_crf_inferencer.LinearCRF.calculate_all_scores", "linear_partial_crf_inferencer.LinearCRF.forward_unlabeled", "linear_partial_crf_inferencer.LinearCRF.backward_score", "log_Z.unsqueeze().unsqueeze", "log_Z.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.calculate_all_scores", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.forward_unlabeled", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.backward_score"], ["", "def", "marginal", "(", "self", ",", "emission_scores", ",", "seq_lens", ")", ":", "\n", "        ", "\"\"\"Marginal distribution with conventional forward-backward\"\"\"", "\n", "all_scores", "=", "self", ".", "calculate_all_scores", "(", "emission_scores", ")", "\n", "alpha", ",", "log_Z", "=", "self", ".", "forward_unlabeled", "(", "all_scores", ",", "seq_lens", ",", "True", ")", "\n", "beta", "=", "self", ".", "backward_score", "(", "emission_scores", ",", "seq_lens", ")", "\n", "log_marginals", "=", "alpha", "+", "beta", "-", "log_Z", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "return", "log_marginals", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.forward_unlabeled": [[87, 114], ["all_scores.size", "all_scores.size", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "linear_partial_crf_inferencer.LinearCRF.transition[].view().expand", "config.log_sum_exp_pytorch().view", "config.log_sum_exp_pytorch", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "alpha[].view().expand", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "linear_partial_crf_inferencer.LinearCRF.transition[].view", "config.log_sum_exp_pytorch", "config.log_sum_exp_pytorch().view.view", "alpha[].view", "word_seq_lens.view().expand", "word_seq_lens.view"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.log_sum_exp_pytorch", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.log_sum_exp_pytorch"], ["", "def", "forward_unlabeled", "(", "self", ",", "all_scores", ":", "torch", ".", "Tensor", ",", "word_seq_lens", ":", "torch", ".", "Tensor", ",", "return_alpha", "=", "False", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Calculate the scores with the forward algorithm. Basically calculating the normalization term\n        :param all_scores: (batch_size x max_seq_len x num_labels x num_labels) from (lstm scores + transition scores).\n        :param word_seq_lens: (batch_size)\n        :return: (batch_size) for the normalization scores\n        \"\"\"", "\n", "batch_size", "=", "all_scores", ".", "size", "(", "0", ")", "\n", "seq_len", "=", "all_scores", ".", "size", "(", "1", ")", "\n", "alpha", "=", "torch", ".", "zeros", "(", "batch_size", ",", "seq_len", ",", "self", ".", "label_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "alpha", "[", ":", ",", "0", ",", ":", "]", "=", "all_scores", "[", ":", ",", "0", ",", "self", ".", "start_idx", ",", ":", "]", "## the first position of all labels = (the transition from start - > all labels) + current emission.", "\n", "\n", "for", "word_idx", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "## batch_size, self.label_size, self.label_size", "\n", "            ", "before_log_sum_exp", "=", "alpha", "[", ":", ",", "word_idx", "-", "1", ",", ":", "]", ".", "view", "(", "batch_size", ",", "self", ".", "label_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "self", ".", "label_size", ",", "self", ".", "label_size", ")", "+", "all_scores", "[", ":", ",", "word_idx", ",", ":", ",", ":", "]", "\n", "alpha", "[", ":", ",", "word_idx", ",", ":", "]", "=", "log_sum_exp_pytorch", "(", "before_log_sum_exp", ")", "\n", "\n", "### batch_size x label_size", "\n", "", "last_alpha", "=", "torch", ".", "gather", "(", "alpha", ",", "1", ",", "word_seq_lens", ".", "view", "(", "batch_size", ",", "1", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "1", ",", "self", ".", "label_size", ")", "-", "1", ")", ".", "view", "(", "batch_size", ",", "self", ".", "label_size", ")", "\n", "last_alpha", "+=", "self", ".", "transition", "[", ":", ",", "self", ".", "end_idx", "]", ".", "view", "(", "1", ",", "self", ".", "label_size", ")", ".", "expand", "(", "batch_size", ",", "self", ".", "label_size", ")", "\n", "last_alpha", "=", "log_sum_exp_pytorch", "(", "last_alpha", ".", "view", "(", "batch_size", ",", "self", ".", "label_size", ",", "1", ")", ")", ".", "view", "(", "batch_size", ")", "\n", "\n", "if", "(", "return_alpha", ")", ":", "\n", "            ", "return", "alpha", ",", "last_alpha", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "sum", "(", "last_alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.forward_labeled": [[116, 145], ["all_scores.size", "all_scores.size", "label_tag_mask.float().log.float().log.float().log", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "linear_partial_crf_inferencer.LinearCRF.transition[].view().expand", "config.log_sum_exp_pytorch().view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "config.log_sum_exp_pytorch", "label_tag_mask.float().log.float().log.float", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "alpha[].view().expand", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "linear_partial_crf_inferencer.LinearCRF.transition[].view", "config.log_sum_exp_pytorch", "config.log_sum_exp_pytorch().view.view", "alpha[].view", "word_seq_lens.view().expand", "word_seq_lens.view"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.log_sum_exp_pytorch", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.log_sum_exp_pytorch"], ["", "", "def", "forward_labeled", "(", "self", ",", "all_scores", ":", "torch", ".", "Tensor", ",", "word_seq_lens", ":", "torch", ".", "Tensor", ",", "label_tag_mask", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Calculate the scores with the forward algorithm. Basically calculating the normalization term\n        :param all_scores: (batch_size x max_seq_len x num_labels) from lstm scores.\n        :param word_seq_lens: (batch_size)\n        :param mask: shape (batch x max_seq_len x num_labels)\n        :return: (batch_size) for the normalization scores\n        \"\"\"", "\n", "batch_size", "=", "all_scores", ".", "size", "(", "0", ")", "\n", "seq_len", "=", "all_scores", ".", "size", "(", "1", ")", "\n", "label_tag_mask", "=", "label_tag_mask", ".", "float", "(", ")", ".", "log", "(", ")", "\n", "## alpha is a log-space score", "\n", "alpha", "=", "torch", ".", "zeros", "(", "batch_size", ",", "seq_len", ",", "self", ".", "label_size", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "alpha", "[", ":", ",", "0", ",", ":", "]", "=", "all_scores", "[", ":", ",", "0", ",", "self", ".", "start_idx", ",", ":", "]", "## the first position of all labels = (the transition from start - > all labels) + current emission.", "\n", "alpha", "[", ":", ",", "0", ",", ":", "]", "+=", "label_tag_mask", "[", ":", ",", "0", ",", ":", "]", "\n", "\n", "for", "word_idx", "in", "range", "(", "1", ",", "seq_len", ")", ":", "\n", "## batch_size, self.label_size, self.label_size", "\n", "            ", "before_log_sum_exp", "=", "alpha", "[", ":", ",", "word_idx", "-", "1", ",", ":", "]", ".", "view", "(", "batch_size", ",", "self", ".", "label_size", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "self", ".", "label_size", ",", "self", ".", "label_size", ")", "+", "all_scores", "[", ":", ",", "word_idx", ",", ":", ",", ":", "]", "\n", "alpha", "[", ":", ",", "word_idx", ",", ":", "]", "=", "log_sum_exp_pytorch", "(", "before_log_sum_exp", ")", "\n", "alpha", "[", ":", ",", "word_idx", ",", ":", "]", "+=", "label_tag_mask", "[", ":", ",", "word_idx", ",", ":", "]", "\n", "\n", "### batch_size x label_size", "\n", "", "last_alpha", "=", "torch", ".", "gather", "(", "alpha", ",", "1", ",", "word_seq_lens", ".", "view", "(", "batch_size", ",", "1", ",", "1", ")", ".", "expand", "(", "batch_size", ",", "1", ",", "self", ".", "label_size", ")", "-", "1", ")", ".", "view", "(", "batch_size", ",", "self", ".", "label_size", ")", "\n", "last_alpha", "+=", "self", ".", "transition", "[", ":", ",", "self", ".", "end_idx", "]", ".", "view", "(", "1", ",", "self", ".", "label_size", ")", ".", "expand", "(", "batch_size", ",", "self", ".", "label_size", ")", "\n", "last_alpha", "=", "log_sum_exp_pytorch", "(", "last_alpha", ".", "view", "(", "batch_size", ",", "self", ".", "label_size", ",", "1", ")", ")", ".", "view", "(", "batch_size", ")", "\n", "\n", "return", "torch", ".", "sum", "(", "last_alpha", ")", "\n", "", "def", "calculate_all_scores", "(", "self", ",", "lstm_scores", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.calculate_all_scores": [[145, 158], ["lstm_scores.size", "lstm_scores.size", "linear_partial_crf_inferencer.LinearCRF.transition.view().expand", "lstm_scores.view().expand", "linear_partial_crf_inferencer.LinearCRF.transition.view", "lstm_scores.view"], "methods", ["None"], ["", "def", "calculate_all_scores", "(", "self", ",", "lstm_scores", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Calculate all scores by adding up the transition scores and emissions (from lstm).\n        Basically, compute the scores for each edges between labels at adjacent positions.\n        This score is later be used for forward-backward inference\n        :param lstm_scores: emission scores.\n        :return:\n        \"\"\"", "\n", "batch_size", "=", "lstm_scores", ".", "size", "(", "0", ")", "\n", "seq_len", "=", "lstm_scores", ".", "size", "(", "1", ")", "\n", "scores", "=", "self", ".", "transition", ".", "view", "(", "1", ",", "1", ",", "self", ".", "label_size", ",", "self", ".", "label_size", ")", ".", "expand", "(", "batch_size", ",", "seq_len", ",", "self", ".", "label_size", ",", "self", ".", "label_size", ")", "+", "lstm_scores", ".", "view", "(", "batch_size", ",", "seq_len", ",", "1", ",", "self", ".", "label_size", ")", ".", "expand", "(", "batch_size", ",", "seq_len", ",", "self", ".", "label_size", ",", "self", ".", "label_size", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.decode": [[159, 168], ["linear_partial_crf_inferencer.LinearCRF.calculate_all_scores", "linear_partial_crf_inferencer.LinearCRF.constrainted_viterbi_decode"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.calculate_all_scores", "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.constrainted_viterbi_decode"], ["", "def", "decode", "(", "self", ",", "features", ",", "wordSeqLengths", ",", "annotation_mask", "=", "None", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Decode the batch input\n        :param batchInput:\n        :return:\n        \"\"\"", "\n", "all_scores", "=", "self", ".", "calculate_all_scores", "(", "features", ")", "\n", "bestScores", ",", "decodeIdx", "=", "self", ".", "constrainted_viterbi_decode", "(", "all_scores", ",", "wordSeqLengths", ",", "annotation_mask", ")", "\n", "return", "bestScores", ",", "decodeIdx", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.model.linear_partial_crf_inferencer.LinearCRF.constrainted_viterbi_decode": [[169, 214], ["torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.ones_like().to", "torch.ones_like().to", "torch.ones_like().to", "torch.ones_like().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.full().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "range", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "linear_partial_crf_inferencer.LinearCRF.transition[].view().expand", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "range", "annotation_mask.float().log.float().log.float().log", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "decodeIdx[].view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.full", "torch.full", "torch.full", "torch.full", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "scoresRecord[].view().expand", "annotation_mask[].view().expand", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "linear_partial_crf_inferencer.LinearCRF.transition[].view", "annotation_mask.float().log.float().log.float", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "scoresRecord[].view", "annotation_mask[].view", "idxRecord[].view", "word_seq_lens.view().expand", "torch.where().view().expand", "torch.where().view().expand", "torch.where().view().expand", "torch.where().view().expand", "decodeIdx[].view", "word_seq_lens.view", "torch.where().view", "torch.where().view", "torch.where().view", "torch.where().view", "torch.where", "torch.where", "torch.where", "torch.where"], "methods", ["None"], ["", "def", "constrainted_viterbi_decode", "(", "self", ",", "all_scores", ":", "torch", ".", "Tensor", ",", "word_seq_lens", ":", "torch", ".", "Tensor", ",", "annotation_mask", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Use viterbi to decode the instances given the scores and transition parameters\n        :param all_scores: (batch_size x max_seq_len x num_labels x num_labels)\n        :param word_seq_lens: (batch_size)\n        :return: the best scores as well as the predicted label ids.\n               (batch_size) and (batch_size x max_seq_len)\n        \"\"\"", "\n", "\n", "batchSize", "=", "all_scores", ".", "shape", "[", "0", "]", "\n", "sentLength", "=", "all_scores", ".", "shape", "[", "1", "]", "\n", "if", "annotation_mask", "is", "not", "None", ":", "\n", "            ", "annotation_mask", "=", "annotation_mask", ".", "float", "(", ")", ".", "log", "(", ")", "\n", "\n", "", "scoresRecord", "=", "torch", ".", "zeros", "(", "[", "batchSize", ",", "sentLength", ",", "self", ".", "label_size", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "idxRecord", "=", "torch", ".", "zeros", "(", "[", "batchSize", ",", "sentLength", ",", "self", ".", "label_size", "]", ",", "dtype", "=", "torch", ".", "int64", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "mask", "=", "torch", ".", "ones_like", "(", "word_seq_lens", ",", "dtype", "=", "torch", ".", "int64", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "startIds", "=", "torch", ".", "full", "(", "(", "batchSize", ",", "self", ".", "label_size", ")", ",", "self", ".", "start_idx", ",", "dtype", "=", "torch", ".", "int64", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "decodeIdx", "=", "torch", ".", "LongTensor", "(", "batchSize", ",", "sentLength", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "scores", "=", "all_scores", "\n", "scoresRecord", "[", ":", ",", "0", ",", ":", "]", "=", "scores", "[", ":", ",", "0", ",", "self", ".", "start_idx", ",", ":", "]", "## represent the best current score from the start, is the best", "\n", "if", "annotation_mask", "is", "not", "None", ":", "\n", "            ", "scoresRecord", "[", ":", ",", "0", ",", ":", "]", "+=", "annotation_mask", "[", ":", ",", "0", ",", ":", "]", "\n", "", "idxRecord", "[", ":", ",", "0", ",", ":", "]", "=", "startIds", "\n", "for", "wordIdx", "in", "range", "(", "1", ",", "sentLength", ")", ":", "\n", "### scoresIdx: batch x from_label x to_label at current index.", "\n", "            ", "scoresIdx", "=", "scoresRecord", "[", ":", ",", "wordIdx", "-", "1", ",", ":", "]", ".", "view", "(", "batchSize", ",", "self", ".", "label_size", ",", "1", ")", ".", "expand", "(", "batchSize", ",", "self", ".", "label_size", ",", "\n", "self", ".", "label_size", ")", "+", "scores", "[", ":", ",", "wordIdx", ",", ":", ",", ":", "]", "\n", "if", "annotation_mask", "is", "not", "None", ":", "\n", "                ", "scoresIdx", "+=", "annotation_mask", "[", ":", ",", "wordIdx", ",", ":", "]", ".", "view", "(", "batchSize", ",", "1", ",", "self", ".", "label_size", ")", ".", "expand", "(", "batchSize", ",", "self", ".", "label_size", ",", "self", ".", "label_size", ")", "\n", "\n", "", "idxRecord", "[", ":", ",", "wordIdx", ",", ":", "]", "=", "torch", ".", "argmax", "(", "scoresIdx", ",", "1", ")", "## the best previous label idx to crrent labels", "\n", "scoresRecord", "[", ":", ",", "wordIdx", ",", ":", "]", "=", "torch", ".", "gather", "(", "scoresIdx", ",", "1", ",", "idxRecord", "[", ":", ",", "wordIdx", ",", ":", "]", ".", "view", "(", "batchSize", ",", "1", ",", "self", ".", "label_size", ")", ")", ".", "view", "(", "batchSize", ",", "self", ".", "label_size", ")", "\n", "\n", "", "lastScores", "=", "torch", ".", "gather", "(", "scoresRecord", ",", "1", ",", "word_seq_lens", ".", "view", "(", "batchSize", ",", "1", ",", "1", ")", ".", "expand", "(", "batchSize", ",", "1", ",", "self", ".", "label_size", ")", "-", "1", ")", ".", "view", "(", "batchSize", ",", "self", ".", "label_size", ")", "##select position", "\n", "lastScores", "+=", "self", ".", "transition", "[", ":", ",", "self", ".", "end_idx", "]", ".", "view", "(", "1", ",", "self", ".", "label_size", ")", ".", "expand", "(", "batchSize", ",", "self", ".", "label_size", ")", "\n", "decodeIdx", "[", ":", ",", "0", "]", "=", "torch", ".", "argmax", "(", "lastScores", ",", "1", ")", "\n", "bestScores", "=", "torch", ".", "gather", "(", "lastScores", ",", "1", ",", "decodeIdx", "[", ":", ",", "0", "]", ".", "view", "(", "batchSize", ",", "1", ")", ")", "\n", "\n", "for", "distance2Last", "in", "range", "(", "sentLength", "-", "1", ")", ":", "\n", "            ", "lastNIdxRecord", "=", "torch", ".", "gather", "(", "idxRecord", ",", "1", ",", "torch", ".", "where", "(", "word_seq_lens", "-", "distance2Last", "-", "1", ">", "0", ",", "word_seq_lens", "-", "distance2Last", "-", "1", ",", "mask", ")", ".", "view", "(", "batchSize", ",", "1", ",", "1", ")", ".", "expand", "(", "batchSize", ",", "1", ",", "self", ".", "label_size", ")", ")", ".", "view", "(", "batchSize", ",", "self", ".", "label_size", ")", "\n", "decodeIdx", "[", ":", ",", "distance2Last", "+", "1", "]", "=", "torch", ".", "gather", "(", "lastNIdxRecord", ",", "1", ",", "decodeIdx", "[", ":", ",", "distance2Last", "]", ".", "view", "(", "batchSize", ",", "1", ")", ")", ".", "view", "(", "batchSize", ")", "\n", "\n", "", "return", "bestScores", ",", "decodeIdx", "\n", "", "", ""]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.__init__": [[24, 95], ["config.Config.read_pretrain_embedding", "args.optimizer.lower", "torch.device"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.read_pretrain_embedding"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Construct the arguments and some hyperparameters\n        :param args:\n        \"\"\"", "\n", "\n", "# Predefined label string.", "\n", "self", ".", "PAD", "=", "PAD", "\n", "self", ".", "B", "=", "\"B-\"", "\n", "self", ".", "I", "=", "\"I-\"", "\n", "self", ".", "S", "=", "\"S-\"", "\n", "self", ".", "E", "=", "\"E-\"", "\n", "self", ".", "O", "=", "\"O\"", "\n", "self", ".", "START_TAG", "=", "START", "\n", "self", ".", "STOP_TAG", "=", "STOP", "\n", "self", ".", "UNK", "=", "\"<UNK>\"", "\n", "self", ".", "unk_id", "=", "-", "1", "\n", "\n", "# Model hyper parameters", "\n", "self", ".", "embedding_file", "=", "args", ".", "embedding_file", "\n", "self", ".", "embedding_dim", "=", "args", ".", "embedding_dim", "\n", "self", ".", "context_emb", "=", "ContextEmb", "[", "args", ".", "context_emb", "]", "\n", "self", ".", "context_emb_size", "=", "0", "\n", "self", ".", "embedding", ",", "self", ".", "embedding_dim", "=", "self", ".", "read_pretrain_embedding", "(", ")", "\n", "self", ".", "word_embedding", "=", "None", "\n", "self", ".", "seed", "=", "args", ".", "seed", "\n", "self", ".", "digit2zero", "=", "args", ".", "digit2zero", "\n", "self", ".", "hidden_dim", "=", "args", ".", "hidden_dim", "\n", "self", ".", "use_brnn", "=", "True", "\n", "self", ".", "num_layers", "=", "1", "\n", "self", ".", "dropout", "=", "args", ".", "dropout", "\n", "self", ".", "char_emb_size", "=", "25", "\n", "self", ".", "charlstm_hidden_dim", "=", "50", "\n", "self", ".", "use_char_rnn", "=", "args", ".", "use_char_rnn", "\n", "\n", "# Data specification", "\n", "self", ".", "dataset", "=", "args", ".", "dataset", "\n", "self", ".", "train_file", "=", "\"data/\"", "+", "self", ".", "dataset", "+", "\"/train.txt\"", "\n", "self", ".", "dev_file", "=", "\"data/\"", "+", "self", ".", "dataset", "+", "\"/dev.txt\"", "\n", "self", ".", "test_file", "=", "\"data/\"", "+", "self", ".", "dataset", "+", "\"/test.txt\"", "\n", "self", ".", "label2idx", "=", "{", "}", "\n", "self", ".", "idx2labels", "=", "[", "]", "\n", "self", ".", "char2idx", "=", "{", "}", "\n", "self", ".", "idx2char", "=", "[", "]", "\n", "self", ".", "num_char", "=", "0", "\n", "self", ".", "train_num", "=", "args", ".", "train_num", "\n", "self", ".", "dev_num", "=", "args", ".", "dev_num", "\n", "self", ".", "test_num", "=", "args", ".", "test_num", "\n", "self", ".", "num_folds", "=", "2", "\n", "\n", "\n", "# Training hyperparameter", "\n", "self", ".", "model_folder", "=", "args", ".", "model_folder", "\n", "self", ".", "res_folder", "=", "args", ".", "res_folder", "\n", "self", ".", "optimizer", "=", "args", ".", "optimizer", ".", "lower", "(", ")", "\n", "self", ".", "learning_rate", "=", "args", ".", "learning_rate", "\n", "self", ".", "momentum", "=", "args", ".", "momentum", "\n", "self", ".", "l2", "=", "args", ".", "l2", "\n", "self", ".", "num_epochs", "=", "args", ".", "num_epochs", "\n", "self", ".", "use_dev", "=", "True", "\n", "self", ".", "batch_size", "=", "args", ".", "batch_size", "\n", "self", ".", "clip", "=", "5", "\n", "self", ".", "lr_decay", "=", "args", ".", "lr_decay", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "args", ".", "device", ")", "\n", "self", ".", "num_outer_iterations", "=", "args", ".", "num_outer_iterations", "\n", "self", ".", "neg_noise_rate", "=", "args", ".", "neg_noise_rate", "\n", "self", ".", "pos_noise_rate", "=", "args", ".", "pos_noise_rate", "\n", "self", ".", "warm_up_num", "=", "args", ".", "warm_up_num", "\n", "self", ".", "num_gradual_neg", "=", "args", ".", "num_gradual_neg", "\n", "self", ".", "num_gradual_pos", "=", "args", ".", "num_gradual_pos", "\n", "self", ".", "is_constrain", "=", "args", ".", "is_constrain", "\n", "", "def", "read_pretrain_embedding", "(", "self", ")", "->", "Tuple", "[", "Union", "[", "Dict", "[", "str", ",", "np", ".", "array", "]", ",", "None", "]", ",", "int", "]", ":", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.read_pretrain_embedding": [[95, 133], ["print", "dict", "print", "os.path.isfile", "open", "file.readline", "tqdm.tqdm.tqdm", "print", "file.readlines", "line.strip.strip.strip", "line.strip.strip.split", "numpy.empty", "termcolor.colored", "len", "len", "len", "remove.append"], "methods", ["None"], ["", "def", "read_pretrain_embedding", "(", "self", ")", "->", "Tuple", "[", "Union", "[", "Dict", "[", "str", ",", "np", ".", "array", "]", ",", "None", "]", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Read the pretrained word embeddings, return the complete embeddings and the embedding dimension\n        :return:\n        \"\"\"", "\n", "print", "(", "\"reading the pretraing embedding: %s\"", "%", "(", "self", ".", "embedding_file", ")", ")", "\n", "if", "self", ".", "embedding_file", "is", "None", ":", "\n", "            ", "print", "(", "\"pretrain embedding in None, using random embedding\"", ")", "\n", "return", "None", ",", "self", ".", "embedding_dim", "\n", "", "else", ":", "\n", "            ", "exists", "=", "os", ".", "path", ".", "isfile", "(", "self", ".", "embedding_file", ")", "\n", "if", "not", "exists", ":", "\n", "                ", "print", "(", "colored", "(", "\"[Warning] pretrain embedding file not exists, using random embedding\"", ",", "'red'", ")", ")", "\n", "return", "None", ",", "self", ".", "embedding_dim", "\n", "\n", "", "", "embedding_dim", "=", "-", "1", "\n", "embedding", "=", "dict", "(", ")", "\n", "remove", "=", "[", "]", "\n", "with", "open", "(", "self", ".", "embedding_file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "file", ":", "\n", "            ", "file", ".", "readline", "(", ")", "#for spanish embedding", "\n", "for", "line", "in", "tqdm", "(", "file", ".", "readlines", "(", ")", ")", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "len", "(", "line", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "tokens", "=", "line", ".", "split", "(", ")", "\n", "if", "embedding_dim", "<", "0", ":", "\n", "                    ", "embedding_dim", "=", "len", "(", "tokens", ")", "-", "1", "\n", "", "else", ":", "\n", "\n", "                    ", "if", "(", "embedding_dim", "+", "1", "!=", "len", "(", "tokens", ")", ")", ":", "\n", "\n", "                        ", "remove", ".", "append", "(", "tokens", "[", "0", "]", ")", "\n", "continue", "\n", "", "", "embedd", "=", "np", ".", "empty", "(", "[", "1", ",", "embedding_dim", "]", ")", "\n", "embedd", "[", ":", "]", "=", "tokens", "[", "1", ":", "]", "\n", "first_col", "=", "tokens", "[", "0", "]", "\n", "embedding", "[", "first_col", "]", "=", "embedd", "\n", "", "", "return", "embedding", ",", "embedding_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.build_word_idx": [[134, 169], ["dict", "config.Config.idx2word.append", "config.Config.idx2word.append", "config.Config.idx2char.append", "config.Config.idx2char.append", "len", "len", "config.Config.idx2word.append", "len", "config.Config.idx2char.append"], "methods", ["None"], ["", "def", "build_word_idx", "(", "self", ",", "train_insts", ":", "List", "[", "Instance", "]", ",", "dev_insts", ":", "List", "[", "Instance", "]", ",", "test_insts", ":", "List", "[", "Instance", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Build the vocab 2 idx for all instances\n        :param train_insts:\n        :param dev_insts:\n        :param test_insts:\n        :return:\n        \"\"\"", "\n", "self", ".", "word2idx", "=", "dict", "(", ")", "\n", "self", ".", "idx2word", "=", "[", "]", "\n", "self", ".", "word2idx", "[", "self", ".", "PAD", "]", "=", "0", "\n", "self", ".", "idx2word", ".", "append", "(", "self", ".", "PAD", ")", "\n", "self", ".", "word2idx", "[", "self", ".", "UNK", "]", "=", "1", "\n", "self", ".", "unk_id", "=", "1", "\n", "self", ".", "idx2word", ".", "append", "(", "self", ".", "UNK", ")", "\n", "\n", "self", ".", "char2idx", "[", "self", ".", "PAD", "]", "=", "0", "\n", "self", ".", "idx2char", ".", "append", "(", "self", ".", "PAD", ")", "\n", "self", ".", "char2idx", "[", "self", ".", "UNK", "]", "=", "1", "\n", "self", ".", "idx2char", ".", "append", "(", "self", ".", "UNK", ")", "\n", "\n", "# extract char on train, dev, test", "\n", "for", "inst", "in", "train_insts", "+", "dev_insts", "+", "test_insts", ":", "\n", "            ", "for", "word", "in", "inst", ".", "input", ".", "words", ":", "\n", "                ", "if", "word", "not", "in", "self", ".", "word2idx", ":", "\n", "                    ", "self", ".", "word2idx", "[", "word", "]", "=", "len", "(", "self", ".", "word2idx", ")", "\n", "self", ".", "idx2word", ".", "append", "(", "word", ")", "\n", "# extract char only on train (doesn't matter for dev and test)", "\n", "", "", "", "for", "inst", "in", "train_insts", ":", "\n", "            ", "for", "word", "in", "inst", ".", "input", ".", "words", ":", "\n", "                ", "for", "c", "in", "word", ":", "\n", "                    ", "if", "c", "not", "in", "self", ".", "char2idx", ":", "\n", "                        ", "self", ".", "char2idx", "[", "c", "]", "=", "len", "(", "self", ".", "idx2char", ")", "\n", "self", ".", "idx2char", ".", "append", "(", "c", ")", "\n", "", "", "", "", "self", ".", "num_char", "=", "len", "(", "self", ".", "idx2char", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.build_emb_table": [[170, 195], ["print", "numpy.sqrt", "print", "print", "numpy.empty", "numpy.empty", "numpy.random.uniform", "len", "len", "len", "word.lower", "numpy.random.uniform", "word.lower"], "methods", ["None"], ["", "def", "build_emb_table", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        build the embedding table with pretrained word embeddings (if given otherwise, use random embeddings)\n        :return:\n        \"\"\"", "\n", "count", "=", "0", "\n", "print", "(", "\"Building the embedding table for vocabulary...\"", ")", "\n", "scale", "=", "np", ".", "sqrt", "(", "3.0", "/", "self", ".", "embedding_dim", ")", "\n", "if", "self", ".", "embedding", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"[Info] Use the pretrained word embedding to initialize: %d x %d\"", "%", "(", "len", "(", "self", ".", "word2idx", ")", ",", "self", ".", "embedding_dim", ")", ")", "\n", "self", ".", "word_embedding", "=", "np", ".", "empty", "(", "[", "len", "(", "self", ".", "word2idx", ")", ",", "self", ".", "embedding_dim", "]", ")", "\n", "for", "word", "in", "self", ".", "word2idx", ":", "\n", "                ", "if", "word", "in", "self", ".", "embedding", ":", "\n", "                    ", "self", ".", "word_embedding", "[", "self", ".", "word2idx", "[", "word", "]", ",", ":", "]", "=", "self", ".", "embedding", "[", "word", "]", "\n", "", "elif", "word", ".", "lower", "(", ")", "in", "self", ".", "embedding", ":", "\n", "                    ", "self", ".", "word_embedding", "[", "self", ".", "word2idx", "[", "word", "]", ",", ":", "]", "=", "self", ".", "embedding", "[", "word", ".", "lower", "(", ")", "]", "\n", "", "else", ":", "\n", "                    ", "count", "+=", "1", "\n", "self", ".", "word_embedding", "[", "self", ".", "word2idx", "[", "word", "]", ",", ":", "]", "=", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "[", "1", ",", "self", ".", "embedding_dim", "]", ")", "\n", "", "", "self", ".", "embedding", "=", "None", "\n", "", "else", ":", "\n", "            ", "self", ".", "word_embedding", "=", "np", ".", "empty", "(", "[", "len", "(", "self", ".", "word2idx", ")", ",", "self", ".", "embedding_dim", "]", ")", "\n", "for", "word", "in", "self", ".", "word2idx", ":", "\n", "                ", "self", ".", "word_embedding", "[", "self", ".", "word2idx", "[", "word", "]", ",", ":", "]", "=", "np", ".", "random", ".", "uniform", "(", "-", "scale", ",", "scale", ",", "[", "1", ",", "self", ".", "embedding_dim", "]", ")", "\n", "", "", "print", "(", "count", ")", "\n", "", "def", "build_label_idx", "(", "self", ",", "insts", ":", "List", "[", "Instance", "]", ")", "->", "None", ":", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.build_label_idx": [[195, 218], ["len", "config.Config.idx2labels.append", "len", "config.Config.idx2labels.append", "len", "config.Config.idx2labels.append", "len", "print", "print", "config.Config.idx2labels.append", "len"], "methods", ["None"], ["", "def", "build_label_idx", "(", "self", ",", "insts", ":", "List", "[", "Instance", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Build the mapping from label to index and index to labels.\n        :param insts: list of instances.\n        :return:\n        \"\"\"", "\n", "self", ".", "label2idx", "[", "self", ".", "PAD", "]", "=", "len", "(", "self", ".", "label2idx", ")", "\n", "self", ".", "idx2labels", ".", "append", "(", "self", ".", "PAD", ")", "\n", "for", "inst", "in", "insts", ":", "\n", "            ", "for", "label", "in", "inst", ".", "output", ":", "\n", "                ", "if", "label", "not", "in", "self", ".", "label2idx", ":", "\n", "                    ", "self", ".", "idx2labels", ".", "append", "(", "label", ")", "\n", "self", ".", "label2idx", "[", "label", "]", "=", "len", "(", "self", ".", "label2idx", ")", "\n", "\n", "", "", "", "self", ".", "label2idx", "[", "self", ".", "START_TAG", "]", "=", "len", "(", "self", ".", "label2idx", ")", "\n", "self", ".", "idx2labels", ".", "append", "(", "self", ".", "START_TAG", ")", "\n", "self", ".", "label2idx", "[", "self", ".", "STOP_TAG", "]", "=", "len", "(", "self", ".", "label2idx", ")", "\n", "self", ".", "idx2labels", ".", "append", "(", "self", ".", "STOP_TAG", ")", "\n", "self", ".", "label_size", "=", "len", "(", "self", ".", "label2idx", ")", "\n", "self", ".", "start_label_id", "=", "self", ".", "label2idx", "[", "self", ".", "START_TAG", "]", "\n", "self", ".", "stop_label_id", "=", "self", ".", "label2idx", "[", "self", ".", "STOP_TAG", "]", "\n", "print", "(", "\"#labels: {}\"", ".", "format", "(", "self", ".", "label_size", ")", ")", "\n", "print", "(", "\"label 2idx: {}\"", ".", "format", "(", "self", ".", "label2idx", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.build_label_idx_noadd": [[219, 235], ["len", "print", "print", "config.Config.idx2labels.append", "len"], "methods", ["None"], ["", "def", "build_label_idx_noadd", "(", "self", ",", "insts", ":", "List", "[", "Instance", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Build the mapping from label to index and index to labels.\n        :param insts: list of instances.\n        :return:\n        \"\"\"", "\n", "for", "inst", "in", "insts", ":", "\n", "            ", "for", "label", "in", "inst", ".", "output", ":", "\n", "                ", "if", "label", "not", "in", "self", ".", "label2idx", ":", "\n", "                    ", "self", ".", "idx2labels", ".", "append", "(", "label", ")", "\n", "self", ".", "label2idx", "[", "label", "]", "=", "len", "(", "self", ".", "label2idx", ")", "\n", "\n", "", "", "", "self", ".", "label_size", "=", "len", "(", "self", ".", "label2idx", ")", "\n", "\n", "print", "(", "\"#labels: {}\"", ".", "format", "(", "self", ".", "label_size", ")", ")", "\n", "print", "(", "\"label 2idx: {}\"", ".", "format", "(", "self", ".", "label2idx", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.use_iobes": [[237, 260], ["range", "len", "curr_entity.startswith", "curr_entity.startswith", "len", "curr_entity.replace", "curr_entity.startswith", "curr_entity.startswith", "curr_entity.replace", "next_entity.startswith", "next_entity.startswith", "curr_entity.replace", "next_entity.startswith", "next_entity.startswith", "curr_entity.replace"], "methods", ["None"], ["", "def", "use_iobes", "(", "self", ",", "insts", ":", "List", "[", "Instance", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Use IOBES tagging schema to replace the IOB tagging schema in the instance\n        :param insts:\n        :return:\n        \"\"\"", "\n", "for", "inst", "in", "insts", ":", "\n", "            ", "output", "=", "inst", ".", "output", "\n", "for", "pos", "in", "range", "(", "len", "(", "inst", ")", ")", ":", "\n", "                ", "curr_entity", "=", "output", "[", "pos", "]", "\n", "if", "pos", "==", "len", "(", "inst", ")", "-", "1", ":", "\n", "                    ", "if", "curr_entity", ".", "startswith", "(", "self", ".", "B", ")", ":", "\n", "                        ", "output", "[", "pos", "]", "=", "curr_entity", ".", "replace", "(", "self", ".", "B", ",", "self", ".", "S", ")", "\n", "", "elif", "curr_entity", ".", "startswith", "(", "self", ".", "I", ")", ":", "\n", "                        ", "output", "[", "pos", "]", "=", "curr_entity", ".", "replace", "(", "self", ".", "I", ",", "self", ".", "E", ")", "\n", "", "", "else", ":", "\n", "                    ", "next_entity", "=", "output", "[", "pos", "+", "1", "]", "\n", "if", "curr_entity", ".", "startswith", "(", "self", ".", "B", ")", ":", "\n", "                        ", "if", "next_entity", ".", "startswith", "(", "self", ".", "O", ")", "or", "next_entity", ".", "startswith", "(", "self", ".", "B", ")", ":", "\n", "                            ", "output", "[", "pos", "]", "=", "curr_entity", ".", "replace", "(", "self", ".", "B", ",", "self", ".", "S", ")", "\n", "", "", "elif", "curr_entity", ".", "startswith", "(", "self", ".", "I", ")", ":", "\n", "                        ", "if", "next_entity", ".", "startswith", "(", "self", ".", "O", ")", "or", "next_entity", ".", "startswith", "(", "self", ".", "B", ")", ":", "\n", "                            ", "output", "[", "pos", "]", "=", "curr_entity", ".", "replace", "(", "self", ".", "I", ",", "self", ".", "E", ")", "\n", "", "", "", "", "", "", "def", "use_iobes_gold", "(", "self", ",", "insts", ":", "List", "[", "Instance", "]", ")", "->", "None", ":", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.use_iobes_gold": [[260, 285], ["range", "len", "curr_entity.startswith", "curr_entity.startswith", "len", "curr_entity.replace", "curr_entity.startswith", "curr_entity.startswith", "curr_entity.replace", "next_entity.startswith", "next_entity.startswith", "curr_entity.replace", "next_entity.startswith", "next_entity.startswith", "curr_entity.replace"], "methods", ["None"], ["", "", "", "", "", "", "def", "use_iobes_gold", "(", "self", ",", "insts", ":", "List", "[", "Instance", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Use IOBES tagging schema to replace the IOB tagging schema in the instance\n        :param insts:\n        :return:\n        \"\"\"", "\n", "if", "(", "not", "insts", "[", "0", "]", ".", "gold_output", ")", ":", "\n", "            ", "return", "\n", "", "for", "inst", "in", "insts", ":", "\n", "            ", "output", "=", "inst", ".", "gold_output", "\n", "for", "pos", "in", "range", "(", "len", "(", "inst", ")", ")", ":", "\n", "                ", "curr_entity", "=", "output", "[", "pos", "]", "\n", "if", "pos", "==", "len", "(", "inst", ")", "-", "1", ":", "\n", "                    ", "if", "curr_entity", ".", "startswith", "(", "self", ".", "B", ")", ":", "\n", "                        ", "output", "[", "pos", "]", "=", "curr_entity", ".", "replace", "(", "self", ".", "B", ",", "self", ".", "S", ")", "\n", "", "elif", "curr_entity", ".", "startswith", "(", "self", ".", "I", ")", ":", "\n", "                        ", "output", "[", "pos", "]", "=", "curr_entity", ".", "replace", "(", "self", ".", "I", ",", "self", ".", "E", ")", "\n", "", "", "else", ":", "\n", "                    ", "next_entity", "=", "output", "[", "pos", "+", "1", "]", "\n", "if", "curr_entity", ".", "startswith", "(", "self", ".", "B", ")", ":", "\n", "                        ", "if", "next_entity", ".", "startswith", "(", "self", ".", "O", ")", "or", "next_entity", ".", "startswith", "(", "self", ".", "B", ")", ":", "\n", "                            ", "output", "[", "pos", "]", "=", "curr_entity", ".", "replace", "(", "self", ".", "B", ",", "self", ".", "S", ")", "\n", "", "", "elif", "curr_entity", ".", "startswith", "(", "self", ".", "I", ")", ":", "\n", "                        ", "if", "next_entity", ".", "startswith", "(", "self", ".", "O", ")", "or", "next_entity", ".", "startswith", "(", "self", ".", "B", ")", ":", "\n", "                            ", "output", "[", "pos", "]", "=", "curr_entity", ".", "replace", "(", "self", ".", "I", ",", "self", ".", "E", ")", "\n", "", "", "", "", "", "", "def", "map_insts_ids", "(", "self", ",", "insts", ":", "List", "[", "Instance", "]", ")", ":", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.map_insts_ids": [[285, 312], ["inst.char_ids.append", "inst.word_ids.append", "inst.word_ids.append", "inst.output_ids.append", "char_id.append", "char_id.append"], "methods", ["None"], ["", "", "", "", "", "", "def", "map_insts_ids", "(", "self", ",", "insts", ":", "List", "[", "Instance", "]", ")", ":", "\n", "        ", "\"\"\"\n        Create id for word, char and label in each instance.\n        :param insts:\n        :return:\n        \"\"\"", "\n", "for", "inst", "in", "insts", ":", "\n", "            ", "words", "=", "inst", ".", "input", ".", "words", "\n", "inst", ".", "word_ids", "=", "[", "]", "\n", "inst", ".", "char_ids", "=", "[", "]", "\n", "inst", ".", "output_ids", "=", "[", "]", "if", "inst", ".", "output", "else", "None", "\n", "\n", "for", "word", "in", "words", ":", "\n", "                ", "if", "word", "in", "self", ".", "word2idx", ":", "\n", "                    ", "inst", ".", "word_ids", ".", "append", "(", "self", ".", "word2idx", "[", "word", "]", ")", "\n", "", "else", ":", "\n", "                    ", "inst", ".", "word_ids", ".", "append", "(", "self", ".", "word2idx", "[", "self", ".", "UNK", "]", ")", "\n", "", "char_id", "=", "[", "]", "\n", "for", "c", "in", "word", ":", "\n", "                    ", "if", "c", "in", "self", ".", "char2idx", ":", "\n", "                        ", "char_id", ".", "append", "(", "self", ".", "char2idx", "[", "c", "]", ")", "\n", "", "else", ":", "\n", "                        ", "char_id", ".", "append", "(", "self", ".", "char2idx", "[", "self", ".", "UNK", "]", ")", "\n", "", "", "inst", ".", "char_ids", ".", "append", "(", "char_id", ")", "\n", "", "if", "inst", ".", "output", ":", "\n", "                ", "for", "label", "in", "inst", ".", "output", ":", "\n", "                    ", "inst", ".", "output_ids", ".", "append", "(", "self", ".", "label2idx", "[", "label", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.get_noise_mask": [[313, 322], ["range", "len", "inst.noise_mask.append", "inst.noise_mask.append"], "methods", ["None"], ["", "", "", "", "def", "get_noise_mask", "(", "self", ",", "insts", ")", ":", "\n", "        ", "for", "inst", "in", "insts", ":", "\n", "            ", "inst", ".", "noise_mask", "=", "[", "]", "if", "inst", ".", "gold_output", "else", "None", "\n", "if", "(", "inst", ".", "gold_output", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "inst", ".", "output", ")", ")", ":", "\n", "                    ", "if", "(", "inst", ".", "output", "[", "i", "]", "==", "inst", ".", "gold_output", "[", "i", "]", ")", ":", "\n", "                        ", "inst", ".", "noise_mask", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "                        ", "inst", ".", "noise_mask", ".", "append", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.config.Config.get_gold_label_ids": [[323, 329], ["inst.gold_output_ids.append"], "methods", ["None"], ["", "", "", "", "", "def", "get_gold_label_ids", "(", "self", ",", "insts", ")", ":", "\n", "        ", "for", "inst", "in", "insts", ":", "\n", "            ", "inst", ".", "gold_output_ids", "=", "[", "]", "if", "inst", ".", "gold_output", "else", "None", "\n", "if", "(", "inst", ".", "gold_output", ")", ":", "\n", "                ", "for", "label", "in", "inst", ".", "gold_output", ":", "\n", "                    ", "inst", ".", "gold_output_ids", ".", "append", "(", "self", ".", "label2idx", "[", "label", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.eval.Span.__init__": [[9, 19], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "left", ":", "int", ",", "right", ":", "int", ",", "type", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        A span compose of left, right (inclusive) and its entity label.\n        :param left:\n        :param right: inclusive.\n        :param type:\n        \"\"\"", "\n", "self", ".", "left", "=", "left", "\n", "self", ".", "right", "=", "right", "\n", "self", ".", "type", "=", "type", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.eval.Span.__eq__": [[20, 22], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "left", "==", "other", ".", "left", "and", "self", ".", "right", "==", "other", ".", "right", "and", "self", ".", "type", "==", "other", ".", "type", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.eval.Span.__hash__": [[23, 25], ["hash"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "hash", "(", "(", "self", ".", "left", ",", "self", ".", "right", ",", "self", ".", "type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.eval.evaluate_batch_insts_marginal": [[27, 82], ["word_seq_lens.tolist.tolist", "range", "numpy.asarray", "len", "[].tolist", "set", "range", "set", "range", "len", "len", "len", "len", "output[].startswith", "output[].startswith", "output[].startswith", "len", "prediction[].startswith", "prediction[].startswith", "prediction[].startswith", "set.intersection", "set.add", "set.add", "set.add", "set.add", "eval.Span", "eval.Span", "eval.Span", "eval.Span"], "function", ["None"], ["", "", "def", "evaluate_batch_insts_marginal", "(", "batch_insts", ":", "List", "[", "Instance", "]", ",", "\n", "batch_pred_ids", ":", "torch", ".", "Tensor", ",", "\n", "batch_gold_ids", ":", "torch", ".", "LongTensor", ",", "\n", "word_seq_lens", ":", "torch", ".", "LongTensor", ",", "\n", "idx2label", ":", "List", "[", "str", "]", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Evaluate a batch of instances and handling the padding positions.\n    :param batch_insts:  a batched of instances.\n    :param batch_pred_ids: Shape: (batch_size, max_length) prediction ids from the viterbi algorithm.\n    :param batch_gold_ids: Shape: (batch_size, max_length) gold ids.\n    :param word_seq_lens: Shape: (batch_size) the length for each instance.\n    :param idx2label: The idx to label mapping.\n    :return: numpy array containing (number of true positive, number of all positive, number of true positive + number of false negative)\n             You can also refer as (number of correctly predicted entities, number of entities predicted, number of entities in the dataset)\n    \"\"\"", "\n", "p", "=", "0", "\n", "total_entity", "=", "0", "\n", "total_predict", "=", "0", "\n", "word_seq_lens", "=", "word_seq_lens", ".", "tolist", "(", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "batch_pred_ids", ")", ")", ":", "\n", "        ", "length", "=", "word_seq_lens", "[", "idx", "]", "\n", "output", "=", "batch_gold_ids", "[", "idx", "]", "[", ":", "length", "]", ".", "tolist", "(", ")", "\n", "prediction", "=", "batch_pred_ids", "[", "idx", "]", "[", ":", "length", "]", "\n", "\n", "output", "=", "[", "idx2label", "[", "l", "]", "for", "l", "in", "output", "]", "\n", "\n", "prediction", "=", "[", "idx2label", "[", "l", "]", "for", "l", "in", "prediction", "]", "\n", "batch_insts", "[", "idx", "]", ".", "prediction", "=", "prediction", "\n", "#convert to span", "\n", "output_spans", "=", "set", "(", ")", "\n", "start", "=", "-", "1", "\n", "for", "i", "in", "range", "(", "len", "(", "output", ")", ")", ":", "\n", "            ", "if", "output", "[", "i", "]", ".", "startswith", "(", "\"B-\"", ")", ":", "\n", "                ", "start", "=", "i", "\n", "", "if", "output", "[", "i", "]", ".", "startswith", "(", "\"E-\"", ")", ":", "\n", "                ", "end", "=", "i", "\n", "output_spans", ".", "add", "(", "Span", "(", "start", ",", "end", ",", "output", "[", "i", "]", "[", "2", ":", "]", ")", ")", "\n", "", "if", "output", "[", "i", "]", ".", "startswith", "(", "\"S-\"", ")", ":", "\n", "                ", "output_spans", ".", "add", "(", "Span", "(", "i", ",", "i", ",", "output", "[", "i", "]", "[", "2", ":", "]", ")", ")", "\n", "", "", "predict_spans", "=", "set", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "prediction", ")", ")", ":", "\n", "            ", "if", "prediction", "[", "i", "]", ".", "startswith", "(", "\"B-\"", ")", ":", "\n", "                ", "start", "=", "i", "\n", "", "if", "prediction", "[", "i", "]", ".", "startswith", "(", "\"E-\"", ")", ":", "\n", "                ", "end", "=", "i", "\n", "predict_spans", ".", "add", "(", "Span", "(", "start", ",", "end", ",", "prediction", "[", "i", "]", "[", "2", ":", "]", ")", ")", "\n", "", "if", "prediction", "[", "i", "]", ".", "startswith", "(", "\"S-\"", ")", ":", "\n", "                ", "predict_spans", ".", "add", "(", "Span", "(", "i", ",", "i", ",", "prediction", "[", "i", "]", "[", "2", ":", "]", ")", ")", "\n", "\n", "", "", "total_entity", "+=", "len", "(", "output_spans", ")", "\n", "total_predict", "+=", "len", "(", "predict_spans", ")", "\n", "p", "+=", "len", "(", "predict_spans", ".", "intersection", "(", "output_spans", ")", ")", "\n", "\n", "\n", "", "return", "np", ".", "asarray", "(", "[", "p", ",", "total_predict", ",", "total_entity", "]", ",", "dtype", "=", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.eval.evaluate_batch_insts": [[83, 138], ["word_seq_lens.tolist.tolist", "range", "numpy.asarray", "len", "[].tolist", "[].tolist", "set", "range", "set", "range", "len", "len", "len", "len", "output[].startswith", "output[].startswith", "output[].startswith", "len", "prediction[].startswith", "prediction[].startswith", "prediction[].startswith", "set.intersection", "set.add", "set.add", "set.add", "set.add", "eval.Span", "eval.Span", "eval.Span", "eval.Span"], "function", ["None"], ["", "def", "evaluate_batch_insts", "(", "batch_insts", ":", "List", "[", "Instance", "]", ",", "\n", "batch_pred_ids", ":", "torch", ".", "Tensor", ",", "\n", "batch_gold_ids", ":", "torch", ".", "LongTensor", ",", "\n", "word_seq_lens", ":", "torch", ".", "LongTensor", ",", "\n", "idx2label", ":", "List", "[", "str", "]", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Evaluate a batch of instances and handling the padding positions.\n    :param batch_insts:  a batched of instances.\n    :param batch_pred_ids: Shape: (batch_size, max_length) prediction ids from the viterbi algorithm.\n    :param batch_gold_ids: Shape: (batch_size, max_length) gold ids.\n    :param word_seq_lens: Shape: (batch_size) the length for each instance.\n    :param idx2label: The idx to label mapping.\n    :return: numpy array containing (number of true positive, number of all positive, number of true positive + number of false negative)\n             You can also refer as (number of correctly predicted entities, number of entities predicted, number of entities in the dataset)\n    \"\"\"", "\n", "p", "=", "0", "\n", "total_entity", "=", "0", "\n", "total_predict", "=", "0", "\n", "word_seq_lens", "=", "word_seq_lens", ".", "tolist", "(", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "batch_pred_ids", ")", ")", ":", "\n", "        ", "length", "=", "word_seq_lens", "[", "idx", "]", "\n", "output", "=", "batch_gold_ids", "[", "idx", "]", "[", ":", "length", "]", ".", "tolist", "(", ")", "\n", "prediction", "=", "batch_pred_ids", "[", "idx", "]", "[", ":", "length", "]", ".", "tolist", "(", ")", "\n", "\n", "prediction", "=", "prediction", "[", ":", ":", "-", "1", "]", "\n", "\n", "output", "=", "[", "idx2label", "[", "l", "]", "for", "l", "in", "output", "]", "\n", "prediction", "=", "[", "idx2label", "[", "l", "]", "for", "l", "in", "prediction", "]", "\n", "batch_insts", "[", "idx", "]", ".", "prediction", "=", "prediction", "\n", "#convert to span", "\n", "output_spans", "=", "set", "(", ")", "\n", "start", "=", "-", "1", "\n", "for", "i", "in", "range", "(", "len", "(", "output", ")", ")", ":", "\n", "            ", "if", "output", "[", "i", "]", ".", "startswith", "(", "\"B-\"", ")", ":", "\n", "                ", "start", "=", "i", "\n", "", "if", "output", "[", "i", "]", ".", "startswith", "(", "\"E-\"", ")", ":", "\n", "                ", "end", "=", "i", "\n", "output_spans", ".", "add", "(", "Span", "(", "start", ",", "end", ",", "output", "[", "i", "]", "[", "2", ":", "]", ")", ")", "\n", "", "if", "output", "[", "i", "]", ".", "startswith", "(", "\"S-\"", ")", ":", "\n", "                ", "output_spans", ".", "add", "(", "Span", "(", "i", ",", "i", ",", "output", "[", "i", "]", "[", "2", ":", "]", ")", ")", "\n", "", "", "predict_spans", "=", "set", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "prediction", ")", ")", ":", "\n", "            ", "if", "prediction", "[", "i", "]", ".", "startswith", "(", "\"B-\"", ")", ":", "\n", "                ", "start", "=", "i", "\n", "", "if", "prediction", "[", "i", "]", ".", "startswith", "(", "\"E-\"", ")", ":", "\n", "                ", "end", "=", "i", "\n", "predict_spans", ".", "add", "(", "Span", "(", "start", ",", "end", ",", "prediction", "[", "i", "]", "[", "2", ":", "]", ")", ")", "\n", "", "if", "prediction", "[", "i", "]", ".", "startswith", "(", "\"S-\"", ")", ":", "\n", "                ", "predict_spans", ".", "add", "(", "Span", "(", "i", ",", "i", ",", "prediction", "[", "i", "]", "[", "2", ":", "]", ")", ")", "\n", "\n", "", "", "total_entity", "+=", "len", "(", "output_spans", ")", "\n", "total_predict", "+=", "len", "(", "predict_spans", ")", "\n", "p", "+=", "len", "(", "predict_spans", ".", "intersection", "(", "output_spans", ")", ")", "\n", "\n", "", "return", "np", ".", "asarray", "(", "[", "p", ",", "total_predict", ",", "total_entity", "]", ",", "dtype", "=", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.eval.do_prediction": [[139, 153], ["word_seq_lens.tolist.tolist", "range", "len", "[].tolist", "[].tolist"], "function", ["None"], ["", "def", "do_prediction", "(", "batch_pred_ids", ":", "torch", ".", "Tensor", ",", "\n", "batch_gold_ids", ":", "torch", ".", "LongTensor", ",", "\n", "word_seq_lens", ":", "torch", ".", "LongTensor", ",", "\n", "idx2label", ":", "List", "[", "str", "]", ")", ":", "\n", "    ", "word_seq_lens", "=", "word_seq_lens", ".", "tolist", "(", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "batch_pred_ids", ")", ")", ":", "\n", "        ", "length", "=", "word_seq_lens", "[", "idx", "]", "\n", "output", "=", "batch_gold_ids", "[", "idx", "]", "[", ":", "length", "]", ".", "tolist", "(", ")", "\n", "prediction", "=", "batch_pred_ids", "[", "idx", "]", "[", ":", "length", "]", ".", "tolist", "(", ")", "\n", "prediction", "=", "prediction", "[", ":", ":", "-", "1", "]", "\n", "output", "=", "[", "idx2label", "[", "l", "]", "for", "l", "in", "output", "]", "\n", "prediction", "=", "[", "idx2label", "[", "l", "]", "for", "l", "in", "prediction", "]", "\n", "batch_insts", "[", "idx", "]", ".", "prediction", "=", "prediction", "\n", "", "return", "output", ",", "prediction", "\n", "", ""]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.log_sum_exp_pytorch": [[14, 24], ["torch.max", "torch.max", "torch.max", "maxScores.view().expand", "torch.log", "torch.log", "torch.log", "maxScores.view", "torch.sum", "torch.sum", "torch.sum", "torch.exp", "torch.exp", "torch.exp", "float"], "function", ["None"], ["def", "log_sum_exp_pytorch", "(", "vec", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Calculate the log_sum_exp trick for the tensor.\n    :param vec: [batchSize * from_label * to_label].\n    :return: [batchSize * to_label]\n    \"\"\"", "\n", "maxScores", ",", "idx", "=", "torch", ".", "max", "(", "vec", ",", "1", ")", "\n", "maxScores", "[", "maxScores", "==", "-", "float", "(", "\"Inf\"", ")", "]", "=", "0", "\n", "maxScoresExpanded", "=", "maxScores", ".", "view", "(", "vec", ".", "shape", "[", "0", "]", ",", "1", ",", "vec", ".", "shape", "[", "2", "]", ")", ".", "expand", "(", "vec", ".", "shape", "[", "0", "]", ",", "vec", ".", "shape", "[", "1", "]", ",", "vec", ".", "shape", "[", "2", "]", ")", "\n", "return", "maxScores", "+", "torch", ".", "log", "(", "torch", ".", "sum", "(", "torch", ".", "exp", "(", "vec", "-", "maxScoresExpanded", ")", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.batching_list_instances": [[25, 36], ["len", "range", "batched_data.append", "utils.simple_batching"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.simple_batching"], ["", "def", "batching_list_instances", "(", "config", ":", "Config", ",", "insts", ":", "List", "[", "Instance", "]", ")", ":", "\n", "    ", "train_num", "=", "len", "(", "insts", ")", "\n", "batch_size", "=", "config", ".", "batch_size", "\n", "total_batch", "=", "train_num", "//", "batch_size", "+", "1", "if", "train_num", "%", "batch_size", "!=", "0", "else", "train_num", "//", "batch_size", "\n", "batched_data", "=", "[", "]", "\n", "\n", "for", "batch_id", "in", "range", "(", "total_batch", ")", ":", "\n", "        ", "one_batch_insts", "=", "insts", "[", "batch_id", "*", "batch_size", ":", "(", "batch_id", "+", "1", ")", "*", "batch_size", "]", "\n", "batched_data", ".", "append", "(", "simple_batching", "(", "config", ",", "one_batch_insts", ")", ")", "\n", "\n", "", "return", "batched_data", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.batching_list_instances_marginal": [[37, 47], ["len", "range", "batched_data.append", "utils.simple_batching_marginal"], "function", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.simple_batching_marginal"], ["", "def", "batching_list_instances_marginal", "(", "config", ":", "Config", ",", "insts", ":", "List", "[", "Instance", "]", ")", ":", "\n", "    ", "train_num", "=", "len", "(", "insts", ")", "\n", "batch_size", "=", "config", ".", "batch_size", "\n", "total_batch", "=", "train_num", "//", "batch_size", "+", "1", "if", "train_num", "%", "batch_size", "!=", "0", "else", "train_num", "//", "batch_size", "\n", "batched_data", "=", "[", "]", "\n", "for", "batch_id", "in", "range", "(", "total_batch", ")", ":", "\n", "        ", "one_batch_insts", "=", "insts", "[", "batch_id", "*", "batch_size", ":", "(", "batch_id", "+", "1", ")", "*", "batch_size", "]", "\n", "batched_data", ".", "append", "(", "simple_batching_marginal", "(", "config", ",", "one_batch_insts", ")", ")", "\n", "\n", "", "return", "batched_data", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.simple_batching": [[48, 123], ["len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "word_seq_len.to.max", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "char_seq_len.to.max", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "word_seq_tensor.to.to", "label_seq_tensor.to.to", "char_seq_tensor.to.to", "word_seq_len.to.to", "char_seq_len.to.to", "list", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "range", "torch.zeros.to", "torch.zeros.to", "map", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "range", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "list", "len", "len", "map", "int", "len"], "function", ["None"], ["", "def", "simple_batching", "(", "config", ",", "insts", ":", "List", "[", "Instance", "]", ")", "->", "Tuple", ":", "\n", "\n", "    ", "\"\"\"\n    batching these instances together and return tensors. The seq_tensors for word and char contain their word id and char id.\n    :return\n        word_seq_tensor: Shape: (batch_size, max_seq_length)\n        word_seq_len: Shape: (batch_size), the length of each sentence in a batch.\n        context_emb_tensor: Shape: (batch_size, max_seq_length, context_emb_size)\n        char_seq_tensor: Shape: (batch_size, max_seq_len, max_char_seq_len)\n        char_seq_len: Shape: (batch_size, max_seq_len),\n        label_seq_tensor: Shape: (batch_size, max_seq_length)\n    \"\"\"", "\n", "batch_size", "=", "len", "(", "insts", ")", "\n", "batch_data", "=", "insts", "\n", "label_size", "=", "config", ".", "label_size", "\n", "\n", "word_seq_len", "=", "torch", ".", "LongTensor", "(", "list", "(", "map", "(", "lambda", "inst", ":", "len", "(", "inst", ".", "input", ".", "words", ")", ",", "batch_data", ")", ")", ")", "\n", "max_seq_len", "=", "word_seq_len", ".", "max", "(", ")", "\n", "\n", "# NOTE: Use 1 here because the CharBiLSTM accepts", "\n", "char_seq_len", "=", "torch", ".", "LongTensor", "(", "[", "list", "(", "map", "(", "len", ",", "inst", ".", "input", ".", "words", ")", ")", "+", "[", "1", "]", "*", "(", "int", "(", "max_seq_len", ")", "-", "len", "(", "inst", ".", "input", ".", "words", ")", ")", "for", "inst", "in", "batch_data", "]", ")", "\n", "max_char_seq_len", "=", "char_seq_len", ".", "max", "(", ")", "\n", "\n", "context_emb_tensor", "=", "None", "\n", "if", "config", ".", "context_emb", "!=", "ContextEmb", ".", "none", ":", "\n", "        ", "emb_size", "=", "insts", "[", "0", "]", ".", "elmo_vec", ".", "shape", "[", "1", "]", "\n", "context_emb_tensor", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_seq_len", ",", "emb_size", ")", ")", "\n", "\n", "", "word_seq_tensor", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_seq_len", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "label_seq_tensor", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_seq_len", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "char_seq_tensor", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_seq_len", ",", "max_char_seq_len", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "annotation_mask", "=", "None", "\n", "if", "batch_data", "[", "0", "]", ".", "is_prediction", "is", "not", "None", ":", "\n", "        ", "annotation_mask", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_seq_len", ",", "label_size", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "", "gold_label_seq_tensor", "=", "None", "\n", "if", "(", "batch_data", "[", "0", "]", ".", "gold_output_ids", ")", ":", "\n", "        ", "gold_label_seq_tensor", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_seq_len", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "", "for", "idx", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "word_seq_tensor", "[", "idx", ",", ":", "word_seq_len", "[", "idx", "]", "]", "=", "torch", ".", "LongTensor", "(", "batch_data", "[", "idx", "]", ".", "word_ids", ")", "\n", "if", "batch_data", "[", "idx", "]", ".", "output_ids", ":", "\n", "            ", "label_seq_tensor", "[", "idx", ",", ":", "word_seq_len", "[", "idx", "]", "]", "=", "torch", ".", "LongTensor", "(", "batch_data", "[", "idx", "]", ".", "output_ids", ")", "\n", "", "if", "batch_data", "[", "idx", "]", ".", "gold_output_ids", ":", "\n", "            ", "gold_label_seq_tensor", "[", "idx", ",", ":", "word_seq_len", "[", "idx", "]", "]", "=", "torch", ".", "LongTensor", "(", "batch_data", "[", "idx", "]", ".", "gold_output_ids", ")", "\n", "\n", "", "if", "config", ".", "context_emb", "!=", "ContextEmb", ".", "none", ":", "\n", "            ", "context_emb_tensor", "[", "idx", ",", ":", "word_seq_len", "[", "idx", "]", ",", ":", "]", "=", "torch", ".", "from_numpy", "(", "batch_data", "[", "idx", "]", ".", "elmo_vec", ")", "\n", "\n", "", "if", "batch_data", "[", "idx", "]", ".", "is_prediction", "is", "not", "None", ":", "\n", "            ", "for", "pos", "in", "range", "(", "len", "(", "batch_data", "[", "idx", "]", ".", "input", ")", ")", ":", "\n", "                ", "if", "batch_data", "[", "idx", "]", ".", "is_prediction", "[", "pos", "]", ":", "\n", "                    ", "annotation_mask", "[", "idx", ",", "pos", ",", ":", "]", "=", "1", "\n", "annotation_mask", "[", "idx", ",", "pos", ",", "config", ".", "start_label_id", "]", "=", "0", "\n", "annotation_mask", "[", "idx", ",", "pos", ",", "config", ".", "stop_label_id", "]", "=", "0", "\n", "", "else", ":", "\n", "                    ", "annotation_mask", "[", "idx", ",", "pos", ",", "batch_data", "[", "idx", "]", ".", "output_ids", "[", "pos", "]", "]", "=", "1", "\n", "", "", "annotation_mask", "[", "idx", ",", "word_seq_len", "[", "idx", "]", ":", ",", ":", "]", "=", "1", "\n", "\n", "", "for", "word_idx", "in", "range", "(", "word_seq_len", "[", "idx", "]", ")", ":", "\n", "            ", "char_seq_tensor", "[", "idx", ",", "word_idx", ",", ":", "char_seq_len", "[", "idx", ",", "word_idx", "]", "]", "=", "torch", ".", "LongTensor", "(", "batch_data", "[", "idx", "]", ".", "char_ids", "[", "word_idx", "]", ")", "\n", "", "for", "wordIdx", "in", "range", "(", "word_seq_len", "[", "idx", "]", ",", "max_seq_len", ")", ":", "\n", "            ", "char_seq_tensor", "[", "idx", ",", "wordIdx", ",", "0", ":", "1", "]", "=", "torch", ".", "LongTensor", "(", "[", "config", ".", "char2idx", "[", "PAD", "]", "]", ")", "\n", "\n", "", "", "word_seq_tensor", "=", "word_seq_tensor", ".", "to", "(", "config", ".", "device", ")", "\n", "label_seq_tensor", "=", "label_seq_tensor", ".", "to", "(", "config", ".", "device", ")", "\n", "gold_label_seq_tensor", "=", "gold_label_seq_tensor", ".", "to", "(", "config", ".", "device", ")", "if", "gold_label_seq_tensor", "is", "not", "None", "else", "None", "\n", "char_seq_tensor", "=", "char_seq_tensor", ".", "to", "(", "config", ".", "device", ")", "\n", "word_seq_len", "=", "word_seq_len", ".", "to", "(", "config", ".", "device", ")", "\n", "char_seq_len", "=", "char_seq_len", ".", "to", "(", "config", ".", "device", ")", "\n", "annotation_mask", "=", "annotation_mask", ".", "to", "(", "config", ".", "device", ")", "if", "annotation_mask", "is", "not", "None", "else", "None", "\n", "\n", "return", "word_seq_tensor", ",", "word_seq_len", ",", "context_emb_tensor", ",", "char_seq_tensor", ",", "char_seq_len", ",", "annotation_mask", ",", "label_seq_tensor", ",", "gold_label_seq_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.simple_batching_marginal": [[124, 198], ["len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "word_seq_len.to.max", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "char_seq_len.to.max", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "word_seq_tensor.to.to", "label_seq_tensor.to.to", "char_seq_tensor.to.to", "word_seq_len.to.to", "char_seq_len.to.to", "list", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "range", "range", "torch.zeros.to", "torch.zeros.to", "map", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "range", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "list", "len", "len", "map", "int", "len"], "function", ["None"], ["", "def", "simple_batching_marginal", "(", "config", ",", "insts", ":", "List", "[", "Instance", "]", ")", "->", "Tuple", ":", "\n", "\n", "    ", "\"\"\"\n    batching these instances together and return tensors. The seq_tensors for word and char contain their word id and char id.\n    :return \n        word_seq_tensor: Shape: (batch_size, max_seq_length)\n        word_seq_len: Shape: (batch_size), the length of each sentence in a batch.\n        context_emb_tensor: Shape: (batch_size, max_seq_length, context_emb_size)\n        char_seq_tensor: Shape: (batch_size, max_seq_len, max_char_seq_len)\n        char_seq_len: Shape: (batch_size, max_seq_len), \n        label_seq_tensor: Shape: (batch_size, max_seq_length)\n    \"\"\"", "\n", "batch_size", "=", "len", "(", "insts", ")", "\n", "batch_data", "=", "insts", "\n", "label_size", "=", "config", ".", "label_size", "\n", "word_seq_len", "=", "torch", ".", "LongTensor", "(", "list", "(", "map", "(", "lambda", "inst", ":", "len", "(", "inst", ".", "input", ".", "words", ")", ",", "batch_data", ")", ")", ")", "\n", "max_seq_len", "=", "word_seq_len", ".", "max", "(", ")", "\n", "\n", "# NOTE: Use 1 here because the CharBiLSTM accepts", "\n", "char_seq_len", "=", "torch", ".", "LongTensor", "(", "[", "list", "(", "map", "(", "len", ",", "inst", ".", "input", ".", "words", ")", ")", "+", "[", "1", "]", "*", "(", "int", "(", "max_seq_len", ")", "-", "len", "(", "inst", ".", "input", ".", "words", ")", ")", "for", "inst", "in", "batch_data", "]", ")", "\n", "max_char_seq_len", "=", "char_seq_len", ".", "max", "(", ")", "\n", "\n", "context_emb_tensor", "=", "None", "\n", "if", "config", ".", "context_emb", "!=", "ContextEmb", ".", "none", ":", "\n", "        ", "emb_size", "=", "insts", "[", "0", "]", ".", "elmo_vec", ".", "shape", "[", "1", "]", "\n", "context_emb_tensor", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_seq_len", ",", "emb_size", ")", ")", "\n", "\n", "", "word_seq_tensor", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_seq_len", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "label_seq_tensor", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_seq_len", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "char_seq_tensor", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_seq_len", ",", "max_char_seq_len", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "annotation_mask", "=", "None", "\n", "if", "batch_data", "[", "0", "]", ".", "is_prediction", "is", "not", "None", ":", "\n", "        ", "annotation_mask", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_seq_len", ",", "label_size", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "", "gold_label_seq_tensor", "=", "None", "\n", "if", "(", "batch_data", "[", "0", "]", ".", "gold_output_ids", ")", ":", "\n", "        ", "gold_label_seq_tensor", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "max_seq_len", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "", "for", "idx", "in", "range", "(", "batch_size", ")", ":", "\n", "        ", "word_seq_tensor", "[", "idx", ",", ":", "word_seq_len", "[", "idx", "]", "]", "=", "torch", ".", "LongTensor", "(", "batch_data", "[", "idx", "]", ".", "word_ids", ")", "\n", "if", "batch_data", "[", "idx", "]", ".", "output_ids", ":", "\n", "            ", "label_seq_tensor", "[", "idx", ",", ":", "word_seq_len", "[", "idx", "]", "]", "=", "torch", ".", "LongTensor", "(", "batch_data", "[", "idx", "]", ".", "output_ids", ")", "\n", "", "if", "batch_data", "[", "idx", "]", ".", "gold_output_ids", ":", "\n", "            ", "gold_label_seq_tensor", "[", "idx", ",", ":", "word_seq_len", "[", "idx", "]", "]", "=", "torch", ".", "LongTensor", "(", "batch_data", "[", "idx", "]", ".", "gold_output_ids", ")", "\n", "\n", "", "if", "config", ".", "context_emb", "!=", "ContextEmb", ".", "none", ":", "\n", "            ", "context_emb_tensor", "[", "idx", ",", ":", "word_seq_len", "[", "idx", "]", ",", ":", "]", "=", "torch", ".", "from_numpy", "(", "batch_data", "[", "idx", "]", ".", "elmo_vec", ")", "\n", "\n", "", "if", "batch_data", "[", "idx", "]", ".", "is_prediction", "is", "not", "None", ":", "\n", "            ", "for", "pos", "in", "range", "(", "len", "(", "batch_data", "[", "idx", "]", ".", "input", ")", ")", ":", "\n", "                ", "if", "batch_data", "[", "idx", "]", ".", "is_prediction", "[", "pos", "]", ":", "\n", "                    ", "annotation_mask", "[", "idx", ",", "pos", ",", ":", "]", "=", "1", "\n", "\n", "", "else", ":", "\n", "                    ", "annotation_mask", "[", "idx", ",", "pos", ",", "batch_data", "[", "idx", "]", ".", "output_ids", "[", "pos", "]", "]", "=", "1", "\n", "", "", "annotation_mask", "[", "idx", ",", "word_seq_len", "[", "idx", "]", ":", ",", ":", "]", "=", "1", "\n", "\n", "", "for", "word_idx", "in", "range", "(", "word_seq_len", "[", "idx", "]", ")", ":", "\n", "            ", "char_seq_tensor", "[", "idx", ",", "word_idx", ",", ":", "char_seq_len", "[", "idx", ",", "word_idx", "]", "]", "=", "torch", ".", "LongTensor", "(", "batch_data", "[", "idx", "]", ".", "char_ids", "[", "word_idx", "]", ")", "\n", "", "for", "wordIdx", "in", "range", "(", "word_seq_len", "[", "idx", "]", ",", "max_seq_len", ")", ":", "\n", "            ", "char_seq_tensor", "[", "idx", ",", "wordIdx", ",", "0", ":", "1", "]", "=", "torch", ".", "LongTensor", "(", "[", "config", ".", "char2idx", "[", "PAD", "]", "]", ")", "\n", "\n", "", "", "word_seq_tensor", "=", "word_seq_tensor", ".", "to", "(", "config", ".", "device", ")", "\n", "label_seq_tensor", "=", "label_seq_tensor", ".", "to", "(", "config", ".", "device", ")", "\n", "gold_label_seq_tensor", "=", "gold_label_seq_tensor", ".", "to", "(", "config", ".", "device", ")", "if", "gold_label_seq_tensor", "is", "not", "None", "else", "None", "\n", "\n", "char_seq_tensor", "=", "char_seq_tensor", ".", "to", "(", "config", ".", "device", ")", "\n", "word_seq_len", "=", "word_seq_len", ".", "to", "(", "config", ".", "device", ")", "\n", "char_seq_len", "=", "char_seq_len", ".", "to", "(", "config", ".", "device", ")", "\n", "annotation_mask", "=", "annotation_mask", ".", "to", "(", "config", ".", "device", ")", "if", "annotation_mask", "is", "not", "None", "else", "None", "\n", "\n", "return", "word_seq_tensor", ",", "word_seq_len", ",", "context_emb_tensor", ",", "char_seq_tensor", ",", "char_seq_len", ",", "annotation_mask", ",", "label_seq_tensor", ",", "gold_label_seq_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.lr_decay": [[200, 213], ["print"], "function", ["None"], ["", "def", "lr_decay", "(", "config", ",", "optimizer", ":", "optim", ".", "Optimizer", ",", "epoch", ":", "int", ")", "->", "optim", ".", "Optimizer", ":", "\n", "    ", "\"\"\"\n    Method to decay the learning rate\n    :param config: configuration\n    :param optimizer: optimizer\n    :param epoch: epoch number\n    :return:\n    \"\"\"", "\n", "lr", "=", "config", ".", "learning_rate", "/", "(", "1", "+", "config", ".", "lr_decay", "*", "(", "epoch", "-", "1", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "", "print", "(", "'learning rate is set to: '", ",", "lr", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.load_elmo_vec": [[215, 229], ["open", "vec.detach().numpy", "len", "pickle.load", "vec.detach"], "function", ["None"], ["", "def", "load_elmo_vec", "(", "file", ":", "str", ",", "insts", ":", "List", "[", "Instance", "]", ")", ":", "\n", "    ", "\"\"\"\n    Load the elmo vectors and the vector will be saved within each instance with a member `elmo_vec`\n    :param file: the vector files for the ELMo vectors\n    :param insts: list of instances\n    :return:\n    \"\"\"", "\n", "f", "=", "open", "(", "file", ",", "'rb'", ")", "\n", "for", "inst", "in", "insts", ":", "\n", "        ", "vec", "=", "pickle", ".", "load", "(", "f", ")", "[", "0", "]", "[", "0", "]", "\n", "inst", ".", "elmo_vec", "=", "vec", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "size", "=", "vec", ".", "shape", "[", "1", "]", "\n", "assert", "(", "vec", ".", "shape", "[", "0", "]", "==", "len", "(", "inst", ".", "input", ".", "words", ")", ")", "\n", "", "return", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.get_optimizer": [[230, 242], ["model.parameters", "config.optimizer.lower", "print", "torch.SGD", "termcolor.colored", "config.optimizer.lower", "print", "torch.Adam", "print", "exit", "float", "termcolor.colored"], "function", ["None"], ["", "def", "get_optimizer", "(", "config", ":", "Config", ",", "model", ":", "nn", ".", "Module", ")", ":", "\n", "    ", "params", "=", "model", ".", "parameters", "(", ")", "\n", "if", "config", ".", "optimizer", ".", "lower", "(", ")", "==", "\"sgd\"", ":", "\n", "        ", "print", "(", "\n", "colored", "(", "\"Using SGD: lr is: {}, L2 regularization is: {}\"", ".", "format", "(", "config", ".", "learning_rate", ",", "config", ".", "l2", ")", ",", "'yellow'", ")", ")", "\n", "return", "optim", ".", "SGD", "(", "params", ",", "lr", "=", "config", ".", "learning_rate", ",", "weight_decay", "=", "float", "(", "config", ".", "l2", ")", ")", "\n", "", "elif", "config", ".", "optimizer", ".", "lower", "(", ")", "==", "\"adam\"", ":", "\n", "        ", "print", "(", "colored", "(", "\"Using Adam\"", ",", "'yellow'", ")", ")", "\n", "return", "optim", ".", "Adam", "(", "params", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Illegal optimizer: {}\"", ".", "format", "(", "config", ".", "optimizer", ")", ")", "\n", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.utils.write_results": [[245, 256], ["open", "open.close", "range", "open.write", "len", "open.write", "len", "len"], "function", ["None"], ["", "", "def", "write_results", "(", "filename", ":", "str", ",", "insts", ")", ":", "\n", "    ", "f", "=", "open", "(", "filename", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "\n", "for", "inst", "in", "insts", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "inst", ".", "input", ")", ")", ":", "\n", "            ", "words", "=", "inst", ".", "input", ".", "words", "\n", "output", "=", "inst", ".", "output", "\n", "prediction", "=", "inst", ".", "prediction", "\n", "assert", "len", "(", "output", ")", "==", "len", "(", "prediction", ")", "\n", "f", ".", "write", "(", "\"{}\\t{}\\t{}\\t{}\\n\"", ".", "format", "(", "i", ",", "words", "[", "i", "]", ",", "output", "[", "i", "]", ",", "prediction", "[", "i", "]", ")", ")", "\n", "", "f", ".", "write", "(", "\"\\n\"", ")", "\n", "", "f", ".", "close", "(", ")", "", "", ""]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.reader.Reader.__init__": [[8, 15], ["set"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "digit2zero", ":", "bool", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Read the dataset into Instance\n        :param digit2zero: convert the digits into 0, which is a common practice for LSTM-CRF.\n        \"\"\"", "\n", "self", ".", "digit2zero", "=", "digit2zero", "\n", "self", ".", "vocab", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.config.reader.Reader.read_txt": [[16, 58], ["print", "print", "open", "tqdm.tqdm.tqdm", "f.readlines", "line.rstrip.rstrip.rstrip", "words.append", "reader.Reader.vocab.add", "labels.append", "len", "common.Instance.set_id", "insts.append", "len", "re.sub", "len", "gold_labels.append", "common.Instance", "common.Instance", "len", "len", "line.rstrip.rstrip.split", "line.rstrip.rstrip.split", "len", "line.rstrip.rstrip.split", "common.Sentence", "common.Sentence", "line.rstrip.rstrip.split", "len", "line.rstrip.rstrip.split", "line.rstrip.rstrip.split", "line.rstrip.rstrip.split", "line.rstrip.rstrip.split", "line.rstrip.rstrip.split", "line.rstrip.rstrip.split"], "methods", ["home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.instance.Instance.set_id"], ["", "def", "read_txt", "(", "self", ",", "file", ":", "str", ",", "number", ":", "int", "=", "-", "1", ")", "->", "List", "[", "Instance", "]", ":", "\n", "        ", "print", "(", "\"Reading file: \"", "+", "file", ")", "\n", "insts", "=", "[", "]", "\n", "with", "open", "(", "file", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "            ", "words", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "gold_labels", "=", "[", "]", "\n", "for", "line", "in", "tqdm", "(", "f", ".", "readlines", "(", ")", ")", ":", "\n", "                ", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "if", "line", "==", "\"\"", ":", "\n", "                    ", "if", "(", "gold_labels", ")", ":", "\n", "                        ", "inst", "=", "Instance", "(", "Sentence", "(", "words", ")", ",", "labels", ",", "gold_labels", ")", "\n", "", "else", ":", "\n", "                        ", "inst", "=", "Instance", "(", "Sentence", "(", "words", ")", ",", "labels", ")", "\n", "", "inst", ".", "set_id", "(", "len", "(", "insts", ")", ")", "\n", "insts", ".", "append", "(", "inst", ")", "\n", "words", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "gold_labels", "=", "[", "]", "\n", "if", "len", "(", "insts", ")", "==", "number", ":", "\n", "                        ", "break", "\n", "", "continue", "\n", "\n", "", "if", "(", "len", "(", "line", ".", "split", "(", ")", ")", "==", "1", ")", ":", "\n", "\n", "                    ", "label", "=", "line", ".", "split", "(", ")", "[", "0", "]", "\n", "word", "=", "','", "\n", "\n", "", "else", ":", "\n", "                    ", "if", "(", "len", "(", "line", ".", "split", "(", ")", ")", "==", "2", ")", ":", "\n", "                        ", "word", ",", "label", "=", "line", ".", "split", "(", ")", "[", "0", "]", ",", "line", ".", "split", "(", ")", "[", "1", "]", "\n", "", "elif", "(", "len", "(", "line", ".", "split", "(", ")", ")", "==", "3", ")", ":", "\n", "                        ", "word", ",", "label", ",", "gold_label", "=", "line", ".", "split", "(", ")", "[", "0", "]", ",", "line", ".", "split", "(", ")", "[", "1", "]", ",", "line", ".", "split", "(", ")", "[", "2", "]", "\n", "", "", "if", "self", ".", "digit2zero", ":", "\n", "                    ", "word", "=", "re", ".", "sub", "(", "'\\d'", ",", "'0'", ",", "word", ")", "# replace digit with 0.", "\n", "", "words", ".", "append", "(", "word", ")", "\n", "self", ".", "vocab", ".", "add", "(", "word", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "if", "(", "len", "(", "line", ".", "split", "(", ")", ")", "==", "3", ")", ":", "\n", "                    ", "gold_labels", ".", "append", "(", "gold_label", ")", "\n", "", "", "", "print", "(", "\"number of sentences: {}\"", ".", "format", "(", "len", "(", "insts", ")", ")", ")", "\n", "return", "insts", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.sentence.Sentence.__init__": [[9, 17], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "words", ":", "List", "[", "str", "]", ",", "pos_tags", ":", "List", "[", "str", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        :param words:\n        :param pos_tags: By default, it is not required to have the pos tags, in case you need it/\n        \"\"\"", "\n", "self", ".", "words", "=", "words", "\n", "self", ".", "pos_tags", "=", "pos_tags", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.sentence.Sentence.get_words": [[18, 20], ["None"], "methods", ["None"], ["", "def", "get_words", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.sentence.Sentence.__len__": [[21, 23], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "words", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.span.Span.__init__": [[3, 8], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "left", ":", "int", ",", "right", ":", "int", ",", "type", ":", "str", ",", "inst_id", ":", "int", "=", "None", ")", ":", "\n", "        ", "self", ".", "left", "=", "left", "\n", "self", ".", "right", "=", "right", "\n", "self", ".", "type", "=", "type", "\n", "self", ".", "inst_id", "=", "inst_id", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.span.Span.__eq__": [[9, 15], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "curr", "=", "self", ".", "left", "==", "other", ".", "left", "and", "self", ".", "right", "==", "other", ".", "right", "and", "self", ".", "type", "==", "other", ".", "type", "\n", "if", "self", ".", "inst_id", "is", "None", ":", "\n", "            ", "return", "curr", "\n", "", "else", ":", "\n", "            ", "return", "curr", "and", "self", ".", "inst_id", "==", "other", ".", "inst_id", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.span.Span.__hash__": [[16, 21], ["hash", "hash"], "methods", ["None"], ["", "", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "inst_id", "is", "None", ":", "\n", "            ", "return", "hash", "(", "(", "self", ".", "left", ",", "self", ".", "right", ",", "self", ".", "type", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "hash", "(", "(", "self", ".", "inst_id", ",", "self", ".", "left", ",", "self", ".", "right", ",", "self", ".", "type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.instance.Instance.__init__": [[5, 23], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "input", ":", "Sentence", ",", "output", ":", "List", "[", "str", "]", "=", "None", ",", "gold_output", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n            Constructor for the instance.\n            :param input: sentence containing the words\n            :param output: each position has a label list. Because each position has a list of labels.\n        \"\"\"", "\n", "self", ".", "input", "=", "input", "\n", "self", ".", "output", "=", "output", "\n", "self", ".", "id", "=", "None", "\n", "self", ".", "marginals", "=", "None", "\n", "self", ".", "elmo_vec", "=", "None", "# used for loading the ELMo vector.", "\n", "self", ".", "word_ids", "=", "None", "\n", "self", ".", "char_ids", "=", "None", "\n", "self", ".", "output_ids", "=", "None", "\n", "self", ".", "gold_output_ids", "=", "None", "\n", "self", ".", "is_prediction", "=", "None", "\n", "self", ".", "noise_mask", "=", "None", "\n", "self", ".", "gold_output", "=", "gold_output", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.instance.Instance.set_id": [[25, 27], ["None"], "methods", ["None"], ["", "def", "set_id", "(", "self", ",", "id", ":", "int", ")", ":", "\n", "        ", "self", ".", "id", "=", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.liukun95_Noisy-NER-Confidence-Estimation.common.instance.Instance.__len__": [[28, 30], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "input", ")", "\n", "\n"]]}