{"home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.None.config.add_data_group": [[3, 12], ["group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument"], "function", ["None"], ["def", "add_data_group", "(", "group", ")", ":", "\n", "    ", "group", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "123", ")", "\n", "group", ".", "add_argument", "(", "'--dataset'", ",", "type", "=", "str", ",", "default", "=", "'AIDS'", ",", "help", "=", "\"used dataset\"", ")", "\n", "group", ".", "add_argument", "(", "'--data_path'", ",", "type", "=", "str", ",", "default", "=", "'../dataset'", ",", "help", "=", "\"the directory used to save dataset\"", ")", "\n", "group", ".", "add_argument", "(", "'--use_nlabel_asfeat'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"use node labels as (part of) node features\"", ")", "\n", "group", ".", "add_argument", "(", "'--use_org_node_attr'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"use node attributes as (part of) node features\"", ")", "\n", "group", ".", "add_argument", "(", "'--use_degree_asfeat'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"use node degrees as (part of) node features\"", ")", "\n", "group", ".", "add_argument", "(", "'--data_verbose'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"print detailed dataset info\"", ")", "\n", "group", ".", "add_argument", "(", "'--save_data'", ",", "action", "=", "'store_true'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.None.config.add_model_group": [[14, 32], ["group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument"], "function", ["None"], ["", "def", "add_model_group", "(", "group", ")", ":", "\n", "    ", "group", ".", "add_argument", "(", "'--model'", ",", "type", "=", "str", ",", "default", "=", "'gcn'", ",", "help", "=", "\"used model\"", ")", "\n", "group", ".", "add_argument", "(", "'--train_ratio'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "\"ratio of trainset from whole dataset\"", ")", "\n", "group", ".", "add_argument", "(", "'--hidden_dim'", ",", "nargs", "=", "'+'", ",", "default", "=", "[", "64", ",", "16", "]", ",", "type", "=", "int", ",", "help", "=", "'constrain how much products a vendor can have'", ")", "\n", "group", ".", "add_argument", "(", "'--num_head'", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "\"GAT head number\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "group", ".", "add_argument", "(", "'--train_epochs'", ",", "type", "=", "int", ",", "default", "=", "40", ")", "\n", "group", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "\n", "group", ".", "add_argument", "(", "'--lr_decay_steps'", ",", "nargs", "=", "'+'", ",", "default", "=", "[", "25", ",", "35", "]", ",", "type", "=", "int", ")", "\n", "group", ".", "add_argument", "(", "'--weight_decay'", ",", "type", "=", "float", ",", "default", "=", "5e-4", ")", "\n", "group", ".", "add_argument", "(", "'--dropout'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "group", ".", "add_argument", "(", "'--train_verbose'", ",", "action", "=", "'store_true'", ",", "help", "=", "\"print training details\"", ")", "\n", "group", ".", "add_argument", "(", "'--log_every'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'print every x epoch'", ")", "\n", "group", ".", "add_argument", "(", "'--eval_every'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'evaluate every x epoch'", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--clean_model_save_path'", ",", "type", "=", "str", ",", "default", "=", "'../save/model/clean'", ")", "\n", "group", ".", "add_argument", "(", "'--save_clean_model'", ",", "action", "=", "'store_true'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.None.config.add_atk_group": [[33, 57], ["group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument", "group.add_argument"], "function", ["None"], ["", "def", "add_atk_group", "(", "group", ")", ":", "\n", "    ", "group", ".", "add_argument", "(", "'--bkd_gratio_train'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "\"backdoor graph ratio in trainset\"", ")", "\n", "group", ".", "add_argument", "(", "'--bkd_gratio_test'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "\"backdoor graph ratio in testset\"", ")", "\n", "group", ".", "add_argument", "(", "'--bkd_num_pergraph'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"number of backdoor triggers per graph\"", ")", "\n", "group", ".", "add_argument", "(", "'--bkd_size'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "\"number of nodes for each trigger\"", ")", "\n", "group", ".", "add_argument", "(", "'--target_class'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "\"the targeted node/graph label\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--gtn_layernum'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "\"layer number of GraphTrojanNet\"", ")", "\n", "group", ".", "add_argument", "(", "'--pn_rate'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "\"ratio between trigger-embedded graphs (positive) and benign ones (negative)\"", ")", "\n", "group", ".", "add_argument", "(", "'--gtn_input_type'", ",", "type", "=", "str", ",", "default", "=", "'2hop'", ",", "help", "=", "\"how to process org graphs before inputting to GTN\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--resample_steps'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "help", "=", "\"# iterations to re-select graph samples\"", ")", "\n", "group", ".", "add_argument", "(", "'--bilevel_steps'", ",", "type", "=", "int", ",", "default", "=", "4", ",", "help", "=", "\"# bi-level optimization iterations\"", ")", "\n", "group", ".", "add_argument", "(", "'--gtn_lr'", ",", "type", "=", "float", ",", "default", "=", "0.01", ")", "\n", "group", ".", "add_argument", "(", "'--gtn_epochs'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "help", "=", "\"# attack epochs\"", ")", "\n", "group", ".", "add_argument", "(", "'--topo_activation'", ",", "type", "=", "str", ",", "default", "=", "'sigmoid'", ",", "help", "=", "\"activation function for topology generator\"", ")", "\n", "group", ".", "add_argument", "(", "'--feat_activation'", ",", "type", "=", "str", ",", "default", "=", "'relu'", ",", "help", "=", "\"activation function for feature generator\"", ")", "\n", "group", ".", "add_argument", "(", "'--topo_thrd'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "\"threshold for topology generator\"", ")", "\n", "group", ".", "add_argument", "(", "'--feat_thrd'", ",", "type", "=", "float", ",", "default", "=", "0", ",", "help", "=", "\"threshold for feature generator (only useful for binary feature)\"", ")", "\n", "\n", "group", ".", "add_argument", "(", "'--lambd'", ",", "type", "=", "float", ",", "default", "=", "1", ",", "help", "=", "\"a hyperparameter to balance attack loss components\"", ")", "\n", "# group.add_argument('--atk_verbose', action='store_true', help=\"print attack details\")", "\n", "group", ".", "add_argument", "(", "'--save_bkd_model'", ",", "action", "=", "'store_true'", ")", "\n", "group", ".", "add_argument", "(", "'--bkd_model_save_path'", ",", "type", "=", "str", ",", "default", "=", "'../save/model/bkd'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.None.config.parse_args": [[58, 69], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument_group", "argparse.ArgumentParser.add_argument_group", "argparse.ArgumentParser.add_argument_group", "config.add_data_group", "config.add_model_group", "config.add_atk_group", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.None.config.add_data_group", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.None.config.add_model_group", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.None.config.add_atk_group", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.None.config.parse_args"], ["", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "data_group", "=", "parser", ".", "add_argument_group", "(", "title", "=", "\"Data-related configuration\"", ")", "\n", "model_group", "=", "parser", ".", "add_argument_group", "(", "title", "=", "\"Model-related configuration\"", ")", "\n", "atk_group", "=", "parser", ".", "add_argument_group", "(", "title", "=", "\"Attack-related configuration\"", ")", "\n", "\n", "add_data_group", "(", "data_group", ")", "\n", "add_model_group", "(", "model_group", ")", "\n", "add_atk_group", "(", "atk_group", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.bkdcdd.select_cdd_graphs": [[11, 60], ["numpy.random.RandomState", "int", "copy.deepcopy", "numpy.ceil", "len", "np.random.RandomState.choice", "list", "list", "len", "len", "len", "len", "len", "set", "print", "numpy.array", "len", "len", "len", "list.append", "set", "set", "len", "len", "len", "list.append", "list.append", "len", "len"], "function", ["None"], ["def", "select_cdd_graphs", "(", "args", ",", "data", ":", "list", ",", "adj_list", ":", "list", ",", "subset", ":", "str", ")", ":", "\n", "    ", "'''\n    Given a data (train/test), (randomly or determinately) \n    pick up some graph to put backdoor information, return ids.\n    '''", "\n", "rs", "=", "np", ".", "random", ".", "RandomState", "(", "args", ".", "seed", ")", "\n", "graph_sizes", "=", "[", "np", ".", "array", "(", "adj", ")", ".", "shape", "[", "0", "]", "for", "adj", "in", "adj_list", "]", "\n", "bkd_graph_ratio", "=", "args", ".", "bkd_gratio_train", "if", "subset", "==", "'train'", "else", "args", ".", "bkd_gratio_test", "\n", "bkd_num", "=", "int", "(", "np", ".", "ceil", "(", "bkd_graph_ratio", "*", "len", "(", "data", ")", ")", ")", "\n", "\n", "assert", "len", "(", "data", ")", ">", "bkd_num", ",", "\"Graph Instances are not enough\"", "\n", "picked_ids", "=", "[", "]", "\n", "\n", "# Randomly pick up graphs as backdoor candidates from data", "\n", "remained_set", "=", "copy", ".", "deepcopy", "(", "data", ")", "\n", "loopcount", "=", "0", "\n", "while", "bkd_num", "-", "len", "(", "picked_ids", ")", ">", "0", "and", "len", "(", "remained_set", ")", ">", "0", "and", "loopcount", "<=", "50", ":", "\n", "        ", "loopcount", "+=", "1", "\n", "\n", "cdd_ids", "=", "rs", ".", "choice", "(", "remained_set", ",", "bkd_num", "-", "len", "(", "picked_ids", ")", ",", "replace", "=", "False", ")", "\n", "for", "gid", "in", "cdd_ids", ":", "\n", "            ", "if", "bkd_num", "-", "len", "(", "picked_ids", ")", "<=", "0", ":", "\n", "                ", "break", "\n", "", "gsize", "=", "graph_sizes", "[", "gid", "]", "\n", "if", "gsize", ">=", "3", "*", "args", ".", "bkd_size", "*", "args", ".", "bkd_num_pergraph", ":", "\n", "                ", "picked_ids", ".", "append", "(", "gid", ")", "\n", "\n", "", "", "if", "len", "(", "remained_set", ")", "<", "len", "(", "data", ")", ":", "\n", "            ", "for", "gid", "in", "cdd_ids", ":", "\n", "                ", "if", "bkd_num", "-", "len", "(", "picked_ids", ")", "<=", "0", ":", "\n", "                    ", "break", "\n", "", "gsize", "=", "graph_sizes", "[", "gid", "]", "\n", "if", "gsize", ">=", "1.5", "*", "args", ".", "bkd_size", "*", "args", ".", "bkd_num_pergraph", "and", "gid", "not", "in", "picked_ids", ":", "\n", "                    ", "picked_ids", ".", "append", "(", "gid", ")", "\n", "\n", "", "", "", "if", "len", "(", "remained_set", ")", "<", "len", "(", "data", ")", ":", "\n", "            ", "for", "gid", "in", "cdd_ids", ":", "\n", "                ", "if", "bkd_num", "-", "len", "(", "picked_ids", ")", "<=", "0", ":", "\n", "                    ", "break", "\n", "", "gsize", "=", "graph_sizes", "[", "gid", "]", "\n", "if", "gsize", ">=", "1.0", "*", "args", ".", "bkd_size", "*", "args", ".", "bkd_num_pergraph", "and", "gid", "not", "in", "picked_ids", ":", "\n", "                    ", "picked_ids", ".", "append", "(", "gid", ")", "\n", "\n", "", "", "", "picked_ids", "=", "list", "(", "set", "(", "picked_ids", ")", ")", "\n", "remained_set", "=", "list", "(", "set", "(", "remained_set", ")", "-", "set", "(", "picked_ids", ")", ")", "\n", "if", "len", "(", "remained_set", ")", "==", "0", "and", "bkd_num", ">", "len", "(", "picked_ids", ")", ":", "\n", "            ", "print", "(", "\"no more graph to pick, return insufficient candidate graphs, try smaller bkd-pattern or graph size\"", ")", "\n", "\n", "", "", "return", "picked_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.bkdcdd.select_cdd_nodes": [[62, 107], ["numpy.random.RandomState", "range", "int", "np.random.RandomState.choice", "picked_nodes.append", "len", "len", "len", "numpy.array_split", "numpy.array().tolist", "node_groups.append", "len", "len", "len", "len", "len", "range", "len", "len", "numpy.array", "len"], "function", ["None"], ["", "def", "select_cdd_nodes", "(", "args", ",", "graph_cdd_ids", ",", "adj_list", ")", ":", "\n", "    ", "'''\n    Given a graph instance, based on pre-determined standard,\n    find nodes who should be put backdoor information, return\n    their ids.\n\n    return: same sequece with bkd-gids\n            (1) a 2D list - bkd nodes under each graph\n            (2) and a 3D list - bkd node groups under each graph\n                (in case of each graph has multiple triggers)\n    '''", "\n", "rs", "=", "np", ".", "random", ".", "RandomState", "(", "args", ".", "seed", ")", "\n", "\n", "# step1: find backdoor nodes", "\n", "picked_nodes", "=", "[", "]", "# 2D, save all cdd graphs", "\n", "\n", "for", "gid", "in", "graph_cdd_ids", ":", "\n", "        ", "node_ids", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "adj_list", "[", "gid", "]", ")", ")", "]", "\n", "assert", "len", "(", "node_ids", ")", "==", "len", "(", "adj_list", "[", "gid", "]", ")", ",", "'node number in graph {} mismatch'", ".", "format", "(", "gid", ")", "\n", "\n", "bkd_node_num", "=", "int", "(", "args", ".", "bkd_num_pergraph", "*", "args", ".", "bkd_size", ")", "\n", "assert", "bkd_node_num", "<=", "len", "(", "adj_list", "[", "gid", "]", ")", ",", "\"error in SelectCddGraphs, candidate graph too small\"", "\n", "cur_picked_nodes", "=", "rs", ".", "choice", "(", "node_ids", ",", "bkd_node_num", ",", "replace", "=", "False", ")", "\n", "picked_nodes", ".", "append", "(", "cur_picked_nodes", ")", "\n", "\n", "# step2: match nodes", "\n", "", "assert", "len", "(", "picked_nodes", ")", "==", "len", "(", "graph_cdd_ids", ")", ",", "\"backdoor graphs & node groups mismatch, check SelectCddGraphs/SelectCddNodes\"", "\n", "\n", "node_groups", "=", "[", "]", "# 3D, grouped trigger nodes", "\n", "for", "i", "in", "range", "(", "len", "(", "graph_cdd_ids", ")", ")", ":", "# for each graph, devide candidate nodes into groups", "\n", "        ", "gid", "=", "graph_cdd_ids", "[", "i", "]", "\n", "nids", "=", "picked_nodes", "[", "i", "]", "\n", "\n", "assert", "len", "(", "nids", ")", "%", "args", ".", "bkd_size", "==", "0.0", ",", "\"Backdoor nodes cannot equally be divided, check SelectCddNodes-STEP1\"", "\n", "\n", "# groups within each graph", "\n", "groups", "=", "np", ".", "array_split", "(", "nids", ",", "len", "(", "nids", ")", "//", "args", ".", "bkd_size", ")", "\n", "# np.array_split return list[array([..]), array([...]), ]", "\n", "# thus transfer internal np.array into list", "\n", "# store groups as a 2D list.", "\n", "groups", "=", "np", ".", "array", "(", "groups", ")", ".", "tolist", "(", ")", "\n", "node_groups", ".", "append", "(", "groups", ")", "\n", "\n", "", "assert", "len", "(", "picked_nodes", ")", "==", "len", "(", "node_groups", ")", ",", "\"groups of bkd-nodes mismatch, check SelectCddNodes-STEP2\"", "\n", "return", "picked_nodes", ",", "node_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.graph.numpy_to_graph": [[5, 45], ["networkx.from_numpy_array", "G.to_directed.to_directed", "dgl.from_networkx", "G.to_directed.nodes", "list", "g.to.to", "node_features.items", "node_features.keys", "torch.device"], "function", ["None"], ["def", "numpy_to_graph", "(", "A", ",", "type_graph", "=", "'dgl'", ",", "node_features", "=", "None", ",", "to_cuda", "=", "True", ")", ":", "\n", "    ", "'''Convert numpy arrays to graph\n\n    Parameters\n    ----------\n    A : mxm array\n        Adjacency matrix\n    type_graph : str\n        'dgl' or 'nx'\n    node_features : dict\n        Optional, dictionary with key=feature name, value=list of size m\n        Allows user to specify node features\n\n    Returns\n\n    -------\n    Graph of 'type_graph' specification\n    '''", "\n", "\n", "G", "=", "nx", ".", "from_numpy_array", "(", "A", ")", "\n", "\n", "if", "node_features", "!=", "None", ":", "\n", "        ", "for", "n", "in", "G", ".", "nodes", "(", ")", ":", "\n", "            ", "for", "k", ",", "v", "in", "node_features", ".", "items", "(", ")", ":", "\n", "                ", "G", ".", "nodes", "[", "n", "]", "[", "k", "]", "=", "v", "[", "n", "]", "\n", "\n", "", "", "", "if", "type_graph", "==", "'nx'", ":", "\n", "        ", "return", "G", "\n", "\n", "", "G", "=", "G", ".", "to_directed", "(", ")", "\n", "\n", "if", "node_features", "!=", "None", ":", "\n", "        ", "node_attrs", "=", "list", "(", "node_features", ".", "keys", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "node_attrs", "=", "[", "]", "\n", "\n", "", "g", "=", "dgl", ".", "from_networkx", "(", "G", ",", "node_attrs", "=", "node_attrs", ",", "edge_attrs", "=", "[", "'weight'", "]", ")", "\n", "if", "to_cuda", ":", "\n", "        ", "g", "=", "g", ".", "to", "(", "torch", ".", "device", "(", "'cuda'", ")", ")", "\n", "", "return", "g", "", "", ""]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.batch.collate_batch": [[5, 31], ["len", "int", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.from_numpy().long", "torch.from_numpy().long", "len", "len", "numpy.max", "range", "torch.from_numpy", "torch.from_numpy", "numpy.array", "numpy.array", "range"], "function", ["None"], ["def", "collate_batch", "(", "batch", ")", ":", "\n", "    ", "'''\n    function: Creates a batch of same size graphs by zero-padding node features and adjacency matrices \n            up to the maximum number of nodes in the CURRENT batch rather than in the entire dataset.\n    param batch: [node_features*batch_size, A*batch_size, label*batch_size]\n    return: [padded feature matrices, padded adjecency matrices, non-padding positions, nodenums, labels]\n    '''", "\n", "B", "=", "len", "(", "batch", ")", "\n", "nodenums", "=", "[", "len", "(", "batch", "[", "b", "]", "[", "1", "]", ")", "for", "b", "in", "range", "(", "B", ")", "]", "\n", "if", "len", "(", "batch", "[", "0", "]", "[", "0", "]", ".", "shape", ")", "==", "2", ":", "\n", "        ", "C", "=", "batch", "[", "0", "]", "[", "0", "]", ".", "shape", "[", "1", "]", "# C is feature dim", "\n", "", "else", ":", "\n", "        ", "C", "=", "batch", "[", "0", "]", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "", "n_node_max", "=", "int", "(", "np", ".", "max", "(", "nodenums", ")", ")", "\n", "\n", "graph_support", "=", "torch", ".", "zeros", "(", "B", ",", "n_node_max", ")", "\n", "A", "=", "torch", ".", "zeros", "(", "B", ",", "n_node_max", ",", "n_node_max", ")", "\n", "X", "=", "torch", ".", "zeros", "(", "B", ",", "n_node_max", ",", "C", ")", "\n", "for", "b", "in", "range", "(", "B", ")", ":", "\n", "        ", "X", "[", "b", ",", ":", "nodenums", "[", "b", "]", "]", "=", "batch", "[", "b", "]", "[", "0", "]", "# store original values in top (no need to pad feat dim, node dim only)", "\n", "A", "[", "b", ",", ":", "nodenums", "[", "b", "]", ",", ":", "nodenums", "[", "b", "]", "]", "=", "batch", "[", "b", "]", "[", "1", "]", "# store original values in top-left corner", "\n", "graph_support", "[", "b", "]", "[", ":", "nodenums", "[", "b", "]", "]", "=", "1", "# mask with values of 0 for dummy (zero padded) nodes, otherwise 1", "\n", "\n", "", "nodenums", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "nodenums", ")", ")", ".", "long", "(", ")", "\n", "labels", "=", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "[", "batch", "[", "b", "]", "[", "2", "]", "for", "b", "in", "range", "(", "B", ")", "]", ")", ")", ".", "long", "(", ")", "\n", "return", "[", "X", ",", "A", ",", "graph_support", ",", "nodenums", ",", "labels", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.mask.gen_mask": [[5, 47], ["max", "range", "len", "len", "numpy.array", "torch.zeros", "torch.zeros"], "function", ["None"], ["def", "gen_mask", "(", "datareader", ",", "bkd_gids", ",", "bkd_nid_groups", ")", ":", "\n", "    ", "\"\"\"\n    Input a datareader and a list of backdoor candidate nodes (train/test),\n    generate 2 list of masks (2D) to each of them, for topology and feature,\n    respectively.\n    \n    Here a adj mask is (N, N), and feat mask is (N, F), where N is maximum \n    num of nodes among all graphs in a dataset, F is fixed feat dim value.\n    \n    About how to use the mask: Topo- and Feat-mask are used in a same manner:\n    (1) After the padding input (N, N/F) pass though its corresponding AdaptNet, \n        we get a (N, N/F) result for one graph instance.\n    (2) Simply do element-wise torch.mul with mask and this result, since we \n        only want to keep mutual information inside of a backdoor pattern.\n    (3) After masking redundant information, remember to remove additional dim\n        in row/col, recover this masked result back to original dim same with\n        corresponding graph instance.\n    (4) Simply add recovered result with initialized adj / feat matrix.\n    \n    About inputs:\n    - bkd_gids: 1D list\n    - bkd_node_groups: 3D list\n    \"\"\"", "\n", "nodenums", "=", "[", "len", "(", "adj", ")", "for", "adj", "in", "datareader", ".", "data", "[", "'adj_list'", "]", "]", "\n", "N", "=", "max", "(", "nodenums", ")", "\n", "F", "=", "np", ".", "array", "(", "datareader", ".", "data", "[", "'features'", "]", "[", "0", "]", ")", ".", "shape", "[", "1", "]", "\n", "topomask", "=", "{", "}", "\n", "featmask", "=", "{", "}", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "bkd_gids", ")", ")", ":", "\n", "        ", "gid", "=", "bkd_gids", "[", "i", "]", "\n", "groups", "=", "bkd_nid_groups", "[", "i", "]", "\n", "if", "gid", "not", "in", "topomask", ":", "topomask", "[", "gid", "]", "=", "torch", ".", "zeros", "(", "N", ",", "N", ")", "\n", "if", "gid", "not", "in", "featmask", ":", "featmask", "[", "gid", "]", "=", "torch", ".", "zeros", "(", "N", ",", "F", ")", "\n", "\n", "for", "group", "in", "groups", ":", "\n", "            ", "for", "nid", "in", "group", ":", "\n", "                ", "topomask", "[", "gid", "]", "[", "nid", "]", "[", "group", "]", "=", "1", "\n", "topomask", "[", "gid", "]", "[", "nid", "]", "[", "nid", "]", "=", "0", "\n", "featmask", "[", "gid", "]", "[", "nid", "]", "[", ":", ":", "]", "=", "1", "\n", "\n", "", "", "", "return", "topomask", ",", "featmask", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.mask.recover_mask": [[49, 70], ["copy.deepcopy"], "function", ["None"], ["", "def", "recover_mask", "(", "Ni", ",", "mask", ",", "for_whom", ")", ":", "\n", "    ", "\"\"\"\n    Step3 of the mask usage, recover each masked result back to original:\n    topomask[gid]: (N, N) --> (Ni, Ni)\n    featmask[gid]: (N, F) --> (Ni, F)\n    \n    Not change original mask\n    \n    About mask: \n    topomask: contains all topo masks in train/test set, dict.\n    featmask: contains all feat masks in train/test set, dict.\n    Return: mask for single graph instance\n    \"\"\"", "\n", "recovermask", "=", "copy", ".", "deepcopy", "(", "mask", ")", "\n", "\n", "if", "for_whom", "==", "'topo'", ":", "\n", "        ", "recovermask", "=", "recovermask", "[", ":", "Ni", ",", ":", "Ni", "]", "\n", "", "elif", "for_whom", "==", "'feat'", ":", "\n", "        ", "recovermask", "=", "recovermask", "[", ":", "Ni", "]", "\n", "\n", "", "return", "recovermask", "\n", "", ""]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.DataReader.__init__": [[85, 223], ["os.path.join", "numpy.random.RandomState", "os.listdir", "datareader.DataReader.read_graph_nodes_relations", "datareader.DataReader.read_graph_adj", "list", "numpy.array", "enumerate", "datareader.GetFinalFeatures", "numpy.min", "numpy.unique", "len", "print", "print", "print", "print", "print", "print", "len", "datareader.split_ids", "numpy.max", "print", "filter", "len", "datareader.DataReader.read_node_features", "datareader.DataReader.parse_txt_file", "datareader.DataReader.read_node_features", "len", "numpy.sum", "n_edges.append", "degrees.extend", "numpy.concatenate", "numpy.concatenate.min", "int", "len", "numpy.all", "print", "range", "numpy.unique", "numpy.unique", "print", "datareader.DataReader.rnd_state.permutation", "len", "len", "len", "list", "list", "int", "list", "nlabels.append", "numpy.zeros", "len", "numpy.mean", "numpy.std", "numpy.min", "numpy.max", "datareader.DataReader.__init__.stats"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.DataReader.read_graph_nodes_relations", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.DataReader.read_graph_adj", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.GetFinalFeatures", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.split_ids", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.DataReader.read_node_features", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.DataReader.parse_txt_file", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.DataReader.read_node_features"], ["def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "\n", "# self.args = args", "\n", "        ", "assert", "args", ".", "use_nlabel_asfeat", "or", "args", ".", "use_org_node_attr", "or", "args", ".", "use_degree_asfeat", ",", "'need at least one source to construct node features'", "\n", "\n", "self", ".", "data_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_path", ",", "args", ".", "dataset", ")", "\n", "self", ".", "rnd_state", "=", "np", ".", "random", ".", "RandomState", "(", "args", ".", "seed", ")", "\n", "files", "=", "os", ".", "listdir", "(", "self", ".", "data_path", ")", "\n", "data", "=", "{", "}", "\n", "\n", "\"\"\"\n        Load raw graphs, nodes, record in 2 dicts.\n        Load adj list for each graph with sequence of graph indicator.\n        Load node labels for each graph with sequence of graph indicator.\n        Load graph labels for each graph with sequence of graph indicator.\n        \"\"\"", "\n", "nodes", ",", "graphs", "=", "self", ".", "read_graph_nodes_relations", "(", "\n", "list", "(", "filter", "(", "lambda", "f", ":", "f", ".", "find", "(", "'graph_indicator'", ")", ">=", "0", ",", "files", ")", ")", "[", "0", "]", ")", "\n", "data", "[", "'adj_list'", "]", "=", "self", ".", "read_graph_adj", "(", "# in case of Tox21_Axx_...", "\n", "list", "(", "filter", "(", "lambda", "f", ":", "f", ".", "find", "(", "'_A.'", ")", ">=", "0", ",", "files", ")", ")", "[", "0", "]", ",", "nodes", ",", "graphs", ")", "\n", "\n", "node_labels_file", "=", "list", "(", "filter", "(", "lambda", "f", ":", "f", ".", "find", "(", "'node_labels'", ")", ">=", "0", ",", "files", ")", ")", "\n", "if", "len", "(", "node_labels_file", ")", "==", "1", ":", "\n", "            ", "data", "[", "'nlabels'", "]", "=", "self", ".", "read_node_features", "(", "\n", "node_labels_file", "[", "0", "]", ",", "nodes", ",", "graphs", ",", "fn", "=", "lambda", "s", ":", "int", "(", "s", ".", "strip", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "data", "[", "'nlabels'", "]", "=", "None", "\n", "\n", "", "data", "[", "'labels'", "]", "=", "np", ".", "array", "(", "\n", "self", ".", "parse_txt_file", "(", "\n", "list", "(", "filter", "(", "lambda", "f", ":", "f", ".", "find", "(", "'graph_labels'", ")", ">=", "0", "or", "f", ".", "find", "(", "'graph_attributes'", ")", ">=", "0", ",", "files", ")", ")", "[", "0", "]", ",", "\n", "line_parse_fn", "=", "lambda", "s", ":", "int", "(", "float", "(", "s", ".", "strip", "(", ")", ")", ")", ")", ")", "\n", "\n", "if", "args", ".", "use_org_node_attr", ":", "\n", "            ", "data", "[", "'attr'", "]", "=", "self", ".", "read_node_features", "(", "list", "(", "filter", "(", "lambda", "f", ":", "f", ".", "find", "(", "'node_attributes'", ")", ">=", "0", ",", "files", ")", ")", "[", "0", "]", ",", "\n", "nodes", ",", "graphs", ",", "\n", "fn", "=", "lambda", "s", ":", "np", ".", "array", "(", "list", "(", "map", "(", "float", ",", "s", ".", "strip", "(", ")", ".", "split", "(", "','", ")", ")", ")", ")", ")", "\n", "\n", "", "'''also include this part into GetFinalFeatures()\n        '''", "\n", "# In each graph sample, treat node labels (if have) as feature for one graph.", "\n", "nlabels", ",", "n_edges", ",", "degrees", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "sample_id", ",", "adj", "in", "enumerate", "(", "data", "[", "'adj_list'", "]", ")", ":", "\n", "            ", "N", "=", "len", "(", "adj", ")", "# number of nodes", "\n", "\n", "# some verifications", "\n", "if", "data", "[", "'nlabels'", "]", "is", "not", "None", ":", "\n", "                ", "assert", "N", "==", "len", "(", "data", "[", "'nlabels'", "]", "[", "sample_id", "]", ")", ",", "(", "N", ",", "len", "(", "data", "[", "'nlabels'", "]", "[", "sample_id", "]", ")", ")", "\n", "# if not np.allclose(adj, adj.T):", "\n", "#     print(sample_id, 'not symmetric')  # not symm is okay, maybe direct graph", "\n", "", "n", "=", "np", ".", "sum", "(", "adj", ")", "# total sum of edges", "\n", "# assert n % 2 == 0, n", "\n", "\n", "n_edges", ".", "append", "(", "int", "(", "n", "/", "2", ")", ")", "# undirected edges, so need to divide by 2", "\n", "degrees", ".", "extend", "(", "list", "(", "np", ".", "sum", "(", "adj", ",", "1", ")", ")", ")", "\n", "if", "data", "[", "'nlabels'", "]", "is", "not", "None", ":", "\n", "                ", "nlabels", ".", "append", "(", "np", ".", "array", "(", "data", "[", "'nlabels'", "]", "[", "sample_id", "]", ")", ")", "\n", "\n", "# Create nlabels over graphs as one-hot vectors for each node", "\n", "", "", "if", "data", "[", "'nlabels'", "]", "is", "not", "None", ":", "\n", "            ", "nlabels_all", "=", "np", ".", "concatenate", "(", "nlabels", ")", "\n", "nlabels_min", "=", "nlabels_all", ".", "min", "(", ")", "\n", "num_nlabels", "=", "int", "(", "nlabels_all", ".", "max", "(", ")", "-", "nlabels_min", "+", "1", ")", "# number of possible values", "\n", "\n", "\n", "\n", "#--------- Generate onehot-feature ---------#", "\n", "", "features", "=", "GetFinalFeatures", "(", "args", ",", "data", ")", "\n", "\n", "# final graph feature dim", "\n", "num_features", "=", "features", "[", "0", "]", ".", "shape", "[", "1", "]", "\n", "\n", "shapes", "=", "[", "len", "(", "adj", ")", "for", "adj", "in", "data", "[", "'adj_list'", "]", "]", "\n", "labels", "=", "data", "[", "'labels'", "]", "# graph class labels, np.ndarray", "\n", "labels", "-=", "np", ".", "min", "(", "labels", ")", "# to start from 0", "\n", "\n", "classes", "=", "np", ".", "unique", "(", "labels", ")", "\n", "num_classes", "=", "len", "(", "classes", ")", "\n", "\n", "\"\"\"\n        Test whether labels are successive, e.g., 0,1,2,3,4,..i, i+1,..\n        If not, make them successive. New labels still store in \"labels\".\n        \"\"\"", "\n", "if", "not", "np", ".", "all", "(", "np", ".", "diff", "(", "classes", ")", "==", "1", ")", ":", "\n", "            ", "print", "(", "'making labels sequential, otherwise pytorch might crash'", ")", "\n", "labels_new", "=", "np", ".", "zeros", "(", "labels", ".", "shape", ",", "dtype", "=", "labels", ".", "dtype", ")", "-", "1", "\n", "for", "lbl", "in", "range", "(", "num_classes", ")", ":", "\n", "                ", "labels_new", "[", "labels", "==", "classes", "[", "lbl", "]", "]", "=", "lbl", "\n", "", "labels", "=", "labels_new", "\n", "classes", "=", "np", ".", "unique", "(", "labels", ")", "\n", "assert", "len", "(", "np", ".", "unique", "(", "labels", ")", ")", "==", "num_classes", ",", "np", ".", "unique", "(", "labels", ")", "\n", "\n", "\n", "", "def", "stats", "(", "x", ")", ":", "\n", "            ", "return", "(", "np", ".", "mean", "(", "x", ")", ",", "np", ".", "std", "(", "x", ")", ",", "np", ".", "min", "(", "x", ")", ",", "np", ".", "max", "(", "x", ")", ")", "\n", "\n", "", "print", "(", "'N nodes avg/std/min/max: \\t%.2f/%.2f/%d/%d'", "%", "stats", "(", "shapes", ")", ")", "\n", "print", "(", "'N edges avg/std/min/max: \\t%.2f/%.2f/%d/%d'", "%", "stats", "(", "n_edges", ")", ")", "\n", "print", "(", "'Node degree avg/std/min/max: \\t%.2f/%.2f/%d/%d'", "%", "stats", "(", "degrees", ")", ")", "\n", "print", "(", "'Node features dim: \\t\\t%d'", "%", "num_features", ")", "\n", "print", "(", "'N classes: \\t\\t\\t%d'", "%", "num_classes", ")", "\n", "print", "(", "'Classes: \\t\\t\\t%s'", "%", "str", "(", "classes", ")", ")", "\n", "\n", "for", "lbl", "in", "classes", ":", "\n", "            ", "print", "(", "'Class %d: \\t\\t\\t%d samples'", "%", "(", "lbl", ",", "np", ".", "sum", "(", "labels", "==", "lbl", ")", ")", ")", "\n", "\n", "", "if", "args", ".", "data_verbose", ":", "\n", "            ", "if", "data", "[", "'nlabels'", "]", "is", "not", "None", ":", "\n", "                ", "for", "u", "in", "np", ".", "unique", "(", "nlabels_all", ")", ":", "\n", "                    ", "print", "(", "'nlabels {}, count {}/{}'", ".", "format", "(", "u", ",", "np", ".", "count_nonzero", "(", "nlabels_all", "==", "u", ")", ",", "len", "(", "nlabels_all", ")", ")", ")", "\n", "\n", "# some datasets like \"Fingerprint\" may lack graph in _indicator.txt", "\n", "#         N_graphs = len(labels)  # number of samples (graphs) in data", "\n", "#         assert N_graphs == len(data['adj_list']) == len(features), 'invalid data'", "\n", "", "", "", "N_graphs", "=", "len", "(", "data", "[", "'adj_list'", "]", ")", "\n", "\n", "# Create train/test sets", "\n", "train_gids", ",", "test_gids", "=", "split_ids", "(", "args", ",", "self", ".", "rnd_state", ".", "permutation", "(", "N_graphs", ")", ",", "self", ".", "rnd_state", ")", "\n", "splits", "=", "{", "'train'", ":", "train_gids", ",", "\n", "'test'", ":", "test_gids", "}", "\n", "\n", "data", "[", "'features'", "]", "=", "features", "\n", "data", "[", "'labels'", "]", "=", "labels", "\n", "data", "[", "'splits'", "]", "=", "splits", "\n", "data", "[", "'n_node_max'", "]", "=", "np", ".", "max", "(", "shapes", ")", "# max number of nodes", "\n", "data", "[", "'num_features'", "]", "=", "num_features", "\n", "data", "[", "'num_classes'", "]", "=", "num_classes", "\n", "\n", "self", ".", "data", "=", "data", "\n", "\n", "# print(len(data['features']), len(data['adj_list']), len(data['labels']))", "\n", "assert", "len", "(", "data", "[", "'features'", "]", ")", "==", "len", "(", "data", "[", "'adj_list'", "]", ")", "==", "len", "(", "data", "[", "'labels'", "]", ")", ",", "\"Graph Number Mismatch, Possible Reason: due to insuccessive graph indicator, \\\n                some gids are not existed in original indicator files, only thing is filtering graph labels. \\\n                Remember that insuccessive graph indicator is okay, graph labels-graphs are corresponding by \\\n                stored index in data['xxx'].\"", "\n", "print", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.DataReader.parse_txt_file": [[224, 233], ["open", "f.readlines", "os.path.join", "line_parse_fn"], "methods", ["None"], ["", "def", "parse_txt_file", "(", "self", ",", "fpath", ",", "line_parse_fn", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Read a file, split each line by pre-defined pattern (e.g., ','),  \n        save results in list. Transferring data into Int is done outside.\n        \"\"\"", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_path", ",", "fpath", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "data", "=", "[", "line_parse_fn", "(", "s", ")", "if", "line_parse_fn", "is", "not", "None", "else", "s", "for", "s", "in", "lines", "]", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.DataReader.read_graph_nodes_relations": [[235, 251], ["datareader.DataReader.parse_txt_file", "enumerate", "numpy.unique", "graphs[].append", "list", "numpy.array", "graphs.keys", "int", "s.rstrip"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.DataReader.parse_txt_file"], ["", "def", "read_graph_nodes_relations", "(", "self", ",", "fpath", ")", ":", "\n", "        ", "\"\"\"\n        From graph_indicator.txt file, find { node_id: graph_id } and { graph_id:[nodes] }.\n        \"\"\"", "\n", "graph_ids", "=", "self", ".", "parse_txt_file", "(", "fpath", ",", "\n", "line_parse_fn", "=", "lambda", "s", ":", "int", "(", "s", ".", "rstrip", "(", ")", ")", ")", "\n", "nodes", ",", "graphs", "=", "{", "}", ",", "{", "}", "\n", "for", "node_id", ",", "graph_id", "in", "enumerate", "(", "graph_ids", ")", ":", "\n", "            ", "if", "graph_id", "not", "in", "graphs", ":", "\n", "                ", "graphs", "[", "graph_id", "]", "=", "[", "]", "\n", "", "graphs", "[", "graph_id", "]", ".", "append", "(", "node_id", ")", "\n", "nodes", "[", "node_id", "]", "=", "graph_id", "\n", "", "graph_ids", "=", "np", ".", "unique", "(", "list", "(", "graphs", ".", "keys", "(", ")", ")", ")", "\n", "for", "graph_id", "in", "graph_ids", ":", "\n", "            ", "graphs", "[", "graph_id", "]", "=", "np", ".", "array", "(", "graphs", "[", "graph_id", "]", ")", "\n", "", "return", "nodes", ",", "graphs", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.DataReader.read_graph_adj": [[254, 289], ["datareader.DataReader.parse_txt_file", "sorted", "list", "int", "int", "len", "numpy.zeros", "numpy.where", "numpy.where", "len", "len", "graphs.keys", "adj_list.append", "adj_list.append", "s.split", "edge[].strip", "edge[].strip", "numpy.zeros", "len", "len"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.DataReader.parse_txt_file"], ["", "def", "read_graph_adj", "(", "self", ",", "fpath", ",", "nodes", ",", "graphs", ")", ":", "\n", "        ", "edges", "=", "self", ".", "parse_txt_file", "(", "fpath", ",", "\n", "line_parse_fn", "=", "lambda", "s", ":", "s", ".", "split", "(", "','", ")", ")", "\n", "\n", "adj_dict", "=", "{", "}", "\n", "for", "edge", "in", "edges", ":", "\n", "# Note: TU-datasets are all 1 based node id", "\n", "            ", "node1", "=", "int", "(", "edge", "[", "0", "]", ".", "strip", "(", ")", ")", "-", "1", "# -1 because of zero-indexing in our code", "\n", "node2", "=", "int", "(", "edge", "[", "1", "]", ".", "strip", "(", ")", ")", "-", "1", "\n", "graph_id", "=", "nodes", "[", "node1", "]", "\n", "\n", "# both nodes in edge side should in a same graph", "\n", "assert", "graph_id", "==", "nodes", "[", "node2", "]", ",", "(", "'invalid data'", ",", "graph_id", ",", "nodes", "[", "node2", "]", ")", "\n", "if", "graph_id", "not", "in", "adj_dict", ":", "\n", "                ", "n", "=", "len", "(", "graphs", "[", "graph_id", "]", ")", "\n", "adj_dict", "[", "graph_id", "]", "=", "np", ".", "zeros", "(", "(", "n", ",", "n", ")", ")", "\n", "\n", "", "ind1", "=", "np", ".", "where", "(", "graphs", "[", "graph_id", "]", "==", "node1", ")", "[", "0", "]", "\n", "ind2", "=", "np", ".", "where", "(", "graphs", "[", "graph_id", "]", "==", "node2", ")", "[", "0", "]", "\n", "assert", "len", "(", "ind1", ")", "==", "len", "(", "ind2", ")", "==", "1", ",", "(", "ind1", ",", "ind2", ")", "\n", "adj_dict", "[", "graph_id", "]", "[", "ind1", ",", "ind2", "]", "=", "1", "\n", "\n", "# no-connection graph may not included on code above,", "\n", "# should specially add it, e.g., graph-291 in Fingerprint", "\n", "# data set only have single node 1477 (1-based index),", "\n", "# which is not in edge file since it has no connection.", "\n", "# But still, we should add it to ensure the consistent.", "\n", "# some graphs in Tox21 also only have isolated nodes.", "\n", "", "adj_list", "=", "[", "]", "\n", "for", "gid", "in", "sorted", "(", "list", "(", "graphs", ".", "keys", "(", ")", ")", ")", ":", "\n", "            ", "if", "gid", "in", "adj_dict", ":", "\n", "                ", "adj_list", ".", "append", "(", "adj_dict", "[", "gid", "]", ")", "\n", "", "else", ":", "\n", "                ", "adj_list", ".", "append", "(", "np", ".", "zeros", "(", "(", "len", "(", "graphs", "[", "gid", "]", ")", ",", "len", "(", "graphs", "[", "gid", "]", ")", ")", ")", ")", "\n", "", "", "return", "adj_list", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.DataReader.read_node_features": [[291, 308], ["datareader.DataReader.parse_txt_file", "enumerate", "numpy.where", "len", "sorted", "len", "list", "graphs.keys"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.DataReader.parse_txt_file"], ["", "def", "read_node_features", "(", "self", ",", "fpath", ",", "nodes", ",", "graphs", ",", "fn", ")", ":", "\n", "        ", "'''\n        Return 'feature' graph by graph.\n        here 'feature' may refer to (1) node attributes; (2) node labels; (3) node degrees\n        '''", "\n", "node_features_all", "=", "self", ".", "parse_txt_file", "(", "fpath", ",", "line_parse_fn", "=", "fn", ")", "\n", "node_features", "=", "{", "}", "\n", "for", "node_id", ",", "x", "in", "enumerate", "(", "node_features_all", ")", ":", "\n", "            ", "graph_id", "=", "nodes", "[", "node_id", "]", "\n", "if", "graph_id", "not", "in", "node_features", ":", "\n", "                ", "node_features", "[", "graph_id", "]", "=", "[", "None", "]", "*", "len", "(", "graphs", "[", "graph_id", "]", ")", "\n", "", "ind", "=", "np", ".", "where", "(", "graphs", "[", "graph_id", "]", "==", "node_id", ")", "[", "0", "]", "# exactly find on index", "\n", "assert", "len", "(", "ind", ")", "==", "1", ",", "ind", "\n", "assert", "node_features", "[", "graph_id", "]", "[", "ind", "[", "0", "]", "]", "is", "None", ",", "node_features", "[", "graph_id", "]", "[", "ind", "[", "0", "]", "]", "\n", "node_features", "[", "graph_id", "]", "[", "ind", "[", "0", "]", "]", "=", "x", "\n", "", "node_features_lst", "=", "[", "node_features", "[", "graph_id", "]", "for", "graph_id", "in", "sorted", "(", "list", "(", "graphs", ".", "keys", "(", ")", ")", ")", "]", "\n", "return", "node_features_lst", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.GraphData.__init__": [[392, 396], ["datareader.GraphData.set_fold"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.GraphData.set_fold"], ["    ", "def", "__init__", "(", "self", ",", "datareader", ":", "DataReader", ",", "gids", ":", "list", ")", ":", "\n", "        ", "self", ".", "idx", "=", "gids", "\n", "self", ".", "rnd_state", "=", "datareader", ".", "rnd_state", "\n", "self", ".", "set_fold", "(", "datareader", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.GraphData.set_fold": [[397, 405], ["len"], "methods", ["None"], ["", "def", "set_fold", "(", "self", ",", "data", ")", ":", "\n", "        ", "self", ".", "total", "=", "len", "(", "data", "[", "'labels'", "]", ")", "\n", "self", ".", "n_node_max", "=", "data", "[", "'n_node_max'", "]", "\n", "self", ".", "num_classes", "=", "data", "[", "'num_classes'", "]", "\n", "self", ".", "num_features", "=", "data", "[", "'num_features'", "]", "\n", "self", ".", "labels", "=", "[", "data", "[", "'labels'", "]", "[", "i", "]", "for", "i", "in", "self", ".", "idx", "]", "\n", "self", ".", "adj_list", "=", "[", "data", "[", "'adj_list'", "]", "[", "i", "]", "for", "i", "in", "self", ".", "idx", "]", "\n", "self", ".", "features", "=", "[", "data", "[", "'features'", "]", "[", "i", "]", "for", "i", "in", "self", ".", "idx", "]", "\n", "# print('%s: %d/%d' % (self.split_name.upper(), len(self.labels), len(data['labels'])))", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.GraphData.__len__": [[407, 409], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.GraphData.__getitem__": [[410, 415], ["torch.as_tensor", "torch.as_tensor", "int"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "# convert to torch", "\n", "        ", "return", "[", "torch", ".", "as_tensor", "(", "self", ".", "features", "[", "index", "]", ",", "dtype", "=", "torch", ".", "float", ")", ",", "# node features", "\n", "torch", ".", "as_tensor", "(", "self", ".", "adj_list", "[", "index", "]", ",", "dtype", "=", "torch", ".", "float", ")", ",", "# adj matrices", "\n", "int", "(", "self", ".", "labels", "[", "index", "]", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.split_ids": [[13, 21], ["list", "list", "rs.choice", "int", "set", "set", "len"], "function", ["None"], ["def", "split_ids", "(", "args", ",", "gids", ",", "rs", ")", ":", "\n", "    ", "'''\n    single fold\n    gids: 0-based graph id list.\n    '''", "\n", "train_gids", "=", "list", "(", "rs", ".", "choice", "(", "gids", ",", "int", "(", "args", ".", "train_ratio", "*", "len", "(", "gids", ")", ")", ",", "replace", "=", "False", ")", ")", "\n", "test_gids", "=", "list", "(", "set", "(", "gids", ")", "-", "set", "(", "train_gids", ")", ")", "\n", "return", "train_gids", ",", "test_gids", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.datareader.GetFinalFeatures": [[310, 389], ["enumerate", "int", "enumerate", "len", "numpy.sum", "n_edges.append", "degrees.extend", "numpy.concatenate", "np.concatenate.min", "int", "numpy.max", "numpy.concatenate", "final_features.append", "int", "list", "nlabels.append", "numpy.empty", "numpy.empty", "numpy.zeros", "numpy.empty", "numpy.ones", "numpy.sum", "numpy.array", "numpy.zeros", "enumerate", "numpy.empty", "numpy.array", "np.concatenate.max", "numpy.array", "len", "numpy.arange", "numpy.sum().astype", "numpy.sum"], "function", ["None"], ["", "", "def", "GetFinalFeatures", "(", "args", ",", "data", ")", ":", "\n", "    ", "'''\n    Construct features for each graph instnace, may comes from 3 parts.\n    Each element in 'features' refers to constructed feature mat\n    to a graph. This feature mas has shape (Ni, Di), where Ni is number\n    of nodes in graph_i, and Di is combined feature dimension, may comes\n    from node labels, node features and degree.\n    '''", "\n", "\n", "# In each graph sample, treat node labels (if have) as feature for one graph.", "\n", "nlabels", ",", "n_edges", ",", "degrees", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "sample_id", ",", "adj", "in", "enumerate", "(", "data", "[", "'adj_list'", "]", ")", ":", "\n", "        ", "N", "=", "len", "(", "adj", ")", "# number of nodes", "\n", "n", "=", "np", ".", "sum", "(", "adj", ")", "# total sum of edges", "\n", "\n", "n_edges", ".", "append", "(", "int", "(", "n", "/", "2", ")", ")", "# undirected edges, so need to divide by 2", "\n", "degrees", ".", "extend", "(", "list", "(", "np", ".", "sum", "(", "adj", ",", "1", ")", ")", ")", "\n", "if", "data", "[", "'nlabels'", "]", "is", "not", "None", ":", "\n", "            ", "nlabels", ".", "append", "(", "np", ".", "array", "(", "data", "[", "'nlabels'", "]", "[", "sample_id", "]", ")", ")", "\n", "\n", "# Create features over graphs as one-hot vectors for each node", "\n", "", "", "if", "data", "[", "'nlabels'", "]", "is", "not", "None", ":", "\n", "        ", "nlabels_all", "=", "np", ".", "concatenate", "(", "nlabels", ")", "\n", "nlabels_min", "=", "nlabels_all", ".", "min", "(", ")", "\n", "num_nlabels", "=", "int", "(", "nlabels_all", ".", "max", "(", ")", "-", "nlabels_min", "+", "1", ")", "# number of possible values", "\n", "\n", "", "final_features", "=", "[", "]", "\n", "max_degree", "=", "int", "(", "np", ".", "max", "(", "degrees", ")", ")", "# maximum node degree among all graphs", "\n", "for", "sample_id", ",", "adj", "in", "enumerate", "(", "data", "[", "'adj_list'", "]", ")", ":", "\n", "        ", "N", "=", "adj", ".", "shape", "[", "0", "]", "\n", "\n", "# OneHot Feature: (N, D), where D is all possible feature nums ", "\n", "# among ondes within a graph. Each position in is 0/1 to show", "\n", "# whether it has/hasnot a corresopnding feature here. E.g., if ", "\n", "# original features (also original node labels) range from 3~8, ", "\n", "# now D = 6 (8-3+1), feature \"3\" will map to position \"0\", even ", "\n", "# though there are multiple \"3\" in original feature vector.", "\n", "\n", "# This is down inside of one single graph.", "\n", "\n", "\n", "# part 1: one-hot nlabels as feature", "\n", "if", "args", ".", "use_nlabel_asfeat", ":", "\n", "            ", "if", "data", "[", "'nlabels'", "]", "is", "not", "None", ":", "\n", "                ", "x", "=", "data", "[", "'nlabels'", "]", "[", "sample_id", "]", "\n", "nlabels_onehot", "=", "np", ".", "zeros", "(", "(", "len", "(", "x", ")", ",", "num_nlabels", ")", ")", "\n", "for", "node", ",", "value", "in", "enumerate", "(", "x", ")", ":", "\n", "                    ", "if", "value", "is", "not", "None", ":", "\n", "                        ", "nlabels_onehot", "[", "node", ",", "value", "-", "nlabels_min", "]", "=", "1", "\n", "", "", "", "else", ":", "\n", "                ", "nlabels_onehot", "=", "np", ".", "empty", "(", "(", "N", ",", "0", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "nlabels_onehot", "=", "np", ".", "empty", "(", "(", "N", ",", "0", ")", ")", "\n", "\n", "# part 2 (optional, not always have): original node features", "\n", "", "if", "args", ".", "use_org_node_attr", ":", "\n", "            ", "if", "args", ".", "dataset", "in", "[", "'COLORS-3'", ",", "'TRIANGLES'", "]", ":", "\n", "# first column corresponds to node attention and shouldn't be used as node features", "\n", "                ", "feature_attr", "=", "np", ".", "array", "(", "data", "[", "'attr'", "]", "[", "sample_id", "]", ")", "[", ":", ",", "1", ":", "]", "\n", "", "else", ":", "\n", "                ", "feature_attr", "=", "np", ".", "array", "(", "data", "[", "'attr'", "]", "[", "sample_id", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "feature_attr", "=", "np", ".", "empty", "(", "(", "N", ",", "0", ")", ")", "\n", "\n", "# part 3 (optinal): node degree ", "\n", "", "if", "args", ".", "use_degree_asfeat", ":", "\n", "            ", "degree_onehot", "=", "np", ".", "zeros", "(", "(", "N", ",", "max_degree", "+", "1", ")", ")", "\n", "degree_onehot", "[", "np", ".", "arange", "(", "N", ")", ",", "np", ".", "sum", "(", "adj", ",", "1", ")", ".", "astype", "(", "np", ".", "int32", ")", "]", "=", "1", "\n", "", "else", ":", "\n", "            ", "degree_onehot", "=", "np", ".", "empty", "(", "(", "N", ",", "0", ")", ")", "\n", "\n", "", "node_features", "=", "np", ".", "concatenate", "(", "(", "nlabels_onehot", ",", "feature_attr", ",", "degree_onehot", ")", ",", "axis", "=", "1", ")", "\n", "if", "node_features", ".", "shape", "[", "1", "]", "==", "0", ":", "\n", "# dummy features for datasets without node labels/attributes", "\n", "# node degree features can be used instead", "\n", "            ", "node_features", "=", "np", ".", "ones", "(", "(", "N", ",", "1", ")", ")", "\n", "", "final_features", ".", "append", "(", "node_features", ")", "\n", "\n", "", "return", "final_features", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.input.gen_input": [[4, 79], ["int", "Ainputs.keys", "numpy.pad().tolist", "numpy.pad().tolist", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.array", "As[].clone().detach", "torch.mm", "torch.add", "torch.where", "As[].fill_diagonal_", "range", "numpy.pad", "numpy.pad", "torch.mm", "torch.tensor", "torch.tensor", "As[].clone().detach", "torch.mm", "torch.add", "torch.diag", "len", "range", "NotImplementedError", "As[].clone", "torch.sum", "torch.pow", "torch.mm", "torch.mm", "torch.add", "torch.where", "As[].fill_diagonal_", "torch.add", "torch.diag", "len", "As[].clone", "torch.mm", "torch.tensor", "torch.tensor", "torch.sum", "torch.pow", "torch.mm", "torch.mm"], "function", ["None"], ["def", "gen_input", "(", "args", ",", "datareader", ",", "bkd_gids", ")", ":", "\n", "    ", "\"\"\"\n    Prepare inputs for GTN, topo input and feat input together.\n    \n    About inputs (of this function):\n    - args: control adapt-input type \n    \n    Note: Extend input size as (N, N) / (N, F) where N is max node num among all graphs\n    \"\"\"", "\n", "As", "=", "{", "}", "\n", "Xs", "=", "{", "}", "\n", "for", "gid", "in", "bkd_gids", ":", "\n", "        ", "if", "gid", "not", "in", "As", ":", "As", "[", "gid", "]", "=", "torch", ".", "tensor", "(", "datareader", ".", "data", "[", "'adj_list'", "]", "[", "gid", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "if", "gid", "not", "in", "Xs", ":", "Xs", "[", "gid", "]", "=", "torch", ".", "tensor", "(", "datareader", ".", "data", "[", "'features'", "]", "[", "gid", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "", "Ainputs", "=", "{", "}", "\n", "Xinputs", "=", "{", "}", "\n", "\n", "if", "args", ".", "gtn_input_type", "==", "'1hop'", ":", "\n", "        ", "for", "gid", "in", "bkd_gids", ":", "\n", "            ", "if", "gid", "not", "in", "Ainputs", ":", "Ainputs", "[", "gid", "]", "=", "As", "[", "gid", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "gid", "not", "in", "Xinputs", ":", "Xinputs", "[", "gid", "]", "=", "torch", ".", "mm", "(", "Ainputs", "[", "gid", "]", ",", "Xs", "[", "gid", "]", ")", "\n", "\n", "", "", "elif", "args", ".", "gtn_input_type", "==", "'2hop'", ":", "\n", "        ", "for", "gid", "in", "bkd_gids", ":", "\n", "            ", "As", "[", "gid", "]", "=", "torch", ".", "add", "(", "As", "[", "gid", "]", ",", "torch", ".", "mm", "(", "As", "[", "gid", "]", ",", "As", "[", "gid", "]", ")", ")", "\n", "As", "[", "gid", "]", "=", "torch", ".", "where", "(", "As", "[", "gid", "]", ">", "0", ",", "torch", ".", "tensor", "(", "1.0", ",", "requires_grad", "=", "True", ")", ",", "\n", "torch", ".", "tensor", "(", "0.0", ",", "requires_grad", "=", "True", ")", ")", "\n", "As", "[", "gid", "]", ".", "fill_diagonal_", "(", "0.0", ")", "\n", "\n", "", "for", "gid", "in", "bkd_gids", ":", "\n", "            ", "if", "gid", "not", "in", "Ainputs", ":", "Ainputs", "[", "gid", "]", "=", "As", "[", "gid", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "gid", "not", "in", "Xinputs", ":", "Xinputs", "[", "gid", "]", "=", "torch", ".", "mm", "(", "Ainputs", "[", "gid", "]", ",", "Xs", "[", "gid", "]", ")", "\n", "\n", "\n", "", "", "elif", "args", ".", "gtn_input_type", "==", "'1hop_degree'", ":", "\n", "        ", "rowsums", "=", "[", "torch", ".", "add", "(", "torch", ".", "sum", "(", "As", "[", "gid", "]", ",", "dim", "=", "1", ")", ",", "1e-6", ")", "for", "gid", "in", "bkd_gids", "]", "\n", "re_Ds", "=", "[", "torch", ".", "diag", "(", "torch", ".", "pow", "(", "rowsum", ",", "-", "1", ")", ")", "for", "rowsum", "in", "rowsums", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "bkd_gids", ")", ")", ":", "\n", "            ", "gid", "=", "bkd_gids", "[", "i", "]", "\n", "if", "gid", "not", "in", "Ainputs", ":", "Ainputs", "[", "gid", "]", "=", "torch", ".", "mm", "(", "re_Ds", "[", "i", "]", ",", "As", "[", "gid", "]", ")", "\n", "if", "gid", "not", "in", "Xinputs", ":", "Xinputs", "[", "gid", "]", "=", "torch", ".", "mm", "(", "Ainputs", "[", "gid", "]", ",", "Xs", "[", "gid", "]", ")", "\n", "\n", "\n", "", "", "elif", "args", ".", "gtn_input_type", "==", "'2hop_degree'", ":", "\n", "        ", "for", "gid", "in", "bkd_gids", ":", "\n", "            ", "As", "[", "gid", "]", "=", "torch", ".", "add", "(", "As", "[", "gid", "]", ",", "torch", ".", "mm", "(", "As", "[", "gid", "]", ",", "As", "[", "gid", "]", ")", ")", "\n", "As", "[", "gid", "]", "=", "torch", ".", "where", "(", "As", "[", "gid", "]", ">", "0", ",", "torch", ".", "tensor", "(", "1.0", ",", "requires_grad", "=", "True", ")", ",", "\n", "torch", ".", "tensor", "(", "0.0", ",", "requires_grad", "=", "True", ")", ")", "\n", "As", "[", "gid", "]", ".", "fill_diagonal_", "(", "0.0", ")", "\n", "\n", "", "rowsums", "=", "[", "torch", ".", "add", "(", "torch", ".", "sum", "(", "As", "[", "gid", "]", ",", "dim", "=", "1", ")", ",", "1e-6", ")", "for", "gid", "in", "bkd_gids", "]", "\n", "re_Ds", "=", "[", "torch", ".", "diag", "(", "torch", ".", "pow", "(", "rowsum", ",", "-", "1", ")", ")", "for", "rowsum", "in", "rowsums", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "bkd_gids", ")", ")", ":", "\n", "            ", "gid", "=", "bkd_gids", "[", "i", "]", "\n", "if", "gid", "not", "in", "Ainputs", ":", "Ainputs", "[", "gid", "]", "=", "torch", ".", "mm", "(", "re_Ds", "[", "i", "]", ",", "As", "[", "gid", "]", ")", "\n", "if", "gid", "not", "in", "Xinputs", ":", "Xinputs", "[", "gid", "]", "=", "torch", ".", "mm", "(", "Ainputs", "[", "gid", "]", ",", "Xs", "[", "gid", "]", ")", "\n", "\n", "", "", "else", ":", "raise", "NotImplementedError", "(", "'not support other types of aggregated inputs'", ")", "\n", "\n", "# pad each input into maxi possible size (N, N) / (N, F)", "\n", "NodeMax", "=", "int", "(", "datareader", ".", "data", "[", "'n_node_max'", "]", ")", "\n", "FeatDim", "=", "np", ".", "array", "(", "datareader", ".", "data", "[", "'features'", "]", "[", "0", "]", ")", ".", "shape", "[", "1", "]", "\n", "for", "gid", "in", "Ainputs", ".", "keys", "(", ")", ":", "\n", "        ", "a_input", "=", "Ainputs", "[", "gid", "]", "\n", "x_input", "=", "Xinputs", "[", "gid", "]", "\n", "\n", "add_dim", "=", "NodeMax", "-", "a_input", ".", "shape", "[", "0", "]", "\n", "Ainputs", "[", "gid", "]", "=", "np", ".", "pad", "(", "a_input", ",", "(", "(", "0", ",", "add_dim", ")", ",", "(", "0", ",", "add_dim", ")", ")", ")", ".", "tolist", "(", ")", "\n", "Xinputs", "[", "gid", "]", "=", "np", ".", "pad", "(", "x_input", ",", "(", "(", "0", ",", "add_dim", ")", ",", "(", "0", ",", "0", ")", ")", ")", ".", "tolist", "(", ")", "\n", "Ainputs", "[", "gid", "]", "=", "torch", ".", "tensor", "(", "Ainputs", "[", "gid", "]", ")", "\n", "Xinputs", "[", "gid", "]", "=", "torch", ".", "tensor", "(", "Xinputs", "[", "gid", "]", ")", "\n", "\n", "", "return", "Ainputs", ",", "Xinputs", "\n", "", ""]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.prop.forwarding": [[15, 44], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "utils.datareader.GraphData", "torch.utils.data.DataLoader", "model.eval", "enumerate", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "model.to", "range", "model", "criterion", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "len", "next", "len", "data[].to", "len", "output.unsqueeze.unsqueeze", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "model.parameters", "len"], "function", ["None"], ["def", "forwarding", "(", "args", ",", "bkd_dr", ":", "DataReader", ",", "model", ",", "gids", ",", "criterion", ")", ":", "\n", "    ", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "\"no GPU available\"", "\n", "cuda", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "\n", "gdata", "=", "GraphData", "(", "bkd_dr", ",", "gids", ")", "\n", "loader", "=", "DataLoader", "(", "gdata", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "collate_batch", ")", "\n", "\n", "if", "not", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "is_cuda", ":", "\n", "        ", "model", ".", "to", "(", "cuda", ")", "\n", "", "model", ".", "eval", "(", ")", "\n", "all_loss", ",", "n_samples", "=", "0.0", ",", "0.0", "\n", "for", "batch_idx", ",", "data", "in", "enumerate", "(", "loader", ")", ":", "\n", "#         assert batch_idx == 0, \"In AdaptNet Train, we only need one GNN pass, batch-size=len(all trainset)\"", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "            ", "data", "[", "i", "]", "=", "data", "[", "i", "]", ".", "to", "(", "cuda", ")", "\n", "", "output", "=", "model", "(", "data", ")", "\n", "\n", "if", "len", "(", "output", ".", "shape", ")", "==", "1", ":", "\n", "            ", "output", "=", "output", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "loss", "=", "criterion", "(", "output", ",", "data", "[", "4", "]", ")", "# only calculate once", "\n", "all_loss", "=", "torch", ".", "add", "(", "torch", ".", "mul", "(", "loss", ",", "len", "(", "output", ")", ")", ",", "all_loss", ")", "# cannot be loss.item()", "\n", "n_samples", "+=", "len", "(", "output", ")", "\n", "\n", "", "all_loss", "=", "torch", ".", "div", "(", "all_loss", ",", "n_samples", ")", "\n", "return", "all_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.prop.train_model": [[46, 92], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "model.to", "list", "torch.Adam", "torch.MultiStepLR", "model.train", "range", "model.to", "utils.datareader.GraphData", "torch.utils.data.DataLoader", "filter", "optim.Adam.zero_grad", "loss.backward", "optim.Adam.step", "lr_scheduler.MultiStepLR.step", "model.parameters", "enumerate", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "range", "model", "len", "range", "len", "data[].to", "len", "output.unsqueeze.unsqueeze", "loss_fn", "len", "len", "data[].to"], "function", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.GradWhere.backward"], ["", "def", "train_model", "(", "args", ",", "dr_train", ":", "DataReader", ",", "model", ",", "pset", ",", "nset", ")", ":", "\n", "    ", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "\"no GPU available\"", "\n", "cuda", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "cpu", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n", "model", ".", "to", "(", "cuda", ")", "\n", "gids", "=", "{", "'pos'", ":", "pset", ",", "'neg'", ":", "nset", "}", "\n", "gdata", "=", "{", "}", "\n", "loader", "=", "{", "}", "\n", "for", "key", "in", "[", "'pos'", ",", "'neg'", "]", ":", "\n", "        ", "gdata", "[", "key", "]", "=", "GraphData", "(", "dr_train", ",", "gids", "[", "key", "]", ")", "\n", "loader", "[", "key", "]", "=", "DataLoader", "(", "gdata", "[", "key", "]", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "collate_batch", ")", "\n", "\n", "", "train_params", "=", "list", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "train_params", ",", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "args", ".", "weight_decay", ",", "betas", "=", "(", "0.5", ",", "0.999", ")", ")", "\n", "scheduler", "=", "lr_scheduler", ".", "MultiStepLR", "(", "optimizer", ",", "args", ".", "lr_decay_steps", ",", "gamma", "=", "0.1", ")", "\n", "loss_fn", "=", "F", ".", "cross_entropy", "\n", "\n", "model", ".", "train", "(", ")", "\n", "for", "epoch", "in", "range", "(", "args", ".", "train_epochs", ")", ":", "\n", "        ", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "losses", "=", "{", "'pos'", ":", "0.0", ",", "'neg'", ":", "0.0", "}", "\n", "n_samples", "=", "{", "'pos'", ":", "0.0", ",", "'neg'", ":", "0.0", "}", "\n", "for", "key", "in", "[", "'pos'", ",", "'neg'", "]", ":", "\n", "            ", "for", "batch_idx", ",", "data", "in", "enumerate", "(", "loader", "[", "key", "]", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "                    ", "data", "[", "i", "]", "=", "data", "[", "i", "]", ".", "to", "(", "cuda", ")", "\n", "", "output", "=", "model", "(", "data", ")", "\n", "if", "len", "(", "output", ".", "shape", ")", "==", "1", ":", "\n", "                    ", "output", "=", "output", ".", "unsqueeze", "(", "0", ")", "\n", "", "losses", "[", "key", "]", "+=", "loss_fn", "(", "output", ",", "data", "[", "4", "]", ")", "*", "len", "(", "output", ")", "\n", "n_samples", "[", "key", "]", "+=", "len", "(", "output", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "                    ", "data", "[", "i", "]", "=", "data", "[", "i", "]", ".", "to", "(", "cpu", ")", "\n", "\n", "", "", "losses", "[", "key", "]", "=", "torch", ".", "div", "(", "losses", "[", "key", "]", ",", "n_samples", "[", "key", "]", ")", "\n", "", "loss", "=", "losses", "[", "'pos'", "]", "+", "args", ".", "lambd", "*", "losses", "[", "'neg'", "]", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "", "model", ".", "to", "(", "cpu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.prop.evaluate": [[157, 193], ["torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "model.cuda", "utils.datareader.GraphData", "torch.utils.data.DataLoader", "model.eval", "enumerate", "print", "model.cpu", "[].detach().cpu", "range", "model", "loss_fn", "loss_fn.item", "len", "predict_fn", "predict_fn.eq().sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "len", "data[].cuda", "len", "output.unsqueeze.unsqueeze", "[].detach", "predict_fn.eq().sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "predict_fn.eq", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "output.unsqueeze.max", "data[].detach().cpu().view_as", "torch.nn.Softmax.", "data[].detach().cpu", "data[].detach"], "function", ["None"], ["", "def", "evaluate", "(", "args", ",", "dr_test", ":", "DataReader", ",", "model", ",", "gids", ")", ":", "\n", "# separate bkd_test/clean_test gids", "\n", "    ", "softmax", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "\n", "model", ".", "cuda", "(", ")", "\n", "gdata", "=", "GraphData", "(", "dr_test", ",", "gids", ")", "\n", "loader", "=", "DataLoader", "(", "gdata", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "collate_batch", ")", "\n", "\n", "loss_fn", "=", "F", ".", "cross_entropy", "\n", "predict_fn", "=", "lambda", "output", ":", "output", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", "[", "1", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "test_loss", ",", "correct", ",", "n_samples", ",", "confidence", "=", "0", ",", "0", ",", "0", ",", "0", "\n", "for", "batch_idx", ",", "data", "in", "enumerate", "(", "loader", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "            ", "data", "[", "i", "]", "=", "data", "[", "i", "]", ".", "cuda", "(", ")", "\n", "", "output", "=", "model", "(", "data", ")", "# not softmax yet", "\n", "if", "len", "(", "output", ".", "shape", ")", "==", "1", ":", "\n", "            ", "output", "=", "output", ".", "unsqueeze", "(", "0", ")", "\n", "", "loss", "=", "loss_fn", "(", "output", ",", "data", "[", "4", "]", ",", "reduction", "=", "'sum'", ")", "\n", "test_loss", "+=", "loss", ".", "item", "(", ")", "\n", "n_samples", "+=", "len", "(", "output", ")", "\n", "pred", "=", "predict_fn", "(", "output", ")", "\n", "\n", "correct", "+=", "pred", ".", "eq", "(", "data", "[", "4", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "confidence", "+=", "torch", ".", "sum", "(", "torch", ".", "max", "(", "softmax", "(", "output", ")", ",", "dim", "=", "1", ")", "[", "0", "]", ")", ".", "item", "(", ")", "\n", "", "acc", "=", "100.", "*", "correct", "/", "n_samples", "\n", "confidence", "=", "confidence", "/", "n_samples", "\n", "\n", "print", "(", "'Test set: Average loss: %.4f, Accuracy: %d/%d (%.2f%s), Average Confidence %.4f'", "%", "(", "\n", "test_loss", "/", "n_samples", ",", "correct", ",", "n_samples", ",", "acc", ",", "'%'", ",", "confidence", ")", ")", "\n", "model", ".", "cpu", "(", ")", "\n", "return", "acc", "", "", ""]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.GradWhere.forward": [[22, 34], ["ctx.save_for_backward", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "thrd", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        In the forward pass we receive a Tensor containing the input and return\n        a Tensor containing the output. ctx is a context object that can be used\n        to stash information for backward computation. You can cache arbitrary\n        objects for use in the backward pass using the ctx.save_for_backward method.\n        \"\"\"", "\n", "ctx", ".", "save_for_backward", "(", "input", ")", "\n", "rst", "=", "torch", ".", "where", "(", "input", ">", "thrd", ",", "torch", ".", "tensor", "(", "1.0", ",", "device", "=", "device", ",", "requires_grad", "=", "True", ")", ",", "\n", "torch", ".", "tensor", "(", "0.0", ",", "device", "=", "device", ",", "requires_grad", "=", "True", ")", ")", "\n", "return", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.GradWhere.backward": [[35, 50], ["grad_output.clone"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "\"\"\"\n        In the backward pass we receive a Tensor containing the gradient of the loss\n        with respect to the output, and we need to compute the gradient of the loss\n        with respect to the input.\n        \"\"\"", "\n", "input", ",", "=", "ctx", ".", "saved_tensors", "\n", "grad_input", "=", "grad_output", ".", "clone", "(", ")", "\n", "\n", "\"\"\"\n        Return results number should corresponding with .forward inputs (besides ctx),\n        for each input, return a corresponding backward grad\n        \"\"\"", "\n", "return", "grad_input", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.GraphTrojanNet.__init__": [[54, 68], ["torch.Module.__init__", "range", "layers.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.append", "layers.append", "layers.append", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "layers.append", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.attack.GraphBackdoor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "sq_dim", ",", "layernum", "=", "1", ",", "dropout", "=", "0.05", ")", ":", "\n", "        ", "super", "(", "GraphTrojanNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "layers", "=", "[", "]", "\n", "if", "dropout", ">", "0", ":", "\n", "            ", "layers", ".", "append", "(", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "", "for", "l", "in", "range", "(", "layernum", "-", "1", ")", ":", "\n", "            ", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "sq_dim", ",", "sq_dim", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "if", "dropout", ">", "0", ":", "\n", "                ", "layers", ".", "append", "(", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "", "", "layers", ".", "append", "(", "nn", ".", "Linear", "(", "sq_dim", ",", "sq_dim", ")", ")", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.GraphTrojanNet.forward": [[69, 95], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "GTA.GraphTrojanNet.layers", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "GW", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.sigmoid.transpose", "torch.sigmoid.transpose", "torch.sigmoid.transpose", "torch.sigmoid.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "mask", ",", "thrd", ",", "\n", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", ",", "\n", "activation", "=", "'relu'", ",", "\n", "for_whom", "=", "'topo'", ",", "\n", "binaryfeat", "=", "False", ")", ":", "\n", "\n", "        ", "\"\"\"\n        \"input\", \"mask\" and \"thrd\", should already in cuda before sent to this function.\n        If using sparse format, corresponding tensor should already in sparse format before\n        sent into this function\n        \"\"\"", "\n", "GW", "=", "GradWhere", ".", "apply", "\n", "\n", "bkdmat", "=", "self", ".", "layers", "(", "input", ")", "\n", "if", "activation", "==", "'relu'", ":", "\n", "            ", "bkdmat", "=", "F", ".", "relu", "(", "bkdmat", ")", "\n", "", "elif", "activation", "==", "'sigmoid'", ":", "\n", "            ", "bkdmat", "=", "torch", ".", "sigmoid", "(", "bkdmat", ")", "# nn.Functional.sigmoid is deprecated", "\n", "\n", "", "if", "for_whom", "==", "'topo'", ":", "# not consider direct yet", "\n", "            ", "bkdmat", "=", "torch", ".", "div", "(", "torch", ".", "add", "(", "bkdmat", ",", "bkdmat", ".", "transpose", "(", "0", ",", "1", ")", ")", ",", "2.0", ")", "\n", "", "if", "for_whom", "==", "'topo'", "or", "(", "for_whom", "==", "'feat'", "and", "binaryfeat", ")", ":", "\n", "            ", "bkdmat", "=", "GW", "(", "bkdmat", ",", "thrd", ",", "device", ")", "\n", "", "bkdmat", "=", "torch", ".", "mul", "(", "bkdmat", ",", "mask", ")", "\n", "\n", "return", "bkdmat", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.train_gtn": [[97, 200], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "numpy.concatenate", "torch.Adam", "torch.Adam", "toponet.to", "model.to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.CrossEntropyLoss", "toponet.train", "tqdm.tqdm", "toponet.eval", "toponet.to", "model.to", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "featnet.to", "model.to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.CrossEntropyLoss", "featnet.train", "tqdm.tqdm", "featnet.eval", "featnet.to", "model.to", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "len", "toponet.parameters", "featnet.parameters", "range", "optim.Adam.zero_grad", "trojan.prop.forwarding", "trojan.prop.forwarding.backward", "optim.Adam.step", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "GTA.SendtoCPU", "range", "optim.Adam.zero_grad", "trojan.prop.forwarding", "trojan.prop.forwarding.backward", "optim.Adam.step", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "GTA.SendtoCPU", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "GTA.SendtoCUDA", "toponet", "torch.add", "torch.add", "torch.add", "torch.add", "GTA.SendtoCPU", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "GTA.SendtoCUDA", "featnet", "torch.add", "torch.add", "torch.add", "torch.add", "GTA.SendtoCPU"], "function", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.prop.forwarding", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.GradWhere.backward", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.SendtoCPU", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.prop.forwarding", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.GradWhere.backward", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.SendtoCPU", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.SendtoCUDA", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.SendtoCPU", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.SendtoCUDA", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.SendtoCPU"], ["", "", "def", "train_gtn", "(", "args", ",", "model", ",", "toponet", ":", "GraphTrojanNet", ",", "featnet", ":", "GraphTrojanNet", ",", "\n", "pset", ",", "nset", ",", "topomasks", ",", "featmasks", ",", "\n", "init_dr", ":", "DataReader", ",", "bkd_dr", ":", "DataReader", ",", "Ainputs", ",", "Xinputs", ")", ":", "\n", "    ", "\"\"\"\n    All matrix/array like inputs should already in torch.tensor format.\n    All tensor parameters or models should initially stay in CPU when\n    feeding into this function.\n    \n    About inputs of this function:\n    - pset/nset: gids in trainset\n    - init_dr: init datareader, keep unmodified inside of each resampling\n    - bkd_dr: store temp adaptive adj/features, get by  init_dr + GTN(inputs)\n    \"\"\"", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "cuda", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "cpu", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "\n", "", "init_As", "=", "init_dr", ".", "data", "[", "'adj_list'", "]", "\n", "init_Xs", "=", "init_dr", ".", "data", "[", "'features'", "]", "\n", "bkd_As", "=", "bkd_dr", ".", "data", "[", "'adj_list'", "]", "\n", "bkd_Xs", "=", "bkd_dr", ".", "data", "[", "'features'", "]", "\n", "\n", "nodenums", "=", "[", "len", "(", "adj", ")", "for", "adj", "in", "init_As", "]", "\n", "glabels", "=", "torch", ".", "LongTensor", "(", "init_dr", ".", "data", "[", "'labels'", "]", ")", ".", "to", "(", "cuda", ")", "\n", "glabels", "[", "pset", "]", "=", "args", ".", "target_class", "\n", "allset", "=", "np", ".", "concatenate", "(", "(", "pset", ",", "nset", ")", ")", "\n", "\n", "optimizer_topo", "=", "optim", ".", "Adam", "(", "toponet", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "args", ".", "gtn_lr", ",", "\n", "weight_decay", "=", "5e-4", ")", "\n", "optimizer_feat", "=", "optim", ".", "Adam", "(", "featnet", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "args", ".", "gtn_lr", ",", "\n", "weight_decay", "=", "5e-4", ")", "\n", "\n", "\n", "#----------- training topo generator -----------#", "\n", "toponet", ".", "to", "(", "cuda", ")", "\n", "model", ".", "to", "(", "cuda", ")", "\n", "topo_thrd", "=", "torch", ".", "tensor", "(", "args", ".", "topo_thrd", ")", ".", "to", "(", "cuda", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "toponet", ".", "train", "(", ")", "\n", "for", "_", "in", "tqdm", "(", "range", "(", "args", ".", "gtn_epochs", ")", ",", "desc", "=", "\"training topology generator\"", ")", ":", "\n", "        ", "optimizer_topo", ".", "zero_grad", "(", ")", "\n", "# generate new adj_list by dr.data['adj_list']", "\n", "for", "gid", "in", "pset", ":", "\n", "            ", "SendtoCUDA", "(", "gid", ",", "[", "init_As", ",", "Ainputs", ",", "topomasks", "]", ")", "# only send the used graph items to cuda", "\n", "rst_bkdA", "=", "toponet", "(", "\n", "Ainputs", "[", "gid", "]", ",", "topomasks", "[", "gid", "]", ",", "topo_thrd", ",", "cuda", ",", "args", ".", "topo_activation", ",", "'topo'", ")", "\n", "# rst_bkdA = recover_mask(nodenums[gid], topomasks[gid], 'topo')", "\n", "# bkd_dr.data['adj_list'][gid] = torch.add(rst_bkdA, init_As[gid])", "\n", "bkd_dr", ".", "data", "[", "'adj_list'", "]", "[", "gid", "]", "=", "torch", ".", "add", "(", "rst_bkdA", "[", ":", "nodenums", "[", "gid", "]", ",", ":", "nodenums", "[", "gid", "]", "]", ",", "init_As", "[", "gid", "]", ")", "# only current position in cuda", "\n", "SendtoCPU", "(", "gid", ",", "[", "init_As", ",", "Ainputs", ",", "topomasks", "]", ")", "\n", "\n", "", "loss", "=", "forwarding", "(", "args", ",", "bkd_dr", ",", "model", ",", "allset", ",", "criterion", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer_topo", ".", "step", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "toponet", ".", "eval", "(", ")", "\n", "toponet", ".", "to", "(", "cpu", ")", "\n", "model", ".", "to", "(", "cpu", ")", "\n", "for", "gid", "in", "pset", ":", "\n", "        ", "SendtoCPU", "(", "gid", ",", "[", "bkd_dr", ".", "data", "[", "'adj_list'", "]", "]", ")", "\n", "", "del", "topo_thrd", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "\n", "#----------- training feat generator -----------#", "\n", "featnet", ".", "to", "(", "cuda", ")", "\n", "model", ".", "to", "(", "cuda", ")", "\n", "feat_thrd", "=", "torch", ".", "tensor", "(", "args", ".", "feat_thrd", ")", ".", "to", "(", "cuda", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "featnet", ".", "train", "(", ")", "\n", "for", "epoch", "in", "tqdm", "(", "range", "(", "args", ".", "gtn_epochs", ")", ",", "desc", "=", "\"training feature generator\"", ")", ":", "\n", "        ", "optimizer_feat", ".", "zero_grad", "(", ")", "\n", "# generate new features by dr.data['features']", "\n", "for", "gid", "in", "pset", ":", "\n", "            ", "SendtoCUDA", "(", "gid", ",", "[", "init_Xs", ",", "Xinputs", ",", "featmasks", "]", ")", "# only send the used graph items to cuda", "\n", "rst_bkdX", "=", "featnet", "(", "\n", "Xinputs", "[", "gid", "]", ",", "featmasks", "[", "gid", "]", ",", "feat_thrd", ",", "cuda", ",", "args", ".", "feat_activation", ",", "'feat'", ")", "\n", "# rst_bkdX = recover_mask(nodenums[gid], featmasks[gid], 'feat')", "\n", "# bkd_dr.data['features'][gid] = torch.add(rst_bkdX, init_Xs[gid])", "\n", "bkd_dr", ".", "data", "[", "'features'", "]", "[", "gid", "]", "=", "torch", ".", "add", "(", "rst_bkdX", "[", ":", "nodenums", "[", "gid", "]", "]", ",", "init_Xs", "[", "gid", "]", ")", "# only current position in cuda", "\n", "SendtoCPU", "(", "gid", ",", "[", "init_Xs", ",", "Xinputs", ",", "featmasks", "]", ")", "\n", "\n", "# generate DataLoader", "\n", "", "loss", "=", "forwarding", "(", "\n", "args", ",", "bkd_dr", ",", "model", ",", "allset", ",", "criterion", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer_feat", ".", "step", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "featnet", ".", "eval", "(", ")", "\n", "featnet", ".", "to", "(", "cpu", ")", "\n", "model", ".", "to", "(", "cpu", ")", "\n", "for", "gid", "in", "pset", ":", "\n", "        ", "SendtoCPU", "(", "gid", ",", "[", "bkd_dr", ".", "data", "[", "'features'", "]", "]", ")", "\n", "", "del", "feat_thrd", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "return", "toponet", ",", "featnet", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.SendtoCUDA": [[202, 211], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor"], "function", ["None"], ["", "def", "SendtoCUDA", "(", "gid", ",", "items", ")", ":", "\n", "    ", "\"\"\"\n    - items: a list of dict / full-graphs list, \n             used as item[gid] in items\n    - gid: int\n    \"\"\"", "\n", "cuda", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "for", "item", "in", "items", ":", "\n", "        ", "item", "[", "gid", "]", "=", "torch", ".", "as_tensor", "(", "item", "[", "gid", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ".", "to", "(", "cuda", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.SendtoCPU": [[213, 225], ["torch.device", "torch.device", "torch.device", "torch.device", "item[].to"], "function", ["None"], ["", "", "def", "SendtoCPU", "(", "gid", ",", "items", ")", ":", "\n", "    ", "\"\"\"\n    Used after SendtoCUDA, target object must be torch.tensor and already in cuda.\n    \n    - items: a list of dict / full-graphs list, \n             used as item[gid] in items\n    - gid: int\n    \"\"\"", "\n", "\n", "cpu", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "for", "item", "in", "items", ":", "\n", "        ", "item", "[", "gid", "]", "=", "item", "[", "gid", "]", ".", "to", "(", "cpu", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.model.sage.GraphSAGE.__init__": [[12, 31], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "sage.GraphSAGE.layers.append", "range", "fc.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "dgl.nn.pytorch.conv.SAGEConv", "sage.GraphSAGE.layers.append", "fc.append", "torch.Linear", "torch.Linear", "torch.Linear", "len", "dgl.nn.pytorch.conv.SAGEConv", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.attack.GraphBackdoor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", ",", "out_dim", ",", "\n", "hidden_dim", "=", "[", "64", ",", "32", "]", ",", "# GNN layers + 1 layer MLP", "\n", "dropout", "=", "0.2", ",", "\n", "activation", "=", "F", ".", "relu", ",", "\n", "aggregator_type", "=", "'gcn'", ")", ":", "# mean/gcn/pool/lstm", "\n", "        ", "super", "(", "GraphSAGE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "# input layer", "\n", "self", ".", "layers", ".", "append", "(", "SAGEConv", "(", "in_dim", ",", "hidden_dim", "[", "0", "]", ",", "aggregator_type", ",", "feat_drop", "=", "dropout", ",", "activation", "=", "activation", ")", ")", "\n", "# hidden layers", "\n", "for", "i", "in", "range", "(", "len", "(", "hidden_dim", ")", "-", "1", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "SAGEConv", "(", "hidden_dim", "[", "i", "]", ",", "hidden_dim", "[", "i", "+", "1", "]", ",", "aggregator_type", ",", "feat_drop", "=", "dropout", ",", "activation", "=", "activation", ")", ")", "\n", "\n", "", "fc", "=", "[", "]", "\n", "if", "dropout", ">", "0", ":", "\n", "            ", "fc", ".", "append", "(", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "", "fc", ".", "append", "(", "nn", ".", "Linear", "(", "hidden_dim", "[", "-", "1", "]", ",", "out_dim", ")", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "*", "fc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.model.sage.GraphSAGE.forward": [[33, 57], ["dgl.batch", "data[].reshape", "mask.unsqueeze.unsqueeze.reshape", "layer.reshape", "[].squeeze", "sage.GraphSAGE.fc", "dgl.batch.append", "len", "mask.unsqueeze.unsqueeze.unsqueeze", "layer", "utils.graph.numpy_to_graph", "adj.cpu().T.numpy", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "adj.cpu"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.graph.numpy_to_graph"], ["", "def", "forward", "(", "self", ",", "data", ")", ":", "\n", "        ", "batch_g", "=", "[", "]", "\n", "for", "adj", "in", "data", "[", "1", "]", ":", "\n", "# cannot use tensor init DGLGraph", "\n", "            ", "batch_g", ".", "append", "(", "numpy_to_graph", "(", "adj", ".", "cpu", "(", ")", ".", "T", ".", "numpy", "(", ")", ",", "to_cuda", "=", "adj", ".", "is_cuda", ")", ")", "\n", "", "batch_g", "=", "dgl", ".", "batch", "(", "batch_g", ")", "\n", "\n", "mask", "=", "data", "[", "2", "]", "\n", "if", "len", "(", "mask", ".", "shape", ")", "==", "2", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "2", ")", "# (B,N,1)  ", "\n", "\n", "", "B", ",", "N", ",", "F", "=", "data", "[", "0", "]", ".", "shape", "[", ":", "3", "]", "\n", "x", "=", "data", "[", "0", "]", ".", "reshape", "(", "B", "*", "N", ",", "F", ")", "\n", "mask", "=", "mask", ".", "reshape", "(", "B", "*", "N", ",", "1", ")", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "batch_g", ",", "x", ")", "\n", "x", "=", "x", "*", "mask", "\n", "\n", "", "F_prime", "=", "x", ".", "shape", "[", "-", "1", "]", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "N", ",", "F_prime", ")", "\n", "x", "=", "torch", ".", "max", "(", "x", ",", "dim", "=", "1", ")", "[", "0", "]", ".", "squeeze", "(", ")", "# max pooling over nodes (usually performs better than average)", "\n", "# x = torch.mean(x, dim=1).squeeze()", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "", "", "", ""]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.model.gat.GATLayer.__init__": [[10, 16], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.attack.GraphBackdoor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", ",", "out_dim", ")", ":", "\n", "        ", "super", "(", "GATLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# equation (1)", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "in_dim", ",", "out_dim", ",", "bias", "=", "False", ")", "\n", "# equation (2)", "\n", "self", ".", "attn_fc", "=", "nn", ".", "Linear", "(", "2", "*", "out_dim", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.model.gat.GATLayer.edge_attention": [[17, 22], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gat.GATLayer.attn_fc", "torch.leaky_relu", "torch.leaky_relu", "torch.leaky_relu"], "methods", ["None"], ["", "def", "edge_attention", "(", "self", ",", "edges", ")", ":", "\n", "# edge UDF for equation (2)", "\n", "        ", "z2", "=", "torch", ".", "cat", "(", "[", "edges", ".", "src", "[", "'z'", "]", ",", "edges", ".", "dst", "[", "'z'", "]", "]", ",", "dim", "=", "1", ")", "\n", "a", "=", "self", ".", "attn_fc", "(", "z2", ")", "\n", "return", "{", "'e'", ":", "F", ".", "leaky_relu", "(", "a", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.model.gat.GATLayer.message_func": [[23, 26], ["None"], "methods", ["None"], ["", "def", "message_func", "(", "self", ",", "edges", ")", ":", "\n", "# message UDF for equation (3) & (4)", "\n", "        ", "return", "{", "'z'", ":", "edges", ".", "src", "[", "'z'", "]", ",", "'e'", ":", "edges", ".", "data", "[", "'e'", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.model.gat.GATLayer.reduce_func": [[27, 34], ["torch.softmax", "torch.softmax", "torch.softmax", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "reduce_func", "(", "self", ",", "nodes", ")", ":", "\n", "# reduce UDF for equation (3) & (4)", "\n", "# equation (3)", "\n", "        ", "alpha", "=", "F", ".", "softmax", "(", "nodes", ".", "mailbox", "[", "'e'", "]", ",", "dim", "=", "1", ")", "\n", "# equation (4)", "\n", "h", "=", "torch", ".", "sum", "(", "alpha", "*", "nodes", ".", "mailbox", "[", "'z'", "]", ",", "dim", "=", "1", ")", "\n", "return", "{", "'h'", ":", "h", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.model.gat.GATLayer.forward": [[35, 44], ["gat.GATLayer.fc", "g.apply_edges", "g.update_all", "g.ndata.pop"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "g", ",", "h", ")", ":", "\n", "# equation (1)", "\n", "        ", "z", "=", "self", ".", "fc", "(", "h", ")", "\n", "g", ".", "ndata", "[", "'z'", "]", "=", "z", "\n", "# equation (2)", "\n", "g", ".", "apply_edges", "(", "self", ".", "edge_attention", ")", "\n", "# equation (3) & (4)", "\n", "g", ".", "update_all", "(", "self", ".", "message_func", ",", "self", ".", "reduce_func", ")", "\n", "return", "g", ".", "ndata", ".", "pop", "(", "'h'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.model.gat.MultiHeadGATLayer.__init__": [[47, 53], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "gat.MultiHeadGATLayer.heads.append", "gat.GATLayer"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.attack.GraphBackdoor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", ",", "out_dim", ",", "num_head", ",", "merge", "=", "'cat'", ")", ":", "\n", "        ", "super", "(", "MultiHeadGATLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "heads", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "num_head", ")", ":", "\n", "            ", "self", ".", "heads", ".", "append", "(", "GATLayer", "(", "in_dim", ",", "out_dim", ")", ")", "\n", "", "self", ".", "merge", "=", "merge", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.model.gat.MultiHeadGATLayer.forward": [[54, 62], ["attn_head", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "g", ",", "h", ")", ":", "\n", "        ", "head_outs", "=", "[", "attn_head", "(", "g", ",", "h", ")", "for", "attn_head", "in", "self", ".", "heads", "]", "\n", "if", "self", ".", "merge", "==", "'cat'", ":", "\n", "# concat on the output feature dimension (dim=1)", "\n", "            ", "return", "torch", ".", "cat", "(", "head_outs", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "# merge using average", "\n", "            ", "return", "torch", ".", "mean", "(", "torch", ".", "stack", "(", "head_outs", ")", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.model.gat.GAT.__init__": [[65, 82], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "gat.GAT.layers.append", "range", "fc.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "gat.MultiHeadGATLayer", "gat.GAT.layers.append", "fc.append", "torch.Linear", "torch.Linear", "torch.Linear", "len", "gat.MultiHeadGATLayer", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.attack.GraphBackdoor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", ",", "out_dim", ",", "\n", "hidden_dim", "=", "[", "64", ",", "32", "]", ",", "\n", "dropout", "=", "0.2", ",", "\n", "num_head", "=", "2", ")", ":", "\n", "        ", "super", "(", "GAT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "self", ".", "layers", ".", "append", "(", "MultiHeadGATLayer", "(", "in_dim", ",", "hidden_dim", "[", "0", "]", ",", "num_head", ",", "merge", "=", "'mean'", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "hidden_dim", ")", "-", "1", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "MultiHeadGATLayer", "(", "hidden_dim", "[", "i", "]", ",", "hidden_dim", "[", "i", "+", "1", "]", ",", "num_head", ",", "merge", "=", "'mean'", ")", ")", "\n", "\n", "", "fc", "=", "[", "]", "\n", "if", "dropout", ">", "0", ":", "\n", "            ", "fc", ".", "append", "(", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "", "fc", ".", "append", "(", "nn", ".", "Linear", "(", "hidden_dim", "[", "-", "1", "]", ",", "out_dim", ")", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "*", "fc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.model.gat.GAT.forward": [[83, 106], ["dgl.batch", "data[].reshape", "mask.unsqueeze.unsqueeze.reshape", "layer.reshape", "[].squeeze", "gat.GAT.fc", "dgl.batch.append", "len", "mask.unsqueeze.unsqueeze.unsqueeze", "layer", "utils.graph.numpy_to_graph", "adj.cpu().detach().T.numpy", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "adj.cpu().detach", "adj.cpu"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.graph.numpy_to_graph"], ["", "def", "forward", "(", "self", ",", "data", ")", ":", "\n", "        ", "batch_g", "=", "[", "]", "\n", "for", "adj", "in", "data", "[", "1", "]", ":", "\n", "            ", "batch_g", ".", "append", "(", "numpy_to_graph", "(", "adj", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "T", ".", "numpy", "(", ")", ",", "to_cuda", "=", "adj", ".", "is_cuda", ")", ")", "\n", "", "batch_g", "=", "dgl", ".", "batch", "(", "batch_g", ")", "\n", "\n", "mask", "=", "data", "[", "2", "]", "\n", "if", "len", "(", "mask", ".", "shape", ")", "==", "2", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "2", ")", "# (B,N,1)  ", "\n", "\n", "", "B", ",", "N", ",", "F", "=", "data", "[", "0", "]", ".", "shape", "[", ":", "3", "]", "\n", "x", "=", "data", "[", "0", "]", ".", "reshape", "(", "B", "*", "N", ",", "F", ")", "\n", "mask", "=", "mask", ".", "reshape", "(", "B", "*", "N", ",", "1", ")", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "batch_g", ",", "x", ")", "\n", "x", "=", "x", "*", "mask", "\n", "\n", "", "F_prime", "=", "x", ".", "shape", "[", "-", "1", "]", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "N", ",", "F_prime", ")", "\n", "x", "=", "torch", ".", "max", "(", "x", ",", "dim", "=", "1", ")", "[", "0", "]", ".", "squeeze", "(", ")", "# max pooling over nodes (usually performs better than average)", "\n", "# x = torch.mean(x, dim=1).squeeze()", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "", "", "", ""]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.model.gcn.GCNLayer.__init__": [[14, 17], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.attack.GraphBackdoor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_feats", ",", "out_feats", ")", ":", "\n", "        ", "super", "(", "GCNLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "in_feats", ",", "out_feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.model.gcn.GCNLayer.forward": [[18, 27], ["g.local_scope", "g.update_all", "gcn.GCNLayer.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "g", ",", "feature", ")", ":", "\n", "# Creating a local scope so that all the stored ndata and edata", "\n", "# (such as the `'h'` ndata below) are automatically popped out", "\n", "# when the scope exits.", "\n", "        ", "with", "g", ".", "local_scope", "(", ")", ":", "\n", "            ", "g", ".", "ndata", "[", "'h'", "]", "=", "feature", "\n", "g", ".", "update_all", "(", "gcn_msg", ",", "gcn_reduce", ")", "\n", "h", "=", "g", ".", "ndata", "[", "'h'", "]", "\n", "return", "self", ".", "linear", "(", "h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.model.gcn.GCN.__init__": [[31, 47], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "gcn.GCN.layers.append", "range", "fc.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "gcn.GCNLayer", "gcn.GCN.layers.append", "fc.append", "torch.Linear", "torch.Linear", "torch.Linear", "len", "gcn.GCNLayer", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.attack.GraphBackdoor.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", ",", "out_dim", ",", "\n", "hidden_dim", "=", "[", "64", ",", "32", "]", ",", "# GNN layers + 1 layer MLP", "\n", "dropout", "=", "0.2", ",", "\n", "activation", "=", "F", ".", "relu", ")", ":", "\n", "        ", "super", "(", "GCN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "self", ".", "layers", ".", "append", "(", "GCNLayer", "(", "in_dim", ",", "hidden_dim", "[", "0", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "hidden_dim", ")", "-", "1", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "GCNLayer", "(", "hidden_dim", "[", "i", "]", ",", "hidden_dim", "[", "i", "+", "1", "]", ")", ")", "\n", "\n", "", "fc", "=", "[", "]", "\n", "if", "dropout", ">", "0", ":", "\n", "            ", "fc", ".", "append", "(", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "", "fc", ".", "append", "(", "nn", ".", "Linear", "(", "hidden_dim", "[", "-", "1", "]", ",", "out_dim", ")", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "*", "fc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.model.gcn.GCN.forward": [[49, 72], ["dgl.batch", "dgl.batch", "dgl.batch", "dgl.batch", "data[].reshape", "mask.unsqueeze.unsqueeze.reshape", "layer.reshape", "[].squeeze", "gcn.GCN.fc", "dgl.batch.append", "dgl.batch.append", "len", "mask.unsqueeze.unsqueeze.unsqueeze", "layer", "utils.graph.numpy_to_graph", "adj.cpu().detach().T.numpy", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "adj.cpu().detach", "adj.cpu"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.graph.numpy_to_graph"], ["", "def", "forward", "(", "self", ",", "data", ")", ":", "\n", "        ", "batch_g", "=", "[", "]", "\n", "for", "adj", "in", "data", "[", "1", "]", ":", "\n", "            ", "batch_g", ".", "append", "(", "numpy_to_graph", "(", "adj", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "T", ".", "numpy", "(", ")", ",", "to_cuda", "=", "adj", ".", "is_cuda", ")", ")", "\n", "", "batch_g", "=", "dgl", ".", "batch", "(", "batch_g", ")", "\n", "\n", "mask", "=", "data", "[", "2", "]", "\n", "if", "len", "(", "mask", ".", "shape", ")", "==", "2", ":", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "2", ")", "# (B,N,1)  ", "\n", "\n", "", "B", ",", "N", ",", "F", "=", "data", "[", "0", "]", ".", "shape", "[", ":", "3", "]", "\n", "x", "=", "data", "[", "0", "]", ".", "reshape", "(", "B", "*", "N", ",", "F", ")", "\n", "mask", "=", "mask", ".", "reshape", "(", "B", "*", "N", ",", "1", ")", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "batch_g", ",", "x", ")", "\n", "x", "=", "x", "*", "mask", "\n", "\n", "", "F_prime", "=", "x", ".", "shape", "[", "-", "1", "]", "\n", "x", "=", "x", ".", "reshape", "(", "B", ",", "N", ",", "F_prime", ")", "\n", "x", "=", "torch", ".", "max", "(", "x", ",", "dim", "=", "1", ")", "[", "0", "]", ".", "squeeze", "(", ")", "# max pooling over nodes (usually performs better than average)", "\n", "# x = torch.mean(x, dim=1).squeeze()", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.attack.GraphBackdoor.__init__": [[23, 29], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", "->", "None", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "\n", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "'no GPU available'", "\n", "self", ".", "cpu", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "self", ".", "cuda", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.attack.GraphBackdoor.run": [[30, 167], ["main.run", "copy.deepcopy().to", "attack.GraphBackdoor.bkd_cdd", "max", "trojan.GraphTrojanNet", "trojan.GraphTrojanNet", "attack.GraphBackdoor.init_trigger", "copy.deepcopy", "utils.mask.gen_mask", "trojan.input.gen_input", "range", "print", "copy.deepcopy", "attack.GraphBackdoor.bkd_cdd", "list", "attack.GraphBackdoor.init_trigger", "copy.deepcopy", "utils.mask.gen_mask", "trojan.input.gen_input", "range", "copy.deepcopy", "numpy.array", "copy.deepcopy", "print", "trojan.train_gtn", "trojan.prop.train_model", "list", "list", "trojan.prop.evaluate", "trojan.prop.evaluate", "trojan.prop.evaluate", "set", "set", "len", "len", "int", "int", "trojan.GraphTrojanNet.", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "trojan.GraphTrojanNet.", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "list", "list", "trojan.GraphTrojanNet.", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "trojan.GraphTrojanNet.", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "abs", "print", "numpy.ceil", "list", "numpy.ceil", "list", "rst_bkdA[].detach().cpu", "rst_bkdX[].detach().cpu", "set", "set", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "set", "set", "set", "set", "os.makedirs", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "print", "copy.deepcopy", "copy.deepcopy", "abs", "len", "len", "rst_bkdA[].detach", "rst_bkdX[].detach", "copy.deepcopy().to.state_dict", "len", "len"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.benign.run", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.attack.GraphBackdoor.bkd_cdd", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.attack.GraphBackdoor.init_trigger", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.mask.gen_mask", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.input.gen_input", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.attack.GraphBackdoor.bkd_cdd", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.attack.GraphBackdoor.init_trigger", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.mask.gen_mask", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.input.gen_input", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.train_gtn", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.prop.train_model", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.prop.evaluate", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.prop.evaluate", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.prop.evaluate"], ["", "def", "run", "(", "self", ")", ":", "\n", "# train a benign GNN", "\n", "        ", "self", ".", "benign_dr", ",", "self", ".", "benign_model", "=", "benign", ".", "run", "(", "self", ".", "args", ")", "\n", "model", "=", "copy", ".", "deepcopy", "(", "self", ".", "benign_model", ")", ".", "to", "(", "self", ".", "cuda", ")", "\n", "# pick up initial candidates", "\n", "bkd_gids_test", ",", "bkd_nids_test", ",", "bkd_nid_groups_test", "=", "self", ".", "bkd_cdd", "(", "'test'", ")", "\n", "\n", "nodenums", "=", "[", "adj", ".", "shape", "[", "0", "]", "for", "adj", "in", "self", ".", "benign_dr", ".", "data", "[", "'adj_list'", "]", "]", "\n", "nodemax", "=", "max", "(", "nodenums", ")", "\n", "featdim", "=", "np", ".", "array", "(", "self", ".", "benign_dr", ".", "data", "[", "'features'", "]", "[", "0", "]", ")", ".", "shape", "[", "1", "]", "\n", "\n", "# init two generators for topo/feat", "\n", "toponet", "=", "gta", ".", "GraphTrojanNet", "(", "nodemax", ",", "self", ".", "args", ".", "gtn_layernum", ")", "\n", "featnet", "=", "gta", ".", "GraphTrojanNet", "(", "featdim", ",", "self", ".", "args", ".", "gtn_layernum", ")", "\n", "\n", "\n", "# init test data", "\n", "# NOTE: for data that can only add perturbation on features, only init the topo value", "\n", "init_dr_test", "=", "self", ".", "init_trigger", "(", "\n", "self", ".", "args", ",", "copy", ".", "deepcopy", "(", "self", ".", "benign_dr", ")", ",", "bkd_gids_test", ",", "bkd_nid_groups_test", ",", "0.0", ",", "0.0", ")", "\n", "bkd_dr_test", "=", "copy", ".", "deepcopy", "(", "init_dr_test", ")", "\n", "\n", "topomask_test", ",", "featmask_test", "=", "gen_mask", "(", "\n", "init_dr_test", ",", "bkd_gids_test", ",", "bkd_nid_groups_test", ")", "\n", "Ainput_test", ",", "Xinput_test", "=", "gen_input", "(", "self", ".", "args", ",", "init_dr_test", ",", "bkd_gids_test", ")", "\n", "\n", "for", "rs_step", "in", "range", "(", "self", ".", "args", ".", "resample_steps", ")", ":", "# for each step, choose different sample", "\n", "\n", "# randomly select new graph backdoor samples", "\n", "            ", "bkd_gids_train", ",", "bkd_nids_train", ",", "bkd_nid_groups_train", "=", "self", ".", "bkd_cdd", "(", "'train'", ")", "\n", "\n", "# positive/negtive sample set", "\n", "pset", "=", "bkd_gids_train", "\n", "nset", "=", "list", "(", "set", "(", "self", ".", "benign_dr", ".", "data", "[", "'splits'", "]", "[", "'train'", "]", ")", "-", "set", "(", "pset", ")", ")", "\n", "\n", "if", "self", ".", "args", ".", "pn_rate", "!=", "None", ":", "\n", "                ", "if", "len", "(", "pset", ")", ">", "len", "(", "nset", ")", ":", "\n", "                    ", "repeat", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "pset", ")", "/", "(", "len", "(", "nset", ")", "*", "self", ".", "args", ".", "pn_rate", ")", ")", ")", "\n", "nset", "=", "list", "(", "nset", ")", "*", "repeat", "\n", "", "else", ":", "\n", "                    ", "repeat", "=", "int", "(", "np", ".", "ceil", "(", "(", "len", "(", "nset", ")", "*", "self", ".", "args", ".", "pn_rate", ")", "/", "len", "(", "pset", ")", ")", ")", "\n", "pset", "=", "list", "(", "pset", ")", "*", "repeat", "\n", "\n", "# init train data", "\n", "# NOTE: for data that can only add perturbation on features, only init the topo value", "\n", "", "", "init_dr_train", "=", "self", ".", "init_trigger", "(", "\n", "self", ".", "args", ",", "copy", ".", "deepcopy", "(", "self", ".", "benign_dr", ")", ",", "bkd_gids_train", ",", "bkd_nid_groups_train", ",", "0.0", ",", "0.0", ")", "\n", "bkd_dr_train", "=", "copy", ".", "deepcopy", "(", "init_dr_train", ")", "\n", "\n", "topomask_train", ",", "featmask_train", "=", "gen_mask", "(", "\n", "init_dr_train", ",", "bkd_gids_train", ",", "bkd_nid_groups_train", ")", "\n", "Ainput_train", ",", "Xinput_train", "=", "gen_input", "(", "self", ".", "args", ",", "init_dr_train", ",", "bkd_gids_train", ")", "\n", "\n", "for", "bi_step", "in", "range", "(", "self", ".", "args", ".", "bilevel_steps", ")", ":", "\n", "                ", "print", "(", "\"Resampling step %d, bi-level optimization step %d\"", "%", "(", "rs_step", ",", "bi_step", ")", ")", "\n", "\n", "toponet", ",", "featnet", "=", "gta", ".", "train_gtn", "(", "\n", "self", ".", "args", ",", "model", ",", "toponet", ",", "featnet", ",", "\n", "pset", ",", "nset", ",", "topomask_train", ",", "featmask_train", ",", "\n", "init_dr_train", ",", "bkd_dr_train", ",", "Ainput_train", ",", "Xinput_train", ")", "\n", "\n", "# get new backdoor datareader for training based on well-trained generators", "\n", "for", "gid", "in", "bkd_gids_train", ":", "\n", "                    ", "rst_bkdA", "=", "toponet", "(", "\n", "Ainput_train", "[", "gid", "]", ",", "topomask_train", "[", "gid", "]", ",", "self", ".", "args", ".", "topo_thrd", ",", "\n", "self", ".", "cpu", ",", "self", ".", "args", ".", "topo_activation", ",", "'topo'", ")", "\n", "# rst_bkdA = recover_mask(nodenums[gid], topomask_train[gid], 'topo')", "\n", "# bkd_dr_train.data['adj_list'][gid] = torch.add(rst_bkdA, init_dr_train.data['adj_list'][gid])", "\n", "bkd_dr_train", ".", "data", "[", "'adj_list'", "]", "[", "gid", "]", "=", "torch", ".", "add", "(", "\n", "rst_bkdA", "[", ":", "nodenums", "[", "gid", "]", ",", ":", "nodenums", "[", "gid", "]", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "\n", "init_dr_train", ".", "data", "[", "'adj_list'", "]", "[", "gid", "]", ")", "\n", "\n", "rst_bkdX", "=", "featnet", "(", "\n", "Xinput_train", "[", "gid", "]", ",", "featmask_train", "[", "gid", "]", ",", "self", ".", "args", ".", "feat_thrd", ",", "\n", "self", ".", "cpu", ",", "self", ".", "args", ".", "feat_activation", ",", "'feat'", ")", "\n", "# rst_bkdX = recover_mask(nodenums[gid], featmask_train[gid], 'feat')", "\n", "# bkd_dr_train.data['features'][gid] = torch.add(rst_bkdX, init_dr_train.data['features'][gid]) ", "\n", "bkd_dr_train", ".", "data", "[", "'features'", "]", "[", "gid", "]", "=", "torch", ".", "add", "(", "\n", "rst_bkdX", "[", ":", "nodenums", "[", "gid", "]", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "init_dr_train", ".", "data", "[", "'features'", "]", "[", "gid", "]", ")", "\n", "\n", "# train GNN", "\n", "", "train_model", "(", "self", ".", "args", ",", "bkd_dr_train", ",", "model", ",", "list", "(", "set", "(", "pset", ")", ")", ",", "list", "(", "set", "(", "nset", ")", ")", ")", "\n", "\n", "#----------------- Evaluation -----------------#", "\n", "for", "gid", "in", "bkd_gids_test", ":", "\n", "                    ", "rst_bkdA", "=", "toponet", "(", "\n", "Ainput_test", "[", "gid", "]", ",", "topomask_test", "[", "gid", "]", ",", "self", ".", "args", ".", "topo_thrd", ",", "\n", "self", ".", "cpu", ",", "self", ".", "args", ".", "topo_activation", ",", "'topo'", ")", "\n", "# rst_bkdA = recover_mask(nodenums[gid], topomask_test[gid], 'topo')", "\n", "# bkd_dr_test.data['adj_list'][gid] = torch.add(rst_bkdA, ", "\n", "#     torch.as_tensor(copy.deepcopy(init_dr_test.data['adj_list'][gid])))", "\n", "bkd_dr_test", ".", "data", "[", "'adj_list'", "]", "[", "gid", "]", "=", "torch", ".", "add", "(", "\n", "rst_bkdA", "[", ":", "nodenums", "[", "gid", "]", ",", ":", "nodenums", "[", "gid", "]", "]", ",", "\n", "torch", ".", "as_tensor", "(", "copy", ".", "deepcopy", "(", "init_dr_test", ".", "data", "[", "'adj_list'", "]", "[", "gid", "]", ")", ")", ")", "\n", "\n", "rst_bkdX", "=", "featnet", "(", "\n", "Xinput_test", "[", "gid", "]", ",", "featmask_test", "[", "gid", "]", ",", "self", ".", "args", ".", "feat_thrd", ",", "\n", "self", ".", "cpu", ",", "self", ".", "args", ".", "feat_activation", ",", "'feat'", ")", "\n", "# rst_bkdX = recover_mask(nodenums[gid], featmask_test[gid], 'feat')", "\n", "# bkd_dr_test.data['features'][gid] = torch.add(", "\n", "#     rst_bkdX, torch.as_tensor(copy.deepcopy(init_dr_test.data['features'][gid])))", "\n", "bkd_dr_test", ".", "data", "[", "'features'", "]", "[", "gid", "]", "=", "torch", ".", "add", "(", "\n", "rst_bkdX", "[", ":", "nodenums", "[", "gid", "]", "]", ",", "torch", ".", "as_tensor", "(", "copy", ".", "deepcopy", "(", "init_dr_test", ".", "data", "[", "'features'", "]", "[", "gid", "]", ")", ")", ")", "\n", "\n", "# graph originally in target label", "\n", "", "yt_gids", "=", "[", "gid", "for", "gid", "in", "bkd_gids_test", "\n", "if", "self", ".", "benign_dr", ".", "data", "[", "'labels'", "]", "[", "gid", "]", "==", "self", ".", "args", ".", "target_class", "]", "\n", "# graph originally notin target label", "\n", "yx_gids", "=", "list", "(", "set", "(", "bkd_gids_test", ")", "-", "set", "(", "yt_gids", ")", ")", "\n", "clean_graphs_test", "=", "list", "(", "set", "(", "self", ".", "benign_dr", ".", "data", "[", "'splits'", "]", "[", "'test'", "]", ")", "-", "set", "(", "bkd_gids_test", ")", ")", "\n", "\n", "# feed into GNN, test success rate", "\n", "bkd_acc", "=", "evaluate", "(", "self", ".", "args", ",", "bkd_dr_test", ",", "model", ",", "bkd_gids_test", ")", "\n", "flip_rate", "=", "evaluate", "(", "self", ".", "args", ",", "bkd_dr_test", ",", "model", ",", "yx_gids", ")", "\n", "clean_acc", "=", "evaluate", "(", "self", ".", "args", ",", "bkd_dr_test", ",", "model", ",", "clean_graphs_test", ")", "\n", "\n", "# save gnn", "\n", "if", "rs_step", "==", "0", "and", "(", "bi_step", "==", "self", ".", "args", ".", "bilevel_steps", "-", "1", "or", "abs", "(", "bkd_acc", "-", "100", ")", "<", "1e-4", ")", ":", "\n", "                    ", "if", "self", ".", "args", ".", "save_bkd_model", ":", "\n", "                        ", "save_path", "=", "self", ".", "args", ".", "bkd_model_save_path", "\n", "os", ".", "makedirs", "(", "save_path", ",", "exist_ok", "=", "True", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'%s-%s-%f.t7'", "%", "(", "\n", "self", ".", "args", ".", "model", ",", "self", ".", "args", ".", "dataset", ",", "self", ".", "args", ".", "train_ratio", ",", "\n", "self", ".", "args", ".", "bkd_gratio_trainset", ",", "self", ".", "args", ".", "bkd_num_pergraph", ",", "self", ".", "args", ".", "bkd_size", ")", ")", "\n", "\n", "torch", ".", "save", "(", "{", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'asr'", ":", "bkd_acc", ",", "\n", "'flip_rate'", ":", "flip_rate", ",", "\n", "'clean_acc'", ":", "clean_acc", ",", "\n", "}", ",", "save_path", ")", "\n", "print", "(", "\"Trojaning model is saved at: \"", ",", "save_path", ")", "\n", "\n", "", "", "if", "abs", "(", "bkd_acc", "-", "100", ")", "<", "1e-4", ":", "\n", "# bkd_dr_tosave = copy.deepcopy(bkd_dr_test)", "\n", "                    ", "print", "(", "\"Early Termination for 100% Attack Rate\"", ")", "\n", "break", "\n", "", "", "", "print", "(", "'Done'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.attack.GraphBackdoor.bkd_cdd": [[169, 182], ["utils.bkdcdd.select_cdd_graphs", "utils.bkdcdd.select_cdd_nodes", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.bkdcdd.select_cdd_graphs", "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.utils.bkdcdd.select_cdd_nodes"], ["", "def", "bkd_cdd", "(", "self", ",", "subset", ":", "str", ")", ":", "\n", "# - subset: 'train', 'test'", "\n", "# find graphs to add trigger (not modify now)", "\n", "        ", "bkd_gids", "=", "select_cdd_graphs", "(", "\n", "self", ".", "args", ",", "self", ".", "benign_dr", ".", "data", "[", "'splits'", "]", "[", "subset", "]", ",", "self", ".", "benign_dr", ".", "data", "[", "'adj_list'", "]", ",", "subset", ")", "\n", "# find trigger nodes per graph", "\n", "# same sequence with selected backdoored graphs", "\n", "bkd_nids", ",", "bkd_nid_groups", "=", "select_cdd_nodes", "(", "\n", "self", ".", "args", ",", "bkd_gids", ",", "self", ".", "benign_dr", ".", "data", "[", "'adj_list'", "]", ")", "\n", "\n", "assert", "len", "(", "bkd_gids", ")", "==", "len", "(", "bkd_nids", ")", "==", "len", "(", "bkd_nid_groups", ")", "\n", "\n", "return", "bkd_gids", ",", "bkd_nids", ",", "bkd_nid_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.attack.GraphBackdoor.init_trigger": [[184, 216], ["tqdm.tqdm.tqdm", "print", "range", "len", "numpy.array", "numpy.array.tolist", "len", "numpy.array", "numpy.array.tolist", "numpy.ones", "src.append", "dst.append", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "init_trigger", "(", "args", ",", "dr", ":", "DataReader", ",", "bkd_gids", ":", "list", ",", "bkd_nid_groups", ":", "list", ",", "init_edge", ":", "float", ",", "init_feat", ":", "float", ")", ":", "\n", "        ", "if", "init_feat", "==", "None", ":", "\n", "            ", "init_feat", "=", "-", "1", "\n", "print", "(", "'init feat == None, transferred into -1'", ")", "\n", "\n", "# (in place) datareader trigger injection", "\n", "", "for", "i", "in", "tqdm", "(", "range", "(", "len", "(", "bkd_gids", ")", ")", ",", "desc", "=", "\"initializing trigger...\"", ")", ":", "\n", "            ", "gid", "=", "bkd_gids", "[", "i", "]", "\n", "for", "group", "in", "bkd_nid_groups", "[", "i", "]", ":", "\n", "# change adj in-place", "\n", "                ", "src", ",", "dst", "=", "[", "]", ",", "[", "]", "\n", "for", "v1", "in", "group", ":", "\n", "                    ", "for", "v2", "in", "group", ":", "\n", "                        ", "if", "v1", "!=", "v2", ":", "\n", "                            ", "src", ".", "append", "(", "v1", ")", "\n", "dst", ".", "append", "(", "v2", ")", "\n", "", "", "", "a", "=", "np", ".", "array", "(", "dr", ".", "data", "[", "'adj_list'", "]", "[", "gid", "]", ")", "\n", "a", "[", "src", ",", "dst", "]", "=", "init_edge", "\n", "dr", ".", "data", "[", "'adj_list'", "]", "[", "gid", "]", "=", "a", ".", "tolist", "(", ")", "\n", "\n", "# change features in-place", "\n", "featdim", "=", "len", "(", "dr", ".", "data", "[", "'features'", "]", "[", "0", "]", "[", "0", "]", ")", "\n", "a", "=", "np", ".", "array", "(", "dr", ".", "data", "[", "'features'", "]", "[", "gid", "]", ")", "\n", "a", "[", "group", "]", "=", "np", ".", "ones", "(", "(", "len", "(", "group", ")", ",", "featdim", ")", ")", "*", "init_feat", "\n", "dr", ".", "data", "[", "'features'", "]", "[", "gid", "]", "=", "a", ".", "tolist", "(", ")", "\n", "\n", "# change graph labels", "\n", "", "assert", "args", ".", "target_class", "is", "not", "None", "\n", "dr", ".", "data", "[", "'labels'", "]", "[", "gid", "]", "=", "args", ".", "target_class", "\n", "\n", "", "return", "dr", "\n", "\n"]], "home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.main.benign.run": [[21, 134], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "utils.datareader.DataReader", "print", "list", "torch.Adam", "torch.MultiStepLR", "model.sage.GraphSAGE.to", "range", "model.sage.GraphSAGE.to", "utils.datareader.GraphData", "torch.utils.data.DataLoader", "model.gcn.GCN", "filter", "[].detach().cpu", "model.sage.GraphSAGE.train", "time.time", "enumerate", "os.makedirs", "os.path.join", "torch.save", "torch.save", "torch.save", "torch.save", "print", "model.gat.GAT", "model.sage.GraphSAGE.parameters", "range", "optim.Adam.zero_grad", "model.sage.GraphSAGE.", "loss_fn", "loss_fn.backward", "optim.Adam.step", "lr_scheduler.MultiStepLR.step", "len", "print", "model.sage.GraphSAGE.eval", "time.time", "enumerate", "print", "os.path.abspath", "len", "len", "model.sage.GraphSAGE", "NotImplementedError", "[].detach", "len", "data[].to", "len", "output.unsqueeze.unsqueeze", "time.time", "loss_fn.item", "len", "range", "model.sage.GraphSAGE.", "loss_fn", "loss_fn.item", "len", "predict_fn", "predict_fn.eq().sum().item", "model.sage.GraphSAGE.state_dict", "len", "data[].to", "len", "output.unsqueeze.unsqueeze", "str", "loss_fn.item", "predict_fn.eq().sum", "output.unsqueeze.max", "len", "predict_fn.eq", "time.time", "data[].detach().cpu().view_as", "data[].detach().cpu", "data[].detach"], "function", ["home.repos.pwc.inspect_result.HarrialX_GraphBackdoor.trojan.GTA.GradWhere.backward"], ["def", "run", "(", "args", ")", ":", "\n", "    ", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "'no GPU available'", "\n", "cpu", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "cuda", "=", "torch", ".", "device", "(", "'cuda'", ")", "\n", "\n", "# load data into DataReader object", "\n", "dr", "=", "DataReader", "(", "args", ")", "\n", "\n", "loaders", "=", "{", "}", "\n", "for", "split", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "        ", "if", "split", "==", "'train'", ":", "\n", "            ", "gids", "=", "dr", ".", "data", "[", "'splits'", "]", "[", "'train'", "]", "\n", "", "else", ":", "\n", "            ", "gids", "=", "dr", ".", "data", "[", "'splits'", "]", "[", "'test'", "]", "\n", "", "gdata", "=", "GraphData", "(", "dr", ",", "gids", ")", "\n", "loader", "=", "DataLoader", "(", "gdata", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "collate_fn", "=", "collate_batch", ")", "\n", "# data in loaders['train/test'] is saved as returned format of collate_batch()", "\n", "loaders", "[", "split", "]", "=", "loader", "\n", "", "print", "(", "'train %d, test %d'", "%", "(", "len", "(", "loaders", "[", "'train'", "]", ".", "dataset", ")", ",", "len", "(", "loaders", "[", "'test'", "]", ".", "dataset", ")", ")", ")", "\n", "\n", "# prepare model", "\n", "in_dim", "=", "loaders", "[", "'train'", "]", ".", "dataset", ".", "num_features", "\n", "out_dim", "=", "loaders", "[", "'train'", "]", ".", "dataset", ".", "num_classes", "\n", "if", "args", ".", "model", "==", "'gcn'", ":", "\n", "        ", "model", "=", "GCN", "(", "in_dim", ",", "out_dim", ",", "hidden_dim", "=", "args", ".", "hidden_dim", ",", "dropout", "=", "args", ".", "dropout", ")", "\n", "", "elif", "args", ".", "model", "==", "'gat'", ":", "\n", "        ", "model", "=", "GAT", "(", "in_dim", ",", "out_dim", ",", "hidden_dim", "=", "args", ".", "hidden_dim", ",", "dropout", "=", "args", ".", "dropout", ",", "num_head", "=", "args", ".", "num_head", ")", "\n", "", "elif", "args", ".", "model", "==", "'sage'", ":", "\n", "        ", "model", "=", "GraphSAGE", "(", "in_dim", ",", "out_dim", ",", "hidden_dim", "=", "args", ".", "hidden_dim", ",", "dropout", "=", "args", ".", "dropout", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "args", ".", "model", ")", "\n", "\n", "# print('\\nInitialize model')", "\n", "# print(model)", "\n", "", "train_params", "=", "list", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ")", "\n", "# print('N trainable parameters:', np.sum([p.numel() for p in train_params]))", "\n", "\n", "# training", "\n", "loss_fn", "=", "F", ".", "cross_entropy", "\n", "predict_fn", "=", "lambda", "output", ":", "output", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", "[", "1", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "train_params", ",", "lr", "=", "args", ".", "lr", ",", "weight_decay", "=", "args", ".", "weight_decay", ",", "betas", "=", "(", "0.5", ",", "0.999", ")", ")", "\n", "scheduler", "=", "lr_scheduler", ".", "MultiStepLR", "(", "optimizer", ",", "args", ".", "lr_decay_steps", ",", "gamma", "=", "0.1", ")", "\n", "\n", "model", ".", "to", "(", "cuda", ")", "\n", "for", "epoch", "in", "range", "(", "args", ".", "train_epochs", ")", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "n_samples", "=", "0", ",", "0", "\n", "for", "batch_id", ",", "data", "in", "enumerate", "(", "loaders", "[", "'train'", "]", ")", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "                ", "data", "[", "i", "]", "=", "data", "[", "i", "]", ".", "to", "(", "cuda", ")", "\n", "# if args.use_cont_node_attr:", "\n", "#     data[0] = norm_features(data[0])", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "if", "len", "(", "output", ".", "shape", ")", "==", "1", ":", "\n", "                ", "output", "=", "output", ".", "unsqueeze", "(", "0", ")", "\n", "", "loss", "=", "loss_fn", "(", "output", ",", "data", "[", "4", "]", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "time_iter", "=", "time", ".", "time", "(", ")", "-", "start", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "*", "len", "(", "output", ")", "\n", "n_samples", "+=", "len", "(", "output", ")", "\n", "\n", "", "if", "args", ".", "train_verbose", "and", "(", "epoch", "%", "args", ".", "log_every", "==", "0", "or", "epoch", "==", "args", ".", "train_epochs", "-", "1", ")", ":", "\n", "            ", "print", "(", "'Train Epoch: %d\\tLoss: %.4f (avg: %.4f) \\tsec/iter: %.2f'", "%", "(", "\n", "epoch", "+", "1", ",", "loss", ".", "item", "(", ")", ",", "train_loss", "/", "n_samples", ",", "time_iter", "/", "(", "batch_id", "+", "1", ")", ")", ")", "\n", "\n", "", "if", "(", "epoch", "+", "1", ")", "%", "args", ".", "eval_every", "==", "0", "or", "epoch", "==", "args", ".", "train_epochs", "-", "1", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "test_loss", ",", "correct", ",", "n_samples", "=", "0", ",", "0", ",", "0", "\n", "for", "batch_id", ",", "data", "in", "enumerate", "(", "loaders", "[", "'test'", "]", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "                    ", "data", "[", "i", "]", "=", "data", "[", "i", "]", ".", "to", "(", "cuda", ")", "\n", "# if args.use_org_node_attr:", "\n", "#     data[0] = norm_features(data[0])", "\n", "", "output", "=", "model", "(", "data", ")", "\n", "if", "len", "(", "output", ".", "shape", ")", "==", "1", ":", "\n", "                    ", "output", "=", "output", ".", "unsqueeze", "(", "0", ")", "\n", "", "loss", "=", "loss_fn", "(", "output", ",", "data", "[", "4", "]", ",", "reduction", "=", "'sum'", ")", "\n", "test_loss", "+=", "loss", ".", "item", "(", ")", "\n", "n_samples", "+=", "len", "(", "output", ")", "\n", "pred", "=", "predict_fn", "(", "output", ")", "\n", "\n", "correct", "+=", "pred", ".", "eq", "(", "data", "[", "4", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "eval_acc", "=", "100.", "*", "correct", "/", "n_samples", "\n", "print", "(", "'Test set (epoch %d): Average loss: %.4f, Accuracy: %d/%d (%.2f%s) \\tsec/iter: %.2f'", "%", "(", "\n", "epoch", "+", "1", ",", "test_loss", "/", "n_samples", ",", "correct", ",", "n_samples", ",", "\n", "eval_acc", ",", "'%'", ",", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "len", "(", "loaders", "[", "'test'", "]", ")", ")", ")", "\n", "\n", "", "", "model", ".", "to", "(", "cpu", ")", "\n", "\n", "if", "args", ".", "save_clean_model", ":", "\n", "        ", "save_path", "=", "args", ".", "clean_model_save_path", "\n", "os", ".", "makedirs", "(", "save_path", ",", "exist_ok", "=", "True", ")", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'%s-%s-%s.t7'", "%", "(", "args", ".", "model", ",", "args", ".", "dataset", ",", "str", "(", "args", ".", "train_ratio", ")", ")", ")", "\n", "\n", "torch", ".", "save", "(", "{", "\n", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'lr'", ":", "args", ".", "lr", ",", "\n", "'batch_size'", ":", "args", ".", "batch_size", ",", "\n", "'eval_acc'", ":", "eval_acc", ",", "\n", "}", ",", "save_path", ")", "\n", "print", "(", "'Clean trained GNN saved at: '", ",", "os", ".", "path", ".", "abspath", "(", "save_path", ")", ")", "\n", "\n", "", "return", "dr", ",", "model", "\n", "\n"]]}