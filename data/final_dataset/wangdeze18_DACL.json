{"home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_score.read_answers": [[8, 16], ["open", "line.strip.strip", "json.loads"], "function", ["None"], ["def", "read_answers", "(", "filename", ")", ":", "\n", "    ", "answers", "=", "{", "}", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "answers", "[", "js", "[", "'index'", "]", "]", "=", "js", "[", "'answers'", "]", "\n", "", "", "return", "answers", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_score.read_predictions": [[18, 26], ["open", "line.strip.strip", "json.loads"], "function", ["None"], ["", "def", "read_predictions", "(", "filename", ")", ":", "\n", "    ", "predictions", "=", "{", "}", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "predictions", "[", "js", "[", "'index'", "]", "]", "=", "js", "[", "'answers'", "]", "\n", "", "", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_score.calculate_scores": [[28, 61], ["set", "range", "open", "sorted", "logging.error", "sys.exit", "len", "len", "logging.error", "sys.exit", "len", "len", "print", "f.write", "int", "str"], "function", ["None"], ["", "def", "calculate_scores", "(", "answers", ",", "predictions", ",", "output_data_file", ")", ":", "\n", "    ", "scores", "=", "{", "}", "\n", "for", "key", "in", "answers", ":", "\n", "#print(key)", "\n", "        ", "if", "key", "not", "in", "predictions", ":", "\n", "            ", "logging", ".", "error", "(", "\"Missing prediction for index {}.\"", ".", "format", "(", "key", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "ans_set", "=", "set", "(", "answers", "[", "key", "]", ")", "\n", "pre_list", "=", "predictions", "[", "key", "]", "\n", "if", "len", "(", "ans_set", ")", "!=", "len", "(", "pre_list", ")", ":", "\n", "            ", "logging", ".", "error", "(", "\"Mismatch the number of answers for index {}.\"", ".", "format", "(", "key", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "score", "=", "0", "\n", "have_find", "=", "0", "\n", "#print(ans_set)", "\n", "for", "i", "in", "range", "(", "len", "(", "pre_list", ")", ")", ":", "\n", "            ", "if", "pre_list", "[", "i", "]", "in", "ans_set", ":", "\n", "\n", "                ", "have_find", "+=", "1", "\n", "score", "+=", "have_find", "/", "(", "i", "+", "1", ")", "\n", "", "", "scores", "[", "int", "(", "key", ")", "]", "=", "score", "/", "len", "(", "pre_list", ")", "\n", "\n", "#scores = np.array(scores)", "\n", "#np.save(output_data_file, scores)", "\n", "", "with", "open", "(", "output_data_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "i", "in", "sorted", "(", "scores", ")", ":", "\n", "            ", "print", "(", "i", ")", "\n", "f", ".", "write", "(", "str", "(", "scores", "[", "i", "]", ")", "+", "\"\\n\"", ")", "\n", "#result = {}", "\n", "#result['MAP'] = round(np.mean(scores), 4)", "\n", "", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_score.main": [[63, 74], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "evaluator_score.read_answers", "evaluator_score.read_predictions", "evaluator_score.calculate_scores"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.code.sumscores.read_answers", "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_large.read_predictions", "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_large.calculate_scores"], ["", "def", "main", "(", ")", ":", "\n", "    ", "import", "argparse", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Evaluate leaderboard predictions for POJ-104 dataset.'", ")", "\n", "parser", ".", "add_argument", "(", "'--answers'", ",", "'-a'", ",", "help", "=", "\"filename of the labels, in txt format.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--predictions'", ",", "'-p'", ",", "help", "=", "\"filename of the leaderboard predictions, in txt format.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_data_file\"", ",", "'-o'", ",", "type", "=", "str", ",", "required", "=", "True", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "answers", "=", "read_answers", "(", "args", ".", "answers", ")", "\n", "predictions", "=", "read_predictions", "(", "args", ".", "predictions", ")", "\n", "calculate_scores", "(", "answers", ",", "predictions", ",", "args", ".", "output_data_file", ")", "\n", "#print(scores)", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.eva_MAP.read_answers": [[8, 16], ["open", "line.strip.strip", "json.loads"], "function", ["None"], ["def", "read_answers", "(", "filename", ")", ":", "\n", "    ", "answers", "=", "{", "}", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "answers", "[", "js", "[", "'index'", "]", "]", "=", "js", "[", "'answers'", "]", "\n", "", "", "return", "answers", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.eva_MAP.read_predictions": [[17, 25], ["open", "line.strip.strip", "json.loads"], "function", ["None"], ["", "def", "read_predictions", "(", "filename", ")", ":", "\n", "    ", "predictions", "=", "{", "}", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "predictions", "[", "js", "[", "'index'", "]", "]", "=", "js", "[", "'answers'", "]", "\n", "", "", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.eva_MAP.calculate_scores": [[26, 49], ["round", "set", "enumerate", "scores.append", "numpy.mean", "logging.error", "sys.exit", "len", "len", "logging.error", "sys.exit", "Avep.append", "sum", "len", "len"], "function", ["None"], ["", "def", "calculate_scores", "(", "answers", ",", "predictions", ")", ":", "\n", "    ", "scores", "=", "[", "]", "\n", "for", "key", "in", "answers", ":", "\n", "        ", "if", "key", "not", "in", "predictions", ":", "\n", "            ", "logging", ".", "error", "(", "\"Missing prediction for index {}.\"", ".", "format", "(", "key", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "if", "len", "(", "answers", "[", "key", "]", ")", "!=", "len", "(", "predictions", "[", "key", "]", ")", ":", "\n", "            ", "logging", ".", "error", "(", "\"Mismatch the number of answers for index {}.\"", ".", "format", "(", "key", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "answer", "=", "set", "(", "answers", "[", "key", "]", ")", "\n", "\n", "Avep", "=", "[", "]", "\n", "for", "k", ",", "p", "in", "enumerate", "(", "predictions", "[", "key", "]", ")", ":", "\n", "            ", "if", "p", "in", "answer", ":", "\n", "                ", "Avep", ".", "append", "(", "(", "len", "(", "Avep", ")", "+", "1", ")", "/", "(", "k", "+", "1", ")", ")", "\n", "\n", "", "", "scores", ".", "append", "(", "sum", "(", "Avep", ")", "/", "len", "(", "answer", ")", ")", "\n", "\n", "", "result", "=", "{", "}", "\n", "result", "[", "'MAP@R'", "]", "=", "round", "(", "np", ".", "mean", "(", "scores", ")", ",", "4", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.eva_MAP.main": [[50, 62], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "eva_MAP.read_answers", "eva_MAP.read_predictions", "eva_MAP.calculate_scores", "print"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.code.sumscores.read_answers", "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_large.read_predictions", "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_large.calculate_scores"], ["", "def", "main", "(", ")", ":", "\n", "    ", "import", "argparse", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Evaluate leaderboard predictions for POJ-104 dataset.'", ")", "\n", "parser", ".", "add_argument", "(", "'--answers'", ",", "'-a'", ",", "help", "=", "\"filename of the labels, in txt format.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--predictions'", ",", "'-p'", ",", "help", "=", "\"filename of the leaderboard predictions, in txt format.\"", ")", "\n", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "answers", "=", "read_answers", "(", "args", ".", "answers", ")", "\n", "predictions", "=", "read_predictions", "(", "args", ".", "predictions", ")", "\n", "scores", "=", "calculate_scores", "(", "answers", ",", "predictions", ")", "\n", "print", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.extract_answers.extract_answers": [[5, 25], ["open", "line.strip.strip", "json.loads", "cluster[].add", "answers.append", "set", "temp[].append"], "function", ["None"], ["def", "extract_answers", "(", "filename", ")", ":", "\n", "\t", "cluster", "=", "{", "}", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "\t\t", "for", "line", "in", "f", ":", "\n", "\t\t\t", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "if", "js", "[", "'label'", "]", "not", "in", "cluster", ":", "\n", "\t\t\t\t", "cluster", "[", "js", "[", "'label'", "]", "]", "=", "set", "(", ")", "\n", "", "cluster", "[", "js", "[", "'label'", "]", "]", ".", "add", "(", "js", "[", "'index'", "]", ")", "\n", "", "", "answers", "=", "[", "]", "\n", "for", "key", "in", "cluster", ":", "\n", "\t\t", "for", "idx1", "in", "cluster", "[", "key", "]", ":", "\n", "\t\t\t", "temp", "=", "{", "}", "\n", "temp", "[", "'index'", "]", "=", "idx1", "\n", "temp", "[", "'answers'", "]", "=", "[", "]", "\n", "for", "idx2", "in", "cluster", "[", "key", "]", ":", "\n", "\t\t\t\t", "if", "idx1", "!=", "idx2", ":", "\n", "\t\t\t\t\t", "temp", "[", "'answers'", "]", ".", "append", "(", "idx2", ")", "\n", "", "", "answers", ".", "append", "(", "temp", ")", "\n", "", "", "return", "answers", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.extract_answers.main": [[27, 37], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "extract_answers.extract_answers", "open", "f.write", "json.dumps"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.extract_answers.extract_answers"], ["", "def", "main", "(", ")", ":", "\n", "    ", "import", "argparse", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Extract answers from code files.'", ")", "\n", "parser", ".", "add_argument", "(", "'--codefile'", ",", "'-c'", ",", "help", "=", "\"filename of the code examples.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--outfile'", ",", "'-o'", ",", "help", "=", "\"filename of output.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "answers", "=", "extract_answers", "(", "args", ".", "codefile", ")", "\n", "with", "open", "(", "args", ".", "outfile", ",", "'w'", ")", "as", "f", ":", "\n", "    \t", "for", "line", "in", "answers", ":", "\n", "    \t\t", "f", ".", "write", "(", "json", ".", "dumps", "(", "line", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator.read_answers": [[7, 15], ["open", "line.strip.strip", "line.strip.split"], "function", ["None"], ["def", "read_answers", "(", "filename", ")", ":", "\n", "    ", "answers", "=", "{", "}", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "answers", "[", "js", "[", "'index'", "]", "]", "=", "js", "[", "'answers'", "]", "\n", "", "", "return", "answers", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator.read_predictions": [[16, 24], ["open", "line.strip.strip", "line.strip.split"], "function", ["None"], ["", "def", "read_predictions", "(", "filename", ")", ":", "\n", "    ", "predictions", "=", "{", "}", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "predictions", "[", "js", "[", "'index'", "]", "]", "=", "js", "[", "'answers'", "]", "\n", "", "", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator.calculate_scores": [[25, 38], ["sklearn.metrics.recall_score", "sklearn.metrics.precision_score", "sklearn.metrics.f1_score", "y_trues.append", "y_preds.append", "logging.error", "sys.exit"], "function", ["None"], ["", "def", "calculate_scores", "(", "answers", ",", "predictions", ")", ":", "\n", "    ", "scores", "=", "[", "]", "\n", "for", "key", "in", "answers", ":", "\n", "        ", "if", "key", "not", "in", "predictions", ":", "\n", "            ", "logging", ".", "error", "(", "\"Missing prediction for index {}.\"", ".", "format", "(", "key", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "a", "=", "set", "(", "answers", "[", "key", "]", ")", "\n", "p", "=", "set", "(", "predictions", "[", "key", "]", ")", "\n", "if", "len", "(", "a", ")", "!=", "len", "(", "p", ")", ":", "\n", "            ", "logging", ".", "error", "(", "\"Mismatch the number of answers for index {}.\"", ".", "format", "(", "key", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "scores", ".", "append", "(", "len", "(", "set", "(", "a", "&", "p", ")", ")", "/", "len", "(", "a", ")", ")", "\n", "", "result", "=", "{", "}", "\n", "result", "[", "'MAP'", "]", "=", "round", "(", "np", ".", "mean", "(", "scores", ")", ",", "4", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator.main": [[39, 51], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "evaluator.read_answers", "evaluator.read_predictions", "evaluator.calculate_scores", "print"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.code.sumscores.read_answers", "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_large.read_predictions", "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_large.calculate_scores"], ["return", "result", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "import", "argparse", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Evaluate leaderboard predictions for POJ-104 dataset.'", ")", "\n", "parser", ".", "add_argument", "(", "'--answers'", ",", "'-a'", ",", "help", "=", "\"filename of the labels, in txt format.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--predictions'", ",", "'-p'", ",", "help", "=", "\"filename of the leaderboard predictions, in txt format.\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "answers", "=", "read_answers", "(", "args", ".", "answers", ")", "\n", "predictions", "=", "read_predictions", "(", "args", ".", "predictions", ")", "\n", "scores", "=", "calculate_scores", "(", "answers", ",", "predictions", ")", "\n", "print", "(", "scores", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_large.read_answers": [[8, 16], ["open", "line.strip.strip", "line.strip.split"], "function", ["None"], ["def", "read_answers", "(", "filename", ")", ":", "\n", "    ", "answers", "=", "{", "}", "\n", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "idx1", ",", "idx2", ",", "label", "=", "line", ".", "split", "(", ")", "\n", "answers", "[", "(", "idx1", ",", "idx2", ")", "]", "=", "label", "\n", "", "", "return", "answers", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_large.read_predictions": [[18, 41], ["filenamelist.split", "predictions.keys", "open", "line.strip.strip", "line.strip.split", "int", "len", "idx1.find", "idx1.find", "idx2.find", "idx2.find"], "function", ["None"], ["", "def", "read_predictions", "(", "filenamelist", ")", ":", "\n", "    ", "filelist", "=", "filenamelist", ".", "split", "(", "','", ")", "\n", "predictions", "=", "{", "}", "\n", "for", "filename", "in", "filelist", ":", "\n", "        ", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "idx1", ",", "idx2", ",", "label", "=", "line", ".", "split", "(", ")", "\n", "if", "idx1", ".", "find", "(", "\"_\"", ")", "!=", "-", "1", ":", "\n", "                    ", "loc", "=", "idx1", ".", "find", "(", "\"_\"", ")", "\n", "idx1", "=", "idx1", "[", ":", "loc", "]", "\n", "", "if", "idx2", ".", "find", "(", "\"_\"", ")", "!=", "-", "1", ":", "\n", "                    ", "loc", "=", "idx2", ".", "find", "(", "\"_\"", ")", "\n", "idx2", "=", "idx2", "[", ":", "loc", "]", "\n", "", "if", "(", "idx1", ",", "idx2", ")", "not", "in", "predictions", ":", "\n", "                    ", "predictions", "[", "(", "idx1", ",", "idx2", ")", "]", "=", "0", "\n", "", "predictions", "[", "(", "idx1", ",", "idx2", ")", "]", "+=", "int", "(", "label", ")", "\n", "", "", "", "for", "k", "in", "predictions", ".", "keys", "(", ")", ":", "\n", "        ", "if", "predictions", "[", "k", "]", ">", "len", "(", "filelist", ")", "/", "2", ":", "# len(filelist) % 2 ==0", "\n", "            ", "predictions", "[", "k", "]", "=", "'1'", "\n", "", "else", ":", "\n", "            ", "predictions", "[", "k", "]", "=", "'0'", "\n", "", "", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_large.calculate_scores": [[43, 56], ["sklearn.metrics.recall_score", "sklearn.metrics.precision_score", "sklearn.metrics.f1_score", "y_trues.append", "y_preds.append", "logging.error", "sys.exit"], "function", ["None"], ["", "def", "calculate_scores", "(", "answers", ",", "predictions", ")", ":", "\n", "    ", "y_trues", ",", "y_preds", "=", "[", "]", ",", "[", "]", "\n", "for", "key", "in", "answers", ":", "\n", "        ", "if", "key", "not", "in", "predictions", ":", "\n", "            ", "logging", ".", "error", "(", "\"Missing prediction for ({},{}) pair.\"", ".", "format", "(", "key", "[", "0", "]", ",", "key", "[", "1", "]", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "y_trues", ".", "append", "(", "answers", "[", "key", "]", ")", "\n", "y_preds", ".", "append", "(", "predictions", "[", "key", "]", ")", "\n", "", "scores", "=", "{", "}", "\n", "scores", "[", "'Recall'", "]", "=", "recall_score", "(", "y_trues", ",", "y_preds", ",", "average", "=", "'macro'", ")", "\n", "scores", "[", "'Prediction'", "]", "=", "precision_score", "(", "y_trues", ",", "y_preds", ",", "average", "=", "'macro'", ")", "\n", "scores", "[", "'F1'", "]", "=", "f1_score", "(", "y_trues", ",", "y_preds", ",", "average", "=", "'macro'", ")", "\n", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_large.main": [[58, 69], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "evaluator_large.read_answers", "evaluator_large.read_predictions", "evaluator_large.calculate_scores", "print"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.code.sumscores.read_answers", "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_large.read_predictions", "home.repos.pwc.inspect_result.wangdeze18_DACL.evaluator.evaluator_large.calculate_scores"], ["", "def", "main", "(", ")", ":", "\n", "    ", "import", "argparse", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Evaluate leaderboard predictions for BigCloneBench dataset.'", ")", "\n", "parser", ".", "add_argument", "(", "'--answers'", ",", "'-a'", ",", "help", "=", "\"filename of the labels, in txt format.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--predictions'", ",", "'-p'", ",", "help", "=", "\"filename of the leaderboard predictions, in txt format.\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "answers", "=", "read_answers", "(", "args", ".", "answers", ")", "\n", "predictions", "=", "read_predictions", "(", "args", ".", "predictions", ")", "\n", "scores", "=", "calculate_scores", "(", "answers", ",", "predictions", ")", "\n", "print", "(", "scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.bagging.InputFeatures.__init__": [[67, 78], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "input_tokens", ",", "\n", "input_ids", ",", "\n", "index", ",", "\n", "label", ",", "\n", "\n", ")", ":", "\n", "        ", "self", ".", "input_tokens", "=", "input_tokens", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.bagging.TextDataset.__init__": [[91, 106], ["open", "bagging.TextDataset.examples.append", "bagging.TextDataset.label_examples[].append", "line.strip.strip.strip", "json.loads", "data.append", "bagging.convert_examples_to_features"], "methods", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.convert_examples_to_features"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ",", "file_path", "=", "None", ")", ":", "\n", "        ", "self", ".", "examples", "=", "[", "]", "\n", "data", "=", "[", "]", "\n", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "data", ".", "append", "(", "js", ")", "\n", "", "", "for", "js", "in", "data", ":", "\n", "            ", "self", ".", "examples", ".", "append", "(", "convert_examples_to_features", "(", "js", ",", "tokenizer", ",", "args", ")", ")", "\n", "", "self", ".", "label_examples", "=", "{", "}", "\n", "for", "e", "in", "self", ".", "examples", ":", "\n", "            ", "if", "e", ".", "label", "not", "in", "self", ".", "label_examples", ":", "\n", "                ", "self", ".", "label_examples", "[", "e", ".", "label", "]", "=", "[", "]", "\n", "", "self", ".", "label_examples", "[", "e", ".", "label", "]", ".", "append", "(", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.bagging.TextDataset.__len__": [[107, 109], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.bagging.TextDataset.__getitem__": [[110, 124], ["list", "list.remove", "random.sample", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "random.sample", "random.sample"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "label", "=", "self", ".", "examples", "[", "i", "]", ".", "label", "\n", "index", "=", "self", ".", "examples", "[", "i", "]", ".", "index", "\n", "labels", "=", "list", "(", "self", ".", "label_examples", ")", "\n", "labels", ".", "remove", "(", "label", ")", "\n", "while", "True", ":", "\n", "            ", "shuffle_example", "=", "random", ".", "sample", "(", "self", ".", "label_examples", "[", "label", "]", ",", "1", ")", "[", "0", "]", "\n", "if", "shuffle_example", ".", "index", "!=", "index", ":", "\n", "                ", "p_example", "=", "shuffle_example", "\n", "break", "\n", "", "", "n_example", "=", "random", ".", "sample", "(", "self", ".", "label_examples", "[", "random", ".", "sample", "(", "labels", ",", "1", ")", "[", "0", "]", "]", ",", "1", ")", "[", "0", "]", "\n", "\n", "return", "(", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "i", "]", ".", "input_ids", ")", ",", "torch", ".", "tensor", "(", "p_example", ".", "input_ids", ")", ",", "\n", "torch", ".", "tensor", "(", "n_example", ".", "input_ids", ")", ",", "torch", ".", "tensor", "(", "label", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.bagging.convert_examples_to_features": [[80, 89], ["tokenizer.convert_tokens_to_ids", "bagging.InputFeatures", "js[].split", "tokenizer.tokenize", "len", "int"], "function", ["None"], ["", "", "def", "convert_examples_to_features", "(", "js", ",", "tokenizer", ",", "args", ")", ":", "\n", "#source", "\n", "    ", "code", "=", "' '", ".", "join", "(", "js", "[", "'code'", "]", ".", "split", "(", ")", ")", "\n", "code_tokens", "=", "tokenizer", ".", "tokenize", "(", "code", ")", "[", ":", "args", ".", "block_size", "-", "2", "]", "\n", "source_tokens", "=", "[", "tokenizer", ".", "cls_token", "]", "+", "code_tokens", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "source_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "source_tokens", ")", "\n", "padding_length", "=", "args", ".", "block_size", "-", "len", "(", "source_ids", ")", "\n", "source_ids", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n", "return", "InputFeatures", "(", "source_tokens", ",", "source_ids", ",", "js", "[", "'index'", "]", ",", "int", "(", "js", "[", "'label'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.bagging.set_seed": [[126, 133], ["random.seed", "str", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["", "", "def", "set_seed", "(", "seed", "=", "42", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "'PYHTONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.bagging.train": [[135, 281], ["torch.utils.data.DataLoader", "len", "len", "len", "torch.nn.parallel.DistributedDataParallel.to", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.path.exists", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "range", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "len", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "transformers.get_linear_schedule_with_warmup.load_state_dict", "transformers.AdamW.load_state_dict", "len", "int", "enumerate", "torch.load", "torch.load", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "loss.mean.item", "round", "ImportError", "torch.distributed.get_world_size", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "logger.info", "transformers.AdamW.step", "transformers.AdamW.zero_grad", "transformers.get_linear_schedule_with_warmup.step", "round", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "numpy.exp", "any", "bagging.evaluate", "evaluate.items", "logger.info", "logger.info", "logger.info", "os.path.join", "os.path.join", "torch.save", "logger.info", "logger.info", "round", "os.path.exists", "os.makedirs", "hasattr", "model_to_save.state_dict", "round"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "10", ")", "\n", "args", ".", "max_steps", "=", "args", ".", "epoch", "*", "len", "(", "train_dataloader", ")", "\n", "args", ".", "save_steps", "=", "len", "(", "train_dataloader", ")", "\n", "args", ".", "warmup_steps", "=", "len", "(", "train_dataloader", ")", "\n", "args", ".", "logging_steps", "=", "len", "(", "train_dataloader", ")", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "epoch", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "max_steps", "*", "0.1", ",", "\n", "num_training_steps", "=", "args", ".", "max_steps", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "\n", "", "checkpoint_last", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-last'", ")", "\n", "scheduler_last", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'scheduler.pt'", ")", "\n", "optimizer_last", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'optimizer.pt'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "scheduler_last", ")", ":", "\n", "        ", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "scheduler_last", ")", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "optimizer_last", ")", ":", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "optimizer_last", ")", ")", "\n", "# Train!", "\n", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "\n", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "args", ".", "max_steps", ")", "\n", "\n", "global_step", "=", "args", ".", "start_step", "\n", "tr_loss", ",", "logging_loss", ",", "avg_loss", ",", "tr_nb", ",", "tr_num", ",", "train_loss", "=", "0.0", ",", "0.0", ",", "0.0", ",", "0", ",", "0", ",", "0", "\n", "best_acc", "=", "0.0", "\n", "# model.resize_token_embeddings(len(tokenizer))", "\n", "model", ".", "zero_grad", "(", ")", "\n", "for", "idx", "in", "range", "(", "args", ".", "start_epoch", ",", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "        ", "'''\n        if idx != args.start_epoch:\n            print(\"idx = \", idx)\n            train_dataset = TextDataset(tokenizer, args, args.train_data_file)\n            train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n\n            train_dataloader = DataLoader(train_dataset, sampler=train_sampler,\n                                          batch_size=args.train_batch_size, num_workers=10)\n        '''", "\n", "bar", "=", "train_dataloader", "\n", "tr_num", "=", "0", "\n", "train_loss", "=", "0", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "bar", ")", ":", "\n", "            ", "inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "p_inputs", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "n_inputs", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "model", ".", "train", "(", ")", "\n", "loss", ",", "vec", "=", "model", "(", "inputs", ",", "p_inputs", ",", "n_inputs", ",", "labels", ")", "\n", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "tr_num", "+=", "1", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "avg_loss", "==", "0", ":", "\n", "                ", "avg_loss", "=", "tr_loss", "\n", "", "avg_loss", "=", "round", "(", "train_loss", "/", "tr_num", ",", "5", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"epoch {} step {} loss {}\"", ".", "format", "(", "idx", ",", "step", "+", "1", ",", "avg_loss", ")", ")", "\n", "#bar.set_description(\"epoch {} loss {}\".format(idx,avg_loss))", "\n", "\n", "\n", "", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "global_step", "+=", "1", "\n", "output_flag", "=", "True", "\n", "avg_loss", "=", "round", "(", "np", ".", "exp", "(", "(", "tr_loss", "-", "logging_loss", ")", "/", "(", "global_step", "-", "tr_nb", ")", ")", ",", "4", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                    ", "logging_loss", "=", "tr_loss", "\n", "tr_nb", "=", "global_step", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "eval_when_training", "=", "True", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "round", "(", "value", ",", "4", ")", ")", "\n", "# Save model checkpoint", "\n", "", "tr_num", "=", "0", "\n", "train_loss", "=", "0", "\n", "\n", "", "if", "results", "[", "'eval_map'", "]", ">", "best_acc", ":", "\n", "                        ", "best_acc", "=", "results", "[", "'eval_map'", "]", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "logger", ".", "info", "(", "\"  Best map:%s\"", ",", "round", "(", "best_acc", ",", "4", ")", ")", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "\n", "checkpoint_prefix", "=", "'checkpoint-best-map'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                            ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'{}'", ".", "format", "(", "'model.bin'", ")", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_dir", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.bagging.evaluate": [[284, 353], ["torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "numpy.concatenate", "numpy.concatenate", "torch.tensor", "numpy.matmul", "range", "range", "bagging.TextDataset", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "numpy.argsort", "int", "range", "MAP.append", "float", "float", "os.path.exists", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "np.concatenate.append", "np.concatenate.append", "int", "numpy.mean", "vec.cpu().numpy", "int.cpu().numpy", "int", "int", "lm_loss.mean", "int", "vec.cpu", "int.cpu"], "function", ["None"], ["def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "eval_when_training", "=", "False", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "global", "eval_dataset", "\n", "if", "eval_dataset", "is", "None", ":", "\n", "        ", "eval_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "eval_data_file", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "num_workers", "=", "10", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "eval_when_training", "is", "False", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "vecs", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "p_inputs", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "n_inputs", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "label", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "lm_loss", ",", "vec", "=", "model", "(", "inputs", ",", "p_inputs", ",", "n_inputs", ",", "label", ")", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "vecs", ".", "append", "(", "vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "labels", ".", "append", "(", "label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "", "vecs", "=", "np", ".", "concatenate", "(", "vecs", ",", "0", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "0", ")", "\n", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "tensor", "(", "eval_loss", ")", "\n", "\n", "scores", "=", "np", ".", "matmul", "(", "vecs", ",", "vecs", ".", "T", ")", "\n", "dic", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "scores", "[", "i", ",", "i", "]", "=", "-", "1000000", "\n", "if", "int", "(", "labels", "[", "i", "]", ")", "not", "in", "dic", ":", "\n", "            ", "dic", "[", "int", "(", "labels", "[", "i", "]", ")", "]", "=", "-", "1", "\n", "", "dic", "[", "int", "(", "labels", "[", "i", "]", ")", "]", "+=", "1", "\n", "", "sort_ids", "=", "np", ".", "argsort", "(", "scores", ",", "axis", "=", "-", "1", ",", "kind", "=", "'quicksort'", ",", "order", "=", "None", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "MAP", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "cont", "=", "0", "\n", "label", "=", "int", "(", "labels", "[", "i", "]", ")", "\n", "for", "j", "in", "range", "(", "dic", "[", "label", "]", ")", ":", "\n", "            ", "index", "=", "sort_ids", "[", "i", ",", "j", "]", "\n", "if", "int", "(", "labels", "[", "index", "]", ")", "==", "label", ":", "\n", "                ", "cont", "+=", "1", "\n", "", "", "MAP", ".", "append", "(", "cont", "/", "dic", "[", "label", "]", ")", "\n", "\n", "", "result", "=", "{", "\n", "\"eval_loss\"", ":", "float", "(", "perplexity", ")", ",", "\n", "\"eval_map\"", ":", "float", "(", "np", ".", "mean", "(", "MAP", ")", ")", "\n", "}", "\n", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.bagging.calScores": [[354, 411], ["bagging.TextDataset", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "numpy.concatenate", "numpy.concatenate", "range", "torch.tensor", "numpy.matmul", "range", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "len", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "np.concatenate.append", "np.concatenate.append", "vec.cpu().numpy", "batch[].to.cpu().numpy", "lm_loss.mean", "vec.cpu", "batch[].to.cpu"], "function", ["None"], ["", "def", "calScores", "(", "args", ",", "model", ",", "tokenizer", ",", "test_data_file", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "test_data_file", ")", "\n", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running Test *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "vecs", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "p_inputs", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "n_inputs", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "label", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "## p,n,label (multi_view) not change", "\n", "## table --> inputs_trans ----> vecs_trans", "\n", "## average", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "lm_loss", ",", "vec", "=", "model", "(", "inputs", ",", "p_inputs", ",", "n_inputs", ",", "label", ")", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "vecs", ".", "append", "(", "vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "labels", ".", "append", "(", "label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "", "vecs", "=", "np", ".", "concatenate", "(", "vecs", ",", "0", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "0", ")", "\n", "cluster", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "        ", "label", "=", "labels", "[", "i", "]", "\n", "if", "label", "not", "in", "cluster", ":", "\n", "            ", "cluster", "[", "label", "]", "=", "0", "\n", "", "cluster", "[", "label", "]", "+=", "1", "\n", "\n", "\n", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "tensor", "(", "eval_loss", ")", "\n", "\n", "scores", "=", "np", ".", "matmul", "(", "vecs", ",", "vecs", ".", "T", ")", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "scores", "[", "i", ",", "i", "]", "=", "-", "1000000", "\n", "\n", "", "return", "scores", ",", "cluster", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.bagging.test": [[412, 441], ["numpy.load", "numpy.load", "numpy.load", "bagging.calScores", "bagging.TextDataset", "numpy.argsort", "indexs.append", "open", "zip", "os.path.join", "f.write", "js[].append", "json.dumps", "int"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.code.bagging.calScores"], ["", "def", "test", "(", "args", ",", "model", ",", "tokenizer", ")", ":", "\n", "\n", "\n", "#scores0,cluster,labels = calScores(args, model, tokenizer, \"../dataset/test_align1.jsonl\")", "\n", "#scores1,cluster,labels = calScores(args, model, tokenizer, \"../dataset/test_align2.jsonl\")", "\n", "#scores2,cluster,labels = calScores(args, model, tokenizer, \"../dataset/test_align3.jsonl\")", "\n", "    ", "scores1", "=", "np", ".", "load", "(", "\"scorestest_align1_decl.npy\"", ")", "\n", "scores2", "=", "np", ".", "load", "(", "\"scorestest_align2_decl.npy\"", ")", "\n", "scores3", "=", "np", ".", "load", "(", "\"scorestest_align3_decl.npy\"", ")", "\n", "scores", ",", "cluster", ",", "labels", "=", "calScores", "(", "args", ",", "model", ",", "tokenizer", ",", "\"../dataset/test.jsonl\"", ")", "\n", "\n", "scores", "=", "scores", "+", "(", "scores1", "+", "scores2", "+", "scores3", ")", "/", "3", "\n", "\n", "sort_ids", "=", "np", ".", "argsort", "(", "scores", ",", "axis", "=", "-", "1", ",", "kind", "=", "'quicksort'", ",", "order", "=", "None", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "eval_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "\"../dataset/test.jsonl\"", ")", "\n", "\n", "indexs", "=", "[", "]", "\n", "for", "example", "in", "eval_dataset", ".", "examples", ":", "\n", "        ", "indexs", ".", "append", "(", "example", ".", "index", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"predictions.jsonl\"", ")", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "cnt", "=", "0", "\n", "for", "index", ",", "sort_id", "in", "zip", "(", "indexs", ",", "sort_ids", ")", ":", "\n", "            ", "js", "=", "{", "}", "\n", "js", "[", "'index'", "]", "=", "index", "\n", "js", "[", "'answers'", "]", "=", "[", "]", "\n", "for", "idx", "in", "sort_id", "[", ":", "cluster", "[", "labels", "[", "cnt", "]", "]", "-", "1", "]", ":", "\n", "                ", "js", "[", "'answers'", "]", ".", "append", "(", "indexs", "[", "int", "(", "idx", ")", "]", ")", "\n", "", "f", ".", "write", "(", "json", ".", "dumps", "(", "js", ")", "+", "'\\n'", ")", "\n", "cnt", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.bagging.main": [[444, 654], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "bagging.set_seed", "os.path.join", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "min", "model.Model", "logger.info", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "os.path.exists", "os.listdir", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "logger.info", "model_class.from_pretrained", "model_class", "torch.distributed.barrier", "bagging.TextDataset", "bagging.train", "os.path.join", "model_class.load_state_dict", "model_class.to", "bagging.evaluate", "logger.info", "sorted", "os.path.join", "model_class.load_state_dict", "model_class.to", "bagging.test", "open", "torch.distributed.barrier", "torch.distributed.barrier", "torch.load", "evaluate.keys", "logger.info", "torch.load", "int", "open", "int", "bool", "str", "torch.cuda.is_available", "[].strip", "[].strip", "round", "idxf.readlines", "stepf.readlines"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.set_seed", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate", "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.test"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input training data file (a text file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--eval_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "\"bert\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model architecture to be fine-tuned.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--mlm\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Train with masked-language modeling loss instead of language modeling.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mlm_probability\"", ",", "type", "=", "float", ",", "default", "=", "0.15", ",", "\n", "help", "=", "\"Ratio of tokens to mask for masked language modeling loss\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional directory to store the pre-trained models downloaded from s3 (instread of the default one)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--block_size\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional input sequence length after tokenization.\"", "\n", "\"The training dataset will be truncated in block of this size for training.\"", "\n", "\"Default to the model max input length for single sentence inputs (take into account special tokens).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Run evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_total_limit'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'Limit the total amount of checkpoints, delete the older checkpoints in the output_dir, does not delete by default'", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "\n", "# Setup distant debugging if needed", "\n", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "#args.n_gpu = 8", "\n", "#os.environ['CUDA_VISIBLE_DEVICES'] = \"8,9,10,11,12,13,14,15\"", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "args", ".", "per_gpu_train_batch_size", "=", "args", ".", "train_batch_size", "//", "args", ".", "n_gpu", "\n", "args", ".", "per_gpu_eval_batch_size", "=", "args", ".", "eval_batch_size", "//", "args", ".", "n_gpu", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s -   %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "args", ".", "start_epoch", "=", "0", "\n", "args", ".", "start_step", "=", "0", "\n", "checkpoint_last", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-last'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "checkpoint_last", ")", "and", "os", ".", "listdir", "(", "checkpoint_last", ")", ":", "\n", "        ", "args", ".", "model_name_or_path", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'pytorch_model.bin'", ")", "\n", "args", ".", "config_name", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'config.json'", ")", "\n", "idx_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'idx_file.txt'", ")", "\n", "with", "open", "(", "idx_file", ",", "encoding", "=", "'utf-8'", ")", "as", "idxf", ":", "\n", "            ", "args", ".", "start_epoch", "=", "int", "(", "idxf", ".", "readlines", "(", ")", "[", "0", "]", ".", "strip", "(", ")", ")", "+", "1", "\n", "\n", "", "step_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'step_file.txt'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "step_file", ")", ":", "\n", "            ", "with", "open", "(", "step_file", ",", "encoding", "=", "'utf-8'", ")", "as", "stepf", ":", "\n", "                ", "args", ".", "start_step", "=", "int", "(", "stepf", ".", "readlines", "(", ")", "[", "0", "]", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"reload model from {}, resume from {} epoch\"", ".", "format", "(", "checkpoint_last", ",", "args", ".", "start_epoch", ")", ")", "\n", "\n", "", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "config", ".", "num_labels", "=", "1", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "if", "args", ".", "block_size", "<=", "0", ":", "\n", "        ", "args", ".", "block_size", "=", "tokenizer", ".", "max_len_single_sentence", "# Our input block size will be the max possible for the model", "\n", "", "args", ".", "block_size", "=", "min", "(", "args", ".", "block_size", ",", "tokenizer", ".", "max_len_single_sentence", ")", "\n", "if", "args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "model_class", "(", "config", ")", "\n", "\n", "", "model", "=", "Model", "(", "model", ",", "config", ",", "tokenizer", ",", "args", ")", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# End of barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "train_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "train_data_file", ")", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "\n", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-map/modelroot_10.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "round", "(", "result", "[", "key", "]", ",", "4", ")", ")", ")", "\n", "\n", "", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-map/modelroot_10.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "test", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.pacing_functions.linear": [[3, 5], ["None"], "function", ["None"], ["def", "linear", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "x", "*", "(", "(", "1", "-", "c0", ")", "/", "t", ")", ")", "+", "c0", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.pacing_functions.root_2": [[6, 8], ["None"], "function", ["None"], ["", "def", "root_2", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "(", "x", "*", "(", "(", "1", "-", "(", "c0", "**", "2.0", ")", ")", "/", "t", ")", ")", "+", "(", "c0", "**", "2.0", ")", ")", "**", "(", "1.", "/", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.pacing_functions.root_5": [[9, 11], ["None"], "function", ["None"], ["", "def", "root_5", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "(", "x", "*", "(", "(", "1", "-", "(", "c0", "**", "5.0", ")", ")", "/", "t", ")", ")", "+", "(", "c0", "**", "5.0", ")", ")", "**", "(", "1.", "/", "5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.pacing_functions.root_10": [[12, 14], ["None"], "function", ["None"], ["", "def", "root_10", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "(", "x", "*", "(", "(", "1", "-", "(", "c0", "**", "10.0", ")", ")", "/", "t", ")", ")", "+", "(", "c0", "**", "10.0", ")", ")", "**", "(", "1.", "/", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.pacing_functions.root_20": [[15, 17], ["None"], "function", ["None"], ["", "def", "root_20", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "(", "x", "*", "(", "(", "1", "-", "(", "c0", "**", "20.0", ")", ")", "/", "t", ")", ")", "+", "(", "c0", "**", "20.0", ")", ")", "**", "(", "1.", "/", "20", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.pacing_functions.root_50": [[18, 20], ["None"], "function", ["None"], ["", "def", "root_50", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "(", "x", "*", "(", "(", "1", "-", "(", "c0", "**", "50.0", ")", ")", "/", "t", ")", ")", "+", "(", "c0", "**", "50.0", ")", ")", "**", "(", "1.", "/", "50", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.pacing_functions.geom_progression": [[21, 23], ["math.log", "math.log", "math.log"], "function", ["None"], ["", "def", "geom_progression", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "2.0", "**", "(", "(", "x", "*", "(", "(", "math", ".", "log", "(", "1", ",", "2.0", ")", "-", "math", ".", "log", "(", "c0", ",", "2.0", ")", ")", "/", "t", ")", ")", "+", "math", ".", "log", "(", "c0", ",", "2.0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.pacing_functions.quadratic": [[24, 26], ["None"], "function", ["None"], ["", "def", "quadratic", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "x", "*", "(", "(", "1", "-", "c0", "**", "1.54", ")", "/", "t", ")", ")", "**", "2", "+", "c0", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.pacing_functions.cubic": [[27, 29], ["None"], "function", ["None"], ["", "def", "cubic", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "x", "*", "(", "(", "1", "-", "c0", "**", "1.87", ")", "/", "t", ")", ")", "**", "3", "+", "c0", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.pacing_functions.step": [[30, 37], ["None"], "function", ["None"], ["", "def", "step", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "if", "x", "<=", "t", "*", "0.33", ":", "\n", "\t\t", "return", "0.33", "\n", "", "elif", "x", ">", "t", "*", "0.33", "and", "x", "<=", "t", "*", "0.66", ":", "\n", "\t\t", "return", "0.66", "\n", "", "else", ":", "\n", "\t\t", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.pacing_functions.standard_training": [[38, 40], ["None"], "function", ["None"], ["", "", "def", "standard_training", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.model.TripletLoss.__init__": [[24, 28], ["torch.Module.__init__", "torch.MarginRankingLoss", "torch.MarginRankingLoss", "torch.MarginRankingLoss", "torch.MarginRankingLoss"], "methods", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.TextDataset.__init__"], ["def", "__init__", "(", "self", ",", "margin", "=", "0.3", ")", ":", "\n", "        ", "super", "(", "TripletLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "ranking_loss", "=", "nn", ".", "MarginRankingLoss", "(", "margin", "=", "margin", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.model.TripletLoss.forward": [[29, 56], ["inputs.size", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "torch.pow().sum().expand", "dist.clamp().sqrt.clamp().sqrt.addmm_", "dist.clamp().sqrt.clamp().sqrt.clamp().sqrt", "torch.Tensor.expand().eq", "torch.Tensor.expand().eq", "torch.Tensor.expand().eq", "torch.Tensor.expand().eq", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "model.TripletLoss.ranking_loss", "dist.clamp().sqrt.clamp().sqrt.t", "inputs.t", "torch.Tensor.expand().t", "torch.Tensor.expand().t", "torch.Tensor.expand().t", "torch.Tensor.expand().t", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "dist.clamp().sqrt.clamp().sqrt.clamp", "torch.Tensor.expand", "torch.Tensor.expand", "torch.Tensor.expand", "torch.Tensor.expand", "[].max().unsqueeze", "[].min().unsqueeze", "torch.Tensor.expand", "torch.Tensor.expand", "torch.Tensor.expand", "torch.Tensor.expand", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "[].max", "[].min"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            inputs (torch.Tensor): feature matrix with shape (batch_size, feat_dim).\n            targets (torch.LongTensor): ground truth labels with shape (num_classes).\n        \"\"\"", "\n", "n", "=", "inputs", ".", "size", "(", "0", ")", "\n", "targets", "=", "torch", ".", "Tensor", "(", "targets", ")", "\n", "\n", "# Compute pairwise distance, replace by the official when merged", "\n", "dist", "=", "torch", ".", "pow", "(", "inputs", ",", "2", ")", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ".", "expand", "(", "n", ",", "n", ")", "\n", "dist", "=", "dist", "+", "dist", ".", "t", "(", ")", "\n", "dist", ".", "addmm_", "(", "1", ",", "-", "2", ",", "inputs", ",", "inputs", ".", "t", "(", ")", ")", "\n", "dist", "=", "dist", ".", "clamp", "(", "min", "=", "1e-12", ")", ".", "sqrt", "(", ")", "# for numerical stability", "\n", "\n", "# For each anchor, find the hardest positive and negative", "\n", "mask", "=", "targets", ".", "expand", "(", "n", ",", "n", ")", ".", "eq", "(", "targets", ".", "expand", "(", "n", ",", "n", ")", ".", "t", "(", ")", ")", "\n", "dist_ap", ",", "dist_an", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "dist_ap", ".", "append", "(", "dist", "[", "i", "]", "[", "mask", "[", "i", "]", "]", ".", "max", "(", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "dist_an", ".", "append", "(", "dist", "[", "i", "]", "[", "mask", "[", "i", "]", "==", "0", "]", ".", "min", "(", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "dist_ap", "=", "torch", ".", "cat", "(", "dist_ap", ")", "\n", "dist_an", "=", "torch", ".", "cat", "(", "dist_an", ")", "\n", "\n", "# Compute ranking hinge loss", "\n", "y", "=", "torch", ".", "ones_like", "(", "dist_an", ")", "\n", "return", "self", ".", "ranking_loss", "(", "dist_an", ",", "dist_ap", ",", "y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.model.Model.__init__": [[31, 38], ["torch.Module.__init__", "model.RobertaClassificationHead"], "methods", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.TextDataset.__init__"], ["\n", "n", "=", "inputs", ".", "size", "(", "0", ")", "\n", "targets", "=", "torch", ".", "Tensor", "(", "targets", ")", "\n", "\n", "# Compute pairwise distance, replace by the official when merged", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.model.Model.forward": [[40, 51], ["input_ids.view.view.view", "model.Model.classifier", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "model.Model.encoder", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "input_ids.view.view.ne"], "methods", ["None"], ["dist", "=", "dist", "+", "dist", ".", "t", "(", ")", "\n", "dist", ".", "addmm_", "(", "1", ",", "-", "2", ",", "inputs", ",", "inputs", ".", "t", "(", ")", ")", "\n", "dist", "=", "dist", ".", "clamp", "(", "min", "=", "1e-12", ")", ".", "sqrt", "(", ")", "# for numerical stability", "\n", "\n", "# For each anchor, find the hardest positive and negative", "\n", "mask", "=", "targets", ".", "expand", "(", "n", ",", "n", ")", ".", "eq", "(", "targets", ".", "expand", "(", "n", ",", "n", ")", ".", "t", "(", ")", ")", "\n", "dist_ap", ",", "dist_an", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "dist_ap", ".", "append", "(", "dist", "[", "i", "]", "[", "mask", "[", "i", "]", "]", ".", "max", "(", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "dist_an", ".", "append", "(", "dist", "[", "i", "]", "[", "mask", "[", "i", "]", "==", "0", "]", ".", "min", "(", ")", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "dist_ap", "=", "torch", ".", "cat", "(", "dist_ap", ")", "\n", "dist_an", "=", "torch", ".", "cat", "(", "dist_an", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_class_curri.InputFeatures.__init__": [[71, 82], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "input_tokens", ",", "\n", "input_ids", ",", "\n", "index", ",", "\n", "label", ",", "\n", "\n", ")", ":", "\n", "        ", "self", ".", "input_tokens", "=", "input_tokens", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_class_curri.TextDataset.__init__": [[97, 125], ["open", "run_class_curri.TextDataset.examples.append", "run_class_curri.TextDataset.label_examples[].append", "line.strip.strip.strip", "json.loads", "data.append", "run_class_curri.convert_examples_to_features"], "methods", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.convert_examples_to_features"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ",", "count_index", ",", "file_path", "=", "None", ")", ":", "\n", "        ", "self", ".", "examples", "=", "[", "]", "\n", "data", "=", "[", "]", "\n", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "if", "count_index", "!=", "-", "1", ":", "\n", "                    ", "js", "[", "'index'", "]", "=", "count_index", "\n", "count_index", "+=", "1", "\n", "", "data", ".", "append", "(", "js", ")", "\n", "", "", "self", ".", "count_index", "=", "count_index", "\n", "for", "js", "in", "data", ":", "\n", "            ", "self", ".", "examples", ".", "append", "(", "convert_examples_to_features", "(", "js", ",", "tokenizer", ",", "args", ")", ")", "\n", "", "'''\n        if 'train' in file_path:\n            for idx, example in enumerate(self.examples[:3]):\n                logger.info(\"*** Example ***\")\n                logger.info(\"idx: {}\".format(idx))\n                logger.info(\"label: {}\".format(example.label))\n                logger.info(\"input_tokens: {}\".format([x.replace('\\u0120', '_') for x in example.input_tokens]))\n                logger.info(\"input_ids: {}\".format(' '.join(map(str, example.input_ids))))\n        '''", "\n", "self", ".", "label_examples", "=", "{", "}", "\n", "for", "e", "in", "self", ".", "examples", ":", "\n", "            ", "if", "e", ".", "label", "not", "in", "self", ".", "label_examples", ":", "\n", "                ", "self", ".", "label_examples", "[", "e", ".", "label", "]", "=", "[", "]", "\n", "", "self", ".", "label_examples", "[", "e", ".", "label", "]", ".", "append", "(", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_class_curri.TextDataset.__len__": [[126, 128], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_class_curri.TextDataset.__getitem__": [[129, 144], ["list", "list.remove", "random.sample", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "random.sample", "random.sample"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "label", "=", "self", ".", "examples", "[", "i", "]", ".", "label", "\n", "index", "=", "self", ".", "examples", "[", "i", "]", ".", "index", "\n", "labels", "=", "list", "(", "self", ".", "label_examples", ")", "\n", "labels", ".", "remove", "(", "label", ")", "\n", "while", "True", ":", "\n", "            ", "shuffle_example", "=", "random", ".", "sample", "(", "self", ".", "label_examples", "[", "label", "]", ",", "1", ")", "[", "0", "]", "\n", "if", "shuffle_example", ".", "index", "!=", "index", ":", "\n", "                ", "p_example", "=", "shuffle_example", "# different example with same label", "\n", "break", "\n", "", "", "n_example", "=", "random", ".", "sample", "(", "self", ".", "label_examples", "[", "random", ".", "sample", "(", "labels", ",", "1", ")", "[", "0", "]", "]", ",", "1", ")", "[", "\n", "0", "]", "# label has removed, n_example with different label", "\n", "\n", "return", "(", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "i", "]", ".", "input_ids", ")", ",", "torch", ".", "tensor", "(", "p_example", ".", "input_ids", ")", ",", "\n", "torch", ".", "tensor", "(", "n_example", ".", "input_ids", ")", ",", "torch", ".", "tensor", "(", "label", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_class_curri.convert_examples_to_features": [[84, 93], ["tokenizer.convert_tokens_to_ids", "run_class_curri.InputFeatures", "js[].split", "tokenizer.tokenize", "len", "int"], "function", ["None"], ["", "", "def", "convert_examples_to_features", "(", "js", ",", "tokenizer", ",", "args", ")", ":", "\n", "# source", "\n", "    ", "code", "=", "' '", ".", "join", "(", "js", "[", "'code'", "]", ".", "split", "(", ")", ")", "\n", "code_tokens", "=", "tokenizer", ".", "tokenize", "(", "code", ")", "[", ":", "args", ".", "block_size", "-", "2", "]", "\n", "source_tokens", "=", "[", "tokenizer", ".", "cls_token", "]", "+", "code_tokens", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "source_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "source_tokens", ")", "\n", "padding_length", "=", "args", ".", "block_size", "-", "len", "(", "source_ids", ")", "\n", "source_ids", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n", "return", "InputFeatures", "(", "source_tokens", ",", "source_ids", ",", "js", "[", "'index'", "]", ",", "int", "(", "js", "[", "'label'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_class_curri.set_seed": [[146, 153], ["random.seed", "str", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["", "", "def", "set_seed", "(", "seed", "=", "42", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "'PYHTONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_class_curri.train": [[155, 361], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "len", "len", "torch.nn.parallel.DistributedDataParallel.to", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.path.exists", "torch.nn.parallel.DistributedDataParallel.zero_grad", "range", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "transformers.get_linear_schedule_with_warmup.load_state_dict", "transformers.AdamW.load_state_dict", "int", "len", "len", "transformers.get_linear_schedule_with_warmup", "enumerate", "int", "len", "torch.load", "torch.load", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "loss.mean.item", "round", "ImportError", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "logger.info", "transformers.AdamW.step", "transformers.AdamW.zero_grad", "transformers.get_linear_schedule_with_warmup.step", "min", "int", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "int", "int", "print", "torch.utils.data.DataLoader", "any", "run_class_curri.evaluate", "evaluate.items", "logger.info", "logger.info", "logger.info", "os.path.join", "os.path.join", "torch.save", "logger.info", "print", "torch.utils.data.DataLoader", "print", "torch.utils.data.DataLoader", "len", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "logger.info", "round", "os.path.exists", "os.makedirs", "hasattr", "model_to_save.state_dict", "len", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "len", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "round"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate"], ["", "def", "train", "(", "args", ",", "ordered_train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "\n", "c0", "=", "0.33", "\n", "\n", "train_data", "=", "ordered_train_dataset", "[", "0", ":", "int", "(", "c0", "*", "len", "(", "ordered_train_dataset", ")", ")", "]", "\n", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "#train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)", "\n", "\n", "#train_dataloader = DataLoader(train_dataset, sampler=train_sampler,", "\n", "#                              batch_size=args.train_batch_size, num_workers=4, pin_memory=True)", "\n", "s_for_count_only", "=", "RandomSampler", "(", "ordered_train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "\n", "ordered_train_dataset", ")", "\n", "t_for_count_only", "=", "DataLoader", "(", "ordered_train_dataset", ",", "sampler", "=", "s_for_count_only", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "args", ".", "max_steps", "=", "args", ".", "epoch", "*", "len", "(", "t_for_count_only", ")", "/", "2", "\n", "args", ".", "save_steps", "=", "len", "(", "train_dataloader", ")", "\n", "args", ".", "warmup_steps", "=", "len", "(", "t_for_count_only", ")", "\n", "args", ".", "logging_steps", "=", "len", "(", "train_dataloader", ")", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "epoch", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "max_steps", "*", "0.1", ",", "\n", "num_training_steps", "=", "args", ".", "max_steps", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "\n", "", "checkpoint_last", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-last'", ")", "\n", "scheduler_last", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'scheduler.pt'", ")", "\n", "optimizer_last", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'optimizer.pt'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "scheduler_last", ")", ":", "\n", "        ", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "scheduler_last", ")", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "optimizer_last", ")", ":", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "optimizer_last", ")", ")", "\n", "# Train!", "\n", "", "'''\n    logger.info(\"***** Running training *****\")\n    logger.info(\"  Num examples = %d\", len(t_for_count_only))\n    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n    logger.info(\"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n                args.train_batch_size * args.gradient_accumulation_steps * (\n                    torch.distributed.get_world_size() if args.local_rank != -1 else 1))\n    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n    logger.info(\"  Total optimization steps = %d\", args.max_steps)\n    '''", "\n", "global_step", "=", "args", ".", "start_step", "\n", "all_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", ",", "avg_loss", ",", "tr_nb", ",", "tr_num", ",", "train_loss", "=", "0.0", ",", "0.0", ",", "0.0", ",", "0", ",", "0", ",", "0", "\n", "best_acc", "=", "0.0", "\n", "# model.resize_token_embeddings(len(tokenizer))", "\n", "model", ".", "zero_grad", "(", ")", "\n", "now_percent", "=", "0", "\n", "for", "idx", "in", "range", "(", "args", ".", "start_epoch", ",", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "        ", "tr_num", "=", "0", "\n", "train_loss", "=", "0", "\n", "\n", "# reset about dataloader", "\n", "args", ".", "save_steps", "=", "len", "(", "train_dataloader", ")", "\n", "args", ".", "logging_steps", "=", "len", "(", "train_dataloader", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "max_steps", "*", "0.1", ",", "\n", "num_training_steps", "=", "args", ".", "max_steps", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "p_inputs", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "n_inputs", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "#print(\"inputs = \",inputs)", "\n", "model", ".", "train", "(", ")", "\n", "loss", ",", "vec", "=", "model", "(", "inputs", ",", "p_inputs", ",", "n_inputs", ",", "labels", ")", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "tr_num", "+=", "1", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "avg_loss", "=", "round", "(", "train_loss", "/", "tr_num", ",", "5", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"epoch {} step {} loss {}\"", ".", "format", "(", "idx", ",", "step", "+", "1", ",", "avg_loss", ")", ")", "\n", "# bar.set_description(\"epoch {} loss {}\".format(idx,avg_loss))", "\n", "\n", "", "all_step", "+=", "1", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "all_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "eval_when_training", "=", "True", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "round", "(", "value", ",", "4", ")", ")", "\n", "# Save model checkpoint", "\n", "", "tr_num", "=", "0", "\n", "train_loss", "=", "0", "\n", "\n", "", "if", "results", "[", "'eval_map'", "]", ">", "best_acc", ":", "\n", "                        ", "best_acc", "=", "results", "[", "'eval_map'", "]", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "logger", ".", "info", "(", "\"  Best map:%s\"", ",", "round", "(", "best_acc", ",", "4", ")", ")", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "\n", "checkpoint_prefix", "=", "'checkpoint-best-map'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                            ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'{}'", ".", "format", "(", "'model'", "+", "args", ".", "pacing_function", "+", "'.bin'", ")", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_dir", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "", "", "", "", "reduce", "=", "0", "\n", "if", "args", ".", "pacing_function", "!=", "\"\"", ":", "\n", "\n", "            ", "if", "args", ".", "pacing_function", "==", "\"reduce\"", ":", "\n", "                ", "if", "reduce", "==", "0", ":", "\n", "                    ", "if", "c0", "==", "0.64", ":", "\n", "                        ", "c0", "=", "0.80", "\n", "", "elif", "c0", "==", "0.80", ":", "\n", "                        ", "c0", "=", "1", "\n", "reduce", "=", "1", "\n", "\n", "", "percent", "=", "int", "(", "c0", "*", "len", "(", "ordered_train_dataset", ")", ")", "\n", "if", "percent", "!=", "now_percent", ":", "\n", "                        ", "now_percent", "=", "percent", "\n", "print", "(", "c0", ")", "\n", "train_data", "=", "ordered_train_dataset", "[", "0", ":", "now_percent", "]", "\n", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "\n", "train_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "train_batch_size", ",", "\n", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n", "", "", "else", ":", "\n", "                    ", "if", "c0", "==", "0.64", ":", "\n", "                        ", "c0", "=", "1.0", "\n", "", "elif", "c0", "==", "0.80", ":", "\n", "                        ", "c0", "=", "0.64", "\n", "", "else", ":", "\n", "                        ", "c0", "=", "0.80", "\n", "\n", "", "percent", "=", "int", "(", "(", "1", "-", "c0", ")", "*", "len", "(", "ordered_train_dataset", ")", ")", "\n", "if", "percent", "!=", "now_percent", ":", "\n", "                        ", "now_percent", "=", "percent", "\n", "print", "(", "c0", ")", "\n", "train_data", "=", "ordered_train_dataset", "[", "now_percent", ":", "]", "\n", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "\n", "train_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "train_batch_size", ",", "\n", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n", "", "", "", "else", ":", "\n", "# percentage_curriculum_iter = 0.90", "\n", "# curriculum_iterations = args.max_steps * percentage_curriculum_iter", "\n", "                ", "curriculum_iterations", "=", "args", ".", "max_steps", "\n", "new_data_fraction", "=", "min", "(", "1", ",", "\n", "PACING_FUNCTIONS", "[", "args", ".", "pacing_function", "]", "(", "all_step", ",", "curriculum_iterations", ",", "c0", ")", ")", "\n", "percent", "=", "int", "(", "new_data_fraction", "*", "len", "(", "ordered_train_dataset", ")", ")", "\n", "if", "percent", "!=", "now_percent", ":", "\n", "                    ", "now_percent", "=", "percent", "\n", "print", "(", "new_data_fraction", ")", "\n", "train_data", "=", "ordered_train_dataset", "[", "0", ":", "now_percent", "]", "\n", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "\n", "train_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "\n", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_class_curri.evaluate": [[365, 436], ["torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "numpy.concatenate", "numpy.concatenate", "torch.tensor", "numpy.matmul", "range", "range", "run_class_curri.TextDataset", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "numpy.argsort", "int", "range", "MAP.append", "float", "float", "os.path.exists", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "np.concatenate.append", "np.concatenate.append", "int", "numpy.mean", "vec.cpu().numpy", "int.cpu().numpy", "int", "int", "lm_loss.mean", "int", "vec.cpu", "int.cpu"], "function", ["None"], ["def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "eval_when_training", "=", "False", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "global", "eval_dataset", "\n", "if", "eval_dataset", "is", "None", ":", "\n", "        ", "eval_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "-", "1", ",", "args", ".", "eval_data_file", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "num_workers", "=", "4", ",", "\n", "pin_memory", "=", "True", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "eval_when_training", "is", "False", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "vecs", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "p_inputs", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "n_inputs", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "label", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "lm_loss", ",", "vec", "=", "model", "(", "inputs", ",", "p_inputs", ",", "n_inputs", ",", "label", ")", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "vecs", ".", "append", "(", "vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "labels", ".", "append", "(", "label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "", "vecs", "=", "np", ".", "concatenate", "(", "vecs", ",", "0", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "0", ")", "\n", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "tensor", "(", "eval_loss", ")", "\n", "# np.save(\"vecs\" + str(args.eval_data_file)[-7] + \".npy\", vecs)", "\n", "# np.save(\"labels\" + str(args.eval_data_file)[-7] + \".npy\", labels)", "\n", "scores", "=", "np", ".", "matmul", "(", "vecs", ",", "vecs", ".", "T", ")", "\n", "\n", "dic", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "scores", "[", "i", ",", "i", "]", "=", "-", "1000000", "\n", "if", "int", "(", "labels", "[", "i", "]", ")", "not", "in", "dic", ":", "\n", "            ", "dic", "[", "int", "(", "labels", "[", "i", "]", ")", "]", "=", "-", "1", "\n", "", "dic", "[", "int", "(", "labels", "[", "i", "]", ")", "]", "+=", "1", "\n", "", "sort_ids", "=", "np", ".", "argsort", "(", "scores", ",", "axis", "=", "-", "1", ",", "kind", "=", "'quicksort'", ",", "order", "=", "None", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "MAP", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "cont", "=", "0", "\n", "label", "=", "int", "(", "labels", "[", "i", "]", ")", "\n", "for", "j", "in", "range", "(", "dic", "[", "label", "]", ")", ":", "\n", "            ", "index", "=", "sort_ids", "[", "i", ",", "j", "]", "\n", "if", "int", "(", "labels", "[", "index", "]", ")", "==", "label", ":", "\n", "                ", "cont", "+=", "1", "\n", "", "", "MAP", ".", "append", "(", "cont", "/", "dic", "[", "label", "]", ")", "\n", "\n", "", "result", "=", "{", "\n", "\"eval_loss\"", ":", "float", "(", "perplexity", ")", ",", "\n", "\"eval_map\"", ":", "float", "(", "np", ".", "mean", "(", "MAP", ")", ")", "\n", "}", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_class_curri.test": [[438, 504], ["run_class_curri.TextDataset", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "numpy.concatenate", "numpy.concatenate", "range", "torch.tensor", "numpy.matmul", "range", "args.test_data_file.rfind", "numpy.save", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "len", "numpy.argsort", "indexs.append", "open", "zip", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "np.concatenate.append", "np.concatenate.append", "str", "os.path.join", "f.write", "vec.cpu().numpy", "batch[].to.cpu().numpy", "js[].append", "lm_loss.mean", "json.dumps", "vec.cpu", "batch[].to.cpu", "int"], "function", ["None"], ["", "def", "test", "(", "args", ",", "model", ",", "tokenizer", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "-", "1", ",", "args", ".", "test_data_file", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running Test *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "vecs", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "p_inputs", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "n_inputs", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "label", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "lm_loss", ",", "vec", "=", "model", "(", "inputs", ",", "p_inputs", ",", "n_inputs", ",", "label", ")", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "vecs", ".", "append", "(", "vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "labels", ".", "append", "(", "label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "", "vecs", "=", "np", ".", "concatenate", "(", "vecs", ",", "0", ")", "\n", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "0", ")", "\n", "cluster", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "        ", "label", "=", "labels", "[", "i", "]", "\n", "if", "label", "not", "in", "cluster", ":", "\n", "            ", "cluster", "[", "label", "]", "=", "0", "\n", "", "cluster", "[", "label", "]", "+=", "1", "\n", "\n", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "tensor", "(", "eval_loss", ")", "\n", "scores", "=", "np", ".", "matmul", "(", "vecs", ",", "vecs", ".", "T", ")", "\n", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "scores", "[", "i", ",", "i", "]", "=", "-", "1000000", "\n", "", "loc", "=", "args", ".", "test_data_file", ".", "rfind", "(", "'/'", ")", "\n", "fname", "=", "\"scores\"", "+", "str", "(", "args", ".", "test_data_file", "[", "loc", "+", "1", ":", "-", "6", "]", ")", "+", "\".npy\"", "\n", "np", ".", "save", "(", "fname", ",", "scores", ")", "\n", "sort_ids", "=", "np", ".", "argsort", "(", "scores", ",", "axis", "=", "-", "1", ",", "kind", "=", "'quicksort'", ",", "order", "=", "None", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "indexs", "=", "[", "]", "\n", "for", "example", "in", "eval_dataset", ".", "examples", ":", "\n", "        ", "indexs", ".", "append", "(", "example", ".", "index", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"predictions.jsonl\"", ")", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "cnt", "=", "0", "\n", "for", "index", ",", "sort_id", "in", "zip", "(", "indexs", ",", "sort_ids", ")", ":", "\n", "            ", "js", "=", "{", "}", "\n", "js", "[", "'index'", "]", "=", "index", "\n", "js", "[", "'answers'", "]", "=", "[", "]", "\n", "for", "idx", "in", "sort_id", "[", ":", "cluster", "[", "labels", "[", "cnt", "]", "]", "-", "1", "]", ":", "\n", "                ", "js", "[", "'answers'", "]", ".", "append", "(", "indexs", "[", "int", "(", "idx", ")", "]", ")", "\n", "", "f", ".", "write", "(", "json", ".", "dumps", "(", "js", ")", "+", "'\\n'", ")", "\n", "cnt", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_class_curri.main": [[506, 732], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_class_curri.set_seed", "os.path.join", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "min", "model.Model", "logger.info", "run_class_curri.TextDataset", "numpy.load", "sorted", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "os.path.exists", "os.listdir", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "logger.info", "model_class.from_pretrained", "model_class", "torch.distributed.barrier", "run_class_curri.train", "os.path.join", "model_class.load_state_dict", "model_class.to", "run_class_curri.evaluate", "logger.info", "sorted", "os.path.join", "model_class.load_state_dict", "model_class.to", "run_class_curri.test", "open", "zip", "torch.distributed.barrier", "torch.distributed.barrier", "torch.load", "evaluate.keys", "logger.info", "torch.load", "int", "open", "int", "bool", "str", "torch.cuda.is_available", "[].strip", "[].strip", "round", "idxf.readlines", "stepf.readlines"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.set_seed", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate", "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.test"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input training data file (a text file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--eval_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "\"bert\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model architecture to be fine-tuned.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--mlm\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Train with masked-language modeling loss instead of language modeling.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mlm_probability\"", ",", "type", "=", "float", ",", "default", "=", "0.15", ",", "\n", "help", "=", "\"Ratio of tokens to mask for masked language modeling loss\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional directory to store the pre-trained models downloaded from s3 (instread of the default one)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--block_size\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional input sequence length after tokenization.\"", "\n", "\"The training dataset will be truncated in block of this size for training.\"", "\n", "\"Default to the model max input length for single sentence inputs (take into account special tokens).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Run evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_total_limit'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'Limit the total amount of checkpoints, delete the older checkpoints in the output_dir, does not delete by default'", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "2021", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--pacing_function\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Use one of the predefined pacing functions instead of shards (requires a values curriculum_file)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--class_score\"", ",", "type", "=", "str", ",", "default", "=", "'class_score.npy'", ",", "help", "=", "\"For curriculum learning\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "#args.n_gpu = 8 ", "\n", "#os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3,4,5,6,7'", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "args", ".", "per_gpu_train_batch_size", "=", "args", ".", "train_batch_size", "//", "args", ".", "n_gpu", "\n", "args", ".", "per_gpu_eval_batch_size", "=", "args", ".", "eval_batch_size", "//", "args", ".", "n_gpu", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s -   %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "args", ".", "start_epoch", "=", "0", "\n", "args", ".", "start_step", "=", "0", "\n", "checkpoint_last", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-last'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "checkpoint_last", ")", "and", "os", ".", "listdir", "(", "checkpoint_last", ")", ":", "\n", "        ", "args", ".", "model_name_or_path", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'pytorch_model.bin'", ")", "\n", "args", ".", "config_name", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'config.json'", ")", "\n", "idx_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'idx_file.txt'", ")", "\n", "with", "open", "(", "idx_file", ",", "encoding", "=", "'utf-8'", ")", "as", "idxf", ":", "\n", "            ", "args", ".", "start_epoch", "=", "int", "(", "idxf", ".", "readlines", "(", ")", "[", "0", "]", ".", "strip", "(", ")", ")", "+", "1", "\n", "\n", "", "step_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'step_file.txt'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "step_file", ")", ":", "\n", "            ", "with", "open", "(", "step_file", ",", "encoding", "=", "'utf-8'", ")", "as", "stepf", ":", "\n", "                ", "args", ".", "start_step", "=", "int", "(", "stepf", ".", "readlines", "(", ")", "[", "0", "]", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"reload model from {}, resume from {} epoch\"", ".", "format", "(", "checkpoint_last", ",", "args", ".", "start_epoch", ")", ")", "\n", "\n", "\n", "", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "config", ".", "num_labels", "=", "1", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "if", "args", ".", "block_size", "<=", "0", ":", "\n", "        ", "args", ".", "block_size", "=", "tokenizer", ".", "max_len_single_sentence", "# Our input block size will be the max possible for the model", "\n", "", "args", ".", "block_size", "=", "min", "(", "args", ".", "block_size", ",", "tokenizer", ".", "max_len_single_sentence", ")", "\n", "if", "args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "model_class", "(", "config", ")", "\n", "\n", "", "model", "=", "Model", "(", "model", ",", "config", ",", "tokenizer", ",", "args", ")", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# End of barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Train dataset", "\n", "file_path", "=", "args", ".", "train_data_file", "\n", "\n", "\n", "count_index", "=", "0", "\n", "\n", "curri_dataset0", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "count_index", ",", "file_path", ")", "\n", "\n", "\n", "score_path0", "=", "args", ".", "class_score", "\n", "\n", "score", "=", "np", ".", "load", "(", "score_path0", ")", "\n", "\n", "c0", "=", "[", "v", "for", "v", "in", "zip", "(", "score", ",", "curri_dataset0", ")", "]", "\n", "\n", "#train_data = sorted(whole_data, key=lambda x: x[0], reverse=True)", "\n", "train_data", "=", "sorted", "(", "c0", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "ordered_train_dataset", "=", "[", "v", "[", "1", "]", "for", "v", "in", "train_data", "]", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "#train_dataset = TextDataset(tokenizer, args, args.train_data_file)", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "train", "(", "args", ",", "ordered_train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-map/model'", "+", "args", ".", "pacing_function", "+", "'.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "round", "(", "result", "[", "key", "]", ",", "4", ")", ")", ")", "\n", "\n", "", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-map/model'", "+", "args", ".", "pacing_function", "+", "'.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "test", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run.InputFeatures.__init__": [[89, 102], ["None"], "methods", ["None"], ["\n", "", "class", "TextDataset", "(", "Dataset", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ",", "file_path", "=", "None", ")", ":", "\n", "        ", "self", ".", "examples", "=", "[", "]", "\n", "data", "=", "[", "]", "\n", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "data", ".", "append", "(", "js", ")", "\n", "", "", "for", "js", "in", "data", ":", "\n", "            ", "self", ".", "examples", ".", "append", "(", "convert_examples_to_features", "(", "js", ",", "tokenizer", ",", "args", ")", ")", "\n", "", "self", ".", "label_examples", "=", "{", "}", "\n", "for", "e", "in", "self", ".", "examples", ":", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run.TextDataset.__init__": [[123, 160], ["logger.info", "open", "pool.map", "[].split", "open", "open", "random.sample", "tqdm.tqdm.tqdm", "enumerate", "line.strip.strip.strip", "json.loads", "line.strip.strip.strip", "line.strip.strip.split", "random.sample.append", "int", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "len", "file_path.split", "len", "index_filename.split", "x.replace", "map"], "methods", ["None"], ["torch", ".", "tensor", "(", "n_example", ".", "input_ids", ")", ",", "torch", ".", "tensor", "(", "label", ")", ")", "\n", "\n", "\n", "", "", "def", "set_seed", "(", "seed", "=", "42", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "'PYHTONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "\n", "", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "10", ")", "\n", "args", ".", "max_steps", "=", "args", ".", "epoch", "*", "len", "(", "train_dataloader", ")", "\n", "args", ".", "save_steps", "=", "len", "(", "train_dataloader", ")", "\n", "args", ".", "warmup_steps", "=", "len", "(", "train_dataloader", ")", "\n", "args", ".", "logging_steps", "=", "len", "(", "train_dataloader", ")", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "epoch", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "max_steps", "*", "0.1", ",", "\n", "num_training_steps", "=", "args", ".", "max_steps", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run.TextDataset.__len__": [[163, 165], ["len"], "methods", ["None"], ["            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run.TextDataset.__getitem__": [[166, 169], ["torch.tensor", "torch.tensor"], "methods", ["None"], ["# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run.convert_examples_to_features": [[103, 121], ["tokenizer.convert_tokens_to_ids", "tokenizer.convert_tokens_to_ids", "run.InputFeatures", "len", "len"], "function", ["None"], ["            ", "if", "e", ".", "label", "not", "in", "self", ".", "label_examples", ":", "\n", "                ", "self", ".", "label_examples", "[", "e", ".", "label", "]", "=", "[", "]", "\n", "", "self", ".", "label_examples", "[", "e", ".", "label", "]", ".", "append", "(", "e", ")", "\n", "\n", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "label", "=", "self", ".", "examples", "[", "i", "]", ".", "label", "\n", "index", "=", "self", ".", "examples", "[", "i", "]", ".", "index", "\n", "labels", "=", "list", "(", "self", ".", "label_examples", ")", "\n", "labels", ".", "remove", "(", "label", ")", "\n", "while", "True", ":", "\n", "            ", "shuffle_example", "=", "random", ".", "sample", "(", "self", ".", "label_examples", "[", "label", "]", ",", "1", ")", "[", "0", "]", "\n", "if", "shuffle_example", ".", "index", "!=", "index", ":", "\n", "                ", "p_example", "=", "shuffle_example", "\n", "break", "\n", "", "", "n_example", "=", "random", ".", "sample", "(", "self", ".", "label_examples", "[", "random", ".", "sample", "(", "labels", ",", "1", ")", "[", "0", "]", "]", ",", "1", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run.set_seed": [[175, 182], ["random.seed", "str", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["\n", "", "checkpoint_last", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-last'", ")", "\n", "scheduler_last", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'scheduler.pt'", ")", "\n", "optimizer_last", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'optimizer.pt'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "scheduler_last", ")", ":", "\n", "        ", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "scheduler_last", ")", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "optimizer_last", ")", ":", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "optimizer_last", ")", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run.train": [[183, 318], ["torch.utils.data.DataLoader", "len", "len", "len", "torch.nn.parallel.DistributedDataParallel.to", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.path.exists", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "run.set_seed", "range", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "len", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "transformers.get_linear_schedule_with_warmup.load_state_dict", "transformers.AdamW.load_state_dict", "len", "int", "tqdm.tqdm", "enumerate", "torch.load", "torch.load", "batch[].to", "batch[].to", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "loss.mean.item", "round", "tqdm.tqdm.set_description", "train_iterator.close", "ImportError", "torch.distributed.get_world_size", "len", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "transformers.AdamW.step", "transformers.AdamW.zero_grad", "transformers.get_linear_schedule_with_warmup.step", "round", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "numpy.exp", "any", "run.evaluate", "logger.info", "logger.info", "logger.info", "os.path.join", "os.path.join", "torch.save", "logger.info", "round", "os.path.exists", "os.makedirs", "hasattr", "model_to_save.state_dict"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.set_seed", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate"], ["# Train!", "\n", "", "'''\n    logger.info(\"***** Running training *****\")\n    logger.info(\"  Num examples = %d\", len(train_dataset))\n    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n    logger.info(\"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n                args.train_batch_size * args.gradient_accumulation_steps * (\n                    torch.distributed.get_world_size() if args.local_rank != -1 else 1))\n    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n    logger.info(\"  Total optimization steps = %d\", args.max_steps)\n    '''", "\n", "global_step", "=", "args", ".", "start_step", "\n", "tr_loss", ",", "logging_loss", ",", "avg_loss", ",", "tr_nb", ",", "tr_num", ",", "train_loss", "=", "0.0", ",", "0.0", ",", "0.0", ",", "0", ",", "0", ",", "0", "\n", "best_acc", "=", "0.0", "\n", "# model.resize_token_embeddings(len(tokenizer))", "\n", "model", ".", "zero_grad", "(", ")", "\n", "for", "idx", "in", "range", "(", "args", ".", "start_epoch", ",", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "        ", "'''\n        if idx != args.start_epoch:\n            print(\"idx = \", idx)\n            train_dataset = TextDataset(tokenizer, args, args.train_data_file)\n            train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n\n            train_dataloader = DataLoader(train_dataset, sampler=train_sampler,\n                                          batch_size=args.train_batch_size, num_workers=10)\n        '''", "\n", "bar", "=", "train_dataloader", "\n", "tr_num", "=", "0", "\n", "train_loss", "=", "0", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "bar", ")", ":", "\n", "            ", "inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "p_inputs", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "n_inputs", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "model", ".", "train", "(", ")", "\n", "loss", ",", "vec", "=", "model", "(", "inputs", ",", "p_inputs", ",", "n_inputs", ",", "labels", ")", "\n", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "tr_num", "+=", "1", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "avg_loss", "==", "0", ":", "\n", "                ", "avg_loss", "=", "tr_loss", "\n", "", "avg_loss", "=", "round", "(", "train_loss", "/", "tr_num", ",", "5", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"epoch {} step {} loss {}\"", ".", "format", "(", "idx", ",", "step", "+", "1", ",", "avg_loss", ")", ")", "\n", "#bar.set_description(\"epoch {} loss {}\".format(idx,avg_loss))", "\n", "\n", "\n", "", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "global_step", "+=", "1", "\n", "output_flag", "=", "True", "\n", "avg_loss", "=", "round", "(", "np", ".", "exp", "(", "(", "tr_loss", "-", "logging_loss", ")", "/", "(", "global_step", "-", "tr_nb", ")", ")", ",", "4", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                    ", "logging_loss", "=", "tr_loss", "\n", "tr_nb", "=", "global_step", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "eval_when_training", "=", "True", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "round", "(", "value", ",", "4", ")", ")", "\n", "# Save model checkpoint", "\n", "", "tr_num", "=", "0", "\n", "train_loss", "=", "0", "\n", "\n", "", "if", "results", "[", "'eval_map'", "]", ">", "best_acc", ":", "\n", "                        ", "best_acc", "=", "results", "[", "'eval_map'", "]", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "logger", ".", "info", "(", "\"  Best map:%s\"", ",", "round", "(", "best_acc", ",", "4", ")", ")", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "\n", "checkpoint_prefix", "=", "'checkpoint-best-map'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                            ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'{}'", ".", "format", "(", "'model.bin'", ")", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_dir", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "\n", "", "", "", "", "", "", "eval_dataset", "=", "None", "\n", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "eval_when_training", "=", "False", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "global", "eval_dataset", "\n", "if", "eval_dataset", "is", "None", ":", "\n", "        ", "eval_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "eval_data_file", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "num_workers", "=", "10", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "eval_when_training", "is", "False", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "vecs", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "p_inputs", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "n_inputs", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "label", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "lm_loss", ",", "vec", "=", "model", "(", "inputs", ",", "p_inputs", ",", "n_inputs", ",", "label", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run.evaluate": [[320, 391], ["run.load_and_cache_examples", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "numpy.concatenate", "numpy.concatenate", "range", "recall_score", "precision_score", "f1_score", "logger.info", "sorted", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "batch[].to", "batch[].to", "recall_score", "precision_score", "f1_score", "float", "float", "float", "result.keys", "logger.info", "os.path.exists", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "np.concatenate.append", "np.concatenate.append", "str", "logit.cpu().numpy", "batch[].to.cpu().numpy", "round", "lm_loss.mean", "logit.cpu", "batch[].to.cpu"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.load_and_cache_examples"], ["vecs", ".", "append", "(", "vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "labels", ".", "append", "(", "label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "", "vecs", "=", "np", ".", "concatenate", "(", "vecs", ",", "0", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "0", ")", "\n", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "tensor", "(", "eval_loss", ")", "\n", "\n", "scores", "=", "np", ".", "matmul", "(", "vecs", ",", "vecs", ".", "T", ")", "\n", "dic", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "scores", "[", "i", ",", "i", "]", "=", "-", "1000000", "\n", "if", "int", "(", "labels", "[", "i", "]", ")", "not", "in", "dic", ":", "\n", "            ", "dic", "[", "int", "(", "labels", "[", "i", "]", ")", "]", "=", "-", "1", "\n", "", "dic", "[", "int", "(", "labels", "[", "i", "]", ")", "]", "+=", "1", "\n", "", "sort_ids", "=", "np", ".", "argsort", "(", "scores", ",", "axis", "=", "-", "1", ",", "kind", "=", "'quicksort'", ",", "order", "=", "None", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "MAP", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "cont", "=", "0", "\n", "label", "=", "int", "(", "labels", "[", "i", "]", ")", "\n", "for", "j", "in", "range", "(", "dic", "[", "label", "]", ")", ":", "\n", "            ", "index", "=", "sort_ids", "[", "i", ",", "j", "]", "\n", "if", "int", "(", "labels", "[", "index", "]", ")", "==", "label", ":", "\n", "                ", "cont", "+=", "1", "\n", "", "", "MAP", ".", "append", "(", "cont", "/", "dic", "[", "label", "]", ")", "\n", "\n", "", "result", "=", "{", "\n", "\"eval_loss\"", ":", "float", "(", "perplexity", ")", ",", "\n", "\"eval_map\"", ":", "float", "(", "np", ".", "mean", "(", "MAP", ")", ")", "\n", "}", "\n", "\n", "\n", "return", "result", "\n", "\n", "", "def", "test", "(", "args", ",", "model", ",", "tokenizer", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "test_data_file", ")", "\n", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running Test *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "vecs", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "p_inputs", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "n_inputs", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "label", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "## p,n,label (multi_view) not change", "\n", "## table --> inputs_trans ----> vecs_trans", "\n", "## average", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "lm_loss", ",", "vec", "=", "model", "(", "inputs", ",", "p_inputs", ",", "n_inputs", ",", "label", ")", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "vecs", ".", "append", "(", "vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "labels", ".", "append", "(", "label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run.test": [[392, 433], ["run.load_and_cache_examples", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "numpy.concatenate", "numpy.save", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "batch[].to", "batch[].to", "open", "zip", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "np.concatenate.append", "y_trues.append", "str", "os.path.join", "logit.cpu().numpy", "batch[].to.cpu().numpy", "f.write", "f.write", "lm_loss.mean", "logit.cpu", "batch[].to.cpu"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.load_and_cache_examples"], ["", "nb_eval_steps", "+=", "1", "\n", "", "vecs", "=", "np", ".", "concatenate", "(", "vecs", ",", "0", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "0", ")", "\n", "cluster", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "        ", "label", "=", "labels", "[", "i", "]", "\n", "if", "label", "not", "in", "cluster", ":", "\n", "            ", "cluster", "[", "label", "]", "=", "0", "\n", "", "cluster", "[", "label", "]", "+=", "1", "\n", "\n", "\n", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "tensor", "(", "eval_loss", ")", "\n", "\n", "scores", "=", "np", ".", "matmul", "(", "vecs", ",", "vecs", ".", "T", ")", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "scores", "[", "i", ",", "i", "]", "=", "-", "1000000", "\n", "\n", "", "loc", "=", "args", ".", "test_data_file", ".", "rfind", "(", "'/'", ")", "\n", "fname", "=", "\"scores\"", "+", "str", "(", "args", ".", "test_data_file", "[", "loc", "+", "1", ":", "-", "6", "]", ")", "+", "\".npy\"", "\n", "np", ".", "save", "(", "fname", ",", "scores", ")", "\n", "\n", "sort_ids", "=", "np", ".", "argsort", "(", "scores", ",", "axis", "=", "-", "1", ",", "kind", "=", "'quicksort'", ",", "order", "=", "None", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "indexs", "=", "[", "]", "\n", "for", "example", "in", "eval_dataset", ".", "examples", ":", "\n", "        ", "indexs", ".", "append", "(", "example", ".", "index", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"predictions.jsonl\"", ")", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "cnt", "=", "0", "\n", "for", "index", ",", "sort_id", "in", "zip", "(", "indexs", ",", "sort_ids", ")", ":", "\n", "            ", "js", "=", "{", "}", "\n", "js", "[", "'index'", "]", "=", "index", "\n", "js", "[", "'answers'", "]", "=", "[", "]", "\n", "for", "idx", "in", "sort_id", "[", ":", "cluster", "[", "labels", "[", "cnt", "]", "]", "-", "1", "]", ":", "\n", "                ", "js", "[", "'answers'", "]", ".", "append", "(", "indexs", "[", "int", "(", "idx", ")", "]", ")", "\n", "", "f", ".", "write", "(", "json", ".", "dumps", "(", "js", ")", "+", "'\\n'", ")", "\n", "cnt", "+=", "1", "\n", "\n", "\n", "\n", "", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run.main": [[434, 638], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "multiprocessing.Pool", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run.set_seed", "os.path.join", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "min", "model.Model", "logger.info", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "os.path.exists", "os.listdir", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "logger.info", "model_class.from_pretrained", "model_class", "torch.distributed.barrier", "run.load_and_cache_examples", "run.train", "os.path.join", "model_class.load_state_dict", "model_class.to", "run.evaluate", "os.path.join", "model_class.load_state_dict", "model_class.to", "run.test", "open", "torch.distributed.barrier", "torch.distributed.barrier", "torch.load", "torch.load", "int", "open", "int", "bool", "torch.cuda.is_available", "[].strip", "[].strip", "idxf.readlines", "stepf.readlines"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.set_seed", "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.load_and_cache_examples", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate", "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.test"], ["## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input training data file (a text file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--eval_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "\"bert\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model architecture to be fine-tuned.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--mlm\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Train with masked-language modeling loss instead of language modeling.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mlm_probability\"", ",", "type", "=", "float", ",", "default", "=", "0.15", ",", "\n", "help", "=", "\"Ratio of tokens to mask for masked language modeling loss\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional directory to store the pre-trained models downloaded from s3 (instread of the default one)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--block_size\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional input sequence length after tokenization.\"", "\n", "\"The training dataset will be truncated in block of this size for training.\"", "\n", "\"Default to the model max input length for single sentence inputs (take into account special tokens).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Run evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_total_limit'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'Limit the total amount of checkpoints, delete the older checkpoints in the output_dir, does not delete by default'", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "\n", "# Setup distant debugging if needed", "\n", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "args", ".", "per_gpu_train_batch_size", "=", "args", ".", "train_batch_size", "//", "args", ".", "n_gpu", "\n", "args", ".", "per_gpu_eval_batch_size", "=", "args", ".", "eval_batch_size", "//", "args", ".", "n_gpu", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s -   %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "args", ".", "start_epoch", "=", "0", "\n", "args", ".", "start_step", "=", "0", "\n", "checkpoint_last", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-last'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "checkpoint_last", ")", "and", "os", ".", "listdir", "(", "checkpoint_last", ")", ":", "\n", "        ", "args", ".", "model_name_or_path", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'pytorch_model.bin'", ")", "\n", "args", ".", "config_name", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'config.json'", ")", "\n", "idx_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'idx_file.txt'", ")", "\n", "with", "open", "(", "idx_file", ",", "encoding", "=", "'utf-8'", ")", "as", "idxf", ":", "\n", "            ", "args", ".", "start_epoch", "=", "int", "(", "idxf", ".", "readlines", "(", ")", "[", "0", "]", ".", "strip", "(", ")", ")", "+", "1", "\n", "\n", "", "step_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'step_file.txt'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "step_file", ")", ":", "\n", "            ", "with", "open", "(", "step_file", ",", "encoding", "=", "'utf-8'", ")", "as", "stepf", ":", "\n", "                ", "args", ".", "start_step", "=", "int", "(", "stepf", ".", "readlines", "(", ")", "[", "0", "]", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"reload model from {}, resume from {} epoch\"", ".", "format", "(", "checkpoint_last", ",", "args", ".", "start_epoch", ")", ")", "\n", "\n", "", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "config", ".", "num_labels", "=", "1", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "if", "args", ".", "block_size", "<=", "0", ":", "\n", "        ", "args", ".", "block_size", "=", "tokenizer", ".", "max_len_single_sentence", "# Our input block size will be the max possible for the model", "\n", "", "args", ".", "block_size", "=", "min", "(", "args", ".", "block_size", ",", "tokenizer", ".", "max_len_single_sentence", ")", "\n", "if", "args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "model_class", "(", "config", ")", "\n", "\n", "", "model", "=", "Model", "(", "model", ",", "config", ",", "tokenizer", ",", "args", ")", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# End of barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "train_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "train_data_file", ")", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "\n", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-map/model.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "round", "(", "result", "[", "key", "]", ",", "4", ")", ")", ")", "\n", "\n", "", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-map/model.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "test", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "\n", "", "return", "results", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_adaptive_curri.InputFeatures.__init__": [[71, 82], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "input_tokens", ",", "\n", "input_ids", ",", "\n", "index", ",", "\n", "label", ",", "\n", "\n", ")", ":", "\n", "        ", "self", ".", "input_tokens", "=", "input_tokens", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_adaptive_curri.TextDataset.__init__": [[97, 123], ["open", "run_adaptive_curri.TextDataset.examples.append", "enumerate", "run_adaptive_curri.TextDataset.label_examples[].append", "line.strip.strip.strip", "json.loads", "data.append", "run_adaptive_curri.convert_examples_to_features", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "x.replace", "map"], "methods", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.convert_examples_to_features"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ",", "count_index", ",", "file_path", "=", "None", ")", ":", "\n", "        ", "self", ".", "examples", "=", "[", "]", "\n", "data", "=", "[", "]", "\n", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "if", "count_index", "!=", "-", "1", ":", "\n", "                    ", "js", "[", "'index'", "]", "=", "count_index", "\n", "count_index", "+=", "1", "\n", "", "data", ".", "append", "(", "js", ")", "\n", "", "", "self", ".", "count_index", "=", "count_index", "\n", "for", "js", "in", "data", ":", "\n", "            ", "self", ".", "examples", ".", "append", "(", "convert_examples_to_features", "(", "js", ",", "tokenizer", ",", "args", ")", ")", "\n", "", "if", "'train'", "in", "file_path", ":", "\n", "            ", "for", "idx", ",", "example", "in", "enumerate", "(", "self", ".", "examples", "[", ":", "3", "]", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"idx: {}\"", ".", "format", "(", "idx", ")", ")", "\n", "logger", ".", "info", "(", "\"label: {}\"", ".", "format", "(", "example", ".", "label", ")", ")", "\n", "logger", ".", "info", "(", "\"input_tokens: {}\"", ".", "format", "(", "[", "x", ".", "replace", "(", "'\\u0120'", ",", "'_'", ")", "for", "x", "in", "example", ".", "input_tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: {}\"", ".", "format", "(", "' '", ".", "join", "(", "map", "(", "str", ",", "example", ".", "input_ids", ")", ")", ")", ")", "\n", "", "", "self", ".", "label_examples", "=", "{", "}", "\n", "for", "e", "in", "self", ".", "examples", ":", "\n", "            ", "if", "e", ".", "label", "not", "in", "self", ".", "label_examples", ":", "\n", "                ", "self", ".", "label_examples", "[", "e", ".", "label", "]", "=", "[", "]", "\n", "", "self", ".", "label_examples", "[", "e", ".", "label", "]", ".", "append", "(", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_adaptive_curri.TextDataset.__len__": [[124, 126], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_adaptive_curri.TextDataset.__getitem__": [[127, 142], ["list", "list.remove", "random.sample", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "random.sample", "random.sample"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "label", "=", "self", ".", "examples", "[", "i", "]", ".", "label", "\n", "index", "=", "self", ".", "examples", "[", "i", "]", ".", "index", "\n", "labels", "=", "list", "(", "self", ".", "label_examples", ")", "\n", "labels", ".", "remove", "(", "label", ")", "\n", "while", "True", ":", "\n", "            ", "shuffle_example", "=", "random", ".", "sample", "(", "self", ".", "label_examples", "[", "label", "]", ",", "1", ")", "[", "0", "]", "\n", "if", "shuffle_example", ".", "index", "!=", "index", ":", "\n", "                ", "p_example", "=", "shuffle_example", "# different example with same label", "\n", "break", "\n", "", "", "n_example", "=", "random", ".", "sample", "(", "self", ".", "label_examples", "[", "random", ".", "sample", "(", "labels", ",", "1", ")", "[", "0", "]", "]", ",", "1", ")", "[", "\n", "0", "]", "# label has removed, n_example with different label", "\n", "\n", "return", "(", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "i", "]", ".", "input_ids", ")", ",", "torch", ".", "tensor", "(", "p_example", ".", "input_ids", ")", ",", "\n", "torch", ".", "tensor", "(", "n_example", ".", "input_ids", ")", ",", "torch", ".", "tensor", "(", "label", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_adaptive_curri.convert_examples_to_features": [[84, 93], ["tokenizer.convert_tokens_to_ids", "run_adaptive_curri.InputFeatures", "js[].split", "tokenizer.tokenize", "len", "int"], "function", ["None"], ["", "", "def", "convert_examples_to_features", "(", "js", ",", "tokenizer", ",", "args", ")", ":", "\n", "# source", "\n", "    ", "code", "=", "' '", ".", "join", "(", "js", "[", "'code'", "]", ".", "split", "(", ")", ")", "\n", "code_tokens", "=", "tokenizer", ".", "tokenize", "(", "code", ")", "[", ":", "args", ".", "block_size", "-", "2", "]", "\n", "source_tokens", "=", "[", "tokenizer", ".", "cls_token", "]", "+", "code_tokens", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "source_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "source_tokens", ")", "\n", "padding_length", "=", "args", ".", "block_size", "-", "len", "(", "source_ids", ")", "\n", "source_ids", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n", "return", "InputFeatures", "(", "source_tokens", ",", "source_ids", ",", "js", "[", "'index'", "]", ",", "int", "(", "js", "[", "'label'", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_adaptive_curri.set_seed": [[144, 151], ["random.seed", "str", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["", "", "def", "set_seed", "(", "seed", "=", "42", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "'PYHTONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_adaptive_curri.train": [[153, 358], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "len", "len", "torch.nn.parallel.DistributedDataParallel.to", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.path.exists", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "range", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "transformers.get_linear_schedule_with_warmup.load_state_dict", "transformers.AdamW.load_state_dict", "len", "int", "len", "len", "transformers.get_linear_schedule_with_warmup", "enumerate", "int", "len", "torch.load", "torch.load", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "loss.mean.item", "round", "ImportError", "torch.distributed.get_world_size", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "logger.info", "transformers.AdamW.step", "transformers.AdamW.zero_grad", "transformers.get_linear_schedule_with_warmup.step", "min", "int", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "int", "int", "print", "torch.utils.data.DataLoader", "any", "run_adaptive_curri.evaluate", "evaluate.items", "logger.info", "logger.info", "logger.info", "os.path.join", "os.path.join", "torch.save", "logger.info", "print", "torch.utils.data.DataLoader", "print", "torch.utils.data.DataLoader", "len", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "logger.info", "round", "os.path.exists", "os.makedirs", "hasattr", "model_to_save.state_dict", "len", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "len", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "round"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate"], ["", "def", "train", "(", "args", ",", "ordered_train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "\n", "c0", "=", "0.64", "\n", "\n", "train_data", "=", "ordered_train_dataset", "[", "0", ":", "int", "(", "c0", "*", "len", "(", "ordered_train_dataset", ")", ")", "]", "\n", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "#train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)", "\n", "\n", "#train_dataloader = DataLoader(train_dataset, sampler=train_sampler,", "\n", "#                              batch_size=args.train_batch_size, num_workers=4, pin_memory=True)", "\n", "s_for_count_only", "=", "RandomSampler", "(", "ordered_train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "\n", "ordered_train_dataset", ")", "\n", "t_for_count_only", "=", "DataLoader", "(", "ordered_train_dataset", ",", "sampler", "=", "s_for_count_only", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "args", ".", "max_steps", "=", "args", ".", "epoch", "*", "len", "(", "t_for_count_only", ")", "/", "2", "\n", "args", ".", "save_steps", "=", "len", "(", "train_dataloader", ")", "\n", "args", ".", "warmup_steps", "=", "len", "(", "t_for_count_only", ")", "\n", "args", ".", "logging_steps", "=", "len", "(", "train_dataloader", ")", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "epoch", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "max_steps", "*", "0.1", ",", "\n", "num_training_steps", "=", "args", ".", "max_steps", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "\n", "", "checkpoint_last", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-last'", ")", "\n", "scheduler_last", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'scheduler.pt'", ")", "\n", "optimizer_last", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'optimizer.pt'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "scheduler_last", ")", ":", "\n", "        ", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "scheduler_last", ")", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "optimizer_last", ")", ":", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "optimizer_last", ")", ")", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "t_for_count_only", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "\n", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "args", ".", "max_steps", ")", "\n", "\n", "global_step", "=", "args", ".", "start_step", "\n", "all_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", ",", "avg_loss", ",", "tr_nb", ",", "tr_num", ",", "train_loss", "=", "0.0", ",", "0.0", ",", "0.0", ",", "0", ",", "0", ",", "0", "\n", "best_acc", "=", "0.0", "\n", "# model.resize_token_embeddings(len(tokenizer))", "\n", "model", ".", "zero_grad", "(", ")", "\n", "now_percent", "=", "0", "\n", "for", "idx", "in", "range", "(", "args", ".", "start_epoch", ",", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "        ", "tr_num", "=", "0", "\n", "train_loss", "=", "0", "\n", "\n", "# reset about dataloader", "\n", "args", ".", "save_steps", "=", "len", "(", "train_dataloader", ")", "\n", "args", ".", "logging_steps", "=", "len", "(", "train_dataloader", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "max_steps", "*", "0.1", ",", "\n", "num_training_steps", "=", "args", ".", "max_steps", ")", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "            ", "inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "p_inputs", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "n_inputs", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "#print(\"inputs = \",inputs)", "\n", "model", ".", "train", "(", ")", "\n", "loss", ",", "vec", "=", "model", "(", "inputs", ",", "p_inputs", ",", "n_inputs", ",", "labels", ")", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "tr_num", "+=", "1", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "avg_loss", "=", "round", "(", "train_loss", "/", "tr_num", ",", "5", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"epoch {} step {} loss {}\"", ".", "format", "(", "idx", ",", "step", "+", "1", ",", "avg_loss", ")", ")", "\n", "# bar.set_description(\"epoch {} loss {}\".format(idx,avg_loss))", "\n", "\n", "", "all_step", "+=", "1", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "all_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "eval_when_training", "=", "True", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "round", "(", "value", ",", "4", ")", ")", "\n", "# Save model checkpoint", "\n", "", "tr_num", "=", "0", "\n", "train_loss", "=", "0", "\n", "\n", "", "if", "results", "[", "'eval_map'", "]", ">", "best_acc", ":", "\n", "                        ", "best_acc", "=", "results", "[", "'eval_map'", "]", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "logger", ".", "info", "(", "\"  Best map:%s\"", ",", "round", "(", "best_acc", ",", "4", ")", ")", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "\n", "checkpoint_prefix", "=", "'checkpoint-best-map'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                            ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'{}'", ".", "format", "(", "'model_adaptive.bin'", ")", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_dir", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "", "", "", "", "reduce", "=", "0", "\n", "if", "args", ".", "pacing_function", "!=", "\"\"", ":", "\n", "\n", "            ", "if", "args", ".", "pacing_function", "==", "\"reduce\"", ":", "\n", "                ", "if", "reduce", "==", "0", ":", "\n", "                    ", "if", "c0", "==", "0.64", ":", "\n", "                        ", "c0", "=", "0.80", "\n", "", "elif", "c0", "==", "0.80", ":", "\n", "                        ", "c0", "=", "1", "\n", "reduce", "=", "1", "\n", "\n", "", "percent", "=", "int", "(", "c0", "*", "len", "(", "ordered_train_dataset", ")", ")", "\n", "if", "percent", "!=", "now_percent", ":", "\n", "                        ", "now_percent", "=", "percent", "\n", "print", "(", "c0", ")", "\n", "train_data", "=", "ordered_train_dataset", "[", "0", ":", "now_percent", "]", "\n", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "\n", "train_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "train_batch_size", ",", "\n", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n", "", "", "else", ":", "\n", "                    ", "if", "c0", "==", "0.64", ":", "\n", "                        ", "c0", "=", "1.0", "\n", "", "elif", "c0", "==", "0.80", ":", "\n", "                        ", "c0", "=", "0.64", "\n", "", "else", ":", "\n", "                        ", "c0", "=", "0.80", "\n", "\n", "", "percent", "=", "int", "(", "(", "1", "-", "c0", ")", "*", "len", "(", "ordered_train_dataset", ")", ")", "\n", "if", "percent", "!=", "now_percent", ":", "\n", "                        ", "now_percent", "=", "percent", "\n", "print", "(", "c0", ")", "\n", "train_data", "=", "ordered_train_dataset", "[", "now_percent", ":", "]", "\n", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "\n", "train_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "train_batch_size", ",", "\n", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n", "", "", "", "else", ":", "\n", "# percentage_curriculum_iter = 0.90", "\n", "# curriculum_iterations = args.max_steps * percentage_curriculum_iter", "\n", "                ", "curriculum_iterations", "=", "args", ".", "max_steps", "\n", "new_data_fraction", "=", "min", "(", "1", ",", "\n", "PACING_FUNCTIONS", "[", "args", ".", "pacing_function", "]", "(", "all_step", ",", "curriculum_iterations", ",", "c0", ")", ")", "\n", "percent", "=", "int", "(", "new_data_fraction", "*", "len", "(", "ordered_train_dataset", ")", ")", "\n", "if", "percent", "!=", "now_percent", ":", "\n", "                    ", "now_percent", "=", "percent", "\n", "print", "(", "new_data_fraction", ")", "\n", "train_data", "=", "ordered_train_dataset", "[", "0", ":", "now_percent", "]", "\n", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "\n", "train_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "\n", "num_workers", "=", "4", ",", "pin_memory", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_adaptive_curri.evaluate": [[362, 433], ["torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "numpy.concatenate", "numpy.concatenate", "torch.tensor", "numpy.matmul", "range", "range", "run_adaptive_curri.TextDataset", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "numpy.argsort", "int", "range", "MAP.append", "float", "float", "os.path.exists", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "np.concatenate.append", "np.concatenate.append", "int", "numpy.mean", "vec.cpu().numpy", "int.cpu().numpy", "int", "int", "lm_loss.mean", "int", "vec.cpu", "int.cpu"], "function", ["None"], ["def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "eval_when_training", "=", "False", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "global", "eval_dataset", "\n", "if", "eval_dataset", "is", "None", ":", "\n", "        ", "eval_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "-", "1", ",", "args", ".", "eval_data_file", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "num_workers", "=", "4", ",", "\n", "pin_memory", "=", "True", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "eval_when_training", "is", "False", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "vecs", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "p_inputs", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "n_inputs", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "label", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "lm_loss", ",", "vec", "=", "model", "(", "inputs", ",", "p_inputs", ",", "n_inputs", ",", "label", ")", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "vecs", ".", "append", "(", "vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "labels", ".", "append", "(", "label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "", "vecs", "=", "np", ".", "concatenate", "(", "vecs", ",", "0", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "0", ")", "\n", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "tensor", "(", "eval_loss", ")", "\n", "# np.save(\"vecs\" + str(args.eval_data_file)[-7] + \".npy\", vecs)", "\n", "# np.save(\"labels\" + str(args.eval_data_file)[-7] + \".npy\", labels)", "\n", "scores", "=", "np", ".", "matmul", "(", "vecs", ",", "vecs", ".", "T", ")", "\n", "\n", "dic", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "scores", "[", "i", ",", "i", "]", "=", "-", "1000000", "\n", "if", "int", "(", "labels", "[", "i", "]", ")", "not", "in", "dic", ":", "\n", "            ", "dic", "[", "int", "(", "labels", "[", "i", "]", ")", "]", "=", "-", "1", "\n", "", "dic", "[", "int", "(", "labels", "[", "i", "]", ")", "]", "+=", "1", "\n", "", "sort_ids", "=", "np", ".", "argsort", "(", "scores", ",", "axis", "=", "-", "1", ",", "kind", "=", "'quicksort'", ",", "order", "=", "None", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "MAP", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "cont", "=", "0", "\n", "label", "=", "int", "(", "labels", "[", "i", "]", ")", "\n", "for", "j", "in", "range", "(", "dic", "[", "label", "]", ")", ":", "\n", "            ", "index", "=", "sort_ids", "[", "i", ",", "j", "]", "\n", "if", "int", "(", "labels", "[", "index", "]", ")", "==", "label", ":", "\n", "                ", "cont", "+=", "1", "\n", "", "", "MAP", ".", "append", "(", "cont", "/", "dic", "[", "label", "]", ")", "\n", "\n", "", "result", "=", "{", "\n", "\"eval_loss\"", ":", "float", "(", "perplexity", ")", ",", "\n", "\"eval_map\"", ":", "float", "(", "np", ".", "mean", "(", "MAP", ")", ")", "\n", "}", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_adaptive_curri.test": [[435, 497], ["run_adaptive_curri.TextDataset", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "numpy.concatenate", "numpy.concatenate", "range", "torch.tensor", "numpy.matmul", "range", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "len", "numpy.argsort", "indexs.append", "open", "zip", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "np.concatenate.append", "np.concatenate.append", "os.path.join", "f.write", "vec.cpu().numpy", "batch[].to.cpu().numpy", "js[].append", "lm_loss.mean", "json.dumps", "vec.cpu", "batch[].to.cpu", "int"], "function", ["None"], ["", "def", "test", "(", "args", ",", "model", ",", "tokenizer", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "-", "1", ",", "args", ".", "test_data_file", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running Test *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "vecs", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "p_inputs", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "n_inputs", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "label", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "lm_loss", ",", "vec", "=", "model", "(", "inputs", ",", "p_inputs", ",", "n_inputs", ",", "label", ")", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "vecs", ".", "append", "(", "vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "labels", ".", "append", "(", "label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "", "vecs", "=", "np", ".", "concatenate", "(", "vecs", ",", "0", ")", "\n", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "0", ")", "\n", "cluster", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "        ", "label", "=", "labels", "[", "i", "]", "\n", "if", "label", "not", "in", "cluster", ":", "\n", "            ", "cluster", "[", "label", "]", "=", "0", "\n", "", "cluster", "[", "label", "]", "+=", "1", "\n", "\n", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "tensor", "(", "eval_loss", ")", "\n", "scores", "=", "np", ".", "matmul", "(", "vecs", ",", "vecs", ".", "T", ")", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "scores", "[", "i", ",", "i", "]", "=", "-", "1000000", "\n", "", "sort_ids", "=", "np", ".", "argsort", "(", "scores", ",", "axis", "=", "-", "1", ",", "kind", "=", "'quicksort'", ",", "order", "=", "None", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "indexs", "=", "[", "]", "\n", "for", "example", "in", "eval_dataset", ".", "examples", ":", "\n", "        ", "indexs", ".", "append", "(", "example", ".", "index", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"predictions.jsonl\"", ")", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "cnt", "=", "0", "\n", "for", "index", ",", "sort_id", "in", "zip", "(", "indexs", ",", "sort_ids", ")", ":", "\n", "            ", "js", "=", "{", "}", "\n", "js", "[", "'index'", "]", "=", "index", "\n", "js", "[", "'answers'", "]", "=", "[", "]", "\n", "for", "idx", "in", "sort_id", "[", ":", "cluster", "[", "labels", "[", "cnt", "]", "]", "-", "1", "]", ":", "\n", "                ", "js", "[", "'answers'", "]", ".", "append", "(", "indexs", "[", "int", "(", "idx", ")", "]", ")", "\n", "", "f", ".", "write", "(", "json", ".", "dumps", "(", "js", ")", "+", "'\\n'", ")", "\n", "cnt", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_adaptive_curri.main": [[499, 737], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_adaptive_curri.set_seed", "os.path.join", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "min", "model.Model", "logger.info", "run_adaptive_curri.TextDataset", "run_adaptive_curri.TextDataset", "run_adaptive_curri.TextDataset", "numpy.load", "numpy.load", "numpy.load", "whole_data.extend", "whole_data.extend", "sorted", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "os.path.exists", "os.listdir", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "logger.info", "model_class.from_pretrained", "model_class", "torch.distributed.barrier", "run_adaptive_curri.train", "os.path.join", "model_class.load_state_dict", "model_class.to", "run_adaptive_curri.evaluate", "logger.info", "sorted", "os.path.join", "model_class.load_state_dict", "model_class.to", "run_adaptive_curri.test", "open", "zip", "zip", "zip", "torch.distributed.barrier", "torch.distributed.barrier", "torch.load", "evaluate.keys", "logger.info", "torch.load", "int", "open", "int", "bool", "str", "torch.cuda.is_available", "[].strip", "[].strip", "round", "idxf.readlines", "stepf.readlines"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.set_seed", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate", "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.test"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input training data file (a text file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--eval_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "\"bert\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model architecture to be fine-tuned.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--mlm\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Train with masked-language modeling loss instead of language modeling.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mlm_probability\"", ",", "type", "=", "float", ",", "default", "=", "0.15", ",", "\n", "help", "=", "\"Ratio of tokens to mask for masked language modeling loss\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional directory to store the pre-trained models downloaded from s3 (instread of the default one)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--block_size\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional input sequence length after tokenization.\"", "\n", "\"The training dataset will be truncated in block of this size for training.\"", "\n", "\"Default to the model max input length for single sentence inputs (take into account special tokens).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Run evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_total_limit'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "\n", "help", "=", "'Limit the total amount of checkpoints, delete the older checkpoints in the output_dir, does not delete by default'", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "2021", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "'--epoch'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--pacing_function\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Use one of the predefined pacing functions instead of shards (requires a values curriculum_file)\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "args", ".", "per_gpu_train_batch_size", "=", "args", ".", "train_batch_size", "//", "args", ".", "n_gpu", "\n", "args", ".", "per_gpu_eval_batch_size", "=", "args", ".", "eval_batch_size", "//", "args", ".", "n_gpu", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s -   %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "args", ".", "start_epoch", "=", "0", "\n", "args", ".", "start_step", "=", "0", "\n", "checkpoint_last", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-last'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "checkpoint_last", ")", "and", "os", ".", "listdir", "(", "checkpoint_last", ")", ":", "\n", "        ", "args", ".", "model_name_or_path", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'pytorch_model.bin'", ")", "\n", "args", ".", "config_name", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'config.json'", ")", "\n", "idx_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'idx_file.txt'", ")", "\n", "with", "open", "(", "idx_file", ",", "encoding", "=", "'utf-8'", ")", "as", "idxf", ":", "\n", "            ", "args", ".", "start_epoch", "=", "int", "(", "idxf", ".", "readlines", "(", ")", "[", "0", "]", ".", "strip", "(", ")", ")", "+", "1", "\n", "\n", "", "step_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'step_file.txt'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "step_file", ")", ":", "\n", "            ", "with", "open", "(", "step_file", ",", "encoding", "=", "'utf-8'", ")", "as", "stepf", ":", "\n", "                ", "args", ".", "start_step", "=", "int", "(", "stepf", ".", "readlines", "(", ")", "[", "0", "]", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"reload model from {}, resume from {} epoch\"", ".", "format", "(", "checkpoint_last", ",", "args", ".", "start_epoch", ")", ")", "\n", "\n", "\n", "", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "config", ".", "num_labels", "=", "1", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "if", "args", ".", "block_size", "<=", "0", ":", "\n", "        ", "args", ".", "block_size", "=", "tokenizer", ".", "max_len_single_sentence", "# Our input block size will be the max possible for the model", "\n", "", "args", ".", "block_size", "=", "min", "(", "args", ".", "block_size", ",", "tokenizer", ".", "max_len_single_sentence", ")", "\n", "if", "args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "model_class", "(", "config", ")", "\n", "\n", "", "model", "=", "Model", "(", "model", ",", "config", ",", "tokenizer", ",", "args", ")", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# End of barrier to make sure only the first process in distributed training download model & vocab", "\n", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Train dataset", "\n", "file_path0", "=", "\"../dataset/3-fold/test0.jsonl\"", "\n", "file_path1", "=", "\"../dataset/3-fold/test1.jsonl\"", "\n", "file_path2", "=", "\"../dataset/3-fold/test2_64.jsonl\"", "\n", "\n", "count_index", "=", "0", "\n", "\n", "curri_dataset0", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "count_index", ",", "file_path0", ")", "\n", "#print(count_index)", "\n", "#print(curri_dataset0.count_index)", "\n", "curri_dataset1", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "curri_dataset0", ".", "count_index", ",", "file_path1", ")", "\n", "#print(curri_dataset1.count_index)", "\n", "curri_dataset2", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "curri_dataset1", ".", "count_index", ",", "file_path2", ")", "\n", "#print(curri_dataset2.count_index)", "\n", "\n", "score_path0", "=", "\"./saved_models/score_for_normal/scores0.npy\"", "\n", "score_path1", "=", "\"./saved_models/score_for_normal/scores1.npy\"", "\n", "score_path2", "=", "\"./saved_models/score_for_normal/scores2.npy\"", "\n", "\n", "score0", "=", "np", ".", "load", "(", "score_path0", ")", "\n", "score1", "=", "np", ".", "load", "(", "score_path1", ")", "\n", "score2", "=", "np", ".", "load", "(", "score_path2", ")", "\n", "\n", "c0", "=", "[", "v", "for", "v", "in", "zip", "(", "score0", ",", "curri_dataset0", ")", "]", "\n", "c1", "=", "[", "v", "for", "v", "in", "zip", "(", "score1", ",", "curri_dataset1", ")", "]", "\n", "c2", "=", "[", "v", "for", "v", "in", "zip", "(", "score2", ",", "curri_dataset2", ")", "]", "\n", "whole_data", "=", "c0", "\n", "whole_data", ".", "extend", "(", "c1", ")", "\n", "whole_data", ".", "extend", "(", "c2", ")", "\n", "\n", "#train_data = sorted(whole_data, key=lambda x: x[0], reverse=True)", "\n", "train_data", "=", "sorted", "(", "whole_data", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "ordered_train_dataset", "=", "[", "v", "[", "1", "]", "for", "v", "in", "train_data", "]", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Barrier to make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "#train_dataset = TextDataset(tokenizer, args, args.train_data_file)", "\n", "", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "train", "(", "args", ",", "ordered_train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-map/model_adaptive.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "round", "(", "result", "[", "key", "]", ",", "4", ")", ")", ")", "\n", "\n", "", "", "if", "args", ".", "do_test", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-map/model_adaptive.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "test", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.sumscores.read_answers": [[9, 17], ["open", "line.strip.strip", "line.strip.split", "answers.append", "int"], "function", ["None"], ["score1", "=", "np", ".", "load", "(", "\"scores1.npy\"", ")", "\n", "score2", "=", "np", ".", "load", "(", "\"scores2.npy\"", ")", "\n", "#print(score)", "\n", "\n", "\n", "def", "builddataset", "(", "file_path", ")", ":", "\n", "    ", "examples", "=", "[", "]", "\n", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.model.RobertaClassificationHead.__init__": [[14, 19], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.TextDataset.__init__"], []], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.model.RobertaClassificationHead.forward": [[20, 29], ["model.RobertaClassificationHead.reshape", "model.RobertaClassificationHead.dropout", "model.RobertaClassificationHead.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "model.RobertaClassificationHead.dropout", "model.RobertaClassificationHead.out_proj", "model.RobertaClassificationHead.size"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "margin", "=", "0.3", ")", ":", "\n", "        ", "super", "(", "TripletLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "ranking_loss", "=", "nn", ".", "MarginRankingLoss", "(", "margin", "=", "margin", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "inputs", ",", "targets", ")", ":", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_curri.InputFeatures.__init__": [[92, 105], ["None"], "methods", ["None"], ["                ", "indexs", ".", "add", "(", "d", "[", "1", "]", ")", "\n", "", "for", "x", "in", "d", "[", "-", "1", "]", ":", "\n", "                ", "indexs", ".", "add", "(", "x", ")", "\n", "", "", "new_DFG", "=", "[", "]", "\n", "for", "d", "in", "DFG", ":", "\n", "            ", "if", "d", "[", "1", "]", "in", "indexs", ":", "\n", "                ", "new_DFG", ".", "append", "(", "d", ")", "\n", "", "", "dfg", "=", "new_DFG", "\n", "", "except", ":", "\n", "        ", "dfg", "=", "[", "]", "\n", "", "return", "code_tokens", ",", "dfg", "\n", "\n", "\n", "", "class", "InputFeatures", "(", "object", ")", ":", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_curri.TextDataset.__init__": [[128, 167], ["logger.info", "open", "pool.map", "[].split", "open", "open", "random.sample", "tqdm.tqdm.tqdm", "line.strip.strip.strip", "json.loads", "line.strip.strip.strip", "line.strip.strip.split", "random.sample.append", "int", "len", "file_path.split", "len", "index_filename.split"], "methods", ["None"], ["\n", "", "", "def", "convert_examples_to_features", "(", "item", ")", ":", "\n", "    ", "js", ",", "tokenizer", ",", "args", "=", "item", "\n", "# code", "\n", "parser", "=", "parsers", "[", "args", ".", "lang", "]", "\n", "# extract data flow", "\n", "code_tokens", ",", "dfg", "=", "extract_dataflow", "(", "js", "[", "'original_string'", "]", ",", "parser", ",", "args", ".", "lang", ")", "\n", "code_tokens", "=", "[", "tokenizer", ".", "tokenize", "(", "'@ '", "+", "x", ")", "[", "1", ":", "]", "if", "idx", "!=", "0", "else", "tokenizer", ".", "tokenize", "(", "x", ")", "for", "idx", ",", "x", "in", "\n", "enumerate", "(", "code_tokens", ")", "]", "\n", "ori2cur_pos", "=", "{", "}", "\n", "ori2cur_pos", "[", "-", "1", "]", "=", "(", "0", ",", "0", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "code_tokens", ")", ")", ":", "\n", "        ", "ori2cur_pos", "[", "i", "]", "=", "(", "ori2cur_pos", "[", "i", "-", "1", "]", "[", "1", "]", ",", "ori2cur_pos", "[", "i", "-", "1", "]", "[", "1", "]", "+", "len", "(", "code_tokens", "[", "i", "]", ")", ")", "\n", "", "code_tokens", "=", "[", "y", "for", "x", "in", "code_tokens", "for", "y", "in", "x", "]", "\n", "# truncating", "\n", "code_tokens", "=", "code_tokens", "[", ":", "args", ".", "code_length", "+", "args", ".", "data_flow_length", "-", "2", "-", "min", "(", "len", "(", "dfg", ")", ",", "args", ".", "data_flow_length", ")", "]", "\n", "code_tokens", "=", "[", "tokenizer", ".", "cls_token", "]", "+", "code_tokens", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "code_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "code_tokens", ")", "\n", "position_idx", "=", "[", "i", "+", "tokenizer", ".", "pad_token_id", "+", "1", "for", "i", "in", "range", "(", "len", "(", "code_tokens", ")", ")", "]", "\n", "dfg", "=", "dfg", "[", ":", "args", ".", "code_length", "+", "args", ".", "data_flow_length", "-", "len", "(", "code_tokens", ")", "]", "\n", "code_tokens", "+=", "[", "x", "[", "0", "]", "for", "x", "in", "dfg", "]", "\n", "position_idx", "+=", "[", "0", "for", "x", "in", "dfg", "]", "\n", "code_ids", "+=", "[", "tokenizer", ".", "unk_token_id", "for", "x", "in", "dfg", "]", "\n", "padding_length", "=", "args", ".", "code_length", "+", "args", ".", "data_flow_length", "-", "len", "(", "code_ids", ")", "\n", "position_idx", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n", "code_ids", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n", "# reindex", "\n", "reverse_index", "=", "{", "}", "\n", "for", "idx", ",", "x", "in", "enumerate", "(", "dfg", ")", ":", "\n", "        ", "reverse_index", "[", "x", "[", "1", "]", "]", "=", "idx", "\n", "", "for", "idx", ",", "x", "in", "enumerate", "(", "dfg", ")", ":", "\n", "        ", "dfg", "[", "idx", "]", "=", "x", "[", ":", "-", "1", "]", "+", "(", "[", "reverse_index", "[", "i", "]", "for", "i", "in", "x", "[", "-", "1", "]", "if", "i", "in", "reverse_index", "]", ",", ")", "\n", "", "dfg_to_dfg", "=", "[", "x", "[", "-", "1", "]", "for", "x", "in", "dfg", "]", "\n", "dfg_to_code", "=", "[", "ori2cur_pos", "[", "x", "[", "1", "]", "]", "for", "x", "in", "dfg", "]", "\n", "length", "=", "len", "(", "[", "tokenizer", ".", "cls_token", "]", ")", "\n", "dfg_to_code", "=", "[", "(", "x", "[", "0", "]", "+", "length", ",", "x", "[", "1", "]", "+", "length", ")", "for", "x", "in", "dfg_to_code", "]", "\n", "# nl", "\n", "nl", "=", "' '", ".", "join", "(", "js", "[", "'docstring_tokens'", "]", ")", "\n", "nl_tokens", "=", "tokenizer", ".", "tokenize", "(", "nl", ")", "[", ":", "args", ".", "nl_length", "-", "2", "]", "\n", "nl_tokens", "=", "[", "tokenizer", ".", "cls_token", "]", "+", "nl_tokens", "+", "[", "tokenizer", ".", "sep_token", "]", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_curri.TextDataset.__len__": [[168, 170], ["len"], "methods", ["None"], ["nl_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "nl_tokens", ")", "\n", "padding_length", "=", "args", ".", "nl_length", "-", "len", "(", "nl_ids", ")", "\n", "nl_ids", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_curri.TextDataset.__getitem__": [[171, 174], ["torch.tensor", "torch.tensor"], "methods", ["None"], ["\n", "return", "InputFeatures", "(", "code_tokens", ",", "code_ids", ",", "position_idx", ",", "dfg_to_code", ",", "dfg_to_dfg", ",", "nl_tokens", ",", "nl_ids", ",", "js", "[", "'url'", "]", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_curri.get_example": [[67, 87], ["run_curri.convert_examples_to_features", "cache[].copy", "tokenizer.tokenize", "cache[].copy", "tokenizer.tokenize", "url_to_code[].split", "url_to_code[].split"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.convert_examples_to_features"], ["# remove comments", "\n", "    ", "try", ":", "\n", "        ", "code", "=", "remove_comments_and_docstrings", "(", "code", ",", "lang", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "# obtain dataflow", "\n", "", "if", "lang", "==", "\"php\"", ":", "\n", "        ", "code", "=", "\"<?php\"", "+", "code", "+", "\"?>\"", "\n", "", "try", ":", "\n", "        ", "tree", "=", "parser", "[", "0", "]", ".", "parse", "(", "bytes", "(", "code", ",", "'utf8'", ")", ")", "\n", "root_node", "=", "tree", ".", "root_node", "\n", "tokens_index", "=", "tree_to_token_index", "(", "root_node", ")", "\n", "code", "=", "code", ".", "split", "(", "'\\n'", ")", "\n", "code_tokens", "=", "[", "index_to_code_token", "(", "x", ",", "code", ")", "for", "x", "in", "tokens_index", "]", "\n", "index_to_code", "=", "{", "}", "\n", "for", "idx", ",", "(", "index", ",", "code", ")", "in", "enumerate", "(", "zip", "(", "tokens_index", ",", "code_tokens", ")", ")", ":", "\n", "            ", "index_to_code", "[", "index", "]", "=", "(", "idx", ",", "code", ")", "\n", "", "try", ":", "\n", "            ", "DFG", ",", "_", "=", "parser", "[", "1", "]", "(", "root_node", ",", "index_to_code", ",", "{", "}", ")", "\n", "", "except", ":", "\n", "            ", "DFG", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_curri.convert_examples_to_features": [[107, 125], ["tokenizer.convert_tokens_to_ids", "tokenizer.convert_tokens_to_ids", "run_curri.InputFeatures", "len", "len"], "function", ["None"], ["\n", "def", "__init__", "(", "self", ",", "\n", "code_tokens", ",", "\n", "code_ids", ",", "\n", "position_idx", ",", "\n", "dfg_to_code", ",", "\n", "dfg_to_dfg", ",", "\n", "nl_tokens", ",", "\n", "nl_ids", ",", "\n", "url", ",", "\n", "\n", ")", ":", "\n", "        ", "self", ".", "code_tokens", "=", "code_tokens", "\n", "self", ".", "code_ids", "=", "code_ids", "\n", "self", ".", "position_idx", "=", "position_idx", "\n", "self", ".", "dfg_to_code", "=", "dfg_to_code", "\n", "self", ".", "dfg_to_dfg", "=", "dfg_to_dfg", "\n", "self", ".", "nl_tokens", "=", "nl_tokens", "\n", "self", ".", "nl_ids", "=", "nl_ids", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_curri.load_and_cache_examples": [[176, 180], ["run_curri.TextDataset"], "function", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ",", "file_path", "=", "None", ",", "pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "prefix", "=", "file_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "[", ":", "-", "6", "]", "\n", "cache_file", "=", "args", ".", "output_dir", "+", "'/'", "+", "prefix", "+", "'.pkl'", "\n", "if", "os", ".", "path", ".", "exists", "(", "cache_file", ")", ":", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_curri.set_seed": [[182, 189], ["random.seed", "str", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["", "else", ":", "\n", "            ", "self", ".", "examples", "=", "[", "]", "\n", "data", "=", "[", "]", "\n", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "data", ".", "append", "(", "(", "js", ",", "tokenizer", ",", "args", ")", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_curri.train": [[191, 340], ["print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "len", "len", "torch.nn.parallel.DistributedDataParallel.to", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.path.exists", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "run_curri.set_seed", "range", "len", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "transformers.get_linear_schedule_with_warmup.load_state_dict", "transformers.AdamW.load_state_dict", "len", "int", "tqdm.tqdm", "enumerate", "int", "len", "torch.load", "torch.load", "batch[].to", "batch[].to", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "loss.mean.item", "round", "tqdm.tqdm.set_description", "min", "int", "ImportError", "torch.distributed.get_world_size", "len", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "transformers.AdamW.step", "transformers.AdamW.zero_grad", "transformers.get_linear_schedule_with_warmup.step", "round", "print", "torch.utils.data.DataLoader", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "numpy.exp", "len", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "any", "run_curri.evaluate", "logger.info", "logger.info", "logger.info", "os.path.join", "os.path.join", "torch.save", "logger.info", "round", "os.path.exists", "os.makedirs", "hasattr", "model_to_save.state_dict"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.set_seed", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate"], ["pickle", ".", "dump", "(", "self", ".", "examples", ",", "open", "(", "cache_file", ",", "'wb'", ")", ")", "\n", "", "'''\n        if 'train' in file_path:\n            for idx, example in enumerate(self.examples[:3]):\n                logger.info(\"*** Example ***\")\n                logger.info(\"idx: {}\".format(idx))\n                logger.info(\"code_tokens: {}\".format([x.replace('\\u0120','_') for x in example.code_tokens]))\n                logger.info(\"code_ids: {}\".format(' '.join(map(str, example.code_ids))))\n                logger.info(\"position_idx: {}\".format(example.position_idx))\n                logger.info(\"dfg_to_code: {}\".format(' '.join(map(str, example.dfg_to_code))))\n                logger.info(\"dfg_to_dfg: {}\".format(' '.join(map(str, example.dfg_to_dfg))))                \n                logger.info(\"nl_tokens: {}\".format([x.replace('\\u0120','_') for x in example.nl_tokens]))\n                logger.info(\"nl_ids: {}\".format(' '.join(map(str, example.nl_ids))))          \n        '''", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "# calculate graph-guided masked function", "\n", "        ", "attn_mask", "=", "np", ".", "zeros", "(", "(", "self", ".", "args", ".", "code_length", "+", "self", ".", "args", ".", "data_flow_length", ",", "\n", "self", ".", "args", ".", "code_length", "+", "self", ".", "args", ".", "data_flow_length", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "# calculate begin index of node and max length of input", "\n", "node_index", "=", "sum", "(", "[", "i", ">", "1", "for", "i", "in", "self", ".", "examples", "[", "item", "]", ".", "position_idx", "]", ")", "\n", "max_length", "=", "sum", "(", "[", "i", "!=", "1", "for", "i", "in", "self", ".", "examples", "[", "item", "]", ".", "position_idx", "]", ")", "\n", "# sequence can attend to sequence", "\n", "attn_mask", "[", ":", "node_index", ",", ":", "node_index", "]", "=", "True", "\n", "# special tokens attend to all tokens", "\n", "for", "idx", ",", "i", "in", "enumerate", "(", "self", ".", "examples", "[", "item", "]", ".", "code_ids", ")", ":", "\n", "            ", "if", "i", "in", "[", "0", ",", "2", "]", ":", "\n", "                ", "attn_mask", "[", "idx", ",", ":", "max_length", "]", "=", "True", "\n", "# nodes attend to code tokens that are identified from", "\n", "", "", "for", "idx", ",", "(", "a", ",", "b", ")", "in", "enumerate", "(", "self", ".", "examples", "[", "item", "]", ".", "dfg_to_code", ")", ":", "\n", "            ", "if", "a", "<", "node_index", "and", "b", "<", "node_index", ":", "\n", "                ", "attn_mask", "[", "idx", "+", "node_index", ",", "a", ":", "b", "]", "=", "True", "\n", "attn_mask", "[", "a", ":", "b", ",", "idx", "+", "node_index", "]", "=", "True", "\n", "# nodes attend to adjacent nodes", "\n", "", "", "for", "idx", ",", "nodes", "in", "enumerate", "(", "self", ".", "examples", "[", "item", "]", ".", "dfg_to_dfg", ")", ":", "\n", "            ", "for", "a", "in", "nodes", ":", "\n", "                ", "if", "a", "+", "node_index", "<", "len", "(", "self", ".", "examples", "[", "item", "]", ".", "position_idx", ")", ":", "\n", "                    ", "attn_mask", "[", "idx", "+", "node_index", ",", "a", "+", "node_index", "]", "=", "True", "\n", "\n", "", "", "", "return", "(", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ".", "code_ids", ")", ",", "\n", "torch", ".", "tensor", "(", "attn_mask", ")", ",", "\n", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ".", "position_idx", ")", ",", "\n", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ".", "nl_ids", ")", ")", "\n", "\n", "\n", "", "", "def", "set_seed", "(", "seed", "=", "42", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "'PYHTONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "\n", "", "def", "train", "(", "args", ",", "model", ",", "tokenizer", ",", "pool", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "# get training dataset", "\n", "train_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "train_data_file", ",", "pool", ")", "\n", "order_dataset", "=", "[", "v", "for", "v", "in", "train_dataset", "]", "\n", "c0", "=", "164923", "/", "len", "(", "order_dataset", ")", "\n", "print", "(", "c0", ")", "\n", "train_data", "=", "order_dataset", "[", "0", ":", "int", "(", "c0", "*", "len", "(", "order_dataset", ")", ")", "]", "\n", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "4", ")", "\n", "t_for_count", "=", "DataLoader", "(", "order_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n", "# get optimizer and scheduler", "\n", "optimizer", "=", "AdamW", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "1e-8", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "0", ",", "\n", "num_training_steps", "=", "len", "(", "t_for_count", ")", "*", "args", ".", "num_train_epochs", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "train_batch_size", "//", "args", ".", "n_gpu", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size  = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "len", "(", "t_for_count", ")", "*", "args", ".", "num_train_epochs", ")", "\n", "\n", "now_percent", "=", "0", "\n", "all_step", "=", "0", "\n", "# model.resize_token_embeddings(len(tokenizer))", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "tr_num", ",", "tr_loss", ",", "best_mrr", "=", "0", ",", "0", ",", "0", "\n", "for", "idx", "in", "range", "(", "args", ".", "num_train_epochs", ")", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "# get inputs", "\n", "            ", "code_inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "attn_mask", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "position_idx", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "nl_inputs", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "# get code and nl vectors", "\n", "code_vec", "=", "model", "(", "code_inputs", "=", "code_inputs", ",", "attn_mask", "=", "attn_mask", ",", "position_idx", "=", "position_idx", ")", "\n", "nl_vec", "=", "model", "(", "nl_inputs", "=", "nl_inputs", ")", "\n", "\n", "# calculate scores and loss", "\n", "scores", "=", "torch", ".", "einsum", "(", "\"ab,cb->ac\"", ",", "nl_vec", ",", "code_vec", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "scores", ",", "torch", ".", "arange", "(", "code_inputs", ".", "size", "(", "0", ")", ",", "device", "=", "scores", ".", "device", ")", ")", "\n", "\n", "all_step", "+=", "1", "\n", "# report loss", "\n", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "tr_num", "+=", "1", "\n", "if", "(", "step", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"epoch {} step {} loss {}\"", ".", "format", "(", "idx", ",", "step", "+", "1", ",", "round", "(", "tr_loss", "/", "tr_num", ",", "5", ")", ")", ")", "\n", "tr_loss", "=", "0", "\n", "tr_num", "=", "0", "\n", "\n", "# backward", "\n", "", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "# evaluate", "\n", "", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "args", ".", "eval_data_file", ",", "pool", ",", "eval_when_training", "=", "True", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "round", "(", "value", ",", "4", ")", ")", "\n", "\n", "# save best model", "\n", "", "if", "results", "[", "'eval_mrr'", "]", ">", "best_mrr", ":", "\n", "            ", "best_mrr", "=", "results", "[", "'eval_mrr'", "]", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "logger", ".", "info", "(", "\"  Best mrr:%s\"", ",", "round", "(", "best_mrr", ",", "4", ")", ")", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "\n", "checkpoint_prefix", "=", "'checkpoint-best-mrr'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'{}'", ".", "format", "(", "'model_curri.bin'", ")", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_dir", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "if", "args", ".", "pacing_function", "!=", "\"\"", ":", "\n", "            ", "curriculum_iterations", "=", "len", "(", "t_for_count", ")", "*", "args", ".", "num_train_epochs", "\n", "new_data_fraction", "=", "min", "(", "1", ",", "\n", "PACING_FUNCTIONS", "[", "args", ".", "pacing_function", "]", "(", "all_step", ",", "curriculum_iterations", ",", "c0", ")", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_curri.evaluate": [[342, 414], ["run_curri.load_and_cache_examples", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "numpy.concatenate", "numpy.concatenate", "range", "recall_score", "precision_score", "f1_score", "logger.info", "sorted", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "batch[].to", "batch[].to", "recall_score", "precision_score", "f1_score", "float", "float", "float", "result.keys", "logger.info", "os.path.exists", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "np.concatenate.append", "np.concatenate.append", "str", "logit.cpu().numpy", "batch[].to.cpu().numpy", "round", "lm_loss.mean", "logit.cpu", "batch[].to.cpu"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.load_and_cache_examples"], ["if", "percent", "!=", "now_percent", ":", "\n", "                ", "now_percent", "=", "percent", "\n", "print", "(", "new_data_fraction", ")", "\n", "train_data", "=", "order_dataset", "[", "0", ":", "now_percent", "]", "\n", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n", "\n", "", "", "", "", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "file_name", ",", "pool", ",", "eval_when_training", "=", "False", ")", ":", "\n", "    ", "query_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "file_name", ",", "pool", ")", "\n", "query_sampler", "=", "SequentialSampler", "(", "query_dataset", ")", "\n", "query_dataloader", "=", "DataLoader", "(", "query_dataset", ",", "sampler", "=", "query_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n", "code_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "codebase_file", ",", "pool", ")", "\n", "code_sampler", "=", "SequentialSampler", "(", "code_dataset", ")", "\n", "code_dataloader", "=", "DataLoader", "(", "code_dataset", ",", "sampler", "=", "code_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "eval_when_training", "is", "False", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num queries = %d\"", ",", "len", "(", "query_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num codes = %d\"", ",", "len", "(", "code_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "code_vecs", "=", "[", "]", "\n", "nl_vecs", "=", "[", "]", "\n", "for", "batch", "in", "query_dataloader", ":", "\n", "        ", "nl_inputs", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "nl_vec", "=", "model", "(", "nl_inputs", "=", "nl_inputs", ")", "\n", "nl_vecs", ".", "append", "(", "nl_vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "for", "batch", "in", "code_dataloader", ":", "\n", "        ", "code_inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "attn_mask", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "position_idx", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "code_vec", "=", "model", "(", "code_inputs", "=", "code_inputs", ",", "attn_mask", "=", "attn_mask", ",", "position_idx", "=", "position_idx", ")", "\n", "code_vecs", ".", "append", "(", "code_vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "model", ".", "train", "(", ")", "\n", "code_vecs", "=", "np", ".", "concatenate", "(", "code_vecs", ",", "0", ")", "\n", "nl_vecs", "=", "np", ".", "concatenate", "(", "nl_vecs", ",", "0", ")", "\n", "\n", "scores", "=", "np", ".", "matmul", "(", "nl_vecs", ",", "code_vecs", ".", "T", ")", "\n", "if", "'test'", "in", "file_name", ":", "\n", "        ", "fname", "=", "\"scores\"", "+", "str", "(", "args", ".", "codebase_file", "[", "-", "7", "]", ")", "+", "\".npy\"", "\n", "np", ".", "save", "(", "fname", ",", "scores", ")", "\n", "", "sort_ids", "=", "np", ".", "argsort", "(", "scores", ",", "axis", "=", "-", "1", ",", "kind", "=", "'quicksort'", ",", "order", "=", "None", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "\n", "nl_urls", "=", "[", "]", "\n", "code_urls", "=", "[", "]", "\n", "for", "example", "in", "query_dataset", ".", "examples", ":", "\n", "        ", "temp", "=", "example", ".", "url", "\n", "if", "(", "example", ".", "url", ")", ".", "find", "(", "\"_\"", ")", "!=", "-", "1", ":", "\n", "            ", "loc", "=", "(", "example", ".", "url", ")", ".", "rfind", "(", "\"_\"", ")", "\n", "if", "loc", "+", "3", ">=", "len", "(", "example", ".", "url", ")", ":", "\n", "                ", "temp", "=", "example", ".", "url", "[", ":", "loc", "]", "\n", "", "", "nl_urls", ".", "append", "(", "temp", ")", "\n", "\n", "", "for", "example", "in", "code_dataset", ".", "examples", ":", "\n", "        ", "temp", "=", "example", ".", "url", "\n", "if", "(", "example", ".", "url", ")", ".", "find", "(", "\"_\"", ")", "!=", "-", "1", ":", "\n", "            ", "loc", "=", "(", "example", ".", "url", ")", ".", "rfind", "(", "\"_\"", ")", "\n", "if", "loc", "+", "3", ">=", "len", "(", "example", ".", "url", ")", ":", "\n", "                ", "temp", "=", "example", ".", "url", "[", ":", "loc", "]", "\n", "", "", "code_urls", ".", "append", "(", "temp", ")", "\n", "", "fname", "=", "\"codeurl\"", "+", "str", "(", "args", ".", "codebase_file", "[", "-", "7", "]", ")", "+", "\".npy\"", "\n", "np", ".", "save", "(", "fname", ",", "code_urls", ")", "\n", "ranks", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_curri.test": [[416, 456], ["run_curri.load_and_cache_examples", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "numpy.concatenate", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "batch[].to", "batch[].to", "open", "zip", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "np.concatenate.append", "y_trues.append", "os.path.join", "logit.cpu().numpy", "batch[].to.cpu().numpy", "f.write", "f.write", "lm_loss.mean", "logit.cpu", "batch[].to.cpu"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.load_and_cache_examples"], ["        ", "rank", "=", "0", "\n", "find", "=", "False", "\n", "for", "idx", "in", "sort_id", "[", ":", "1000", "]", ":", "\n", "            ", "if", "find", "is", "False", ":", "\n", "                ", "rank", "+=", "1", "\n", "", "if", "code_urls", "[", "idx", "]", "==", "url", ":", "\n", "                ", "find", "=", "True", "\n", "", "", "if", "find", ":", "\n", "            ", "ranks", ".", "append", "(", "1", "/", "rank", ")", "\n", "", "else", ":", "\n", "            ", "ranks", ".", "append", "(", "0", ")", "\n", "\n", "", "", "result", "=", "{", "\n", "\"eval_mrr\"", ":", "float", "(", "np", ".", "mean", "(", "ranks", ")", ")", "\n", "}", "\n", "\n", "return", "result", "\n", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input training data file (a json file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the MRR(a jsonl file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input test data file to test the MRR(a josnl file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--codebase_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input test data file to codebase (a jsonl file).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--lang\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"language.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path\"", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_curri.main": [[458, 661], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "multiprocessing.Pool", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_curri.set_seed", "os.path.join", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "min", "model.Model", "logger.info", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "os.path.exists", "os.listdir", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "logger.info", "model_class.from_pretrained", "model_class", "torch.distributed.barrier", "run_curri.load_and_cache_examples", "run_curri.train", "os.path.join", "model_class.load_state_dict", "model_class.to", "run_curri.evaluate", "os.path.join", "model_class.load_state_dict", "model_class.to", "run_curri.test", "open", "torch.distributed.barrier", "torch.distributed.barrier", "torch.load", "torch.load", "int", "open", "int", "bool", "torch.cuda.is_available", "[].strip", "[].strip", "idxf.readlines", "stepf.readlines"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.set_seed", "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.load_and_cache_examples", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate", "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.test"], ["help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--nl_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional NL input sequence length after tokenization.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_length\"", ",", "default", "=", "256", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional Code input sequence length after tokenization.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_flow_length\"", ",", "default", "=", "64", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional Data Flow input sequence length after tokenization.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the test set.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--pacing_function\"", ",", "default", "=", "\"linear\"", ",", "type", "=", "str", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "cpu_cont", ")", "\n", "\n", "# print arguments", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# set log", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s -   %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "level", "=", "logging", ".", "INFO", ")", "\n", "# set device", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "args", ".", "device", "=", "device", "\n", "logger", ".", "info", "(", "\"device: %s, n_gpu: %s\"", ",", "device", ",", "args", ".", "n_gpu", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# build model", "\n", "config", "=", "RobertaConfig", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ")", "\n", "tokenizer", "=", "RobertaTokenizer", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", ")", "\n", "model", "=", "RobertaModel", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "model", "=", "Model", "(", "model", ")", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train", "(", "args", ",", "model", ",", "tokenizer", ",", "pool", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-mrr/model_curri.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ",", "strict", "=", "False", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "args", ".", "eval_data_file", ",", "pool", ")", "\n", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "round", "(", "result", "[", "key", "]", ",", "4", ")", ")", ")", "\n", "\n", "", "", "if", "args", ".", "do_test", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-mrr/model_curri.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ",", "strict", "=", "False", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "args", ".", "test_data_file", ",", "pool", ")", "\n", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "round", "(", "result", "[", "key", "]", ",", "4", ")", ")", ")", "\n", "\n", "", "", "return", "results", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "main", "(", ")", "\n", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run.get_example": [[65, 85], ["run.convert_examples_to_features", "cache[].copy", "tokenizer.tokenize", "cache[].copy", "tokenizer.tokenize", "url_to_code[].split", "url_to_code[].split"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.convert_examples_to_features"], ["class", "InputFeatures", "(", "object", ")", ":", "\n", "    ", "\"\"\"A single training/test features for a example.\"\"\"", "\n", "def", "__init__", "(", "self", ",", "\n", "input_tokens", ",", "\n", "input_ids", ",", "\n", "index", ",", "\n", "label", ",", "\n", "\n", ")", ":", "\n", "        ", "self", ".", "input_tokens", "=", "input_tokens", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "label", "=", "label", "\n", "\n", "\n", "", "", "def", "convert_examples_to_features", "(", "js", ",", "tokenizer", ",", "args", ")", ":", "\n", "#source", "\n", "    ", "code", "=", "' '", ".", "join", "(", "js", "[", "'code'", "]", ".", "split", "(", ")", ")", "\n", "code_tokens", "=", "tokenizer", ".", "tokenize", "(", "code", ")", "[", ":", "args", ".", "block_size", "-", "2", "]", "\n", "source_tokens", "=", "[", "tokenizer", ".", "cls_token", "]", "+", "code_tokens", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "source_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "source_tokens", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run.load_and_cache_examples": [[171, 174], ["run.TextDataset"], "function", ["None"], ["", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.InputFeatures.__init__": [[89, 102], ["None"], "methods", ["None"], ["for", "d", "in", "DFG", ":", "\n", "            ", "if", "len", "(", "d", "[", "-", "1", "]", ")", "!=", "0", ":", "\n", "                ", "indexs", ".", "add", "(", "d", "[", "1", "]", ")", "\n", "", "for", "x", "in", "d", "[", "-", "1", "]", ":", "\n", "                ", "indexs", ".", "add", "(", "x", ")", "\n", "", "", "new_DFG", "=", "[", "]", "\n", "for", "d", "in", "DFG", ":", "\n", "            ", "if", "d", "[", "1", "]", "in", "indexs", ":", "\n", "                ", "new_DFG", ".", "append", "(", "d", ")", "\n", "", "", "dfg", "=", "new_DFG", "\n", "", "except", ":", "\n", "        ", "dfg", "=", "[", "]", "\n", "", "return", "code_tokens", ",", "dfg", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.TextDataset.__init__": [[123, 162], ["logger.info", "open", "pool.map", "[].split", "open", "open", "random.sample", "tqdm.tqdm.tqdm", "line.strip.strip.strip", "json.loads", "line.strip.strip.strip", "line.strip.strip.split", "random.sample.append", "int", "len", "file_path.split", "len", "index_filename.split"], "methods", ["None"], ["self", ".", "nl_tokens", "=", "nl_tokens", "\n", "self", ".", "nl_ids", "=", "nl_ids", "\n", "self", ".", "url", "=", "url", "\n", "\n", "\n", "", "", "def", "convert_examples_to_features", "(", "item", ")", ":", "\n", "    ", "js", ",", "tokenizer", ",", "args", "=", "item", "\n", "# code", "\n", "parser", "=", "parsers", "[", "args", ".", "lang", "]", "\n", "# extract data flow", "\n", "code_tokens", ",", "dfg", "=", "extract_dataflow", "(", "js", "[", "'original_string'", "]", ",", "parser", ",", "args", ".", "lang", ")", "\n", "code_tokens", "=", "[", "tokenizer", ".", "tokenize", "(", "'@ '", "+", "x", ")", "[", "1", ":", "]", "if", "idx", "!=", "0", "else", "tokenizer", ".", "tokenize", "(", "x", ")", "for", "idx", ",", "x", "in", "\n", "enumerate", "(", "code_tokens", ")", "]", "\n", "ori2cur_pos", "=", "{", "}", "\n", "ori2cur_pos", "[", "-", "1", "]", "=", "(", "0", ",", "0", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "code_tokens", ")", ")", ":", "\n", "        ", "ori2cur_pos", "[", "i", "]", "=", "(", "ori2cur_pos", "[", "i", "-", "1", "]", "[", "1", "]", ",", "ori2cur_pos", "[", "i", "-", "1", "]", "[", "1", "]", "+", "len", "(", "code_tokens", "[", "i", "]", ")", ")", "\n", "", "code_tokens", "=", "[", "y", "for", "x", "in", "code_tokens", "for", "y", "in", "x", "]", "\n", "# truncating", "\n", "code_tokens", "=", "code_tokens", "[", ":", "args", ".", "code_length", "+", "args", ".", "data_flow_length", "-", "2", "-", "min", "(", "len", "(", "dfg", ")", ",", "args", ".", "data_flow_length", ")", "]", "\n", "code_tokens", "=", "[", "tokenizer", ".", "cls_token", "]", "+", "code_tokens", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "code_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "code_tokens", ")", "\n", "position_idx", "=", "[", "i", "+", "tokenizer", ".", "pad_token_id", "+", "1", "for", "i", "in", "range", "(", "len", "(", "code_tokens", ")", ")", "]", "\n", "dfg", "=", "dfg", "[", ":", "args", ".", "code_length", "+", "args", ".", "data_flow_length", "-", "len", "(", "code_tokens", ")", "]", "\n", "code_tokens", "+=", "[", "x", "[", "0", "]", "for", "x", "in", "dfg", "]", "\n", "position_idx", "+=", "[", "0", "for", "x", "in", "dfg", "]", "\n", "code_ids", "+=", "[", "tokenizer", ".", "unk_token_id", "for", "x", "in", "dfg", "]", "\n", "padding_length", "=", "args", ".", "code_length", "+", "args", ".", "data_flow_length", "-", "len", "(", "code_ids", ")", "\n", "position_idx", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n", "code_ids", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n", "# reindex", "\n", "reverse_index", "=", "{", "}", "\n", "for", "idx", ",", "x", "in", "enumerate", "(", "dfg", ")", ":", "\n", "        ", "reverse_index", "[", "x", "[", "1", "]", "]", "=", "idx", "\n", "", "for", "idx", ",", "x", "in", "enumerate", "(", "dfg", ")", ":", "\n", "        ", "dfg", "[", "idx", "]", "=", "x", "[", ":", "-", "1", "]", "+", "(", "[", "reverse_index", "[", "i", "]", "for", "i", "in", "x", "[", "-", "1", "]", "if", "i", "in", "reverse_index", "]", ",", ")", "\n", "", "dfg_to_dfg", "=", "[", "x", "[", "-", "1", "]", "for", "x", "in", "dfg", "]", "\n", "dfg_to_code", "=", "[", "ori2cur_pos", "[", "x", "[", "1", "]", "]", "for", "x", "in", "dfg", "]", "\n", "length", "=", "len", "(", "[", "tokenizer", ".", "cls_token", "]", ")", "\n", "dfg_to_code", "=", "[", "(", "x", "[", "0", "]", "+", "length", ",", "x", "[", "1", "]", "+", "length", ")", "for", "x", "in", "dfg_to_code", "]", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.TextDataset.__len__": [[164, 166], ["len"], "methods", ["None"], ["nl", "=", "' '", ".", "join", "(", "js", "[", "'docstring_tokens'", "]", ")", "\n", "nl_tokens", "=", "tokenizer", ".", "tokenize", "(", "nl", ")", "[", ":", "args", ".", "nl_length", "-", "2", "]", "\n", "nl_tokens", "=", "[", "tokenizer", ".", "cls_token", "]", "+", "nl_tokens", "+", "[", "tokenizer", ".", "sep_token", "]", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.TextDataset.__getitem__": [[167, 170], ["torch.tensor", "torch.tensor"], "methods", ["None"], ["nl_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "nl_tokens", ")", "\n", "padding_length", "=", "args", ".", "nl_length", "-", "len", "(", "nl_ids", ")", "\n", "nl_ids", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.get_example": [[65, 85], ["run_large.convert_examples_to_features", "cache[].copy", "tokenizer.tokenize", "cache[].copy", "tokenizer.tokenize", "url_to_code[].split", "url_to_code[].split"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.convert_examples_to_features"], ["", "def", "extract_dataflow", "(", "code", ",", "parser", ",", "lang", ")", ":", "\n", "# remove comments", "\n", "    ", "try", ":", "\n", "        ", "code", "=", "remove_comments_and_docstrings", "(", "code", ",", "lang", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "# obtain dataflow", "\n", "", "if", "lang", "==", "\"php\"", ":", "\n", "        ", "code", "=", "\"<?php\"", "+", "code", "+", "\"?>\"", "\n", "", "try", ":", "\n", "        ", "tree", "=", "parser", "[", "0", "]", ".", "parse", "(", "bytes", "(", "code", ",", "'utf8'", ")", ")", "\n", "root_node", "=", "tree", ".", "root_node", "\n", "tokens_index", "=", "tree_to_token_index", "(", "root_node", ")", "\n", "code", "=", "code", ".", "split", "(", "'\\n'", ")", "\n", "code_tokens", "=", "[", "index_to_code_token", "(", "x", ",", "code", ")", "for", "x", "in", "tokens_index", "]", "\n", "index_to_code", "=", "{", "}", "\n", "for", "idx", ",", "(", "index", ",", "code", ")", "in", "enumerate", "(", "zip", "(", "tokens_index", ",", "code_tokens", ")", ")", ":", "\n", "            ", "index_to_code", "[", "index", "]", "=", "(", "idx", ",", "code", ")", "\n", "", "try", ":", "\n", "            ", "DFG", ",", "_", "=", "parser", "[", "1", "]", "(", "root_node", ",", "index_to_code", ",", "{", "}", ")", "\n", "", "except", ":", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.convert_examples_to_features": [[103, 121], ["tokenizer.convert_tokens_to_ids", "tokenizer.convert_tokens_to_ids", "run_large.InputFeatures", "len", "len"], "function", ["None"], ["\n", "", "class", "InputFeatures", "(", "object", ")", ":", "\n", "    ", "\"\"\"A single training/test features for a example.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "\n", "code_tokens", ",", "\n", "code_ids", ",", "\n", "position_idx", ",", "\n", "dfg_to_code", ",", "\n", "dfg_to_dfg", ",", "\n", "nl_tokens", ",", "\n", "nl_ids", ",", "\n", "url", ",", "\n", "\n", ")", ":", "\n", "        ", "self", ".", "code_tokens", "=", "code_tokens", "\n", "self", ".", "code_ids", "=", "code_ids", "\n", "self", ".", "position_idx", "=", "position_idx", "\n", "self", ".", "dfg_to_code", "=", "dfg_to_code", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.load_and_cache_examples": [[172, 175], ["run_large.TextDataset"], "function", ["None"], ["\n", "\n", "", "class", "TextDataset", "(", "Dataset", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ",", "file_path", "=", "None", ",", "pool", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.set_seed": [[176, 183], ["random.seed", "str", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["        ", "self", ".", "args", "=", "args", "\n", "prefix", "=", "file_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "[", ":", "-", "6", "]", "\n", "cache_file", "=", "args", ".", "output_dir", "+", "'/'", "+", "prefix", "+", "'.pkl'", "\n", "if", "os", ".", "path", ".", "exists", "(", "cache_file", ")", ":", "\n", "            ", "self", ".", "examples", "=", "pickle", ".", "load", "(", "open", "(", "cache_file", ",", "'rb'", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "examples", "=", "[", "]", "\n", "data", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.train": [[184, 319], ["torch.utils.data.DataLoader", "len", "len", "len", "torch.nn.parallel.DistributedDataParallel.to", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.path.exists", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "run_large.set_seed", "range", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "len", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "transformers.get_linear_schedule_with_warmup.load_state_dict", "transformers.AdamW.load_state_dict", "len", "int", "tqdm.tqdm", "enumerate", "torch.load", "torch.load", "batch[].to", "batch[].to", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "loss.mean.item", "round", "tqdm.tqdm.set_description", "train_iterator.close", "ImportError", "torch.distributed.get_world_size", "len", "loss.mean.mean", "torch.nn.utils.clip_grad_norm_", "loss.mean.backward", "torch.nn.utils.clip_grad_norm_", "transformers.AdamW.step", "transformers.AdamW.zero_grad", "transformers.get_linear_schedule_with_warmup.step", "round", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "amp.scale_loss", "scaled_loss.backward", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "numpy.exp", "any", "run_large.evaluate", "logger.info", "logger.info", "logger.info", "os.path.join", "os.path.join", "torch.save", "logger.info", "round", "os.path.exists", "os.makedirs", "hasattr", "model_to_save.state_dict"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.set_seed", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate"], ["with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "data", ".", "append", "(", "(", "js", ",", "tokenizer", ",", "args", ")", ")", "\n", "", "", "self", ".", "examples", "=", "pool", ".", "map", "(", "convert_examples_to_features", ",", "tqdm", "(", "data", ",", "total", "=", "len", "(", "data", ")", ")", ")", "\n", "pickle", ".", "dump", "(", "self", ".", "examples", ",", "open", "(", "cache_file", ",", "'wb'", ")", ")", "\n", "", "'''\n        if 'train' in file_path:\n            for idx, example in enumerate(self.examples[:3]):\n                logger.info(\"*** Example ***\")\n                logger.info(\"idx: {}\".format(idx))\n                logger.info(\"code_tokens: {}\".format([x.replace('\\u0120','_') for x in example.code_tokens]))\n                logger.info(\"code_ids: {}\".format(' '.join(map(str, example.code_ids))))\n                logger.info(\"position_idx: {}\".format(example.position_idx))\n                logger.info(\"dfg_to_code: {}\".format(' '.join(map(str, example.dfg_to_code))))\n                logger.info(\"dfg_to_dfg: {}\".format(' '.join(map(str, example.dfg_to_dfg))))                \n                logger.info(\"nl_tokens: {}\".format([x.replace('\\u0120','_') for x in example.nl_tokens]))\n                logger.info(\"nl_ids: {}\".format(' '.join(map(str, example.nl_ids))))          \n        '''", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "# calculate graph-guided masked function", "\n", "        ", "attn_mask", "=", "np", ".", "zeros", "(", "(", "self", ".", "args", ".", "code_length", "+", "self", ".", "args", ".", "data_flow_length", ",", "\n", "self", ".", "args", ".", "code_length", "+", "self", ".", "args", ".", "data_flow_length", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "# calculate begin index of node and max length of input", "\n", "node_index", "=", "sum", "(", "[", "i", ">", "1", "for", "i", "in", "self", ".", "examples", "[", "item", "]", ".", "position_idx", "]", ")", "\n", "max_length", "=", "sum", "(", "[", "i", "!=", "1", "for", "i", "in", "self", ".", "examples", "[", "item", "]", ".", "position_idx", "]", ")", "\n", "# sequence can attend to sequence", "\n", "attn_mask", "[", ":", "node_index", ",", ":", "node_index", "]", "=", "True", "\n", "# special tokens attend to all tokens", "\n", "for", "idx", ",", "i", "in", "enumerate", "(", "self", ".", "examples", "[", "item", "]", ".", "code_ids", ")", ":", "\n", "            ", "if", "i", "in", "[", "0", ",", "2", "]", ":", "\n", "                ", "attn_mask", "[", "idx", ",", ":", "max_length", "]", "=", "True", "\n", "# nodes attend to code tokens that are identified from", "\n", "", "", "for", "idx", ",", "(", "a", ",", "b", ")", "in", "enumerate", "(", "self", ".", "examples", "[", "item", "]", ".", "dfg_to_code", ")", ":", "\n", "            ", "if", "a", "<", "node_index", "and", "b", "<", "node_index", ":", "\n", "                ", "attn_mask", "[", "idx", "+", "node_index", ",", "a", ":", "b", "]", "=", "True", "\n", "attn_mask", "[", "a", ":", "b", ",", "idx", "+", "node_index", "]", "=", "True", "\n", "# nodes attend to adjacent nodes", "\n", "", "", "for", "idx", ",", "nodes", "in", "enumerate", "(", "self", ".", "examples", "[", "item", "]", ".", "dfg_to_dfg", ")", ":", "\n", "            ", "for", "a", "in", "nodes", ":", "\n", "                ", "if", "a", "+", "node_index", "<", "len", "(", "self", ".", "examples", "[", "item", "]", ".", "position_idx", ")", ":", "\n", "                    ", "attn_mask", "[", "idx", "+", "node_index", ",", "a", "+", "node_index", "]", "=", "True", "\n", "\n", "", "", "", "return", "(", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ".", "code_ids", ")", ",", "\n", "torch", ".", "tensor", "(", "attn_mask", ")", ",", "\n", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ".", "position_idx", ")", ",", "\n", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ".", "nl_ids", ")", ")", "\n", "\n", "\n", "", "", "def", "set_seed", "(", "seed", "=", "42", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "'PYHTONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "\n", "", "def", "train", "(", "args", ",", "model", ",", "tokenizer", ",", "pool", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "# get training dataset", "\n", "train_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "train_data_file", ",", "pool", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n", "# get optimizer and scheduler", "\n", "optimizer", "=", "AdamW", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "1e-8", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "0", ",", "\n", "num_training_steps", "=", "len", "(", "train_dataloader", ")", "*", "args", ".", "num_train_epochs", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "train_batch_size", "//", "args", ".", "n_gpu", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size  = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "len", "(", "train_dataloader", ")", "*", "args", ".", "num_train_epochs", ")", "\n", "\n", "# model.resize_token_embeddings(len(tokenizer))", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "tr_num", ",", "tr_loss", ",", "best_mrr", "=", "0", ",", "0", ",", "0", "\n", "for", "idx", "in", "range", "(", "args", ".", "num_train_epochs", ")", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "# get inputs", "\n", "            ", "code_inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "attn_mask", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "position_idx", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "nl_inputs", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "# get code and nl vectors", "\n", "code_vec", "=", "model", "(", "code_inputs", "=", "code_inputs", ",", "attn_mask", "=", "attn_mask", ",", "position_idx", "=", "position_idx", ")", "\n", "nl_vec", "=", "model", "(", "nl_inputs", "=", "nl_inputs", ")", "\n", "\n", "# calculate scores and loss", "\n", "scores", "=", "torch", ".", "einsum", "(", "\"ab,cb->ac\"", ",", "nl_vec", ",", "code_vec", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "scores", ",", "torch", ".", "arange", "(", "code_inputs", ".", "size", "(", "0", ")", ",", "device", "=", "scores", ".", "device", ")", ")", "\n", "\n", "# report loss", "\n", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "tr_num", "+=", "1", "\n", "if", "(", "step", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"epoch {} step {} loss {}\"", ".", "format", "(", "idx", ",", "step", "+", "1", ",", "round", "(", "tr_loss", "/", "tr_num", ",", "5", ")", ")", ")", "\n", "tr_loss", "=", "0", "\n", "tr_num", "=", "0", "\n", "\n", "# backward", "\n", "", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "# evaluate", "\n", "", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "args", ".", "eval_data_file", ",", "pool", ",", "eval_when_training", "=", "True", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "round", "(", "value", ",", "4", ")", ")", "\n", "\n", "# save best model", "\n", "", "if", "results", "[", "'eval_mrr'", "]", ">", "best_mrr", ":", "\n", "            ", "best_mrr", "=", "results", "[", "'eval_mrr'", "]", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "logger", ".", "info", "(", "\"  Best mrr:%s\"", ",", "round", "(", "best_mrr", ",", "4", ")", ")", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "\n", "checkpoint_prefix", "=", "'checkpoint-best-mrr'", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.evaluate": [[321, 392], ["run_large.load_and_cache_examples", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "numpy.concatenate", "numpy.concatenate", "range", "recall_score", "precision_score", "f1_score", "logger.info", "sorted", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "batch[].to", "batch[].to", "recall_score", "precision_score", "f1_score", "float", "float", "float", "result.keys", "logger.info", "os.path.exists", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "np.concatenate.append", "np.concatenate.append", "str", "logit.cpu().numpy", "batch[].to.cpu().numpy", "round", "lm_loss.mean", "logit.cpu", "batch[].to.cpu"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.load_and_cache_examples"], ["if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'{}'", ".", "format", "(", "'model_large.bin'", ")", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_dir", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "\n", "", "", "", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "file_name", ",", "pool", ",", "eval_when_training", "=", "False", ")", ":", "\n", "    ", "query_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "file_name", ",", "pool", ")", "\n", "query_sampler", "=", "SequentialSampler", "(", "query_dataset", ")", "\n", "query_dataloader", "=", "DataLoader", "(", "query_dataset", ",", "sampler", "=", "query_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n", "code_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "codebase_file", ",", "pool", ")", "\n", "code_sampler", "=", "SequentialSampler", "(", "code_dataset", ")", "\n", "code_dataloader", "=", "DataLoader", "(", "code_dataset", ",", "sampler", "=", "code_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "eval_when_training", "is", "False", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num queries = %d\"", ",", "len", "(", "query_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num codes = %d\"", ",", "len", "(", "code_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "code_vecs", "=", "[", "]", "\n", "nl_vecs", "=", "[", "]", "\n", "for", "batch", "in", "query_dataloader", ":", "\n", "        ", "nl_inputs", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "nl_vec", "=", "model", "(", "nl_inputs", "=", "nl_inputs", ")", "\n", "nl_vecs", ".", "append", "(", "nl_vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "for", "batch", "in", "code_dataloader", ":", "\n", "        ", "code_inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "attn_mask", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "position_idx", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "code_vec", "=", "model", "(", "code_inputs", "=", "code_inputs", ",", "attn_mask", "=", "attn_mask", ",", "position_idx", "=", "position_idx", ")", "\n", "code_vecs", ".", "append", "(", "code_vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "model", ".", "train", "(", ")", "\n", "code_vecs", "=", "np", ".", "concatenate", "(", "code_vecs", ",", "0", ")", "\n", "nl_vecs", "=", "np", ".", "concatenate", "(", "nl_vecs", ",", "0", ")", "\n", "\n", "scores", "=", "np", ".", "matmul", "(", "nl_vecs", ",", "code_vecs", ".", "T", ")", "\n", "if", "'test'", "in", "file_name", ":", "\n", "        ", "fname", "=", "\"scores\"", "+", "file_name", "[", "-", "5", "]", "+", "\".npy\"", "\n", "np", ".", "save", "(", "fname", ",", "scores", ")", "\n", "", "sort_ids", "=", "np", ".", "argsort", "(", "scores", ",", "axis", "=", "-", "1", ",", "kind", "=", "'quicksort'", ",", "order", "=", "None", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "\n", "nl_urls", "=", "[", "]", "\n", "code_urls", "=", "[", "]", "\n", "for", "example", "in", "query_dataset", ".", "examples", ":", "\n", "        ", "temp", "=", "example", ".", "url", "\n", "if", "(", "example", ".", "url", ")", ".", "find", "(", "\"_\"", ")", "!=", "-", "1", ":", "\n", "            ", "loc", "=", "(", "example", ".", "url", ")", ".", "rfind", "(", "\"_\"", ")", "\n", "if", "loc", "+", "3", ">=", "len", "(", "example", ".", "url", ")", ":", "\n", "                ", "temp", "=", "example", ".", "url", "[", ":", "loc", "]", "\n", "", "", "nl_urls", ".", "append", "(", "temp", ")", "\n", "\n", "", "for", "example", "in", "code_dataset", ".", "examples", ":", "\n", "        ", "temp", "=", "example", ".", "url", "\n", "if", "(", "example", ".", "url", ")", ".", "find", "(", "\"_\"", ")", "!=", "-", "1", ":", "\n", "            ", "loc", "=", "(", "example", ".", "url", ")", ".", "rfind", "(", "\"_\"", ")", "\n", "if", "loc", "+", "3", ">=", "len", "(", "example", ".", "url", ")", ":", "\n", "                ", "temp", "=", "example", ".", "url", "[", ":", "loc", "]", "\n", "", "", "code_urls", ".", "append", "(", "temp", ")", "\n", "\n", "", "ranks", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.test": [[393, 434], ["run_large.load_and_cache_examples", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "numpy.concatenate", "numpy.save", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "batch[].to", "batch[].to", "open", "zip", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "np.concatenate.append", "y_trues.append", "str", "os.path.join", "logit.cpu().numpy", "batch[].to.cpu().numpy", "f.write", "f.write", "lm_loss.mean", "logit.cpu", "batch[].to.cpu"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.load_and_cache_examples"], ["for", "url", ",", "sort_id", "in", "zip", "(", "nl_urls", ",", "sort_ids", ")", ":", "\n", "        ", "rank", "=", "0", "\n", "find", "=", "False", "\n", "for", "idx", "in", "sort_id", "[", ":", "1000", "]", ":", "\n", "            ", "if", "find", "is", "False", ":", "\n", "                ", "rank", "+=", "1", "\n", "", "if", "code_urls", "[", "idx", "]", "==", "url", ":", "\n", "                ", "find", "=", "True", "\n", "", "", "if", "find", ":", "\n", "            ", "ranks", ".", "append", "(", "1", "/", "rank", ")", "\n", "", "else", ":", "\n", "            ", "ranks", ".", "append", "(", "0", ")", "\n", "\n", "", "", "result", "=", "{", "\n", "\"eval_mrr\"", ":", "float", "(", "np", ".", "mean", "(", "ranks", ")", ")", "\n", "}", "\n", "\n", "return", "result", "\n", "\n", "\n", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input training data file (a json file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the MRR(a jsonl file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input test data file to test the MRR(a josnl file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--codebase_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input test data file to codebase (a jsonl file).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--lang\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"language.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path\"", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.main": [[435, 641], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "multiprocessing.Pool", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_large.set_seed", "os.path.join", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "min", "model.Model", "logger.info", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "os.path.exists", "os.listdir", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "logger.info", "model_class.from_pretrained", "model_class", "torch.distributed.barrier", "run_large.load_and_cache_examples", "run_large.train", "os.path.join", "model_class.load_state_dict", "model_class.to", "run_large.evaluate", "os.path.join", "model_class.load_state_dict", "model_class.to", "run_large.test", "open", "torch.distributed.barrier", "torch.distributed.barrier", "torch.load", "torch.load", "int", "open", "int", "bool", "torch.cuda.is_available", "[].strip", "[].strip", "idxf.readlines", "stepf.readlines"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.set_seed", "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.load_and_cache_examples", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate", "home.repos.pwc.inspect_result.wangdeze18_DACL.code.run_large.test"], ["parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--nl_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional NL input sequence length after tokenization.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_length\"", ",", "default", "=", "256", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional Code input sequence length after tokenization.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_flow_length\"", ",", "default", "=", "64", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional Data Flow input sequence length after tokenization.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the test set.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "cpu_cont", ")", "\n", "\n", "# print arguments", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# set log", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s -   %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "level", "=", "logging", ".", "INFO", ")", "\n", "# set device", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "args", ".", "device", "=", "device", "\n", "logger", ".", "info", "(", "\"device: %s, n_gpu: %s\"", ",", "device", ",", "args", ".", "n_gpu", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# build model", "\n", "config", "=", "RobertaConfig", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ")", "\n", "tokenizer", "=", "RobertaTokenizer", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", ")", "\n", "model", "=", "RobertaModel", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "model", "=", "Model", "(", "model", ")", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train", "(", "args", ",", "model", ",", "tokenizer", ",", "pool", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-mrr/model_large.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ",", "strict", "=", "False", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "args", ".", "eval_data_file", ",", "pool", ")", "\n", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "round", "(", "result", "[", "key", "]", ",", "4", ")", ")", ")", "\n", "\n", "", "", "if", "args", ".", "do_test", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-mrr/model_large.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ",", "strict", "=", "False", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "args", ".", "test_data_file", ",", "pool", ")", "\n", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "round", "(", "result", "[", "key", "]", ",", "4", ")", ")", ")", "\n", "\n", "", "", "return", "results", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "main", "(", ")", "\n", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.linear": [[3, 5], ["None"], "function", ["None"], ["def", "linear", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "x", "*", "(", "(", "1", "-", "c0", ")", "/", "t", ")", ")", "+", "c0", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.root_2": [[6, 8], ["None"], "function", ["None"], ["", "def", "root_2", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "(", "x", "*", "(", "(", "1", "-", "(", "c0", "**", "2.0", ")", ")", "/", "t", ")", ")", "+", "(", "c0", "**", "2.0", ")", ")", "**", "(", "1.", "/", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.root_5": [[9, 11], ["None"], "function", ["None"], ["", "def", "root_5", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "(", "x", "*", "(", "(", "1", "-", "(", "c0", "**", "5.0", ")", ")", "/", "t", ")", ")", "+", "(", "c0", "**", "5.0", ")", ")", "**", "(", "1.", "/", "5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.root_10": [[12, 14], ["None"], "function", ["None"], ["", "def", "root_10", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "(", "x", "*", "(", "(", "1", "-", "(", "c0", "**", "10.0", ")", ")", "/", "t", ")", ")", "+", "(", "c0", "**", "10.0", ")", ")", "**", "(", "1.", "/", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.root_20": [[15, 17], ["None"], "function", ["None"], ["", "def", "root_20", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "(", "x", "*", "(", "(", "1", "-", "(", "c0", "**", "20.0", ")", ")", "/", "t", ")", ")", "+", "(", "c0", "**", "20.0", ")", ")", "**", "(", "1.", "/", "20", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.root_50": [[18, 20], ["None"], "function", ["None"], ["", "def", "root_50", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "(", "x", "*", "(", "(", "1", "-", "(", "c0", "**", "50.0", ")", ")", "/", "t", ")", ")", "+", "(", "c0", "**", "50.0", ")", ")", "**", "(", "1.", "/", "50", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.geom_progression": [[21, 23], ["math.log", "math.log", "math.log"], "function", ["None"], ["", "def", "geom_progression", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "2.0", "**", "(", "(", "x", "*", "(", "(", "math", ".", "log", "(", "1", ",", "2.0", ")", "-", "math", ".", "log", "(", "c0", ",", "2.0", ")", ")", "/", "t", ")", ")", "+", "math", ".", "log", "(", "c0", ",", "2.0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.quadratic": [[24, 26], ["None"], "function", ["None"], ["", "def", "quadratic", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "x", "*", "(", "(", "1", "-", "c0", "**", "1.54", ")", "/", "t", ")", ")", "**", "2", "+", "c0", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.cubic": [[27, 29], ["None"], "function", ["None"], ["", "def", "cubic", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "(", "x", "*", "(", "(", "1", "-", "c0", "**", "1.87", ")", "/", "t", ")", ")", "**", "3", "+", "c0", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step": [[30, 37], ["None"], "function", ["None"], ["", "def", "step", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "if", "x", "<=", "t", "*", "0.33", ":", "\n", "\t\t", "return", "0.33", "\n", "", "elif", "x", ">", "t", "*", "0.33", "and", "x", "<=", "t", "*", "0.66", ":", "\n", "\t\t", "return", "0.66", "\n", "", "else", ":", "\n", "\t\t", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.standard_training": [[38, 40], ["None"], "function", ["None"], ["", "", "def", "standard_training", "(", "x", ",", "t", ",", "c0", ")", ":", "\n", "\t", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.sumscores.builddataset": [[14, 22], ["open", "line.strip.strip", "json.loads", "examples.append"], "function", ["None"], ["def", "builddataset", "(", "file_path", ")", ":", "\n", "    ", "examples", "=", "[", "]", "\n", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "examples", ".", "append", "(", "js", "[", "'url'", "]", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.model.Model.__init__": [[6, 9], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.TextDataset.__init__"], ["from", "torch", ".", "autograd", "import", "Variable", "\n", "import", "copy", "\n", "import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "from", "torch", ".", "nn", "import", "CrossEntropyLoss", ",", "MSELoss", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.model.Model.forward": [[10, 22], ["position_idx.eq", "position_idx.ge", "model.Model.encoder.embeddings.word_embeddings", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "model.Model.encoder", "model.Model.encoder", "nodes_to_token_mask.sum", "nl_inputs.ne"], "methods", ["None"], ["\n", "\n", "class", "TripletLoss", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Triplet loss with hard positive/negative mining.\n\n    Reference:\n        Hermans et al. In Defense of the Triplet Loss for Person Re-Identification. arXiv:1703.07737.\n\n    Imported from `<https://github.com/Cysu/open-reid/blob/master/reid/loss/triplet.py>`_.\n\n    Args:\n        margin (float, optional): margin for triplet. Default is 0.3.\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.convert_score.builddataset": [[14, 22], ["open", "line.strip.strip", "json.loads", "examples.append"], "function", ["None"], ["def", "builddataset", "(", "file_path", ")", ":", "\n", "    ", "examples", "=", "[", "]", "\n", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "examples", ".", "append", "(", "js", "[", "'url'", "]", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_curri.InputFeatures.__init__": [[108, 127], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "code_tokens", ",", "\n", "code_ids", ",", "\n", "position_idx", ",", "\n", "dfg_to_code", ",", "\n", "dfg_to_dfg", ",", "\n", "nl_tokens", ",", "\n", "nl_ids", ",", "\n", "url", ",", "\n", "\n", ")", ":", "\n", "        ", "self", ".", "code_tokens", "=", "code_tokens", "\n", "self", ".", "code_ids", "=", "code_ids", "\n", "self", ".", "position_idx", "=", "position_idx", "\n", "self", ".", "dfg_to_code", "=", "dfg_to_code", "\n", "self", ".", "dfg_to_dfg", "=", "dfg_to_dfg", "\n", "self", ".", "nl_tokens", "=", "nl_tokens", "\n", "self", ".", "nl_ids", "=", "nl_ids", "\n", "self", ".", "url", "=", "url", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_curri.TextDataset.__init__": [[176, 205], ["os.path.exists", "pickle.load", "pool.map", "pickle.dump", "file_path.split", "open", "open", "tqdm.tqdm.tqdm", "open", "line.strip.strip.strip", "json.loads", "data.append", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ",", "file_path", "=", "None", ",", "pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "prefix", "=", "file_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "[", ":", "-", "6", "]", "\n", "cache_file", "=", "args", ".", "output_dir", "+", "'/'", "+", "prefix", "+", "'.pkl'", "\n", "if", "os", ".", "path", ".", "exists", "(", "cache_file", ")", ":", "\n", "            ", "self", ".", "examples", "=", "pickle", ".", "load", "(", "open", "(", "cache_file", ",", "'rb'", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "examples", "=", "[", "]", "\n", "data", "=", "[", "]", "\n", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "data", ".", "append", "(", "(", "js", ",", "tokenizer", ",", "args", ")", ")", "\n", "", "", "self", ".", "examples", "=", "pool", ".", "map", "(", "convert_examples_to_features", ",", "tqdm", "(", "data", ",", "total", "=", "len", "(", "data", ")", ")", ")", "\n", "pickle", ".", "dump", "(", "self", ".", "examples", ",", "open", "(", "cache_file", ",", "'wb'", ")", ")", "\n", "", "'''\n        if 'train' in file_path:\n            for idx, example in enumerate(self.examples[:3]):\n                logger.info(\"*** Example ***\")\n                logger.info(\"idx: {}\".format(idx))\n                logger.info(\"code_tokens: {}\".format([x.replace('\\u0120','_') for x in example.code_tokens]))\n                logger.info(\"code_ids: {}\".format(' '.join(map(str, example.code_ids))))\n                logger.info(\"position_idx: {}\".format(example.position_idx))\n                logger.info(\"dfg_to_code: {}\".format(' '.join(map(str, example.dfg_to_code))))\n                logger.info(\"dfg_to_dfg: {}\".format(' '.join(map(str, example.dfg_to_dfg))))                \n                logger.info(\"nl_tokens: {}\".format([x.replace('\\u0120','_') for x in example.nl_tokens]))\n                logger.info(\"nl_ids: {}\".format(' '.join(map(str, example.nl_ids))))          \n        '''", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_curri.TextDataset.__len__": [[206, 208], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_curri.TextDataset.__getitem__": [[209, 237], ["numpy.zeros", "sum", "sum", "enumerate", "enumerate", "enumerate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "# calculate graph-guided masked function", "\n", "        ", "attn_mask", "=", "np", ".", "zeros", "(", "(", "self", ".", "args", ".", "code_length", "+", "self", ".", "args", ".", "data_flow_length", ",", "\n", "self", ".", "args", ".", "code_length", "+", "self", ".", "args", ".", "data_flow_length", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "# calculate begin index of node and max length of input", "\n", "node_index", "=", "sum", "(", "[", "i", ">", "1", "for", "i", "in", "self", ".", "examples", "[", "item", "]", ".", "position_idx", "]", ")", "\n", "max_length", "=", "sum", "(", "[", "i", "!=", "1", "for", "i", "in", "self", ".", "examples", "[", "item", "]", ".", "position_idx", "]", ")", "\n", "# sequence can attend to sequence", "\n", "attn_mask", "[", ":", "node_index", ",", ":", "node_index", "]", "=", "True", "\n", "# special tokens attend to all tokens", "\n", "for", "idx", ",", "i", "in", "enumerate", "(", "self", ".", "examples", "[", "item", "]", ".", "code_ids", ")", ":", "\n", "            ", "if", "i", "in", "[", "0", ",", "2", "]", ":", "\n", "                ", "attn_mask", "[", "idx", ",", ":", "max_length", "]", "=", "True", "\n", "# nodes attend to code tokens that are identified from", "\n", "", "", "for", "idx", ",", "(", "a", ",", "b", ")", "in", "enumerate", "(", "self", ".", "examples", "[", "item", "]", ".", "dfg_to_code", ")", ":", "\n", "            ", "if", "a", "<", "node_index", "and", "b", "<", "node_index", ":", "\n", "                ", "attn_mask", "[", "idx", "+", "node_index", ",", "a", ":", "b", "]", "=", "True", "\n", "attn_mask", "[", "a", ":", "b", ",", "idx", "+", "node_index", "]", "=", "True", "\n", "# nodes attend to adjacent nodes", "\n", "", "", "for", "idx", ",", "nodes", "in", "enumerate", "(", "self", ".", "examples", "[", "item", "]", ".", "dfg_to_dfg", ")", ":", "\n", "            ", "for", "a", "in", "nodes", ":", "\n", "                ", "if", "a", "+", "node_index", "<", "len", "(", "self", ".", "examples", "[", "item", "]", ".", "position_idx", ")", ":", "\n", "                    ", "attn_mask", "[", "idx", "+", "node_index", ",", "a", "+", "node_index", "]", "=", "True", "\n", "\n", "", "", "", "return", "(", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ".", "code_ids", ")", ",", "\n", "torch", ".", "tensor", "(", "attn_mask", ")", ",", "\n", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ".", "position_idx", ")", ",", "\n", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ".", "nl_ids", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_curri.extract_dataflow": [[66, 103], ["parser.remove_comments_and_docstrings", "parser[].parse", "parser.tree_to_token_index", "code.split.split", "enumerate", "sorted", "set", "bytes", "parser.index_to_code_token", "zip", "len", "set.add", "set.add", "new_DFG.append"], "function", ["None"], ["", "def", "extract_dataflow", "(", "code", ",", "parser", ",", "lang", ")", ":", "\n", "# remove comments", "\n", "    ", "try", ":", "\n", "        ", "code", "=", "remove_comments_and_docstrings", "(", "code", ",", "lang", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "# obtain dataflow", "\n", "", "if", "lang", "==", "\"php\"", ":", "\n", "        ", "code", "=", "\"<?php\"", "+", "code", "+", "\"?>\"", "\n", "", "try", ":", "\n", "        ", "tree", "=", "parser", "[", "0", "]", ".", "parse", "(", "bytes", "(", "code", ",", "'utf8'", ")", ")", "\n", "root_node", "=", "tree", ".", "root_node", "\n", "tokens_index", "=", "tree_to_token_index", "(", "root_node", ")", "\n", "code", "=", "code", ".", "split", "(", "'\\n'", ")", "\n", "code_tokens", "=", "[", "index_to_code_token", "(", "x", ",", "code", ")", "for", "x", "in", "tokens_index", "]", "\n", "index_to_code", "=", "{", "}", "\n", "for", "idx", ",", "(", "index", ",", "code", ")", "in", "enumerate", "(", "zip", "(", "tokens_index", ",", "code_tokens", ")", ")", ":", "\n", "            ", "index_to_code", "[", "index", "]", "=", "(", "idx", ",", "code", ")", "\n", "", "try", ":", "\n", "            ", "DFG", ",", "_", "=", "parser", "[", "1", "]", "(", "root_node", ",", "index_to_code", ",", "{", "}", ")", "\n", "", "except", ":", "\n", "            ", "DFG", "=", "[", "]", "\n", "", "DFG", "=", "sorted", "(", "DFG", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "indexs", "=", "set", "(", ")", "\n", "for", "d", "in", "DFG", ":", "\n", "            ", "if", "len", "(", "d", "[", "-", "1", "]", ")", "!=", "0", ":", "\n", "                ", "indexs", ".", "add", "(", "d", "[", "1", "]", ")", "\n", "", "for", "x", "in", "d", "[", "-", "1", "]", ":", "\n", "                ", "indexs", ".", "add", "(", "x", ")", "\n", "", "", "new_DFG", "=", "[", "]", "\n", "for", "d", "in", "DFG", ":", "\n", "            ", "if", "d", "[", "1", "]", "in", "indexs", ":", "\n", "                ", "new_DFG", ".", "append", "(", "d", ")", "\n", "", "", "dfg", "=", "new_DFG", "\n", "", "except", ":", "\n", "        ", "dfg", "=", "[", "]", "\n", "", "return", "code_tokens", ",", "dfg", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_curri.convert_examples_to_features": [[129, 173], ["run_curri.extract_dataflow", "range", "tokenizer.convert_tokens_to_ids", "enumerate", "enumerate", "len", "tokenizer.convert_tokens_to_ids", "run_curri.InputFeatures", "len", "len", "tokenizer.tokenize", "len", "tokenizer.tokenize", "enumerate", "range", "tokenizer.tokenize", "len", "min", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.extract_dataflow"], ["", "", "def", "convert_examples_to_features", "(", "item", ")", ":", "\n", "    ", "js", ",", "tokenizer", ",", "args", "=", "item", "\n", "# code", "\n", "parser", "=", "parsers", "[", "args", ".", "lang", "]", "\n", "# extract data flow", "\n", "code_tokens", ",", "dfg", "=", "extract_dataflow", "(", "js", "[", "'original_string'", "]", ",", "parser", ",", "args", ".", "lang", ")", "\n", "code_tokens", "=", "[", "tokenizer", ".", "tokenize", "(", "'@ '", "+", "x", ")", "[", "1", ":", "]", "if", "idx", "!=", "0", "else", "tokenizer", ".", "tokenize", "(", "x", ")", "for", "idx", ",", "x", "in", "\n", "enumerate", "(", "code_tokens", ")", "]", "\n", "ori2cur_pos", "=", "{", "}", "\n", "ori2cur_pos", "[", "-", "1", "]", "=", "(", "0", ",", "0", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "code_tokens", ")", ")", ":", "\n", "        ", "ori2cur_pos", "[", "i", "]", "=", "(", "ori2cur_pos", "[", "i", "-", "1", "]", "[", "1", "]", ",", "ori2cur_pos", "[", "i", "-", "1", "]", "[", "1", "]", "+", "len", "(", "code_tokens", "[", "i", "]", ")", ")", "\n", "", "code_tokens", "=", "[", "y", "for", "x", "in", "code_tokens", "for", "y", "in", "x", "]", "\n", "# truncating", "\n", "code_tokens", "=", "code_tokens", "[", ":", "args", ".", "code_length", "+", "args", ".", "data_flow_length", "-", "2", "-", "min", "(", "len", "(", "dfg", ")", ",", "args", ".", "data_flow_length", ")", "]", "\n", "code_tokens", "=", "[", "tokenizer", ".", "cls_token", "]", "+", "code_tokens", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "code_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "code_tokens", ")", "\n", "position_idx", "=", "[", "i", "+", "tokenizer", ".", "pad_token_id", "+", "1", "for", "i", "in", "range", "(", "len", "(", "code_tokens", ")", ")", "]", "\n", "dfg", "=", "dfg", "[", ":", "args", ".", "code_length", "+", "args", ".", "data_flow_length", "-", "len", "(", "code_tokens", ")", "]", "\n", "code_tokens", "+=", "[", "x", "[", "0", "]", "for", "x", "in", "dfg", "]", "\n", "position_idx", "+=", "[", "0", "for", "x", "in", "dfg", "]", "\n", "code_ids", "+=", "[", "tokenizer", ".", "unk_token_id", "for", "x", "in", "dfg", "]", "\n", "padding_length", "=", "args", ".", "code_length", "+", "args", ".", "data_flow_length", "-", "len", "(", "code_ids", ")", "\n", "position_idx", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n", "code_ids", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n", "# reindex", "\n", "reverse_index", "=", "{", "}", "\n", "for", "idx", ",", "x", "in", "enumerate", "(", "dfg", ")", ":", "\n", "        ", "reverse_index", "[", "x", "[", "1", "]", "]", "=", "idx", "\n", "", "for", "idx", ",", "x", "in", "enumerate", "(", "dfg", ")", ":", "\n", "        ", "dfg", "[", "idx", "]", "=", "x", "[", ":", "-", "1", "]", "+", "(", "[", "reverse_index", "[", "i", "]", "for", "i", "in", "x", "[", "-", "1", "]", "if", "i", "in", "reverse_index", "]", ",", ")", "\n", "", "dfg_to_dfg", "=", "[", "x", "[", "-", "1", "]", "for", "x", "in", "dfg", "]", "\n", "dfg_to_code", "=", "[", "ori2cur_pos", "[", "x", "[", "1", "]", "]", "for", "x", "in", "dfg", "]", "\n", "length", "=", "len", "(", "[", "tokenizer", ".", "cls_token", "]", ")", "\n", "dfg_to_code", "=", "[", "(", "x", "[", "0", "]", "+", "length", ",", "x", "[", "1", "]", "+", "length", ")", "for", "x", "in", "dfg_to_code", "]", "\n", "# nl", "\n", "nl", "=", "' '", ".", "join", "(", "js", "[", "'docstring_tokens'", "]", ")", "\n", "nl_tokens", "=", "tokenizer", ".", "tokenize", "(", "nl", ")", "[", ":", "args", ".", "nl_length", "-", "2", "]", "\n", "nl_tokens", "=", "[", "tokenizer", ".", "cls_token", "]", "+", "nl_tokens", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "nl_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "nl_tokens", ")", "\n", "padding_length", "=", "args", ".", "nl_length", "-", "len", "(", "nl_ids", ")", "\n", "nl_ids", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n", "\n", "return", "InputFeatures", "(", "code_tokens", ",", "code_ids", ",", "position_idx", ",", "dfg_to_code", ",", "dfg_to_dfg", ",", "nl_tokens", ",", "nl_ids", ",", "js", "[", "'url'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_curri.set_seed": [[239, 246], ["random.seed", "str", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["", "", "def", "set_seed", "(", "seed", "=", "42", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "'PYHTONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_curri.train": [[248, 348], ["run_curri.TextDataset", "print", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.zero_grad", "torch.nn.DataParallel.train", "range", "len", "torch.nn.DataParallel.parameters", "torch.nn.DataParallel", "len", "enumerate", "run_curri.evaluate", "evaluate.items", "int", "len", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "torch.nn.DataParallel.", "torch.nn.DataParallel.", "torch.einsum", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "loss_fct.item", "loss_fct.backward", "torch.nn.utils.clip_grad_norm_", "transformers.AdamW.step", "transformers.AdamW.zero_grad", "transformers.get_linear_schedule_with_warmup.step", "logger.info", "logger.info", "logger.info", "logger.info", "os.path.join", "os.path.join", "torch.save", "logger.info", "min", "int", "len", "torch.arange", "logger.info", "torch.nn.DataParallel.parameters", "round", "round", "os.path.exists", "os.makedirs", "hasattr", "model_to_save.state_dict", "len", "print", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "len", "batch[].to.size", "len", "round"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step"], ["", "def", "train", "(", "args", ",", "model", ",", "tokenizer", ",", "pool", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "# get training dataset", "\n", "train_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "train_data_file", ",", "pool", ")", "\n", "order_dataset", "=", "[", "v", "for", "v", "in", "train_dataset", "]", "\n", "c0", "=", "164923", "/", "len", "(", "order_dataset", ")", "\n", "print", "(", "c0", ")", "\n", "train_data", "=", "order_dataset", "[", "0", ":", "int", "(", "c0", "*", "len", "(", "order_dataset", ")", ")", "]", "\n", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "4", ")", "\n", "t_for_count", "=", "DataLoader", "(", "order_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n", "# get optimizer and scheduler", "\n", "optimizer", "=", "AdamW", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "1e-8", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "0", ",", "\n", "num_training_steps", "=", "len", "(", "t_for_count", ")", "*", "args", ".", "num_train_epochs", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "train_batch_size", "//", "args", ".", "n_gpu", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size  = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "len", "(", "t_for_count", ")", "*", "args", ".", "num_train_epochs", ")", "\n", "\n", "now_percent", "=", "0", "\n", "all_step", "=", "0", "\n", "# model.resize_token_embeddings(len(tokenizer))", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "tr_num", ",", "tr_loss", ",", "best_mrr", "=", "0", ",", "0", ",", "0", "\n", "for", "idx", "in", "range", "(", "args", ".", "num_train_epochs", ")", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "# get inputs", "\n", "            ", "code_inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "attn_mask", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "position_idx", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "nl_inputs", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "# get code and nl vectors", "\n", "code_vec", "=", "model", "(", "code_inputs", "=", "code_inputs", ",", "attn_mask", "=", "attn_mask", ",", "position_idx", "=", "position_idx", ")", "\n", "nl_vec", "=", "model", "(", "nl_inputs", "=", "nl_inputs", ")", "\n", "\n", "# calculate scores and loss", "\n", "scores", "=", "torch", ".", "einsum", "(", "\"ab,cb->ac\"", ",", "nl_vec", ",", "code_vec", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "scores", ",", "torch", ".", "arange", "(", "code_inputs", ".", "size", "(", "0", ")", ",", "device", "=", "scores", ".", "device", ")", ")", "\n", "\n", "all_step", "+=", "1", "\n", "# report loss", "\n", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "tr_num", "+=", "1", "\n", "if", "(", "step", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"epoch {} step {} loss {}\"", ".", "format", "(", "idx", ",", "step", "+", "1", ",", "round", "(", "tr_loss", "/", "tr_num", ",", "5", ")", ")", ")", "\n", "tr_loss", "=", "0", "\n", "tr_num", "=", "0", "\n", "\n", "# backward", "\n", "", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "# evaluate", "\n", "", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "args", ".", "eval_data_file", ",", "pool", ",", "eval_when_training", "=", "True", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "round", "(", "value", ",", "4", ")", ")", "\n", "\n", "# save best model", "\n", "", "if", "results", "[", "'eval_mrr'", "]", ">", "best_mrr", ":", "\n", "            ", "best_mrr", "=", "results", "[", "'eval_mrr'", "]", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "logger", ".", "info", "(", "\"  Best mrr:%s\"", ",", "round", "(", "best_mrr", ",", "4", ")", ")", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "\n", "checkpoint_prefix", "=", "'checkpoint-best-mrr'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'{}'", ".", "format", "(", "'model_curri.bin'", ")", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_dir", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "if", "args", ".", "pacing_function", "!=", "\"\"", ":", "\n", "            ", "curriculum_iterations", "=", "len", "(", "t_for_count", ")", "*", "args", ".", "num_train_epochs", "\n", "new_data_fraction", "=", "min", "(", "1", ",", "\n", "PACING_FUNCTIONS", "[", "args", ".", "pacing_function", "]", "(", "all_step", ",", "curriculum_iterations", ",", "c0", ")", ")", "\n", "percent", "=", "int", "(", "new_data_fraction", "*", "len", "(", "train_dataset", ")", ")", "\n", "if", "percent", "!=", "now_percent", ":", "\n", "                ", "now_percent", "=", "percent", "\n", "print", "(", "new_data_fraction", ")", "\n", "train_data", "=", "order_dataset", "[", "0", ":", "now_percent", "]", "\n", "train_sampler", "=", "RandomSampler", "(", "train_data", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_curri.evaluate": [[350, 433], ["run_curri.TextDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "run_curri.TextDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "torch.nn.DataParallel.train", "numpy.concatenate", "numpy.concatenate", "numpy.matmul", "numpy.save", "zip", "torch.nn.DataParallel", "len", "len", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "numpy.save", "numpy.argsort", "nl_urls.append", "code_urls.append", "float", "torch.no_grad", "torch.nn.DataParallel.", "np.concatenate.append", "torch.no_grad", "torch.nn.DataParallel.", "np.concatenate.append", "example.url.find", "example.url.rfind", "example.url.find", "example.url.rfind", "str", "ranks.append", "ranks.append", "numpy.mean", "model.cpu().numpy", "model.cpu().numpy", "str", "len", "len", "model.cpu", "model.cpu"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train"], ["", "", "", "", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "file_name", ",", "pool", ",", "eval_when_training", "=", "False", ")", ":", "\n", "    ", "query_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "file_name", ",", "pool", ")", "\n", "query_sampler", "=", "SequentialSampler", "(", "query_dataset", ")", "\n", "query_dataloader", "=", "DataLoader", "(", "query_dataset", ",", "sampler", "=", "query_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n", "code_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "codebase_file", ",", "pool", ")", "\n", "code_sampler", "=", "SequentialSampler", "(", "code_dataset", ")", "\n", "code_dataloader", "=", "DataLoader", "(", "code_dataset", ",", "sampler", "=", "code_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "eval_when_training", "is", "False", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num queries = %d\"", ",", "len", "(", "query_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num codes = %d\"", ",", "len", "(", "code_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "code_vecs", "=", "[", "]", "\n", "nl_vecs", "=", "[", "]", "\n", "for", "batch", "in", "query_dataloader", ":", "\n", "        ", "nl_inputs", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "nl_vec", "=", "model", "(", "nl_inputs", "=", "nl_inputs", ")", "\n", "nl_vecs", ".", "append", "(", "nl_vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "for", "batch", "in", "code_dataloader", ":", "\n", "        ", "code_inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "attn_mask", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "position_idx", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "code_vec", "=", "model", "(", "code_inputs", "=", "code_inputs", ",", "attn_mask", "=", "attn_mask", ",", "position_idx", "=", "position_idx", ")", "\n", "code_vecs", ".", "append", "(", "code_vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "model", ".", "train", "(", ")", "\n", "code_vecs", "=", "np", ".", "concatenate", "(", "code_vecs", ",", "0", ")", "\n", "nl_vecs", "=", "np", ".", "concatenate", "(", "nl_vecs", ",", "0", ")", "\n", "\n", "scores", "=", "np", ".", "matmul", "(", "nl_vecs", ",", "code_vecs", ".", "T", ")", "\n", "if", "'test'", "in", "file_name", ":", "\n", "        ", "fname", "=", "\"scores\"", "+", "str", "(", "args", ".", "codebase_file", "[", "-", "7", "]", ")", "+", "\".npy\"", "\n", "np", ".", "save", "(", "fname", ",", "scores", ")", "\n", "", "sort_ids", "=", "np", ".", "argsort", "(", "scores", ",", "axis", "=", "-", "1", ",", "kind", "=", "'quicksort'", ",", "order", "=", "None", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "\n", "nl_urls", "=", "[", "]", "\n", "code_urls", "=", "[", "]", "\n", "for", "example", "in", "query_dataset", ".", "examples", ":", "\n", "        ", "temp", "=", "example", ".", "url", "\n", "if", "(", "example", ".", "url", ")", ".", "find", "(", "\"_\"", ")", "!=", "-", "1", ":", "\n", "            ", "loc", "=", "(", "example", ".", "url", ")", ".", "rfind", "(", "\"_\"", ")", "\n", "if", "loc", "+", "3", ">=", "len", "(", "example", ".", "url", ")", ":", "\n", "                ", "temp", "=", "example", ".", "url", "[", ":", "loc", "]", "\n", "", "", "nl_urls", ".", "append", "(", "temp", ")", "\n", "\n", "", "for", "example", "in", "code_dataset", ".", "examples", ":", "\n", "        ", "temp", "=", "example", ".", "url", "\n", "if", "(", "example", ".", "url", ")", ".", "find", "(", "\"_\"", ")", "!=", "-", "1", ":", "\n", "            ", "loc", "=", "(", "example", ".", "url", ")", ".", "rfind", "(", "\"_\"", ")", "\n", "if", "loc", "+", "3", ">=", "len", "(", "example", ".", "url", ")", ":", "\n", "                ", "temp", "=", "example", ".", "url", "[", ":", "loc", "]", "\n", "", "", "code_urls", ".", "append", "(", "temp", ")", "\n", "", "fname", "=", "\"codeurl\"", "+", "str", "(", "args", ".", "codebase_file", "[", "-", "7", "]", ")", "+", "\".npy\"", "\n", "np", ".", "save", "(", "fname", ",", "code_urls", ")", "\n", "ranks", "=", "[", "]", "\n", "for", "url", ",", "sort_id", "in", "zip", "(", "nl_urls", ",", "sort_ids", ")", ":", "\n", "        ", "rank", "=", "0", "\n", "find", "=", "False", "\n", "for", "idx", "in", "sort_id", "[", ":", "1000", "]", ":", "\n", "            ", "if", "find", "is", "False", ":", "\n", "                ", "rank", "+=", "1", "\n", "", "if", "code_urls", "[", "idx", "]", "==", "url", ":", "\n", "                ", "find", "=", "True", "\n", "", "", "if", "find", ":", "\n", "            ", "ranks", ".", "append", "(", "1", "/", "rank", ")", "\n", "", "else", ":", "\n", "            ", "ranks", ".", "append", "(", "0", ")", "\n", "\n", "", "", "result", "=", "{", "\n", "\"eval_mrr\"", ":", "float", "(", "np", ".", "mean", "(", "ranks", ")", ")", "\n", "}", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_curri.main": [[435, 542], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "multiprocessing.Pool", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "torch.device", "torch.cuda.device_count", "logger.info", "run_curri.set_seed", "transformers.RobertaConfig.from_pretrained", "transformers.RobertaTokenizer.from_pretrained", "transformers.RobertaModel.from_pretrained", "model.Model", "logger.info", "model.Model.to", "run_curri.train", "os.path.join", "model.Model.load_state_dict", "model.Model.to", "run_curri.evaluate", "logger.info", "sorted", "os.path.join", "model.Model.load_state_dict", "model.Model.to", "run_curri.evaluate", "logger.info", "sorted", "torch.cuda.is_available", "torch.load", "evaluate.keys", "logger.info", "torch.load", "evaluate.keys", "logger.info", "str", "str", "round", "round"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.set_seed", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input training data file (a json file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the MRR(a jsonl file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input test data file to test the MRR(a josnl file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--codebase_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input test data file to codebase (a jsonl file).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--lang\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"language.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--nl_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional NL input sequence length after tokenization.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_length\"", ",", "default", "=", "256", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional Code input sequence length after tokenization.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_flow_length\"", ",", "default", "=", "64", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional Data Flow input sequence length after tokenization.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the test set.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--pacing_function\"", ",", "default", "=", "\"linear\"", ",", "type", "=", "str", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "cpu_cont", ")", "\n", "\n", "# print arguments", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# set log", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s -   %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "level", "=", "logging", ".", "INFO", ")", "\n", "# set device", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "args", ".", "device", "=", "device", "\n", "logger", ".", "info", "(", "\"device: %s, n_gpu: %s\"", ",", "device", ",", "args", ".", "n_gpu", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# build model", "\n", "config", "=", "RobertaConfig", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ")", "\n", "tokenizer", "=", "RobertaTokenizer", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", ")", "\n", "model", "=", "RobertaModel", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "model", "=", "Model", "(", "model", ")", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train", "(", "args", ",", "model", ",", "tokenizer", ",", "pool", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-mrr/model_curri.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ",", "strict", "=", "False", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "args", ".", "eval_data_file", ",", "pool", ")", "\n", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "round", "(", "result", "[", "key", "]", ",", "4", ")", ")", ")", "\n", "\n", "", "", "if", "args", ".", "do_test", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-mrr/model_curri.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ",", "strict", "=", "False", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "args", ".", "test_data_file", ",", "pool", ")", "\n", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "round", "(", "result", "[", "key", "]", ",", "4", ")", ")", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run.InputFeatures.__init__": [[103, 122], ["None"], "methods", ["None"], ["            ", "if", "e", ".", "label", "not", "in", "self", ".", "label_examples", ":", "\n", "                ", "self", ".", "label_examples", "[", "e", ".", "label", "]", "=", "[", "]", "\n", "", "self", ".", "label_examples", "[", "e", ".", "label", "]", ".", "append", "(", "e", ")", "\n", "\n", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n", "", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "label", "=", "self", ".", "examples", "[", "i", "]", ".", "label", "\n", "index", "=", "self", ".", "examples", "[", "i", "]", ".", "index", "\n", "labels", "=", "list", "(", "self", ".", "label_examples", ")", "\n", "labels", ".", "remove", "(", "label", ")", "\n", "while", "True", ":", "\n", "            ", "shuffle_example", "=", "random", ".", "sample", "(", "self", ".", "label_examples", "[", "label", "]", ",", "1", ")", "[", "0", "]", "\n", "if", "shuffle_example", ".", "index", "!=", "index", ":", "\n", "                ", "p_example", "=", "shuffle_example", "\n", "break", "\n", "", "", "n_example", "=", "random", ".", "sample", "(", "self", ".", "label_examples", "[", "random", ".", "sample", "(", "labels", ",", "1", ")", "[", "0", "]", "]", ",", "1", ")", "[", "0", "]", "\n", "\n", "return", "(", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "i", "]", ".", "input_ids", ")", ",", "torch", ".", "tensor", "(", "p_example", ".", "input_ids", ")", ",", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run.TextDataset.__init__": [[169, 198], ["os.path.exists", "pickle.load", "pool.map", "pickle.dump", "file_path.split", "open", "open", "tqdm.tqdm.tqdm", "open", "line.strip.strip.strip", "json.loads", "data.append", "len"], "methods", ["None"], ["\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "\n", "", "checkpoint_last", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-last'", ")", "\n", "scheduler_last", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'scheduler.pt'", ")", "\n", "optimizer_last", "=", "os", ".", "path", ".", "join", "(", "checkpoint_last", ",", "'optimizer.pt'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "scheduler_last", ")", ":", "\n", "        ", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "scheduler_last", ")", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "optimizer_last", ")", ":", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "optimizer_last", ")", ")", "\n", "# Train!", "\n", "", "'''\n    logger.info(\"***** Running training *****\")\n    logger.info(\"  Num examples = %d\", len(train_dataset))\n    logger.info(\"  Num Epochs = %d\", args.num_train_epochs)\n    logger.info(\"  Instantaneous batch size per GPU = %d\", args.per_gpu_train_batch_size)\n    logger.info(\"  Total train batch size (w. parallel, distributed & accumulation) = %d\",\n                args.train_batch_size * args.gradient_accumulation_steps * (\n                    torch.distributed.get_world_size() if args.local_rank != -1 else 1))\n    logger.info(\"  Gradient Accumulation steps = %d\", args.gradient_accumulation_steps)\n    logger.info(\"  Total optimization steps = %d\", args.max_steps)\n    '''", "\n", "global_step", "=", "args", ".", "start_step", "\n", "tr_loss", ",", "logging_loss", ",", "avg_loss", ",", "tr_nb", ",", "tr_num", ",", "train_loss", "=", "0.0", ",", "0.0", ",", "0.0", ",", "0", ",", "0", ",", "0", "\n", "best_acc", "=", "0.0", "\n", "# model.resize_token_embeddings(len(tokenizer))", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run.TextDataset.__len__": [[198, 200], ["len"], "methods", ["None"], ["# model.resize_token_embeddings(len(tokenizer))", "\n", "model", ".", "zero_grad", "(", ")", "\n", "for", "idx", "in", "range", "(", "args", ".", "start_epoch", ",", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run.TextDataset.__getitem__": [[201, 229], ["numpy.zeros", "sum", "sum", "enumerate", "enumerate", "enumerate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len"], "methods", ["None"], ["        ", "'''\n        if idx != args.start_epoch:\n            print(\"idx = \", idx)\n            train_dataset = TextDataset(tokenizer, args, args.train_data_file)\n            train_sampler = RandomSampler(train_dataset) if args.local_rank == -1 else DistributedSampler(train_dataset)\n\n            train_dataloader = DataLoader(train_dataset, sampler=train_sampler,\n                                          batch_size=args.train_batch_size, num_workers=10)\n        '''", "\n", "bar", "=", "train_dataloader", "\n", "tr_num", "=", "0", "\n", "train_loss", "=", "0", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "bar", ")", ":", "\n", "            ", "inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "p_inputs", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "n_inputs", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "model", ".", "train", "(", ")", "\n", "loss", ",", "vec", "=", "model", "(", "inputs", ",", "p_inputs", ",", "n_inputs", ",", "labels", ")", "\n", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run.extract_dataflow": [[63, 100], ["parser.remove_comments_and_docstrings", "parser[].parse", "parser.tree_to_token_index", "code.split.split", "enumerate", "sorted", "set", "bytes", "parser.index_to_code_token", "zip", "len", "set.add", "set.add", "new_DFG.append"], "function", ["None"], ["\n", "\n", "class", "InputFeatures", "(", "object", ")", ":", "\n", "    ", "\"\"\"A single training/test features for a example.\"\"\"", "\n", "def", "__init__", "(", "self", ",", "\n", "input_tokens", ",", "\n", "input_ids", ",", "\n", "index", ",", "\n", "label", ",", "\n", "\n", ")", ":", "\n", "        ", "self", ".", "input_tokens", "=", "input_tokens", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "label", "=", "label", "\n", "\n", "\n", "", "", "def", "convert_examples_to_features", "(", "js", ",", "tokenizer", ",", "args", ")", ":", "\n", "#source", "\n", "    ", "code", "=", "' '", ".", "join", "(", "js", "[", "'code'", "]", ".", "split", "(", ")", ")", "\n", "code_tokens", "=", "tokenizer", ".", "tokenize", "(", "code", ")", "[", ":", "args", ".", "block_size", "-", "2", "]", "\n", "source_tokens", "=", "[", "tokenizer", ".", "cls_token", "]", "+", "code_tokens", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "source_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "source_tokens", ")", "\n", "padding_length", "=", "args", ".", "block_size", "-", "len", "(", "source_ids", ")", "\n", "source_ids", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n", "return", "InputFeatures", "(", "source_tokens", ",", "source_ids", ",", "js", "[", "'index'", "]", ",", "int", "(", "js", "[", "'label'", "]", ")", ")", "\n", "\n", "", "class", "TextDataset", "(", "Dataset", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ",", "file_path", "=", "None", ")", ":", "\n", "        ", "self", ".", "examples", "=", "[", "]", "\n", "data", "=", "[", "]", "\n", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "data", ".", "append", "(", "js", ")", "\n", "", "", "for", "js", "in", "data", ":", "\n", "            ", "self", ".", "examples", ".", "append", "(", "convert_examples_to_features", "(", "js", ",", "tokenizer", ",", "args", ")", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run.convert_examples_to_features": [[124, 167], ["run.extract_dataflow", "range", "tokenizer.convert_tokens_to_ids", "enumerate", "enumerate", "len", "tokenizer.convert_tokens_to_ids", "run.InputFeatures", "len", "len", "tokenizer.tokenize", "len", "tokenizer.tokenize", "enumerate", "range", "tokenizer.tokenize", "len", "min", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.extract_dataflow"], ["\n", "\n", "", "", "def", "set_seed", "(", "seed", "=", "42", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "'PYHTONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n", "\n", "", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "\n", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "10", ")", "\n", "args", ".", "max_steps", "=", "args", ".", "epoch", "*", "len", "(", "train_dataloader", ")", "\n", "args", ".", "save_steps", "=", "len", "(", "train_dataloader", ")", "\n", "args", ".", "warmup_steps", "=", "len", "(", "train_dataloader", ")", "\n", "args", ".", "logging_steps", "=", "len", "(", "train_dataloader", ")", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "epoch", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "max_steps", "*", "0.1", ",", "\n", "num_training_steps", "=", "args", ".", "max_steps", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run.set_seed": [[231, 238], ["random.seed", "str", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "tr_num", "+=", "1", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "avg_loss", "==", "0", ":", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run.train": [[240, 319], ["run.TextDataset", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.zero_grad", "torch.nn.DataParallel.train", "range", "torch.nn.DataParallel.parameters", "torch.nn.DataParallel", "len", "enumerate", "run.evaluate", "evaluate.items", "len", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "torch.nn.DataParallel.", "torch.nn.DataParallel.", "torch.einsum", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "loss_fct.item", "loss_fct.backward", "torch.nn.utils.clip_grad_norm_", "transformers.AdamW.step", "transformers.AdamW.zero_grad", "transformers.get_linear_schedule_with_warmup.step", "logger.info", "logger.info", "logger.info", "logger.info", "os.path.join", "os.path.join", "torch.save", "logger.info", "len", "torch.arange", "logger.info", "torch.nn.DataParallel.parameters", "round", "round", "os.path.exists", "os.makedirs", "hasattr", "model_to_save.state_dict", "batch[].to.size", "round"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step"], ["", "avg_loss", "=", "round", "(", "train_loss", "/", "tr_num", ",", "5", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"epoch {} step {} loss {}\"", ".", "format", "(", "idx", ",", "step", "+", "1", ",", "avg_loss", ")", ")", "\n", "#bar.set_description(\"epoch {} loss {}\".format(idx,avg_loss))", "\n", "\n", "\n", "", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "global_step", "+=", "1", "\n", "output_flag", "=", "True", "\n", "avg_loss", "=", "round", "(", "np", ".", "exp", "(", "(", "tr_loss", "-", "logging_loss", ")", "/", "(", "global_step", "-", "tr_nb", ")", ")", ",", "4", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                    ", "logging_loss", "=", "tr_loss", "\n", "tr_nb", "=", "global_step", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "eval_when_training", "=", "True", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "round", "(", "value", ",", "4", ")", ")", "\n", "# Save model checkpoint", "\n", "", "tr_num", "=", "0", "\n", "train_loss", "=", "0", "\n", "\n", "", "if", "results", "[", "'eval_map'", "]", ">", "best_acc", ":", "\n", "                        ", "best_acc", "=", "results", "[", "'eval_map'", "]", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "logger", ".", "info", "(", "\"  Best map:%s\"", ",", "round", "(", "best_acc", ",", "4", ")", ")", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "\n", "checkpoint_prefix", "=", "'checkpoint-best-map'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                            ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'{}'", ".", "format", "(", "'model.bin'", ")", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_dir", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "\n", "", "", "", "", "", "", "eval_dataset", "=", "None", "\n", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "eval_when_training", "=", "False", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "global", "eval_dataset", "\n", "if", "eval_dataset", "is", "None", ":", "\n", "        ", "eval_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "eval_data_file", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "num_workers", "=", "10", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "eval_when_training", "is", "False", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "vecs", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "p_inputs", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "n_inputs", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "label", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "lm_loss", ",", "vec", "=", "model", "(", "inputs", ",", "p_inputs", ",", "n_inputs", ",", "label", ")", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run.evaluate": [[321, 392], ["run.TextDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "run.TextDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "torch.nn.DataParallel.train", "numpy.concatenate", "numpy.concatenate", "numpy.matmul", "zip", "torch.nn.DataParallel", "len", "len", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "numpy.argsort", "nl_urls.append", "code_urls.append", "float", "torch.no_grad", "torch.nn.DataParallel.", "np.concatenate.append", "torch.no_grad", "torch.nn.DataParallel.", "np.concatenate.append", "ranks.append", "ranks.append", "numpy.mean", "model.cpu().numpy", "model.cpu().numpy", "model.cpu", "model.cpu"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train"], ["labels", ".", "append", "(", "label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "", "vecs", "=", "np", ".", "concatenate", "(", "vecs", ",", "0", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "0", ")", "\n", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "tensor", "(", "eval_loss", ")", "\n", "\n", "scores", "=", "np", ".", "matmul", "(", "vecs", ",", "vecs", ".", "T", ")", "\n", "dic", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "scores", "[", "i", ",", "i", "]", "=", "-", "1000000", "\n", "if", "int", "(", "labels", "[", "i", "]", ")", "not", "in", "dic", ":", "\n", "            ", "dic", "[", "int", "(", "labels", "[", "i", "]", ")", "]", "=", "-", "1", "\n", "", "dic", "[", "int", "(", "labels", "[", "i", "]", ")", "]", "+=", "1", "\n", "", "sort_ids", "=", "np", ".", "argsort", "(", "scores", ",", "axis", "=", "-", "1", ",", "kind", "=", "'quicksort'", ",", "order", "=", "None", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "MAP", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "cont", "=", "0", "\n", "label", "=", "int", "(", "labels", "[", "i", "]", ")", "\n", "for", "j", "in", "range", "(", "dic", "[", "label", "]", ")", ":", "\n", "            ", "index", "=", "sort_ids", "[", "i", ",", "j", "]", "\n", "if", "int", "(", "labels", "[", "index", "]", ")", "==", "label", ":", "\n", "                ", "cont", "+=", "1", "\n", "", "", "MAP", ".", "append", "(", "cont", "/", "dic", "[", "label", "]", ")", "\n", "\n", "", "result", "=", "{", "\n", "\"eval_loss\"", ":", "float", "(", "perplexity", ")", ",", "\n", "\"eval_map\"", ":", "float", "(", "np", ".", "mean", "(", "MAP", ")", ")", "\n", "}", "\n", "\n", "\n", "return", "result", "\n", "\n", "", "def", "test", "(", "args", ",", "model", ",", "tokenizer", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "test_data_file", ")", "\n", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running Test *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "vecs", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "        ", "inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "p_inputs", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "n_inputs", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "label", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "## p,n,label (multi_view) not change", "\n", "## table --> inputs_trans ----> vecs_trans", "\n", "## average", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "lm_loss", ",", "vec", "=", "model", "(", "inputs", ",", "p_inputs", ",", "n_inputs", ",", "label", ")", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "vecs", ".", "append", "(", "vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "labels", ".", "append", "(", "label", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run.main": [[395, 501], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "multiprocessing.Pool", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "torch.device", "torch.cuda.device_count", "logger.info", "run.set_seed", "transformers.RobertaConfig.from_pretrained", "transformers.RobertaTokenizer.from_pretrained", "transformers.RobertaModel.from_pretrained", "model.Model", "logger.info", "model.Model.to", "run.train", "os.path.join", "model.Model.load_state_dict", "model.Model.to", "run.evaluate", "logger.info", "sorted", "os.path.join", "model.Model.load_state_dict", "model.Model.to", "run.evaluate", "logger.info", "sorted", "torch.cuda.is_available", "torch.load", "evaluate.keys", "logger.info", "torch.load", "evaluate.keys", "logger.info", "str", "str", "round", "round"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.set_seed", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate"], ["cluster", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "        ", "label", "=", "labels", "[", "i", "]", "\n", "if", "label", "not", "in", "cluster", ":", "\n", "            ", "cluster", "[", "label", "]", "=", "0", "\n", "", "cluster", "[", "label", "]", "+=", "1", "\n", "\n", "\n", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "tensor", "(", "eval_loss", ")", "\n", "\n", "scores", "=", "np", ".", "matmul", "(", "vecs", ",", "vecs", ".", "T", ")", "\n", "for", "i", "in", "range", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "scores", "[", "i", ",", "i", "]", "=", "-", "1000000", "\n", "\n", "", "loc", "=", "args", ".", "test_data_file", ".", "rfind", "(", "'/'", ")", "\n", "fname", "=", "\"scores\"", "+", "str", "(", "args", ".", "test_data_file", "[", "loc", "+", "1", ":", "-", "6", "]", ")", "+", "\".npy\"", "\n", "np", ".", "save", "(", "fname", ",", "scores", ")", "\n", "\n", "sort_ids", "=", "np", ".", "argsort", "(", "scores", ",", "axis", "=", "-", "1", ",", "kind", "=", "'quicksort'", ",", "order", "=", "None", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "indexs", "=", "[", "]", "\n", "for", "example", "in", "eval_dataset", ".", "examples", ":", "\n", "        ", "indexs", ".", "append", "(", "example", ".", "index", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"predictions.jsonl\"", ")", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "cnt", "=", "0", "\n", "for", "index", ",", "sort_id", "in", "zip", "(", "indexs", ",", "sort_ids", ")", ":", "\n", "            ", "js", "=", "{", "}", "\n", "js", "[", "'index'", "]", "=", "index", "\n", "js", "[", "'answers'", "]", "=", "[", "]", "\n", "for", "idx", "in", "sort_id", "[", ":", "cluster", "[", "labels", "[", "cnt", "]", "]", "-", "1", "]", ":", "\n", "                ", "js", "[", "'answers'", "]", ".", "append", "(", "indexs", "[", "int", "(", "idx", ")", "]", ")", "\n", "", "f", ".", "write", "(", "json", ".", "dumps", "(", "js", ")", "+", "'\\n'", ")", "\n", "cnt", "+=", "1", "\n", "\n", "\n", "\n", "", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input training data file (a text file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--eval_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "\"bert\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model architecture to be fine-tuned.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--mlm\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Train with masked-language modeling loss instead of language modeling.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--mlm_probability\"", ",", "type", "=", "float", ",", "default", "=", "0.15", ",", "\n", "help", "=", "\"Ratio of tokens to mask for masked language modeling loss\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional directory to store the pre-trained models downloaded from s3 (instread of the default one)\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--block_size\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional input sequence length after tokenization.\"", "\n", "\"The training dataset will be truncated in block of this size for training.\"", "\n", "\"Default to the model max input length for single sentence inputs (take into account special tokens).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Run evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.InputFeatures.__init__": [[107, 126], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "code_tokens", ",", "\n", "code_ids", ",", "\n", "position_idx", ",", "\n", "dfg_to_code", ",", "\n", "dfg_to_dfg", ",", "\n", "nl_tokens", ",", "\n", "nl_ids", ",", "\n", "url", ",", "\n", "\n", ")", ":", "\n", "        ", "self", ".", "code_tokens", "=", "code_tokens", "\n", "self", ".", "code_ids", "=", "code_ids", "\n", "self", ".", "position_idx", "=", "position_idx", "\n", "self", ".", "dfg_to_code", "=", "dfg_to_code", "\n", "self", ".", "dfg_to_dfg", "=", "dfg_to_dfg", "\n", "self", ".", "nl_tokens", "=", "nl_tokens", "\n", "self", ".", "nl_ids", "=", "nl_ids", "\n", "self", ".", "url", "=", "url", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.TextDataset.__init__": [[175, 204], ["os.path.exists", "pickle.load", "pool.map", "pickle.dump", "file_path.split", "open", "open", "tqdm.tqdm.tqdm", "open", "line.strip.strip.strip", "json.loads", "data.append", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "args", ",", "file_path", "=", "None", ",", "pool", "=", "None", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "prefix", "=", "file_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "[", ":", "-", "6", "]", "\n", "cache_file", "=", "args", ".", "output_dir", "+", "'/'", "+", "prefix", "+", "'.pkl'", "\n", "if", "os", ".", "path", ".", "exists", "(", "cache_file", ")", ":", "\n", "            ", "self", ".", "examples", "=", "pickle", ".", "load", "(", "open", "(", "cache_file", ",", "'rb'", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "examples", "=", "[", "]", "\n", "data", "=", "[", "]", "\n", "with", "open", "(", "file_path", ")", "as", "f", ":", "\n", "                ", "for", "line", "in", "f", ":", "\n", "                    ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "data", ".", "append", "(", "(", "js", ",", "tokenizer", ",", "args", ")", ")", "\n", "", "", "self", ".", "examples", "=", "pool", ".", "map", "(", "convert_examples_to_features", ",", "tqdm", "(", "data", ",", "total", "=", "len", "(", "data", ")", ")", ")", "\n", "pickle", ".", "dump", "(", "self", ".", "examples", ",", "open", "(", "cache_file", ",", "'wb'", ")", ")", "\n", "", "'''\n        if 'train' in file_path:\n            for idx, example in enumerate(self.examples[:3]):\n                logger.info(\"*** Example ***\")\n                logger.info(\"idx: {}\".format(idx))\n                logger.info(\"code_tokens: {}\".format([x.replace('\\u0120','_') for x in example.code_tokens]))\n                logger.info(\"code_ids: {}\".format(' '.join(map(str, example.code_ids))))\n                logger.info(\"position_idx: {}\".format(example.position_idx))\n                logger.info(\"dfg_to_code: {}\".format(' '.join(map(str, example.dfg_to_code))))\n                logger.info(\"dfg_to_dfg: {}\".format(' '.join(map(str, example.dfg_to_dfg))))                \n                logger.info(\"nl_tokens: {}\".format([x.replace('\\u0120','_') for x in example.nl_tokens]))\n                logger.info(\"nl_ids: {}\".format(' '.join(map(str, example.nl_ids))))          \n        '''", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.TextDataset.__len__": [[205, 207], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.TextDataset.__getitem__": [[208, 236], ["numpy.zeros", "sum", "sum", "enumerate", "enumerate", "enumerate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "# calculate graph-guided masked function", "\n", "        ", "attn_mask", "=", "np", ".", "zeros", "(", "(", "self", ".", "args", ".", "code_length", "+", "self", ".", "args", ".", "data_flow_length", ",", "\n", "self", ".", "args", ".", "code_length", "+", "self", ".", "args", ".", "data_flow_length", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "# calculate begin index of node and max length of input", "\n", "node_index", "=", "sum", "(", "[", "i", ">", "1", "for", "i", "in", "self", ".", "examples", "[", "item", "]", ".", "position_idx", "]", ")", "\n", "max_length", "=", "sum", "(", "[", "i", "!=", "1", "for", "i", "in", "self", ".", "examples", "[", "item", "]", ".", "position_idx", "]", ")", "\n", "# sequence can attend to sequence", "\n", "attn_mask", "[", ":", "node_index", ",", ":", "node_index", "]", "=", "True", "\n", "# special tokens attend to all tokens", "\n", "for", "idx", ",", "i", "in", "enumerate", "(", "self", ".", "examples", "[", "item", "]", ".", "code_ids", ")", ":", "\n", "            ", "if", "i", "in", "[", "0", ",", "2", "]", ":", "\n", "                ", "attn_mask", "[", "idx", ",", ":", "max_length", "]", "=", "True", "\n", "# nodes attend to code tokens that are identified from", "\n", "", "", "for", "idx", ",", "(", "a", ",", "b", ")", "in", "enumerate", "(", "self", ".", "examples", "[", "item", "]", ".", "dfg_to_code", ")", ":", "\n", "            ", "if", "a", "<", "node_index", "and", "b", "<", "node_index", ":", "\n", "                ", "attn_mask", "[", "idx", "+", "node_index", ",", "a", ":", "b", "]", "=", "True", "\n", "attn_mask", "[", "a", ":", "b", ",", "idx", "+", "node_index", "]", "=", "True", "\n", "# nodes attend to adjacent nodes", "\n", "", "", "for", "idx", ",", "nodes", "in", "enumerate", "(", "self", ".", "examples", "[", "item", "]", ".", "dfg_to_dfg", ")", ":", "\n", "            ", "for", "a", "in", "nodes", ":", "\n", "                ", "if", "a", "+", "node_index", "<", "len", "(", "self", ".", "examples", "[", "item", "]", ".", "position_idx", ")", ":", "\n", "                    ", "attn_mask", "[", "idx", "+", "node_index", ",", "a", "+", "node_index", "]", "=", "True", "\n", "\n", "", "", "", "return", "(", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ".", "code_ids", ")", ",", "\n", "torch", ".", "tensor", "(", "attn_mask", ")", ",", "\n", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ".", "position_idx", ")", ",", "\n", "torch", ".", "tensor", "(", "self", ".", "examples", "[", "item", "]", ".", "nl_ids", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.extract_dataflow": [[65, 102], ["parser.remove_comments_and_docstrings", "parser[].parse", "parser.tree_to_token_index", "code.split.split", "enumerate", "sorted", "set", "bytes", "parser.index_to_code_token", "zip", "len", "set.add", "set.add", "new_DFG.append"], "function", ["None"], ["", "def", "extract_dataflow", "(", "code", ",", "parser", ",", "lang", ")", ":", "\n", "# remove comments", "\n", "    ", "try", ":", "\n", "        ", "code", "=", "remove_comments_and_docstrings", "(", "code", ",", "lang", ")", "\n", "", "except", ":", "\n", "        ", "pass", "\n", "# obtain dataflow", "\n", "", "if", "lang", "==", "\"php\"", ":", "\n", "        ", "code", "=", "\"<?php\"", "+", "code", "+", "\"?>\"", "\n", "", "try", ":", "\n", "        ", "tree", "=", "parser", "[", "0", "]", ".", "parse", "(", "bytes", "(", "code", ",", "'utf8'", ")", ")", "\n", "root_node", "=", "tree", ".", "root_node", "\n", "tokens_index", "=", "tree_to_token_index", "(", "root_node", ")", "\n", "code", "=", "code", ".", "split", "(", "'\\n'", ")", "\n", "code_tokens", "=", "[", "index_to_code_token", "(", "x", ",", "code", ")", "for", "x", "in", "tokens_index", "]", "\n", "index_to_code", "=", "{", "}", "\n", "for", "idx", ",", "(", "index", ",", "code", ")", "in", "enumerate", "(", "zip", "(", "tokens_index", ",", "code_tokens", ")", ")", ":", "\n", "            ", "index_to_code", "[", "index", "]", "=", "(", "idx", ",", "code", ")", "\n", "", "try", ":", "\n", "            ", "DFG", ",", "_", "=", "parser", "[", "1", "]", "(", "root_node", ",", "index_to_code", ",", "{", "}", ")", "\n", "", "except", ":", "\n", "            ", "DFG", "=", "[", "]", "\n", "", "DFG", "=", "sorted", "(", "DFG", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "indexs", "=", "set", "(", ")", "\n", "for", "d", "in", "DFG", ":", "\n", "            ", "if", "len", "(", "d", "[", "-", "1", "]", ")", "!=", "0", ":", "\n", "                ", "indexs", ".", "add", "(", "d", "[", "1", "]", ")", "\n", "", "for", "x", "in", "d", "[", "-", "1", "]", ":", "\n", "                ", "indexs", ".", "add", "(", "x", ")", "\n", "", "", "new_DFG", "=", "[", "]", "\n", "for", "d", "in", "DFG", ":", "\n", "            ", "if", "d", "[", "1", "]", "in", "indexs", ":", "\n", "                ", "new_DFG", ".", "append", "(", "d", ")", "\n", "", "", "dfg", "=", "new_DFG", "\n", "", "except", ":", "\n", "        ", "dfg", "=", "[", "]", "\n", "", "return", "code_tokens", ",", "dfg", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.convert_examples_to_features": [[128, 172], ["run_large.extract_dataflow", "range", "tokenizer.convert_tokens_to_ids", "enumerate", "enumerate", "len", "tokenizer.convert_tokens_to_ids", "run_large.InputFeatures", "len", "len", "tokenizer.tokenize", "len", "tokenizer.tokenize", "enumerate", "range", "tokenizer.tokenize", "len", "min", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.extract_dataflow"], ["", "", "def", "convert_examples_to_features", "(", "item", ")", ":", "\n", "    ", "js", ",", "tokenizer", ",", "args", "=", "item", "\n", "# code", "\n", "parser", "=", "parsers", "[", "args", ".", "lang", "]", "\n", "# extract data flow", "\n", "code_tokens", ",", "dfg", "=", "extract_dataflow", "(", "js", "[", "'original_string'", "]", ",", "parser", ",", "args", ".", "lang", ")", "\n", "code_tokens", "=", "[", "tokenizer", ".", "tokenize", "(", "'@ '", "+", "x", ")", "[", "1", ":", "]", "if", "idx", "!=", "0", "else", "tokenizer", ".", "tokenize", "(", "x", ")", "for", "idx", ",", "x", "in", "\n", "enumerate", "(", "code_tokens", ")", "]", "\n", "ori2cur_pos", "=", "{", "}", "\n", "ori2cur_pos", "[", "-", "1", "]", "=", "(", "0", ",", "0", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "code_tokens", ")", ")", ":", "\n", "        ", "ori2cur_pos", "[", "i", "]", "=", "(", "ori2cur_pos", "[", "i", "-", "1", "]", "[", "1", "]", ",", "ori2cur_pos", "[", "i", "-", "1", "]", "[", "1", "]", "+", "len", "(", "code_tokens", "[", "i", "]", ")", ")", "\n", "", "code_tokens", "=", "[", "y", "for", "x", "in", "code_tokens", "for", "y", "in", "x", "]", "\n", "# truncating", "\n", "code_tokens", "=", "code_tokens", "[", ":", "args", ".", "code_length", "+", "args", ".", "data_flow_length", "-", "2", "-", "min", "(", "len", "(", "dfg", ")", ",", "args", ".", "data_flow_length", ")", "]", "\n", "code_tokens", "=", "[", "tokenizer", ".", "cls_token", "]", "+", "code_tokens", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "code_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "code_tokens", ")", "\n", "position_idx", "=", "[", "i", "+", "tokenizer", ".", "pad_token_id", "+", "1", "for", "i", "in", "range", "(", "len", "(", "code_tokens", ")", ")", "]", "\n", "dfg", "=", "dfg", "[", ":", "args", ".", "code_length", "+", "args", ".", "data_flow_length", "-", "len", "(", "code_tokens", ")", "]", "\n", "code_tokens", "+=", "[", "x", "[", "0", "]", "for", "x", "in", "dfg", "]", "\n", "position_idx", "+=", "[", "0", "for", "x", "in", "dfg", "]", "\n", "code_ids", "+=", "[", "tokenizer", ".", "unk_token_id", "for", "x", "in", "dfg", "]", "\n", "padding_length", "=", "args", ".", "code_length", "+", "args", ".", "data_flow_length", "-", "len", "(", "code_ids", ")", "\n", "position_idx", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n", "code_ids", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n", "# reindex", "\n", "reverse_index", "=", "{", "}", "\n", "for", "idx", ",", "x", "in", "enumerate", "(", "dfg", ")", ":", "\n", "        ", "reverse_index", "[", "x", "[", "1", "]", "]", "=", "idx", "\n", "", "for", "idx", ",", "x", "in", "enumerate", "(", "dfg", ")", ":", "\n", "        ", "dfg", "[", "idx", "]", "=", "x", "[", ":", "-", "1", "]", "+", "(", "[", "reverse_index", "[", "i", "]", "for", "i", "in", "x", "[", "-", "1", "]", "if", "i", "in", "reverse_index", "]", ",", ")", "\n", "", "dfg_to_dfg", "=", "[", "x", "[", "-", "1", "]", "for", "x", "in", "dfg", "]", "\n", "dfg_to_code", "=", "[", "ori2cur_pos", "[", "x", "[", "1", "]", "]", "for", "x", "in", "dfg", "]", "\n", "length", "=", "len", "(", "[", "tokenizer", ".", "cls_token", "]", ")", "\n", "dfg_to_code", "=", "[", "(", "x", "[", "0", "]", "+", "length", ",", "x", "[", "1", "]", "+", "length", ")", "for", "x", "in", "dfg_to_code", "]", "\n", "# nl", "\n", "nl", "=", "' '", ".", "join", "(", "js", "[", "'docstring_tokens'", "]", ")", "\n", "nl_tokens", "=", "tokenizer", ".", "tokenize", "(", "nl", ")", "[", ":", "args", ".", "nl_length", "-", "2", "]", "\n", "nl_tokens", "=", "[", "tokenizer", ".", "cls_token", "]", "+", "nl_tokens", "+", "[", "tokenizer", ".", "sep_token", "]", "\n", "nl_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "nl_tokens", ")", "\n", "padding_length", "=", "args", ".", "nl_length", "-", "len", "(", "nl_ids", ")", "\n", "nl_ids", "+=", "[", "tokenizer", ".", "pad_token_id", "]", "*", "padding_length", "\n", "\n", "return", "InputFeatures", "(", "code_tokens", ",", "code_ids", ",", "position_idx", ",", "dfg_to_code", ",", "dfg_to_dfg", ",", "nl_tokens", ",", "nl_ids", ",", "js", "[", "'url'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.set_seed": [[238, 245], ["random.seed", "str", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed"], "function", ["None"], ["", "", "def", "set_seed", "(", "seed", "=", "42", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "os", ".", "environ", "[", "'PYHTONHASHSEED'", "]", "=", "str", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed", "(", "seed", ")", "\n", "torch", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train": [[247, 327], ["run_large.TextDataset", "torch.utils.data.RandomSampler", "torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.zero_grad", "torch.nn.DataParallel.train", "range", "torch.nn.DataParallel.parameters", "torch.nn.DataParallel", "len", "enumerate", "run_large.evaluate", "evaluate.items", "len", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "torch.nn.DataParallel.", "torch.nn.DataParallel.", "torch.einsum", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "loss_fct.item", "loss_fct.backward", "torch.nn.utils.clip_grad_norm_", "transformers.AdamW.step", "transformers.AdamW.zero_grad", "transformers.get_linear_schedule_with_warmup.step", "logger.info", "logger.info", "logger.info", "logger.info", "os.path.join", "os.path.join", "torch.save", "logger.info", "len", "torch.arange", "logger.info", "torch.nn.DataParallel.parameters", "round", "round", "os.path.exists", "os.makedirs", "hasattr", "model_to_save.state_dict", "batch[].to.size", "round"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.pacing_functions.step"], ["", "def", "train", "(", "args", ",", "model", ",", "tokenizer", ",", "pool", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "# get training dataset", "\n", "train_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "train_data_file", ",", "pool", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n", "# get optimizer and scheduler", "\n", "optimizer", "=", "AdamW", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "1e-8", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "0", ",", "\n", "num_training_steps", "=", "len", "(", "train_dataloader", ")", "*", "args", ".", "num_train_epochs", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "train_batch_size", "//", "args", ".", "n_gpu", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size  = %d\"", ",", "args", ".", "train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "len", "(", "train_dataloader", ")", "*", "args", ".", "num_train_epochs", ")", "\n", "\n", "# model.resize_token_embeddings(len(tokenizer))", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "tr_num", ",", "tr_loss", ",", "best_mrr", "=", "0", ",", "0", ",", "0", "\n", "for", "idx", "in", "range", "(", "args", ".", "num_train_epochs", ")", ":", "\n", "        ", "for", "step", ",", "batch", "in", "enumerate", "(", "train_dataloader", ")", ":", "\n", "# get inputs", "\n", "            ", "code_inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "attn_mask", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "position_idx", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "nl_inputs", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "# get code and nl vectors", "\n", "code_vec", "=", "model", "(", "code_inputs", "=", "code_inputs", ",", "attn_mask", "=", "attn_mask", ",", "position_idx", "=", "position_idx", ")", "\n", "nl_vec", "=", "model", "(", "nl_inputs", "=", "nl_inputs", ")", "\n", "\n", "# calculate scores and loss", "\n", "scores", "=", "torch", ".", "einsum", "(", "\"ab,cb->ac\"", ",", "nl_vec", ",", "code_vec", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "scores", ",", "torch", ".", "arange", "(", "code_inputs", ".", "size", "(", "0", ")", ",", "device", "=", "scores", ".", "device", ")", ")", "\n", "\n", "# report loss", "\n", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "tr_num", "+=", "1", "\n", "if", "(", "step", "+", "1", ")", "%", "100", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"epoch {} step {} loss {}\"", ".", "format", "(", "idx", ",", "step", "+", "1", ",", "round", "(", "tr_loss", "/", "tr_num", ",", "5", ")", ")", ")", "\n", "tr_loss", "=", "0", "\n", "tr_num", "=", "0", "\n", "\n", "# backward", "\n", "", "loss", ".", "backward", "(", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "# evaluate", "\n", "", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "args", ".", "eval_data_file", ",", "pool", ",", "eval_when_training", "=", "True", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "round", "(", "value", ",", "4", ")", ")", "\n", "\n", "# save best model", "\n", "", "if", "results", "[", "'eval_mrr'", "]", ">", "best_mrr", ":", "\n", "            ", "best_mrr", "=", "results", "[", "'eval_mrr'", "]", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "logger", ".", "info", "(", "\"  Best mrr:%s\"", ",", "round", "(", "best_mrr", ",", "4", ")", ")", "\n", "logger", ".", "info", "(", "\"  \"", "+", "\"*\"", "*", "20", ")", "\n", "\n", "checkpoint_prefix", "=", "'checkpoint-best-mrr'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'{}'", ".", "format", "(", "'model_large.bin'", ")", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_dir", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate": [[329, 411], ["run_large.TextDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "run_large.TextDataset", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "torch.nn.DataParallel.train", "numpy.concatenate", "numpy.concatenate", "numpy.matmul", "zip", "torch.nn.DataParallel", "len", "len", "batch[].to", "batch[].to", "batch[].to", "batch[].to", "numpy.save", "numpy.argsort", "nl_urls.append", "code_urls.append", "float", "torch.no_grad", "torch.nn.DataParallel.", "np.concatenate.append", "torch.no_grad", "torch.nn.DataParallel.", "np.concatenate.append", "example.url.find", "example.url.rfind", "example.url.find", "example.url.rfind", "ranks.append", "ranks.append", "numpy.mean", "model.cpu().numpy", "model.cpu().numpy", "len", "len", "model.cpu", "model.cpu"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train"], ["", "", "", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "file_name", ",", "pool", ",", "eval_when_training", "=", "False", ")", ":", "\n", "    ", "query_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "file_name", ",", "pool", ")", "\n", "query_sampler", "=", "SequentialSampler", "(", "query_dataset", ")", "\n", "query_dataloader", "=", "DataLoader", "(", "query_dataset", ",", "sampler", "=", "query_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n", "code_dataset", "=", "TextDataset", "(", "tokenizer", ",", "args", ",", "args", ".", "codebase_file", ",", "pool", ")", "\n", "code_sampler", "=", "SequentialSampler", "(", "code_dataset", ")", "\n", "code_dataloader", "=", "DataLoader", "(", "code_dataset", ",", "sampler", "=", "code_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "eval_when_training", "is", "False", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num queries = %d\"", ",", "len", "(", "query_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num codes = %d\"", ",", "len", "(", "code_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "code_vecs", "=", "[", "]", "\n", "nl_vecs", "=", "[", "]", "\n", "for", "batch", "in", "query_dataloader", ":", "\n", "        ", "nl_inputs", "=", "batch", "[", "3", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "nl_vec", "=", "model", "(", "nl_inputs", "=", "nl_inputs", ")", "\n", "nl_vecs", ".", "append", "(", "nl_vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "", "", "for", "batch", "in", "code_dataloader", ":", "\n", "        ", "code_inputs", "=", "batch", "[", "0", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "attn_mask", "=", "batch", "[", "1", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "position_idx", "=", "batch", "[", "2", "]", ".", "to", "(", "args", ".", "device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "code_vec", "=", "model", "(", "code_inputs", "=", "code_inputs", ",", "attn_mask", "=", "attn_mask", ",", "position_idx", "=", "position_idx", ")", "\n", "code_vecs", ".", "append", "(", "code_vec", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "", "model", ".", "train", "(", ")", "\n", "code_vecs", "=", "np", ".", "concatenate", "(", "code_vecs", ",", "0", ")", "\n", "nl_vecs", "=", "np", ".", "concatenate", "(", "nl_vecs", ",", "0", ")", "\n", "\n", "scores", "=", "np", ".", "matmul", "(", "nl_vecs", ",", "code_vecs", ".", "T", ")", "\n", "if", "'test'", "in", "file_name", ":", "\n", "        ", "fname", "=", "\"scores\"", "+", "file_name", "[", "-", "5", "]", "+", "\".npy\"", "\n", "np", ".", "save", "(", "fname", ",", "scores", ")", "\n", "", "sort_ids", "=", "np", ".", "argsort", "(", "scores", ",", "axis", "=", "-", "1", ",", "kind", "=", "'quicksort'", ",", "order", "=", "None", ")", "[", ":", ",", ":", ":", "-", "1", "]", "\n", "\n", "nl_urls", "=", "[", "]", "\n", "code_urls", "=", "[", "]", "\n", "for", "example", "in", "query_dataset", ".", "examples", ":", "\n", "        ", "temp", "=", "example", ".", "url", "\n", "if", "(", "example", ".", "url", ")", ".", "find", "(", "\"_\"", ")", "!=", "-", "1", ":", "\n", "            ", "loc", "=", "(", "example", ".", "url", ")", ".", "rfind", "(", "\"_\"", ")", "\n", "if", "loc", "+", "3", ">=", "len", "(", "example", ".", "url", ")", ":", "\n", "                ", "temp", "=", "example", ".", "url", "[", ":", "loc", "]", "\n", "", "", "nl_urls", ".", "append", "(", "temp", ")", "\n", "\n", "", "for", "example", "in", "code_dataset", ".", "examples", ":", "\n", "        ", "temp", "=", "example", ".", "url", "\n", "if", "(", "example", ".", "url", ")", ".", "find", "(", "\"_\"", ")", "!=", "-", "1", ":", "\n", "            ", "loc", "=", "(", "example", ".", "url", ")", ".", "rfind", "(", "\"_\"", ")", "\n", "if", "loc", "+", "3", ">=", "len", "(", "example", ".", "url", ")", ":", "\n", "                ", "temp", "=", "example", ".", "url", "[", ":", "loc", "]", "\n", "", "", "code_urls", ".", "append", "(", "temp", ")", "\n", "\n", "", "ranks", "=", "[", "]", "\n", "for", "url", ",", "sort_id", "in", "zip", "(", "nl_urls", ",", "sort_ids", ")", ":", "\n", "        ", "rank", "=", "0", "\n", "find", "=", "False", "\n", "for", "idx", "in", "sort_id", "[", ":", "1000", "]", ":", "\n", "            ", "if", "find", "is", "False", ":", "\n", "                ", "rank", "+=", "1", "\n", "", "if", "code_urls", "[", "idx", "]", "==", "url", ":", "\n", "                ", "find", "=", "True", "\n", "", "", "if", "find", ":", "\n", "            ", "ranks", ".", "append", "(", "1", "/", "rank", ")", "\n", "", "else", ":", "\n", "            ", "ranks", ".", "append", "(", "0", ")", "\n", "\n", "", "", "result", "=", "{", "\n", "\"eval_mrr\"", ":", "float", "(", "np", ".", "mean", "(", "ranks", ")", ")", "\n", "}", "\n", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.main": [[413, 518], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "multiprocessing.Pool", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "torch.device", "torch.cuda.device_count", "logger.info", "run_large.set_seed", "transformers.RobertaConfig.from_pretrained", "transformers.RobertaTokenizer.from_pretrained", "transformers.RobertaModel.from_pretrained", "model.Model", "logger.info", "model.Model.to", "run_large.train", "os.path.join", "model.Model.load_state_dict", "model.Model.to", "run_large.evaluate", "logger.info", "sorted", "os.path.join", "model.Model.load_state_dict", "model.Model.to", "run_large.evaluate", "logger.info", "sorted", "torch.cuda.is_available", "torch.load", "evaluate.keys", "logger.info", "torch.load", "evaluate.keys", "logger.info", "str", "str", "round", "round"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.set_seed", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.train", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate", "home.repos.pwc.inspect_result.wangdeze18_DACL.codesearch.run_large.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input training data file (a json file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the MRR(a jsonl file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input test data file to test the MRR(a josnl file).\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--codebase_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input test data file to codebase (a jsonl file).\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--lang\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"language.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--nl_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional NL input sequence length after tokenization.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--code_length\"", ",", "default", "=", "256", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional Code input sequence length after tokenization.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_flow_length\"", ",", "default", "=", "64", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Optional Data Flow input sequence length after tokenization.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_test\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the test set.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "pool", "=", "multiprocessing", ".", "Pool", "(", "cpu_cont", ")", "\n", "\n", "# print arguments", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# set log", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s -   %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "level", "=", "logging", ".", "INFO", ")", "\n", "# set device", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "args", ".", "device", "=", "device", "\n", "logger", ".", "info", "(", "\"device: %s, n_gpu: %s\"", ",", "device", ",", "args", ".", "n_gpu", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ".", "seed", ")", "\n", "\n", "# build model", "\n", "config", "=", "RobertaConfig", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ")", "\n", "tokenizer", "=", "RobertaTokenizer", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", ")", "\n", "model", "=", "RobertaModel", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ")", "\n", "model", "=", "Model", "(", "model", ")", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train", "(", "args", ",", "model", ",", "tokenizer", ",", "pool", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-mrr/model_large.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ",", "strict", "=", "False", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "args", ".", "eval_data_file", ",", "pool", ")", "\n", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "round", "(", "result", "[", "key", "]", ",", "4", ")", ")", ")", "\n", "\n", "", "", "if", "args", ".", "do_test", ":", "\n", "        ", "checkpoint_prefix", "=", "'checkpoint-best-mrr/model_large.bin'", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'{}'", ".", "format", "(", "checkpoint_prefix", ")", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "output_dir", ")", ",", "strict", "=", "False", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "args", ".", "test_data_file", ",", "pool", ")", "\n", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "round", "(", "result", "[", "key", "]", ",", "4", ")", ")", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.dataset.cleandata.cleanCla": [[11, 24], ["open", "open.readlines", "print", "transDic[].append", "print", "open", "f.write", "str", "len"], "function", ["None"], ["", "", "def", "cleanCla", "(", "source_file", ",", "filename", ")", ":", "\n", "\n", "    ", "content", "=", "open", "(", "source_file", ",", "\"r\"", ")", "\n", "lines", "=", "content", ".", "readlines", "(", ")", "\n", "newl", "=", "\"\"", ".", "join", "(", "lines", "[", "1", ":", "-", "1", "]", ")", "\n", "print", "(", "newl", ")", "\n", "#filename = filename.replace('n',\"\")", "\n", "fileid", "=", "filename", "[", ":", "-", "5", "]", "+", "\"_\"", "+", "str", "(", "len", "(", "transDic", "[", "filename", "]", ")", ")", "+", "\".java\"", "\n", "transDic", "[", "filename", "]", ".", "append", "(", "fileid", ")", "\n", "newfilename", "=", "\"./smallClean/\"", "+", "fileid", "\n", "print", "(", "fileid", ")", "\n", "with", "open", "(", "newfilename", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "newl", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.dataset.preprocesstxt.transfertrain": [[12, 30], ["open", "jsonlines.open", "line.strip.strip", "json.loads", "data.append", "writer.write", "open", "open.read", "open.close", "data.append", "str"], "function", ["None"], ["def", "transfertrain", "(", "origin_data", ",", "output_data", ")", ":", "\n", "    ", "data", "=", "[", "]", "\n", "with", "open", "(", "origin_data", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "data", ".", "append", "(", "js", ")", "\n", "num", "=", "url_to_num", "[", "js", "[", "'url'", "]", "]", "\n", "translist", "=", "smallDict", "[", "str", "(", "num", ")", "+", "\".java\"", "]", "\n", "for", "transfile", "in", "translist", ":", "\n", "                ", "transf", "=", "open", "(", "\"./smallClean/\"", "+", "transfile", ",", "\"r\"", ")", "\n", "js", "[", "'original_string'", "]", "=", "transf", ".", "read", "(", ")", "\n", "transf", ".", "close", "(", ")", "\n", "data", ".", "append", "(", "js", ")", "\n", "\n", "", "", "", "with", "jsonlines", ".", "open", "(", "output_data", ",", "mode", "=", "'w'", ")", "as", "writer", ":", "\n", "        ", "for", "i", "in", "data", ":", "\n", "            ", "writer", ".", "write", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.dataset.preprocesstxt.transfervalid": [[32, 51], ["open", "jsonlines.open", "line.strip.strip", "json.loads", "data.append", "writer.write", "transfile.find", "data.append", "str"], "function", ["None"], ["", "", "", "def", "transfervalid", "(", "origin_data", ",", "output_data", ")", ":", "\n", "    ", "data", "=", "[", "]", "\n", "with", "open", "(", "origin_data", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "data", ".", "append", "(", "js", ")", "\n", "num", "=", "url_to_num", "[", "js", "[", "'url'", "]", "]", "\n", "translist", "=", "smallDict", "[", "str", "(", "num", ")", "+", "\".java\"", "]", "\n", "for", "transfile", "in", "translist", ":", "\n", "                ", "loc", "=", "transfile", ".", "find", "(", "\"_\"", ")", "\n", "suffix", "=", "transfile", "[", "loc", ":", "loc", "+", "2", "]", "\n", "temp", "=", "js", "\n", "temp", "[", "'url'", "]", "=", "js", "[", "'url'", "]", "+", "suffix", "\n", "data", ".", "append", "(", "temp", ")", "\n", "\n", "", "", "", "with", "jsonlines", ".", "open", "(", "output_data", ",", "mode", "=", "'w'", ")", "as", "writer", ":", "\n", "        ", "for", "i", "in", "data", ":", "\n", "            ", "writer", ".", "write", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.dataset.preprocesstxt.select": [[52, 56], ["len", "random.sample"], "function", ["None"], ["", "", "", "def", "select", "(", "file_key", ")", ":", "\n", "    ", "if", "len", "(", "smallDict", "[", "file_key", "]", ")", "==", "0", ":", "\n", "        ", "return", "file_key", "\n", "", "return", "random", ".", "sample", "(", "smallDict", "[", "file_key", "]", ",", "1", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.dataset.preprocesstxt.transfer": [[57, 75], ["open", "jsonlines.open", "line.strip.strip", "json.loads", "preprocesstxt.select", "select.find", "data.append", "writer.write", "str"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.dataset.preprocesstxt.select"], ["", "def", "transfer", "(", "origin_data", ",", "output_data", ")", ":", "\n", "    ", "data", "=", "[", "]", "\n", "with", "open", "(", "origin_data", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "line", "=", "line", ".", "strip", "(", ")", "\n", "js", "=", "json", ".", "loads", "(", "line", ")", "\n", "num", "=", "url_to_num", "[", "js", "[", "'url'", "]", "]", "\n", "\n", "transfile", "=", "select", "(", "str", "(", "num", ")", "+", "\".java\"", ")", "\n", "loc", "=", "transfile", ".", "find", "(", "\"_\"", ")", "\n", "suffix", "=", "transfile", "[", "loc", ":", "loc", "+", "2", "]", "\n", "temp", "=", "js", "\n", "temp", "[", "'url'", "]", "=", "js", "[", "'url'", "]", "+", "suffix", "\n", "data", ".", "append", "(", "temp", ")", "\n", "\n", "", "", "with", "jsonlines", ".", "open", "(", "output_data", ",", "mode", "=", "'w'", ")", "as", "writer", ":", "\n", "        ", "for", "i", "in", "data", ":", "\n", "            ", "writer", ".", "write", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.data_preparation(4.1).to_correct.write_file": [[5, 10], ["open", "range", "open.close", "len", "open.write"], "function", ["None"], ["def", "write_file", "(", "filename", ",", "a_list", ")", ":", "\n", "    ", "fw", "=", "open", "(", "filename", ",", "'w'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "a_list", ")", ")", ":", "\n", "        ", "fw", ".", "write", "(", "a_list", "[", "i", "]", "+", "'\\n'", ")", "\n", "", "fw", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.data_preparation(4.1).to_correct.read_file": [[11, 16], ["open", "open.read", "open.close"], "function", ["None"], ["", "def", "read_file", "(", "filename", ")", ":", "\n", "    ", "f", "=", "open", "(", "filename", ",", "encoding", "=", "'unicode_escape'", ")", "\n", "doc_str", "=", "f", ".", "read", "(", ")", "\n", "f", ".", "close", "(", ")", "\n", "return", "doc_str", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.data_preparation(4.1).to_correct.correct_define": [[17, 28], ["to_correct.read_file", "read_file.find", "open", "open.write", "open.close", "print", "str", "len", "len"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.data_preparation(4.1).to_correct.read_file"], ["", "def", "correct_define", "(", "cpp_name", ",", "error_char", ")", ":", "\n", "    ", "label", "=", "\"using namespace std;\"", "\n", "doc_str", "=", "read_file", "(", "cpp_name", ")", "\n", "index", "=", "doc_str", ".", "find", "(", "label", ")", "\n", "if", "index", "!=", "-", "1", ":", "\n", "        ", "fw", "=", "open", "(", "cpp_name", ",", "'w'", ")", "\n", "new_str", "=", "doc_str", "[", ":", "index", "+", "len", "(", "label", ")", "]", "+", "\"\\n\"", "+", "\"#define\"", "+", "\" \"", "+", "error_char", "+", "\" \"", "+", "str", "(", "1000", ")", "+", "doc_str", "[", "index", "+", "len", "(", "label", ")", ":", "]", "\n", "fw", ".", "write", "(", "new_str", ")", "\n", "fw", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "cpp_name", ",", "\"correct_define exception\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.data_preparation(4.1).to_correct.correct_gets": [[33, 48], ["to_correct.read_file", "read_file.find", "open", "open.write", "open.close", "read_file.find", "read_file.find"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.data_preparation(4.1).to_correct.read_file"], ["", "", "def", "correct_gets", "(", "cpp_name", ")", ":", "\n", "    ", "label", "=", "\"gets(\"", "\n", "doc_str", "=", "read_file", "(", "cpp_name", ")", "\n", "index", "=", "doc_str", ".", "find", "(", "label", ")", "\n", "while", "(", "index", "!=", "-", "1", ")", ":", "\n", "        ", "index_r", "=", "doc_str", ".", "find", "(", "')'", ",", "index", ")", "\n", "content", "=", "doc_str", "[", ":", "index_r", "]", "[", "index", "+", "5", ":", "]", "\n", "doc_str", "=", "doc_str", "[", ":", "index", "]", "+", "\"\\n\"", "+", "\"cin>>\"", "+", "content", "+", "doc_str", "[", "index_r", "+", "1", ":", "]", "\n", "\n", "index", "=", "doc_str", ".", "find", "(", "label", ")", "\n", "\n", "#print(doc_str)", "\n", "", "fw", "=", "open", "(", "cpp_name", ",", "'w'", ")", "\n", "fw", ".", "write", "(", "doc_str", ")", "\n", "fw", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.data_preparation(4.1).to_correct.correct_int_main": [[49, 67], ["to_correct.read_file", "read_file.find", "open", "open", "read_file.find", "open.write", "open.close", "len"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.data_preparation(4.1).to_correct.read_file"], ["", "def", "correct_int_main", "(", "cpp_name", ")", ":", "\n", "    ", "label", "=", "\"main()\"", "\n", "doc_str", "=", "read_file", "(", "cpp_name", ")", "\n", "index", "=", "doc_str", ".", "find", "(", "label", ")", "\n", "if", "index", "!=", "-", "1", ":", "\n", "        ", "fw", "=", "open", "(", "cpp_name", ",", "'w'", ")", "\n", "new_str", "=", "doc_str", "[", ":", "index", "]", "+", "\"int \"", "+", "doc_str", "[", "index", ":", "]", "\n", "#print(new_str)", "\n", "#fw.write(new_str)", "\n", "#fw.close()", "\n", "", "else", ":", "\n", "        ", "fw", "=", "open", "(", "cpp_name", ",", "'w'", ")", "\n", "label", "=", "\"main ()\"", "\n", "index", "=", "doc_str", ".", "find", "(", "label", ")", "\n", "new_str", "=", "doc_str", "[", ":", "index", "]", "+", "\"int main()\"", "+", "doc_str", "[", "index", "+", "len", "(", "label", ")", ":", "]", "\n", "#print(new_str)", "\n", "fw", ".", "write", "(", "new_str", ")", "\n", "fw", ".", "close", "(", ")", "\n", "#print(cpp_name, \"correct_int_main exception\")", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.data_preparation(4.1).to_correct.correct_none_return": [[69, 81], ["to_correct.read_file", "read_file.find", "open", "open.write", "open.close", "print", "len"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.data_preparation(4.1).to_correct.read_file"], ["", "", "def", "correct_none_return", "(", "cpp_name", ")", ":", "\n", "    ", "label", "=", "\"return ;\"", "\n", "doc_str", "=", "read_file", "(", "cpp_name", ")", "\n", "index", "=", "doc_str", ".", "find", "(", "label", ")", "\n", "if", "index", "!=", "-", "1", ":", "\n", "        ", "fw", "=", "open", "(", "cpp_name", ",", "'w'", ")", "\n", "new_str", "=", "doc_str", "[", ":", "index", "]", "+", "\"return 0;\"", "+", "doc_str", "[", "index", "+", "len", "(", "label", ")", ":", "]", "\n", "#print(new_str)", "\n", "fw", ".", "write", "(", "new_str", ")", "\n", "fw", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "cpp_name", ",", "\"correct_none_return exception\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.data_preparation(4.1).to_correct.correct_ambiguous": [[82, 91], ["to_correct.read_file", "re.sub", "open", "open.write", "open.close"], "function", ["home.repos.pwc.inspect_result.wangdeze18_DACL.data_preparation(4.1).to_correct.read_file"], ["", "", "def", "correct_ambiguous", "(", "cpp_name", ",", "error_char", ")", ":", "\n", "    ", "doc_str", "=", "read_file", "(", "cpp_name", ")", "\n", "\n", "new_str", "=", "re", ".", "sub", "(", "error_char", ",", "error_char", "+", "\"_1\"", ",", "doc_str", ")", "\n", "#print(new_str)", "\n", "\n", "fw", "=", "open", "(", "cpp_name", ",", "'w'", ")", "\n", "fw", ".", "write", "(", "new_str", ")", "\n", "fw", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.data_preparation(4.1).to_correct.correct_missing": [[92, 109], ["open", "open.readlines", "open.close", "range", "open", "open.write", "open.close", "len", "lines[].replace"], "function", ["None"], ["", "def", "correct_missing", "(", "cpp_name", ",", "line_num_list", ")", ":", "\n", "\n", "    ", "f", "=", "open", "(", "cpp_name", ")", "\n", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "f", ".", "close", "(", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "line_num_list", ")", ",", "2", ")", ":", "\n", "        ", "num", "=", "line_num_list", "[", "i", "]", "-", "1", "\n", "#print(num)", "\n", "#print(lines[num])", "\n", "lines", "[", "num", "]", "=", "lines", "[", "num", "]", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "#print(lines[num])", "\n", "\n", "\n", "", "doc_str", "=", "\"\"", ".", "join", "(", "lines", ")", "\n", "fw", "=", "open", "(", "cpp_name", ",", "'w'", ")", "\n", "fw", ".", "write", "(", "doc_str", ")", "\n", "fw", ".", "close", "(", ")", "\n", "#print(doc_str)", "\n"]], "home.repos.pwc.inspect_result.wangdeze18_DACL.data_preparation(4.1).to_correct.excute_cmd": [[111, 117], ["cmd.split.split", "subprocess.run", "str"], "function", ["None"], ["", "def", "excute_cmd", "(", "cmd", ")", ":", "\n", "    ", "cmd", "=", "cmd", ".", "split", "(", "\" \"", ")", "\n", "p", "=", "subprocess", ".", "run", "(", "cmd", ",", "stderr", "=", "subprocess", ".", "PIPE", ",", "shell", "=", "False", ",", "timeout", "=", "145", ")", "\n", "err", "=", "p", ".", "stderr", "\n", "err", "=", "str", "(", "err", ",", "encoding", "=", "'utf-8'", ",", "errors", "=", "'ignore'", ")", "\n", "return", "err", "\n", "\n"]]}