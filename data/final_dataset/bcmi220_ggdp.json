{"home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.config": [[15, 33], ["transformers.file_utils.add_start_docstrings", "transformers.AutoConfig.from_pretrained"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.add_start_docstrings", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["@", "add_start_docstrings", "(", "AutoConfig", ".", "__doc__", ")", "\n", "def", "config", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"\n                # Using torch.hub !\n                import torch\n\n                config = torch.hub.load('huggingface/transformers', 'config', 'bert-base-uncased')  # Download configuration from S3 and cache.\n                config = torch.hub.load('huggingface/transformers', 'config', './test/bert_saved_model/')  # E.g. config (or model) was saved using `save_pretrained('./test/saved_model/')`\n                config = torch.hub.load('huggingface/transformers', 'config', './test/bert_saved_model/my_configuration.json')\n                config = torch.hub.load('huggingface/transformers', 'config', 'bert-base-uncased', output_attention=True, foo=False)\n                assert config.output_attention == True\n                config, unused_kwargs = torch.hub.load('huggingface/transformers', 'config', 'bert-base-uncased', output_attention=True, foo=False, return_unused_kwargs=True)\n                assert config.output_attention == True\n                assert unused_kwargs == {'foo': False}\n\n            \"\"\"", "\n", "\n", "return", "AutoConfig", ".", "from_pretrained", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.tokenizer": [[35, 47], ["transformers.file_utils.add_start_docstrings", "transformers.AutoTokenizer.from_pretrained"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.add_start_docstrings", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "add_start_docstrings", "(", "AutoTokenizer", ".", "__doc__", ")", "\n", "def", "tokenizer", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"\n        # Using torch.hub !\n        import torch\n\n        tokenizer = torch.hub.load('huggingface/transformers', 'tokenizer', 'bert-base-uncased')    # Download vocabulary from S3 and cache.\n        tokenizer = torch.hub.load('huggingface/transformers', 'tokenizer', './test/bert_saved_model/')  # E.g. tokenizer was saved using `save_pretrained('./test/saved_model/')`\n\n    \"\"\"", "\n", "\n", "return", "AutoTokenizer", ".", "from_pretrained", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.model": [[49, 66], ["transformers.file_utils.add_start_docstrings", "transformers.AutoModel.from_pretrained"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.add_start_docstrings", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "add_start_docstrings", "(", "AutoModel", ".", "__doc__", ")", "\n", "def", "model", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"\n            # Using torch.hub !\n            import torch\n\n            model = torch.hub.load('huggingface/transformers', 'model', 'bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = torch.hub.load('huggingface/transformers', 'model', './test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = torch.hub.load('huggingface/transformers', 'model', 'bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = torch.hub.load('huggingface/transformers', 'model', './tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "\n", "return", "AutoModel", ".", "from_pretrained", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.modelWithLMHead": [[68, 84], ["transformers.file_utils.add_start_docstrings", "transformers.AutoModelWithLMHead.from_pretrained"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.add_start_docstrings", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "add_start_docstrings", "(", "AutoModelWithLMHead", ".", "__doc__", ")", "\n", "def", "modelWithLMHead", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"\n        # Using torch.hub !\n        import torch\n\n        model = torch.hub.load('huggingface/transformers', 'modelWithLMHead', 'bert-base-uncased')    # Download model and configuration from S3 and cache.\n        model = torch.hub.load('huggingface/transformers', 'modelWithLMHead', './test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n        model = torch.hub.load('huggingface/transformers', 'modelWithLMHead', 'bert-base-uncased', output_attention=True)  # Update configuration during loading\n        assert model.config.output_attention == True\n        # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n        config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n        model = torch.hub.load('huggingface/transformers', 'modelWithLMHead', './tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n    \"\"\"", "\n", "return", "AutoModelWithLMHead", ".", "from_pretrained", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.modelForSequenceClassification": [[86, 103], ["transformers.file_utils.add_start_docstrings", "transformers.AutoModelForSequenceClassification.from_pretrained"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.add_start_docstrings", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "add_start_docstrings", "(", "AutoModelForSequenceClassification", ".", "__doc__", ")", "\n", "def", "modelForSequenceClassification", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"\n            # Using torch.hub !\n            import torch\n\n            model = torch.hub.load('huggingface/transformers', 'modelForSequenceClassification', 'bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = torch.hub.load('huggingface/transformers', 'modelForSequenceClassification', './test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = torch.hub.load('huggingface/transformers', 'modelForSequenceClassification', 'bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = torch.hub.load('huggingface/transformers', 'modelForSequenceClassification', './tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "\n", "return", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.modelForQuestionAnswering": [[105, 121], ["transformers.file_utils.add_start_docstrings", "transformers.AutoModelForQuestionAnswering.from_pretrained"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.add_start_docstrings", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "add_start_docstrings", "(", "AutoModelForQuestionAnswering", ".", "__doc__", ")", "\n", "def", "modelForQuestionAnswering", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"\n        # Using torch.hub !\n        import torch\n\n        model = torch.hub.load('huggingface/transformers', 'modelForQuestionAnswering', 'bert-base-uncased')    # Download model and configuration from S3 and cache.\n        model = torch.hub.load('huggingface/transformers', 'modelForQuestionAnswering', './test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n        model = torch.hub.load('huggingface/transformers', 'modelForQuestionAnswering', 'bert-base-uncased', output_attention=True)  # Update configuration during loading\n        assert model.config.output_attention == True\n        # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n        config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n        model = torch.hub.load('huggingface/transformers', 'modelForQuestionAnswering', './tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n    \"\"\"", "\n", "return", "AutoModelForQuestionAnswering", ".", "from_pretrained", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.__init__": [[66, 115], ["tokenization_utils.PreTrainedTokenizer.__init__", "collections.Counter", "torch.load", "torch.load.items", "tokenization_transfo_xl.TransfoXLTokenizer.build_vocab"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.build_vocab"], ["def", "__init__", "(", "\n", "self", ",", "\n", "special", "=", "None", ",", "\n", "min_freq", "=", "0", ",", "\n", "max_size", "=", "None", ",", "\n", "lower_case", "=", "False", ",", "\n", "delimiter", "=", "None", ",", "\n", "vocab_file", "=", "None", ",", "\n", "pretrained_vocab_file", "=", "None", ",", "\n", "never_split", "=", "None", ",", "\n", "unk_token", "=", "\"<unk>\"", ",", "\n", "eos_token", "=", "\"<eos>\"", ",", "\n", "additional_special_tokens", "=", "[", "\"<formula>\"", "]", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "TransfoXLTokenizer", ",", "self", ")", ".", "__init__", "(", "\n", "unk_token", "=", "unk_token", ",", "eos_token", "=", "eos_token", ",", "additional_special_tokens", "=", "additional_special_tokens", ",", "**", "kwargs", "\n", ")", "\n", "\n", "self", ".", "max_len_single_sentence", "=", "(", "\n", "self", ".", "max_len", "\n", ")", "# no default special tokens - you can update this value if you add special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "(", "\n", "self", ".", "max_len", "\n", ")", "# no default special tokens - you can update this value if you add special tokens", "\n", "\n", "if", "never_split", "is", "None", ":", "\n", "            ", "never_split", "=", "self", ".", "all_special_tokens", "\n", "", "if", "special", "is", "None", ":", "\n", "            ", "special", "=", "[", "]", "\n", "", "self", ".", "counter", "=", "Counter", "(", ")", "\n", "self", ".", "special", "=", "special", "\n", "self", ".", "min_freq", "=", "min_freq", "\n", "self", ".", "max_size", "=", "max_size", "\n", "self", ".", "lower_case", "=", "lower_case", "\n", "self", ".", "delimiter", "=", "delimiter", "\n", "self", ".", "vocab_file", "=", "vocab_file", "\n", "self", ".", "never_split", "=", "never_split", "\n", "\n", "if", "pretrained_vocab_file", "is", "not", "None", ":", "\n", "# Hack because, honestly this tokenizer was not made to be used", "\n", "# in a library like ours, at all.", "\n", "            ", "vocab_dict", "=", "torch", ".", "load", "(", "pretrained_vocab_file", ")", "\n", "for", "key", ",", "value", "in", "vocab_dict", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "not", "in", "self", ".", "__dict__", ":", "\n", "                    ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "\n", "", "", "", "if", "vocab_file", "is", "not", "None", ":", "\n", "            ", "self", ".", "build_vocab", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_file": [[116, 131], ["os.path.exists", "logger.info", "open", "enumerate", "tokenization_transfo_xl.TransfoXLTokenizer.tokenize", "tokenization_transfo_xl.TransfoXLTokenizer.counter.update", "sents.append", "logger.info"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "", "def", "count_file", "(", "self", ",", "path", ",", "verbose", "=", "False", ",", "add_eos", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "logger", ".", "info", "(", "\"counting file {} ...\"", ".", "format", "(", "path", ")", ")", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "\n", "sents", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "\"    line {}\"", ".", "format", "(", "idx", ")", ")", "\n", "", "symbols", "=", "self", ".", "tokenize", "(", "line", ",", "add_eos", "=", "add_eos", ")", "\n", "self", ".", "counter", ".", "update", "(", "symbols", ")", "\n", "sents", ".", "append", "(", "symbols", ")", "\n", "\n", "", "", "return", "sents", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_sents": [[132, 142], ["enumerate", "logger.info", "tokenization_transfo_xl.TransfoXLTokenizer.counter.update", "logger.info", "len"], "methods", ["None"], ["", "def", "count_sents", "(", "self", ",", "sents", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            sents : a list of sentences, each a list of tokenized symbols\n        \"\"\"", "\n", "if", "verbose", ":", "\n", "            ", "logger", ".", "info", "(", "\"counting {} sents ...\"", ".", "format", "(", "len", "(", "sents", ")", ")", ")", "\n", "", "for", "idx", ",", "symbols", "in", "enumerate", "(", "sents", ")", ":", "\n", "            ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"    line {}\"", ".", "format", "(", "idx", ")", ")", "\n", "", "self", ".", "counter", ".", "update", "(", "symbols", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer._build_from_file": [[143, 157], ["collections.OrderedDict", "open", "tokenization_transfo_xl.TransfoXLTokenizer.add_symbol", "ValueError", "line.strip().split", "line.strip"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.add_symbol"], ["", "", "def", "_build_from_file", "(", "self", ",", "vocab_file", ")", ":", "\n", "        ", "self", ".", "idx2sym", "=", "[", "]", "\n", "self", ".", "sym2idx", "=", "OrderedDict", "(", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "symb", "=", "line", ".", "strip", "(", ")", ".", "split", "(", ")", "[", "0", "]", "\n", "self", ".", "add_symbol", "(", "symb", ")", "\n", "", "", "if", "\"<UNK>\"", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "unk_idx", "=", "self", ".", "sym2idx", "[", "\"<UNK>\"", "]", "\n", "", "elif", "\"<unk>\"", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "unk_idx", "=", "self", ".", "sym2idx", "[", "\"<unk>\"", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"No <unkown> token in vocabulary\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.save_vocabulary": [[158, 164], ["os.path.isdir", "torch.save", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save"], ["", "", "def", "save_vocabulary", "(", "self", ",", "vocab_path", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary to a directory or file.\"\"\"", "\n", "if", "os", ".", "path", ".", "isdir", "(", "vocab_path", ")", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "vocab_path", ",", "VOCAB_FILES_NAMES", "[", "\"pretrained_vocab_file\"", "]", ")", "\n", "", "torch", ".", "save", "(", "self", ".", "__dict__", ",", "vocab_file", ")", "\n", "return", "(", "vocab_file", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.build_vocab": [[165, 184], ["logger.info", "tokenization_transfo_xl.TransfoXLTokenizer._build_from_file", "logger.info", "logger.info", "collections.OrderedDict", "tokenization_transfo_xl.TransfoXLTokenizer.counter.most_common", "logger.info", "tokenization_transfo_xl.TransfoXLTokenizer.add_special", "tokenization_transfo_xl.TransfoXLTokenizer.add_symbol", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer._build_from_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.add_special", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.add_symbol"], ["", "def", "build_vocab", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "vocab_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"building vocab from {}\"", ".", "format", "(", "self", ".", "vocab_file", ")", ")", "\n", "self", ".", "_build_from_file", "(", "self", ".", "vocab_file", ")", "\n", "logger", ".", "info", "(", "\"final vocab size {}\"", ".", "format", "(", "len", "(", "self", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"building vocab with min_freq={}, max_size={}\"", ".", "format", "(", "self", ".", "min_freq", ",", "self", ".", "max_size", ")", ")", "\n", "self", ".", "idx2sym", "=", "[", "]", "\n", "self", ".", "sym2idx", "=", "OrderedDict", "(", ")", "\n", "\n", "for", "sym", "in", "self", ".", "special", ":", "\n", "                ", "self", ".", "add_special", "(", "sym", ")", "\n", "\n", "", "for", "sym", ",", "cnt", "in", "self", ".", "counter", ".", "most_common", "(", "self", ".", "max_size", ")", ":", "\n", "                ", "if", "cnt", "<", "self", ".", "min_freq", ":", "\n", "                    ", "break", "\n", "", "self", ".", "add_symbol", "(", "sym", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"final vocab size {} from {} unique tokens\"", ".", "format", "(", "len", "(", "self", ")", ",", "len", "(", "self", ".", "counter", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file": [[185, 201], ["os.path.exists", "logger.info", "open", "enumerate", "torch.cat", "tokenization_transfo_xl.TransfoXLTokenizer.tokenize", "torch.cat.append", "logger.info", "tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor"], ["", "", "def", "encode_file", "(", "self", ",", "path", ",", "ordered", "=", "False", ",", "verbose", "=", "False", ",", "add_eos", "=", "True", ",", "add_double_eos", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "logger", ".", "info", "(", "\"encoding file {} ...\"", ".", "format", "(", "path", ")", ")", "\n", "", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "encoded", "=", "[", "]", "\n", "with", "open", "(", "path", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "for", "idx", ",", "line", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "\"    line {}\"", ".", "format", "(", "idx", ")", ")", "\n", "", "symbols", "=", "self", ".", "tokenize", "(", "line", ",", "add_eos", "=", "add_eos", ",", "add_double_eos", "=", "add_double_eos", ")", "\n", "encoded", ".", "append", "(", "self", ".", "convert_to_tensor", "(", "symbols", ")", ")", "\n", "\n", "", "", "if", "ordered", ":", "\n", "            ", "encoded", "=", "torch", ".", "cat", "(", "encoded", ")", "\n", "\n", "", "return", "encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_sents": [[202, 215], ["enumerate", "logger.info", "torch.cat.append", "torch.cat", "logger.info", "tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor"], ["", "def", "encode_sents", "(", "self", ",", "sents", ",", "ordered", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "logger", ".", "info", "(", "\"encoding {} sents ...\"", ".", "format", "(", "len", "(", "sents", ")", ")", ")", "\n", "", "encoded", "=", "[", "]", "\n", "for", "idx", ",", "symbols", "in", "enumerate", "(", "sents", ")", ":", "\n", "            ", "if", "verbose", "and", "idx", ">", "0", "and", "idx", "%", "500000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"    line {}\"", ".", "format", "(", "idx", ")", ")", "\n", "", "encoded", ".", "append", "(", "self", ".", "convert_to_tensor", "(", "symbols", ")", ")", "\n", "\n", "", "if", "ordered", ":", "\n", "            ", "encoded", "=", "torch", ".", "cat", "(", "encoded", ")", "\n", "\n", "", "return", "encoded", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.add_special": [[216, 221], ["tokenization_transfo_xl.TransfoXLTokenizer.idx2sym.append", "setattr", "len", "sym.strip"], "methods", ["None"], ["", "def", "add_special", "(", "self", ",", "sym", ")", ":", "\n", "        ", "if", "sym", "not", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "idx2sym", ".", "append", "(", "sym", ")", "\n", "self", ".", "sym2idx", "[", "sym", "]", "=", "len", "(", "self", ".", "idx2sym", ")", "-", "1", "\n", "setattr", "(", "self", ",", "\"{}_idx\"", ".", "format", "(", "sym", ".", "strip", "(", "\"<>\"", ")", ")", ",", "self", ".", "sym2idx", "[", "sym", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.add_symbol": [[222, 226], ["tokenization_transfo_xl.TransfoXLTokenizer.idx2sym.append", "len"], "methods", ["None"], ["", "", "def", "add_symbol", "(", "self", ",", "sym", ")", ":", "\n", "        ", "if", "sym", "not", "in", "self", ".", "sym2idx", ":", "\n", "            ", "self", ".", "idx2sym", ".", "append", "(", "sym", ")", "\n", "self", ".", "sym2idx", "[", "sym", "]", "=", "len", "(", "self", ".", "idx2sym", ")", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer._convert_id_to_token": [[227, 231], ["len"], "methods", ["None"], ["", "", "def", "_convert_id_to_token", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"Converts an id in a token (BPE) using the vocab.\"\"\"", "\n", "assert", "0", "<=", "idx", "<", "len", "(", "self", ")", ",", "\"Index {} out of vocabulary range\"", ".", "format", "(", "idx", ")", "\n", "return", "self", ".", "idx2sym", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer._convert_token_to_id": [[232, 248], ["hasattr", "tokenization_transfo_xl.TransfoXLTokenizer.sym2idx.get", "ValueError"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "sym", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "if", "sym", "in", "self", ".", "sym2idx", ":", "\n", "            ", "return", "self", ".", "sym2idx", "[", "sym", "]", "\n", "", "else", ":", "\n", "# logger.info('encounter unk {}'.format(sym))", "\n", "# assert '<eos>' not in sym", "\n", "            ", "if", "hasattr", "(", "self", ",", "\"unk_idx\"", ")", ":", "\n", "                ", "return", "self", ".", "sym2idx", ".", "get", "(", "sym", ",", "self", ".", "unk_idx", ")", "\n", "# Backward compatibility with pre-trained models", "\n", "", "elif", "\"<unk>\"", "in", "self", ".", "sym2idx", ":", "\n", "                ", "return", "self", ".", "sym2idx", "[", "\"<unk>\"", "]", "\n", "", "elif", "\"<UNK>\"", "in", "self", ".", "sym2idx", ":", "\n", "                ", "return", "self", ".", "sym2idx", "[", "\"<UNK>\"", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Token not in vocabulary and no <unk> token in vocabulary for replacement\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.convert_tokens_to_string": [[249, 253], ["None"], "methods", ["None"], ["", "", "", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "\" \"", ".", "join", "(", "tokens", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor": [[254, 256], ["torch.LongTensor", "tokenization_transfo_xl.TransfoXLTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "convert_to_tensor", "(", "self", ",", "symbols", ")", ":", "\n", "        ", "return", "torch", ".", "LongTensor", "(", "self", ".", "convert_tokens_to_ids", "(", "symbols", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.vocab_size": [[257, 260], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx2sym", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer._tokenize": [[261, 279], ["line.lower.lower.strip", "line.lower.lower.lower", "line.lower.lower.split"], "methods", ["None"], ["", "def", "_tokenize", "(", "self", ",", "line", ",", "add_eos", "=", "False", ",", "add_double_eos", "=", "False", ")", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "# convert to lower case", "\n", "if", "self", ".", "lower_case", ":", "\n", "            ", "line", "=", "line", ".", "lower", "(", ")", "\n", "\n", "# empty delimiter '' will evaluate False", "\n", "", "if", "self", ".", "delimiter", "==", "\"\"", ":", "\n", "            ", "symbols", "=", "line", "\n", "", "else", ":", "\n", "            ", "symbols", "=", "line", ".", "split", "(", "self", ".", "delimiter", ")", "\n", "\n", "", "if", "add_double_eos", ":", "# lm1b", "\n", "            ", "return", "[", "\"<S>\"", "]", "+", "symbols", "+", "[", "\"<S>\"", "]", "\n", "", "elif", "add_eos", ":", "\n", "            ", "return", "symbols", "+", "[", "\"<eos>\"", "]", "\n", "", "else", ":", "\n", "            ", "return", "symbols", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMOrderedIterator.__init__": [[282, 303], ["data.narrow.narrow.narrow", "data.narrow.narrow.view().t().contiguous().to", "data.narrow.narrow.size", "data.narrow.narrow.view().t().contiguous", "data.narrow.narrow.view().t", "data.narrow.narrow.view"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "bsz", ",", "bptt", ",", "device", "=", "\"cpu\"", ",", "ext_len", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            data -- LongTensor -- the LongTensor is strictly ordered\n        \"\"\"", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "bptt", "=", "bptt", "\n", "self", ".", "ext_len", "=", "ext_len", "if", "ext_len", "is", "not", "None", "else", "0", "\n", "\n", "self", ".", "device", "=", "device", "\n", "\n", "# Work out how cleanly we can divide the dataset into bsz parts.", "\n", "self", ".", "n_step", "=", "data", ".", "size", "(", "0", ")", "//", "bsz", "\n", "\n", "# Trim off any extra elements that wouldn't cleanly fit (remainders).", "\n", "data", "=", "data", ".", "narrow", "(", "0", ",", "0", ",", "self", ".", "n_step", "*", "bsz", ")", "\n", "\n", "# Evenly divide the data across the bsz batches.", "\n", "self", ".", "data", "=", "data", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Number of mini-batches", "\n", "self", ".", "n_batch", "=", "(", "self", ".", "n_step", "+", "self", ".", "bptt", "-", "1", ")", "//", "self", ".", "bptt", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMOrderedIterator.get_batch": [[304, 319], ["min", "max", "data.transpose().contiguous().to", "target.transpose().contiguous().to", "data.transpose().contiguous", "target.transpose().contiguous", "tokenization_transfo_xl.LMOrderedIterator.data.size", "data.transpose", "target.transpose"], "methods", ["None"], ["", "def", "get_batch", "(", "self", ",", "i", ",", "bptt", "=", "None", ")", ":", "\n", "        ", "if", "bptt", "is", "None", ":", "\n", "            ", "bptt", "=", "self", ".", "bptt", "\n", "", "seq_len", "=", "min", "(", "bptt", ",", "self", ".", "data", ".", "size", "(", "0", ")", "-", "1", "-", "i", ")", "\n", "\n", "end_idx", "=", "i", "+", "seq_len", "\n", "beg_idx", "=", "max", "(", "0", ",", "i", "-", "self", ".", "ext_len", ")", "\n", "\n", "data", "=", "self", ".", "data", "[", "beg_idx", ":", "end_idx", "]", "\n", "target", "=", "self", ".", "data", "[", "i", "+", "1", ":", "i", "+", "1", "+", "seq_len", "]", "\n", "\n", "data_out", "=", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "target_out", "=", "target", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "return", "data_out", ",", "target_out", ",", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMOrderedIterator.get_fixlen_iter": [[320, 323], ["range", "tokenization_transfo_xl.LMOrderedIterator.data.size", "tokenization_transfo_xl.LMOrderedIterator.get_batch"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMOrderedIterator.get_batch"], ["", "def", "get_fixlen_iter", "(", "self", ",", "start", "=", "0", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "start", ",", "self", ".", "data", ".", "size", "(", "0", ")", "-", "1", ",", "self", ".", "bptt", ")", ":", "\n", "            ", "yield", "self", ".", "get_batch", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMOrderedIterator.get_varlen_iter": [[324, 335], ["min", "tokenization_transfo_xl.LMOrderedIterator.get_batch", "max", "numpy.random.random", "int", "tokenization_transfo_xl.LMOrderedIterator.data.size", "numpy.random.normal"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMOrderedIterator.get_batch"], ["", "", "def", "get_varlen_iter", "(", "self", ",", "start", "=", "0", ",", "std", "=", "5", ",", "min_len", "=", "5", ",", "max_deviation", "=", "3", ")", ":", "\n", "        ", "max_len", "=", "self", ".", "bptt", "+", "max_deviation", "*", "std", "\n", "i", "=", "start", "\n", "while", "True", ":", "\n", "            ", "bptt", "=", "self", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "self", ".", "bptt", "/", "2.0", "\n", "bptt", "=", "min", "(", "max_len", ",", "max", "(", "min_len", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "std", ")", ")", ")", ")", "\n", "data", ",", "target", ",", "seq_len", "=", "self", ".", "get_batch", "(", "i", ",", "bptt", ")", "\n", "i", "+=", "seq_len", "\n", "yield", "data", ",", "target", ",", "seq_len", "\n", "if", "i", ">=", "self", ".", "data", ".", "size", "(", "0", ")", "-", "2", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMOrderedIterator.__iter__": [[336, 338], ["tokenization_transfo_xl.LMOrderedIterator.get_fixlen_iter"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMOrderedIterator.get_fixlen_iter"], ["", "", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "get_fixlen_iter", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMShuffledIterator.__init__": [[341, 353], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data", ",", "bsz", ",", "bptt", ",", "device", "=", "\"cpu\"", ",", "ext_len", "=", "None", ",", "shuffle", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            data -- list[LongTensor] -- there is no order among the LongTensors\n        \"\"\"", "\n", "self", ".", "data", "=", "data", "\n", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "bptt", "=", "bptt", "\n", "self", ".", "ext_len", "=", "ext_len", "if", "ext_len", "is", "not", "None", "else", "0", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMShuffledIterator.get_sent_stream": [[354, 361], ["numpy.random.permutation", "numpy.array", "len", "range", "len"], "methods", ["None"], ["", "def", "get_sent_stream", "(", "self", ")", ":", "\n", "# index iterator", "\n", "        ", "epoch_indices", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ".", "data", ")", ")", "if", "self", ".", "shuffle", "else", "np", ".", "array", "(", "range", "(", "len", "(", "self", ".", "data", ")", ")", ")", "\n", "\n", "# sentence iterator", "\n", "for", "idx", "in", "epoch_indices", ":", "\n", "            ", "yield", "self", ".", "data", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMShuffledIterator.stream_iterator": [[362, 408], ["torch.LongTensor", "torch.LongTensor", "data[].fill_", "torch.LongTensor.fill_", "range", "torch.LongTensor.transpose().contiguous().to", "torch.LongTensor.transpose().contiguous().to", "min", "torch.LongTensor.resize_", "torch.LongTensor.size", "torch.LongTensor.size", "torch.LongTensor.transpose().contiguous", "torch.LongTensor.transpose().contiguous", "min", "next", "torch.LongTensor.transpose", "torch.LongTensor.transpose", "len", "len"], "methods", ["None"], ["", "", "def", "stream_iterator", "(", "self", ",", "sent_stream", ")", ":", "\n", "# streams for each data in the batch", "\n", "        ", "streams", "=", "[", "None", "]", "*", "self", ".", "bsz", "\n", "\n", "data", "=", "torch", ".", "LongTensor", "(", "self", ".", "bptt", ",", "self", ".", "bsz", ")", "\n", "target", "=", "torch", ".", "LongTensor", "(", "self", ".", "bptt", ",", "self", ".", "bsz", ")", "\n", "\n", "n_retain", "=", "0", "\n", "\n", "while", "True", ":", "\n", "# data   : [n_retain+bptt x bsz]", "\n", "# target : [bptt x bsz]", "\n", "            ", "data", "[", "n_retain", ":", "]", ".", "fill_", "(", "-", "1", ")", "\n", "target", ".", "fill_", "(", "-", "1", ")", "\n", "\n", "valid_batch", "=", "True", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "bsz", ")", ":", "\n", "                ", "n_filled", "=", "0", "\n", "try", ":", "\n", "                    ", "while", "n_filled", "<", "self", ".", "bptt", ":", "\n", "                        ", "if", "streams", "[", "i", "]", "is", "None", "or", "len", "(", "streams", "[", "i", "]", ")", "<=", "1", ":", "\n", "                            ", "streams", "[", "i", "]", "=", "next", "(", "sent_stream", ")", "\n", "# number of new tokens to fill in", "\n", "", "n_new", "=", "min", "(", "len", "(", "streams", "[", "i", "]", ")", "-", "1", ",", "self", ".", "bptt", "-", "n_filled", ")", "\n", "# first n_retain tokens are retained from last batch", "\n", "data", "[", "n_retain", "+", "n_filled", ":", "n_retain", "+", "n_filled", "+", "n_new", ",", "i", "]", "=", "streams", "[", "i", "]", "[", ":", "n_new", "]", "\n", "target", "[", "n_filled", ":", "n_filled", "+", "n_new", ",", "i", "]", "=", "streams", "[", "i", "]", "[", "1", ":", "n_new", "+", "1", "]", "\n", "streams", "[", "i", "]", "=", "streams", "[", "i", "]", "[", "n_new", ":", "]", "\n", "n_filled", "+=", "n_new", "\n", "", "", "except", "StopIteration", ":", "\n", "                    ", "valid_batch", "=", "False", "\n", "break", "\n", "\n", "", "", "if", "not", "valid_batch", ":", "\n", "                ", "return", "\n", "\n", "", "data_out", "=", "data", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "target_out", "=", "target", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "yield", "data_out", ",", "target_out", ",", "self", ".", "bptt", "\n", "\n", "n_retain", "=", "min", "(", "data", ".", "size", "(", "0", ")", ",", "self", ".", "ext_len", ")", "\n", "if", "n_retain", ">", "0", ":", "\n", "                ", "data", "[", ":", "n_retain", "]", "=", "data", "[", "-", "n_retain", ":", "]", "\n", "", "data", ".", "resize_", "(", "n_retain", "+", "self", ".", "bptt", ",", "data", ".", "size", "(", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMShuffledIterator.__iter__": [[409, 415], ["tokenization_transfo_xl.LMShuffledIterator.get_sent_stream", "tokenization_transfo_xl.LMShuffledIterator.stream_iterator"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMShuffledIterator.stream_iterator"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "# sent_stream is an iterator", "\n", "        ", "sent_stream", "=", "self", ".", "get_sent_stream", "(", ")", "\n", "\n", "for", "batch", "in", "self", ".", "stream_iterator", "(", "sent_stream", ")", ":", "\n", "            ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMMultiFileIterator.__init__": [[418, 429], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "paths", ",", "vocab", ",", "bsz", ",", "bptt", ",", "device", "=", "\"cpu\"", ",", "ext_len", "=", "None", ",", "shuffle", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "paths", "=", "paths", "\n", "self", ".", "vocab", "=", "vocab", "\n", "\n", "self", ".", "bsz", "=", "bsz", "\n", "self", ".", "bptt", "=", "bptt", "\n", "self", ".", "ext_len", "=", "ext_len", "if", "ext_len", "is", "not", "None", "else", "0", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream": [[430, 437], ["tokenization_transfo_xl.LMMultiFileIterator.vocab.encode_file", "iter", "numpy.random.shuffle"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file"], ["", "def", "get_sent_stream", "(", "self", ",", "path", ")", ":", "\n", "        ", "sents", "=", "self", ".", "vocab", ".", "encode_file", "(", "path", ",", "add_double_eos", "=", "True", ")", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "sents", ")", "\n", "", "sent_stream", "=", "iter", "(", "sents", ")", "\n", "\n", "return", "sent_stream", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMMultiFileIterator.__iter__": [[438, 447], ["numpy.random.shuffle", "tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream", "tokenization_transfo_xl.LMMultiFileIterator.stream_iterator"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMMultiFileIterator.get_sent_stream", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.LMShuffledIterator.stream_iterator"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "shuffle", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "self", ".", "paths", ")", "\n", "\n", "", "for", "path", "in", "self", ".", "paths", ":", "\n", "# sent_stream is an iterator", "\n", "            ", "sent_stream", "=", "self", ".", "get_sent_stream", "(", "path", ")", "\n", "for", "batch", "in", "self", ".", "stream_iterator", "(", "sent_stream", ")", ":", "\n", "                ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLCorpus.from_pretrained": [[450, 493], ["TransfoXLTokenizer.from_pretrained", "cls", "torch.load", "torch.load.items", "os.path.join", "file_utils.cached_path", "logger.info", "logger.info", "torch.tensor", "torch.tensor", "torch.tensor", "logger.error", "PRETRAINED_CORPUS_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.cached_path"], ["    ", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a pre-processed corpus.\n        \"\"\"", "\n", "vocab", "=", "TransfoXLTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_CORPUS_ARCHIVE_MAP", ":", "\n", "            ", "corpus_file", "=", "PRETRAINED_CORPUS_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "corpus_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CORPUS_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_corpus_file", "=", "cached_path", "(", "corpus_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Corpus '{}' was not found in corpus list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find files {} \"", "\n", "\"at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "\", \"", ".", "join", "(", "PRETRAINED_CORPUS_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "corpus_file", ",", "\n", ")", "\n", ")", "\n", "return", "None", "\n", "", "if", "resolved_corpus_file", "==", "corpus_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading corpus file {}\"", ".", "format", "(", "corpus_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading corpus file {} from cache at {}\"", ".", "format", "(", "corpus_file", ",", "resolved_corpus_file", ")", ")", "\n", "\n", "# Instantiate tokenizer.", "\n", "", "corpus", "=", "cls", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "corpus_dict", "=", "torch", ".", "load", "(", "resolved_corpus_file", ")", "\n", "for", "key", ",", "value", "in", "corpus_dict", ".", "items", "(", ")", ":", "\n", "            ", "corpus", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "corpus", ".", "vocab", "=", "vocab", "\n", "if", "corpus", ".", "train", "is", "not", "None", ":", "\n", "            ", "corpus", ".", "train", "=", "torch", ".", "tensor", "(", "corpus", ".", "train", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "if", "corpus", ".", "valid", "is", "not", "None", ":", "\n", "            ", "corpus", ".", "valid", "=", "torch", ".", "tensor", "(", "corpus", ".", "valid", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "if", "corpus", ".", "test", "is", "not", "None", ":", "\n", "            ", "corpus", ".", "test", "=", "torch", ".", "tensor", "(", "corpus", ".", "test", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLCorpus.__init__": [[494, 500], ["tokenization_transfo_xl.TransfoXLTokenizer"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "TransfoXLTokenizer", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "train", "=", "None", "\n", "self", ".", "valid", "=", "None", "\n", "self", ".", "test", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLCorpus.build_corpus": [[501, 534], ["tokenization_transfo_xl.TransfoXLCorpus.vocab.build_vocab", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "os.path.join", "os.path.join", "os.path.join", "tokenization_transfo_xl.TransfoXLCorpus.vocab.count_file", "os.path.join", "os.path.join", "os.path.join", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "os.path.join", "os.path.join", "glob.glob", "os.path.join", "os.path.join", "os.path.join", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "tokenization_transfo_xl.TransfoXLCorpus.vocab.encode_file", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.build_vocab", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.count_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.encode_file"], ["", "def", "build_corpus", "(", "self", ",", "path", ",", "dataset", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "dataset", "\n", "\n", "if", "self", ".", "dataset", "in", "[", "\"ptb\"", ",", "\"wt2\"", ",", "\"enwik8\"", ",", "\"text8\"", "]", ":", "\n", "            ", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"train.txt\"", ")", ")", "\n", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"valid.txt\"", ")", ")", "\n", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"test.txt\"", ")", ")", "\n", "", "elif", "self", ".", "dataset", "==", "\"wt103\"", ":", "\n", "            ", "self", ".", "vocab", ".", "count_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"train.txt\"", ")", ")", "\n", "", "elif", "self", ".", "dataset", "==", "\"lm1b\"", ":", "\n", "            ", "train_path_pattern", "=", "os", ".", "path", ".", "join", "(", "\n", "path", ",", "\n", "\"1-billion-word-language-modeling-benchmark-r13output\"", ",", "\n", "\"training-monolingual.tokenized.shuffled\"", ",", "\n", "\"news.en-*\"", ",", "\n", ")", "\n", "train_paths", "=", "glob", ".", "glob", "(", "train_path_pattern", ")", "\n", "# the vocab will load from file when build_vocab() is called", "\n", "\n", "", "self", ".", "vocab", ".", "build_vocab", "(", ")", "\n", "\n", "if", "self", ".", "dataset", "in", "[", "\"ptb\"", ",", "\"wt2\"", ",", "\"wt103\"", "]", ":", "\n", "            ", "self", ".", "train", "=", "self", ".", "vocab", ".", "encode_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"train.txt\"", ")", ",", "ordered", "=", "True", ")", "\n", "self", ".", "valid", "=", "self", ".", "vocab", ".", "encode_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"valid.txt\"", ")", ",", "ordered", "=", "True", ")", "\n", "self", ".", "test", "=", "self", ".", "vocab", ".", "encode_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"test.txt\"", ")", ",", "ordered", "=", "True", ")", "\n", "", "elif", "self", ".", "dataset", "in", "[", "\"enwik8\"", ",", "\"text8\"", "]", ":", "\n", "            ", "self", ".", "train", "=", "self", ".", "vocab", ".", "encode_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"train.txt\"", ")", ",", "ordered", "=", "True", ",", "add_eos", "=", "False", ")", "\n", "self", ".", "valid", "=", "self", ".", "vocab", ".", "encode_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"valid.txt\"", ")", ",", "ordered", "=", "True", ",", "add_eos", "=", "False", ")", "\n", "self", ".", "test", "=", "self", ".", "vocab", ".", "encode_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"test.txt\"", ")", ",", "ordered", "=", "True", ",", "add_eos", "=", "False", ")", "\n", "", "elif", "self", ".", "dataset", "==", "\"lm1b\"", ":", "\n", "            ", "self", ".", "train", "=", "train_paths", "\n", "self", ".", "valid", "=", "self", ".", "vocab", ".", "encode_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"valid.txt\"", ")", ",", "ordered", "=", "False", ",", "add_double_eos", "=", "True", ")", "\n", "self", ".", "test", "=", "self", ".", "vocab", ".", "encode_file", "(", "os", ".", "path", ".", "join", "(", "path", ",", "\"test.txt\"", ")", ",", "ordered", "=", "False", ",", "add_double_eos", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLCorpus.get_iterator": [[535, 550], ["tokenization_transfo_xl.LMOrderedIterator", "tokenization_transfo_xl.LMMultiFileIterator", "tokenization_transfo_xl.LMOrderedIterator", "tokenization_transfo_xl.LMShuffledIterator"], "methods", ["None"], ["", "", "def", "get_iterator", "(", "self", ",", "split", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "split", "==", "\"train\"", ":", "\n", "            ", "if", "self", ".", "dataset", "in", "[", "\"ptb\"", ",", "\"wt2\"", ",", "\"wt103\"", ",", "\"enwik8\"", ",", "\"text8\"", "]", ":", "\n", "                ", "data_iter", "=", "LMOrderedIterator", "(", "self", ".", "train", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "self", ".", "dataset", "==", "\"lm1b\"", ":", "\n", "                ", "kwargs", "[", "\"shuffle\"", "]", "=", "True", "\n", "data_iter", "=", "LMMultiFileIterator", "(", "self", ".", "train", ",", "self", ".", "vocab", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", "elif", "split", "in", "[", "\"valid\"", ",", "\"test\"", "]", ":", "\n", "            ", "data", "=", "self", ".", "valid", "if", "split", "==", "\"valid\"", "else", "self", ".", "test", "\n", "if", "self", ".", "dataset", "in", "[", "\"ptb\"", ",", "\"wt2\"", ",", "\"wt103\"", ",", "\"enwik8\"", ",", "\"text8\"", "]", ":", "\n", "                ", "data_iter", "=", "LMOrderedIterator", "(", "data", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "self", ".", "dataset", "==", "\"lm1b\"", ":", "\n", "                ", "data_iter", "=", "LMShuffledIterator", "(", "data", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "", "", "return", "data_iter", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.get_lm_corpus": [[552, 582], ["os.path.join", "os.path.join", "os.path.exists", "logger.info", "torch.load", "os.path.exists", "logger.info", "logger.info", "tokenization_transfo_xl.TransfoXLCorpus", "torch.save", "open", "pickle.load", "os.path.join"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save"], ["", "", "def", "get_lm_corpus", "(", "datadir", ",", "dataset", ")", ":", "\n", "    ", "fn", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "\"cache.pt\"", ")", "\n", "fn_pickle", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "\"cache.pkl\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fn", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading cached dataset...\"", ")", "\n", "corpus", "=", "torch", ".", "load", "(", "fn_pickle", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "fn", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading cached dataset from pickle...\"", ")", "\n", "with", "open", "(", "fn", ",", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "corpus", "=", "pickle", ".", "load", "(", "fp", ")", "\n", "", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Producing dataset {}...\"", ".", "format", "(", "dataset", ")", ")", "\n", "kwargs", "=", "{", "}", "\n", "if", "dataset", "in", "[", "\"wt103\"", ",", "\"wt2\"", "]", ":", "\n", "            ", "kwargs", "[", "\"special\"", "]", "=", "[", "\"<eos>\"", "]", "\n", "kwargs", "[", "\"lower_case\"", "]", "=", "False", "\n", "", "elif", "dataset", "==", "\"ptb\"", ":", "\n", "            ", "kwargs", "[", "\"special\"", "]", "=", "[", "\"<eos>\"", "]", "\n", "kwargs", "[", "\"lower_case\"", "]", "=", "True", "\n", "", "elif", "dataset", "==", "\"lm1b\"", ":", "\n", "            ", "kwargs", "[", "\"special\"", "]", "=", "[", "]", "\n", "kwargs", "[", "\"lower_case\"", "]", "=", "False", "\n", "kwargs", "[", "\"vocab_file\"", "]", "=", "os", ".", "path", ".", "join", "(", "datadir", ",", "\"1b_word_vocab.txt\"", ")", "\n", "", "elif", "dataset", "in", "[", "\"enwik8\"", ",", "\"text8\"", "]", ":", "\n", "            ", "pass", "\n", "\n", "", "corpus", "=", "TransfoXLCorpus", "(", "datadir", ",", "dataset", ",", "**", "kwargs", ")", "\n", "torch", ".", "save", "(", "corpus", ",", "fn", ")", "\n", "\n", "", "return", "corpus", "\n", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_gpt2.GPT2Config.__init__": [[58, 114], ["configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "50257", ",", "\n", "n_positions", "=", "1024", ",", "\n", "n_ctx", "=", "1024", ",", "\n", "n_embd", "=", "768", ",", "\n", "n_layer", "=", "12", ",", "\n", "n_head", "=", "12", ",", "\n", "resid_pdrop", "=", "0.1", ",", "\n", "embd_pdrop", "=", "0.1", ",", "\n", "attn_pdrop", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "summary_type", "=", "\"cls_index\"", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs GPT2Config.\n\n        Args:\n            vocab_size: Vocabulary size of `inputs_ids` in `GPT2Model` or a configuration json file.\n            n_positions: Number of positional embeddings.\n            n_ctx: Size of the causal mask (usually same as n_positions).\n            n_embd: Dimensionality of the embeddings and hidden states.\n            n_layer: Number of hidden layers in the Transformer encoder.\n            n_head: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            layer_norm_epsilon: epsilon to use in the layer norm layers\n            resid_pdrop: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            attn_pdrop: The dropout ratio for the attention\n                probabilities.\n            embd_pdrop: The dropout ratio for the embeddings.\n            initializer_range: The sttdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n        \"\"\"", "\n", "super", "(", "GPT2Config", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "resid_pdrop", "=", "resid_pdrop", "\n", "self", ".", "embd_pdrop", "=", "embd_pdrop", "\n", "self", ".", "attn_pdrop", "=", "attn_pdrop", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_gpt2.GPT2Config.max_position_embeddings": [[115, 118], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_gpt2.GPT2Config.hidden_size": [[119, 122], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_embd", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_gpt2.GPT2Config.num_attention_heads": [[123, 126], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_gpt2.GPT2Config.num_hidden_layers": [[127, 130], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_auto.TFAutoModel.__init__": [[134, 137], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\n", "\"TFAutoModel is designed to be instantiated \"", "\n", "\"using the `TFAutoModel.from_pretrained(pretrained_model_name_or_path)` or \"", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_auto.TFAutoModel.from_config": [[141, 182], ["isinstance", "ValueError", "modeling_tf_distilbert.TFDistilBertModel", "isinstance", "modeling_tf_roberta.TFRobertaModel", "isinstance", "modeling_tf_bert.TFBertModel", "isinstance", "modeling_tf_openai.TFOpenAIGPTModel", "isinstance", "modeling_tf_gpt2.TFGPT2Model", "isinstance", "modeling_tf_transfo_xl.TFTransfoXLModel", "isinstance", "modeling_tf_xlnet.TFXLNetModel", "isinstance", "modeling_tf_xlm.TFXLMModel", "isinstance", "modeling_tf_ctrl.TFCTRLModel"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "config", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the base model classes of the library\n        from a configuration.\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                The model class to instantiate is selected based on the configuration class:\n                    - isInstance of `distilbert` configuration class: TFDistilBertModel (DistilBERT model)\n                    - isInstance of `roberta` configuration class: TFRobertaModel (RoBERTa model)\n                    - isInstance of `bert` configuration class: TFBertModel (Bert model)\n                    - isInstance of `openai-gpt` configuration class: TFOpenAIGPTModel (OpenAI GPT model)\n                    - isInstance of `gpt2` configuration class: TFGPT2Model (OpenAI GPT-2 model)\n                    - isInstance of `ctrl` configuration class: TFCTRLModel (Salesforce CTRL  model)\n                    - isInstance of `transfo-xl` configuration class: TFTransfoXLModel (Transformer-XL model)\n                    - isInstance of `xlnet` configuration class: TFXLNetModel (XLNet model)\n                    - isInstance of `xlm` configuration class: TFXLMModel (XLM model)\n\n        Examples::\n\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            model = TFAutoModel.from_config(config)  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n        \"\"\"", "\n", "if", "isinstance", "(", "config", ",", "DistilBertConfig", ")", ":", "\n", "            ", "return", "TFDistilBertModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "RobertaConfig", ")", ":", "\n", "            ", "return", "TFRobertaModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "return", "TFBertModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "OpenAIGPTConfig", ")", ":", "\n", "            ", "return", "TFOpenAIGPTModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "GPT2Config", ")", ":", "\n", "            ", "return", "TFGPT2Model", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "TransfoXLConfig", ")", ":", "\n", "            ", "return", "TFTransfoXLModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLNetConfig", ")", ":", "\n", "            ", "return", "TFXLNetModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLMConfig", ")", ":", "\n", "            ", "return", "TFXLMModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "CTRLConfig", ")", ":", "\n", "            ", "return", "TFCTRLModel", "(", "config", ")", "\n", "", "raise", "ValueError", "(", "\"Unrecognized configuration class {}\"", ".", "format", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_auto.TFAutoModel.from_pretrained": [[183, 287], ["ValueError", "modeling_tf_t5.TFT5Model.from_pretrained", "modeling_tf_distilbert.TFDistilBertModel.from_pretrained", "modeling_tf_albert.TFAlbertModel.from_pretrained", "modeling_tf_roberta.TFRobertaModel.from_pretrained", "modeling_tf_bert.TFBertModel.from_pretrained", "modeling_tf_openai.TFOpenAIGPTModel.from_pretrained", "modeling_tf_gpt2.TFGPT2Model.from_pretrained", "modeling_tf_transfo_xl.TFTransfoXLModel.from_pretrained", "modeling_tf_xlnet.TFXLNetModel.from_pretrained", "modeling_tf_xlm.TFXLMModel.from_pretrained", "modeling_tf_ctrl.TFCTRLModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the base model classes of the library\n        from a pre-trained model configuration.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `t5`: TFT5Model (T5 model)\n            - contains `distilbert`: TFDistilBertModel (DistilBERT model)\n            - contains `roberta`: TFRobertaModel (RoBERTa model)\n            - contains `bert`: TFTFBertModel (Bert model)\n            - contains `openai-gpt`: TFOpenAIGPTModel (OpenAI GPT model)\n            - contains `gpt2`: TFGPT2Model (OpenAI GPT-2 model)\n            - contains `transfo-xl`: TFTransfoXLModel (Transformer-XL model)\n            - contains `xlnet`: TFXLNetModel (XLNet model)\n            - contains `ctrl`: TFCTRLModel (CTRL model)\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `PyTorch, TF 1.X or TF 2.0 checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In the case of a PyTorch checkpoint, ``from_pt`` should be set to True and a configuration object should be provided as ``config`` argument.\n\n            from_pt: (`Optional`) Boolean\n                Set to True if the Checkpoint is a PyTorch checkpoint.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = TFAutoModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = TFAutoModel.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = TFAutoModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = TFAutoModel.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config)\n\n        \"\"\"", "\n", "if", "\"t5\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFT5Model", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"distilbert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFDistilBertModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"albert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFAlbertModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFRobertaModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"bert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFBertModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"openai-gpt\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFOpenAIGPTModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"gpt2\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFGPT2Model", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"transfo-xl\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFTransfoXLModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlnet\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLNetModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlm\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLMModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"ctrl\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFCTRLModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "\n", "", "raise", "ValueError", "(", "\n", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'distilbert', 'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm', 'roberta', 'ctrl'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_auto.TFAutoModelWithLMHead.__init__": [[316, 319], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\n", "\"TFAutoModelWithLMHead is designed to be instantiated \"", "\n", "\"using the `TFAutoModelWithLMHead.from_pretrained(pretrained_model_name_or_path)` or \"", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_auto.TFAutoModelWithLMHead.from_config": [[323, 364], ["isinstance", "ValueError", "modeling_tf_distilbert.TFDistilBertForMaskedLM", "isinstance", "modeling_tf_roberta.TFRobertaForMaskedLM", "isinstance", "modeling_tf_bert.TFBertForMaskedLM", "isinstance", "modeling_tf_openai.TFOpenAIGPTLMHeadModel", "isinstance", "modeling_tf_gpt2.TFGPT2LMHeadModel", "isinstance", "modeling_tf_transfo_xl.TFTransfoXLLMHeadModel", "isinstance", "modeling_tf_xlnet.TFXLNetLMHeadModel", "isinstance", "modeling_tf_xlm.TFXLMWithLMHeadModel", "isinstance", "modeling_tf_ctrl.TFCTRLLMHeadModel"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "config", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the base model classes of the library\n        from a configuration.\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                The model class to instantiate is selected based on the configuration class:\n                    - isInstance of `distilbert` configuration class: DistilBertModel (DistilBERT model)\n                    - isInstance of `roberta` configuration class: RobertaModel (RoBERTa model)\n                    - isInstance of `bert` configuration class: BertModel (Bert model)\n                    - isInstance of `openai-gpt` configuration class: OpenAIGPTModel (OpenAI GPT model)\n                    - isInstance of `gpt2` configuration class: GPT2Model (OpenAI GPT-2 model)\n                    - isInstance of `ctrl` configuration class: CTRLModel (Salesforce CTRL  model)\n                    - isInstance of `transfo-xl` configuration class: TransfoXLModel (Transformer-XL model)\n                    - isInstance of `xlnet` configuration class: XLNetModel (XLNet model)\n                    - isInstance of `xlm` configuration class: XLMModel (XLM model)\n\n        Examples::\n\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            model = AutoModelWithLMHead.from_config(config)  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n        \"\"\"", "\n", "if", "isinstance", "(", "config", ",", "DistilBertConfig", ")", ":", "\n", "            ", "return", "TFDistilBertForMaskedLM", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "RobertaConfig", ")", ":", "\n", "            ", "return", "TFRobertaForMaskedLM", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "return", "TFBertForMaskedLM", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "OpenAIGPTConfig", ")", ":", "\n", "            ", "return", "TFOpenAIGPTLMHeadModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "GPT2Config", ")", ":", "\n", "            ", "return", "TFGPT2LMHeadModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "TransfoXLConfig", ")", ":", "\n", "            ", "return", "TFTransfoXLLMHeadModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLNetConfig", ")", ":", "\n", "            ", "return", "TFXLNetLMHeadModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLMConfig", ")", ":", "\n", "            ", "return", "TFXLMWithLMHeadModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "CTRLConfig", ")", ":", "\n", "            ", "return", "TFCTRLLMHeadModel", "(", "config", ")", "\n", "", "raise", "ValueError", "(", "\"Unrecognized configuration class {}\"", ".", "format", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_auto.TFAutoModelWithLMHead.from_pretrained": [[365, 473], ["ValueError", "modeling_tf_t5.TFT5WithLMHeadModel.from_pretrained", "modeling_tf_distilbert.TFDistilBertForMaskedLM.from_pretrained", "modeling_tf_albert.TFAlbertForMaskedLM.from_pretrained", "modeling_tf_roberta.TFRobertaForMaskedLM.from_pretrained", "modeling_tf_bert.TFBertForMaskedLM.from_pretrained", "modeling_tf_openai.TFOpenAIGPTLMHeadModel.from_pretrained", "modeling_tf_gpt2.TFGPT2LMHeadModel.from_pretrained", "modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.from_pretrained", "modeling_tf_xlnet.TFXLNetLMHeadModel.from_pretrained", "modeling_tf_xlm.TFXLMWithLMHeadModel.from_pretrained", "modeling_tf_ctrl.TFCTRLLMHeadModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the language modeling model classes of the library\n        from a pre-trained model configuration.\n\n        The `from_pretrained()` method takes care of returning the correct model class instance\n        using pattern matching on the `pretrained_model_name_or_path` string.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `t5`: TFT5WithLMHeadModel (T5 model)\n            - contains `distilbert`: TFDistilBertForMaskedLM (DistilBERT model)\n            - contains `roberta`: TFRobertaForMaskedLM (RoBERTa model)\n            - contains `bert`: TFBertForMaskedLM (Bert model)\n            - contains `openai-gpt`: TFOpenAIGPTLMHeadModel (OpenAI GPT model)\n            - contains `gpt2`: TFGPT2LMHeadModel (OpenAI GPT-2 model)\n            - contains `transfo-xl`: TFTransfoXLLMHeadModel (Transformer-XL model)\n            - contains `xlnet`: TFXLNetLMHeadModel (XLNet model)\n            - contains `xlm`: TFXLMWithLMHeadModel (XLM model)\n            - contains `ctrl`: TFCTRLLMHeadModel (CTRL model)\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `PyTorch, TF 1.X or TF 2.0 checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In the case of a PyTorch checkpoint, ``from_pt`` should be set to True and a configuration object should be provided as ``config`` argument.\n\n            from_pt: (`Optional`) Boolean\n                Set to True if the Checkpoint is a PyTorch checkpoint.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = TFAutoModelWithLMHead.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = TFAutoModelWithLMHead.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = TFAutoModelWithLMHead.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = TFAutoModelWithLMHead.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config)\n\n        \"\"\"", "\n", "if", "\"t5\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFT5WithLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"distilbert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFDistilBertForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"albert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFAlbertForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFRobertaForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"bert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFBertForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"openai-gpt\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFOpenAIGPTLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"gpt2\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFGPT2LMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"transfo-xl\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFTransfoXLLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlnet\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLNetLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlm\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLMWithLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"ctrl\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFCTRLLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "\n", "", "raise", "ValueError", "(", "\n", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'distilbert', 'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm', 'roberta', 'ctrl'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_auto.TFAutoModelForSequenceClassification.__init__": [[497, 500], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\n", "\"TFAutoModelForSequenceClassification is designed to be instantiated \"", "\n", "\"using the `TFAutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path)` or \"", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_auto.TFAutoModelForSequenceClassification.from_config": [[504, 533], ["isinstance", "ValueError", "modeling_tf_distilbert.TFDistilBertForSequenceClassification", "isinstance", "modeling_tf_roberta.TFRobertaForSequenceClassification", "isinstance", "modeling_tf_bert.TFBertForSequenceClassification", "isinstance", "modeling_tf_xlnet.TFXLNetForSequenceClassification", "isinstance", "modeling_tf_xlm.TFXLMForSequenceClassification"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "config", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the base model classes of the library\n        from a configuration.\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                The model class to instantiate is selected based on the configuration class:\n                    - isInstance of `distilbert` configuration class: DistilBertModel (DistilBERT model)\n                    - isInstance of `roberta` configuration class: RobertaModel (RoBERTa model)\n                    - isInstance of `bert` configuration class: BertModel (Bert model)\n                    - isInstance of `xlnet` configuration class: XLNetModel (XLNet model)\n                    - isInstance of `xlm` configuration class: XLMModel (XLM model)\n\n        Examples::\n\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            model = AutoModelForSequenceClassification.from_config(config)  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n        \"\"\"", "\n", "if", "isinstance", "(", "config", ",", "DistilBertConfig", ")", ":", "\n", "            ", "return", "TFDistilBertForSequenceClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "RobertaConfig", ")", ":", "\n", "            ", "return", "TFRobertaForSequenceClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "return", "TFBertForSequenceClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLNetConfig", ")", ":", "\n", "            ", "return", "TFXLNetForSequenceClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLMConfig", ")", ":", "\n", "            ", "return", "TFXLMForSequenceClassification", "(", "config", ")", "\n", "", "raise", "ValueError", "(", "\"Unrecognized configuration class {}\"", ".", "format", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_auto.TFAutoModelForSequenceClassification.from_pretrained": [[534, 639], ["ValueError", "modeling_tf_distilbert.TFDistilBertForSequenceClassification.from_pretrained", "modeling_tf_albert.TFAlbertForSequenceClassification.from_pretrained", "modeling_tf_roberta.TFRobertaForSequenceClassification.from_pretrained", "modeling_tf_bert.TFBertForSequenceClassification.from_pretrained", "modeling_tf_xlnet.TFXLNetForSequenceClassification.from_pretrained", "modeling_tf_xlm.TFXLMForSequenceClassification.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the sequence classification model classes of the library\n        from a pre-trained model configuration.\n\n        The `from_pretrained()` method takes care of returning the correct model class instance\n        using pattern matching on the `pretrained_model_name_or_path` string.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `distilbert`: TFDistilBertForSequenceClassification (DistilBERT model)\n            - contains `roberta`: TFRobertaForSequenceClassification (RoBERTa model)\n            - contains `bert`: TFBertForSequenceClassification (Bert model)\n            - contains `xlnet`: TFXLNetForSequenceClassification (XLNet model)\n            - contains `xlm`: TFXLMForSequenceClassification (XLM model)\n\n        The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `PyTorch, TF 1.X or TF 2.0 checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In the case of a PyTorch checkpoint, ``from_pt`` should be set to True and a configuration object should be provided as ``config`` argument.\n\n            from_pt: (`Optional`) Boolean\n                Set to True if the Checkpoint is a PyTorch checkpoint.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = TFAutoModelForSequenceClassification.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = TFAutoModelForSequenceClassification.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = TFAutoModelForSequenceClassification.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = TFAutoModelForSequenceClassification.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config)\n\n        \"\"\"", "\n", "if", "\"distilbert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFDistilBertForSequenceClassification", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"albert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFAlbertForSequenceClassification", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFRobertaForSequenceClassification", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"bert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFBertForSequenceClassification", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"xlnet\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLNetForSequenceClassification", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"xlm\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLMForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "\n", "", "raise", "ValueError", "(", "\n", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'distilbert', 'bert', 'xlnet', 'xlm', 'roberta'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_auto.TFAutoModelForQuestionAnswering.__init__": [[662, 665], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\n", "\"TFAutoModelForQuestionAnswering is designed to be instantiated \"", "\n", "\"using the `TFAutoModelForQuestionAnswering.from_pretrained(pretrained_model_name_or_path)` or \"", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_auto.TFAutoModelForQuestionAnswering.from_config": [[669, 695], ["isinstance", "ValueError", "modeling_tf_distilbert.TFDistilBertForQuestionAnswering", "isinstance", "modeling_tf_bert.TFBertForQuestionAnswering", "isinstance", "NotImplementedError", "isinstance", "NotImplementedError"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "config", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the base model classes of the library\n        from a configuration.\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                The model class to instantiate is selected based on the configuration class:\n                    - isInstance of `distilbert` configuration class: DistilBertModel (DistilBERT model)\n                    - isInstance of `bert` configuration class: BertModel (Bert model)\n                    - isInstance of `xlnet` configuration class: XLNetModel (XLNet model)\n                    - isInstance of `xlm` configuration class: XLMModel (XLM model)\n\n        Examples::\n\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            model = AutoModelForSequenceClassification.from_config(config)  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n        \"\"\"", "\n", "if", "isinstance", "(", "config", ",", "DistilBertConfig", ")", ":", "\n", "            ", "return", "TFDistilBertForQuestionAnswering", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "return", "TFBertForQuestionAnswering", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLNetConfig", ")", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"TFXLNetForQuestionAnswering isn't implemented\"", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLMConfig", ")", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"TFXLMForQuestionAnswering isn't implemented\"", ")", "\n", "", "raise", "ValueError", "(", "\"Unrecognized configuration class {}\"", ".", "format", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_auto.TFAutoModelForQuestionAnswering.from_pretrained": [[696, 792], ["ValueError", "modeling_tf_distilbert.TFDistilBertForQuestionAnswering.from_pretrained", "modeling_tf_bert.TFBertForQuestionAnswering.from_pretrained", "modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimple.from_pretrained", "modeling_tf_xlm.TFXLMForQuestionAnsweringSimple.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the question answering model classes of the library\n        from a pre-trained model configuration.\n\n        The `from_pretrained()` method takes care of returning the correct model class instance\n        using pattern matching on the `pretrained_model_name_or_path` string.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `distilbert`: TFDistilBertForQuestionAnswering (DistilBERT model)\n            - contains `bert`: TFBertForQuestionAnswering (Bert model)\n            - contains `xlnet`: TFXLNetForQuestionAnswering (XLNet model)\n            - contains `xlm`: TFXLMForQuestionAnswering (XLM model)\n\n        The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `PyTorch, TF 1.X or TF 2.0 checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In the case of a PyTorch checkpoint, ``from_pt`` should be set to True and a configuration object should be provided as ``config`` argument.\n\n            from_pt: (`Optional`) Boolean\n                Set to True if the Checkpoint is a PyTorch checkpoint.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = TFAutoModelForQuestionAnswering.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = TFAutoModelForQuestionAnswering.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = TFAutoModelForQuestionAnswering.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = TFAutoModelForQuestionAnswering.from_pretrained('./pt_model/bert_pytorch_model.bin', from_pt=True, config=config)\n\n        \"\"\"", "\n", "if", "\"distilbert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFDistilBertForQuestionAnswering", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"bert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFBertForQuestionAnswering", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlnet\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLNetForQuestionAnsweringSimple", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"xlm\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLMForQuestionAnsweringSimple", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "\n", "", "raise", "ValueError", "(", "\n", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'distilbert', 'bert', 'xlnet', 'xlm'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_auto.TFAutoModelForTokenClassification.__init__": [[796, 799], ["EnvironmentError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\n", "\"TFAutoModelForTokenClassification is designed to be instantiated \"", "\n", "\"using the `TFAutoModelForTokenClassification.from_pretrained(pretrained_model_name_or_path)` or \"", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_auto.TFAutoModelForTokenClassification.from_config": [[803, 829], ["isinstance", "ValueError", "modeling_tf_bert.TFBertForTokenClassification", "isinstance", "modeling_tf_xlnet.TFXLNetForTokenClassification", "isinstance", "modeling_tf_distilbert.TFDistilBertForTokenClassification", "isinstance", "modeling_tf_roberta.TFRobertaForTokenClassification"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "config", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the base model classes of the library\n        from a configuration.\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                The model class to instantiate is selected based on the configuration class:\n                    - isInstance of `bert` configuration class: BertModel (Bert model)\n                    - isInstance of `xlnet` configuration class: XLNetModel (XLNet model)\n                    - isInstance of `distilbert` configuration class: DistilBertModel (DistilBert model)\n                    - isInstance of `roberta` configuration class: RobteraModel (Roberta model)\n\n        Examples::\n\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            model = TFAutoModelForTokenClassification.from_config(config)  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n        \"\"\"", "\n", "if", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "return", "TFBertForTokenClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLNetConfig", ")", ":", "\n", "            ", "return", "TFXLNetForTokenClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "DistilBertConfig", ")", ":", "\n", "            ", "return", "TFDistilBertForTokenClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "RobertaConfig", ")", ":", "\n", "            ", "return", "TFRobertaForTokenClassification", "(", "config", ")", "\n", "", "raise", "ValueError", "(", "\"Unrecognized configuration class {}\"", ".", "format", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_auto.TFAutoModelForTokenClassification.from_pretrained": [[830, 917], ["ValueError", "modeling_tf_bert.TFBertForTokenClassification.from_pretrained", "modeling_tf_xlnet.TFXLNetForTokenClassification.from_pretrained", "modeling_tf_distilbert.TFDistilBertForTokenClassification.from_pretrained", "modeling_tf_roberta.TFRobertaForTokenClassification.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the question answering model classes of the library\n        from a pre-trained model configuration.\n\n        The `from_pretrained()` method takes care of returning the correct model class instance\n        using pattern matching on the `pretrained_model_name_or_path` string.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `bert`: BertForTokenClassification (Bert model)\n            - contains `xlnet`: XLNetForTokenClassification (XLNet model)\n            - contains `distilbert`: DistilBertForTokenClassification (DistilBert model)\n            - contains `roberta`: RobertaForTokenClassification (Roberta model)\n\n        The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = TFAutoModelForTokenClassification.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = TFAutoModelForTokenClassification.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = TFAutoModelForTokenClassification.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = TFAutoModelForTokenClassification.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "if", "\"bert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFBertForTokenClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlnet\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFXLNetForTokenClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"distilbert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFDistilBertForTokenClassification", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TFRobertaForTokenClassification", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "\n", "", "raise", "ValueError", "(", "\n", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'xlnet', 'distilbert', 'roberta'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFPreTrainedModel.dummy_inputs": [[55, 63], ["tensorflow.constant"], "methods", ["None"], ["@", "property", "\n", "def", "dummy_inputs", "(", "self", ")", ":", "\n", "        ", "\"\"\" Dummy inputs to build the network.\n\n        Returns:\n            tf.Tensor with dummy inputs\n        \"\"\"", "\n", "return", "{", "\"input_ids\"", ":", "tf", ".", "constant", "(", "DUMMY_INPUTS", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFPreTrainedModel.__init__": [[64, 76], ["super().__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["", "def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFPreTrainedModel", ",", "self", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "PretrainedConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `PretrainedConfig`. \"", "\n", "\"To create a model from a pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", ")", "\n", "# Save config in model", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFPreTrainedModel.get_input_embeddings": [[77, 85], ["getattr", "getattr.get_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.get_input_embeddings"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "\"\"\" Get model's input embeddings\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "\n", "if", "base_model", "is", "not", "self", ":", "\n", "            ", "return", "base_model", ".", "get_input_embeddings", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFPreTrainedModel.get_output_embeddings": [[86, 91], ["None"], "methods", ["None"], ["", "", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "\"\"\" Get model's output embeddings\n            Return None if the model doesn't have output embeddings\n        \"\"\"", "\n", "return", "None", "# Overwrite for models with output embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFPreTrainedModel._get_resized_embeddings": [[92, 106], ["None"], "methods", ["None"], ["", "def", "_get_resized_embeddings", "(", "self", ",", "old_embeddings", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Build a resized Embedding Variable from a provided token Embedding Module.\n            Increasing the size will add newly initialized vectors at the end\n            Reducing the size will remove vectors from the end\n\n        Args:\n            new_num_tokens: (`optional`) int\n                New number of tokens in the embedding matrix.\n                Increasing the size will add newly initialized vectors at the end\n                Reducing the size will remove vectors from the end\n                If not provided or None: return the provided token Embedding Module.\n        Return: ``tf.Variable``\n            Pointer to the resized Embedding Module or the old Embedding Module if new_num_tokens is None\n        \"\"\"", "\n", "# if new_num_tokens is None:", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFPreTrainedModel.resize_token_embeddings": [[126, 140], ["None"], "methods", ["None"], ["", "def", "resize_token_embeddings", "(", "self", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Resize input token embeddings matrix of the model if new_num_tokens != config.vocab_size.\n        Take care of tying weights embeddings afterwards if the model class has a `tie_weights()` method.\n\n        Arguments:\n\n            new_num_tokens: (`optional`) int:\n                New number of tokens in the embedding matrix. Increasing the size will add newly initialized vectors at the end. Reducing the size will remove vectors from the end.\n                If not provided or None: does nothing and just returns a pointer to the input tokens ``tf.Variable`` Module of the model.\n\n        Return: ``tf.Variable``\n            Pointer to the input tokens Embeddings Module of the model\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFPreTrainedModel.prune_heads": [[141, 149], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the base model.\n\n            Arguments:\n\n                heads_to_prune: dict with keys being selected layer indices (`int`) and associated values being the list of heads to prune in said layer (list of `int`).\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFPreTrainedModel.save_pretrained": [[150, 165], ["os.path.isdir", "modeling_tf_utils.TFPreTrainedModel.config.save_pretrained", "os.path.join", "modeling_tf_utils.TFPreTrainedModel.save_weights", "logger.info"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a model and its configuration file to a directory, so that it\n            can be re-loaded using the `:func:`~transformers.PreTrainedModel.from_pretrained`` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "\n", "save_directory", "\n", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# Save configuration file", "\n", "self", ".", "config", ".", "save_pretrained", "(", "save_directory", ")", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "TF2_WEIGHTS_NAME", ")", "\n", "self", ".", "save_weights", "(", "output_model_file", ")", "\n", "logger", ".", "info", "(", "\"Model weights saved in {}\"", ".", "format", "(", "output_model_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFPreTrainedModel.from_pretrained": [[166, 365], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "cls", "cls.", "os.path.isfile", "cls.", "set", "list", "list", "isinstance", "cls.config_class.from_pretrained", "modeling_tf_pytorch_utils.load_pytorch_checkpoint_in_tf2_model", "cls.load_weights", "h5py.File", "set", "len", "logger.info", "len", "logger.info", "len", "RuntimeError", "os.path.isdir", "file_utils.cached_path", "logger.info", "logger.info", "OSError", "tensorflow.python.keras.saving.hdf5_format.load_attributes_from_hdf5_group", "os.path.isfile", "os.path.join", "os.path.join", "os.path.isfile", "file_utils.is_remote_url", "os.path.isfile", "logger.error", "logger.error", "os.path.isfile", "os.path.join", "EnvironmentError", "file_utils.hf_bucket_url", "os.path.join", "EnvironmentError", "cls.pretrained_model_archive_map.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_pytorch_checkpoint_in_tf2_model", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_remote_url", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.hf_bucket_url"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Instantiate a pretrained TF 2.0 model from a pre-trained model configuration.\n\n        The model is set in evaluation mode by default using ``model.eval()`` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with ``model.train()``\n\n        The warning ``Weights from XXX not initialized from pretrained model`` means that the weights of XXX do not come pre-trained with the rest of the model.\n        It is up to you to train those weights with a downstream fine-tuning task.\n\n        The warning ``Weights from XXX not used in YYY`` means that the layer XXX is not used by YYY, therefore those weights are discarded.\n\n        Parameters:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `PyTorch state_dict save file` (e.g. `./pt_model/pytorch_model.bin`). In this case, ``from_pt`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the PyTorch checkpoint in a TensorFlow model using the provided conversion scripts and loading the TensorFlow model afterwards.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) one of:\n                    - an instance of a class derived from :class:`~transformers.PretrainedConfig`, or\n                    - a string valid as input to :func:`~transformers.PretrainedConfig.from_pretrained()`\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            from_pt: (`optional`) boolean, default False:\n                Load the model weights from a PyTorch state_dict save file (see docstring of pretrained_model_name_or_path argument).\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = BertModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = BertModel.from_pretrained('./test/saved_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = BertModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = BertConfig.from_json_file('./tf_model/my_tf_model_config.json')\n            model = BertModel.from_pretrained('./tf_model/my_tf_checkpoint.ckpt.index', from_pt=True, config=config)\n\n        \"\"\"", "\n", "config", "=", "kwargs", ".", "pop", "(", "\"config\"", ",", "None", ")", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "\"cache_dir\"", ",", "None", ")", "\n", "from_pt", "=", "kwargs", ".", "pop", "(", "\"from_pt\"", ",", "False", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "\"force_download\"", ",", "False", ")", "\n", "resume_download", "=", "kwargs", ".", "pop", "(", "\"resume_download\"", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "\"proxies\"", ",", "None", ")", "\n", "output_loading_info", "=", "kwargs", ".", "pop", "(", "\"output_loading_info\"", ",", "False", ")", "\n", "\n", "# Load config if we don't provide a configuration", "\n", "if", "not", "isinstance", "(", "config", ",", "PretrainedConfig", ")", ":", "\n", "            ", "config_path", "=", "config", "if", "config", "is", "not", "None", "else", "pretrained_model_name_or_path", "\n", "config", ",", "model_kwargs", "=", "cls", ".", "config_class", ".", "from_pretrained", "(", "\n", "config_path", ",", "\n", "*", "model_args", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "return_unused_kwargs", "=", "True", ",", "\n", "force_download", "=", "force_download", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", "**", "kwargs", "\n", ")", "\n", "", "else", ":", "\n", "            ", "model_kwargs", "=", "kwargs", "\n", "\n", "# Load model", "\n", "", "if", "pretrained_model_name_or_path", "is", "not", "None", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                ", "archive_file", "=", "cls", ".", "pretrained_model_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "                ", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a TF 2.0 checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", "\n", "", "elif", "from_pt", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a PyTorch checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "EnvironmentError", "(", "\n", "\"Error no file named {} found in directory {} or `from_pt` set to False\"", ".", "format", "(", "\n", "[", "WEIGHTS_NAME", ",", "TF2_WEIGHTS_NAME", "]", ",", "pretrained_model_name_or_path", "\n", ")", "\n", ")", "\n", "", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", ")", "or", "is_remote_url", "(", "pretrained_model_name_or_path", ")", ":", "\n", "                ", "archive_file", "=", "pretrained_model_name_or_path", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", "+", "\".index\"", ")", ":", "\n", "                ", "archive_file", "=", "pretrained_model_name_or_path", "+", "\".index\"", "\n", "", "else", ":", "\n", "                ", "archive_file", "=", "hf_bucket_url", "(", "pretrained_model_name_or_path", ",", "postfix", "=", "TF2_WEIGHTS_NAME", ")", "\n", "if", "from_pt", ":", "\n", "                    ", "raise", "EnvironmentError", "(", "\n", "\"Loading a TF model from a PyTorch checkpoint is not supported when using a model identifier name.\"", "\n", ")", "\n", "\n", "# redirect to the cache, if necessary", "\n", "", "", "try", ":", "\n", "                ", "resolved_archive_file", "=", "cached_path", "(", "\n", "archive_file", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "force_download", "=", "force_download", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", ")", "\n", "", "except", "EnvironmentError", "as", "e", ":", "\n", "                ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                    ", "logger", ".", "error", "(", "\"Couldn't reach server at '{}' to download pretrained weights.\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "                    ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "\", \"", ".", "join", "(", "cls", ".", "pretrained_model_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ",", "\n", ")", "\n", ")", "\n", "", "raise", "e", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "resolved_archive_file", "=", "None", "\n", "\n", "# Instantiate model.", "\n", "", "model", "=", "cls", "(", "config", ",", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "from_pt", ":", "\n", "# Load from a PyTorch checkpoint", "\n", "            ", "return", "load_pytorch_checkpoint_in_tf2_model", "(", "model", ",", "resolved_archive_file", ",", "allow_missing_keys", "=", "True", ")", "\n", "\n", "", "ret", "=", "model", "(", "model", ".", "dummy_inputs", ",", "training", "=", "False", ")", "# build the network with dummy inputs", "\n", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "resolved_archive_file", ")", ",", "\"Error retrieving file {}\"", ".", "format", "(", "resolved_archive_file", ")", "\n", "# 'by_name' allow us to do transfer learning by skipping/adding layers", "\n", "# see https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/keras/engine/network.py#L1339-L1357", "\n", "try", ":", "\n", "            ", "model", ".", "load_weights", "(", "resolved_archive_file", ",", "by_name", "=", "True", ")", "\n", "", "except", "OSError", ":", "\n", "            ", "raise", "OSError", "(", "\n", "\"Unable to load weights from h5 file. \"", "\n", "\"If you tried to load a TF 2.0 model from a PyTorch checkpoint, please set from_pt=True. \"", "\n", ")", "\n", "\n", "", "ret", "=", "model", "(", "model", ".", "dummy_inputs", ",", "training", "=", "False", ")", "# Make sure restore ops are run", "\n", "\n", "# Check if the models are the same to output loading informations", "\n", "with", "h5py", ".", "File", "(", "resolved_archive_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "if", "\"layer_names\"", "not", "in", "f", ".", "attrs", "and", "\"model_weights\"", "in", "f", ":", "\n", "                ", "f", "=", "f", "[", "\"model_weights\"", "]", "\n", "", "hdf5_layer_names", "=", "set", "(", "hdf5_format", ".", "load_attributes_from_hdf5_group", "(", "f", ",", "\"layer_names\"", ")", ")", "\n", "", "model_layer_names", "=", "set", "(", "layer", ".", "name", "for", "layer", "in", "model", ".", "layers", ")", "\n", "missing_keys", "=", "list", "(", "model_layer_names", "-", "hdf5_layer_names", ")", "\n", "unexpected_keys", "=", "list", "(", "hdf5_layer_names", "-", "model_layer_names", ")", "\n", "error_msgs", "=", "[", "]", "\n", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Layers of {} not initialized from pretrained model: {}\"", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", "\n", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Layers from pretrained model not used in {}: {}\"", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", "\n", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Error(s) in loading weights for {}:\\n\\t{}\"", ".", "format", "(", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", "\n", ")", "\n", "", "if", "output_loading_info", ":", "\n", "            ", "loading_info", "=", "{", "\"missing_keys\"", ":", "missing_keys", ",", "\"unexpected_keys\"", ":", "unexpected_keys", ",", "\"error_msgs\"", ":", "error_msgs", "}", "\n", "return", "model", ",", "loading_info", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFConv1D.__init__": [[368, 376], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "nx", ",", "initializer_range", "=", "0.02", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" TFConv1D layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2)\n            Basically works like a Linear layer but the weights are transposed\n        \"\"\"", "\n", "super", "(", "TFConv1D", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "nf", "=", "nf", "\n", "self", ".", "nx", "=", "nx", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFConv1D.build": [[377, 382], ["modeling_tf_utils.TFConv1D.add_weight", "modeling_tf_utils.TFConv1D.add_weight", "modeling_tf_utils.get_initializer", "tensorflow.zeros_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "weight", "=", "self", ".", "add_weight", "(", "\n", "\"weight\"", ",", "shape", "=", "[", "self", ".", "nx", ",", "self", ".", "nf", "]", ",", "initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", "\n", ")", "\n", "self", ".", "bias", "=", "self", ".", "add_weight", "(", "\"bias\"", ",", "shape", "=", "[", "1", ",", "self", ".", "nf", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFConv1D.call": [[383, 392], ["tensorflow.reshape", "tensorflow.reshape", "modeling_tf_utils.shape_list", "tensorflow.matmul"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "x", ")", ":", "\n", "        ", "bz", ",", "sl", "=", "shape_list", "(", "x", ")", "[", ":", "2", "]", "\n", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", ",", "self", ".", "nx", "]", ")", "\n", "x", "=", "tf", ".", "matmul", "(", "x", ",", "self", ".", "weight", ")", "+", "self", ".", "bias", "\n", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "bz", ",", "sl", ",", "self", ".", "nf", "]", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFSharedEmbeddings.__init__": [[398, 403], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "vocab_size", ",", "hidden_size", ",", "initializer_range", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFSharedEmbeddings", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "initializer_range", "=", "hidden_size", "**", "-", "0.5", "if", "initializer_range", "is", "None", "else", "initializer_range", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFSharedEmbeddings.build": [[404, 413], ["modeling_tf_utils.TFSharedEmbeddings.add_weight", "super().build", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "\"\"\"Build shared word embedding layer\n        Shared weights logic adapted from\n            https://github.com/tensorflow/models/blob/a009f4fb9d2fc4949e32192a944688925ef78659/official/transformer/v2/embedding_layer.py#L24\n        \"\"\"", "\n", "self", ".", "weight", "=", "self", ".", "add_weight", "(", "\n", "\"weight\"", ",", "shape", "=", "[", "self", ".", "vocab_size", ",", "self", ".", "hidden_size", "]", ",", "initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", "\n", ")", "\n", "super", "(", "TFSharedEmbeddings", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFSharedEmbeddings.call": [[414, 435], ["modeling_tf_utils.TFSharedEmbeddings._embedding", "modeling_tf_utils.TFSharedEmbeddings._linear", "ValueError"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertEmbeddings._embedding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertEmbeddings._linear"], ["", "def", "call", "(", "self", ",", "inputs", ",", "mode", "=", "\"embedding\"", ")", ":", "\n", "        ", "\"\"\"Get token embeddings of inputs.\n        Args:\n            inputs: list of three int64 tensors with shape [batch_size, length]: (input_ids, position_ids, token_type_ids)\n            mode: string, a valid value is one of \"embedding\" and \"linear\".\n        Returns:\n            outputs: (1) If mode == \"embedding\", output embedding tensor, float32 with\n                shape [batch_size, length, embedding_size]; (2) mode == \"linear\", output\n                linear tensor, float32 with shape [batch_size, length, vocab_size].\n        Raises:\n            ValueError: if mode is not valid.\n\n        Shared weights logic adapted from\n            https://github.com/tensorflow/models/blob/a009f4fb9d2fc4949e32192a944688925ef78659/official/transformer/v2/embedding_layer.py#L24\n        \"\"\"", "\n", "if", "mode", "==", "\"embedding\"", ":", "\n", "            ", "return", "self", ".", "_embedding", "(", "inputs", ")", "\n", "", "elif", "mode", "==", "\"linear\"", ":", "\n", "            ", "return", "self", ".", "_linear", "(", "inputs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"mode {} is not valid.\"", ".", "format", "(", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFSharedEmbeddings._embedding": [[436, 439], ["tensorflow.gather"], "methods", ["None"], ["", "", "def", "_embedding", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "\"\"\"Applies embedding based on inputs tensor.\"\"\"", "\n", "return", "tf", ".", "gather", "(", "self", ".", "weight", ",", "input_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFSharedEmbeddings._linear": [[440, 453], ["tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "_linear", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Computes logits by running inputs through a linear layer.\n            Args:\n                inputs: A float32 tensor with shape [..., hidden_size]\n            Returns:\n                float32 tensor with shape [..., vocab_size].\n        \"\"\"", "\n", "first_dims", "=", "shape_list", "(", "inputs", ")", "[", ":", "-", "1", "]", "\n", "\n", "x", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "-", "1", ",", "self", ".", "hidden_size", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "x", ",", "self", ".", "weight", ",", "transpose_b", "=", "True", ")", "\n", "\n", "return", "tf", ".", "reshape", "(", "logits", ",", "first_dims", "+", "[", "self", ".", "vocab_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFSequenceSummary.__init__": [[471, 502], ["super().__init__", "hasattr", "hasattr", "tensorflow.keras.layers.Dense", "hasattr", "hasattr", "tensorflow.keras.layers.Dropout", "hasattr", "tensorflow.keras.layers.Dropout", "hasattr", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "initializer_range", "=", "0.02", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFSequenceSummary", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "summary_type", "=", "config", ".", "summary_type", "if", "hasattr", "(", "config", ",", "\"summary_use_proj\"", ")", "else", "\"last\"", "\n", "if", "self", ".", "summary_type", "==", "\"attn\"", ":", "\n", "# We should use a standard multi-head attention module with absolute positional embedding for that.", "\n", "# Cf. https://github.com/zihangdai/xlnet/blob/master/modeling.py#L253-L276", "\n", "# We can probably just use the multi-head attention module of PyTorch >=1.1.0", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "has_summary", "=", "hasattr", "(", "config", ",", "\"summary_use_proj\"", ")", "and", "config", ".", "summary_use_proj", "\n", "if", "self", ".", "has_summary", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "\"summary_proj_to_labels\"", ")", "and", "config", ".", "summary_proj_to_labels", "and", "config", ".", "num_labels", ">", "0", ":", "\n", "                ", "num_classes", "=", "config", ".", "num_labels", "\n", "", "else", ":", "\n", "                ", "num_classes", "=", "config", ".", "hidden_size", "\n", "", "self", ".", "summary", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "num_classes", ",", "kernel_initializer", "=", "get_initializer", "(", "initializer_range", ")", ",", "name", "=", "\"summary\"", "\n", ")", "\n", "\n", "", "self", ".", "has_activation", "=", "hasattr", "(", "config", ",", "\"summary_activation\"", ")", "and", "config", ".", "summary_activation", "==", "\"tanh\"", "\n", "if", "self", ".", "has_activation", ":", "\n", "            ", "self", ".", "activation", "=", "tf", ".", "keras", ".", "activations", ".", "tanh", "\n", "\n", "", "self", ".", "has_first_dropout", "=", "hasattr", "(", "config", ",", "\"summary_first_dropout\"", ")", "and", "config", ".", "summary_first_dropout", ">", "0", "\n", "if", "self", ".", "has_first_dropout", ":", "\n", "            ", "self", ".", "first_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "summary_first_dropout", ")", "\n", "\n", "", "self", ".", "has_last_dropout", "=", "hasattr", "(", "config", ",", "\"summary_last_dropout\"", ")", "and", "config", ".", "summary_last_dropout", ">", "0", "\n", "if", "self", ".", "has_last_dropout", ":", "\n", "            ", "self", ".", "last_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "summary_last_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.TFSequenceSummary.call": [[503, 560], ["isinstance", "isinstance", "modeling_tf_utils.TFSequenceSummary.first_dropout", "modeling_tf_utils.TFSequenceSummary.summary", "modeling_tf_utils.TFSequenceSummary.activation", "modeling_tf_utils.TFSequenceSummary.last_dropout", "inputs.get", "inputs.get", "len", "tensorflow.reduce_mean", "len", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "tensorflow.gather", "tensorflow.squeeze", "tensorflow.fill", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\" hidden_states: float Tensor in shape [bsz, seq_len, hidden_size], the hidden-states of the last layer.\n            cls_index: [optional] position of the classification token if summary_type == 'cls_index',\n                shape (bsz,) or more generally (bsz, ...) where ... are optional leading dimensions of hidden_states.\n                if summary_type == 'cls_index' and cls_index is None:\n                    we take the last token of the sequence as classification token\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "inputs", ",", "(", "dict", ",", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "hidden_states", "=", "inputs", "\n", "cls_index", "=", "None", "\n", "", "elif", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "hidden_states", "=", "inputs", "[", "0", "]", "\n", "cls_index", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "None", "\n", "assert", "len", "(", "inputs", ")", "<=", "2", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "\"input_ids\"", ")", "\n", "cls_index", "=", "inputs", ".", "get", "(", "\"cls_index\"", ",", "None", ")", "\n", "\n", "", "if", "self", ".", "summary_type", "==", "\"last\"", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "-", "1", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "\"first\"", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "\"mean\"", ":", "\n", "            ", "output", "=", "tf", ".", "reduce_mean", "(", "hidden_states", ",", "axis", "=", "1", ")", "\n", "", "elif", "self", ".", "summary_type", "==", "\"cls_index\"", ":", "\n", "            ", "hidden_shape", "=", "shape_list", "(", "hidden_states", ")", "# e.g. [batch, num choices, seq length, hidden dims]", "\n", "if", "cls_index", "is", "None", ":", "\n", "                ", "cls_index", "=", "tf", ".", "fill", "(", "\n", "hidden_shape", "[", ":", "-", "2", "]", ",", "hidden_shape", "[", "-", "2", "]", "-", "1", "\n", ")", "# A tensor full of shape [batch] or [batch, num choices] full of sequence length", "\n", "", "cls_shape", "=", "shape_list", "(", "cls_index", ")", "\n", "if", "len", "(", "cls_shape", ")", "<=", "len", "(", "hidden_shape", ")", "-", "2", ":", "\n", "                ", "cls_index", "=", "cls_index", "[", "...", ",", "tf", ".", "newaxis", "]", "\n", "# else:", "\n", "# cls_index = cls_index[..., tf.newaxis]", "\n", "# cls_index = cls_index.expand((-1,) * (cls_index.dim()-1) + (hidden_states.size(-1),))", "\n", "# shape of cls_index: (bsz, XX, 1, hidden_size) where XX are optional leading dim of hidden_states", "\n", "", "output", "=", "tf", ".", "gather", "(", "hidden_states", ",", "cls_index", ",", "batch_dims", "=", "len", "(", "hidden_shape", ")", "-", "2", ")", "\n", "output", "=", "tf", ".", "squeeze", "(", "\n", "output", ",", "axis", "=", "len", "(", "hidden_shape", ")", "-", "2", "\n", ")", "# shape of output: (batch, num choices, hidden_size)", "\n", "", "elif", "self", ".", "summary_type", "==", "\"attn\"", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "if", "self", ".", "has_first_dropout", ":", "\n", "            ", "output", "=", "self", ".", "first_dropout", "(", "output", ",", "training", "=", "training", ")", "\n", "\n", "", "if", "self", ".", "has_summary", ":", "\n", "            ", "output", "=", "self", ".", "summary", "(", "output", ")", "\n", "\n", "", "if", "self", ".", "has_activation", ":", "\n", "            ", "output", "=", "self", ".", "activation", "(", "output", ")", "\n", "\n", "", "if", "self", ".", "has_last_dropout", ":", "\n", "            ", "output", "=", "self", ".", "last_dropout", "(", "output", ",", "training", "=", "training", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list": [[562, 567], ["x.shape.as_list", "tensorflow.shape", "enumerate"], "function", ["None"], ["", "", "def", "shape_list", "(", "x", ")", ":", "\n", "    ", "\"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"", "\n", "static", "=", "x", ".", "shape", ".", "as_list", "(", ")", "\n", "dynamic", "=", "tf", ".", "shape", "(", "x", ")", "\n", "return", "[", "dynamic", "[", "i", "]", "if", "s", "is", "None", "else", "s", "for", "i", ",", "s", "in", "enumerate", "(", "static", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer": [[569, 577], ["tensorflow.keras.initializers.TruncatedNormal"], "function", ["None"], ["", "def", "get_initializer", "(", "initializer_range", "=", "0.02", ")", ":", "\n", "    ", "\"\"\"Creates a `tf.initializers.truncated_normal` with the given range.\n    Args:\n        initializer_range: float, initializer range for stddev.\n    Returns:\n        TruncatedNormal initializer with stddev = `initializer_range`.\n    \"\"\"", "\n", "return", "tf", ".", "keras", ".", "initializers", ".", "TruncatedNormal", "(", "stddev", "=", "initializer_range", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_roberta_original_pytorch_checkpoint_to_pytorch.convert_roberta_checkpoint_to_pytorch": [[49, 160], ["fairseq.models.roberta.RobertaModel.from_pretrained", "FairseqRobertaModel.from_pretrained.eval", "transformers.modeling_bert.BertConfig", "print", "model.eval", "torch.zeros_like", "range", "FairseqRobertaModel.from_pretrained.encode().unsqueeze", "print", "torch.max().item", "print", "torch.allclose", "print", "pathlib.Path().mkdir", "print", "model.save_pretrained", "transformers.modeling_roberta.RobertaForSequenceClassification", "transformers.modeling_roberta.RobertaForMaskedLM", "model", "Exception", "torch.Size", "FairseqRobertaModel.from_pretrained.encode", "FairseqRobertaModel.from_pretrained.extract_features", "FairseqRobertaModel.from_pretrained.model", "torch.max", "pathlib.Path", "torch.abs"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.model", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.model"], ["def", "convert_roberta_checkpoint_to_pytorch", "(", "roberta_checkpoint_path", ",", "pytorch_dump_folder_path", ",", "classification_head", ")", ":", "\n", "    ", "\"\"\"\n    Copy/paste/tweak roberta's weights to our BERT structure.\n    \"\"\"", "\n", "roberta", "=", "FairseqRobertaModel", ".", "from_pretrained", "(", "roberta_checkpoint_path", ")", "\n", "roberta", ".", "eval", "(", ")", "# disable dropout", "\n", "roberta_sent_encoder", "=", "roberta", ".", "model", ".", "decoder", ".", "sentence_encoder", "\n", "config", "=", "BertConfig", "(", "\n", "vocab_size", "=", "roberta_sent_encoder", ".", "embed_tokens", ".", "num_embeddings", ",", "\n", "hidden_size", "=", "roberta", ".", "args", ".", "encoder_embed_dim", ",", "\n", "num_hidden_layers", "=", "roberta", ".", "args", ".", "encoder_layers", ",", "\n", "num_attention_heads", "=", "roberta", ".", "args", ".", "encoder_attention_heads", ",", "\n", "intermediate_size", "=", "roberta", ".", "args", ".", "encoder_ffn_embed_dim", ",", "\n", "max_position_embeddings", "=", "514", ",", "\n", "type_vocab_size", "=", "1", ",", "\n", "layer_norm_eps", "=", "1e-5", ",", "# PyTorch default used in fairseq", "\n", ")", "\n", "if", "classification_head", ":", "\n", "        ", "config", ".", "num_labels", "=", "roberta", ".", "args", ".", "num_classes", "\n", "", "print", "(", "\"Our BERT config:\"", ",", "config", ")", "\n", "\n", "model", "=", "RobertaForSequenceClassification", "(", "config", ")", "if", "classification_head", "else", "RobertaForMaskedLM", "(", "config", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Now let's copy all the weights.", "\n", "# Embeddings", "\n", "model", ".", "roberta", ".", "embeddings", ".", "word_embeddings", ".", "weight", "=", "roberta_sent_encoder", ".", "embed_tokens", ".", "weight", "\n", "model", ".", "roberta", ".", "embeddings", ".", "position_embeddings", ".", "weight", "=", "roberta_sent_encoder", ".", "embed_positions", ".", "weight", "\n", "model", ".", "roberta", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", ".", "data", "=", "torch", ".", "zeros_like", "(", "\n", "model", ".", "roberta", ".", "embeddings", ".", "token_type_embeddings", ".", "weight", "\n", ")", "# just zero them out b/c RoBERTa doesn't use them.", "\n", "model", ".", "roberta", ".", "embeddings", ".", "LayerNorm", ".", "weight", "=", "roberta_sent_encoder", ".", "emb_layer_norm", ".", "weight", "\n", "model", ".", "roberta", ".", "embeddings", ".", "LayerNorm", ".", "bias", "=", "roberta_sent_encoder", ".", "emb_layer_norm", ".", "bias", "\n", "\n", "for", "i", "in", "range", "(", "config", ".", "num_hidden_layers", ")", ":", "\n", "# Encoder: start of layer", "\n", "        ", "layer", ":", "BertLayer", "=", "model", ".", "roberta", ".", "encoder", ".", "layer", "[", "i", "]", "\n", "roberta_layer", ":", "TransformerSentenceEncoderLayer", "=", "roberta_sent_encoder", ".", "layers", "[", "i", "]", "\n", "\n", "# self attention", "\n", "self_attn", ":", "BertSelfAttention", "=", "layer", ".", "attention", ".", "self", "\n", "assert", "(", "\n", "roberta_layer", ".", "self_attn", ".", "k_proj", ".", "weight", ".", "data", ".", "shape", "\n", "==", "roberta_layer", ".", "self_attn", ".", "q_proj", ".", "weight", ".", "data", ".", "shape", "\n", "==", "roberta_layer", ".", "self_attn", ".", "v_proj", ".", "weight", ".", "data", ".", "shape", "\n", "==", "torch", ".", "Size", "(", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", ")", "\n", ")", "\n", "\n", "self_attn", ".", "query", ".", "weight", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "q_proj", ".", "weight", "\n", "self_attn", ".", "query", ".", "bias", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "q_proj", ".", "bias", "\n", "self_attn", ".", "key", ".", "weight", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "k_proj", ".", "weight", "\n", "self_attn", ".", "key", ".", "bias", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "k_proj", ".", "bias", "\n", "self_attn", ".", "value", ".", "weight", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "v_proj", ".", "weight", "\n", "self_attn", ".", "value", ".", "bias", ".", "data", "=", "roberta_layer", ".", "self_attn", ".", "v_proj", ".", "bias", "\n", "\n", "# self-attention output", "\n", "self_output", ":", "BertSelfOutput", "=", "layer", ".", "attention", ".", "output", "\n", "assert", "self_output", ".", "dense", ".", "weight", ".", "shape", "==", "roberta_layer", ".", "self_attn", ".", "out_proj", ".", "weight", ".", "shape", "\n", "self_output", ".", "dense", ".", "weight", "=", "roberta_layer", ".", "self_attn", ".", "out_proj", ".", "weight", "\n", "self_output", ".", "dense", ".", "bias", "=", "roberta_layer", ".", "self_attn", ".", "out_proj", ".", "bias", "\n", "self_output", ".", "LayerNorm", ".", "weight", "=", "roberta_layer", ".", "self_attn_layer_norm", ".", "weight", "\n", "self_output", ".", "LayerNorm", ".", "bias", "=", "roberta_layer", ".", "self_attn_layer_norm", ".", "bias", "\n", "\n", "# intermediate", "\n", "intermediate", ":", "BertIntermediate", "=", "layer", ".", "intermediate", "\n", "assert", "intermediate", ".", "dense", ".", "weight", ".", "shape", "==", "roberta_layer", ".", "fc1", ".", "weight", ".", "shape", "\n", "intermediate", ".", "dense", ".", "weight", "=", "roberta_layer", ".", "fc1", ".", "weight", "\n", "intermediate", ".", "dense", ".", "bias", "=", "roberta_layer", ".", "fc1", ".", "bias", "\n", "\n", "# output", "\n", "bert_output", ":", "BertOutput", "=", "layer", ".", "output", "\n", "assert", "bert_output", ".", "dense", ".", "weight", ".", "shape", "==", "roberta_layer", ".", "fc2", ".", "weight", ".", "shape", "\n", "bert_output", ".", "dense", ".", "weight", "=", "roberta_layer", ".", "fc2", ".", "weight", "\n", "bert_output", ".", "dense", ".", "bias", "=", "roberta_layer", ".", "fc2", ".", "bias", "\n", "bert_output", ".", "LayerNorm", ".", "weight", "=", "roberta_layer", ".", "final_layer_norm", ".", "weight", "\n", "bert_output", ".", "LayerNorm", ".", "bias", "=", "roberta_layer", ".", "final_layer_norm", ".", "bias", "\n", "# end of layer", "\n", "\n", "", "if", "classification_head", ":", "\n", "        ", "model", ".", "classifier", ".", "dense", ".", "weight", "=", "roberta", ".", "model", ".", "classification_heads", "[", "\"mnli\"", "]", ".", "dense", ".", "weight", "\n", "model", ".", "classifier", ".", "dense", ".", "bias", "=", "roberta", ".", "model", ".", "classification_heads", "[", "\"mnli\"", "]", ".", "dense", ".", "bias", "\n", "model", ".", "classifier", ".", "out_proj", ".", "weight", "=", "roberta", ".", "model", ".", "classification_heads", "[", "\"mnli\"", "]", ".", "out_proj", ".", "weight", "\n", "model", ".", "classifier", ".", "out_proj", ".", "bias", "=", "roberta", ".", "model", ".", "classification_heads", "[", "\"mnli\"", "]", ".", "out_proj", ".", "bias", "\n", "", "else", ":", "\n", "# LM Head", "\n", "        ", "model", ".", "lm_head", ".", "dense", ".", "weight", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "dense", ".", "weight", "\n", "model", ".", "lm_head", ".", "dense", ".", "bias", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "dense", ".", "bias", "\n", "model", ".", "lm_head", ".", "layer_norm", ".", "weight", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "layer_norm", ".", "weight", "\n", "model", ".", "lm_head", ".", "layer_norm", ".", "bias", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "layer_norm", ".", "bias", "\n", "model", ".", "lm_head", ".", "decoder", ".", "weight", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "weight", "\n", "model", ".", "lm_head", ".", "bias", "=", "roberta", ".", "model", ".", "decoder", ".", "lm_head", ".", "bias", "\n", "\n", "# Let's check that we get the same results.", "\n", "", "input_ids", ":", "torch", ".", "Tensor", "=", "roberta", ".", "encode", "(", "SAMPLE_TEXT", ")", ".", "unsqueeze", "(", "0", ")", "# batch of size 1", "\n", "\n", "our_output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "if", "classification_head", ":", "\n", "        ", "their_output", "=", "roberta", ".", "model", ".", "classification_heads", "[", "\"mnli\"", "]", "(", "roberta", ".", "extract_features", "(", "input_ids", ")", ")", "\n", "", "else", ":", "\n", "        ", "their_output", "=", "roberta", ".", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "", "print", "(", "our_output", ".", "shape", ",", "their_output", ".", "shape", ")", "\n", "max_absolute_diff", "=", "torch", ".", "max", "(", "torch", ".", "abs", "(", "our_output", "-", "their_output", ")", ")", ".", "item", "(", ")", "\n", "print", "(", "f\"max_absolute_diff = {max_absolute_diff}\"", ")", "# ~ 1e-7", "\n", "success", "=", "torch", ".", "allclose", "(", "our_output", ",", "their_output", ",", "atol", "=", "1e-3", ")", "\n", "print", "(", "\"Do both models output the same tensors?\"", ",", "\"\ud83d\udd25\"", "if", "success", "else", "\"\ud83d\udca9\"", ")", "\n", "if", "not", "success", ":", "\n", "        ", "raise", "Exception", "(", "\"Something went wRoNg\"", ")", "\n", "\n", "", "pathlib", ".", "Path", "(", "pytorch_dump_folder_path", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "print", "(", "f\"Saving model to {pytorch_dump_folder_path}\"", ")", "\n", "model", ".", "save_pretrained", "(", "pytorch_dump_folder_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlnet.XLNetTokenizer.__init__": [[64, 112], ["tokenization_utils.PreTrainedTokenizer.__init__", "spm.SentencePieceProcessor", "tokenization_xlnet.XLNetTokenizer.sp_model.Load", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "do_lower_case", "=", "False", ",", "\n", "remove_space", "=", "True", ",", "\n", "keep_accents", "=", "False", ",", "\n", "bos_token", "=", "\"<s>\"", ",", "\n", "eos_token", "=", "\"</s>\"", ",", "\n", "unk_token", "=", "\"<unk>\"", ",", "\n", "sep_token", "=", "\"<sep>\"", ",", "\n", "pad_token", "=", "\"<pad>\"", ",", "\n", "cls_token", "=", "\"<cls>\"", ",", "\n", "mask_token", "=", "\"<mask>\"", ",", "\n", "additional_special_tokens", "=", "[", "\"<eop>\"", ",", "\"<eod>\"", "]", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "XLNetTokenizer", ",", "self", ")", ".", "__init__", "(", "\n", "bos_token", "=", "bos_token", ",", "\n", "eos_token", "=", "eos_token", ",", "\n", "unk_token", "=", "unk_token", ",", "\n", "sep_token", "=", "sep_token", ",", "\n", "pad_token", "=", "pad_token", ",", "\n", "cls_token", "=", "cls_token", ",", "\n", "mask_token", "=", "mask_token", ",", "\n", "additional_special_tokens", "=", "additional_special_tokens", ",", "\n", "**", "kwargs", "\n", ")", "\n", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "-", "2", "# take into account special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "-", "3", "# take into account special tokens", "\n", "self", ".", "_pad_token_type_id", "=", "3", "\n", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"You need to install SentencePiece to use XLNetTokenizer: https://github.com/google/sentencepiece\"", "\n", "\"pip install sentencepiece\"", "\n", ")", "\n", "raise", "\n", "\n", "", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "self", ".", "remove_space", "=", "remove_space", "\n", "self", ".", "keep_accents", "=", "keep_accents", "\n", "self", ".", "vocab_file", "=", "vocab_file", "\n", "\n", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlnet.XLNetTokenizer.vocab_size": [[113, 116], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sp_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlnet.XLNetTokenizer.__getstate__": [[117, 121], ["tokenization_xlnet.XLNetTokenizer.__dict__.copy"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "state", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "state", "[", "\"sp_model\"", "]", "=", "None", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlnet.XLNetTokenizer.__setstate__": [[122, 134], ["spm.SentencePieceProcessor", "tokenization_xlnet.XLNetTokenizer.sp_model.Load", "logger.warning"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "d", ")", ":", "\n", "        ", "self", ".", "__dict__", "=", "d", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"You need to install SentencePiece to use XLNetTokenizer: https://github.com/google/sentencepiece\"", "\n", "\"pip install sentencepiece\"", "\n", ")", "\n", "raise", "\n", "", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "self", ".", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlnet.XLNetTokenizer.preprocess_text": [[135, 149], ["outputs.lower.lower.replace().replace", "unicodedata.normalize", "outputs.lower.lower.lower", "inputs.strip().split", "outputs.lower.lower.replace", "inputs.strip", "unicodedata.combining"], "methods", ["None"], ["", "def", "preprocess_text", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "remove_space", ":", "\n", "            ", "outputs", "=", "\" \"", ".", "join", "(", "inputs", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "inputs", "\n", "", "outputs", "=", "outputs", ".", "replace", "(", "\"``\"", ",", "'\"'", ")", ".", "replace", "(", "\"''\"", ",", "'\"'", ")", "\n", "\n", "if", "not", "self", ".", "keep_accents", ":", "\n", "            ", "outputs", "=", "unicodedata", ".", "normalize", "(", "\"NFKD\"", ",", "outputs", ")", "\n", "outputs", "=", "\"\"", ".", "join", "(", "[", "c", "for", "c", "in", "outputs", "if", "not", "unicodedata", ".", "combining", "(", "c", ")", "]", ")", "\n", "", "if", "self", ".", "do_lower_case", ":", "\n", "            ", "outputs", "=", "outputs", ".", "lower", "(", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlnet.XLNetTokenizer._tokenize": [[150, 173], ["tokenization_xlnet.XLNetTokenizer.preprocess_text", "tokenization_xlnet.XLNetTokenizer.sp_model.EncodeAsPieces", "tokenization_xlnet.XLNetTokenizer.sp_model.SampleEncodeAsPieces", "piece[].isdigit", "tokenization_xlnet.XLNetTokenizer.sp_model.EncodeAsPieces", "tokenization_xlnet.XLNetTokenizer.append", "new_pieces.extend", "new_pieces.append", "len", "str", "piece[].replace", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_albert.AlbertTokenizer.preprocess_text"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "sample", "=", "False", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. \"\"\"", "\n", "text", "=", "self", ".", "preprocess_text", "(", "text", ")", "\n", "\n", "if", "not", "sample", ":", "\n", "            ", "pieces", "=", "self", ".", "sp_model", ".", "EncodeAsPieces", "(", "text", ")", "\n", "", "else", ":", "\n", "            ", "pieces", "=", "self", ".", "sp_model", ".", "SampleEncodeAsPieces", "(", "text", ",", "64", ",", "0.1", ")", "\n", "", "new_pieces", "=", "[", "]", "\n", "for", "piece", "in", "pieces", ":", "\n", "            ", "if", "len", "(", "piece", ")", ">", "1", "and", "piece", "[", "-", "1", "]", "==", "str", "(", "\",\"", ")", "and", "piece", "[", "-", "2", "]", ".", "isdigit", "(", ")", ":", "\n", "                ", "cur_pieces", "=", "self", ".", "sp_model", ".", "EncodeAsPieces", "(", "piece", "[", ":", "-", "1", "]", ".", "replace", "(", "SPIECE_UNDERLINE", ",", "\"\"", ")", ")", "\n", "if", "piece", "[", "0", "]", "!=", "SPIECE_UNDERLINE", "and", "cur_pieces", "[", "0", "]", "[", "0", "]", "==", "SPIECE_UNDERLINE", ":", "\n", "                    ", "if", "len", "(", "cur_pieces", "[", "0", "]", ")", "==", "1", ":", "\n", "                        ", "cur_pieces", "=", "cur_pieces", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "                        ", "cur_pieces", "[", "0", "]", "=", "cur_pieces", "[", "0", "]", "[", "1", ":", "]", "\n", "", "", "cur_pieces", ".", "append", "(", "piece", "[", "-", "1", "]", ")", "\n", "new_pieces", ".", "extend", "(", "cur_pieces", ")", "\n", "", "else", ":", "\n", "                ", "new_pieces", ".", "append", "(", "piece", ")", "\n", "\n", "", "", "return", "new_pieces", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlnet.XLNetTokenizer._convert_token_to_id": [[174, 177], ["tokenization_xlnet.XLNetTokenizer.sp_model.PieceToId"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "sp_model", ".", "PieceToId", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlnet.XLNetTokenizer._convert_id_to_token": [[178, 181], ["tokenization_xlnet.XLNetTokenizer.sp_model.IdToPiece"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"", "\n", "return", "self", ".", "sp_model", ".", "IdToPiece", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlnet.XLNetTokenizer.convert_tokens_to_string": [[182, 186], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"", "\n", "out_string", "=", "\"\"", ".", "join", "(", "tokens", ")", ".", "replace", "(", "SPIECE_UNDERLINE", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlnet.XLNetTokenizer.build_inputs_with_special_tokens": [[187, 200], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n        by concatenating and adding special tokens.\n        An XLNet sequence has the following format:\n            single sequence: X <sep> <cls>\n            pair of sequences: A <sep> B <sep> <cls>\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "token_ids_0", "+", "sep", "+", "cls", "\n", "", "return", "token_ids_0", "+", "sep", "+", "token_ids_1", "+", "sep", "+", "cls", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlnet.XLNetTokenizer.get_special_tokens_mask": [[201, 228], ["list", "ValueError", "map", "len", "len", "len"], "methods", ["None"], ["", "def", "get_special_tokens_mask", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ",", "already_has_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n\n        Args:\n            token_ids_0: list of ids (must not contain special tokens)\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n                for sequence pairs\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n                special tokens for the model\n\n        Returns:\n            A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.\n        \"\"\"", "\n", "\n", "if", "already_has_special_tokens", ":", "\n", "            ", "if", "token_ids_1", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"You should not supply a second sequence if the provided sequence of \"", "\n", "\"ids is already formated with special tokens for the model.\"", "\n", ")", "\n", "", "return", "list", "(", "map", "(", "lambda", "x", ":", "1", "if", "x", "in", "[", "self", ".", "sep_token_id", ",", "self", ".", "cls_token_id", "]", "else", "0", ",", "token_ids_0", ")", ")", "\n", "\n", "", "if", "token_ids_1", "is", "not", "None", ":", "\n", "            ", "return", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_1", ")", ")", "+", "[", "1", ",", "1", "]", "\n", "", "return", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", ",", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlnet.XLNetTokenizer.create_token_type_ids_from_sequences": [[229, 245], ["len", "len", "len"], "methods", ["None"], ["", "def", "create_token_type_ids_from_sequences", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n        An XLNet sequence pair mask has the following format:\n        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 2\n        | first sequence    | second sequence     | CLS segment ID\n\n        if token_ids_1 is None, only returns the first portion of the mask (0's).\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "cls_segment_id", "=", "[", "2", "]", "\n", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "len", "(", "token_ids_0", "+", "sep", "+", "cls", ")", "*", "[", "0", "]", "\n", "", "return", "len", "(", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "+", "len", "(", "token_ids_1", "+", "sep", ")", "*", "[", "1", "]", "+", "cls_segment_id", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlnet.XLNetTokenizer.save_vocabulary": [[246, 259], ["os.path.join", "os.path.isdir", "logger.error", "os.path.abspath", "os.path.abspath", "shutil.copyfile"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n            to a directory.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "out_vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "\n", "if", "os", ".", "path", ".", "abspath", "(", "self", ".", "vocab_file", ")", "!=", "os", ".", "path", ".", "abspath", "(", "out_vocab_file", ")", ":", "\n", "            ", "copyfile", "(", "self", ".", "vocab_file", ",", "out_vocab_file", ")", "\n", "\n", "", "return", "(", "out_vocab_file", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFEmbeddings.__init__": [[66, 85], ["super().__init__", "modeling_tf_utils.TFSharedEmbeddings", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFEmbeddings", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "self", ".", "dim", "=", "config", ".", "dim", "\n", "self", ".", "initializer_range", "=", "config", ".", "initializer_range", "\n", "self", ".", "word_embeddings", "=", "TFSharedEmbeddings", "(", "\n", "config", ".", "vocab_size", ",", "config", ".", "dim", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"word_embeddings\"", "\n", ")", "# padding_idx=0)", "\n", "self", ".", "position_embeddings", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "\n", "config", ".", "dim", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"position_embeddings\"", ",", "\n", ")", "\n", "if", "config", ".", "sinusoidal_pos_embds", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "LayerNorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "1e-12", ",", "name", "=", "\"LayerNorm\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFEmbeddings.build": [[86, 95], ["super().build", "tensorflow.name_scope", "modeling_tf_distilbert.TFEmbeddings.add_weight", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "\"\"\"Build shared word embedding layer \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"word_embeddings\"", ")", ":", "\n", "# Create and initialize weights. The random normal initializer was chosen", "\n", "# arbitrarily, and works well.", "\n", "            ", "self", ".", "word_embeddings", "=", "self", ".", "add_weight", "(", "\n", "\"weight\"", ",", "shape", "=", "[", "self", ".", "vocab_size", ",", "self", ".", "dim", "]", ",", "initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", "\n", ")", "\n", "", "super", "(", "TFEmbeddings", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFEmbeddings.call": [[96, 117], ["modeling_tf_distilbert.TFEmbeddings._embedding", "modeling_tf_distilbert.TFEmbeddings._linear", "ValueError"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertEmbeddings._embedding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertEmbeddings._linear"], ["", "def", "call", "(", "self", ",", "inputs", ",", "inputs_embeds", "=", "None", ",", "mode", "=", "\"embedding\"", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Get token embeddings of inputs.\n        Args:\n            inputs: list of three int64 tensors with shape [batch_size, length]: (input_ids, position_ids, token_type_ids)\n            mode: string, a valid value is one of \"embedding\" and \"linear\".\n        Returns:\n            outputs: (1) If mode == \"embedding\", output embedding tensor, float32 with\n                shape [batch_size, length, embedding_size]; (2) mode == \"linear\", output\n                linear tensor, float32 with shape [batch_size, length, vocab_size].\n        Raises:\n            ValueError: if mode is not valid.\n\n        Shared weights logic adapted from\n            https://github.com/tensorflow/models/blob/a009f4fb9d2fc4949e32192a944688925ef78659/official/transformer/v2/embedding_layer.py#L24\n        \"\"\"", "\n", "if", "mode", "==", "\"embedding\"", ":", "\n", "            ", "return", "self", ".", "_embedding", "(", "inputs", ",", "inputs_embeds", "=", "inputs_embeds", ",", "training", "=", "training", ")", "\n", "", "elif", "mode", "==", "\"linear\"", ":", "\n", "            ", "return", "self", ".", "_linear", "(", "inputs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"mode {} is not valid.\"", ".", "format", "(", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFEmbeddings._embedding": [[118, 152], ["modeling_tf_distilbert.TFEmbeddings.position_embeddings", "modeling_tf_distilbert.TFEmbeddings.LayerNorm", "modeling_tf_distilbert.TFEmbeddings.dropout", "isinstance", "tensorflow.gather", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "tensorflow.range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "", "def", "_embedding", "(", "self", ",", "inputs", ",", "inputs_embeds", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        input_ids: tf.Tensor(bs, max_seq_length)\n            The token ids to embed.\n\n        Outputs\n        -------\n        embeddings: tf.Tensor(bs, max_seq_length, dim)\n            The embedded tokens (plus position embeddings, no token_type embeddings)\n        \"\"\"", "\n", "if", "not", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "position_ids", "=", "None", "\n", "", "else", ":", "\n", "            ", "input_ids", ",", "position_ids", "=", "inputs", "\n", "\n", "", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "seq_length", "=", "shape_list", "(", "input_ids", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "seq_length", "=", "shape_list", "(", "inputs_embeds", ")", "[", "1", "]", "\n", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "tf", ".", "range", "(", "seq_length", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "tf", ".", "gather", "(", "self", ".", "word_embeddings", ",", "input_ids", ")", "\n", "", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "# (bs, max_seq_length, dim)", "\n", "\n", "embeddings", "=", "inputs_embeds", "+", "position_embeddings", "# (bs, max_seq_length, dim)", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "# (bs, max_seq_length, dim)", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ",", "training", "=", "training", ")", "# (bs, max_seq_length, dim)", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFEmbeddings._linear": [[153, 167], ["tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "_linear", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Computes logits by running inputs through a linear layer.\n            Args:\n                inputs: A float32 tensor with shape [batch_size, length, hidden_size]\n            Returns:\n                float32 tensor with shape [batch_size, length, vocab_size].\n        \"\"\"", "\n", "batch_size", "=", "shape_list", "(", "inputs", ")", "[", "0", "]", "\n", "length", "=", "shape_list", "(", "inputs", ")", "[", "1", "]", "\n", "\n", "x", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "-", "1", ",", "self", ".", "dim", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "x", ",", "self", ".", "word_embeddings", ",", "transpose_b", "=", "True", ")", "\n", "\n", "return", "tf", ".", "reshape", "(", "logits", ",", "[", "batch_size", ",", "length", ",", "self", ".", "vocab_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFMultiHeadSelfAttention.__init__": [[170, 194], ["super().__init__", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "set", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFMultiHeadSelfAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "n_heads", "=", "config", ".", "n_heads", "\n", "self", ".", "dim", "=", "config", ".", "dim", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "attention_dropout", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "assert", "self", ".", "dim", "%", "self", ".", "n_heads", "==", "0", "\n", "\n", "self", ".", "q_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"q_lin\"", "\n", ")", "\n", "self", ".", "k_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"k_lin\"", "\n", ")", "\n", "self", ".", "v_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"v_lin\"", "\n", ")", "\n", "self", ".", "out_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"out_lin\"", "\n", ")", "\n", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFMultiHeadSelfAttention.prune_heads": [[195, 197], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFMultiHeadSelfAttention.call": [[198, 257], ["modeling_tf_utils.shape_list", "modeling_tf_distilbert.TFMultiHeadSelfAttention.call.shape"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        query: tf.Tensor(bs, seq_length, dim)\n        key: tf.Tensor(bs, seq_length, dim)\n        value: tf.Tensor(bs, seq_length, dim)\n        mask: tf.Tensor(bs, seq_length)\n\n        Outputs\n        -------\n        weights: tf.Tensor(bs, n_heads, seq_length, seq_length)\n            Attention weights\n        context: tf.Tensor(bs, seq_length, dim)\n            Contextualized layer. Optional: only if `output_attentions=True`\n        \"\"\"", "\n", "query", ",", "key", ",", "value", ",", "mask", ",", "head_mask", "=", "inputs", "\n", "bs", ",", "q_length", ",", "dim", "=", "shape_list", "(", "query", ")", "\n", "k_length", "=", "shape_list", "(", "key", ")", "[", "1", "]", "\n", "# assert dim == self.dim, 'Dimensions do not match: %s input vs %s configured' % (dim, self.dim)", "\n", "# assert key.size() == value.size()", "\n", "\n", "dim_per_head", "=", "self", ".", "dim", "//", "self", ".", "n_heads", "\n", "\n", "mask_reshape", "=", "[", "bs", ",", "1", ",", "1", ",", "k_length", "]", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\" separate heads \"\"\"", "\n", "return", "tf", ".", "transpose", "(", "tf", ".", "reshape", "(", "x", ",", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", ",", "dim_per_head", ")", ")", ",", "perm", "=", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\" group heads \"\"\"", "\n", "return", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "x", ",", "perm", "=", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", ",", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", "*", "dim_per_head", ")", ")", "\n", "\n", "", "q", "=", "shape", "(", "self", ".", "q_lin", "(", "query", ")", ")", "# (bs, n_heads, q_length, dim_per_head)", "\n", "k", "=", "shape", "(", "self", ".", "k_lin", "(", "key", ")", ")", "# (bs, n_heads, k_length, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v_lin", "(", "value", ")", ")", "# (bs, n_heads, k_length, dim_per_head)", "\n", "\n", "q", "=", "q", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "# (bs, n_heads, q_length, dim_per_head)", "\n", "scores", "=", "tf", ".", "matmul", "(", "q", ",", "k", ",", "transpose_b", "=", "True", ")", "# (bs, n_heads, q_length, k_length)", "\n", "mask", "=", "tf", ".", "reshape", "(", "mask", ",", "mask_reshape", ")", "# (bs, n_heads, qlen, klen)", "\n", "# scores.masked_fill_(mask, -float('inf'))            # (bs, n_heads, q_length, k_length)", "\n", "scores", "=", "scores", "-", "1e30", "*", "(", "1.0", "-", "mask", ")", "\n", "\n", "weights", "=", "tf", ".", "nn", ".", "softmax", "(", "scores", ",", "axis", "=", "-", "1", ")", "# (bs, n_heads, qlen, klen)", "\n", "weights", "=", "self", ".", "dropout", "(", "weights", ",", "training", "=", "training", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "weights", "=", "weights", "*", "head_mask", "\n", "\n", "", "context", "=", "tf", ".", "matmul", "(", "weights", ",", "v", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "context", "=", "unshape", "(", "context", ")", "# (bs, q_length, dim)", "\n", "context", "=", "self", ".", "out_lin", "(", "context", ")", "# (bs, q_length, dim)", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "return", "(", "context", ",", "weights", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "context", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFFFN.__init__": [[260, 274], ["super().__init__", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Activation", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFFFN", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "self", ".", "lin1", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "hidden_dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"lin1\"", "\n", ")", "\n", "self", ".", "lin2", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"lin2\"", "\n", ")", "\n", "assert", "config", ".", "activation", "in", "[", "\"relu\"", ",", "\"gelu\"", "]", ",", "\"activation ({}) must be in ['relu', 'gelu']\"", ".", "format", "(", "\n", "config", ".", "activation", "\n", ")", "\n", "self", ".", "activation", "=", "(", "\n", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "gelu", ")", "if", "config", ".", "activation", "==", "\"gelu\"", "else", "tf", ".", "keras", ".", "activations", ".", "relu", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFFFN.call": [[276, 282], ["modeling_tf_distilbert.TFFFN.lin1", "modeling_tf_distilbert.TFFFN.activation", "modeling_tf_distilbert.TFFFN.lin2", "modeling_tf_distilbert.TFFFN.dropout"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "lin1", "(", "input", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "lin2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ",", "training", "=", "training", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFTransformerBlock.__init__": [[285, 302], ["super().__init__", "tensorflow.keras.layers.Dropout", "modeling_tf_distilbert.TFMultiHeadSelfAttention", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_distilbert.TFFFN", "tensorflow.keras.layers.LayerNormalization"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFTransformerBlock", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "n_heads", "=", "config", ".", "n_heads", "\n", "self", ".", "dim", "=", "config", ".", "dim", "\n", "self", ".", "hidden_dim", "=", "config", ".", "hidden_dim", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "self", ".", "activation", "=", "config", ".", "activation", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "assert", "config", ".", "dim", "%", "config", ".", "n_heads", "==", "0", "\n", "\n", "self", ".", "attention", "=", "TFMultiHeadSelfAttention", "(", "config", ",", "name", "=", "\"attention\"", ")", "\n", "self", ".", "sa_layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "1e-12", ",", "name", "=", "\"sa_layer_norm\"", ")", "\n", "\n", "self", ".", "ffn", "=", "TFFFN", "(", "config", ",", "name", "=", "\"ffn\"", ")", "\n", "self", ".", "output_layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "1e-12", ",", "name", "=", "\"output_layer_norm\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFTransformerBlock.call": [[303, 336], ["modeling_tf_distilbert.TFTransformerBlock.attention", "modeling_tf_distilbert.TFTransformerBlock.sa_layer_norm", "modeling_tf_distilbert.TFTransformerBlock.ffn", "modeling_tf_distilbert.TFTransformerBlock.output_layer_norm"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "# removed: src_enc=None, src_len=None", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        x: tf.Tensor(bs, seq_length, dim)\n        attn_mask: tf.Tensor(bs, seq_length)\n\n        Outputs\n        -------\n        sa_weights: tf.Tensor(bs, n_heads, seq_length, seq_length)\n            The attention weights\n        ffn_output: tf.Tensor(bs, seq_length, dim)\n            The output of the transformer block contextualization.\n        \"\"\"", "\n", "x", ",", "attn_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "# Self-Attention", "\n", "sa_output", "=", "self", ".", "attention", "(", "[", "x", ",", "x", ",", "x", ",", "attn_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "sa_output", ",", "sa_weights", "=", "sa_output", "# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)", "\n", "", "else", ":", "# To handle these `output_attention` or `output_hidden_states` cases returning tuples", "\n", "# assert type(sa_output) == tuple", "\n", "            ", "sa_output", "=", "sa_output", "[", "0", "]", "\n", "", "sa_output", "=", "self", ".", "sa_layer_norm", "(", "sa_output", "+", "x", ")", "# (bs, seq_length, dim)", "\n", "\n", "# Feed Forward Network", "\n", "ffn_output", "=", "self", ".", "ffn", "(", "sa_output", ",", "training", "=", "training", ")", "# (bs, seq_length, dim)", "\n", "ffn_output", "=", "self", ".", "output_layer_norm", "(", "ffn_output", "+", "sa_output", ")", "# (bs, seq_length, dim)", "\n", "\n", "output", "=", "(", "ffn_output", ",", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "output", "=", "(", "sa_weights", ",", ")", "+", "output", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFTransformer.__init__": [[339, 346], ["super().__init__", "modeling_tf_distilbert.TFTransformerBlock", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFTransformer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "n_layers", "=", "config", ".", "n_layers", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "self", ".", "layer", "=", "[", "TFTransformerBlock", "(", "config", ",", "name", "=", "\"layer_._{}\"", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "config", ".", "n_layers", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFTransformer.call": [[347, 397], ["enumerate", "layer_module", "len", "len"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        x: tf.Tensor(bs, seq_length, dim)\n            Input sequence embedded.\n        attn_mask: tf.Tensor(bs, seq_length)\n            Attention mask on the sequence.\n\n        Outputs\n        -------\n        hidden_state: tf.Tensor(bs, seq_length, dim)\n            Sequence of hiddens states in the last (top) layer\n        all_hidden_states: Tuple[tf.Tensor(bs, seq_length, dim)]\n            Tuple of length n_layers with the hidden states from each layer.\n            Optional: only if output_hidden_states=True\n        all_attentions: Tuple[tf.Tensor(bs, n_heads, seq_length, seq_length)]\n            Tuple of length n_layers with the attention weights from each layer\n            Optional: only if output_attentions=True\n        \"\"\"", "\n", "x", ",", "attn_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "\n", "hidden_state", "=", "x", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_state", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "[", "hidden_state", ",", "attn_mask", ",", "head_mask", "[", "i", "]", "]", ",", "training", "=", "training", ")", "\n", "hidden_state", "=", "layer_outputs", "[", "-", "1", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "assert", "len", "(", "layer_outputs", ")", "==", "2", "\n", "attentions", "=", "layer_outputs", "[", "0", "]", "\n", "all_attentions", "=", "all_attentions", "+", "(", "attentions", ",", ")", "\n", "", "else", ":", "\n", "                ", "assert", "len", "(", "layer_outputs", ")", "==", "1", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_state", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_state", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertMainLayer.__init__": [[400, 406], ["super().__init__", "modeling_tf_distilbert.TFEmbeddings", "modeling_tf_distilbert.TFTransformer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFDistilBertMainLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "num_hidden_layers", "=", "config", ".", "num_hidden_layers", "\n", "\n", "self", ".", "embeddings", "=", "TFEmbeddings", "(", "config", ",", "name", "=", "\"embeddings\"", ")", "# Embeddings", "\n", "self", ".", "transformer", "=", "TFTransformer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "# Encoder", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertMainLayer.get_input_embeddings": [[407, 409], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertMainLayer._resize_token_embeddings": [[410, 412], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertMainLayer._prune_heads": [[413, 415], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertMainLayer.call": [[416, 459], ["isinstance", "tensorflow.cast", "modeling_tf_distilbert.TFDistilBertMainLayer.embeddings", "modeling_tf_distilbert.TFDistilBertMainLayer.transformer", "isinstance", "ValueError", "tensorflow.ones", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "modeling_tf_utils.shape_list", "len", "len", "len", "len", "ValueError", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "head_mask", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "head_mask", "\n", "inputs_embeds", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "inputs_embeds", "\n", "assert", "len", "(", "inputs", ")", "<=", "4", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "\"input_ids\"", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "\"attention_mask\"", ",", "attention_mask", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "\"head_mask\"", ",", "head_mask", ")", "\n", "inputs_embeds", "=", "inputs", ".", "get", "(", "\"inputs_embeds\"", ",", "inputs_embeds", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "4", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "input_ids", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "inputs_embeds", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "tf", ".", "ones", "(", "input_shape", ")", "# (bs, seq_length)", "\n", "", "attention_mask", "=", "tf", ".", "cast", "(", "attention_mask", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "num_hidden_layers", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", ",", "inputs_embeds", "=", "inputs_embeds", ")", "# (bs, seq_length, dim)", "\n", "tfmr_output", "=", "self", ".", "transformer", "(", "[", "embedding_output", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "\n", "return", "tfmr_output", "# last-layer hidden-state, (all hidden_states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertModel.__init__": [[570, 573], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_distilbert.TFDistilBertMainLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFDistilBertModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "distilbert", "=", "TFDistilBertMainLayer", "(", "config", ",", "name", "=", "\"distilbert\"", ")", "# Embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertModel.call": [[574, 577], ["modeling_tf_distilbert.TFDistilBertModel.distilbert"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "distilbert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertLMHead.__init__": [[580, 587], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "input_embeddings", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFDistilBertLMHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "input_embeddings", "=", "input_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertLMHead.build": [[588, 591], ["modeling_tf_distilbert.TFDistilBertLMHead.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "vocab_size", ",", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"bias\"", ")", "\n", "super", "(", "TFDistilBertLMHead", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertLMHead.call": [[592, 596], ["modeling_tf_distilbert.TFDistilBertLMHead.input_embeddings"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "input_embeddings", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "hidden_states", "=", "hidden_states", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertForMaskedLM.__init__": [[629, 642], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_distilbert.TFDistilBertMainLayer", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Activation", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_distilbert.TFDistilBertLMHead", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFDistilBertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "\n", "self", ".", "distilbert", "=", "TFDistilBertMainLayer", "(", "config", ",", "name", "=", "\"distilbert\"", ")", "\n", "self", ".", "vocab_transform", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"vocab_transform\"", "\n", ")", "\n", "self", ".", "act", "=", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "gelu", ")", "\n", "self", ".", "vocab_layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "1e-12", ",", "name", "=", "\"vocab_layer_norm\"", ")", "\n", "self", ".", "vocab_projector", "=", "TFDistilBertLMHead", "(", "config", ",", "self", ".", "distilbert", ".", "embeddings", ",", "name", "=", "\"vocab_projector\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertForMaskedLM.get_output_embeddings": [[643, 645], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "vocab_projector", ".", "input_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertForMaskedLM.call": [[646, 657], ["modeling_tf_distilbert.TFDistilBertForMaskedLM.distilbert", "modeling_tf_distilbert.TFDistilBertForMaskedLM.vocab_transform", "modeling_tf_distilbert.TFDistilBertForMaskedLM.act", "modeling_tf_distilbert.TFDistilBertForMaskedLM.vocab_layer_norm", "modeling_tf_distilbert.TFDistilBertForMaskedLM.vocab_projector"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "distilbert_output", "=", "self", ".", "distilbert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "hidden_states", "=", "distilbert_output", "[", "0", "]", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "self", ".", "vocab_transform", "(", "hidden_states", ")", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "self", ".", "act", "(", "prediction_logits", ")", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "self", ".", "vocab_layer_norm", "(", "prediction_logits", ")", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "self", ".", "vocab_projector", "(", "prediction_logits", ")", "\n", "\n", "outputs", "=", "(", "prediction_logits", ",", ")", "+", "distilbert_output", "[", "1", ":", "]", "\n", "return", "outputs", "# logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertForSequenceClassification.__init__": [[691, 706], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_distilbert.TFDistilBertMainLayer", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFDistilBertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "distilbert", "=", "TFDistilBertMainLayer", "(", "config", ",", "name", "=", "\"distilbert\"", ")", "\n", "self", ".", "pre_classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "dim", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "activation", "=", "\"relu\"", ",", "\n", "name", "=", "\"pre_classifier\"", ",", "\n", ")", "\n", "self", ".", "classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"classifier\"", "\n", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "seq_classif_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertForSequenceClassification.call": [[707, 718], ["modeling_tf_distilbert.TFDistilBertForSequenceClassification.distilbert", "modeling_tf_distilbert.TFDistilBertForSequenceClassification.pre_classifier", "modeling_tf_distilbert.TFDistilBertForSequenceClassification.dropout", "modeling_tf_distilbert.TFDistilBertForSequenceClassification.classifier", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "distilbert_output", "=", "self", ".", "distilbert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "hidden_state", "=", "distilbert_output", "[", "0", "]", "# (bs, seq_len, dim)", "\n", "pooled_output", "=", "hidden_state", "[", ":", ",", "0", "]", "# (bs, dim)", "\n", "pooled_output", "=", "self", ".", "pre_classifier", "(", "pooled_output", ")", "# (bs, dim)", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ",", "training", "=", "kwargs", ".", "get", "(", "\"training\"", ",", "False", ")", ")", "# (bs, dim)", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "# (bs, dim)", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "distilbert_output", "[", "1", ":", "]", "\n", "return", "outputs", "# logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertForTokenClassification.__init__": [[748, 756], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_distilbert.TFDistilBertMainLayer", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFDistilBertForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "distilbert", "=", "TFDistilBertMainLayer", "(", "config", ",", "name", "=", "\"distilbert\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "self", ".", "classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"classifier\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertForTokenClassification.call": [[758, 769], ["modeling_tf_distilbert.TFDistilBertForTokenClassification.distilbert", "modeling_tf_distilbert.TFDistilBertForTokenClassification.dropout", "modeling_tf_distilbert.TFDistilBertForTokenClassification.classifier", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "distilbert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ",", "training", "=", "kwargs", ".", "get", "(", "\"training\"", ",", "False", ")", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertForQuestionAnswering.__init__": [[805, 814], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_distilbert.TFDistilBertMainLayer", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFDistilBertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "distilbert", "=", "TFDistilBertMainLayer", "(", "config", ",", "name", "=", "\"distilbert\"", ")", "\n", "self", ".", "qa_outputs", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"qa_outputs\"", "\n", ")", "\n", "assert", "config", ".", "num_labels", "==", "2", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "qa_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.TFDistilBertForQuestionAnswering.call": [[815, 827], ["modeling_tf_distilbert.TFDistilBertForQuestionAnswering.distilbert", "modeling_tf_distilbert.TFDistilBertForQuestionAnswering.dropout", "modeling_tf_distilbert.TFDistilBertForQuestionAnswering.qa_outputs", "tensorflow.split", "tensorflow.squeeze", "tensorflow.squeeze", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "distilbert_output", "=", "self", ".", "distilbert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "hidden_states", "=", "distilbert_output", "[", "0", "]", "# (bs, max_query_len, dim)", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ",", "training", "=", "kwargs", ".", "get", "(", "\"training\"", ",", "False", ")", ")", "# (bs, max_query_len, dim)", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "hidden_states", ")", "# (bs, max_query_len, 2)", "\n", "start_logits", ",", "end_logits", "=", "tf", ".", "split", "(", "logits", ",", "2", ",", "axis", "=", "-", "1", ")", "\n", "start_logits", "=", "tf", ".", "squeeze", "(", "start_logits", ",", "axis", "=", "-", "1", ")", "\n", "end_logits", "=", "tf", ".", "squeeze", "(", "end_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "distilbert_output", "[", "1", ":", "]", "\n", "return", "outputs", "# start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.gelu": [[41, 50], ["tensorflow.math.erf", "tensorflow.math.sqrt"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Gaussian Error Linear Unit.\n    Original Implementation of the gelu activation function in Google Bert repo when initially created.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "math", ".", "erf", "(", "x", "/", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_distilbert.gelu_new": [[52, 63], ["tensorflow.tanh", "numpy.sqrt", "tensorflow.pow"], "function", ["None"], ["", "def", "gelu_new", "(", "x", ")", ":", "\n", "    ", "\"\"\"Gaussian Error Linear Unit.\n    This is a smoother version of the RELU.\n    Original paper: https://arxiv.org/abs/1606.08415\n    Args:\n        x: float Tensor to perform activation.\n    Returns:\n        `x` with the GELU activation applied.\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "tanh", "(", "(", "np", ".", "sqrt", "(", "2", "/", "np", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "tf", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.ArgumentHandler.__call__": [[87, 90], ["NotImplementedError"], "methods", ["None"], ["@", "abstractmethod", "\n", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.DefaultArgumentHandler.__call__": [[97, 110], ["ValueError", "len", "isinstance", "len", "list"], "methods", ["None"], ["def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "\"X\"", "in", "kwargs", ":", "\n", "            ", "return", "kwargs", "[", "\"X\"", "]", "\n", "", "elif", "\"data\"", "in", "kwargs", ":", "\n", "            ", "return", "kwargs", "[", "\"data\"", "]", "\n", "", "elif", "len", "(", "args", ")", "==", "1", ":", "\n", "            ", "if", "isinstance", "(", "args", "[", "0", "]", ",", "list", ")", ":", "\n", "                ", "return", "args", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "return", "[", "args", "[", "0", "]", "]", "\n", "", "", "elif", "len", "(", "args", ")", ">", "1", ":", "\n", "            ", "return", "list", "(", "args", ")", "\n", "", "raise", "ValueError", "(", "\"Unable to infer the format of the provided data (X=, data=, ...)\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipelineDataFormat.__init__": [[126, 142], ["column.split", "len", "os.path.exists", "os.path.abspath", "OSError", "os.path.exists", "OSError", "tuple", "os.path.abspath", "c.split"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "output_path", ":", "Optional", "[", "str", "]", ",", "input_path", ":", "Optional", "[", "str", "]", ",", "column", ":", "Optional", "[", "str", "]", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "self", ".", "output_path", "=", "output_path", "\n", "self", ".", "input_path", "=", "input_path", "\n", "self", ".", "column", "=", "column", ".", "split", "(", "\",\"", ")", "if", "column", "is", "not", "None", "else", "[", "\"\"", "]", "\n", "self", ".", "is_multi_columns", "=", "len", "(", "self", ".", "column", ")", ">", "1", "\n", "\n", "if", "self", ".", "is_multi_columns", ":", "\n", "            ", "self", ".", "column", "=", "[", "tuple", "(", "c", ".", "split", "(", "\"=\"", ")", ")", "if", "\"=\"", "in", "c", "else", "(", "c", ",", "c", ")", "for", "c", "in", "self", ".", "column", "]", "\n", "\n", "", "if", "output_path", "is", "not", "None", "and", "not", "overwrite", ":", "\n", "            ", "if", "exists", "(", "abspath", "(", "self", ".", "output_path", ")", ")", ":", "\n", "                ", "raise", "OSError", "(", "\"{} already exists on disk\"", ".", "format", "(", "self", ".", "output_path", ")", ")", "\n", "\n", "", "", "if", "input_path", "is", "not", "None", ":", "\n", "            ", "if", "not", "exists", "(", "abspath", "(", "self", ".", "input_path", ")", ")", ":", "\n", "                ", "raise", "OSError", "(", "\"{} doesnt exist on disk\"", ".", "format", "(", "self", ".", "input_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipelineDataFormat.__iter__": [[143, 146], ["NotImplementedError"], "methods", ["None"], ["", "", "", "@", "abstractmethod", "\n", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipelineDataFormat.save": [[147, 155], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "save", "(", "self", ",", "data", ":", "dict", ")", ":", "\n", "        ", "\"\"\"\n        Save the provided data object with the representation for the current `DataFormat`.\n        :param data: data to store\n        :return:\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipelineDataFormat.save_binary": [[156, 169], ["os.path.splitext", "os.path.extsep.join", "open", "pickle.dump"], "methods", ["None"], ["", "def", "save_binary", "(", "self", ",", "data", ":", "Union", "[", "dict", ",", "List", "[", "dict", "]", "]", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Save the provided data object as a pickle-formatted binary data on the disk.\n        :param data: data to store\n        :return: (str) Path where the data has been saved\n        \"\"\"", "\n", "path", ",", "_", "=", "os", ".", "path", ".", "splitext", "(", "self", ".", "output_path", ")", "\n", "binary_path", "=", "os", ".", "path", ".", "extsep", ".", "join", "(", "(", "path", ",", "\"pickle\"", ")", ")", "\n", "\n", "with", "open", "(", "binary_path", ",", "\"wb+\"", ")", "as", "f_output", ":", "\n", "            ", "pickle", ".", "dump", "(", "data", ",", "f_output", ")", "\n", "\n", "", "return", "binary_path", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipelineDataFormat.from_str": [[170, 182], ["pipelines.JsonPipelineDataFormat", "pipelines.CsvPipelineDataFormat", "pipelines.PipedPipelineDataFormat", "KeyError"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "from_str", "(", "\n", "format", ":", "str", ",", "output_path", ":", "Optional", "[", "str", "]", ",", "input_path", ":", "Optional", "[", "str", "]", ",", "column", ":", "Optional", "[", "str", "]", ",", "overwrite", "=", "False", "\n", ")", ":", "\n", "        ", "if", "format", "==", "\"json\"", ":", "\n", "            ", "return", "JsonPipelineDataFormat", "(", "output_path", ",", "input_path", ",", "column", ",", "overwrite", "=", "overwrite", ")", "\n", "", "elif", "format", "==", "\"csv\"", ":", "\n", "            ", "return", "CsvPipelineDataFormat", "(", "output_path", ",", "input_path", ",", "column", ",", "overwrite", "=", "overwrite", ")", "\n", "", "elif", "format", "==", "\"pipe\"", ":", "\n", "            ", "return", "PipedPipelineDataFormat", "(", "output_path", ",", "input_path", ",", "column", ",", "overwrite", "=", "overwrite", ")", "\n", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "\"Unknown reader {} (Available reader are json/csv/pipe)\"", ".", "format", "(", "format", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.CsvPipelineDataFormat.__init__": [[185, 187], ["pipelines.PipelineDataFormat.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_path", ":", "Optional", "[", "str", "]", ",", "input_path", ":", "Optional", "[", "str", "]", ",", "column", ":", "Optional", "[", "str", "]", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "output_path", ",", "input_path", ",", "column", ",", "overwrite", "=", "overwrite", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.CsvPipelineDataFormat.__iter__": [[188, 196], ["open", "csv.DictReader"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "input_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "reader", "=", "csv", ".", "DictReader", "(", "f", ")", "\n", "for", "row", "in", "reader", ":", "\n", "                ", "if", "self", ".", "is_multi_columns", ":", "\n", "                    ", "yield", "{", "k", ":", "row", "[", "c", "]", "for", "k", ",", "c", "in", "self", ".", "column", "}", "\n", "", "else", ":", "\n", "                    ", "yield", "row", "[", "self", ".", "column", "[", "0", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.CsvPipelineDataFormat.save": [[197, 203], ["open", "len", "csv.DictWriter", "csv.DictWriter.writeheader", "csv.DictWriter.writerows", "list", "data[].keys"], "methods", ["None"], ["", "", "", "", "def", "save", "(", "self", ",", "data", ":", "List", "[", "dict", "]", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "output_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "if", "len", "(", "data", ")", ">", "0", ":", "\n", "                ", "writer", "=", "csv", ".", "DictWriter", "(", "f", ",", "list", "(", "data", "[", "0", "]", ".", "keys", "(", ")", ")", ")", "\n", "writer", ".", "writeheader", "(", ")", "\n", "writer", ".", "writerows", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.JsonPipelineDataFormat.__init__": [[206, 211], ["pipelines.PipelineDataFormat.__init__", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "output_path", ":", "Optional", "[", "str", "]", ",", "input_path", ":", "Optional", "[", "str", "]", ",", "column", ":", "Optional", "[", "str", "]", ",", "overwrite", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "output_path", ",", "input_path", ",", "column", ",", "overwrite", "=", "overwrite", ")", "\n", "\n", "with", "open", "(", "input_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "self", ".", "_entries", "=", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.JsonPipelineDataFormat.__iter__": [[212, 218], ["None"], "methods", ["None"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "entry", "in", "self", ".", "_entries", ":", "\n", "            ", "if", "self", ".", "is_multi_columns", ":", "\n", "                ", "yield", "{", "k", ":", "entry", "[", "c", "]", "for", "k", ",", "c", "in", "self", ".", "column", "}", "\n", "", "else", ":", "\n", "                ", "yield", "entry", "[", "self", ".", "column", "[", "0", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.JsonPipelineDataFormat.save": [[219, 222], ["open", "json.dump"], "methods", ["None"], ["", "", "", "def", "save", "(", "self", ",", "data", ":", "dict", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "output_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "data", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.__iter__": [[232, 247], ["line.split.split.split", "tuple", "zip"], "methods", ["None"], ["def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "line", "in", "sys", ".", "stdin", ":", "\n", "# Split for multi-columns", "\n", "            ", "if", "\"\\t\"", "in", "line", ":", "\n", "\n", "                ", "line", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "if", "self", ".", "column", ":", "\n", "# Dictionary to map arguments", "\n", "                    ", "yield", "{", "kwargs", ":", "l", "for", "(", "kwargs", ",", "_", ")", ",", "l", "in", "zip", "(", "self", ".", "column", ",", "line", ")", "}", "\n", "", "else", ":", "\n", "                    ", "yield", "tuple", "(", "line", ")", "\n", "\n", "# No dictionary to map arguments", "\n", "", "", "else", ":", "\n", "                ", "yield", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save": [[248, 250], ["print"], "methods", ["None"], ["", "", "", "def", "save", "(", "self", ",", "data", ":", "dict", ")", ":", "\n", "        ", "print", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save_binary": [[251, 259], ["pipelines.PipelineDataFormat.save_binary", "KeyError"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save_binary"], ["", "def", "save_binary", "(", "self", ",", "data", ":", "Union", "[", "dict", ",", "List", "[", "dict", "]", "]", ")", "->", "str", ":", "\n", "        ", "if", "self", ".", "output_path", "is", "None", ":", "\n", "            ", "raise", "KeyError", "(", "\n", "\"When using piped input on pipeline outputting large object requires an output file path. \"", "\n", "\"Please provide such output path through --output argument.\"", "\n", ")", "\n", "\n", "", "return", "super", "(", ")", ".", "save_binary", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines._ScikitCompat.transform": [[266, 269], ["NotImplementedError"], "methods", ["None"], ["@", "abstractmethod", "\n", "def", "transform", "(", "self", ",", "X", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines._ScikitCompat.predict": [[270, 273], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "predict", "(", "self", ",", "X", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline.__init__": [[320, 345], ["pipelines.get_framework", "pipelines.DefaultArgumentHandler", "pipelines.Pipeline.model.to"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.get_framework"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", "=", "None", ",", "\n", "modelcard", ":", "ModelCard", "=", "None", ",", "\n", "framework", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "args_parser", ":", "ArgumentHandler", "=", "None", ",", "\n", "device", ":", "int", "=", "-", "1", ",", "\n", "binary_output", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "\n", "        ", "if", "framework", "is", "None", ":", "\n", "            ", "framework", "=", "get_framework", "(", ")", "\n", "\n", "", "self", ".", "model", "=", "model", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "modelcard", "=", "modelcard", "\n", "self", ".", "framework", "=", "framework", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "binary_output", "=", "binary_output", "\n", "self", ".", "_args_parser", "=", "args_parser", "or", "DefaultArgumentHandler", "(", ")", "\n", "\n", "# Special handling", "\n", "if", "self", ".", "device", ">=", "0", "and", "self", ".", "framework", "==", "\"pt\"", ":", "\n", "            ", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "\"cuda:{}\"", ".", "format", "(", "self", ".", "device", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline.save_pretrained": [[346, 357], ["pipelines.Pipeline.model.save_pretrained", "pipelines.Pipeline.tokenizer.save_pretrained", "pipelines.Pipeline.modelcard.save_pretrained", "os.path.isdir", "logger.error"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained"], ["", "", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"\n        Save the pipeline's model and tokenizer to the specified save_directory\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Provided path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "\n", "", "self", ".", "model", ".", "save_pretrained", "(", "save_directory", ")", "\n", "self", ".", "tokenizer", ".", "save_pretrained", "(", "save_directory", ")", "\n", "self", ".", "modelcard", ".", "save_pretrained", "(", "save_directory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline.transform": [[358, 363], ["pipelines.Pipeline."], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "X", ")", ":", "\n", "        ", "\"\"\"\n        Scikit / Keras interface to transformers' pipelines. This method will forward to __call__().\n        \"\"\"", "\n", "return", "self", "(", "X", "=", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline.predict": [[364, 370], ["pipelines.Pipeline."], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "X", ")", ":", "\n", "        ", "\"\"\"\n        Scikit / Keras interface to transformers' pipelines. This method will forward to __call__().\n        Se\n        \"\"\"", "\n", "return", "self", "(", "X", "=", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline.device_placement": [[371, 392], ["tf.device", "torch.cuda.set_device"], "methods", ["None"], ["", "@", "contextmanager", "\n", "def", "device_placement", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Context Manager allowing tensor allocation on the user-specified device in framework agnostic way.\n        example:\n            # Explicitly ask for tensor allocation on CUDA device :0\n            nlp = pipeline(..., device=0)\n            with nlp.device_placement():\n                # Every framework specific tensor allocation will be done on the request device\n                output = nlp(...)\n        Returns:\n            Context manager\n        \"\"\"", "\n", "if", "self", ".", "framework", "==", "\"tf\"", ":", "\n", "            ", "with", "tf", ".", "device", "(", "\"/CPU:0\"", "if", "self", ".", "device", "==", "-", "1", "else", "\"/device:GPU:{}\"", ".", "format", "(", "self", ".", "device", ")", ")", ":", "\n", "                ", "yield", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "device", ">=", "0", ":", "\n", "                ", "torch", ".", "cuda", ".", "set_device", "(", "self", ".", "device", ")", "\n", "\n", "", "yield", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline.inputs_for_model": [[393, 414], ["type().__name__.lower", "isinstance", "type"], "methods", ["None"], ["", "", "def", "inputs_for_model", "(", "self", ",", "features", ":", "Union", "[", "dict", ",", "List", "[", "dict", "]", "]", ")", "->", "Dict", ":", "\n", "        ", "\"\"\"\n        Generates the input dictionary with model-specific parameters.\n\n        Returns:\n            dict holding all the required parameters for model's forward\n        \"\"\"", "\n", "args", "=", "[", "\"input_ids\"", ",", "\"attention_mask\"", "]", "\n", "model_type", "=", "type", "(", "self", ".", "model", ")", ".", "__name__", ".", "lower", "(", ")", "\n", "\n", "if", "\"distilbert\"", "not", "in", "model_type", "and", "\"xlm\"", "not", "in", "model_type", ":", "\n", "            ", "args", "+=", "[", "\"token_type_ids\"", "]", "\n", "\n", "# PR #1548 (CLI) There is an issue with attention_mask", "\n", "# if 'xlnet' in model_type or 'xlm' in model_type:", "\n", "#     args += ['cls_index', 'p_mask']", "\n", "\n", "", "if", "isinstance", "(", "features", ",", "dict", ")", ":", "\n", "            ", "return", "{", "k", ":", "features", "[", "k", "]", "for", "k", "in", "args", "}", "\n", "", "else", ":", "\n", "            ", "return", "{", "k", ":", "[", "feature", "[", "k", "]", "for", "feature", "in", "features", "]", "for", "k", "in", "args", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline.__call__": [[415, 428], ["pipelines.Pipeline._args_parser", "pipelines.Pipeline.device_placement", "pipelines.Pipeline.tokenizer.batch_encode_plus", "pipelines.Pipeline.inputs_for_model", "pipelines.Pipeline._forward"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline.device_placement", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.batch_encode_plus", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline.inputs_for_model", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline._forward"], ["", "", "def", "__call__", "(", "self", ",", "*", "texts", ",", "**", "kwargs", ")", ":", "\n", "# Parse arguments", "\n", "        ", "inputs", "=", "self", ".", "_args_parser", "(", "*", "texts", ",", "**", "kwargs", ")", "\n", "\n", "# Encode for forward", "\n", "with", "self", ".", "device_placement", "(", ")", ":", "\n", "            ", "inputs", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "\n", "inputs", ",", "add_special_tokens", "=", "True", ",", "return_tensors", "=", "self", ".", "framework", ",", "max_length", "=", "self", ".", "tokenizer", ".", "max_len", "\n", ")", "\n", "\n", "# Filter out features not available on specific models", "\n", "inputs", "=", "self", ".", "inputs_for_model", "(", "inputs", ")", "\n", "return", "self", ".", "_forward", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline._forward": [[429, 445], ["[].cpu.numpy", "pipelines.Pipeline.model", "torch.no_grad", "[].cpu", "pipelines.Pipeline.model"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.model", "home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.model"], ["", "", "def", "_forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"\n        Internal framework specific forward dispatching.\n        Args:\n            inputs: dict holding all the keyworded arguments for required by the model forward method.\n        Returns:\n            Numpy array\n        \"\"\"", "\n", "if", "self", ".", "framework", "==", "\"tf\"", ":", "\n", "# TODO trace model", "\n", "            ", "predictions", "=", "self", ".", "model", "(", "inputs", ",", "training", "=", "False", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "predictions", "=", "self", ".", "model", "(", "**", "inputs", ")", "[", "0", "]", ".", "cpu", "(", ")", "\n", "\n", "", "", "return", "predictions", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.FeatureExtractionPipeline.__init__": [[452, 469], ["pipelines.Pipeline.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", "=", "None", ",", "\n", "modelcard", ":", "ModelCard", "=", "None", ",", "\n", "framework", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "args_parser", ":", "ArgumentHandler", "=", "None", ",", "\n", "device", ":", "int", "=", "-", "1", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "model", "=", "model", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "modelcard", "=", "modelcard", ",", "\n", "framework", "=", "framework", ",", "\n", "args_parser", "=", "args_parser", ",", "\n", "device", "=", "device", ",", "\n", "binary_output", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.FeatureExtractionPipeline.__call__": [[471, 473], ["super().__call__().tolist", "pipelines.Pipeline.__call__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator.__call__"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "__call__", "(", "*", "args", ",", "**", "kwargs", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.TextClassificationPipeline.__call__": [[480, 484], ["pipelines.Pipeline.__call__", "numpy.exp", "numpy.exp().sum", "item.max", "numpy.exp", "item.argmax"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator.__call__"], ["def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "super", "(", ")", ".", "__call__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "scores", "=", "np", ".", "exp", "(", "outputs", ")", "/", "np", ".", "exp", "(", "outputs", ")", ".", "sum", "(", "-", "1", ")", "\n", "return", "[", "{", "\"label\"", ":", "self", ".", "model", ".", "config", ".", "id2label", "[", "item", ".", "argmax", "(", ")", "]", ",", "\"score\"", ":", "item", ".", "max", "(", ")", "}", "for", "item", "in", "scores", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.NerPipeline.__init__": [[493, 516], ["pipelines.Pipeline.__init__", "tokenization_bert.BasicTokenizer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "tokenizer", ":", "PreTrainedTokenizer", "=", "None", ",", "\n", "modelcard", ":", "ModelCard", "=", "None", ",", "\n", "framework", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "args_parser", ":", "ArgumentHandler", "=", "None", ",", "\n", "device", ":", "int", "=", "-", "1", ",", "\n", "binary_output", ":", "bool", "=", "False", ",", "\n", "ignore_labels", "=", "[", "\"O\"", "]", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "model", "=", "model", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "modelcard", "=", "modelcard", ",", "\n", "framework", "=", "framework", ",", "\n", "args_parser", "=", "args_parser", ",", "\n", "device", "=", "device", ",", "\n", "binary_output", "=", "binary_output", ",", "\n", ")", "\n", "\n", "self", ".", "_basic_tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "False", ")", "\n", "self", ".", "ignore_labels", "=", "ignore_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.NerPipeline.__call__": [[517, 559], ["pipelines.NerPipeline._args_parser", "score.argmax", "enumerate", "len", "pipelines.NerPipeline.device_placement", "pipelines.NerPipeline.tokenizer.encode_plus", "numpy.exp", "numpy.exp().sum", "[].numpy", "tokens[].numpy", "torch.no_grad", "[].cpu().numpy", "numpy.exp", "tokens[].cpu().numpy", "pipelines.NerPipeline.tokenizer.decode", "[].item", "[].cpu", "pipelines.NerPipeline.model", "tokens[].cpu", "int", "pipelines.NerPipeline.model"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline.device_placement", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.model", "home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.model"], ["", "def", "__call__", "(", "self", ",", "*", "texts", ",", "**", "kwargs", ")", ":", "\n", "        ", "inputs", ",", "answers", "=", "self", ".", "_args_parser", "(", "*", "texts", ",", "**", "kwargs", ")", ",", "[", "]", "\n", "for", "sentence", "in", "inputs", ":", "\n", "\n", "# Manage correct placement of the tensors", "\n", "            ", "with", "self", ".", "device_placement", "(", ")", ":", "\n", "\n", "                ", "tokens", "=", "self", ".", "tokenizer", ".", "encode_plus", "(", "\n", "sentence", ",", "\n", "return_attention_mask", "=", "False", ",", "\n", "return_tensors", "=", "self", ".", "framework", ",", "\n", "max_length", "=", "self", ".", "tokenizer", ".", "max_len", ",", "\n", ")", "\n", "\n", "# Forward", "\n", "if", "self", ".", "framework", "==", "\"tf\"", ":", "\n", "                    ", "entities", "=", "self", ".", "model", "(", "tokens", ")", "[", "0", "]", "[", "0", "]", ".", "numpy", "(", ")", "\n", "input_ids", "=", "tokens", "[", "\"input_ids\"", "]", ".", "numpy", "(", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                    ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                        ", "entities", "=", "self", ".", "model", "(", "**", "tokens", ")", "[", "0", "]", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "input_ids", "=", "tokens", "[", "\"input_ids\"", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", "\n", "\n", "", "", "", "score", "=", "np", ".", "exp", "(", "entities", ")", "/", "np", ".", "exp", "(", "entities", ")", ".", "sum", "(", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "labels_idx", "=", "score", ".", "argmax", "(", "axis", "=", "-", "1", ")", "\n", "\n", "answer", "=", "[", "]", "\n", "for", "idx", ",", "label_idx", "in", "enumerate", "(", "labels_idx", ")", ":", "\n", "                ", "if", "self", ".", "model", ".", "config", ".", "id2label", "[", "label_idx", "]", "not", "in", "self", ".", "ignore_labels", ":", "\n", "                    ", "answer", "+=", "[", "\n", "{", "\n", "\"word\"", ":", "self", ".", "tokenizer", ".", "decode", "(", "[", "int", "(", "input_ids", "[", "idx", "]", ")", "]", ")", ",", "\n", "\"score\"", ":", "score", "[", "idx", "]", "[", "label_idx", "]", ".", "item", "(", ")", ",", "\n", "\"entity\"", ":", "self", ".", "model", ".", "config", ".", "id2label", "[", "label_idx", "]", ",", "\n", "}", "\n", "]", "\n", "\n", "# Append", "\n", "", "", "answers", "+=", "[", "answer", "]", "\n", "", "if", "len", "(", "answers", ")", "==", "1", ":", "\n", "            ", "return", "answers", "[", "0", "]", "\n", "", "return", "answers", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.QuestionAnsweringArgumentHandler.__call__": [[570, 621], ["isinstance", "enumerate", "isinstance", "len", "len", "list", "isinstance", "isinstance", "isinstance", "ValueError", "any", "pipelines.QuestionAnsweringPipeline.create_sample", "pipelines.QuestionAnsweringPipeline.create_sample", "KeyError", "isinstance", "ValueError", "zip"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.QuestionAnsweringPipeline.create_sample", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.QuestionAnsweringPipeline.create_sample"], ["def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# Position args, handling is sensibly the same as X and data, so forwarding to avoid duplicating", "\n", "        ", "if", "args", "is", "not", "None", "and", "len", "(", "args", ")", ">", "0", ":", "\n", "            ", "if", "len", "(", "args", ")", "==", "1", ":", "\n", "                ", "kwargs", "[", "\"X\"", "]", "=", "args", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "kwargs", "[", "\"X\"", "]", "=", "list", "(", "args", ")", "\n", "\n", "# Generic compatibility with sklearn and Keras", "\n", "# Batched data", "\n", "", "", "if", "\"X\"", "in", "kwargs", "or", "\"data\"", "in", "kwargs", ":", "\n", "            ", "inputs", "=", "kwargs", "[", "\"X\"", "]", "if", "\"X\"", "in", "kwargs", "else", "kwargs", "[", "\"data\"", "]", "\n", "\n", "if", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "                ", "inputs", "=", "[", "inputs", "]", "\n", "", "else", ":", "\n", "# Copy to avoid overriding arguments", "\n", "                ", "inputs", "=", "[", "i", "for", "i", "in", "inputs", "]", "\n", "\n", "", "for", "i", ",", "item", "in", "enumerate", "(", "inputs", ")", ":", "\n", "                ", "if", "isinstance", "(", "item", ",", "dict", ")", ":", "\n", "                    ", "if", "any", "(", "k", "not", "in", "item", "for", "k", "in", "[", "\"question\"", ",", "\"context\"", "]", ")", ":", "\n", "                        ", "raise", "KeyError", "(", "\"You need to provide a dictionary with keys {question:..., context:...}\"", ")", "\n", "\n", "", "inputs", "[", "i", "]", "=", "QuestionAnsweringPipeline", ".", "create_sample", "(", "**", "item", ")", "\n", "\n", "", "elif", "not", "isinstance", "(", "item", ",", "SquadExample", ")", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"{} argument needs to be of type (list[SquadExample | dict], SquadExample, dict)\"", ".", "format", "(", "\n", "\"X\"", "if", "\"X\"", "in", "kwargs", "else", "\"data\"", "\n", ")", "\n", ")", "\n", "\n", "# Tabular input", "\n", "", "", "", "elif", "\"question\"", "in", "kwargs", "and", "\"context\"", "in", "kwargs", ":", "\n", "            ", "if", "isinstance", "(", "kwargs", "[", "\"question\"", "]", ",", "str", ")", ":", "\n", "                ", "kwargs", "[", "\"question\"", "]", "=", "[", "kwargs", "[", "\"question\"", "]", "]", "\n", "\n", "", "if", "isinstance", "(", "kwargs", "[", "\"context\"", "]", ",", "str", ")", ":", "\n", "                ", "kwargs", "[", "\"context\"", "]", "=", "[", "kwargs", "[", "\"context\"", "]", "]", "\n", "\n", "", "inputs", "=", "[", "\n", "QuestionAnsweringPipeline", ".", "create_sample", "(", "q", ",", "c", ")", "for", "q", ",", "c", "in", "zip", "(", "kwargs", "[", "\"question\"", "]", ",", "kwargs", "[", "\"context\"", "]", ")", "\n", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown arguments {}\"", ".", "format", "(", "kwargs", ")", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "inputs", ",", "list", ")", ":", "\n", "            ", "inputs", "=", "[", "inputs", "]", "\n", "\n", "", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.QuestionAnsweringPipeline.__init__": [[630, 647], ["pipelines.Pipeline.__init__", "pipelines.QuestionAnsweringArgumentHandler"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "tokenizer", ":", "Optional", "[", "PreTrainedTokenizer", "]", ",", "\n", "modelcard", ":", "Optional", "[", "ModelCard", "]", ",", "\n", "framework", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "device", ":", "int", "=", "-", "1", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "model", "=", "model", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "modelcard", "=", "modelcard", ",", "\n", "framework", "=", "framework", ",", "\n", "args_parser", "=", "QuestionAnsweringArgumentHandler", "(", ")", ",", "\n", "device", "=", "device", ",", "\n", "**", "kwargs", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.QuestionAnsweringPipeline.create_sample": [[649, 668], ["isinstance", "data.SquadExample", "data.SquadExample", "zip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_sample", "(", "\n", "question", ":", "Union", "[", "str", ",", "List", "[", "str", "]", "]", ",", "context", ":", "Union", "[", "str", ",", "List", "[", "str", "]", "]", "\n", ")", "->", "Union", "[", "SquadExample", ",", "List", "[", "SquadExample", "]", "]", ":", "\n", "        ", "\"\"\"\n        QuestionAnsweringPipeline leverages the SquadExample/SquadFeatures internally.\n        This helper method encapsulate all the logic for converting question(s) and context(s) to SquadExample(s).\n        We currently support extractive question answering.\n        Arguments:\n             question: (str, List[str]) The question to be ask for the associated context\n             context: (str, List[str]) The context in which we will look for the answer.\n\n        Returns:\n            SquadExample initialized with the corresponding question and context.\n        \"\"\"", "\n", "if", "isinstance", "(", "question", ",", "list", ")", ":", "\n", "            ", "return", "[", "SquadExample", "(", "None", ",", "q", ",", "c", ",", "None", ",", "None", ",", "None", ")", "for", "q", ",", "c", "in", "zip", "(", "question", ",", "context", ")", "]", "\n", "", "else", ":", "\n", "            ", "return", "SquadExample", "(", "None", ",", "question", ",", "context", ",", "None", ",", "None", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.QuestionAnsweringPipeline.__call__": [[669, 748], ["kwargs.setdefault", "kwargs.setdefault", "kwargs.setdefault", "kwargs.setdefault", "kwargs.setdefault", "pipelines.QuestionAnsweringPipeline._args_parser", "data.squad_convert_examples_to_features", "pipelines.QuestionAnsweringPipeline.inputs_for_model", "zip", "ValueError", "ValueError", "pipelines.QuestionAnsweringPipeline.device_placement", "pipelines.QuestionAnsweringPipeline.decode", "numpy.array", "len", "pipelines.QuestionAnsweringPipeline.model", "numpy.exp", "numpy.sum", "numpy.exp", "numpy.sum", "tf.constant", "start.numpy", "end.numpy", "torch.no_grad", "pipelines.QuestionAnsweringPipeline.model", "numpy.exp", "numpy.exp", "numpy.abs", "numpy.abs", "score.item", "[].item", "[].item", "zip", "pipelines.QuestionAnsweringPipeline.items", "torch.tensor", "start.cpu().numpy", "end.cpu().numpy", "pipelines.QuestionAnsweringPipeline.items", "numpy.array", "numpy.array", "start.cpu", "end.cpu", "numpy.where", "numpy.where"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.squad_convert_examples_to_features", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline.inputs_for_model", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline.device_placement", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.model", "home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.model"], ["", "", "def", "__call__", "(", "self", ",", "*", "texts", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            We support multiple use-cases, the following are exclusive:\n            X: sequence of SquadExample\n            data: sequence of SquadExample\n            question: (str, List[str]), batch of question(s) to map along with context\n            context: (str, List[str]), batch of context(s) associated with the provided question keyword argument\n        Returns:\n            dict: {'answer': str, 'score\": float, 'start\": int, \"end\": int}\n            answer: the textual answer in the intial context\n            score: the score the current answer scored for the model\n            start: the character index in the original string corresponding to the beginning of the answer' span\n            end: the character index in the original string corresponding to the ending of the answer' span\n        \"\"\"", "\n", "# Set defaults values", "\n", "kwargs", ".", "setdefault", "(", "\"topk\"", ",", "1", ")", "\n", "kwargs", ".", "setdefault", "(", "\"doc_stride\"", ",", "128", ")", "\n", "kwargs", ".", "setdefault", "(", "\"max_answer_len\"", ",", "15", ")", "\n", "kwargs", ".", "setdefault", "(", "\"max_seq_len\"", ",", "384", ")", "\n", "kwargs", ".", "setdefault", "(", "\"max_question_len\"", ",", "64", ")", "\n", "\n", "if", "kwargs", "[", "\"topk\"", "]", "<", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"topk parameter should be >= 1 (got {})\"", ".", "format", "(", "kwargs", "[", "\"topk\"", "]", ")", ")", "\n", "\n", "", "if", "kwargs", "[", "\"max_answer_len\"", "]", "<", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"max_answer_len parameter should be >= 1 (got {})\"", ".", "format", "(", "kwargs", "[", "\"max_answer_len\"", "]", ")", ")", "\n", "\n", "# Convert inputs to features", "\n", "", "examples", "=", "self", ".", "_args_parser", "(", "*", "texts", ",", "**", "kwargs", ")", "\n", "features", "=", "squad_convert_examples_to_features", "(", "\n", "examples", ",", "self", ".", "tokenizer", ",", "kwargs", "[", "\"max_seq_len\"", "]", ",", "kwargs", "[", "\"doc_stride\"", "]", ",", "kwargs", "[", "\"max_question_len\"", "]", ",", "False", "\n", ")", "\n", "fw_args", "=", "self", ".", "inputs_for_model", "(", "[", "f", ".", "__dict__", "for", "f", "in", "features", "]", ")", "\n", "\n", "# Manage tensor allocation on correct device", "\n", "with", "self", ".", "device_placement", "(", ")", ":", "\n", "            ", "if", "self", ".", "framework", "==", "\"tf\"", ":", "\n", "                ", "fw_args", "=", "{", "k", ":", "tf", ".", "constant", "(", "v", ")", "for", "(", "k", ",", "v", ")", "in", "fw_args", ".", "items", "(", ")", "}", "\n", "start", ",", "end", "=", "self", ".", "model", "(", "fw_args", ")", "\n", "start", ",", "end", "=", "start", ".", "numpy", "(", ")", ",", "end", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Retrieve the score for the context tokens only (removing question tokens)", "\n", "                    ", "fw_args", "=", "{", "k", ":", "torch", ".", "tensor", "(", "v", ")", "for", "(", "k", ",", "v", ")", "in", "fw_args", ".", "items", "(", ")", "}", "\n", "start", ",", "end", "=", "self", ".", "model", "(", "**", "fw_args", ")", "\n", "start", ",", "end", "=", "start", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "end", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "", "", "answers", "=", "[", "]", "\n", "for", "(", "example", ",", "feature", ",", "start_", ",", "end_", ")", "in", "zip", "(", "examples", ",", "features", ",", "start", ",", "end", ")", ":", "\n", "# Normalize logits and spans to retrieve the answer", "\n", "            ", "start_", "=", "np", ".", "exp", "(", "start_", ")", "/", "np", ".", "sum", "(", "np", ".", "exp", "(", "start_", ")", ")", "\n", "end_", "=", "np", ".", "exp", "(", "end_", ")", "/", "np", ".", "sum", "(", "np", ".", "exp", "(", "end_", ")", ")", "\n", "\n", "# Mask padding and question", "\n", "start_", ",", "end_", "=", "start_", "*", "np", ".", "abs", "(", "np", ".", "array", "(", "feature", ".", "p_mask", ")", "-", "1", ")", ",", "end_", "*", "np", ".", "abs", "(", "np", ".", "array", "(", "feature", ".", "p_mask", ")", "-", "1", ")", "\n", "\n", "# TODO : What happens if not possible", "\n", "# Mask CLS", "\n", "start_", "[", "0", "]", "=", "end_", "[", "0", "]", "=", "0", "\n", "\n", "starts", ",", "ends", ",", "scores", "=", "self", ".", "decode", "(", "start_", ",", "end_", ",", "kwargs", "[", "\"topk\"", "]", ",", "kwargs", "[", "\"max_answer_len\"", "]", ")", "\n", "char_to_word", "=", "np", ".", "array", "(", "example", ".", "char_to_word_offset", ")", "\n", "\n", "# Convert the answer (tokens) back to the original text", "\n", "answers", "+=", "[", "\n", "{", "\n", "\"score\"", ":", "score", ".", "item", "(", ")", ",", "\n", "\"start\"", ":", "np", ".", "where", "(", "char_to_word", "==", "feature", ".", "token_to_orig_map", "[", "s", "]", ")", "[", "0", "]", "[", "0", "]", ".", "item", "(", ")", ",", "\n", "\"end\"", ":", "np", ".", "where", "(", "char_to_word", "==", "feature", ".", "token_to_orig_map", "[", "e", "]", ")", "[", "0", "]", "[", "-", "1", "]", ".", "item", "(", ")", ",", "\n", "\"answer\"", ":", "\" \"", ".", "join", "(", "\n", "example", ".", "doc_tokens", "[", "feature", ".", "token_to_orig_map", "[", "s", "]", ":", "feature", ".", "token_to_orig_map", "[", "e", "]", "+", "1", "]", "\n", ")", ",", "\n", "}", "\n", "for", "s", ",", "e", ",", "score", "in", "zip", "(", "starts", ",", "ends", ",", "scores", ")", "\n", "]", "\n", "", "if", "len", "(", "answers", ")", "==", "1", ":", "\n", "            ", "return", "answers", "[", "0", "]", "\n", "", "return", "answers", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.QuestionAnsweringPipeline.decode": [[749, 788], ["numpy.matmul", "numpy.tril", "numpy.tril.flatten", "numpy.expand_dims", "numpy.expand_dims", "numpy.triu", "numpy.unravel_index", "numpy.argmax", "len", "numpy.argsort", "numpy.argpartition", "numpy.argsort"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "start", ":", "np", ".", "ndarray", ",", "end", ":", "np", ".", "ndarray", ",", "topk", ":", "int", ",", "max_answer_len", ":", "int", ")", "->", "Tuple", ":", "\n", "        ", "\"\"\"\n        Take the output of any QuestionAnswering head and will generate probalities for each span to be\n        the actual answer.\n        In addition, it filters out some unwanted/impossible cases like answer len being greater than\n        max_answer_len or answer end position being before the starting position.\n        The method supports output the k-best answer through the topk argument.\n\n        Args:\n            start: numpy array, holding individual start probabilities for each token\n            end: numpy array, holding individual end probabilities for each token\n            topk: int, indicates how many possible answer span(s) to extract from the model's output\n            max_answer_len: int, maximum size of the answer to extract from the model's output\n        \"\"\"", "\n", "# Ensure we have batch axis", "\n", "if", "start", ".", "ndim", "==", "1", ":", "\n", "            ", "start", "=", "start", "[", "None", "]", "\n", "\n", "", "if", "end", ".", "ndim", "==", "1", ":", "\n", "            ", "end", "=", "end", "[", "None", "]", "\n", "\n", "# Compute the score of each tuple(start, end) to be the real answer", "\n", "", "outer", "=", "np", ".", "matmul", "(", "np", ".", "expand_dims", "(", "start", ",", "-", "1", ")", ",", "np", ".", "expand_dims", "(", "end", ",", "1", ")", ")", "\n", "\n", "# Remove candidate with end < start and end - start > max_answer_len", "\n", "candidates", "=", "np", ".", "tril", "(", "np", ".", "triu", "(", "outer", ")", ",", "max_answer_len", "-", "1", ")", "\n", "\n", "#  Inspired by Chen & al. (https://github.com/facebookresearch/DrQA)", "\n", "scores_flat", "=", "candidates", ".", "flatten", "(", ")", "\n", "if", "topk", "==", "1", ":", "\n", "            ", "idx_sort", "=", "[", "np", ".", "argmax", "(", "scores_flat", ")", "]", "\n", "", "elif", "len", "(", "scores_flat", ")", "<", "topk", ":", "\n", "            ", "idx_sort", "=", "np", ".", "argsort", "(", "-", "scores_flat", ")", "\n", "", "else", ":", "\n", "            ", "idx", "=", "np", ".", "argpartition", "(", "-", "scores_flat", ",", "topk", ")", "[", "0", ":", "topk", "]", "\n", "idx_sort", "=", "idx", "[", "np", ".", "argsort", "(", "-", "scores_flat", "[", "idx", "]", ")", "]", "\n", "\n", "", "start", ",", "end", "=", "np", ".", "unravel_index", "(", "idx_sort", ",", "candidates", ".", "shape", ")", "[", "1", ":", "]", "\n", "return", "start", ",", "end", ",", "candidates", "[", "0", ",", "start", ",", "end", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.QuestionAnsweringPipeline.span_to_answer": [[789, 828], ["enumerate", "text.split", "pipelines.QuestionAnsweringPipeline.tokenizer.tokenize", "len", "max", "min", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "span_to_answer", "(", "self", ",", "text", ":", "str", ",", "start", ":", "int", ",", "end", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        When decoding from token probalities, this method maps token indexes to actual word in\n        the initial context.\n\n        Args:\n            text: str, the actual context to extract the answer from\n            start: int, starting answer token index\n            end: int, ending answer token index\n\n        Returns:\n            dict: {'answer': str, 'start': int, 'end': int}\n        \"\"\"", "\n", "words", "=", "[", "]", "\n", "token_idx", "=", "char_start_idx", "=", "char_end_idx", "=", "chars_idx", "=", "0", "\n", "\n", "for", "i", ",", "word", "in", "enumerate", "(", "text", ".", "split", "(", "\" \"", ")", ")", ":", "\n", "            ", "token", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "\n", "# Append words if they are in the span", "\n", "if", "start", "<=", "token_idx", "<=", "end", ":", "\n", "                ", "if", "token_idx", "==", "start", ":", "\n", "                    ", "char_start_idx", "=", "chars_idx", "\n", "\n", "", "if", "token_idx", "==", "end", ":", "\n", "                    ", "char_end_idx", "=", "chars_idx", "+", "len", "(", "word", ")", "\n", "\n", "", "words", "+=", "[", "word", "]", "\n", "\n", "# Stop if we went over the end of the answer", "\n", "", "if", "token_idx", ">", "end", ":", "\n", "                ", "break", "\n", "\n", "# Append the subtokenization length to the running index", "\n", "", "token_idx", "+=", "len", "(", "token", ")", "\n", "chars_idx", "+=", "len", "(", "word", ")", "+", "1", "\n", "\n", "# Join text with spaces", "\n", "", "return", "{", "\"answer\"", ":", "\" \"", ".", "join", "(", "words", ")", ",", "\"start\"", ":", "max", "(", "0", ",", "char_start_idx", ")", ",", "\"end\"", ":", "min", "(", "len", "(", "text", ")", ",", "char_end_idx", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.get_framework": [[62, 80], ["file_utils.is_tf_available", "file_utils.is_torch_available", "isinstance", "model.__class__.__name__.startswith", "RuntimeError", "file_utils.is_tf_available", "file_utils.is_torch_available", "file_utils.is_torch_available"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_tf_available", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_torch_available", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_tf_available", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_torch_available", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_torch_available"], ["def", "get_framework", "(", "model", "=", "None", ")", ":", "\n", "    ", "\"\"\" Select framework (TensorFlow/PyTorch) to use.\n        If both frameworks are installed and no specific model is provided, defaults to using PyTorch.\n    \"\"\"", "\n", "if", "is_tf_available", "(", ")", "and", "is_torch_available", "(", ")", "and", "model", "is", "not", "None", "and", "not", "isinstance", "(", "model", ",", "str", ")", ":", "\n", "# Both framework are available but the use supplied a model class instance.", "\n", "# Try to guess which framework to use from the model classname", "\n", "        ", "framework", "=", "\"tf\"", "if", "model", ".", "__class__", ".", "__name__", ".", "startswith", "(", "\"TF\"", ")", "else", "\"pt\"", "\n", "", "elif", "not", "is_tf_available", "(", ")", "and", "not", "is_torch_available", "(", ")", ":", "\n", "        ", "raise", "RuntimeError", "(", "\n", "\"At least one of TensorFlow 2.0 or PyTorch should be installed. \"", "\n", "\"To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ \"", "\n", "\"To install PyTorch, read the instructions at https://pytorch.org/.\"", "\n", ")", "\n", "", "else", ":", "\n", "# framework = 'tf' if is_tf_available() else 'pt'", "\n", "        ", "framework", "=", "\"pt\"", "if", "is_torch_available", "(", ")", "else", "\"tf\"", "\n", "", "return", "framework", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.pipeline": [[884, 971], ["pipelines.get_framework", "isinstance", "isinstance", "isinstance", "isinstance", "task", "KeyError", "tuple", "isinstance", "tokenization_auto.AutoTokenizer.from_pretrained", "configuration_auto.AutoConfig.from_pretrained", "modelcard.ModelCard.from_pretrained", "model_class.from_pretrained", "targeted_task[].values", "isinstance", "isinstance", "model_class.from_pretrained.endswith", "logger.warning", "list", "isinstance", "Exception", "model_class.from_pretrained.endswith", "logger.warning", "SUPPORTED_TASKS.keys"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.get_framework", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["def", "pipeline", "(", "\n", "task", ":", "str", ",", "\n", "model", ":", "Optional", "=", "None", ",", "\n", "config", ":", "Optional", "[", "Union", "[", "str", ",", "PretrainedConfig", "]", "]", "=", "None", ",", "\n", "tokenizer", ":", "Optional", "[", "Union", "[", "str", ",", "PreTrainedTokenizer", "]", "]", "=", "None", ",", "\n", "modelcard", ":", "Optional", "[", "Union", "[", "str", ",", "ModelCard", "]", "]", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", "->", "Pipeline", ":", "\n", "    ", "\"\"\"\n    Utility factory method to build a pipeline.\n    Pipeline are made of:\n        A Tokenizer instance in charge of mapping raw textual input to token\n        A Model instance\n        Some (optional) post processing for enhancing model's output\n\n    Examples:\n        pipeline('sentiment-analysis')\n        pipeline('question-answering', model='distilbert-base-uncased-distilled-squad', tokenizer='bert-base-cased')\n        pipeline('ner', model=AutoModel.from_pretrained(...), tokenizer=AutoTokenizer.from_pretrained(...)\n        pipeline('ner', model='https://...pytorch-model.bin', config='https://...config.json', tokenizer='bert-base-cased')\n    \"\"\"", "\n", "# Retrieve the task", "\n", "if", "task", "not", "in", "SUPPORTED_TASKS", ":", "\n", "        ", "raise", "KeyError", "(", "\"Unknown task {}, available tasks are {}\"", ".", "format", "(", "task", ",", "list", "(", "SUPPORTED_TASKS", ".", "keys", "(", ")", ")", ")", ")", "\n", "\n", "", "framework", "=", "get_framework", "(", "model", ")", "\n", "\n", "targeted_task", "=", "SUPPORTED_TASKS", "[", "task", "]", "\n", "task", ",", "model_class", "=", "targeted_task", "[", "\"impl\"", "]", ",", "targeted_task", "[", "framework", "]", "\n", "\n", "# Use default model/config/tokenizer for the task if no model is provided", "\n", "if", "model", "is", "None", ":", "\n", "        ", "models", ",", "config", ",", "tokenizer", "=", "tuple", "(", "targeted_task", "[", "\"default\"", "]", ".", "values", "(", ")", ")", "\n", "model", "=", "models", "[", "framework", "]", "\n", "\n", "# Try to infer tokenizer from model or config name (if provided as str)", "\n", "", "if", "tokenizer", "is", "None", ":", "\n", "        ", "if", "isinstance", "(", "model", ",", "str", ")", "and", "model", "in", "ALL_PRETRAINED_CONFIG_ARCHIVE_MAP", ":", "\n", "            ", "tokenizer", "=", "model", "\n", "", "elif", "isinstance", "(", "config", ",", "str", ")", "and", "config", "in", "ALL_PRETRAINED_CONFIG_ARCHIVE_MAP", ":", "\n", "            ", "tokenizer", "=", "config", "\n", "", "else", ":", "\n", "# Impossible to guest what is the right tokenizer here", "\n", "            ", "raise", "Exception", "(", "\n", "\"Impossible to guess which tokenizer to use. \"", "\n", "\"Please provided a PretrainedTokenizer class or a path/url/shortcut name to a pretrained tokenizer.\"", "\n", ")", "\n", "\n", "# Try to infer modelcard from model or config name (if provided as str)", "\n", "", "", "if", "modelcard", "is", "None", ":", "\n", "# Try to fallback on one of the provided string for model or config (will replace the suffix)", "\n", "        ", "if", "isinstance", "(", "model", ",", "str", ")", ":", "\n", "            ", "modelcard", "=", "model", "\n", "", "elif", "isinstance", "(", "config", ",", "str", ")", ":", "\n", "            ", "modelcard", "=", "config", "\n", "\n", "# Instantiate tokenizer if needed", "\n", "", "", "if", "isinstance", "(", "tokenizer", ",", "str", ")", ":", "\n", "        ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "tokenizer", ")", "\n", "\n", "# Instantiate config if needed", "\n", "", "if", "isinstance", "(", "config", ",", "str", ")", ":", "\n", "        ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "config", ")", "\n", "\n", "# Instantiate modelcard if needed", "\n", "", "if", "isinstance", "(", "modelcard", ",", "str", ")", ":", "\n", "        ", "modelcard", "=", "ModelCard", ".", "from_pretrained", "(", "modelcard", ")", "\n", "\n", "# Instantiate model if needed", "\n", "", "if", "isinstance", "(", "model", ",", "str", ")", ":", "\n", "# Handle transparent TF/PT model conversion", "\n", "        ", "model_kwargs", "=", "{", "}", "\n", "if", "framework", "==", "\"pt\"", "and", "model", ".", "endswith", "(", "\".h5\"", ")", ":", "\n", "            ", "model_kwargs", "[", "\"from_tf\"", "]", "=", "True", "\n", "logger", ".", "warning", "(", "\n", "\"Model might be a TensorFlow model (ending with `.h5`) but TensorFlow is not available. \"", "\n", "\"Trying to load the model with PyTorch.\"", "\n", ")", "\n", "", "elif", "framework", "==", "\"tf\"", "and", "model", ".", "endswith", "(", "\".bin\"", ")", ":", "\n", "            ", "model_kwargs", "[", "\"from_pt\"", "]", "=", "True", "\n", "logger", ".", "warning", "(", "\n", "\"Model might be a PyTorch model (ending with `.bin`) but PyTorch is not available. \"", "\n", "\"Trying to load the model with Tensorflow.\"", "\n", ")", "\n", "", "model", "=", "model_class", ".", "from_pretrained", "(", "model", ",", "config", "=", "config", ",", "**", "model_kwargs", ")", "\n", "\n", "", "return", "task", "(", "model", "=", "model", ",", "tokenizer", "=", "tokenizer", ",", "modelcard", "=", "modelcard", ",", "framework", "=", "framework", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFAttention.__init__": [[68, 85], ["super().__init__", "modeling_tf_utils.TFConv1D", "modeling_tf_utils.TFConv1D", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "set"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "c_attn", "=", "TFConv1D", "(", "n_state", "*", "3", ",", "nx", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"c_attn\"", ")", "\n", "self", ".", "c_proj", "=", "TFConv1D", "(", "n_state", ",", "nx", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"c_proj\"", ")", "\n", "self", ".", "attn_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFAttention.prune_heads": [[86, 88], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFAttention.causal_attention_mask": [[89, 98], ["tensorflow.range", "tensorflow.cast", "tensorflow.range"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "causal_attention_mask", "(", "nd", ",", "ns", ",", "dtype", ")", ":", "\n", "        ", "\"\"\"1's in the lower triangle, counting from the lower right corner.\n        Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n        \"\"\"", "\n", "i", "=", "tf", ".", "range", "(", "nd", ")", "[", ":", ",", "None", "]", "\n", "j", "=", "tf", ".", "range", "(", "ns", ")", "\n", "m", "=", "i", ">=", "j", "-", "ns", "+", "nd", "\n", "return", "tf", ".", "cast", "(", "m", ",", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFAttention._attn": [[99, 128], ["tensorflow.matmul", "modeling_tf_utils.shape_list", "modeling_tf_openai.TFAttention.causal_attention_mask", "tensorflow.reshape", "tensorflow.nn.softmax", "modeling_tf_openai.TFAttention.attn_dropout", "tensorflow.cast", "tensorflow.matmul", "outputs.append", "tensorflow.math.sqrt", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFAttention.causal_attention_mask", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "_attn", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "q", ",", "k", ",", "v", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "# q, k, v have shape [batch, heads, sequence, features]", "\n", "w", "=", "tf", ".", "matmul", "(", "q", ",", "k", ",", "transpose_b", "=", "True", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "dk", "=", "tf", ".", "cast", "(", "shape_list", "(", "k", ")", "[", "-", "1", "]", ",", "tf", ".", "float32", ")", "# scale attention_scores", "\n", "w", "=", "w", "/", "tf", ".", "math", ".", "sqrt", "(", "dk", ")", "\n", "\n", "# w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.", "\n", "", "_", ",", "_", ",", "nd", ",", "ns", "=", "shape_list", "(", "w", ")", "\n", "b", "=", "self", ".", "causal_attention_mask", "(", "nd", ",", "ns", ",", "dtype", "=", "w", ".", "dtype", ")", "\n", "b", "=", "tf", ".", "reshape", "(", "b", ",", "[", "1", ",", "1", ",", "nd", ",", "ns", "]", ")", "\n", "w", "=", "w", "*", "b", "-", "1e4", "*", "(", "1", "-", "b", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "            ", "w", "=", "w", "+", "attention_mask", "\n", "\n", "", "w", "=", "tf", ".", "nn", ".", "softmax", "(", "w", ",", "axis", "=", "-", "1", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ",", "training", "=", "training", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "w", "=", "w", "*", "head_mask", "\n", "\n", "", "outputs", "=", "[", "tf", ".", "matmul", "(", "w", ",", "v", ")", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "w", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFAttention.merge_heads": [[129, 134], ["tensorflow.transpose", "modeling_tf_utils.shape_list", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "tf", ".", "transpose", "(", "x", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "x_shape", "=", "shape_list", "(", "x", ")", "\n", "new_x_shape", "=", "x_shape", "[", ":", "-", "2", "]", "+", "[", "x_shape", "[", "-", "2", "]", "*", "x_shape", "[", "-", "1", "]", "]", "\n", "return", "tf", ".", "reshape", "(", "x", ",", "new_x_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFAttention.split_heads": [[135, 140], ["modeling_tf_utils.shape_list", "tensorflow.reshape", "tensorflow.transpose"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "split_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_shape", "=", "shape_list", "(", "x", ")", "\n", "new_x_shape", "=", "x_shape", "[", ":", "-", "1", "]", "+", "[", "self", ".", "n_head", ",", "x_shape", "[", "-", "1", "]", "//", "self", ".", "n_head", "]", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "new_x_shape", ")", "\n", "return", "tf", ".", "transpose", "(", "x", ",", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "# (batch, head, seq_length, head_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFAttention.call": [[141, 159], ["modeling_tf_openai.TFAttention.c_attn", "tensorflow.split", "modeling_tf_openai.TFAttention.split_heads", "modeling_tf_openai.TFAttention.split_heads", "modeling_tf_openai.TFAttention.split_heads", "modeling_tf_openai.TFAttention._attn", "modeling_tf_openai.TFAttention.merge_heads", "modeling_tf_openai.TFAttention.c_proj", "modeling_tf_openai.TFAttention.resid_dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention._attn", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.merge_heads"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "tf", ".", "split", "(", "x", ",", "3", ",", "axis", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "\n", "attn_outputs", "=", "self", ".", "_attn", "(", "[", "query", ",", "key", ",", "value", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ",", "training", "=", "training", ")", "\n", "\n", "outputs", "=", "[", "a", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "# a, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFMLP.__init__": [[162, 169], ["super().__init__", "modeling_tf_utils.TFConv1D", "modeling_tf_utils.TFConv1D", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFMLP", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "TFConv1D", "(", "n_state", ",", "nx", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"c_fc\"", ")", "\n", "self", ".", "c_proj", "=", "TFConv1D", "(", "nx", ",", "n_state", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"c_proj\"", ")", "\n", "self", ".", "act", "=", "gelu", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFMLP.call": [[170, 175], ["modeling_tf_openai.TFMLP.act", "modeling_tf_openai.TFMLP.c_proj", "modeling_tf_openai.TFMLP.dropout", "modeling_tf_openai.TFMLP.c_fc"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "x", ",", "training", "=", "False", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "h2", "=", "self", ".", "dropout", "(", "h2", ",", "training", "=", "training", ")", "\n", "return", "h2", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFBlock.__init__": [[178, 185], ["super().__init__", "modeling_tf_openai.TFAttention", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_openai.TFMLP", "tensorflow.keras.layers.LayerNormalization"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBlock", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "attn", "=", "TFAttention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ",", "name", "=", "\"attn\"", ")", "\n", "self", ".", "ln_1", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "\"ln_1\"", ")", "\n", "self", ".", "mlp", "=", "TFMLP", "(", "4", "*", "nx", ",", "config", ",", "name", "=", "\"mlp\"", ")", "\n", "self", ".", "ln_2", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "\"ln_2\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFBlock.call": [[186, 198], ["modeling_tf_openai.TFBlock.attn", "modeling_tf_openai.TFBlock.ln_1", "modeling_tf_openai.TFBlock.mlp", "modeling_tf_openai.TFBlock.ln_2"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "output_attn", "=", "self", ".", "attn", "(", "[", "x", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "a", "=", "output_attn", "[", "0", "]", "# output_attn: a, (attentions)", "\n", "\n", "n", "=", "self", ".", "ln_1", "(", "x", "+", "a", ")", "\n", "m", "=", "self", ".", "mlp", "(", "n", ",", "training", "=", "training", ")", "\n", "h", "=", "self", ".", "ln_2", "(", "n", "+", "m", ")", "\n", "\n", "outputs", "=", "[", "h", "]", "+", "output_attn", "[", "1", ":", "]", "\n", "return", "outputs", "# x, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFOpenAIGPTMainLayer.__init__": [[201, 220], ["super().__init__", "modeling_tf_utils.TFSharedEmbeddings", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.Dropout", "modeling_tf_openai.TFBlock", "modeling_tf_utils.get_initializer", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFOpenAIGPTMainLayer", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "num_hidden_layers", "=", "config", ".", "n_layer", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "self", ".", "n_embd", "=", "config", ".", "n_embd", "\n", "\n", "self", ".", "tokens_embed", "=", "TFSharedEmbeddings", "(", "\n", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"tokens_embed\"", "\n", ")", "\n", "self", ".", "positions_embed", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "\n", "config", ".", "n_positions", ",", "\n", "config", ".", "n_embd", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"positions_embed\"", ",", "\n", ")", "\n", "self", ".", "drop", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "[", "TFBlock", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ",", "name", "=", "\"h_._{}\"", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFOpenAIGPTMainLayer.get_input_embeddings": [[221, 223], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tokens_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFOpenAIGPTMainLayer._resize_token_embeddings": [[224, 226], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFOpenAIGPTMainLayer._prune_heads": [[227, 232], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFOpenAIGPTMainLayer.call": [[233, 345], ["isinstance", "tensorflow.reshape", "modeling_tf_openai.TFOpenAIGPTMainLayer.positions_embed", "modeling_tf_openai.TFOpenAIGPTMainLayer.drop", "enumerate", "tensorflow.reshape", "isinstance", "ValueError", "tensorflow.cast", "modeling_tf_openai.TFOpenAIGPTMainLayer.tokens_embed", "tensorflow.reshape", "modeling_tf_openai.TFOpenAIGPTMainLayer.tokens_embed", "block", "tuple", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "modeling_tf_utils.shape_list", "tensorflow.reshape", "tensorflow.range", "tuple.append", "len", "len", "len", "len", "len", "len", "ValueError", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "tensorflow.reshape", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "\n", "self", ",", "\n", "inputs", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "training", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "head_mask", "\n", "inputs_embeds", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "inputs_embeds", "\n", "assert", "len", "(", "inputs", ")", "<=", "6", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "\"input_ids\"", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "\"attention_mask\"", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "\"token_type_ids\"", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "\"position_ids\"", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "\"head_mask\"", ",", "head_mask", ")", "\n", "inputs_embeds", "=", "inputs", ".", "get", "(", "\"inputs_embeds\"", ",", "inputs_embeds", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "6", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "input_ids", ")", "\n", "input_ids", "=", "tf", ".", "reshape", "(", "input_ids", ",", "[", "-", "1", ",", "input_shape", "[", "-", "1", "]", "]", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "inputs_embeds", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "tf", ".", "range", "(", "input_shape", "[", "-", "1", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "            ", "attention_mask", "=", "attention_mask", "[", ":", ",", "tf", ".", "newaxis", ",", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "\n", "attention_mask", "=", "tf", ".", "cast", "(", "attention_mask", ",", "tf", ".", "float32", ")", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "", "else", ":", "\n", "            ", "attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "num_hidden_layers", "\n", "# head_mask = tf.constant([0] * self.num_hidden_layers)", "\n", "\n", "", "position_ids", "=", "tf", ".", "reshape", "(", "position_ids", ",", "[", "-", "1", ",", "shape_list", "(", "position_ids", ")", "[", "-", "1", "]", "]", ")", "\n", "\n", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "tokens_embed", "(", "input_ids", ",", "mode", "=", "\"embedding\"", ")", "\n", "", "position_embeds", "=", "self", ".", "positions_embed", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "tf", ".", "reshape", "(", "token_type_ids", ",", "[", "-", "1", ",", "shape_list", "(", "token_type_ids", ")", "[", "-", "1", "]", "]", ")", "\n", "token_type_embeds", "=", "self", ".", "tokens_embed", "(", "token_type_ids", ",", "mode", "=", "\"embedding\"", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "hidden_states", "=", "self", ".", "drop", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "[", "shape_list", "(", "hidden_states", ")", "[", "-", "1", "]", "]", "\n", "\n", "all_attentions", "=", "[", "]", "\n", "all_hidden_states", "=", "(", ")", "\n", "for", "i", ",", "block", "in", "enumerate", "(", "self", ".", "h", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "tf", ".", "reshape", "(", "hidden_states", ",", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "block", "(", "[", "hidden_states", ",", "attention_mask", ",", "head_mask", "[", "i", "]", "]", ",", "training", "=", "training", ")", "\n", "hidden_states", "=", "outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "outputs", "[", "1", "]", ")", "\n", "\n", "", "", "hidden_states", "=", "tf", ".", "reshape", "(", "hidden_states", ",", "output_shape", ")", "\n", "# Add last hidden state", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# let the number of heads free (-1) so we can extract attention even after head pruning", "\n", "            ", "attention_output_shape", "=", "input_shape", "[", ":", "-", "1", "]", "+", "[", "-", "1", "]", "+", "shape_list", "(", "all_attentions", "[", "0", "]", ")", "[", "-", "2", ":", "]", "\n", "all_attentions", "=", "tuple", "(", "tf", ".", "reshape", "(", "t", ",", "attention_output_shape", ")", "for", "t", "in", "all_attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last hidden state, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFOpenAIGPTModel.__init__": [[455, 458], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_openai.TFOpenAIGPTMainLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFOpenAIGPTModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFOpenAIGPTMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFOpenAIGPTModel.call": [[459, 462], ["modeling_tf_openai.TFOpenAIGPTModel.transformer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFOpenAIGPTLMHeadModel.__init__": [[496, 499], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_openai.TFOpenAIGPTMainLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFOpenAIGPTLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFOpenAIGPTMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFOpenAIGPTLMHeadModel.get_output_embeddings": [[500, 502], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "transformer", ".", "tokens_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFOpenAIGPTLMHeadModel.call": [[503, 512], ["modeling_tf_openai.TFOpenAIGPTLMHeadModel.transformer", "modeling_tf_openai.TFOpenAIGPTLMHeadModel.transformer.tokens_embed"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "transformer", ".", "tokens_embed", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "# lm_logits, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFOpenAIGPTDoubleHeadsModel.__init__": [[565, 571], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_openai.TFOpenAIGPTMainLayer", "modeling_tf_utils.TFSequenceSummary"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFOpenAIGPTDoubleHeadsModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "config", ".", "num_labels", "=", "1", "\n", "self", ".", "transformer", "=", "TFOpenAIGPTMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "self", ".", "multiple_choice_head", "=", "TFSequenceSummary", "(", "\n", "config", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"multiple_choice_head\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFOpenAIGPTDoubleHeadsModel.get_output_embeddings": [[573, 575], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "transformer", ".", "tokens_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.TFOpenAIGPTDoubleHeadsModel.call": [[576, 642], ["isinstance", "modeling_tf_openai.TFOpenAIGPTDoubleHeadsModel.transformer", "tensorflow.reshape", "modeling_tf_openai.TFOpenAIGPTDoubleHeadsModel.transformer.tokens_embed", "modeling_tf_openai.TFOpenAIGPTDoubleHeadsModel.multiple_choice_head", "tensorflow.squeeze", "isinstance", "modeling_tf_utils.shape_list", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "modeling_tf_utils.shape_list", "len", "len", "len", "len", "len", "len", "len", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "\n", "self", ",", "\n", "inputs", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "mc_token_ids", "=", "None", ",", "\n", "training", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "head_mask", "\n", "inputs_embeds", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "inputs_embeds", "\n", "mc_token_ids", "=", "inputs", "[", "6", "]", "if", "len", "(", "inputs", ")", ">", "6", "else", "mc_token_ids", "\n", "assert", "len", "(", "inputs", ")", "<=", "7", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "\"input_ids\"", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "\"attention_mask\"", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "\"token_type_ids\"", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "\"position_ids\"", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "\"head_mask\"", ",", "head_mask", ")", "\n", "inputs_embeds", "=", "inputs", ".", "get", "(", "\"inputs_embeds\"", ",", "inputs_embeds", ")", "\n", "mc_token_ids", "=", "inputs", ".", "get", "(", "\"mc_token_ids\"", ",", "mc_token_ids", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "7", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shapes", "=", "shape_list", "(", "input_ids", ")", "\n", "", "else", ":", "\n", "            ", "input_shapes", "=", "shape_list", "(", "inputs_embeds", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "seq_length", "=", "input_shapes", "[", "-", "1", "]", "\n", "\n", "flat_input_ids", "=", "tf", ".", "reshape", "(", "input_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "input_ids", "is", "not", "None", "else", "None", "\n", "flat_attention_mask", "=", "tf", ".", "reshape", "(", "attention_mask", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "flat_token_type_ids", "=", "tf", ".", "reshape", "(", "token_type_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_position_ids", "=", "tf", ".", "reshape", "(", "position_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "\n", "flat_inputs", "=", "[", "\n", "flat_input_ids", ",", "\n", "flat_attention_mask", ",", "\n", "flat_token_type_ids", ",", "\n", "flat_position_ids", ",", "\n", "head_mask", ",", "\n", "inputs_embeds", ",", "\n", "]", "\n", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "flat_inputs", ",", "training", "=", "training", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "hidden_states", "=", "tf", ".", "reshape", "(", "hidden_states", ",", "input_shapes", "+", "shape_list", "(", "hidden_states", ")", "[", "-", "1", ":", "]", ")", "\n", "\n", "lm_logits", "=", "self", ".", "transformer", ".", "tokens_embed", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "[", "hidden_states", ",", "mc_token_ids", "]", ",", "training", "=", "training", ")", "\n", "\n", "mc_logits", "=", "tf", ".", "squeeze", "(", "mc_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", "mc_logits", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "# lm logits, mc logits, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.gelu": [[43, 54], ["tensorflow.tanh", "numpy.sqrt", "tensorflow.pow"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"Gaussian Error Linear Unit.\n    This is a smoother version of the RELU.\n    Original paper: https://arxiv.org/abs/1606.08415\n    Args:\n        x: float Tensor to perform activation.\n    Returns:\n        `x` with the GELU activation applied.\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "tanh", "(", "(", "np", ".", "sqrt", "(", "2", "/", "np", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "tf", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_openai.swish": [[56, 58], ["tensorflow.math.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "tf", ".", "math", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFPositionalEmbedding.__init__": [[38, 42], ["super().__init__", "tensorflow.range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "demb", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFPositionalEmbedding", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "inv_freq", "=", "1", "/", "(", "10000", "**", "(", "tf", ".", "range", "(", "0", ",", "demb", ",", "2.0", ")", "/", "demb", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFPositionalEmbedding.call": [[43, 51], ["tensorflow.einsum", "tensorflow.concat", "tensorflow.tile", "tensorflow.sin", "tensorflow.cos"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "pos_seq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "tf", ".", "einsum", "(", "\"i,j->ij\"", ",", "pos_seq", ",", "self", ".", "inv_freq", ")", "\n", "pos_emb", "=", "tf", ".", "concat", "(", "[", "tf", ".", "sin", "(", "sinusoid_inp", ")", ",", "tf", ".", "cos", "(", "sinusoid_inp", ")", "]", ",", "-", "1", ")", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "return", "tf", ".", "tile", "(", "pos_emb", "[", ":", ",", "None", ",", ":", "]", ",", "[", "1", ",", "bsz", ",", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFPositionwiseFF.__init__": [[54, 71], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "d_inner", ",", "dropout", ",", "pre_lnorm", "=", "False", ",", "layer_norm_epsilon", "=", "1e-5", ",", "init_std", "=", "0.02", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFPositionwiseFF", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "layer_1", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "d_inner", ",", "kernel_initializer", "=", "get_initializer", "(", "init_std", ")", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "name", "=", "\"CoreNet_._0\"", "\n", ")", "\n", "self", ".", "drop_1", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "layer_2", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "d_model", ",", "kernel_initializer", "=", "get_initializer", "(", "init_std", ")", ",", "name", "=", "\"CoreNet_._3\"", ")", "\n", "self", ".", "drop_2", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "layer_norm_epsilon", ",", "name", "=", "\"layer_norm\"", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFPositionwiseFF.call": [[72, 94], ["modeling_tf_transfo_xl.TFPositionwiseFF.layer_norm", "modeling_tf_transfo_xl.TFPositionwiseFF.layer_1", "modeling_tf_transfo_xl.TFPositionwiseFF.drop_1", "modeling_tf_transfo_xl.TFPositionwiseFF.layer_2", "modeling_tf_transfo_xl.TFPositionwiseFF.drop_2", "modeling_tf_transfo_xl.TFPositionwiseFF.layer_1", "modeling_tf_transfo_xl.TFPositionwiseFF.drop_1", "modeling_tf_transfo_xl.TFPositionwiseFF.layer_2", "modeling_tf_transfo_xl.TFPositionwiseFF.drop_2", "modeling_tf_transfo_xl.TFPositionwiseFF.layer_norm"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inp", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "pre_lnorm", ":", "\n", "# layer normalization + positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "layer_norm", "(", "inp", ")", "\n", "core_out", "=", "self", ".", "layer_1", "(", "core_out", ")", "\n", "core_out", "=", "self", ".", "drop_1", "(", "core_out", ",", "training", "=", "training", ")", "\n", "core_out", "=", "self", ".", "layer_2", "(", "core_out", ")", "\n", "core_out", "=", "self", ".", "drop_2", "(", "core_out", ",", "training", "=", "training", ")", "\n", "\n", "# residual connection", "\n", "output", "=", "core_out", "+", "inp", "\n", "", "else", ":", "\n", "# positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "layer_1", "(", "inp", ")", "\n", "core_out", "=", "self", ".", "drop_1", "(", "core_out", ",", "training", "=", "training", ")", "\n", "core_out", "=", "self", ".", "layer_2", "(", "core_out", ")", "\n", "core_out", "=", "self", ".", "drop_2", "(", "core_out", ",", "training", "=", "training", ")", "\n", "\n", "# residual connection + layer normalization", "\n", "output", "=", "self", ".", "layer_norm", "(", "inp", "+", "core_out", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.__init__": [[97, 148], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "n_head", ",", "\n", "d_model", ",", "\n", "d_head", ",", "\n", "dropout", ",", "\n", "dropatt", "=", "0", ",", "\n", "tgt_len", "=", "None", ",", "\n", "ext_len", "=", "None", ",", "\n", "mem_len", "=", "None", ",", "\n", "pre_lnorm", "=", "False", ",", "\n", "r_r_bias", "=", "None", ",", "\n", "r_w_bias", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "init_std", "=", "0.02", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "TFRelPartialLearnableMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "output_attentions", "=", "output_attentions", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "qkv_net", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "3", "*", "n_head", "*", "d_head", ",", "kernel_initializer", "=", "get_initializer", "(", "init_std", ")", ",", "use_bias", "=", "False", ",", "name", "=", "\"qkv_net\"", "\n", ")", "\n", "\n", "self", ".", "drop", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropatt", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "dropatt", ")", "\n", "self", ".", "o_net", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "d_model", ",", "kernel_initializer", "=", "get_initializer", "(", "init_std", ")", ",", "use_bias", "=", "False", ",", "name", "=", "\"o_net\"", "\n", ")", "\n", "\n", "self", ".", "layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "layer_norm_epsilon", ",", "name", "=", "\"layer_norm\"", ")", "\n", "\n", "self", ".", "scale", "=", "1", "/", "(", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n", "if", "r_r_bias", "is", "not", "None", "and", "r_w_bias", "is", "not", "None", ":", "# Biases are shared", "\n", "            ", "self", ".", "r_r_bias", "=", "r_r_bias", "\n", "self", ".", "r_w_bias", "=", "r_w_bias", "\n", "", "else", ":", "\n", "            ", "self", ".", "r_r_bias", "=", "None", "\n", "self", ".", "r_w_bias", "=", "None", "\n", "\n", "", "self", ".", "r_net", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "n_head", "*", "self", ".", "d_head", ",", "kernel_initializer", "=", "get_initializer", "(", "init_std", ")", ",", "use_bias", "=", "False", ",", "name", "=", "\"r_net\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.build": [[150, 159], ["super().build", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.add_weight", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.add_weight"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "if", "self", ".", "r_r_bias", "is", "None", "or", "self", ".", "r_w_bias", "is", "None", ":", "# Biases are not shared", "\n", "            ", "self", ".", "r_r_bias", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"r_r_bias\"", "\n", ")", "\n", "self", ".", "r_w_bias", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"r_w_bias\"", "\n", ")", "\n", "", "super", "(", "TFRelPartialLearnableMultiHeadAttn", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn._rel_shift": [[160, 169], ["modeling_tf_utils.shape_list", "tensorflow.pad", "tensorflow.reshape", "tensorflow.slice", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "_rel_shift", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_size", "=", "shape_list", "(", "x", ")", "\n", "\n", "x", "=", "tf", ".", "pad", "(", "x", ",", "[", "[", "0", ",", "0", "]", ",", "[", "1", ",", "0", "]", ",", "[", "0", ",", "0", "]", ",", "[", "0", ",", "0", "]", "]", ")", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "x_size", "[", "1", "]", "+", "1", ",", "x_size", "[", "0", "]", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", "]", ")", "\n", "x", "=", "tf", ".", "slice", "(", "x", ",", "[", "1", ",", "0", ",", "0", ",", "0", "]", ",", "[", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", "]", ")", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "x_size", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.call": [[170, 248], ["tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.einsum", "tensorflow.einsum", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn._rel_shift", "tensorflow.nn.softmax", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.dropatt", "tensorflow.einsum", "modeling_tf_utils.shape_list", "tensorflow.reshape", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.o_net", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.drop", "tensorflow.concat", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.r_net", "tensorflow.split", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.r_net", "tensorflow.split", "modeling_tf_utils.shape_list", "outputs.append", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.qkv_net", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.qkv_net", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.qkv_net", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.qkv_net", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.layer_norm", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.layer_norm", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn.layer_norm"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn._rel_shift", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "w", ",", "r", ",", "attn_mask", ",", "mems", ",", "head_mask", "=", "inputs", "\n", "qlen", ",", "rlen", ",", "bsz", "=", "shape_list", "(", "w", ")", "[", "0", "]", ",", "shape_list", "(", "r", ")", "[", "0", "]", ",", "shape_list", "(", "w", ")", "[", "1", "]", "\n", "\n", "if", "mems", "is", "not", "None", ":", "\n", "            ", "cat", "=", "tf", ".", "concat", "(", "[", "mems", ",", "w", "]", ",", "0", ")", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "cat", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "cat", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "tf", ".", "split", "(", "w_heads", ",", "3", ",", "axis", "=", "-", "1", ")", "\n", "w_head_q", "=", "w_head_q", "[", "-", "qlen", ":", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "w", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "w", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "tf", ".", "split", "(", "w_heads", ",", "3", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "klen", "=", "shape_list", "(", "w_head_k", ")", "[", "0", "]", "\n", "\n", "w_head_q", "=", "tf", ".", "reshape", "(", "w_head_q", ",", "(", "qlen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_k", "=", "tf", ".", "reshape", "(", "w_head_k", ",", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_v", "=", "tf", ".", "reshape", "(", "w_head_v", ",", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "# qlen x bsz x n_head x d_head", "\n", "\n", "r_head_k", "=", "tf", ".", "reshape", "(", "r_head_k", ",", "(", "rlen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "# qlen x n_head x d_head", "\n", "\n", "# compute attention score", "\n", "rw_head_q", "=", "w_head_q", "+", "self", ".", "r_w_bias", "# qlen x bsz x n_head x d_head", "\n", "AC", "=", "tf", ".", "einsum", "(", "\"ibnd,jbnd->ijbn\"", ",", "rw_head_q", ",", "w_head_k", ")", "# qlen x klen x bsz x n_head", "\n", "\n", "rr_head_q", "=", "w_head_q", "+", "self", ".", "r_r_bias", "\n", "BD", "=", "tf", ".", "einsum", "(", "\"ibnd,jnd->ijbn\"", ",", "rr_head_q", ",", "r_head_k", ")", "# qlen x klen x bsz x n_head", "\n", "BD", "=", "self", ".", "_rel_shift", "(", "BD", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "AC", "+", "BD", "\n", "attn_score", "=", "attn_score", "*", "self", ".", "scale", "\n", "\n", "# compute attention probability", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask_t", "=", "attn_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "attn_score", "=", "attn_score", "*", "(", "1", "-", "attn_mask_t", ")", "-", "1e30", "*", "attn_mask_t", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "attn_prob", "=", "tf", ".", "nn", ".", "softmax", "(", "attn_score", ",", "axis", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ",", "training", "=", "training", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attn_prob", "=", "attn_prob", "*", "head_mask", "\n", "\n", "# compute attention vector", "\n", "", "attn_vec", "=", "tf", ".", "einsum", "(", "\"ijbn,jbnd->ibnd\"", ",", "attn_prob", ",", "w_head_v", ")", "\n", "\n", "# [qlen x bsz x n_head x d_head]", "\n", "attn_vec_sizes", "=", "shape_list", "(", "attn_vec", ")", "\n", "attn_vec", "=", "tf", ".", "reshape", "(", "attn_vec", ",", "(", "attn_vec_sizes", "[", "0", "]", ",", "attn_vec_sizes", "[", "1", "]", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", ")", "\n", "\n", "# linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ",", "training", "=", "training", ")", "\n", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "# residual connection", "\n", "            ", "outputs", "=", "[", "w", "+", "attn_out", "]", "\n", "", "else", ":", "\n", "# residual connection + layer normalization", "\n", "            ", "outputs", "=", "[", "self", ".", "layer_norm", "(", "w", "+", "attn_out", ")", "]", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "attn_prob", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFRelPartialLearnableDecoderLayer.__init__": [[251, 297], ["super().__init__", "modeling_tf_transfo_xl.TFRelPartialLearnableMultiHeadAttn", "modeling_tf_transfo_xl.TFPositionwiseFF"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "n_head", ",", "\n", "d_model", ",", "\n", "d_head", ",", "\n", "d_inner", ",", "\n", "dropout", ",", "\n", "tgt_len", "=", "None", ",", "\n", "ext_len", "=", "None", ",", "\n", "mem_len", "=", "None", ",", "\n", "dropatt", "=", "0.0", ",", "\n", "pre_lnorm", "=", "False", ",", "\n", "r_w_bias", "=", "None", ",", "\n", "r_r_bias", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "init_std", "=", "0.02", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "TFRelPartialLearnableDecoderLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "dec_attn", "=", "TFRelPartialLearnableMultiHeadAttn", "(", "\n", "n_head", ",", "\n", "d_model", ",", "\n", "d_head", ",", "\n", "dropout", ",", "\n", "tgt_len", "=", "tgt_len", ",", "\n", "ext_len", "=", "ext_len", ",", "\n", "mem_len", "=", "mem_len", ",", "\n", "dropatt", "=", "dropatt", ",", "\n", "pre_lnorm", "=", "pre_lnorm", ",", "\n", "r_w_bias", "=", "r_w_bias", ",", "\n", "r_r_bias", "=", "r_r_bias", ",", "\n", "init_std", "=", "init_std", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "layer_norm_epsilon", "=", "layer_norm_epsilon", ",", "\n", "name", "=", "\"dec_attn\"", ",", "\n", ")", "\n", "self", ".", "pos_ff", "=", "TFPositionwiseFF", "(", "\n", "d_model", ",", "\n", "d_inner", ",", "\n", "dropout", ",", "\n", "pre_lnorm", "=", "pre_lnorm", ",", "\n", "init_std", "=", "init_std", ",", "\n", "layer_norm_epsilon", "=", "layer_norm_epsilon", ",", "\n", "name", "=", "\"pos_ff\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFRelPartialLearnableDecoderLayer.call": [[299, 307], ["modeling_tf_transfo_xl.TFRelPartialLearnableDecoderLayer.dec_attn", "modeling_tf_transfo_xl.TFRelPartialLearnableDecoderLayer.pos_ff"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "dec_inp", ",", "r", ",", "dec_attn_mask", ",", "mems", ",", "head_mask", "=", "inputs", "\n", "attn_outputs", "=", "self", ".", "dec_attn", "(", "[", "dec_inp", ",", "r", ",", "dec_attn_mask", ",", "mems", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "ff_output", "=", "self", ".", "pos_ff", "(", "attn_outputs", "[", "0", "]", ",", "training", "=", "training", ")", "\n", "\n", "outputs", "=", "[", "ff_output", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFAdaptiveEmbedding.__init__": [[310, 339], ["super().__init__", "range", "len", "modeling_tf_transfo_xl.TFAdaptiveEmbedding.emb_layers.append", "tensorflow.keras.layers.Embedding", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "1", ",", "init_std", "=", "0.02", ",", "sample_softmax", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAdaptiveEmbedding", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "n_token", "=", "n_token", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "init_std", "=", "init_std", "\n", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_token", "]", "\n", "self", ".", "div_val", "=", "div_val", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "self", ".", "emb_scale", "=", "d_proj", "**", "0.5", "\n", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "\n", "self", ".", "emb_layers", "=", "[", "]", "\n", "self", ".", "emb_projs", "=", "[", "]", "\n", "if", "div_val", "==", "1", ":", "\n", "            ", "raise", "NotImplementedError", "# Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoint", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "self", ".", "emb_layers", ".", "append", "(", "\n", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "\n", "r_idx", "-", "l_idx", ",", "\n", "d_emb_i", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "init_std", ")", ",", "\n", "name", "=", "\"emb_layers_._{}\"", ".", "format", "(", "i", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFAdaptiveEmbedding.build": [[342, 354], ["range", "super().build", "len", "modeling_tf_transfo_xl.TFAdaptiveEmbedding.emb_projs.append", "modeling_tf_transfo_xl.TFAdaptiveEmbedding.add_weight", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["", "", "", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "            ", "d_emb_i", "=", "self", ".", "d_embed", "//", "(", "self", ".", "div_val", "**", "i", ")", "\n", "self", ".", "emb_projs", ".", "append", "(", "\n", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "d_emb_i", ",", "self", ".", "d_proj", ")", ",", "\n", "initializer", "=", "get_initializer", "(", "self", ".", "init_std", ")", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "\"emb_projs_._{}\"", ".", "format", "(", "i", ")", ",", "\n", ")", "\n", ")", "\n", "", "super", "(", "TFAdaptiveEmbedding", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFAdaptiveEmbedding.call": [[355, 379], ["tensorflow.reshape", "tensorflow.zeros", "range", "tensorflow.reshape", "len", "tensorflow.einsum", "tensorflow.cast", "tensorflow.scatter_nd", "modeling_tf_utils.shape_list", "tensorflow.boolean_mask", "tensorflow.where", "tensorflow.cast", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "            ", "raise", "NotImplementedError", "# Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoint", "\n", "", "else", ":", "\n", "            ", "inp_flat", "=", "tf", ".", "reshape", "(", "inp", ",", "(", "-", "1", ",", ")", ")", "\n", "emb_flat", "=", "tf", ".", "zeros", "(", "[", "shape_list", "(", "inp_flat", ")", "[", "0", "]", ",", "self", ".", "d_proj", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "\n", "mask_i", "=", "(", "inp_flat", ">=", "l_idx", ")", "&", "(", "inp_flat", "<", "r_idx", ")", "\n", "\n", "inp_i", "=", "tf", ".", "boolean_mask", "(", "inp_flat", ",", "mask_i", ")", "-", "l_idx", "\n", "emb_i", "=", "self", ".", "emb_layers", "[", "i", "]", "(", "inp_i", ")", "\n", "emb_i", "=", "tf", ".", "einsum", "(", "\"id,de->ie\"", ",", "emb_i", ",", "self", ".", "emb_projs", "[", "i", "]", ")", "\n", "\n", "mask_idx", "=", "tf", ".", "cast", "(", "tf", ".", "where", "(", "mask_i", ")", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "emb_flat", "+=", "tf", ".", "scatter_nd", "(", "mask_idx", ",", "emb_i", ",", "tf", ".", "cast", "(", "shape_list", "(", "emb_flat", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ")", "\n", "\n", "", "embed_shape", "=", "shape_list", "(", "inp", ")", "+", "[", "self", ".", "d_proj", "]", "\n", "embed", "=", "tf", ".", "reshape", "(", "emb_flat", ",", "embed_shape", ")", "\n", "\n", "", "embed", "*=", "self", ".", "emb_scale", "\n", "\n", "return", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer.__init__": [[382, 449], ["super().__init__", "modeling_tf_transfo_xl.TFAdaptiveEmbedding", "tensorflow.keras.layers.Dropout", "range", "modeling_tf_transfo_xl.TFPositionalEmbedding", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.layers.append", "modeling_tf_transfo_xl.TFRelPartialLearnableDecoderLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFTransfoXLMainLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "self", ".", "n_token", "=", "config", ".", "vocab_size", "\n", "\n", "self", ".", "d_embed", "=", "config", ".", "d_embed", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "d_head", "=", "config", ".", "d_head", "\n", "self", ".", "untie_r", "=", "config", ".", "untie_r", "\n", "\n", "self", ".", "word_emb", "=", "TFAdaptiveEmbedding", "(", "\n", "config", ".", "vocab_size", ",", "\n", "config", ".", "d_embed", ",", "\n", "config", ".", "d_model", ",", "\n", "config", ".", "cutoffs", ",", "\n", "div_val", "=", "config", ".", "div_val", ",", "\n", "init_std", "=", "config", ".", "init_std", ",", "\n", "name", "=", "\"word_emb\"", ",", "\n", ")", "\n", "\n", "self", ".", "drop", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n", "self", ".", "n_layer", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "tgt_len", "=", "config", ".", "tgt_len", "\n", "self", ".", "mem_len", "=", "config", ".", "mem_len", "\n", "self", ".", "ext_len", "=", "config", ".", "ext_len", "\n", "self", ".", "max_klen", "=", "config", ".", "tgt_len", "+", "config", ".", "ext_len", "+", "config", ".", "mem_len", "\n", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "\n", "self", ".", "layers", "=", "[", "]", "\n", "if", "config", ".", "attn_type", "==", "0", ":", "# the default attention", "\n", "            ", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "\n", "TFRelPartialLearnableDecoderLayer", "(", "\n", "config", ".", "n_head", ",", "\n", "config", ".", "d_model", ",", "\n", "config", ".", "d_head", ",", "\n", "config", ".", "d_inner", ",", "\n", "config", ".", "dropout", ",", "\n", "tgt_len", "=", "config", ".", "tgt_len", ",", "\n", "ext_len", "=", "config", ".", "ext_len", ",", "\n", "mem_len", "=", "config", ".", "mem_len", ",", "\n", "dropatt", "=", "config", ".", "dropatt", ",", "\n", "pre_lnorm", "=", "config", ".", "pre_lnorm", ",", "\n", "r_w_bias", "=", "None", "if", "self", ".", "untie_r", "else", "self", ".", "r_w_bias", ",", "\n", "r_r_bias", "=", "None", "if", "self", ".", "untie_r", "else", "self", ".", "r_r_bias", ",", "\n", "output_attentions", "=", "self", ".", "output_attentions", ",", "\n", "layer_norm_epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "\n", "init_std", "=", "config", ".", "init_std", ",", "\n", "name", "=", "\"layers_._{}\"", ".", "format", "(", "i", ")", ",", "\n", ")", "\n", ")", "\n", "", "", "else", ":", "# learnable embeddings and absolute embeddings", "\n", "            ", "raise", "NotImplementedError", "# Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoint", "\n", "\n", "", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "self", ".", "clamp_len", "=", "config", ".", "clamp_len", "\n", "\n", "if", "self", ".", "attn_type", "==", "0", ":", "# default attention", "\n", "            ", "self", ".", "pos_emb", "=", "TFPositionalEmbedding", "(", "self", ".", "d_model", ",", "name", "=", "\"pos_emb\"", ")", "\n", "", "else", ":", "# learnable embeddings and absolute embeddings", "\n", "            ", "raise", "NotImplementedError", "# Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer.build": [[450, 459], ["super().build", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.add_weight", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.add_weight"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "if", "not", "self", ".", "untie_r", ":", "\n", "            ", "self", ".", "r_w_bias", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"r_w_bias\"", "\n", ")", "\n", "self", ".", "r_r_bias", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"r_r_bias\"", "\n", ")", "\n", "", "super", "(", "TFTransfoXLMainLayer", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer.get_input_embeddings": [[460, 462], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "word_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer._resize_token_embeddings": [[463, 465], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "return", "self", ".", "word_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer.backward_compatible": [[466, 468], ["None"], "methods", ["None"], ["", "def", "backward_compatible", "(", "self", ")", ":", "\n", "        ", "self", ".", "sample_softmax", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer.reset_length": [[469, 473], ["None"], "methods", ["None"], ["", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer._prune_heads": [[474, 476], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer.init_mems": [[477, 487], ["range", "tensorflow.zeros", "mems.append"], "methods", ["None"], ["", "def", "init_mems", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "if", "self", ".", "mem_len", ">", "0", ":", "\n", "            ", "mems", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layer", ")", ":", "\n", "                ", "empty", "=", "tf", ".", "zeros", "(", "[", "self", ".", "mem_len", ",", "bsz", ",", "self", ".", "d_model", "]", ")", "\n", "mems", ".", "append", "(", "empty", ")", "\n", "\n", "", "return", "mems", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer._update_mems": [[488, 511], ["max", "range", "len", "len", "max", "len", "tensorflow.concat", "tensorflow.stop_gradient", "new_mems.append"], "methods", ["None"], ["", "", "def", "_update_mems", "(", "self", ",", "hids", ",", "mems", ",", "qlen", ",", "mlen", ")", ":", "\n", "# does not deal with None", "\n", "        ", "if", "mems", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "# mems is not None", "\n", "", "assert", "len", "(", "hids", ")", "==", "len", "(", "mems", ")", ",", "\"len(hids) != len(mems)\"", "\n", "\n", "# There are `mlen + qlen` steps that can be cached into mems", "\n", "# For the next step, the last `ext_len` of the `qlen` tokens", "\n", "# will be used as the extended context. Hence, we only cache", "\n", "# the tokens from `mlen + qlen - self.ext_len - self.mem_len`", "\n", "# to `mlen + qlen - self.ext_len`.", "\n", "new_mems", "=", "[", "]", "\n", "end_idx", "=", "mlen", "+", "max", "(", "0", ",", "qlen", "-", "0", "-", "self", ".", "ext_len", ")", "\n", "beg_idx", "=", "max", "(", "0", ",", "end_idx", "-", "self", ".", "mem_len", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "hids", ")", ")", ":", "\n", "\n", "            ", "cat", "=", "tf", ".", "concat", "(", "[", "mems", "[", "i", "]", ",", "hids", "[", "i", "]", "]", ",", "axis", "=", "0", ")", "\n", "tf", ".", "stop_gradient", "(", "cat", ")", "\n", "new_mems", ".", "append", "(", "cat", "[", "beg_idx", ":", "end_idx", "]", ")", "\n", "\n", "", "return", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLMainLayer.call": [[512, 621], ["isinstance", "tensorflow.ones", "tensorflow.linalg.band_part", "tensorflow.linalg.band_part", "tensorflow.zeros", "tensorflow.concat", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.drop", "modeling_tf_transfo_xl.TFTransfoXLMainLayer._update_mems", "isinstance", "ValueError", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.init_mems", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.word_emb", "tensorflow.linalg.band_part", "tensorflow.concat", "tensorflow.range", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.pos_emb", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.drop", "modeling_tf_transfo_xl.TFTransfoXLMainLayer.drop", "enumerate", "tensorflow.transpose", "list.append", "list", "outputs.append", "list", "outputs.append", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "tensorflow.transpose", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "tensorflow.minimum", "list.append", "layer", "len", "len", "len", "len", "tensorflow.transpose", "ValueError", "list.append", "tensorflow.transpose", "tensorflow.transpose", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLModel._update_mems", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "mems", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "mems", "\n", "head_mask", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "head_mask", "\n", "inputs_embeds", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "inputs_embeds", "\n", "assert", "len", "(", "inputs", ")", "<=", "4", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "\"input_ids\"", ")", "\n", "mems", "=", "inputs", ".", "get", "(", "\"mems\"", ",", "mems", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "\"head_mask\"", ",", "head_mask", ")", "\n", "inputs_embeds", "=", "inputs", ".", "get", "(", "\"inputs_embeds\"", ",", "inputs_embeds", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "4", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "# the original code for Transformer-XL used shapes [len, bsz] but we want a unified interface in the library", "\n", "# so we transpose here from shape [bsz, len] to shape [len, bsz]", "\n", "", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_ids", "=", "tf", ".", "transpose", "(", "input_ids", ",", "perm", "=", "(", "1", ",", "0", ")", ")", "\n", "qlen", ",", "bsz", "=", "shape_list", "(", "input_ids", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "inputs_embeds", "=", "tf", ".", "transpose", "(", "inputs_embeds", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "qlen", ",", "bsz", "=", "shape_list", "(", "inputs_embeds", ")", "[", ":", "2", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "mems", "is", "None", ":", "\n", "            ", "mems", "=", "self", ".", "init_mems", "(", "bsz", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads] (a head_mask for each layer)", "\n", "# and head_mask is converted to shape [num_hidden_layers x qlen x klen x bsz x n_head]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layer", "\n", "\n", "", "if", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "word_emb", "=", "inputs_embeds", "\n", "", "else", ":", "\n", "            ", "word_emb", "=", "self", ".", "word_emb", "(", "input_ids", ")", "\n", "\n", "", "mlen", "=", "shape_list", "(", "mems", "[", "0", "]", ")", "[", "0", "]", "if", "mems", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "\n", "attn_mask", "=", "tf", ".", "ones", "(", "[", "qlen", ",", "qlen", "]", ")", "\n", "mask_u", "=", "tf", ".", "linalg", ".", "band_part", "(", "attn_mask", ",", "0", ",", "-", "1", ")", "\n", "mask_dia", "=", "tf", ".", "linalg", ".", "band_part", "(", "attn_mask", ",", "0", ",", "0", ")", "\n", "attn_mask_pad", "=", "tf", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ")", "\n", "dec_attn_mask", "=", "tf", ".", "concat", "(", "[", "attn_mask_pad", ",", "mask_u", "-", "mask_dia", "]", ",", "1", ")", "\n", "if", "self", ".", "same_length", ":", "\n", "            ", "mask_l", "=", "tf", ".", "linalg", ".", "band_part", "(", "attn_mask", ",", "-", "1", ",", "0", ")", "\n", "dec_attn_mask", "=", "tf", ".", "concat", "(", "[", "dec_attn_mask", "[", ":", ",", ":", "qlen", "]", "+", "mask_l", "-", "mask_dia", ",", "dec_attn_mask", "[", ":", ",", "qlen", ":", "]", "]", ",", "1", ")", "\n", "# ::: PyTorch masking code for reference :::", "\n", "# if self.same_length:", "\n", "#     all_ones = word_emb.new_ones((qlen, klen), dtype=torch.uint8)", "\n", "#     mask_len = klen - self.mem_len", "\n", "#     if mask_len > 0:", "\n", "#         mask_shift_len = qlen - mask_len", "\n", "#     else:", "\n", "#         mask_shift_len = qlen", "\n", "#     dec_attn_mask = (torch.triu(all_ones, 1+mlen)", "\n", "#             + torch.tril(all_ones, -mask_shift_len))[:, :, None] # -1", "\n", "# else:", "\n", "#     dec_attn_mask = torch.triu(", "\n", "#         word_emb.new_ones((qlen, klen), dtype=torch.uint8), diagonal=1+mlen)[:,:,None]", "\n", "\n", "", "hids", "=", "[", "]", "\n", "attentions", "=", "[", "]", "\n", "if", "self", ".", "attn_type", "==", "0", ":", "# default", "\n", "            ", "pos_seq", "=", "tf", ".", "range", "(", "klen", "-", "1", ",", "-", "1", ",", "-", "1.0", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "pos_seq", "=", "tf", ".", "minimum", "(", "pos_seq", ",", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "pos_emb", "(", "pos_seq", ")", "\n", "\n", "core_out", "=", "self", ".", "drop", "(", "word_emb", ",", "training", "=", "training", ")", "\n", "pos_emb", "=", "self", ".", "drop", "(", "pos_emb", ",", "training", "=", "training", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "layer_outputs", "=", "layer", "(", "[", "core_out", ",", "pos_emb", ",", "dec_attn_mask", ",", "mems_i", ",", "head_mask", "[", "i", "]", "]", ",", "training", "=", "training", ")", "\n", "core_out", "=", "layer_outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attentions", ".", "append", "(", "layer_outputs", "[", "1", "]", ")", "\n", "", "", "", "else", ":", "# learnable embeddings and absolute embeddings", "\n", "            ", "raise", "NotImplementedError", "# Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoint", "\n", "\n", "", "core_out", "=", "self", ".", "drop", "(", "core_out", ",", "training", "=", "training", ")", "\n", "\n", "new_mems", "=", "self", ".", "_update_mems", "(", "hids", ",", "mems", ",", "mlen", ",", "qlen", ")", "\n", "\n", "# We transpose back here to shape [bsz, len, hidden_dim]", "\n", "outputs", "=", "[", "tf", ".", "transpose", "(", "core_out", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", ",", "new_mems", "]", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "# Add last layer and transpose to library standard shape [bsz, len, hidden_dim]", "\n", "            ", "hids", ".", "append", "(", "core_out", ")", "\n", "hids", "=", "list", "(", "tf", ".", "transpose", "(", "t", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", "for", "t", "in", "hids", ")", "\n", "outputs", ".", "append", "(", "hids", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# Transpose to library standard shape [bsz, n_heads, query_seq_len, key_seq_len]", "\n", "            ", "attentions", "=", "list", "(", "tf", ".", "transpose", "(", "t", ",", "perm", "=", "(", "2", ",", "3", ",", "0", ",", "1", ")", ")", "for", "t", "in", "attentions", ")", "\n", "outputs", ".", "append", "(", "attentions", ")", "\n", "", "return", "outputs", "# last hidden state, new_mems, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLModel.__init__": [[730, 733], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_transfo_xl.TFTransfoXLMainLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFTransfoXLModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFTransfoXLMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLModel.call": [[734, 737], ["modeling_tf_transfo_xl.TFTransfoXLModel.transformer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.__init__": [[776, 787], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_transfo_xl.TFTransfoXLMainLayer", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "TFTransfoXLLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "TFTransfoXLMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "self", ".", "sample_softmax", "=", "config", ".", "sample_softmax", "\n", "# use sampled softmax", "\n", "if", "config", ".", "sample_softmax", ">", "0", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "# use adaptive softmax (including standard softmax)", "\n", "", "else", ":", "\n", "            ", "self", ".", "crit", "=", "TFAdaptiveSoftmaxMask", "(", "\n", "config", ".", "vocab_size", ",", "config", ".", "d_embed", ",", "config", ".", "d_model", ",", "config", ".", "cutoffs", ",", "div_val", "=", "config", ".", "div_val", ",", "name", "=", "\"crit\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.reset_length": [[789, 791], ["modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.transformer.reset_length"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.reset_length"], ["", "", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "transformer", ".", "reset_length", "(", "tgt_len", ",", "ext_len", ",", "mem_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.init_mems": [[792, 794], ["modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.transformer.init_mems"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems"], ["", "def", "init_mems", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "return", "self", ".", "transformer", ".", "init_mems", "(", "bsz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.call": [[795, 832], ["isinstance", "modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.transformer", "isinstance", "modeling_tf_transfo_xl.TFTransfoXLLMHeadModel.crit", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "labels", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "mems", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "mems", "\n", "head_mask", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "head_mask", "\n", "inputs_embeds", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "inputs_embeds", "\n", "labels", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "labels", "\n", "assert", "len", "(", "inputs", ")", "<=", "5", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "\"input_ids\"", ")", "\n", "mems", "=", "inputs", ".", "get", "(", "\"mems\"", ",", "mems", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "\"head_mask\"", ",", "head_mask", ")", "\n", "inputs_embeds", "=", "inputs", ".", "get", "(", "\"inputs_embeds\"", ",", "inputs_embeds", ")", "\n", "labels", "=", "inputs", ".", "get", "(", "\"labels\"", ",", "labels", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "5", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "bsz", ",", "tgt_len", "=", "shape_list", "(", "input_ids", ")", "[", ":", "2", "]", "\n", "", "else", ":", "\n", "            ", "bsz", ",", "tgt_len", "=", "shape_list", "(", "inputs_embeds", ")", "[", ":", "2", "]", "\n", "\n", "", "transformer_outputs", "=", "self", ".", "transformer", "(", "[", "input_ids", ",", "mems", ",", "head_mask", ",", "inputs_embeds", "]", ",", "training", "=", "training", ")", "\n", "\n", "last_hidden", "=", "transformer_outputs", "[", "0", "]", "\n", "pred_hid", "=", "last_hidden", "[", ":", ",", "-", "tgt_len", ":", "]", "\n", "outputs", "=", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "self", ".", "sample_softmax", ">", "0", "and", "training", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "# pred_hid = tf.reshape(pred_hid, (-1, shape_list(pred_hid)[-1]))", "\n", "            ", "softmax_output", "=", "self", ".", "crit", "(", "[", "pred_hid", ",", "labels", "]", ",", "training", "=", "training", ")", "\n", "# softmax_output = tf.reshape(softmax_output, (bsz, tgt_len, -1))", "\n", "outputs", "=", "[", "softmax_output", "]", "+", "outputs", "\n", "\n", "", "return", "outputs", "# logits, new_mems, (all hidden states), (all attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaEmbeddings.__init__": [[44, 47], ["modeling_tf_bert.TFBertEmbeddings.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaEmbeddings", ",", "self", ")", ".", "__init__", "(", "config", ",", "**", "kwargs", ")", "\n", "self", ".", "padding_idx", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaEmbeddings.create_position_ids_from_input_ids": [[48, 58], ["tensorflow.cast", "tensorflow.math.not_equal", "tensorflow.math.cumsum"], "methods", ["None"], ["", "def", "create_position_ids_from_input_ids", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" Replace non-padding symbols with their position numbers. Position numbers begin at\n        padding_idx+1. Padding symbols are ignored. This is modified from fairseq's\n        `utils.make_positions`.\n        :param torch.Tensor x:\n        :return torch.Tensor:\n        \"\"\"", "\n", "mask", "=", "tf", ".", "cast", "(", "tf", ".", "math", ".", "not_equal", "(", "x", ",", "self", ".", "padding_idx", ")", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "incremental_indicies", "=", "tf", ".", "math", ".", "cumsum", "(", "mask", ",", "axis", "=", "1", ")", "*", "mask", "\n", "return", "incremental_indicies", "+", "self", ".", "padding_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaEmbeddings.create_position_ids_from_inputs_embeds": [[59, 69], ["modeling_tf_utils.shape_list", "tensorflow.range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "create_position_ids_from_inputs_embeds", "(", "self", ",", "inputs_embeds", ")", ":", "\n", "        ", "\"\"\" We are provided embeddings directly. We cannot infer which are padded so just generate\n        sequential position ids.\n        :param torch.Tensor inputs_embeds:\n        :return torch.Tensor:\n        \"\"\"", "\n", "seq_length", "=", "shape_list", "(", "inputs_embeds", ")", "[", "1", "]", "\n", "\n", "position_ids", "=", "tf", ".", "range", "(", "self", ".", "padding_idx", "+", "1", ",", "seq_length", "+", "self", ".", "padding_idx", "+", "1", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "tf", ".", "newaxis", ",", ":", "]", "\n", "return", "position_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaEmbeddings._embedding": [[70, 83], ["super()._embedding", "modeling_tf_roberta.TFRobertaEmbeddings.create_position_ids_from_input_ids", "modeling_tf_roberta.TFRobertaEmbeddings.create_position_ids_from_inputs_embeds"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertEmbeddings._embedding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaEmbeddings.create_position_ids_from_input_ids", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaEmbeddings.create_position_ids_from_inputs_embeds"], ["", "def", "_embedding", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Applies embedding based on inputs tensor.\"\"\"", "\n", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "inputs_embeds", "=", "inputs", "\n", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "if", "input_ids", "is", "not", "None", ":", "\n", "# Create the position ids from the input token ids. Any padded tokens remain padded.", "\n", "                ", "position_ids", "=", "self", ".", "create_position_ids_from_input_ids", "(", "input_ids", ")", "\n", "", "else", ":", "\n", "                ", "position_ids", "=", "self", ".", "create_position_ids_from_inputs_embeds", "(", "inputs_embeds", ")", "\n", "\n", "", "", "return", "super", "(", "TFRobertaEmbeddings", ",", "self", ")", ".", "_embedding", "(", "\n", "[", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "inputs_embeds", "]", ",", "training", "=", "training", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaMainLayer.__init__": [[91, 94], ["modeling_tf_bert.TFBertMainLayer.__init__", "modeling_tf_roberta.TFRobertaEmbeddings"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaMainLayer", ",", "self", ")", ".", "__init__", "(", "config", ",", "**", "kwargs", ")", "\n", "self", ".", "embeddings", "=", "TFRobertaEmbeddings", "(", "config", ",", "name", "=", "\"embeddings\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaMainLayer.get_input_embeddings": [[95, 97], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaModel.__init__": [[236, 239], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_roberta.TFRobertaMainLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "roberta", "=", "TFRobertaMainLayer", "(", "config", ",", "name", "=", "\"roberta\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaModel.call": [[240, 243], ["modeling_tf_roberta.TFRobertaModel.roberta"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaLMHead.__init__": [[248, 260], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Activation", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "input_embeddings", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaLMHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "hidden_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"dense\"", "\n", ")", "\n", "self", ".", "layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "\"layer_norm\"", ")", "\n", "self", ".", "act", "=", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "gelu", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "decoder", "=", "input_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaLMHead.build": [[261, 264], ["modeling_tf_roberta.TFRobertaLMHead.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "vocab_size", ",", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"bias\"", ")", "\n", "super", "(", "TFRobertaLMHead", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaLMHead.call": [[265, 274], ["modeling_tf_roberta.TFRobertaLMHead.dense", "modeling_tf_roberta.TFRobertaLMHead.act", "modeling_tf_roberta.TFRobertaLMHead.layer_norm", "modeling_tf_roberta.TFRobertaLMHead.decoder"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "features", ")", ":", "\n", "        ", "x", "=", "self", ".", "dense", "(", "features", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# project back to size of vocabulary with bias", "\n", "x", "=", "self", ".", "decoder", "(", "x", ",", "mode", "=", "\"linear\"", ")", "+", "self", ".", "bias", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaForMaskedLM.__init__": [[307, 312], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_roberta.TFRobertaMainLayer", "modeling_tf_roberta.TFRobertaLMHead"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "roberta", "=", "TFRobertaMainLayer", "(", "config", ",", "name", "=", "\"roberta\"", ")", "\n", "self", ".", "lm_head", "=", "TFRobertaLMHead", "(", "config", ",", "self", ".", "roberta", ".", "embeddings", ",", "name", "=", "\"lm_head\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaForMaskedLM.get_output_embeddings": [[313, 315], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaForMaskedLM.call": [[316, 325], ["modeling_tf_roberta.TFRobertaForMaskedLM.roberta", "modeling_tf_roberta.TFRobertaForMaskedLM.lm_head"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaClassificationHead.__init__": [[330, 341], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaClassificationHead", ",", "self", ")", ".", "__init__", "(", "config", ",", "**", "kwargs", ")", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "hidden_size", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "activation", "=", "\"tanh\"", ",", "\n", "name", "=", "\"dense\"", ",", "\n", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "out_proj", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"out_proj\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaClassificationHead.call": [[343, 350], ["modeling_tf_roberta.TFRobertaClassificationHead.dropout", "modeling_tf_roberta.TFRobertaClassificationHead.dense", "modeling_tf_roberta.TFRobertaClassificationHead.dropout", "modeling_tf_roberta.TFRobertaClassificationHead.out_proj"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "features", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", "=", "features", "[", ":", ",", "0", ",", ":", "]", "# take <s> token (equiv. to [CLS])", "\n", "x", "=", "self", ".", "dropout", "(", "x", ",", "training", "=", "training", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ",", "training", "=", "training", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaForSequenceClassification.__init__": [[385, 391], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_roberta.TFRobertaMainLayer", "modeling_tf_roberta.TFRobertaClassificationHead"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "TFRobertaMainLayer", "(", "config", ",", "name", "=", "\"roberta\"", ")", "\n", "self", ".", "classifier", "=", "TFRobertaClassificationHead", "(", "config", ",", "name", "=", "\"classifier\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaForSequenceClassification.call": [[392, 401], ["modeling_tf_roberta.TFRobertaForSequenceClassification.roberta", "modeling_tf_roberta.TFRobertaForSequenceClassification.classifier", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ",", "training", "=", "kwargs", ".", "get", "(", "\"training\"", ",", "False", ")", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "\n", "return", "outputs", "# logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaForTokenClassification.__init__": [[435, 443], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_roberta.TFRobertaMainLayer", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFRobertaForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "TFRobertaMainLayer", "(", "config", ",", "name", "=", "\"roberta\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"classifier\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_roberta.TFRobertaForTokenClassification.call": [[445, 456], ["modeling_tf_roberta.TFRobertaForTokenClassification.roberta", "modeling_tf_roberta.TFRobertaForTokenClassification.dropout", "modeling_tf_roberta.TFRobertaForTokenClassification.classifier", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ",", "training", "=", "kwargs", ".", "get", "(", "\"training\"", ",", "False", ")", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# scores, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_xlnet_original_tf_checkpoint_to_pytorch.convert_xlnet_checkpoint_to_pytorch": [[51, 80], ["transformers.XLNetConfig.from_json_file", "transformers.load_tf_weights_in_xlnet", "os.path.join", "os.path.join", "print", "torch.save", "print", "finetuning_task.lower", "print", "transformers.XLNetForSequenceClassification", "transformers.XLNetLMHeadModel.state_dict", "open", "f.write", "transformers.XLNetForQuestionAnswering", "transformers.XLNetLMHeadModel", "os.path.abspath", "os.path.abspath", "XLNetConfig.from_json_file.to_json_string", "str"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.load_tf_weights_in_xlnet", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_json_string"], ["def", "convert_xlnet_checkpoint_to_pytorch", "(", "\n", "tf_checkpoint_path", ",", "bert_config_file", ",", "pytorch_dump_folder_path", ",", "finetuning_task", "=", "None", "\n", ")", ":", "\n", "# Initialise PyTorch model", "\n", "    ", "config", "=", "XLNetConfig", ".", "from_json_file", "(", "bert_config_file", ")", "\n", "\n", "finetuning_task", "=", "finetuning_task", ".", "lower", "(", ")", "if", "finetuning_task", "is", "not", "None", "else", "\"\"", "\n", "if", "finetuning_task", "in", "GLUE_TASKS_NUM_LABELS", ":", "\n", "        ", "print", "(", "\"Building PyTorch XLNetForSequenceClassification model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "config", ".", "finetuning_task", "=", "finetuning_task", "\n", "config", ".", "num_labels", "=", "GLUE_TASKS_NUM_LABELS", "[", "finetuning_task", "]", "\n", "model", "=", "XLNetForSequenceClassification", "(", "config", ")", "\n", "", "elif", "\"squad\"", "in", "finetuning_task", ":", "\n", "        ", "config", ".", "finetuning_task", "=", "finetuning_task", "\n", "model", "=", "XLNetForQuestionAnswering", "(", "config", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "XLNetLMHeadModel", "(", "config", ")", "\n", "\n", "# Load weights from tf checkpoint", "\n", "", "load_tf_weights_in_xlnet", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "WEIGHTS_NAME", ")", "\n", "pytorch_config_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "CONFIG_NAME", ")", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_weights_dump_path", ")", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_config_dump_path", ")", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5LayerNorm.__init__": [[49, 55], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "epsilon", "=", "1e-6", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Construct a layernorm module in the T5 style\n            No bias and no substraction of mean.\n        \"\"\"", "\n", "super", "(", "TFT5LayerNorm", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "variance_epsilon", "=", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5LayerNorm.build": [[56, 60], ["modeling_tf_t5.TFT5LayerNorm.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "\"\"\"Build shared word embedding layer \"\"\"", "\n", "self", ".", "weight", "=", "self", ".", "add_weight", "(", "\"weight\"", ",", "shape", "=", "(", "input_shape", "[", "-", "1", "]", ",", ")", ",", "initializer", "=", "\"ones\"", ")", "\n", "super", "(", "TFT5LayerNorm", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5LayerNorm.call": [[61, 65], ["tensorflow.math.reduce_mean", "tensorflow.math.square", "tensorflow.math.rsqrt"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "x", ")", ":", "\n", "        ", "variance", "=", "tf", ".", "math", ".", "reduce_mean", "(", "tf", ".", "math", ".", "square", "(", "x", ")", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "x", "=", "x", "*", "tf", ".", "math", ".", "rsqrt", "(", "variance", "+", "self", ".", "variance_epsilon", ")", "\n", "return", "self", ".", "weight", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5DenseReluDense.__init__": [[68, 74], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFT5DenseReluDense", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "wi", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "d_ff", ",", "use_bias", "=", "False", ",", "name", "=", "\"wi\"", ")", "\n", "self", ".", "wo", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "config", ".", "d_model", ",", "use_bias", "=", "False", ",", "name", "=", "\"wo\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "self", ".", "act", "=", "tf", ".", "keras", ".", "activations", ".", "relu", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5DenseReluDense.call": [[75, 81], ["modeling_tf_t5.TFT5DenseReluDense.wi", "modeling_tf_t5.TFT5DenseReluDense.act", "modeling_tf_t5.TFT5DenseReluDense.dropout", "modeling_tf_t5.TFT5DenseReluDense.wo"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ",", "training", "=", "False", ")", ":", "\n", "        ", "h", "=", "self", ".", "wi", "(", "hidden_states", ")", "\n", "h", "=", "self", ".", "act", "(", "h", ")", "\n", "h", "=", "self", ".", "dropout", "(", "h", ",", "training", "=", "training", ")", "\n", "h", "=", "self", ".", "wo", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5LayerFF.__init__": [[84, 89], ["super().__init__", "modeling_tf_t5.TFT5DenseReluDense", "modeling_tf_t5.TFT5LayerNorm", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFT5LayerFF", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "DenseReluDense", "=", "TFT5DenseReluDense", "(", "config", ",", "name", "=", "\"DenseReluDense\"", ")", "\n", "self", ".", "layer_norm", "=", "TFT5LayerNorm", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "\"layer_norm\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5LayerFF.call": [[90, 95], ["modeling_tf_t5.TFT5LayerFF.layer_norm", "modeling_tf_t5.TFT5LayerFF.DenseReluDense", "modeling_tf_t5.TFT5LayerFF.dropout"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ",", "training", "=", "False", ")", ":", "\n", "        ", "norm_x", "=", "self", ".", "layer_norm", "(", "hidden_states", ")", "\n", "y", "=", "self", ".", "DenseReluDense", "(", "norm_x", ",", "training", "=", "training", ")", "\n", "layer_output", "=", "hidden_states", "+", "self", ".", "dropout", "(", "y", ",", "training", "=", "training", ")", "\n", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5Attention.__init__": [[100, 125], ["super().__init__", "next", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "set", "tensorflow.keras.layers.Embedding"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "has_relative_attention_bias", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFT5Attention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "layer_id", "=", "next", "(", "TFT5Attention", ".", "NEW_ID", ")", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "self", ".", "has_relative_attention_bias", "=", "has_relative_attention_bias", "\n", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "relative_attention_num_buckets", "=", "config", ".", "relative_attention_num_buckets", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "d_kv", "=", "config", ".", "d_kv", "\n", "self", ".", "n_heads", "=", "config", ".", "num_heads", "\n", "self", ".", "inner_dim", "=", "self", ".", "n_heads", "*", "self", ".", "d_kv", "\n", "\n", "# Mesh TensorFlow initialization to avoid scaling before softmax", "\n", "self", ".", "q", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "inner_dim", ",", "use_bias", "=", "False", ",", "name", "=", "\"q\"", ")", "\n", "self", ".", "k", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "inner_dim", ",", "use_bias", "=", "False", ",", "name", "=", "\"k\"", ")", "\n", "self", ".", "v", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "inner_dim", ",", "use_bias", "=", "False", ",", "name", "=", "\"v\"", ")", "\n", "self", ".", "o", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "self", ".", "d_model", ",", "use_bias", "=", "False", ",", "name", "=", "\"o\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n", "if", "self", ".", "has_relative_attention_bias", ":", "\n", "            ", "self", ".", "relative_attention_bias", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "\n", "self", ".", "relative_attention_num_buckets", ",", "self", ".", "n_heads", ",", "name", "=", "\"relative_attention_bias\"", "\n", ")", "\n", "", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5Attention.prune_heads": [[126, 128], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5Attention._relative_position_bucket": [[129, 174], ["tensorflow.math.less", "tensorflow.math.minimum", "tensorflow.where", "tensorflow.math.abs", "tensorflow.math.maximum", "tensorflow.dtypes.cast", "tensorflow.dtypes.cast", "tensorflow.math.less", "tensorflow.math.log", "math.log", "tensorflow.dtypes.cast"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_relative_position_bucket", "(", "relative_position", ",", "bidirectional", "=", "True", ",", "num_buckets", "=", "32", ",", "max_distance", "=", "128", ")", ":", "\n", "        ", "\"\"\"\n        Adapted from Mesh Tensorflow:\n        https://github.com/tensorflow/mesh/blob/0cb87fe07da627bf0b7e60475d59f95ed6b5be3d/mesh_tensorflow/transformer/transformer_layers.py#L593\n\n        Translate relative position to a bucket number for relative attention.\n        The relative position is defined as memory_position - query_position, i.e.\n        the distance in tokens from the attending position to the attended-to\n        position.  If bidirectional=False, then positive relative positions are\n        invalid.\n        We use smaller buckets for small absolute relative_position and larger buckets\n        for larger absolute relative_positions.  All relative positions >=max_distance\n        map to the same bucket.  All relative positions <=-max_distance map to the\n        same bucket.  This should allow for more graceful generalization to longer\n        sequences than the model has been trained on.\n        Args:\n            relative_position: an int32 Tensor\n            bidirectional: a boolean - whether the attention is bidirectional\n            num_buckets: an integer\n            max_distance: an integer\n        Returns:\n            a Tensor with the same shape as relative_position, containing int32\n            values in the range [0, num_buckets)\n        \"\"\"", "\n", "ret", "=", "0", "\n", "n", "=", "-", "relative_position", "\n", "if", "bidirectional", ":", "\n", "            ", "num_buckets", "//=", "2", "\n", "ret", "+=", "tf", ".", "dtypes", ".", "cast", "(", "tf", ".", "math", ".", "less", "(", "n", ",", "0", ")", ",", "tf", ".", "int32", ")", "*", "num_buckets", "\n", "n", "=", "tf", ".", "math", ".", "abs", "(", "n", ")", "\n", "", "else", ":", "\n", "            ", "n", "=", "tf", ".", "math", ".", "maximum", "(", "n", ",", "0", ")", "\n", "# now n is in the range [0, inf)", "\n", "", "max_exact", "=", "num_buckets", "//", "2", "\n", "is_small", "=", "tf", ".", "math", ".", "less", "(", "n", ",", "max_exact", ")", "\n", "val_if_large", "=", "max_exact", "+", "tf", ".", "dtypes", ".", "cast", "(", "\n", "tf", ".", "math", ".", "log", "(", "tf", ".", "dtypes", ".", "cast", "(", "n", ",", "tf", ".", "float32", ")", "/", "max_exact", ")", "\n", "/", "math", ".", "log", "(", "max_distance", "/", "max_exact", ")", "\n", "*", "(", "num_buckets", "-", "max_exact", ")", ",", "\n", "tf", ".", "int32", ",", "\n", ")", "\n", "val_if_large", "=", "tf", ".", "math", ".", "minimum", "(", "val_if_large", ",", "num_buckets", "-", "1", ")", "\n", "ret", "+=", "tf", ".", "where", "(", "is_small", ",", "n", ",", "val_if_large", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5Attention.compute_bias": [[175, 186], ["modeling_tf_t5.TFT5Attention._relative_position_bucket", "modeling_tf_t5.TFT5Attention.relative_attention_bias", "tensorflow.expand_dims", "tensorflow.range", "tensorflow.range", "tensorflow.transpose"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Attention._relative_position_bucket"], ["", "def", "compute_bias", "(", "self", ",", "qlen", ",", "klen", ")", ":", "\n", "        ", "\"\"\" Compute binned relative position bias \"\"\"", "\n", "context_position", "=", "tf", ".", "range", "(", "qlen", ")", "[", ":", ",", "None", "]", "\n", "memory_position", "=", "tf", ".", "range", "(", "klen", ")", "[", "None", ",", ":", "]", "\n", "relative_position", "=", "memory_position", "-", "context_position", "# shape (qlen, klen)", "\n", "rp_bucket", "=", "self", ".", "_relative_position_bucket", "(", "\n", "relative_position", ",", "bidirectional", "=", "not", "self", ".", "is_decoder", ",", "num_buckets", "=", "self", ".", "relative_attention_num_buckets", "\n", ")", "\n", "values", "=", "self", ".", "relative_attention_bias", "(", "rp_bucket", ")", "# shape (qlen, klen, num_heads)", "\n", "values", "=", "tf", ".", "expand_dims", "(", "tf", ".", "transpose", "(", "values", ",", "[", "2", ",", "0", ",", "1", "]", ")", ",", "axis", "=", "0", ")", "# shape (1, num_heads, qlen, klen)", "\n", "return", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5Attention.call": [[187, 258], ["modeling_tf_utils.shape_list", "modeling_tf_t5.TFT5Attention.call.shape"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "input", ",", "mask", "=", "None", ",", "kv", "=", "None", ",", "position_bias", "=", "None", ",", "cache", "=", "None", ",", "head_mask", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Self-attention (if kv is None) or attention over source sentence (provided by kv).\n        \"\"\"", "\n", "# Input is (bs, qlen, dim)", "\n", "# Mask is (bs, klen) (non-causal) or (bs, klen, klen)", "\n", "bs", ",", "qlen", ",", "dim", "=", "shape_list", "(", "input", ")", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "klen", "=", "qlen", "if", "cache", "is", "None", "else", "cache", "[", "\"slen\"", "]", "+", "qlen", "\n", "", "else", ":", "\n", "            ", "klen", "=", "shape_list", "(", "kv", ")", "[", "1", "]", "\n", "\n", "", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  projection \"\"\"", "\n", "return", "tf", ".", "transpose", "(", "tf", ".", "reshape", "(", "x", ",", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", ",", "self", ".", "d_kv", ")", ")", ",", "perm", "=", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  compute context \"\"\"", "\n", "return", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "x", ",", "perm", "=", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", ",", "(", "bs", ",", "-", "1", ",", "self", ".", "inner_dim", ")", ")", "\n", "\n", "", "q", "=", "shape", "(", "self", ".", "q", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "k", "=", "shape", "(", "self", ".", "k", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "", "elif", "cache", "is", "None", "or", "self", ".", "layer_id", "not", "in", "cache", ":", "\n", "            ", "k", "=", "v", "=", "kv", "\n", "k", "=", "shape", "(", "self", ".", "k", "(", "k", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v", "(", "v", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "\n", "", "if", "cache", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "layer_id", "in", "cache", ":", "\n", "                ", "if", "kv", "is", "None", ":", "\n", "                    ", "k_", ",", "v_", "=", "cache", "[", "self", ".", "layer_id", "]", "\n", "k", "=", "tf", ".", "concat", "(", "[", "k_", ",", "k", "]", ",", "axis", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "v", "=", "tf", ".", "concat", "(", "[", "v_", ",", "v", "]", ",", "axis", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "", "else", ":", "\n", "                    ", "k", ",", "v", "=", "cache", "[", "self", ".", "layer_id", "]", "\n", "", "", "cache", "[", "self", ".", "layer_id", "]", "=", "(", "k", ",", "v", ")", "\n", "\n", "# q = q / math.sqrt(dim_per_head)                                     # No scaling in T5", "\n", "# scores = tf.matmul(q, k, transpose_b=True)                            # (bs, n_heads, qlen, klen)", "\n", "", "scores", "=", "tf", ".", "einsum", "(", "\"bnqd,bnkd->bnqk\"", ",", "q", ",", "k", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "if", "position_bias", "is", "None", ":", "\n", "            ", "if", "not", "self", ".", "has_relative_attention_bias", ":", "\n", "                ", "raise", "ValueError", "(", "\"No position_bias provided and no weights to compute position_bias\"", ")", "\n", "", "position_bias", "=", "self", ".", "compute_bias", "(", "qlen", ",", "klen", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "                ", "position_bias", "=", "position_bias", "+", "mask", "\n", "# mask = (mask == 0).expand_as(scores)                              # (bs, n_heads, qlen, klen)", "\n", "# scores.masked_fill_(mask, -float('inf'))                          # (bs, n_heads, qlen, klen)", "\n", "\n", "", "", "scores", "+=", "position_bias", "\n", "weights", "=", "tf", ".", "nn", ".", "softmax", "(", "scores", ",", "axis", "=", "-", "1", ")", "# (bs, n_heads, qlen, klen)", "\n", "weights", "=", "self", ".", "dropout", "(", "weights", ",", "training", "=", "training", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "weights", "=", "weights", "*", "head_mask", "\n", "\n", "", "context", "=", "tf", ".", "matmul", "(", "weights", ",", "v", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "context", "=", "unshape", "(", "context", ")", "# (bs, qlen, dim)", "\n", "\n", "context", "=", "self", ".", "o", "(", "context", ")", "\n", "\n", "outputs", "=", "(", "context", ",", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "weights", ",", ")", "\n", "", "if", "self", ".", "has_relative_attention_bias", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "position_bias", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5LayerSelfAttention.__init__": [[261, 268], ["super().__init__", "modeling_tf_t5.TFT5Attention", "modeling_tf_t5.TFT5LayerNorm", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "has_relative_attention_bias", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFT5LayerSelfAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "SelfAttention", "=", "TFT5Attention", "(", "\n", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ",", "name", "=", "\"SelfAttention\"", "\n", ")", "\n", "self", ".", "layer_norm", "=", "TFT5LayerNorm", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "\"layer_norm\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5LayerSelfAttention.call": [[269, 278], ["modeling_tf_t5.TFT5LayerSelfAttention.layer_norm", "modeling_tf_t5.TFT5LayerSelfAttention.SelfAttention", "modeling_tf_t5.TFT5LayerSelfAttention.dropout"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ",", "attention_mask", "=", "None", ",", "position_bias", "=", "None", ",", "head_mask", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "norm_x", "=", "self", ".", "layer_norm", "(", "hidden_states", ")", "\n", "attention_output", "=", "self", ".", "SelfAttention", "(", "\n", "norm_x", ",", "mask", "=", "attention_mask", ",", "position_bias", "=", "position_bias", ",", "head_mask", "=", "head_mask", ",", "training", "=", "training", "\n", ")", "\n", "y", "=", "attention_output", "[", "0", "]", "\n", "layer_output", "=", "hidden_states", "+", "self", ".", "dropout", "(", "y", ",", "training", "=", "training", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "attention_output", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5LayerCrossAttention.__init__": [[281, 288], ["super().__init__", "modeling_tf_t5.TFT5Attention", "modeling_tf_t5.TFT5LayerNorm", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "has_relative_attention_bias", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFT5LayerCrossAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "EncDecAttention", "=", "TFT5Attention", "(", "\n", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ",", "name", "=", "\"EncDecAttention\"", "\n", ")", "\n", "self", ".", "layer_norm", "=", "TFT5LayerNorm", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "\"layer_norm\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5LayerCrossAttention.call": [[289, 298], ["modeling_tf_t5.TFT5LayerCrossAttention.layer_norm", "modeling_tf_t5.TFT5LayerCrossAttention.EncDecAttention", "modeling_tf_t5.TFT5LayerCrossAttention.dropout"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ",", "kv", ",", "attention_mask", "=", "None", ",", "position_bias", "=", "None", ",", "head_mask", "=", "None", ",", "training", "=", "False", ")", ":", "\n", "        ", "norm_x", "=", "self", ".", "layer_norm", "(", "hidden_states", ")", "\n", "attention_output", "=", "self", ".", "EncDecAttention", "(", "\n", "norm_x", ",", "mask", "=", "attention_mask", ",", "kv", "=", "kv", ",", "position_bias", "=", "position_bias", ",", "head_mask", "=", "head_mask", ",", "training", "=", "training", "\n", ")", "\n", "y", "=", "attention_output", "[", "0", "]", "\n", "layer_output", "=", "hidden_states", "+", "self", ".", "dropout", "(", "y", ",", "training", "=", "training", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "attention_output", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5Block.__init__": [[301, 317], ["super().__init__", "modeling_tf_t5.TFT5Block.layer.append", "modeling_tf_t5.TFT5LayerSelfAttention", "modeling_tf_t5.TFT5Block.layer.append", "modeling_tf_t5.TFT5Block.layer.append", "modeling_tf_t5.TFT5Block.layer.append", "modeling_tf_t5.TFT5LayerCrossAttention", "modeling_tf_t5.TFT5LayerFF", "modeling_tf_t5.TFT5LayerFF"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "has_relative_attention_bias", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFT5Block", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "self", ".", "layer", "=", "[", "]", "\n", "self", ".", "layer", ".", "append", "(", "\n", "TFT5LayerSelfAttention", "(", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ",", "name", "=", "\"layer_._0\"", ")", "\n", ")", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "self", ".", "layer", ".", "append", "(", "\n", "TFT5LayerCrossAttention", "(", "\n", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ",", "name", "=", "\"layer_._1\"", "\n", ")", "\n", ")", "\n", "self", ".", "layer", ".", "append", "(", "TFT5LayerFF", "(", "config", ",", "name", "=", "\"layer_._2\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer", ".", "append", "(", "TFT5LayerFF", "(", "config", ",", "name", "=", "\"layer_._1\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5Block.call": [[318, 356], ["None"], "methods", ["None"], ["", "", "def", "call", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "position_bias", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "encoder_decoder_position_bias", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "training", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self_attention_outputs", "=", "self", ".", "layer", "[", "0", "]", "(", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "position_bias", "=", "position_bias", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "training", "=", "training", ",", "\n", ")", "\n", "hidden_states", "=", "self_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "self_attention_outputs", "[", "1", ":", "]", "\n", "\n", "if", "not", "self", ".", "is_decoder", ":", "\n", "            ", "hidden_states", "=", "self", ".", "layer", "[", "1", "]", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "", "else", ":", "\n", "            ", "cross_attention_outputs", "=", "self", ".", "layer", "[", "1", "]", "(", "\n", "hidden_states", ",", "\n", "kv", "=", "encoder_hidden_states", ",", "\n", "attention_mask", "=", "encoder_attention_mask", ",", "\n", "position_bias", "=", "encoder_decoder_position_bias", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "training", "=", "training", ",", "\n", ")", "\n", "hidden_states", "=", "cross_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "outputs", "+", "cross_attention_outputs", "[", "1", ":", "]", "\n", "hidden_states", "=", "self", ".", "layer", "[", "2", "]", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "+", "outputs", "# add attentions if we output them", "\n", "return", "outputs", "# hidden-states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5MainLayer.__init__": [[363, 377], ["super().__init__", "modeling_tf_t5.TFT5LayerNorm", "tensorflow.keras.layers.Dropout", "modeling_tf_t5.TFT5Block", "range", "bool"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFT5MainLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "num_hidden_layers", "=", "config", ".", "num_layers", "\n", "\n", "self", ".", "block", "=", "[", "\n", "TFT5Block", "(", "config", ",", "has_relative_attention_bias", "=", "bool", "(", "i", "==", "0", ")", ",", "name", "=", "\"block_._{}\"", ".", "format", "(", "i", ")", ")", "\n", "for", "i", "in", "range", "(", "config", ".", "num_layers", ")", "\n", "]", "\n", "self", ".", "final_layer_norm", "=", "TFT5LayerNorm", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "\"final_layer_norm\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5MainLayer._resize_token_embeddings": [[378, 380], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "# Not implemented yet in the library fr TF 2.0 models", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5MainLayer._prune_heads": [[381, 383], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "raise", "NotImplementedError", "# Not implemented yet in the library fr TF 2.0 models", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5MainLayer.call": [[384, 506], ["tensorflow.cast", "len", "enumerate", "modeling_tf_t5.TFT5MainLayer.final_layer_norm", "modeling_tf_t5.TFT5MainLayer.dropout", "modeling_tf_utils.shape_list", "tensorflow.fill", "tensorflow.fill", "modeling_tf_utils.shape_list", "tensorflow.cast", "len", "layer_module", "modeling_tf_utils.shape_list", "tensorflow.range", "tensorflow.less_equal", "tensorflow.cast", "tensorflow.tile"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "training", "=", "False", ",", "\n", ")", ":", "\n", "\n", "        ", "batch_size", ",", "seq_length", "=", "shape_list", "(", "hidden_states", ")", "[", ":", "2", "]", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "tf", ".", "fill", "(", "(", "batch_size", ",", "seq_length", ")", ",", "1", ")", "\n", "", "if", "self", ".", "is_decoder", "and", "encoder_attention_mask", "is", "None", ":", "\n", "            ", "encoder_seq_length", "=", "encoder_hidden_states", ".", "shape", "[", "1", "]", "\n", "encoder_attention_mask", "=", "tf", ".", "fill", "(", "(", "batch_size", ",", "encoder_seq_length", ")", ",", "1", ")", "\n", "\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "attention_mask", "=", "tf", ".", "cast", "(", "attention_mask", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "num_dims_attention_mask", "=", "len", "(", "shape_list", "(", "attention_mask", ")", ")", "\n", "if", "num_dims_attention_mask", "==", "3", ":", "\n", "            ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "num_dims_attention_mask", "==", "2", ":", "\n", "# Provided a padding mask of dimensions [batch_size, seq_length]", "\n", "# - if the model is a decoder, apply a causal mask in addition to the padding mask", "\n", "# - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]", "\n", "            ", "if", "self", ".", "config", ".", "is_decoder", ":", "\n", "                ", "seq_ids", "=", "tf", ".", "range", "(", "seq_length", ")", "\n", "causal_mask", "=", "tf", ".", "less_equal", "(", "\n", "tf", ".", "tile", "(", "seq_ids", "[", "None", ",", "None", ",", ":", "]", ",", "(", "batch_size", ",", "seq_length", ",", "1", ")", ")", ",", "seq_ids", "[", "None", ",", ":", ",", "None", "]", "\n", ")", "\n", "causal_mask", "=", "tf", ".", "cast", "(", "causal_mask", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "extended_attention_mask", "=", "causal_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "*", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "\n", "# T5 has a mask that can compare sequence ids, we can simulate this here with this transposistion", "\n", "# Cf. https://github.com/tensorflow/mesh/blob/8d2465e9bc93129b913b5ccc6a59aa97abd96ec6/mesh_tensorflow/transformer/transformer_layers.py#L270", "\n", "# extended_attention_mask = tf.math.equal(extended_attention_mask,", "\n", "#                                         tf.transpose(extended_attention_mask, perm=(-1, -2)))", "\n", "\n", "", "", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "1e9", "\n", "\n", "if", "self", ".", "is_decoder", ":", "\n", "# If a 2D ou 3D attention mask is provided for the cross-attention", "\n", "# we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]", "\n", "            ", "encoder_attention_mask", "=", "tf", ".", "cast", "(", "encoder_attention_mask", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "num_dims_encoder_attention_mask", "=", "len", "(", "shape_list", "(", "encoder_attention_mask", ")", ")", "\n", "if", "num_dims_encoder_attention_mask", "==", "3", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "if", "num_dims_encoder_attention_mask", "==", "2", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "\n", "# T5 has a mask that can compare sequence ids, we can simulate this here with this transposistion", "\n", "# Cf. https://github.com/tensorflow/mesh/blob/8d2465e9bc93129b913b5ccc6a59aa97abd96ec6/mesh_tensorflow/transformer/transformer_layers.py#L270", "\n", "# encoder_extended_attention_mask = tf.math.equal(encoder_extended_attention_mask,", "\n", "#                                         tf.transpose(encoder_extended_attention_mask, perm=(-1, -2)))", "\n", "\n", "", "encoder_extended_attention_mask", "=", "(", "1.0", "-", "encoder_extended_attention_mask", ")", "*", "-", "1e9", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "num_hidden_layers", "\n", "# head_mask = tf.constant([0] * self.num_hidden_layers)", "\n", "\n", "", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "position_bias", "=", "None", "\n", "encoder_decoder_position_bias", "=", "None", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "block", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "position_bias", "=", "position_bias", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", "encoder_decoder_position_bias", "=", "encoder_decoder_position_bias", ",", "\n", "head_mask", "=", "head_mask", "[", "i", "]", ",", "\n", "training", "=", "training", ",", "\n", ")", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "if", "i", "==", "0", ":", "\n", "# We share the position biases between the layers - the first layer store them", "\n", "# layer_outputs = hidden-states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "                ", "position_bias", "=", "layer_outputs", "[", "2", "if", "self", ".", "output_attentions", "else", "1", "]", "\n", "if", "self", ".", "is_decoder", ":", "\n", "                    ", "encoder_decoder_position_bias", "=", "layer_outputs", "[", "4", "if", "self", ".", "output_attentions", "else", "2", "]", "\n", "\n", "", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "final_layer_norm", "(", "hidden_states", ")", "\n", "layer_output", "=", "self", ".", "dropout", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "\n", "# Add last layer", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5PreTrainedModel.dummy_inputs": [[524, 534], ["tensorflow.constant", "tensorflow.constant"], "methods", ["None"], ["@", "property", "\n", "def", "dummy_inputs", "(", "self", ")", ":", "\n", "        ", "input_ids", "=", "tf", ".", "constant", "(", "DUMMY_INPUTS", ")", "\n", "input_mask", "=", "tf", ".", "constant", "(", "DUMMY_MASK", ")", "\n", "dummy_inputs", "=", "{", "\n", "\"decoder_input_ids\"", ":", "input_ids", ",", "\n", "\"encoder_input_ids\"", ":", "input_ids", ",", "\n", "\"decoder_attention_mask\"", ":", "input_mask", ",", "\n", "}", "\n", "return", "dummy_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5Model.__init__": [[635, 645], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_utils.TFSharedEmbeddings", "copy.deepcopy", "modeling_tf_t5.TFT5MainLayer", "copy.deepcopy", "modeling_tf_t5.TFT5MainLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFT5Model", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "shared", "=", "TFSharedEmbeddings", "(", "config", ".", "vocab_size", ",", "config", ".", "d_model", ",", "name", "=", "\"shared\"", ")", "\n", "\n", "encoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "self", ".", "encoder", "=", "TFT5MainLayer", "(", "encoder_config", ",", "name", "=", "\"encoder\"", ")", "\n", "\n", "decoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "decoder_config", ".", "is_decoder", "=", "True", "\n", "self", ".", "decoder", "=", "TFT5MainLayer", "(", "decoder_config", ",", "name", "=", "\"decoder\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5Model.get_input_embeddings": [[646, 648], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5Model.get_output_embeddings": [[649, 651], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5Model.call": [[652, 697], ["isinstance", "dict", "dict.copy", "dict.copy", "dict.copy.update", "dict.copy.update", "dict.copy.pop", "dict.copy.pop", "dict.copy.get", "modeling_tf_t5.TFT5Model.decoder", "kwargs.update", "dict", "dict", "dict.copy.pop", "modeling_tf_t5.TFT5Model.encoder", "dict.copy.pop", "modeling_tf_t5.TFT5Model.shared", "dict.copy.pop", "modeling_tf_t5.TFT5Model.shared", "kwargs.items", "kwargs.items", "k.startswith", "kwargs.items", "k.startswith", "k.startswith", "k.startswith", "len", "len"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "decoder_input_ids", ",", "**", "kwargs", ")", ":", "\n", "# We allow two types of multi-inputs:", "\n", "# - traditional keyword arguments in the call method", "\n", "# - all the arguments provided as a dict in the first positional argument of call", "\n", "# The last option is useful to use the tf.keras fit() method.", "\n", "\n", "        ", "if", "isinstance", "(", "decoder_input_ids", ",", "dict", ")", ":", "\n", "            ", "kwargs", ".", "update", "(", "decoder_input_ids", ")", "\n", "", "else", ":", "\n", "            ", "kwargs", "[", "\"decoder_input_ids\"", "]", "=", "decoder_input_ids", "\n", "\n", "", "kwargs_common", "=", "dict", "(", "\n", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "if", "not", "k", ".", "startswith", "(", "\"encoder_\"", ")", "and", "not", "k", ".", "startswith", "(", "\"decoder_\"", ")", "\n", ")", "\n", "kwargs_encoder", "=", "kwargs_common", ".", "copy", "(", ")", "\n", "kwargs_decoder", "=", "kwargs_common", ".", "copy", "(", ")", "\n", "kwargs_encoder", ".", "update", "(", "dict", "(", "(", "k", "[", "len", "(", "\"encoder_\"", ")", ":", "]", ",", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "if", "k", ".", "startswith", "(", "\"encoder_\"", ")", ")", ")", "\n", "kwargs_decoder", ".", "update", "(", "dict", "(", "(", "k", "[", "len", "(", "\"decoder_\"", ")", ":", "]", ",", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "if", "k", ".", "startswith", "(", "\"decoder_\"", ")", ")", ")", "\n", "\n", "# Encode if needed (training, first prediction pass)", "\n", "encoder_hidden_states", "=", "kwargs_encoder", ".", "pop", "(", "\"hidden_states\"", ",", "None", ")", "\n", "if", "encoder_hidden_states", "is", "None", ":", "\n", "# Convert encoder inputs in embeddings if needed", "\n", "            ", "hidden_states", "=", "kwargs_encoder", ".", "pop", "(", "\"inputs_embeds\"", ",", "None", ")", "\n", "if", "hidden_states", "is", "None", ":", "\n", "                ", "encoder_inputs_ids", "=", "kwargs_encoder", ".", "pop", "(", "\"input_ids\"", ")", "\n", "hidden_states", "=", "self", ".", "shared", "(", "encoder_inputs_ids", ")", "# Convert inputs in embeddings", "\n", "\n", "", "encoder_outputs", "=", "self", ".", "encoder", "(", "hidden_states", ",", "**", "kwargs_encoder", ")", "\n", "encoder_hidden_states", "=", "encoder_outputs", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "encoder_outputs", "=", "(", ")", "\n", "\n", "# Decode", "\n", "# Convert decoder inputs in embeddings if needed", "\n", "", "hidden_states", "=", "kwargs_decoder", ".", "pop", "(", "\"inputs_embeds\"", ",", "None", ")", "\n", "if", "hidden_states", "is", "None", ":", "\n", "            ", "decoder_inputs_ids", "=", "kwargs_decoder", ".", "pop", "(", "\"input_ids\"", ")", "\n", "hidden_states", "=", "self", ".", "shared", "(", "decoder_inputs_ids", ")", "\n", "\n", "", "kwargs_decoder", "[", "\"encoder_hidden_states\"", "]", "=", "encoder_hidden_states", "\n", "kwargs_decoder", "[", "\"encoder_attention_mask\"", "]", "=", "kwargs_encoder", ".", "get", "(", "\"attention_mask\"", ",", "None", ")", "\n", "decoder_outputs", "=", "self", ".", "decoder", "(", "hidden_states", ",", "**", "kwargs_decoder", ")", "\n", "\n", "return", "decoder_outputs", "+", "encoder_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5WithLMHeadModel.__init__": [[726, 738], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_utils.TFSharedEmbeddings", "copy.deepcopy", "modeling_tf_t5.TFT5MainLayer", "copy.deepcopy", "modeling_tf_t5.TFT5MainLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFT5WithLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "model_dim", "=", "config", ".", "d_model", "\n", "\n", "self", ".", "shared", "=", "TFSharedEmbeddings", "(", "config", ".", "vocab_size", ",", "config", ".", "d_model", ",", "name", "=", "\"shared\"", ")", "\n", "\n", "encoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "self", ".", "encoder", "=", "TFT5MainLayer", "(", "encoder_config", ",", "name", "=", "\"encoder\"", ")", "\n", "\n", "decoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "decoder_config", ".", "is_decoder", "=", "True", "\n", "self", ".", "decoder", "=", "TFT5MainLayer", "(", "decoder_config", ",", "name", "=", "\"decoder\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5WithLMHeadModel.get_input_embeddings": [[739, 741], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5WithLMHeadModel.get_output_embeddings": [[742, 744], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_t5.TFT5WithLMHeadModel.call": [[745, 794], ["isinstance", "dict", "dict.copy", "dict.copy", "dict.copy.update", "dict.copy.update", "dict.copy.pop", "dict.copy.pop", "dict.copy.get", "modeling_tf_t5.TFT5WithLMHeadModel.decoder", "modeling_tf_t5.TFT5WithLMHeadModel.shared", "kwargs.update", "dict", "dict", "dict.copy.pop", "modeling_tf_t5.TFT5WithLMHeadModel.encoder", "dict.copy.pop", "modeling_tf_t5.TFT5WithLMHeadModel.shared", "dict.copy.pop", "modeling_tf_t5.TFT5WithLMHeadModel.shared", "kwargs.items", "kwargs.items", "k.startswith", "kwargs.items", "k.startswith", "k.startswith", "k.startswith", "len", "len"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "decoder_input_ids", ",", "**", "kwargs", ")", ":", "\n", "# We allow two types of multi-inputs:", "\n", "# - traditional keyword arguments in the call method", "\n", "# - all the arguments provided as a dict in the first positional argument of call", "\n", "# The last option is useful to use the tf.keras fit() method.", "\n", "\n", "        ", "if", "isinstance", "(", "decoder_input_ids", ",", "dict", ")", ":", "\n", "            ", "kwargs", ".", "update", "(", "decoder_input_ids", ")", "\n", "", "else", ":", "\n", "            ", "kwargs", "[", "\"decoder_input_ids\"", "]", "=", "decoder_input_ids", "\n", "\n", "", "kwargs_common", "=", "dict", "(", "\n", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "if", "not", "k", ".", "startswith", "(", "\"encoder_\"", ")", "and", "not", "k", ".", "startswith", "(", "\"decoder_\"", ")", "\n", ")", "\n", "kwargs_encoder", "=", "kwargs_common", ".", "copy", "(", ")", "\n", "kwargs_decoder", "=", "kwargs_common", ".", "copy", "(", ")", "\n", "kwargs_encoder", ".", "update", "(", "dict", "(", "(", "k", "[", "len", "(", "\"encoder_\"", ")", ":", "]", ",", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "if", "k", ".", "startswith", "(", "\"encoder_\"", ")", ")", ")", "\n", "kwargs_decoder", ".", "update", "(", "dict", "(", "(", "k", "[", "len", "(", "\"decoder_\"", ")", ":", "]", ",", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "if", "k", ".", "startswith", "(", "\"decoder_\"", ")", ")", ")", "\n", "\n", "# Encode if needed (training, first prediction pass)", "\n", "encoder_hidden_states", "=", "kwargs_encoder", ".", "pop", "(", "\"hidden_states\"", ",", "None", ")", "\n", "if", "encoder_hidden_states", "is", "None", ":", "\n", "# Convert encoder inputs in embeddings if needed", "\n", "            ", "hidden_states", "=", "kwargs_encoder", ".", "pop", "(", "\"inputs_embeds\"", ",", "None", ")", "\n", "if", "hidden_states", "is", "None", ":", "\n", "                ", "encoder_inputs_ids", "=", "kwargs_encoder", ".", "pop", "(", "\"input_ids\"", ")", "\n", "hidden_states", "=", "self", ".", "shared", "(", "encoder_inputs_ids", ")", "# Convert inputs in embeddings", "\n", "\n", "", "encoder_outputs", "=", "self", ".", "encoder", "(", "hidden_states", ",", "**", "kwargs_encoder", ")", "\n", "encoder_hidden_states", "=", "encoder_outputs", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "encoder_outputs", "=", "(", ")", "\n", "\n", "# Decode", "\n", "# Convert decoder inputs in embeddings if needed", "\n", "", "hidden_states", "=", "kwargs_decoder", ".", "pop", "(", "\"inputs_embeds\"", ",", "None", ")", "\n", "if", "hidden_states", "is", "None", ":", "\n", "            ", "decoder_inputs_ids", "=", "kwargs_decoder", ".", "pop", "(", "\"input_ids\"", ")", "\n", "hidden_states", "=", "self", ".", "shared", "(", "decoder_inputs_ids", ")", "\n", "\n", "", "kwargs_decoder", "[", "\"encoder_hidden_states\"", "]", "=", "encoder_hidden_states", "\n", "kwargs_decoder", "[", "\"encoder_attention_mask\"", "]", "=", "kwargs_encoder", ".", "get", "(", "\"attention_mask\"", ",", "None", ")", "\n", "decoder_outputs", "=", "self", ".", "decoder", "(", "hidden_states", ",", "**", "kwargs_decoder", ")", "\n", "\n", "sequence_output", "=", "decoder_outputs", "[", "0", "]", "*", "(", "self", ".", "model_dim", "**", "-", "0.5", ")", "\n", "lm_logits", "=", "self", ".", "shared", "(", "sequence_output", ",", "mode", "=", "\"linear\"", ")", "\n", "decoder_outputs", "=", "(", "lm_logits", ",", ")", "+", "decoder_outputs", "[", "1", ":", "]", "\n", "\n", "return", "decoder_outputs", "+", "encoder_outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_encoder_decoder.PreTrainedEncoderDecoder.__init__": [[39, 43], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ")", ":", "\n", "        ", "super", "(", "PreTrainedEncoderDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_encoder_decoder.PreTrainedEncoderDecoder.from_pretrained": [[44, 157], ["kwargs_common.copy", "kwargs_common.copy", "kwargs_common.copy.update", "kwargs_common.copy.update", "kwargs_common.copy.pop", "kwargs_common.copy.pop", "cls", "modeling_auto.AutoModel.from_pretrained", "modeling_auto.AutoModelWithLMHead.from_pretrained", "kwargs.items", "kwargs.items", "argument.startswith", "kwargs.items", "argument.startswith", "argument.startswith", "argument.startswith", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "\n", "cls", ",", "\n", "encoder_pretrained_model_name_or_path", "=", "None", ",", "\n", "decoder_pretrained_model_name_or_path", "=", "None", ",", "\n", "*", "model_args", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "r\"\"\" Instantiates an encoder and a decoder from one or two base classes of the library from pre-trained model checkpoints.\n\n\n        The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n        To train the model, you need to first set it back in training mode with `model.train()`\n\n        Params:\n            encoder_pretrained_model_name_or_path: information necessary to initiate the encoder. Either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/encoder``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n\n            decoder_pretrained_model_name_or_path: information necessary to initiate the decoder. Either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/decoder``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments.\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n                You can specify kwargs sepcific for the encoder and decoder by prefixing the key with `encoder_` and `decoder_` respectively. (e.g. ``decoder_output_attention=True``). The remaining kwargs will be passed to both encoders and decoders.\n\n        Examples::\n\n            model = PreTrainedEncoderDecoder.from_pretained('bert-base-uncased', 'bert-base-uncased') # initialize Bert2Bert\n        \"\"\"", "\n", "\n", "# keyword arguments come in 3 flavors: encoder-specific (prefixed by", "\n", "# `encoder_`), decoder-specific (prefixed by `decoder_`) and those", "\n", "# that apply to the model as a whole.", "\n", "# We let the specific kwargs override the common ones in case of conflict.", "\n", "kwargs_common", "=", "{", "\n", "argument", ":", "value", "\n", "for", "argument", ",", "value", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "not", "argument", ".", "startswith", "(", "\"encoder_\"", ")", "and", "not", "argument", ".", "startswith", "(", "\"decoder_\"", ")", "\n", "}", "\n", "kwargs_decoder", "=", "kwargs_common", ".", "copy", "(", ")", "\n", "kwargs_encoder", "=", "kwargs_common", ".", "copy", "(", ")", "\n", "kwargs_encoder", ".", "update", "(", "\n", "{", "\n", "argument", "[", "len", "(", "\"encoder_\"", ")", ":", "]", ":", "value", "\n", "for", "argument", ",", "value", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "argument", ".", "startswith", "(", "\"encoder_\"", ")", "\n", "}", "\n", ")", "\n", "kwargs_decoder", ".", "update", "(", "\n", "{", "\n", "argument", "[", "len", "(", "\"decoder_\"", ")", ":", "]", ":", "value", "\n", "for", "argument", ",", "value", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "argument", ".", "startswith", "(", "\"decoder_\"", ")", "\n", "}", "\n", ")", "\n", "\n", "# Load and initialize the encoder and decoder", "\n", "# The distinction between encoder and decoder at the model level is made", "\n", "# by the value of the flag `is_decoder` that we need to set correctly.", "\n", "encoder", "=", "kwargs_encoder", ".", "pop", "(", "\"model\"", ",", "None", ")", "\n", "if", "encoder", "is", "None", ":", "\n", "            ", "encoder", "=", "AutoModel", ".", "from_pretrained", "(", "encoder_pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs_encoder", ")", "\n", "", "encoder", ".", "config", ".", "is_decoder", "=", "False", "\n", "\n", "decoder", "=", "kwargs_decoder", ".", "pop", "(", "\"model\"", ",", "None", ")", "\n", "if", "decoder", "is", "None", ":", "\n", "            ", "decoder", "=", "AutoModelWithLMHead", ".", "from_pretrained", "(", "decoder_pretrained_model_name_or_path", ",", "**", "kwargs_decoder", ")", "\n", "", "decoder", ".", "config", ".", "is_decoder", "=", "True", "\n", "\n", "model", "=", "cls", "(", "encoder", ",", "decoder", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_encoder_decoder.PreTrainedEncoderDecoder.save_pretrained": [[158, 203], ["modeling_encoder_decoder.PreTrainedEncoderDecoder.encoder.save_pretrained", "modeling_encoder_decoder.PreTrainedEncoderDecoder.decoder.save_pretrained", "os.path.exists", "os.mkdir", "len", "os.path.exists", "os.mkdir", "os.path.join", "os.path.exists", "os.mkdir", "os.path.join", "os.listdir", "os.path.isdir", "print", "os.listdir", "os.rmdir", "len", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.remove", "os.path.join", "os.listdir", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a Seq2Seq model and its configuration file in a format such\n        that it can be loaded using `:func:`~transformers.PreTrainedEncoderDecoder.from_pretrained`\n\n        We save the encoder' and decoder's parameters in two separate directories.\n        \"\"\"", "\n", "\n", "# If the root output directory does not exist, create it", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "save_directory", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "save_directory", ")", "\n", "\n", "# Check whether the output directory is empty or not", "\n", "", "sub_directories", "=", "[", "\n", "directory", "\n", "for", "directory", "in", "os", ".", "listdir", "(", "save_directory", ")", "\n", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "save_directory", ",", "directory", ")", ")", "\n", "]", "\n", "\n", "if", "len", "(", "sub_directories", ")", ">", "0", ":", "\n", "            ", "if", "\"encoder\"", "in", "sub_directories", "and", "\"decoder\"", "in", "sub_directories", ":", "\n", "                ", "print", "(", "\n", "\"WARNING: there is an older version of encoder-decoder saved in\"", "\n", "+", "\" the output directory. The default behaviour is to overwrite them.\"", "\n", ")", "\n", "\n", "# Empty the output directory", "\n", "", "for", "directory_to_remove", "in", "sub_directories", ":", "\n", "# Remove all files into the subdirectory", "\n", "                ", "files_to_remove", "=", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "save_directory", ",", "directory_to_remove", ")", ")", "\n", "for", "file_to_remove", "in", "files_to_remove", ":", "\n", "                    ", "os", ".", "remove", "(", "os", ".", "path", ".", "join", "(", "save_directory", ",", "directory_to_remove", ",", "file_to_remove", ")", ")", "\n", "# Remove the subdirectory itself", "\n", "", "os", ".", "rmdir", "(", "os", ".", "path", ".", "join", "(", "save_directory", ",", "directory_to_remove", ")", ")", "\n", "\n", "", "assert", "len", "(", "os", ".", "listdir", "(", "save_directory", ")", ")", "==", "0", "# sanity check", "\n", "\n", "# Create the \"encoder\" directory inside the output directory and save the encoder into it", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "save_directory", ",", "\"encoder\"", ")", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "save_directory", ",", "\"encoder\"", ")", ")", "\n", "", "self", ".", "encoder", ".", "save_pretrained", "(", "os", ".", "path", ".", "join", "(", "save_directory", ",", "\"encoder\"", ")", ")", "\n", "\n", "# Create the \"encoder\" directory inside the output directory and save the decoder into it", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "save_directory", ",", "\"decoder\"", ")", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "save_directory", ",", "\"decoder\"", ")", ")", "\n", "", "self", ".", "decoder", ".", "save_pretrained", "(", "os", ".", "path", ".", "join", "(", "save_directory", ",", "\"decoder\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_encoder_decoder.PreTrainedEncoderDecoder.forward": [[204, 237], ["modeling_encoder_decoder.PreTrainedEncoderDecoder.prepare_model_kwargs", "kwargs_encoder.pop", "modeling_encoder_decoder.PreTrainedEncoderDecoder.decoder", "modeling_encoder_decoder.PreTrainedEncoderDecoder.encoder"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_encoder_decoder.PreTrainedEncoderDecoder.prepare_model_kwargs"], ["", "def", "forward", "(", "self", ",", "encoder_input_ids", ",", "decoder_input_ids", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" The forward pass on a seq2eq depends what we are performing:\n\n        - During training we perform one forward pass through both the encoder\n          and decoder;\n        - During prediction, we perform one forward pass through the encoder,\n          and then perform several forward passes with the encoder's hidden\n          state through the decoder to decode a full sequence.\n\n        Therefore, we skip the forward pass on the encoder if an argument named\n        `encoder_hidden_state` is passed to this function.\n\n        Params:\n            encoder_input_ids: ``torch.LongTensor`` of shape ``(batch_size, sequence_length)``\n                Indices of encoder input sequence tokens in the vocabulary.\n            decoder_input_ids: ``torch.LongTensor`` of shape ``(batch_size, sequence_length)``\n                Indices of decoder input sequence tokens in the vocabulary.\n            kwargs: (`optional`) Remaining dictionary of keyword arguments.\n        \"\"\"", "\n", "kwargs_encoder", ",", "kwargs_decoder", "=", "self", ".", "prepare_model_kwargs", "(", "**", "kwargs", ")", "\n", "\n", "# Encode if needed (training, first prediction pass)", "\n", "encoder_hidden_states", "=", "kwargs_encoder", ".", "pop", "(", "\"hidden_states\"", ",", "None", ")", "\n", "if", "encoder_hidden_states", "is", "None", ":", "\n", "            ", "encoder_outputs", "=", "self", ".", "encoder", "(", "encoder_input_ids", ",", "**", "kwargs_encoder", ")", "\n", "encoder_hidden_states", "=", "encoder_outputs", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "encoder_outputs", "=", "(", ")", "\n", "\n", "", "kwargs_decoder", "[", "\"encoder_hidden_states\"", "]", "=", "encoder_hidden_states", "\n", "decoder_outputs", "=", "self", ".", "decoder", "(", "decoder_input_ids", ",", "encoder_hidden_states", ",", "**", "kwargs_decoder", ")", "\n", "\n", "return", "decoder_outputs", "+", "encoder_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_encoder_decoder.PreTrainedEncoderDecoder.prepare_model_kwargs": [[238, 273], ["kwargs_common.copy", "kwargs_common.copy", "kwargs_common.copy.update", "kwargs_common.copy.update", "kwargs_common.copy.get", "kwargs.items", "kwargs.items", "argument.startswith", "kwargs.items", "argument.startswith", "argument.startswith", "argument.startswith", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "prepare_model_kwargs", "(", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Prepare the encoder and decoder's keyword arguments.\n\n        Keyword arguments come in 3 flavors:\n        - encoder-specific (prefixed by `encoder_`)\n        - decoder-specific (prefixed by `decoder_`)\n        - those that apply to the model as whole.\n\n        We let the specific kwargs override the common ones in case of\n        conflict.\n        \"\"\"", "\n", "kwargs_common", "=", "{", "\n", "argument", ":", "value", "\n", "for", "argument", ",", "value", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "not", "argument", ".", "startswith", "(", "\"encoder_\"", ")", "and", "not", "argument", ".", "startswith", "(", "\"decoder_\"", ")", "\n", "}", "\n", "decoder_kwargs", "=", "kwargs_common", ".", "copy", "(", ")", "\n", "encoder_kwargs", "=", "kwargs_common", ".", "copy", "(", ")", "\n", "encoder_kwargs", ".", "update", "(", "\n", "{", "\n", "argument", "[", "len", "(", "\"encoder_\"", ")", ":", "]", ":", "value", "\n", "for", "argument", ",", "value", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "argument", ".", "startswith", "(", "\"encoder_\"", ")", "\n", "}", "\n", ")", "\n", "decoder_kwargs", ".", "update", "(", "\n", "{", "\n", "argument", "[", "len", "(", "\"decoder_\"", ")", ":", "]", ":", "value", "\n", "for", "argument", ",", "value", "in", "kwargs", ".", "items", "(", ")", "\n", "if", "argument", ".", "startswith", "(", "\"decoder_\"", ")", "\n", "}", "\n", ")", "\n", "decoder_kwargs", "[", "\"encoder_attention_mask\"", "]", "=", "encoder_kwargs", ".", "get", "(", "\"attention_mask\"", ",", "None", ")", "\n", "return", "encoder_kwargs", ",", "decoder_kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_encoder_decoder.Model2Model.__init__": [[292, 295], ["modeling_encoder_decoder.PreTrainedEncoderDecoder.__init__", "modeling_encoder_decoder.Model2Model.tie_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertForMaskedLM.tie_weights"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "Model2Model", ",", "self", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_encoder_decoder.Model2Model.tie_weights": [[296, 313], ["None"], "methods", ["None"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Tying the encoder and decoders' embeddings together.\n\n       We need for each to get down to the embedding weights. However the\n        different model classes are inconsistent to that respect:\n        - BertModel: embeddings.word_embeddings\n        - RoBERTa: embeddings.word_embeddings\n        - XLMModel: embeddings\n        - GPT2: wte\n        - BertForMaskedLM: bert.embeddings.word_embeddings\n        - RobertaForMaskedLM: roberta.embeddings.word_embeddings\n\n        argument of the XEmbedding layer for each model, but it is \"blocked\"\n        by a model-specific keyword (bert, )...\n        \"\"\"", "\n", "# self._tie_or_clone_weights(self.encoder, self.decoder)", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_encoder_decoder.Model2Model.from_pretrained": [[314, 332], ["modeling_encoder_decoder.PreTrainedEncoderDecoder.from_pretrained", "ValueError"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\n", "        ", "if", "(", "\n", "\"bert\"", "not", "in", "pretrained_model_name_or_path", "\n", "or", "\"roberta\"", "in", "pretrained_model_name_or_path", "\n", "or", "\"distilbert\"", "in", "pretrained_model_name_or_path", "\n", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only the Bert model is currently supported.\"", ")", "\n", "\n", "", "model", "=", "super", "(", "Model2Model", ",", "cls", ")", ".", "from_pretrained", "(", "\n", "encoder_pretrained_model_name_or_path", "=", "pretrained_model_name_or_path", ",", "\n", "decoder_pretrained_model_name_or_path", "=", "pretrained_model_name_or_path", ",", "\n", "*", "args", ",", "\n", "**", "kwargs", "\n", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_encoder_decoder.Model2LSTM.from_pretrained": [[335, 350], ["modeling_encoder_decoder.PreTrainedEncoderDecoder.from_pretrained", "kwargs.get", "torch.nn.LSTM", "ValueError", "kwargs.pop"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["    ", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "kwargs", ".", "get", "(", "\"decoder_model\"", ",", "None", ")", "is", "None", ":", "\n", "# We will create a randomly initilized LSTM model as decoder", "\n", "            ", "if", "\"decoder_config\"", "not", "in", "kwargs", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"To load an LSTM in Encoder-Decoder model, please supply either: \"", "\n", "\"    - a torch.nn.LSTM model as `decoder_model` parameter (`decoder_model=lstm_model`), or\"", "\n", "\"    - a dictionary of configuration parameters that will be used to initialize a\"", "\n", "\"      torch.nn.LSTM model as `decoder_config` keyword argument. \"", "\n", "\"      E.g. `decoder_config={'input_size': 768, 'hidden_size': 768, 'num_layers': 2}`\"", "\n", ")", "\n", "", "kwargs", "[", "\"decoder_model\"", "]", "=", "torch", ".", "nn", ".", "LSTM", "(", "kwargs", ".", "pop", "(", "\"decoder_config\"", ")", ")", "\n", "", "model", "=", "super", "(", "Model2LSTM", ",", "cls", ")", ".", "from_pretrained", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "return", "model", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.Embeddings.__init__": [[60, 71], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.LayerNorm", "torch.LayerNorm", "torch.Dropout", "torch.Dropout", "modeling_distilbert.create_sinusoidal_embeddings"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.create_sinusoidal_embeddings"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "Embeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "dim", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "dim", ")", "\n", "if", "config", ".", "sinusoidal_pos_embds", ":", "\n", "            ", "create_sinusoidal_embeddings", "(", "\n", "n_pos", "=", "config", ".", "max_position_embeddings", ",", "dim", "=", "config", ".", "dim", ",", "out", "=", "self", ".", "position_embeddings", ".", "weight", "\n", ")", "\n", "\n", "", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "dim", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.Embeddings.forward": [[72, 95], ["input_ids.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "modeling_distilbert.Embeddings.word_embeddings", "modeling_distilbert.Embeddings.position_embeddings", "modeling_distilbert.Embeddings.LayerNorm", "modeling_distilbert.Embeddings.dropout", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        input_ids: torch.tensor(bs, max_seq_length)\n            The token ids to embed.\n\n        Outputs\n        -------\n        embeddings: torch.tensor(bs, max_seq_length, dim)\n            The embedded tokens (plus position embeddings, no token_type embeddings)\n        \"\"\"", "\n", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "# (max_seq_length)", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "# (bs, max_seq_length)", "\n", "\n", "word_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "# (bs, max_seq_length, dim)", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "# (bs, max_seq_length, dim)", "\n", "\n", "embeddings", "=", "word_embeddings", "+", "position_embeddings", "# (bs, max_seq_length, dim)", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "# (bs, max_seq_length, dim)", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "# (bs, max_seq_length, dim)", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.MultiHeadSelfAttention.__init__": [[98, 114], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "set"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "MultiHeadSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_heads", "=", "config", ".", "n_heads", "\n", "self", ".", "dim", "=", "config", ".", "dim", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "config", ".", "attention_dropout", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "assert", "self", ".", "dim", "%", "self", ".", "n_heads", "==", "0", "\n", "\n", "self", ".", "q_lin", "=", "nn", ".", "Linear", "(", "in_features", "=", "config", ".", "dim", ",", "out_features", "=", "config", ".", "dim", ")", "\n", "self", ".", "k_lin", "=", "nn", ".", "Linear", "(", "in_features", "=", "config", ".", "dim", ",", "out_features", "=", "config", ".", "dim", ")", "\n", "self", ".", "v_lin", "=", "nn", ".", "Linear", "(", "in_features", "=", "config", ".", "dim", ",", "out_features", "=", "config", ".", "dim", ")", "\n", "self", ".", "out_lin", "=", "nn", ".", "Linear", "(", "in_features", "=", "config", ".", "dim", ",", "out_features", "=", "config", ".", "dim", ")", "\n", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.MultiHeadSelfAttention.prune_heads": [[115, 135], ["torch.ones", "torch.ones", "torch.ones", "torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_distilbert.MultiHeadSelfAttention.pruned_heads.union", "len", "set", "sum", "len", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "attention_head_size", "=", "self", ".", "dim", "//", "self", ".", "n_heads", "\n", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "n_heads", ",", "attention_head_size", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "\n", "for", "head", "in", "heads", ":", "\n", "            ", "head", "-=", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "# Prune linear layers", "\n", "self", ".", "q_lin", "=", "prune_linear_layer", "(", "self", ".", "q_lin", ",", "index", ")", "\n", "self", ".", "k_lin", "=", "prune_linear_layer", "(", "self", ".", "k_lin", ",", "index", ")", "\n", "self", ".", "v_lin", "=", "prune_linear_layer", "(", "self", ".", "v_lin", ",", "index", ")", "\n", "self", ".", "out_lin", "=", "prune_linear_layer", "(", "self", ".", "out_lin", ",", "index", ",", "dim", "=", "1", ")", "\n", "# Update hyper params", "\n", "self", ".", "n_heads", "=", "self", ".", "n_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "dim", "=", "attention_head_size", "*", "self", ".", "n_heads", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.MultiHeadSelfAttention.forward": [[136, 193], ["query.size", "key.size", "modeling_distilbert.MultiHeadSelfAttention.forward.shape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "mask", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        query: torch.tensor(bs, seq_length, dim)\n        key: torch.tensor(bs, seq_length, dim)\n        value: torch.tensor(bs, seq_length, dim)\n        mask: torch.tensor(bs, seq_length)\n\n        Outputs\n        -------\n        weights: torch.tensor(bs, n_heads, seq_length, seq_length)\n            Attention weights\n        context: torch.tensor(bs, seq_length, dim)\n            Contextualized layer. Optional: only if `output_attentions=True`\n        \"\"\"", "\n", "bs", ",", "q_length", ",", "dim", "=", "query", ".", "size", "(", ")", "\n", "k_length", "=", "key", ".", "size", "(", "1", ")", "\n", "# assert dim == self.dim, 'Dimensions do not match: %s input vs %s configured' % (dim, self.dim)", "\n", "# assert key.size() == value.size()", "\n", "\n", "dim_per_head", "=", "self", ".", "dim", "//", "self", ".", "n_heads", "\n", "\n", "mask_reshp", "=", "(", "bs", ",", "1", ",", "1", ",", "k_length", ")", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\" separate heads \"\"\"", "\n", "return", "x", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", ",", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\" group heads \"\"\"", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", "*", "dim_per_head", ")", "\n", "\n", "", "q", "=", "shape", "(", "self", ".", "q_lin", "(", "query", ")", ")", "# (bs, n_heads, q_length, dim_per_head)", "\n", "k", "=", "shape", "(", "self", ".", "k_lin", "(", "key", ")", ")", "# (bs, n_heads, k_length, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v_lin", "(", "value", ")", ")", "# (bs, n_heads, k_length, dim_per_head)", "\n", "\n", "q", "=", "q", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "# (bs, n_heads, q_length, dim_per_head)", "\n", "scores", "=", "torch", ".", "matmul", "(", "q", ",", "k", ".", "transpose", "(", "2", ",", "3", ")", ")", "# (bs, n_heads, q_length, k_length)", "\n", "mask", "=", "(", "mask", "==", "0", ")", ".", "view", "(", "mask_reshp", ")", ".", "expand_as", "(", "scores", ")", "# (bs, n_heads, q_length, k_length)", "\n", "scores", ".", "masked_fill_", "(", "mask", ",", "-", "float", "(", "\"inf\"", ")", ")", "# (bs, n_heads, q_length, k_length)", "\n", "\n", "weights", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "scores", ")", "# (bs, n_heads, q_length, k_length)", "\n", "weights", "=", "self", ".", "dropout", "(", "weights", ")", "# (bs, n_heads, q_length, k_length)", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "weights", "=", "weights", "*", "head_mask", "\n", "\n", "", "context", "=", "torch", ".", "matmul", "(", "weights", ",", "v", ")", "# (bs, n_heads, q_length, dim_per_head)", "\n", "context", "=", "unshape", "(", "context", ")", "# (bs, q_length, dim)", "\n", "context", "=", "self", ".", "out_lin", "(", "context", ")", "# (bs, q_length, dim)", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "return", "(", "context", ",", "weights", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "context", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.FFN.__init__": [[196, 205], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "FFN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "config", ".", "dropout", ")", "\n", "self", ".", "lin1", "=", "nn", ".", "Linear", "(", "in_features", "=", "config", ".", "dim", ",", "out_features", "=", "config", ".", "hidden_dim", ")", "\n", "self", ".", "lin2", "=", "nn", ".", "Linear", "(", "in_features", "=", "config", ".", "hidden_dim", ",", "out_features", "=", "config", ".", "dim", ")", "\n", "assert", "config", ".", "activation", "in", "[", "\"relu\"", ",", "\"gelu\"", "]", ",", "\"activation ({}) must be in ['relu', 'gelu']\"", ".", "format", "(", "\n", "config", ".", "activation", "\n", ")", "\n", "self", ".", "activation", "=", "gelu", "if", "config", ".", "activation", "==", "\"gelu\"", "else", "nn", ".", "ReLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.FFN.forward": [[206, 212], ["modeling_distilbert.FFN.lin1", "modeling_distilbert.FFN.activation", "modeling_distilbert.FFN.lin2", "modeling_distilbert.FFN.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "self", ".", "lin1", "(", "input", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "lin2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.TransformerBlock.__init__": [[215, 232], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "modeling_distilbert.MultiHeadSelfAttention", "torch.LayerNorm", "torch.LayerNorm", "modeling_distilbert.FFN", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransformerBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_heads", "=", "config", ".", "n_heads", "\n", "self", ".", "dim", "=", "config", ".", "dim", "\n", "self", ".", "hidden_dim", "=", "config", ".", "hidden_dim", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "config", ".", "dropout", ")", "\n", "self", ".", "activation", "=", "config", ".", "activation", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "assert", "config", ".", "dim", "%", "config", ".", "n_heads", "==", "0", "\n", "\n", "self", ".", "attention", "=", "MultiHeadSelfAttention", "(", "config", ")", "\n", "self", ".", "sa_layer_norm", "=", "nn", ".", "LayerNorm", "(", "normalized_shape", "=", "config", ".", "dim", ",", "eps", "=", "1e-12", ")", "\n", "\n", "self", ".", "ffn", "=", "FFN", "(", "config", ")", "\n", "self", ".", "output_layer_norm", "=", "nn", ".", "LayerNorm", "(", "normalized_shape", "=", "config", ".", "dim", ",", "eps", "=", "1e-12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.TransformerBlock.forward": [[233, 264], ["modeling_distilbert.TransformerBlock.attention", "modeling_distilbert.TransformerBlock.sa_layer_norm", "modeling_distilbert.TransformerBlock.ffn", "modeling_distilbert.TransformerBlock.output_layer_norm", "type"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "attn_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        x: torch.tensor(bs, seq_length, dim)\n        attn_mask: torch.tensor(bs, seq_length)\n\n        Outputs\n        -------\n        sa_weights: torch.tensor(bs, n_heads, seq_length, seq_length)\n            The attention weights\n        ffn_output: torch.tensor(bs, seq_length, dim)\n            The output of the transformer block contextualization.\n        \"\"\"", "\n", "# Self-Attention", "\n", "sa_output", "=", "self", ".", "attention", "(", "query", "=", "x", ",", "key", "=", "x", ",", "value", "=", "x", ",", "mask", "=", "attn_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "sa_output", ",", "sa_weights", "=", "sa_output", "# (bs, seq_length, dim), (bs, n_heads, seq_length, seq_length)", "\n", "", "else", ":", "# To handle these `output_attention` or `output_hidden_states` cases returning tuples", "\n", "            ", "assert", "type", "(", "sa_output", ")", "==", "tuple", "\n", "sa_output", "=", "sa_output", "[", "0", "]", "\n", "", "sa_output", "=", "self", ".", "sa_layer_norm", "(", "sa_output", "+", "x", ")", "# (bs, seq_length, dim)", "\n", "\n", "# Feed Forward Network", "\n", "ffn_output", "=", "self", ".", "ffn", "(", "sa_output", ")", "# (bs, seq_length, dim)", "\n", "ffn_output", "=", "self", ".", "output_layer_norm", "(", "ffn_output", "+", "sa_output", ")", "# (bs, seq_length, dim)", "\n", "\n", "output", "=", "(", "ffn_output", ",", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "output", "=", "(", "sa_weights", ",", ")", "+", "output", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.Transformer.__init__": [[267, 275], ["torch.Module.__init__", "modeling_distilbert.TransformerBlock", "torch.ModuleList", "torch.ModuleList", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "Transformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_layers", "=", "config", ".", "n_layers", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "layer", "=", "TransformerBlock", "(", "config", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "layer", ")", "for", "_", "in", "range", "(", "config", ".", "n_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.Transformer.forward": [[276, 324], ["enumerate", "layer_module", "len", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "attn_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n        x: torch.tensor(bs, seq_length, dim)\n            Input sequence embedded.\n        attn_mask: torch.tensor(bs, seq_length)\n            Attention mask on the sequence.\n\n        Outputs\n        -------\n        hidden_state: torch.tensor(bs, seq_length, dim)\n            Sequence of hiddens states in the last (top) layer\n        all_hidden_states: Tuple[torch.tensor(bs, seq_length, dim)]\n            Tuple of length n_layers with the hidden states from each layer.\n            Optional: only if output_hidden_states=True\n        all_attentions: Tuple[torch.tensor(bs, n_heads, seq_length, seq_length)]\n            Tuple of length n_layers with the attention weights from each layer\n            Optional: only if output_attentions=True\n        \"\"\"", "\n", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "\n", "hidden_state", "=", "x", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_state", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "x", "=", "hidden_state", ",", "attn_mask", "=", "attn_mask", ",", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "hidden_state", "=", "layer_outputs", "[", "-", "1", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "assert", "len", "(", "layer_outputs", ")", "==", "2", "\n", "attentions", "=", "layer_outputs", "[", "0", "]", "\n", "all_attentions", "=", "all_attentions", "+", "(", "attentions", ",", ")", "\n", "", "else", ":", "\n", "                ", "assert", "len", "(", "layer_outputs", ")", "==", "1", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_state", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_state", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.DistilBertPreTrainedModel._init_weights": [[337, 350], ["isinstance", "isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.weight.data.normal_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "            ", "if", "module", ".", "weight", ".", "requires_grad", ":", "\n", "                ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.DistilBertModel.__init__": [[425, 432], ["modeling_utils.PreTrainedModel.__init__", "modeling_distilbert.Embeddings", "modeling_distilbert.Transformer", "modeling_distilbert.DistilBertModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "DistilBertModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embeddings", "=", "Embeddings", "(", "config", ")", "# Embeddings", "\n", "self", ".", "transformer", "=", "Transformer", "(", "config", ")", "# Encoder", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.DistilBertModel.get_input_embeddings": [[433, 435], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.DistilBertModel.set_input_embeddings": [[436, 438], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "embeddings", ".", "word_embeddings", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.DistilBertModel._prune_heads": [[439, 446], ["heads_to_prune.items", "modeling_distilbert.DistilBertModel.transformer.layer[].attention.prune_heads"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "transformer", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.DistilBertModel.forward": [[447, 488], ["modeling_distilbert.DistilBertModel.transformer", "ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "modeling_distilbert.DistilBertModel.embeddings", "input_ids.size", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "ValueError", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_distilbert.DistilBertModel.size", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_distilbert.DistilBertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ")", ":", "\n", "        ", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "input_shape", ",", "device", "=", "device", ")", "# (bs, seq_length)", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "num_hidden_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "embeddings", "(", "input_ids", ")", "# (bs, seq_length, dim)", "\n", "", "tfmr_output", "=", "self", ".", "transformer", "(", "x", "=", "inputs_embeds", ",", "attn_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "hidden_state", "=", "tfmr_output", "[", "0", "]", "\n", "output", "=", "(", "hidden_state", ",", ")", "+", "tfmr_output", "[", "1", ":", "]", "\n", "\n", "return", "output", "# last-layer hidden-state, (all hidden_states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.DistilBertForMaskedLM.__init__": [[526, 539], ["modeling_utils.PreTrainedModel.__init__", "modeling_distilbert.DistilBertModel", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "modeling_distilbert.DistilBertForMaskedLM.init_weights", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "DistilBertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "self", ".", "distilbert", "=", "DistilBertModel", "(", "config", ")", "\n", "self", ".", "vocab_transform", "=", "nn", ".", "Linear", "(", "config", ".", "dim", ",", "config", ".", "dim", ")", "\n", "self", ".", "vocab_layer_norm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "dim", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "vocab_projector", "=", "nn", ".", "Linear", "(", "config", ".", "dim", ",", "config", ".", "vocab_size", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n", "self", ".", "mlm_loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.DistilBertForMaskedLM.get_output_embeddings": [[540, 542], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "vocab_projector", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.DistilBertForMaskedLM.forward": [[543, 561], ["modeling_distilbert.DistilBertForMaskedLM.distilbert", "modeling_distilbert.DistilBertForMaskedLM.vocab_transform", "modeling_distilbert.gelu", "modeling_distilbert.DistilBertForMaskedLM.vocab_layer_norm", "modeling_distilbert.DistilBertForMaskedLM.vocab_projector", "modeling_distilbert.DistilBertForMaskedLM.mlm_loss_fct", "modeling_distilbert.DistilBertForMaskedLM.view", "masked_lm_labels.view", "modeling_distilbert.DistilBertForMaskedLM.size"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.gelu"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "masked_lm_labels", "=", "None", ")", ":", "\n", "        ", "dlbrt_output", "=", "self", ".", "distilbert", "(", "\n", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ",", "inputs_embeds", "=", "inputs_embeds", "\n", ")", "\n", "hidden_states", "=", "dlbrt_output", "[", "0", "]", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "self", ".", "vocab_transform", "(", "hidden_states", ")", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "gelu", "(", "prediction_logits", ")", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "self", ".", "vocab_layer_norm", "(", "prediction_logits", ")", "# (bs, seq_length, dim)", "\n", "prediction_logits", "=", "self", ".", "vocab_projector", "(", "prediction_logits", ")", "# (bs, seq_length, vocab_size)", "\n", "\n", "outputs", "=", "(", "prediction_logits", ",", ")", "+", "dlbrt_output", "[", "1", ":", "]", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "mlm_loss", "=", "self", ".", "mlm_loss_fct", "(", "\n", "prediction_logits", ".", "view", "(", "-", "1", ",", "prediction_logits", ".", "size", "(", "-", "1", ")", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", "\n", ")", "\n", "outputs", "=", "(", "mlm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (mlm_loss), prediction_logits, (all hidden_states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.DistilBertForSequenceClassification.__init__": [[601, 611], ["modeling_utils.PreTrainedModel.__init__", "modeling_distilbert.DistilBertModel", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "modeling_distilbert.DistilBertForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "DistilBertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "distilbert", "=", "DistilBertModel", "(", "config", ")", "\n", "self", ".", "pre_classifier", "=", "nn", ".", "Linear", "(", "config", ".", "dim", ",", "config", ".", "dim", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "dim", ",", "config", ".", "num_labels", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "seq_classif_dropout", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.DistilBertForSequenceClassification.forward": [[612, 634], ["modeling_distilbert.DistilBertForSequenceClassification.distilbert", "modeling_distilbert.DistilBertForSequenceClassification.pre_classifier", "modeling_distilbert.DistilBertForSequenceClassification.dropout", "modeling_distilbert.DistilBertForSequenceClassification.classifier", "torch.ReLU", "torch.ReLU", "torch.MSELoss", "torch.MSELoss", "torch.CrossEntropyLoss.", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss.", "modeling_distilbert.DistilBertForSequenceClassification.view", "labels.view", "modeling_distilbert.DistilBertForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "distilbert_output", "=", "self", ".", "distilbert", "(", "\n", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ",", "inputs_embeds", "=", "inputs_embeds", "\n", ")", "\n", "hidden_state", "=", "distilbert_output", "[", "0", "]", "# (bs, seq_len, dim)", "\n", "pooled_output", "=", "hidden_state", "[", ":", ",", "0", "]", "# (bs, dim)", "\n", "pooled_output", "=", "self", ".", "pre_classifier", "(", "pooled_output", ")", "# (bs, dim)", "\n", "pooled_output", "=", "nn", ".", "ReLU", "(", ")", "(", "pooled_output", ")", "# (bs, dim)", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "# (bs, dim)", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "# (bs, dim)", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "distilbert_output", "[", "1", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "                ", "loss_fct", "=", "nn", ".", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.DistilBertForQuestionAnswering.__init__": [[680, 689], ["modeling_utils.PreTrainedModel.__init__", "modeling_distilbert.DistilBertModel", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "modeling_distilbert.DistilBertForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "DistilBertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "distilbert", "=", "DistilBertModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "dim", ",", "config", ".", "num_labels", ")", "\n", "assert", "config", ".", "num_labels", "==", "2", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "qa_dropout", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.DistilBertForQuestionAnswering.forward": [[690, 729], ["modeling_distilbert.DistilBertForQuestionAnswering.distilbert", "modeling_distilbert.DistilBertForQuestionAnswering.dropout", "modeling_distilbert.DistilBertForQuestionAnswering.qa_outputs", "modeling_distilbert.DistilBertForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss.", "torch.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "\n", "end_positions", "=", "None", ",", "\n", ")", ":", "\n", "        ", "distilbert_output", "=", "self", ".", "distilbert", "(", "\n", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ",", "inputs_embeds", "=", "inputs_embeds", "\n", ")", "\n", "hidden_states", "=", "distilbert_output", "[", "0", "]", "# (bs, max_query_len, dim)", "\n", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "# (bs, max_query_len, dim)", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "hidden_states", ")", "# (bs, max_query_len, 2)", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "# (bs, max_query_len)", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "# (bs, max_query_len)", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "distilbert_output", "[", "1", ":", "]", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.DistilBertForTokenClassification.__init__": [[767, 776], ["modeling_utils.PreTrainedModel.__init__", "modeling_distilbert.DistilBertModel", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "modeling_distilbert.DistilBertForTokenClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "DistilBertForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "distilbert", "=", "DistilBertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.DistilBertForTokenClassification.forward": [[777, 802], ["modeling_distilbert.DistilBertForTokenClassification.distilbert", "modeling_distilbert.DistilBertForTokenClassification.dropout", "modeling_distilbert.DistilBertForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "modeling_distilbert.DistilBertForTokenClassification.view", "labels.view", "modeling_distilbert.DistilBertForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "distilbert", "(", "\n", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ",", "inputs_embeds", "=", "inputs_embeds", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), scores, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.gelu": [[47, 49], ["torch.erf", "torch.erf", "math.sqrt"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_distilbert.create_sinusoidal_embeddings": [[51, 57], ["numpy.array", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "out.detach_", "numpy.sin", "numpy.cos", "range", "numpy.power", "range"], "function", ["None"], ["", "def", "create_sinusoidal_embeddings", "(", "n_pos", ",", "dim", ",", "out", ")", ":", "\n", "    ", "position_enc", "=", "np", ".", "array", "(", "[", "[", "pos", "/", "np", ".", "power", "(", "10000", ",", "2", "*", "(", "j", "//", "2", ")", "/", "dim", ")", "for", "j", "in", "range", "(", "dim", ")", "]", "for", "pos", "in", "range", "(", "n_pos", ")", "]", ")", "\n", "out", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "FloatTensor", "(", "np", ".", "sin", "(", "position_enc", "[", ":", ",", "0", ":", ":", "2", "]", ")", ")", "\n", "out", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "FloatTensor", "(", "np", ".", "cos", "(", "position_enc", "[", ":", ",", "1", ":", ":", "2", "]", ")", ")", "\n", "out", ".", "detach_", "(", ")", "\n", "out", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.Attention.__init__": [[103, 120], ["torch.Module.__init__", "modeling_gpt2.Attention.register_buffer", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "set", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "register_buffer", "(", "\"bias\"", ",", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "n_ctx", ",", "n_ctx", ")", ")", ".", "view", "(", "1", ",", "1", ",", "n_ctx", ",", "n_ctx", ")", ")", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "c_attn", "=", "Conv1D", "(", "n_state", "*", "3", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "attn_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.Attention.prune_heads": [[121, 142], ["torch.ones", "torch.ones", "torch.ones", "torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_utils.prune_conv1d_layer", "modeling_utils.prune_conv1d_layer", "modeling_gpt2.Attention.pruned_heads.union", "len", "set", "len", "sum", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "len", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_conv1d_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "n_head", ",", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "# Convert to set and emove already pruned heads", "\n", "for", "head", "in", "heads", ":", "\n", "# Compute how many pruned heads are before the head and move the index accordingly", "\n", "            ", "head", "=", "head", "-", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "index_attn", "=", "torch", ".", "cat", "(", "[", "index", ",", "index", "+", "self", ".", "split_size", ",", "index", "+", "(", "2", "*", "self", ".", "split_size", ")", "]", ")", "\n", "\n", "# Prune conv1d layers", "\n", "self", ".", "c_attn", "=", "prune_conv1d_layer", "(", "self", ".", "c_attn", ",", "index_attn", ",", "dim", "=", "1", ")", "\n", "self", ".", "c_proj", "=", "prune_conv1d_layer", "(", "self", ".", "c_proj", ",", "index", ",", "dim", "=", "0", ")", "\n", "\n", "# Update hyper params", "\n", "self", ".", "split_size", "=", "(", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "*", "(", "self", ".", "n_head", "-", "len", "(", "heads", ")", ")", "\n", "self", ".", "n_head", "=", "self", ".", "n_head", "-", "len", "(", "heads", ")", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.Attention._attn": [[143, 166], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "modeling_gpt2.Attention.attn_dropout", "modeling_gpt2.Attention.size", "modeling_gpt2.Attention.size", "torch.Softmax", "torch.Softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "outputs.append", "math.sqrt", "v.size"], "methods", ["None"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "math", ".", "sqrt", "(", "v", ".", "size", "(", "-", "1", ")", ")", "\n", "", "nd", ",", "ns", "=", "w", ".", "size", "(", "-", "2", ")", ",", "w", ".", "size", "(", "-", "1", ")", "\n", "b", "=", "self", ".", "bias", "[", ":", ",", ":", ",", "ns", "-", "nd", ":", "ns", ",", ":", "ns", "]", "\n", "w", "=", "w", "*", "b", "-", "1e4", "*", "(", "1", "-", "b", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "            ", "w", "=", "w", "+", "attention_mask", "\n", "\n", "", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "w", "=", "w", "*", "head_mask", "\n", "\n", "", "outputs", "=", "[", "torch", ".", "matmul", "(", "w", ",", "v", ")", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "w", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.Attention.merge_heads": [[167, 171], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["None"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.Attention.split_heads": [[172, 179], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# (batch, head, head_features, seq_length)", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "# (batch, head, seq_length, head_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.Attention.forward": [[180, 201], ["modeling_gpt2.Attention.c_attn", "modeling_gpt2.Attention.split", "modeling_gpt2.Attention.split_heads", "modeling_gpt2.Attention.split_heads", "modeling_gpt2.Attention.split_heads", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "modeling_gpt2.Attention._attn", "modeling_gpt2.Attention.merge_heads", "modeling_gpt2.Attention.c_proj", "modeling_gpt2.Attention.resid_dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layer_past[].transpose", "torch.cat.transpose", "torch.cat.transpose"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention._attn", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.merge_heads"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "layer_past", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "x", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "if", "layer_past", "is", "not", "None", ":", "\n", "            ", "past_key", ",", "past_value", "=", "layer_past", "[", "0", "]", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "layer_past", "[", "1", "]", "# transpose back cf below", "\n", "key", "=", "torch", ".", "cat", "(", "(", "past_key", ",", "key", ")", ",", "dim", "=", "-", "1", ")", "\n", "value", "=", "torch", ".", "cat", "(", "(", "past_value", ",", "value", ")", ",", "dim", "=", "-", "2", ")", "\n", "", "present", "=", "torch", ".", "stack", "(", "(", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "value", ")", ")", "# transpose to have same shapes for stacking", "\n", "\n", "attn_outputs", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ",", "attention_mask", ",", "head_mask", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ")", "\n", "\n", "outputs", "=", "[", "a", ",", "present", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "# a, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.MLP.__init__": [[204, 211], ["torch.Module.__init__", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "nx", ",", "n_state", ")", "\n", "self", ".", "act", "=", "gelu", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.MLP.forward": [[212, 216], ["modeling_gpt2.MLP.act", "modeling_gpt2.MLP.c_proj", "modeling_gpt2.MLP.dropout", "modeling_gpt2.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "return", "self", ".", "dropout", "(", "h2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.Block.__init__": [[219, 226], ["torch.Module.__init__", "torch.LayerNorm", "torch.LayerNorm", "modeling_gpt2.Attention", "torch.LayerNorm", "torch.LayerNorm", "modeling_gpt2.MLP"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "ln_1", "=", "nn", ".", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_2", "=", "nn", ".", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "4", "*", "nx", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.Block.forward": [[227, 239], ["modeling_gpt2.Block.attn", "modeling_gpt2.Block.mlp", "modeling_gpt2.Block.ln_1", "modeling_gpt2.Block.ln_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "layer_past", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "output_attn", "=", "self", ".", "attn", "(", "\n", "self", ".", "ln_1", "(", "x", ")", ",", "layer_past", "=", "layer_past", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", "\n", ")", "\n", "a", "=", "output_attn", "[", "0", "]", "# output_attn: a, present, (attentions)", "\n", "\n", "x", "=", "x", "+", "a", "\n", "m", "=", "self", ".", "mlp", "(", "self", ".", "ln_2", "(", "x", ")", ")", "\n", "x", "=", "x", "+", "m", "\n", "\n", "outputs", "=", "[", "x", "]", "+", "output_attn", "[", "1", ":", "]", "\n", "return", "outputs", "# x, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.GPT2PreTrainedModel.__init__": [[251, 253], ["modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "GPT2PreTrainedModel", ",", "self", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.GPT2PreTrainedModel._init_weights": [[254, 266], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "Conv1D", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "Conv1D", ")", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.GPT2Model.__init__": [[357, 370], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.LayerNorm", "torch.LayerNorm", "modeling_gpt2.GPT2Model.init_weights", "modeling_gpt2.Block", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2Model", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "\n", "self", ".", "wte", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "wpe", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "Block", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "ln_f", "=", "nn", ".", "LayerNorm", "(", "config", ".", "n_embd", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.GPT2Model.get_input_embeddings": [[371, 373], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wte", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.GPT2Model.set_input_embeddings": [[374, 376], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "wte", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.GPT2Model._prune_heads": [[377, 383], ["heads_to_prune.items", "modeling_gpt2.GPT2Model.h[].attn.prune_heads"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "h", "[", "layer", "]", ".", "attn", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.GPT2Model.forward": [[384, 503], ["modeling_gpt2.GPT2Model.wpe", "modeling_gpt2.GPT2Model.drop", "enumerate", "modeling_gpt2.GPT2Model.ln_f", "hidden_states.view.view.view", "ValueError", "token_type_ids.view.view.view", "position_ids.unsqueeze().view.unsqueeze().view.view", "[].size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze().view", "attention_mask.to.to.view", "attention_mask.to.to.unsqueeze().unsqueeze", "attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "modeling_gpt2.GPT2Model.wte", "modeling_gpt2.GPT2Model.wte", "zip", "block", "tuple", "input_ids.view.view.size", "input_ids.view.view.view", "len", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "hidden_states.view.view.size", "tuple.append", "ValueError", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze", "attention_mask.to.to.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "t.view", "modeling_gpt2.GPT2Model.size", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "hidden_states.view.view.view", "modeling_gpt2.GPT2Model.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_gpt2.GPT2Model.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "if", "position_ids", "is", "not", "None", ":", "\n", "            ", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "", "if", "past", "is", "None", ":", "\n", "            ", "past_length", "=", "0", "\n", "past", "=", "[", "None", "]", "*", "len", "(", "self", ".", "h", ")", "\n", "", "else", ":", "\n", "            ", "past_length", "=", "past", "[", "0", "]", "[", "0", "]", ".", "size", "(", "-", "2", ")", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "position_ids", "=", "torch", ".", "arange", "(", "past_length", ",", "input_shape", "[", "-", "1", "]", "+", "past_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "# Attention mask.", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "attention_mask", "=", "attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# head_mask has shape n_layer x batch x n_heads x N x N", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "n_layer", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "wte", "(", "input_ids", ")", "\n", "", "position_embeds", "=", "self", ".", "wpe", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_embeds", "=", "self", ".", "wte", "(", "token_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "hidden_states", "=", "self", ".", "drop", "(", "hidden_states", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "\n", "presents", "=", "(", ")", "\n", "all_attentions", "=", "[", "]", "\n", "all_hidden_states", "=", "(", ")", "\n", "for", "i", ",", "(", "block", ",", "layer_past", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "h", ",", "past", ")", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "block", "(", "\n", "hidden_states", ",", "layer_past", "=", "layer_past", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", "[", "i", "]", "\n", ")", "\n", "\n", "hidden_states", ",", "present", "=", "outputs", "[", ":", "2", "]", "\n", "if", "self", ".", "output_past", ":", "\n", "                ", "presents", "=", "presents", "+", "(", "present", ",", ")", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "ln_f", "(", "hidden_states", ")", "\n", "\n", "hidden_states", "=", "hidden_states", ".", "view", "(", "*", "output_shape", ")", "\n", "# Add last hidden state", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_past", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "presents", ",", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# let the number of heads free (-1) so we can extract attention even after head pruning", "\n", "            ", "attention_output_shape", "=", "input_shape", "[", ":", "-", "1", "]", "+", "(", "-", "1", ",", ")", "+", "all_attentions", "[", "0", "]", ".", "shape", "[", "-", "2", ":", "]", "\n", "all_attentions", "=", "tuple", "(", "t", ".", "view", "(", "*", "attention_output_shape", ")", "for", "t", "in", "all_attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last hidden state, (presents), (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.GPT2LMHeadModel.__init__": [[552, 558], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2Model", "torch.Linear", "torch.Linear", "modeling_gpt2.GPT2LMHeadModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2LMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.GPT2LMHeadModel.get_output_embeddings": [[559, 561], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.GPT2LMHeadModel.forward": [[562, 597], ["modeling_gpt2.GPT2LMHeadModel.transformer", "modeling_gpt2.GPT2LMHeadModel.lm_head", "lm_logits[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous.view", "labels[].contiguous.view", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "past", "=", "past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Shift so that tokens < n predict n", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), lm_logits, presents, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.GPT2DoubleHeadsModel.__init__": [[671, 679], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2Model", "torch.Linear", "torch.Linear", "modeling_utils.SequenceSummary", "modeling_gpt2.GPT2DoubleHeadsModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GPT2DoubleHeadsModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "config", ".", "num_labels", "=", "1", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "multiple_choice_head", "=", "SequenceSummary", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.GPT2DoubleHeadsModel.get_output_embeddings": [[680, 682], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.GPT2DoubleHeadsModel.forward": [[683, 724], ["modeling_gpt2.GPT2DoubleHeadsModel.transformer", "modeling_gpt2.GPT2DoubleHeadsModel.lm_head", "modeling_gpt2.GPT2DoubleHeadsModel.multiple_choice_head().squeeze", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous", "lm_labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_gpt2.GPT2DoubleHeadsModel.multiple_choice_head", "modeling_gpt2.GPT2DoubleHeadsModel.view", "mc_labels.view", "lm_logits[].contiguous.view", "lm_labels[].contiguous.view", "modeling_gpt2.GPT2DoubleHeadsModel.size", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "mc_token_ids", "=", "None", ",", "\n", "lm_labels", "=", "None", ",", "\n", "mc_labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "past", "=", "past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "hidden_states", ",", "mc_token_ids", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", "mc_logits", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "mc_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "mc_logits", ".", "view", "(", "-", "1", ",", "mc_logits", ".", "size", "(", "-", "1", ")", ")", ",", "mc_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "lm_labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (lm loss), (mc loss), lm logits, mc logits, presents, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.load_tf_weights_in_gpt2": [[43, 96], ["os.path.abspath", "logger.info", "tf.train.list_variables", "zip", "logger.info", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "logger.info", "torch.from_numpy", "torch.from_numpy", "logger.error", "tf.train.load_variable.squeeze", "re.fullmatch", "re.split", "getattr", "len", "int", "getattr", "getattr", "getattr", "getattr"], "function", ["None"], ["def", "load_tf_weights_in_gpt2", "(", "model", ",", "config", ",", "gpt2_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "gpt2_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ".", "squeeze", "(", ")", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", "[", "6", ":", "]", "# skip \"model/\"", "\n", "name", "=", "name", ".", "split", "(", "\"/\"", ")", "\n", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r\"[A-Za-z]+\\d+\"", ",", "m_name", ")", ":", "\n", "                ", "scope_names", "=", "re", ".", "split", "(", "r\"(\\d+)\"", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "scope_names", "=", "[", "m_name", "]", "\n", "", "if", "scope_names", "[", "0", "]", "==", "\"w\"", "or", "scope_names", "[", "0", "]", "==", "\"g\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"b\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"bias\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"wpe\"", "or", "scope_names", "[", "0", "]", "==", "\"wte\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "", "if", "len", "(", "scope_names", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "scope_names", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.gelu": [[98, 100], ["torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetRelativeAttention.__init__": [[206, 234], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "XLNetLayerNorm", "torch.nn.Dropout", "ValueError", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetRelativeAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "if", "config", ".", "d_model", "%", "config", ".", "n_head", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "d_model", ",", "config", ".", "n_head", ")", "\n", ")", "\n", "\n", "", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "d_head", "=", "config", ".", "d_head", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "scale", "=", "1", "/", "(", "config", ".", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "q", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "k", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "v", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "o", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_s_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "seg_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "2", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "self", ".", "layer_norm", "=", "XLNetLayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetRelativeAttention.prune_heads": [[235, 237], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetRelativeAttention.rel_shift": [[238, 250], ["torch.index_select.reshape", "torch.index_select.reshape", "torch.index_select", "torch.arange"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "rel_shift", "(", "x", ",", "klen", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"perform relative shift to form the relative attention score.\"\"\"", "\n", "x_size", "=", "x", ".", "shape", "\n", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "1", "]", ",", "x_size", "[", "0", "]", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", ")", "\n", "x", "=", "x", "[", "1", ":", ",", "...", "]", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "0", "]", ",", "x_size", "[", "1", "]", "-", "1", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", ")", "\n", "# x = x[:, 0:klen, :, :]", "\n", "x", "=", "torch", ".", "index_select", "(", "x", ",", "1", ",", "torch", ".", "arange", "(", "klen", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetRelativeAttention.rel_shift_bnij": [[251, 265], ["torch.index_select.reshape", "torch.index_select.reshape", "torch.index_select", "torch.arange"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "rel_shift_bnij", "(", "x", ",", "klen", "=", "-", "1", ")", ":", "\n", "        ", "x_size", "=", "x", ".", "shape", "\n", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "0", "]", ",", "x_size", "[", "1", "]", ",", "x_size", "[", "3", "]", ",", "x_size", "[", "2", "]", ")", "\n", "x", "=", "x", "[", ":", ",", ":", ",", "1", ":", ",", ":", "]", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "0", "]", ",", "x_size", "[", "1", "]", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", "-", "1", ")", "\n", "# Note: the tensor-slice form was faster in my testing than torch.index_select", "\n", "#       However, tracing doesn't like the nature of the slice, and if klen changes", "\n", "#       during the run then it'll fail, whereas index_select will be fine.", "\n", "x", "=", "torch", ".", "index_select", "(", "x", ",", "3", ",", "torch", ".", "arange", "(", "klen", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "# x = x[:, :, :, :klen]", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetRelativeAttention.rel_attn_core": [[266, 307], ["torch.einsum", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_shift_bnij", "torch.nn.functional.softmax", "modeling_xlnet.XLNetRelativeAttention.dropout", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetRelativeAttention.rel_shift_bnij"], ["", "def", "rel_attn_core", "(", "self", ",", "q_head", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "None", ",", "attn_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"Core relative positional attention operations.\"\"\"", "\n", "\n", "# content based attention score", "\n", "ac", "=", "torch", ".", "einsum", "(", "\"ibnd,jbnd->bnij\"", ",", "q_head", "+", "self", ".", "r_w_bias", ",", "k_head_h", ")", "\n", "\n", "# position based attention score", "\n", "bd", "=", "torch", ".", "einsum", "(", "\"ibnd,jbnd->bnij\"", ",", "q_head", "+", "self", ".", "r_r_bias", ",", "k_head_r", ")", "\n", "bd", "=", "self", ".", "rel_shift_bnij", "(", "bd", ",", "klen", "=", "ac", ".", "shape", "[", "3", "]", ")", "\n", "\n", "# segment based attention score", "\n", "if", "seg_mat", "is", "None", ":", "\n", "            ", "ef", "=", "0", "\n", "", "else", ":", "\n", "            ", "ef", "=", "torch", ".", "einsum", "(", "\"ibnd,snd->ibns\"", ",", "q_head", "+", "self", ".", "r_s_bias", ",", "self", ".", "seg_embed", ")", "\n", "ef", "=", "torch", ".", "einsum", "(", "\"ijbs,ibns->bnij\"", ",", "seg_mat", ",", "ef", ")", "\n", "\n", "# merge attention scores and perform masking", "\n", "", "attn_score", "=", "(", "ac", "+", "bd", "+", "ef", ")", "*", "self", ".", "scale", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "# attn_score = attn_score * (1 - attn_mask) - 1e30 * attn_mask", "\n", "            ", "if", "attn_mask", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "                ", "attn_score", "=", "attn_score", "-", "65500", "*", "torch", ".", "einsum", "(", "\"ijbn->bnij\"", ",", "attn_mask", ")", "\n", "", "else", ":", "\n", "                ", "attn_score", "=", "attn_score", "-", "1e30", "*", "torch", ".", "einsum", "(", "\"ijbn->bnij\"", ",", "attn_mask", ")", "\n", "\n", "# attention probability", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "3", ")", "\n", "attn_prob", "=", "self", ".", "dropout", "(", "attn_prob", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attn_prob", "=", "attn_prob", "*", "torch", ".", "einsum", "(", "\"ijbn->bnij\"", ",", "head_mask", ")", "\n", "\n", "# attention output", "\n", "", "attn_vec", "=", "torch", ".", "einsum", "(", "\"bnij,jbnd->ibnd\"", ",", "attn_prob", ",", "v_head_h", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "return", "attn_vec", ",", "torch", ".", "einsum", "(", "\"bnij->ijbn\"", ",", "attn_prob", ")", "\n", "\n", "", "return", "attn_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetRelativeAttention.post_attention": [[308, 319], ["torch.einsum", "modeling_xlnet.XLNetRelativeAttention.dropout", "modeling_xlnet.XLNetRelativeAttention.layer_norm"], "methods", ["None"], ["", "def", "post_attention", "(", "self", ",", "h", ",", "attn_vec", ",", "residual", "=", "True", ")", ":", "\n", "        ", "\"\"\"Post-attention processing.\"\"\"", "\n", "# post-attention projection (back to `d_model`)", "\n", "attn_out", "=", "torch", ".", "einsum", "(", "\"ibnd,hnd->ibh\"", ",", "attn_vec", ",", "self", ".", "o", ")", "\n", "\n", "attn_out", "=", "self", ".", "dropout", "(", "attn_out", ")", "\n", "if", "residual", ":", "\n", "            ", "attn_out", "=", "attn_out", "+", "h", "\n", "", "output", "=", "self", ".", "layer_norm", "(", "attn_out", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetRelativeAttention.forward": [[320, 413], ["torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "modeling_xlnet.XLNetRelativeAttention.post_attention", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.post_attention", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "modeling_xlnet.XLNetRelativeAttention.post_attention", "torch.cat", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "torch.cat", "mems.dim", "mems.dim"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core"], ["", "def", "forward", "(", "self", ",", "h", ",", "g", ",", "attn_mask_h", ",", "attn_mask_g", ",", "r", ",", "seg_mat", ",", "mems", "=", "None", ",", "target_mapping", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "if", "g", "is", "not", "None", ":", "\n", "# Two-stream attention with relative positional encoding.", "\n", "# content based attention score", "\n", "            ", "if", "mems", "is", "not", "None", "and", "mems", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "h", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat", "=", "h", "\n", "\n", "# content-based key head", "\n", "", "k_head_h", "=", "torch", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "cat", ",", "self", ".", "k", ")", "\n", "\n", "# content-based value head", "\n", "v_head_h", "=", "torch", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "cat", ",", "self", ".", "v", ")", "\n", "\n", "# position-based key head", "\n", "k_head_r", "=", "torch", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "r", ",", "self", ".", "r", ")", "\n", "\n", "# h-stream", "\n", "# content-stream query head", "\n", "q_head_h", "=", "torch", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "h", ",", "self", ".", "q", ")", "\n", "\n", "# core attention ops", "\n", "attn_vec_h", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_h", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_h", ",", "head_mask", "=", "head_mask", "\n", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_vec_h", ",", "attn_prob_h", "=", "attn_vec_h", "\n", "\n", "# post processing", "\n", "", "output_h", "=", "self", ".", "post_attention", "(", "h", ",", "attn_vec_h", ")", "\n", "\n", "# g-stream", "\n", "# query-stream query head", "\n", "q_head_g", "=", "torch", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "g", ",", "self", ".", "q", ")", "\n", "\n", "# core attention ops", "\n", "if", "target_mapping", "is", "not", "None", ":", "\n", "                ", "q_head_g", "=", "torch", ".", "einsum", "(", "\"mbnd,mlb->lbnd\"", ",", "q_head_g", ",", "target_mapping", ")", "\n", "attn_vec_g", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_g", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_g", ",", "head_mask", "=", "head_mask", "\n", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attn_vec_g", ",", "attn_prob_g", "=", "attn_vec_g", "\n", "\n", "", "attn_vec_g", "=", "torch", ".", "einsum", "(", "\"lbnd,mlb->mbnd\"", ",", "attn_vec_g", ",", "target_mapping", ")", "\n", "", "else", ":", "\n", "                ", "attn_vec_g", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_g", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_g", ",", "head_mask", "=", "head_mask", "\n", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attn_vec_g", ",", "attn_prob_g", "=", "attn_vec_g", "\n", "\n", "# post processing", "\n", "", "", "output_g", "=", "self", ".", "post_attention", "(", "g", ",", "attn_vec_g", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_prob", "=", "attn_prob_h", ",", "attn_prob_g", "\n", "\n", "", "", "else", ":", "\n", "# Multi-head attention with relative positional encoding", "\n", "            ", "if", "mems", "is", "not", "None", "and", "mems", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "h", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat", "=", "h", "\n", "\n", "# content heads", "\n", "", "q_head_h", "=", "torch", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "h", ",", "self", ".", "q", ")", "\n", "k_head_h", "=", "torch", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "cat", ",", "self", ".", "k", ")", "\n", "v_head_h", "=", "torch", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "cat", ",", "self", ".", "v", ")", "\n", "\n", "# positional heads", "\n", "k_head_r", "=", "torch", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "r", ",", "self", ".", "r", ")", "\n", "\n", "# core attention ops", "\n", "attn_vec", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_h", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_h", ",", "head_mask", "=", "head_mask", "\n", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_vec", ",", "attn_prob", "=", "attn_vec", "\n", "\n", "# post processing", "\n", "", "output_h", "=", "self", ".", "post_attention", "(", "h", ",", "attn_vec", ")", "\n", "output_g", "=", "None", "\n", "\n", "", "outputs", "=", "(", "output_h", ",", "output_g", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attn_prob", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetFeedForward.__init__": [[416, 426], ["torch.nn.Module.__init__", "XLNetLayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "isinstance"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer_norm", "=", "XLNetLayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "layer_1", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "d_inner", ")", "\n", "self", ".", "layer_2", "=", "nn", ".", "Linear", "(", "config", ".", "d_inner", ",", "config", ".", "d_model", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "if", "isinstance", "(", "config", ".", "ff_activation", ",", "str", ")", ":", "\n", "            ", "self", ".", "activation_function", "=", "ACT2FN", "[", "config", ".", "ff_activation", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "activation_function", "=", "config", ".", "ff_activation", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetFeedForward.forward": [[427, 436], ["modeling_xlnet.XLNetFeedForward.layer_1", "modeling_xlnet.XLNetFeedForward.activation_function", "modeling_xlnet.XLNetFeedForward.dropout", "modeling_xlnet.XLNetFeedForward.layer_2", "modeling_xlnet.XLNetFeedForward.dropout", "modeling_xlnet.XLNetFeedForward.layer_norm"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "output", "=", "inp", "\n", "output", "=", "self", ".", "layer_1", "(", "output", ")", "\n", "output", "=", "self", ".", "activation_function", "(", "output", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "layer_2", "(", "output", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "layer_norm", "(", "output", "+", "inp", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetLayer.__init__": [[439, 444], ["torch.nn.Module.__init__", "modeling_xlnet.XLNetRelativeAttention", "modeling_xlnet.XLNetFeedForward", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rel_attn", "=", "XLNetRelativeAttention", "(", "config", ")", "\n", "self", ".", "ff", "=", "XLNetFeedForward", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetLayer.forward": [[445, 467], ["modeling_xlnet.XLNetLayer.rel_attn", "modeling_xlnet.XLNetLayer.ff", "modeling_xlnet.XLNetLayer.ff"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "output_h", ",", "output_g", ",", "attn_mask_h", ",", "attn_mask_g", ",", "r", ",", "seg_mat", ",", "mems", "=", "None", ",", "target_mapping", "=", "None", ",", "head_mask", "=", "None", "\n", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "rel_attn", "(", "\n", "output_h", ",", "\n", "output_g", ",", "\n", "attn_mask_h", ",", "\n", "attn_mask_g", ",", "\n", "r", ",", "\n", "seg_mat", ",", "\n", "mems", "=", "mems", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", ")", "\n", "output_h", ",", "output_g", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "output_g", "is", "not", "None", ":", "\n", "            ", "output_g", "=", "self", ".", "ff", "(", "output_g", ")", "\n", "", "output_h", "=", "self", ".", "ff", "(", "output_h", ")", "\n", "\n", "outputs", "=", "(", "output_h", ",", "output_g", ")", "+", "outputs", "[", "2", ":", "]", "# Add again attentions if there are there", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetPreTrainedModel._init_weights": [[479, 506], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_", "isinstance", "isinstance", "param.data.normal_", "module.mask_emb.data.normal_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "XLNetLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "XLNetRelativeAttention", ")", ":", "\n", "            ", "for", "param", "in", "[", "\n", "module", ".", "q", ",", "\n", "module", ".", "k", ",", "\n", "module", ".", "v", ",", "\n", "module", ".", "o", ",", "\n", "module", ".", "r", ",", "\n", "module", ".", "r_r_bias", ",", "\n", "module", ".", "r_s_bias", ",", "\n", "module", ".", "r_w_bias", ",", "\n", "module", ".", "seg_embed", ",", "\n", "]", ":", "\n", "                ", "param", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "XLNetModel", ")", ":", "\n", "            ", "module", ".", "mask_emb", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetModel.__init__": [[633, 654], ["modeling_utils.PreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Parameter", "torch.nn.ModuleList", "torch.nn.Dropout", "modeling_xlnet.XLNetModel.init_weights", "torch.FloatTensor", "modeling_xlnet.XLNetLayer", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "\n", "self", ".", "mem_len", "=", "config", ".", "mem_len", "\n", "self", ".", "reuse_len", "=", "config", ".", "reuse_len", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "self", ".", "bi_data", "=", "config", ".", "bi_data", "\n", "self", ".", "clamp_len", "=", "config", ".", "clamp_len", "\n", "self", ".", "n_layer", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "word_embedding", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "d_model", ")", "\n", "self", ".", "mask_emb", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "1", ",", "1", ",", "config", ".", "d_model", ")", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "XLNetLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetModel.get_input_embeddings": [[655, 657], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "word_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetModel.set_input_embeddings": [[658, 660], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "word_embedding", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetModel._prune_heads": [[661, 663], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetModel.create_mask": [[664, 693], ["torch.ones", "torch.triu", "torch.zeros", "torch.cat", "torch.cat.to", "torch.tril", "torch.cat", "next", "modeling_xlnet.XLNetModel.parameters"], "methods", ["None"], ["", "def", "create_mask", "(", "self", ",", "qlen", ",", "mlen", ")", ":", "\n", "        ", "\"\"\"\n        Creates causal attention mask. Float mask where 1.0 indicates masked, 0.0 indicates not-masked.\n\n        Args:\n            qlen: TODO Lysandre didn't fill\n            mlen: TODO Lysandre didn't fill\n\n        ::\n\n                  same_length=False:      same_length=True:\n                  <mlen > <  qlen >       <mlen > <  qlen >\n               ^ [0 0 0 0 0 1 1 1 1]     [0 0 0 0 0 1 1 1 1]\n                 [0 0 0 0 0 0 1 1 1]     [1 0 0 0 0 0 1 1 1]\n            qlen [0 0 0 0 0 0 0 1 1]     [1 1 0 0 0 0 0 1 1]\n                 [0 0 0 0 0 0 0 0 1]     [1 1 1 0 0 0 0 0 1]\n               v [0 0 0 0 0 0 0 0 0]     [1 1 1 1 0 0 0 0 0]\n\n        \"\"\"", "\n", "attn_mask", "=", "torch", ".", "ones", "(", "[", "qlen", ",", "qlen", "]", ")", "\n", "mask_up", "=", "torch", ".", "triu", "(", "attn_mask", ",", "diagonal", "=", "1", ")", "\n", "attn_mask_pad", "=", "torch", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ")", "\n", "ret", "=", "torch", ".", "cat", "(", "[", "attn_mask_pad", ",", "mask_up", "]", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "same_length", ":", "\n", "            ", "mask_lo", "=", "torch", ".", "tril", "(", "attn_mask", ",", "diagonal", "=", "-", "1", ")", "\n", "ret", "=", "torch", ".", "cat", "(", "[", "ret", "[", ":", ",", ":", "qlen", "]", "+", "mask_lo", ",", "ret", "[", ":", ",", "qlen", ":", "]", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "ret", "=", "ret", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetModel.cache_mem": [[694, 705], ["new_mem.detach", "torch.cat"], "methods", ["None"], ["", "def", "cache_mem", "(", "self", ",", "curr_out", ",", "prev_mem", ")", ":", "\n", "        ", "\"\"\"cache hidden states into memory.\"\"\"", "\n", "if", "self", ".", "reuse_len", "is", "not", "None", "and", "self", ".", "reuse_len", ">", "0", ":", "\n", "            ", "curr_out", "=", "curr_out", "[", ":", "self", ".", "reuse_len", "]", "\n", "\n", "", "if", "prev_mem", "is", "None", ":", "\n", "            ", "new_mem", "=", "curr_out", "[", "-", "self", ".", "mem_len", ":", "]", "\n", "", "else", ":", "\n", "            ", "new_mem", "=", "torch", ".", "cat", "(", "[", "prev_mem", ",", "curr_out", "]", ",", "dim", "=", "0", ")", "[", "-", "self", ".", "mem_len", ":", "]", "\n", "\n", "", "return", "new_mem", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetModel.positional_embedding": [[706, 716], ["torch.einsum", "torch.cat", "pos_emb.expand.expand.expand", "torch.sin", "torch.cos"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "positional_embedding", "(", "pos_seq", ",", "inv_freq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "torch", ".", "einsum", "(", "\"i,d->id\"", ",", "pos_seq", ",", "inv_freq", ")", "\n", "pos_emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "sinusoid_inp", ")", ",", "torch", ".", "cos", "(", "sinusoid_inp", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "pos_emb", "=", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "pos_emb", "=", "pos_emb", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "\n", "", "return", "pos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetModel.relative_positional_encoding": [[717, 755], ["torch.arange", "modeling_xlnet.XLNetModel.to", "torch.pow", "torch.arange", "torch.arange", "torch.cat", "torch.arange", "modeling_xlnet.XLNetModel.positional_embedding", "next", "ValueError", "fwd_pos_seq.clamp.clamp.clamp", "bwd_pos_seq.clamp.clamp.clamp", "modeling_xlnet.XLNetModel.positional_embedding", "modeling_xlnet.XLNetModel.positional_embedding", "modeling_xlnet.XLNetModel.positional_embedding", "modeling_xlnet.XLNetModel.positional_embedding", "fwd_pos_seq.clamp.clamp.clamp", "modeling_xlnet.XLNetModel.parameters"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding"], ["", "def", "relative_positional_encoding", "(", "self", ",", "qlen", ",", "klen", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "\"\"\"create relative positional encoding.\"\"\"", "\n", "freq_seq", "=", "torch", ".", "arange", "(", "0", ",", "self", ".", "d_model", ",", "2.0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "inv_freq", "=", "1", "/", "torch", ".", "pow", "(", "10000", ",", "(", "freq_seq", "/", "self", ".", "d_model", ")", ")", "\n", "\n", "if", "self", ".", "attn_type", "==", "\"bi\"", ":", "\n", "# beg, end = klen - 1, -qlen", "\n", "            ", "beg", ",", "end", "=", "klen", ",", "-", "qlen", "\n", "", "elif", "self", ".", "attn_type", "==", "\"uni\"", ":", "\n", "# beg, end = klen - 1, -1", "\n", "            ", "beg", ",", "end", "=", "klen", ",", "-", "1", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown `attn_type` {}.\"", ".", "format", "(", "self", ".", "attn_type", ")", ")", "\n", "\n", "", "if", "self", ".", "bi_data", ":", "\n", "            ", "fwd_pos_seq", "=", "torch", ".", "arange", "(", "beg", ",", "end", ",", "-", "1.0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "bwd_pos_seq", "=", "torch", ".", "arange", "(", "-", "beg", ",", "-", "end", ",", "1.0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "fwd_pos_seq", "=", "fwd_pos_seq", ".", "clamp", "(", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "bwd_pos_seq", "=", "bwd_pos_seq", ".", "clamp", "(", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "\n", "", "if", "bsz", "is", "not", "None", ":", "\n", "                ", "fwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ",", "bsz", "//", "2", ")", "\n", "bwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "bwd_pos_seq", ",", "inv_freq", ",", "bsz", "//", "2", ")", "\n", "", "else", ":", "\n", "                ", "fwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ")", "\n", "bwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "bwd_pos_seq", ",", "inv_freq", ")", "\n", "\n", "", "pos_emb", "=", "torch", ".", "cat", "(", "[", "fwd_pos_emb", ",", "bwd_pos_emb", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "fwd_pos_seq", "=", "torch", ".", "arange", "(", "beg", ",", "end", ",", "-", "1.0", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "fwd_pos_seq", "=", "fwd_pos_seq", ".", "clamp", "(", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ",", "bsz", ")", "\n", "\n", "", "pos_emb", "=", "pos_emb", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ")", "\n", "return", "pos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetModel.forward": [[756, 947], ["modeling_xlnet.XLNetModel.dropout", "modeling_xlnet.XLNetModel.relative_positional_encoding", "modeling_xlnet.XLNetModel.dropout", "enumerate", "modeling_xlnet.XLNetModel.dropout", "ValueError", "token_type_ids.transpose().contiguous", "input_mask.transpose().contiguous", "attention_mask.transpose().contiguous", "perm_mask.permute().contiguous", "target_mapping.permute().contiguous", "next", "next", "modeling_xlnet.XLNetModel.create_mask", "modeling_xlnet.XLNetModel.word_embedding", "modeling_xlnet.XLNetModel.mask_emb.expand", "modeling_xlnet.XLNetModel.dropout", "torch.nn.functional.one_hot().to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "layer_module", "tuple.append", "modeling_xlnet.XLNetModel.permute().contiguous", "input_ids.transpose().contiguous.transpose().contiguous.transpose().contiguous", "modeling_xlnet.XLNetModel.parameters", "modeling_xlnet.XLNetModel.parameters", "ValueError", "torch.zeros().to", "torch.cat", "torch.eye().to", "torch.cat", "torch.zeros", "torch.cat", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "len", "tuple.append", "tuple.append", "tuple", "tuple", "tuple", "tuple", "inputs_embeds.transpose().contiguous", "ValueError", "token_type_ids.transpose", "input_mask.transpose", "attention_mask.transpose", "perm_mask.permute", "target_mapping.permute", "torch.nn.functional.one_hot", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_xlnet.XLNetModel.permute", "input_ids.transpose().contiguous.transpose().contiguous.transpose", "torch.zeros", "torch.eye", "torch.zeros().to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "modeling_xlnet.XLNetModel.cache_mem", "h.permute().contiguous", "hs.permute().contiguous", "tuple", "t.permute().contiguous", "inputs_embeds.transpose", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_xlnet.XLNetModel.parameters", "torch.zeros", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "h.permute", "hs.permute", "att_stream.permute().contiguous", "t.permute", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "att_stream.permute"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.relative_positional_encoding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.create_mask", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.cache_mem"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "\n", "perm_mask", "=", "None", ",", "\n", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "input_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", ")", ":", "\n", "# the original code for XLNet uses shapes [len, bsz] with the batch dimension at the end", "\n", "# but we want a unified interface in the library with the batch size on the first dimension", "\n", "# so we move here the first dimension (batch) to the end", "\n", "        ", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_ids", "=", "input_ids", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "qlen", ",", "bsz", "=", "input_ids", ".", "shape", "[", "0", "]", ",", "input_ids", ".", "shape", "[", "1", "]", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "inputs_embeds", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "qlen", ",", "bsz", "=", "inputs_embeds", ".", "shape", "[", "0", "]", ",", "inputs_embeds", ".", "shape", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "token_type_ids", "=", "token_type_ids", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "input_mask", "=", "input_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "if", "input_mask", "is", "not", "None", "else", "None", "\n", "attention_mask", "=", "attention_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "perm_mask", "=", "perm_mask", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "if", "perm_mask", "is", "not", "None", "else", "None", "\n", "target_mapping", "=", "target_mapping", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "if", "target_mapping", "is", "not", "None", "else", "None", "\n", "\n", "mlen", "=", "mems", "[", "0", "]", ".", "shape", "[", "0", "]", "if", "mems", "is", "not", "None", "and", "mems", "[", "0", "]", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "\n", "dtype_float", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "# Attention mask", "\n", "# causal attention mask", "\n", "if", "self", ".", "attn_type", "==", "\"uni\"", ":", "\n", "            ", "attn_mask", "=", "self", ".", "create_mask", "(", "qlen", ",", "mlen", ")", "\n", "attn_mask", "=", "attn_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "", "elif", "self", ".", "attn_type", "==", "\"bi\"", ":", "\n", "            ", "attn_mask", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unsupported attention type: {}\"", ".", "format", "(", "self", ".", "attn_type", ")", ")", "\n", "\n", "# data mask: input mask & perm mask", "\n", "", "assert", "input_mask", "is", "None", "or", "attention_mask", "is", "None", ",", "\"You can only use one of input_mask (uses 1 for padding) \"", "\n", "\"or attention_mask (uses 0 for padding, added for compatbility with BERT). Please choose one.\"", "\n", "if", "input_mask", "is", "None", "and", "attention_mask", "is", "not", "None", ":", "\n", "            ", "input_mask", "=", "1.0", "-", "attention_mask", "\n", "", "if", "input_mask", "is", "not", "None", "and", "perm_mask", "is", "not", "None", ":", "\n", "            ", "data_mask", "=", "input_mask", "[", "None", "]", "+", "perm_mask", "\n", "", "elif", "input_mask", "is", "not", "None", "and", "perm_mask", "is", "None", ":", "\n", "            ", "data_mask", "=", "input_mask", "[", "None", "]", "\n", "", "elif", "input_mask", "is", "None", "and", "perm_mask", "is", "not", "None", ":", "\n", "            ", "data_mask", "=", "perm_mask", "\n", "", "else", ":", "\n", "            ", "data_mask", "=", "None", "\n", "\n", "", "if", "data_mask", "is", "not", "None", ":", "\n", "# all mems can be attended to", "\n", "            ", "if", "mlen", ">", "0", ":", "\n", "                ", "mems_mask", "=", "torch", ".", "zeros", "(", "[", "data_mask", ".", "shape", "[", "0", "]", ",", "mlen", ",", "bsz", "]", ")", ".", "to", "(", "data_mask", ")", "\n", "data_mask", "=", "torch", ".", "cat", "(", "[", "mems_mask", ",", "data_mask", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "attn_mask", "is", "None", ":", "\n", "                ", "attn_mask", "=", "data_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "", "else", ":", "\n", "                ", "attn_mask", "+=", "data_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "(", "attn_mask", ">", "0", ")", ".", "to", "(", "dtype_float", ")", "\n", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "non_tgt_mask", "=", "-", "torch", ".", "eye", "(", "qlen", ")", ".", "to", "(", "attn_mask", ")", "\n", "if", "mlen", ">", "0", ":", "\n", "                ", "non_tgt_mask", "=", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ")", ".", "to", "(", "attn_mask", ")", ",", "non_tgt_mask", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "non_tgt_mask", "=", "(", "(", "attn_mask", "+", "non_tgt_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", ")", ">", "0", ")", ".", "to", "(", "attn_mask", ")", "\n", "", "else", ":", "\n", "            ", "non_tgt_mask", "=", "None", "\n", "\n", "# Word embeddings and prepare h & g hidden states", "\n", "", "if", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "word_emb_k", "=", "inputs_embeds", "\n", "", "else", ":", "\n", "            ", "word_emb_k", "=", "self", ".", "word_embedding", "(", "input_ids", ")", "\n", "", "output_h", "=", "self", ".", "dropout", "(", "word_emb_k", ")", "\n", "if", "target_mapping", "is", "not", "None", ":", "\n", "            ", "word_emb_q", "=", "self", ".", "mask_emb", ".", "expand", "(", "target_mapping", ".", "shape", "[", "0", "]", ",", "bsz", ",", "-", "1", ")", "\n", "# else:  # We removed the inp_q input which was same as target mapping", "\n", "#     inp_q_ext = inp_q[:, :, None]", "\n", "#     word_emb_q = inp_q_ext * self.mask_emb + (1 - inp_q_ext) * word_emb_k", "\n", "output_g", "=", "self", ".", "dropout", "(", "word_emb_q", ")", "\n", "", "else", ":", "\n", "            ", "output_g", "=", "None", "\n", "\n", "# Segment embedding", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "# Convert `token_type_ids` to one-hot `seg_mat`", "\n", "            ", "if", "mlen", ">", "0", ":", "\n", "                ", "mem_pad", "=", "torch", ".", "zeros", "(", "[", "mlen", ",", "bsz", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "cat_ids", "=", "torch", ".", "cat", "(", "[", "mem_pad", ",", "token_type_ids", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat_ids", "=", "token_type_ids", "\n", "\n", "# `1` indicates not in the same segment [qlen x klen x bsz]", "\n", "", "seg_mat", "=", "(", "token_type_ids", "[", ":", ",", "None", "]", "!=", "cat_ids", "[", "None", ",", ":", "]", ")", ".", "long", "(", ")", "\n", "seg_mat", "=", "F", ".", "one_hot", "(", "seg_mat", ",", "num_classes", "=", "2", ")", ".", "to", "(", "dtype_float", ")", "\n", "", "else", ":", "\n", "            ", "seg_mat", "=", "None", "\n", "\n", "# Positional encoding", "\n", "", "pos_emb", "=", "self", ".", "relative_positional_encoding", "(", "qlen", ",", "klen", ",", "bsz", "=", "bsz", ")", "\n", "pos_emb", "=", "self", ".", "dropout", "(", "pos_emb", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads] (a head_mask for each layer)", "\n", "# and head_mask is converted to shape [num_hidden_layers x qlen x klen x bsz x n_head]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layer", "\n", "\n", "", "new_mems", "=", "(", ")", "\n", "if", "mems", "is", "None", ":", "\n", "            ", "mems", "=", "[", "None", "]", "*", "len", "(", "self", ".", "layer", ")", "\n", "\n", "", "attentions", "=", "[", "]", "\n", "hidden_states", "=", "[", "]", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "mem_len", "is", "not", "None", "and", "self", ".", "mem_len", ">", "0", "and", "self", ".", "output_past", ":", "\n", "# cache new mems", "\n", "                ", "new_mems", "=", "new_mems", "+", "(", "self", ".", "cache_mem", "(", "output_h", ",", "mems", "[", "i", "]", ")", ",", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "hidden_states", ".", "append", "(", "(", "output_h", ",", "output_g", ")", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "", "outputs", "=", "layer_module", "(", "\n", "output_h", ",", "\n", "output_g", ",", "\n", "attn_mask_h", "=", "non_tgt_mask", ",", "\n", "attn_mask_g", "=", "attn_mask", ",", "\n", "r", "=", "pos_emb", ",", "\n", "seg_mat", "=", "seg_mat", ",", "\n", "mems", "=", "mems", "[", "i", "]", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", "[", "i", "]", ",", "\n", ")", "\n", "output_h", ",", "output_g", "=", "outputs", "[", ":", "2", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "# Add last hidden state", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "hidden_states", ".", "append", "(", "(", "output_h", ",", "output_g", ")", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "", "output", "=", "self", ".", "dropout", "(", "output_g", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "# Prepare outputs, we transpose back here to shape [bsz, len, hidden_dim] (cf. beginning of forward() method)", "\n", "outputs", "=", "(", "output", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ",", ")", "\n", "\n", "if", "self", ".", "mem_len", "is", "not", "None", "and", "self", ".", "mem_len", ">", "0", "and", "self", ".", "output_past", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "new_mems", ",", ")", "\n", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "if", "output_g", "is", "not", "None", ":", "\n", "                ", "hidden_states", "=", "tuple", "(", "h", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", "for", "hs", "in", "hidden_states", "for", "h", "in", "hs", ")", "\n", "", "else", ":", "\n", "                ", "hidden_states", "=", "tuple", "(", "hs", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", "for", "hs", "in", "hidden_states", ")", "\n", "", "outputs", "=", "outputs", "+", "(", "hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "if", "target_mapping", "is", "not", "None", ":", "\n", "# when target_mapping is provided, there are 2-tuple of attentions", "\n", "                ", "attentions", "=", "tuple", "(", "\n", "tuple", "(", "att_stream", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "for", "att_stream", "in", "t", ")", "for", "t", "in", "attentions", "\n", ")", "\n", "", "else", ":", "\n", "                ", "attentions", "=", "tuple", "(", "t", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "for", "t", "in", "attentions", ")", "\n", "", "outputs", "=", "outputs", "+", "(", "attentions", ",", ")", "\n", "\n", "", "return", "outputs", "# outputs, (new_mems), (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetLMHeadModel.__init__": [[998, 1007], ["modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "torch.nn.Linear", "modeling_xlnet.XLNetLMHeadModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "lm_loss", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "vocab_size", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetLMHeadModel.get_output_embeddings": [[1008, 1010], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetLMHeadModel.prepare_inputs_for_generation": [[1011, 1029], ["torch.zeros", "torch.cat", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "**", "model_kwargs", ")", ":", "\n", "# Add dummy token at the end (no attention on this one)", "\n", "        ", "dummy_token", "=", "torch", ".", "zeros", "(", "(", "1", ",", "1", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", ",", "dummy_token", "]", ",", "dim", "=", "1", ")", "\n", "\n", "# Build permutation mask so that previous tokens don't see last token", "\n", "perm_mask", "=", "torch", ".", "zeros", "(", "\n", "(", "input_ids", ".", "shape", "[", "0", "]", ",", "input_ids", ".", "shape", "[", "1", "]", ",", "input_ids", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "input_ids", ".", "device", "\n", ")", "\n", "perm_mask", "[", ":", ",", ":", ",", "-", "1", "]", "=", "1.0", "\n", "\n", "# We'll only predict the last token", "\n", "target_mapping", "=", "torch", ".", "zeros", "(", "\n", "(", "input_ids", ".", "shape", "[", "0", "]", ",", "1", ",", "input_ids", ".", "shape", "[", "1", "]", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "input_ids", ".", "device", "\n", ")", "\n", "target_mapping", "[", "0", ",", "0", ",", "-", "1", "]", "=", "1.0", "\n", "\n", "return", "{", "\"input_ids\"", ":", "input_ids", ",", "\"perm_mask\"", ":", "perm_mask", ",", "\"target_mapping\"", ":", "target_mapping", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetLMHeadModel.forward": [[1030, 1066], ["modeling_xlnet.XLNetLMHeadModel.transformer", "modeling_xlnet.XLNetLMHeadModel.lm_loss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_xlnet.XLNetLMHeadModel.view", "labels.view", "modeling_xlnet.XLNetLMHeadModel.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "\n", "perm_mask", "=", "None", ",", "\n", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "input_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "\n", "perm_mask", "=", "perm_mask", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "logits", "=", "self", ".", "lm_loss", "(", "transformer_outputs", "[", "0", "]", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Flatten the tokens", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# return (loss), logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetForSequenceClassification.__init__": [[1112, 1121], ["modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "modeling_utils.SequenceSummary", "torch.nn.Linear", "modeling_xlnet.XLNetForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "sequence_summary", "=", "SequenceSummary", "(", "config", ")", "\n", "self", ".", "logits_proj", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetForSequenceClassification.forward": [[1122, 1164], ["modeling_xlnet.XLNetForSequenceClassification.transformer", "modeling_xlnet.XLNetForSequenceClassification.sequence_summary", "modeling_xlnet.XLNetForSequenceClassification.logits_proj", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_xlnet.XLNetForSequenceClassification.view", "labels.view", "modeling_xlnet.XLNetForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "\n", "perm_mask", "=", "None", ",", "\n", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "input_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "\n", "perm_mask", "=", "perm_mask", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "output", "=", "self", ".", "sequence_summary", "(", "output", ")", "\n", "logits", "=", "self", ".", "logits_proj", "(", "output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# return (loss), logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetForTokenClassification.__init__": [[1227, 1235], ["modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "torch.nn.Linear", "modeling_xlnet.XLNetForTokenClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetForTokenClassification.forward": [[1236, 1280], ["modeling_xlnet.XLNetForTokenClassification.transformer", "modeling_xlnet.XLNetForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "modeling_xlnet.XLNetForTokenClassification.view", "labels.view", "modeling_xlnet.XLNetForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "\n", "perm_mask", "=", "None", ",", "\n", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "input_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "\n", "perm_mask", "=", "perm_mask", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# return (loss), logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetForMultipleChoice.__init__": [[1348, 1356], ["modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "modeling_utils.SequenceSummary", "torch.nn.Linear", "modeling_xlnet.XLNetForMultipleChoice.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "sequence_summary", "=", "SequenceSummary", "(", "config", ")", "\n", "self", ".", "logits_proj", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "1", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetForMultipleChoice.forward": [[1357, 1404], ["input_ids.view", "modeling_xlnet.XLNetForMultipleChoice.transformer", "modeling_xlnet.XLNetForMultipleChoice.sequence_summary", "modeling_xlnet.XLNetForMultipleChoice.logits_proj", "modeling_xlnet.XLNetForMultipleChoice.view", "input_ids.size", "token_type_ids.view", "attention_mask.view", "input_mask.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "token_type_ids.size", "attention_mask.size", "input_mask.size", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "input_mask", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "\n", "perm_mask", "=", "None", ",", "\n", "target_mapping", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", ")", ":", "\n", "        ", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "\n", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "flat_input_mask", "=", "input_mask", ".", "view", "(", "-", "1", ",", "input_mask", ".", "size", "(", "-", "1", ")", ")", "if", "input_mask", "is", "not", "None", "else", "None", "\n", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "flat_input_ids", ",", "\n", "token_type_ids", "=", "flat_token_type_ids", ",", "\n", "input_mask", "=", "flat_input_mask", ",", "\n", "attention_mask", "=", "flat_attention_mask", ",", "\n", "mems", "=", "mems", ",", "\n", "perm_mask", "=", "perm_mask", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "output", "=", "self", ".", "sequence_summary", "(", "output", ")", "\n", "logits", "=", "self", ".", "logits_proj", "(", "output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "num_choices", ")", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "+", "transformer_outputs", "[", "\n", "1", ":", "\n", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# return (loss), logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetForQuestionAnsweringSimple.__init__": [[1456, 1464], ["modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "torch.nn.Linear", "modeling_xlnet.XLNetForQuestionAnsweringSimple.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForQuestionAnsweringSimple", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetForQuestionAnsweringSimple.forward": [[1465, 1518], ["modeling_xlnet.XLNetForQuestionAnsweringSimple.transformer", "modeling_xlnet.XLNetForQuestionAnsweringSimple.qa_outputs", "modeling_xlnet.XLNetForQuestionAnsweringSimple.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "\n", "perm_mask", "=", "None", ",", "\n", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "input_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "\n", "end_positions", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "\n", "perm_mask", "=", "perm_mask", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (mems), (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetForQuestionAnswering.__init__": [[1588, 1599], ["modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "modeling_utils.PoolerStartLogits", "modeling_utils.PoolerEndLogits", "modeling_utils.PoolerAnswerClass", "modeling_xlnet.XLNetForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "start_n_top", "=", "config", ".", "start_n_top", "\n", "self", ".", "end_n_top", "=", "config", ".", "end_n_top", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "start_logits", "=", "PoolerStartLogits", "(", "config", ")", "\n", "self", ".", "end_logits", "=", "PoolerEndLogits", "(", "config", ")", "\n", "self", ".", "answer_class", "=", "PoolerAnswerClass", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.XLNetForQuestionAnswering.forward": [[1600, 1695], ["modeling_xlnet.XLNetForQuestionAnswering.transformer", "modeling_xlnet.XLNetForQuestionAnswering.start_logits", "modeling_xlnet.XLNetForQuestionAnswering.end_logits", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "hidden_states.size", "torch.nn.functional.softmax", "torch.topk", "start_top_index.unsqueeze().expand", "torch.gather", "torch.einsum.unsqueeze().expand", "hidden_states.unsqueeze().expand_as", "modeling_xlnet.XLNetForQuestionAnswering.end_logits", "torch.nn.functional.softmax", "torch.topk", "end_top_log_probs.view.view.view", "end_top_index.view.view.view", "torch.einsum", "modeling_xlnet.XLNetForQuestionAnswering.answer_class", "modeling_xlnet.XLNetForQuestionAnswering.answer_class", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "p_mask.unsqueeze", "x.squeeze_", "start_top_index.unsqueeze", "torch.einsum.unsqueeze", "hidden_states.unsqueeze", "x.dim"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "\n", "perm_mask", "=", "None", ",", "\n", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "input_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "\n", "end_positions", "=", "None", ",", "\n", "is_impossible", "=", "None", ",", "\n", "cls_index", "=", "None", ",", "\n", "p_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "\n", "perm_mask", "=", "perm_mask", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "start_logits", "=", "self", ".", "start_logits", "(", "hidden_states", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "outputs", "=", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, let's remove the dimension added by batch splitting", "\n", "            ", "for", "x", "in", "(", "start_positions", ",", "end_positions", ",", "cls_index", ",", "is_impossible", ")", ":", "\n", "                ", "if", "x", "is", "not", "None", "and", "x", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "x", ".", "squeeze_", "(", "-", "1", ")", "\n", "\n", "# during training, compute the end logits based on the ground truth of the start position", "\n", "", "", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "if", "cls_index", "is", "not", "None", "and", "is_impossible", "is", "not", "None", ":", "\n", "# Predict answerability from the representation of CLS and START", "\n", "                ", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "cls_index", "=", "cls_index", ")", "\n", "loss_fct_cls", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "cls_loss", "=", "loss_fct_cls", "(", "cls_logits", ",", "is_impossible", ")", "\n", "\n", "# note(zhiliny): by default multiply the loss by 0.5 so that the scale is comparable to start_loss and end_loss", "\n", "total_loss", "+=", "cls_loss", "*", "0.5", "\n", "\n", "", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "else", ":", "\n", "# during inference, compute the end logits based on beam search", "\n", "            ", "bsz", ",", "slen", ",", "hsz", "=", "hidden_states", ".", "size", "(", ")", "\n", "start_log_probs", "=", "F", ".", "softmax", "(", "start_logits", ",", "dim", "=", "-", "1", ")", "# shape (bsz, slen)", "\n", "\n", "start_top_log_probs", ",", "start_top_index", "=", "torch", ".", "topk", "(", "\n", "start_log_probs", ",", "self", ".", "start_n_top", ",", "dim", "=", "-", "1", "\n", ")", "# shape (bsz, start_n_top)", "\n", "start_top_index_exp", "=", "start_top_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "torch", ".", "gather", "(", "hidden_states", ",", "-", "2", ",", "start_top_index_exp", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "start_states", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ",", "-", "1", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "\n", "hidden_states_expanded", "=", "hidden_states", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "\n", "start_states", "\n", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "p_mask", "=", "p_mask", ".", "unsqueeze", "(", "-", "1", ")", "if", "p_mask", "is", "not", "None", "else", "None", "\n", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states_expanded", ",", "start_states", "=", "start_states", ",", "p_mask", "=", "p_mask", ")", "\n", "end_log_probs", "=", "F", ".", "softmax", "(", "end_logits", ",", "dim", "=", "1", ")", "# shape (bsz, slen, start_n_top)", "\n", "\n", "end_top_log_probs", ",", "end_top_index", "=", "torch", ".", "topk", "(", "\n", "end_log_probs", ",", "self", ".", "end_n_top", ",", "dim", "=", "1", "\n", ")", "# shape (bsz, end_n_top, start_n_top)", "\n", "end_top_log_probs", "=", "end_top_log_probs", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "end_top_index", "=", "end_top_index", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "\n", "start_states", "=", "torch", ".", "einsum", "(", "\n", "\"blh,bl->bh\"", ",", "hidden_states", ",", "start_log_probs", "\n", ")", "# get the representation of START as weighted sum of hidden states", "\n", "cls_logits", "=", "self", ".", "answer_class", "(", "\n", "hidden_states", ",", "start_states", "=", "start_states", ",", "cls_index", "=", "cls_index", "\n", ")", "# Shape (batch size,): one single `cls_logits` for each sample", "\n", "\n", "outputs", "=", "(", "start_top_log_probs", ",", "start_top_index", ",", "end_top_log_probs", ",", "end_top_index", ",", "cls_logits", ")", "+", "outputs", "\n", "\n", "# return start_top_log_probs, start_top_index, end_top_log_probs, end_top_index, cls_logits", "\n", "# or (if labels are provided) (total_loss,)", "\n", "", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.build_tf_xlnet_to_pytorch_map": [[41, 122], ["hasattr", "tf_to_pt_map.update", "enumerate", "tf_to_pt_map.update", "hasattr", "tf_to_pt_map.update", "hasattr", "hasattr", "r_r_list.append", "r_w_list.append", "r_s_list.append", "seg_embed_list.append"], "function", ["None"], ["def", "build_tf_xlnet_to_pytorch_map", "(", "model", ",", "config", ",", "tf_weights", "=", "None", ")", ":", "\n", "    ", "\"\"\" A map of modules from TF to PyTorch.\n        I use a map to keep the PyTorch model as\n        identical to the original PyTorch model as possible.\n    \"\"\"", "\n", "\n", "tf_to_pt_map", "=", "{", "}", "\n", "\n", "if", "hasattr", "(", "model", ",", "\"transformer\"", ")", ":", "\n", "        ", "if", "hasattr", "(", "model", ",", "\"lm_loss\"", ")", ":", "\n", "# We will load also the output bias", "\n", "            ", "tf_to_pt_map", "[", "\"model/lm_loss/bias\"", "]", "=", "model", ".", "lm_loss", ".", "bias", "\n", "", "if", "hasattr", "(", "model", ",", "\"sequence_summary\"", ")", "and", "\"model/sequnece_summary/summary/kernel\"", "in", "tf_weights", ":", "\n", "# We will load also the sequence summary", "\n", "            ", "tf_to_pt_map", "[", "\"model/sequnece_summary/summary/kernel\"", "]", "=", "model", ".", "sequence_summary", ".", "summary", ".", "weight", "\n", "tf_to_pt_map", "[", "\"model/sequnece_summary/summary/bias\"", "]", "=", "model", ".", "sequence_summary", ".", "summary", ".", "bias", "\n", "", "if", "(", "\n", "hasattr", "(", "model", ",", "\"logits_proj\"", ")", "\n", "and", "config", ".", "finetuning_task", "is", "not", "None", "\n", "and", "\"model/regression_{}/logit/kernel\"", ".", "format", "(", "config", ".", "finetuning_task", ")", "in", "tf_weights", "\n", ")", ":", "\n", "            ", "tf_to_pt_map", "[", "\"model/regression_{}/logit/kernel\"", ".", "format", "(", "config", ".", "finetuning_task", ")", "]", "=", "model", ".", "logits_proj", ".", "weight", "\n", "tf_to_pt_map", "[", "\"model/regression_{}/logit/bias\"", ".", "format", "(", "config", ".", "finetuning_task", ")", "]", "=", "model", ".", "logits_proj", ".", "bias", "\n", "\n", "# Now load the rest of the transformer", "\n", "", "model", "=", "model", ".", "transformer", "\n", "\n", "# Embeddings and output", "\n", "", "tf_to_pt_map", ".", "update", "(", "\n", "{", "\n", "\"model/transformer/word_embedding/lookup_table\"", ":", "model", ".", "word_embedding", ".", "weight", ",", "\n", "\"model/transformer/mask_emb/mask_emb\"", ":", "model", ".", "mask_emb", ",", "\n", "}", "\n", ")", "\n", "\n", "# Transformer blocks", "\n", "for", "i", ",", "b", "in", "enumerate", "(", "model", ".", "layer", ")", ":", "\n", "        ", "layer_str", "=", "\"model/transformer/layer_%d/\"", "%", "i", "\n", "tf_to_pt_map", ".", "update", "(", "\n", "{", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/gamma\"", ":", "b", ".", "rel_attn", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/beta\"", ":", "b", ".", "rel_attn", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"rel_attn/o/kernel\"", ":", "b", ".", "rel_attn", ".", "o", ",", "\n", "layer_str", "+", "\"rel_attn/q/kernel\"", ":", "b", ".", "rel_attn", ".", "q", ",", "\n", "layer_str", "+", "\"rel_attn/k/kernel\"", ":", "b", ".", "rel_attn", ".", "k", ",", "\n", "layer_str", "+", "\"rel_attn/r/kernel\"", ":", "b", ".", "rel_attn", ".", "r", ",", "\n", "layer_str", "+", "\"rel_attn/v/kernel\"", ":", "b", ".", "rel_attn", ".", "v", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/gamma\"", ":", "b", ".", "ff", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/beta\"", ":", "b", ".", "ff", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_1/kernel\"", ":", "b", ".", "ff", ".", "layer_1", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_1/bias\"", ":", "b", ".", "ff", ".", "layer_1", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_2/kernel\"", ":", "b", ".", "ff", ".", "layer_2", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_2/bias\"", ":", "b", ".", "ff", ".", "layer_2", ".", "bias", ",", "\n", "}", "\n", ")", "\n", "\n", "# Relative positioning biases", "\n", "", "if", "config", ".", "untie_r", ":", "\n", "        ", "r_r_list", "=", "[", "]", "\n", "r_w_list", "=", "[", "]", "\n", "r_s_list", "=", "[", "]", "\n", "seg_embed_list", "=", "[", "]", "\n", "for", "b", "in", "model", ".", "layer", ":", "\n", "            ", "r_r_list", ".", "append", "(", "b", ".", "rel_attn", ".", "r_r_bias", ")", "\n", "r_w_list", ".", "append", "(", "b", ".", "rel_attn", ".", "r_w_bias", ")", "\n", "r_s_list", ".", "append", "(", "b", ".", "rel_attn", ".", "r_s_bias", ")", "\n", "seg_embed_list", ".", "append", "(", "b", ".", "rel_attn", ".", "seg_embed", ")", "\n", "", "", "else", ":", "\n", "        ", "r_r_list", "=", "[", "model", ".", "r_r_bias", "]", "\n", "r_w_list", "=", "[", "model", ".", "r_w_bias", "]", "\n", "r_s_list", "=", "[", "model", ".", "r_s_bias", "]", "\n", "seg_embed_list", "=", "[", "model", ".", "seg_embed", "]", "\n", "", "tf_to_pt_map", ".", "update", "(", "\n", "{", "\n", "\"model/transformer/r_r_bias\"", ":", "r_r_list", ",", "\n", "\"model/transformer/r_w_bias\"", ":", "r_w_list", ",", "\n", "\"model/transformer/r_s_bias\"", ":", "r_s_list", ",", "\n", "\"model/transformer/seg_embed\"", ":", "seg_embed_list", ",", "\n", "}", "\n", ")", "\n", "return", "tf_to_pt_map", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.load_tf_weights_in_xlnet": [[124, 184], ["tf.train.list_variables", "modeling_xlnet.build_tf_xlnet_to_pytorch_map", "build_tf_xlnet_to_pytorch_map.items", "logger.info", "logger.info", "tf.train.load_variable", "logger.info", "isinstance", "tf_weights.pop", "tf_weights.pop", "tf_weights.pop", "logger.error", "logger.info", "logger.info", "np.transpose", "enumerate", "logger.info", "torch.from_numpy", "len", "logger.info", "torch.from_numpy", "tf_weights.keys"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.build_tf_xlnet_to_pytorch_map"], ["", "def", "load_tf_weights_in_xlnet", "(", "model", ",", "config", ",", "tf_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow models in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "# Load weights from TF model", "\n", "", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "tf_weights", "=", "{", "}", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "tf_weights", "[", "name", "]", "=", "array", "\n", "\n", "# Build TF to PyTorch weights loading map", "\n", "", "tf_to_pt_map", "=", "build_tf_xlnet_to_pytorch_map", "(", "model", ",", "config", ",", "tf_weights", ")", "\n", "\n", "for", "name", ",", "pointer", "in", "tf_to_pt_map", ".", "items", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Importing {}\"", ".", "format", "(", "name", ")", ")", "\n", "if", "name", "not", "in", "tf_weights", ":", "\n", "            ", "logger", ".", "info", "(", "\"{} not in tf pre-trained weights, skipping\"", ".", "format", "(", "name", ")", ")", "\n", "continue", "\n", "", "array", "=", "tf_weights", "[", "name", "]", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "\"kernel\"", "in", "name", "and", "(", "\"ff\"", "in", "name", "or", "\"summary\"", "in", "name", "or", "\"logit\"", "in", "name", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Transposing\"", ")", "\n", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "if", "isinstance", "(", "pointer", ",", "list", ")", ":", "\n", "# Here we will split the TF weigths", "\n", "            ", "assert", "len", "(", "pointer", ")", "==", "array", ".", "shape", "[", "0", "]", "\n", "for", "i", ",", "p_i", "in", "enumerate", "(", "pointer", ")", ":", "\n", "                ", "arr_i", "=", "array", "[", "i", ",", "...", "]", "\n", "try", ":", "\n", "                    ", "assert", "p_i", ".", "shape", "==", "arr_i", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                    ", "e", ".", "args", "+=", "(", "p_i", ".", "shape", ",", "arr_i", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {} for layer {}\"", ".", "format", "(", "name", ",", "i", ")", ")", "\n", "p_i", ".", "data", "=", "torch", ".", "from_numpy", "(", "arr_i", ")", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "tf_weights", ".", "pop", "(", "name", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "\"/Adam\"", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "\"/Adam_1\"", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Weights not copied to PyTorch model: {}\"", ".", "format", "(", "\", \"", ".", "join", "(", "tf_weights", ".", "keys", "(", ")", ")", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.gelu": [[186, 193], ["torch.tanh", "math.sqrt", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Implementation of the gelu activation function.\n        XLNet is using OpenAI GPT's gelu (not exactly the same as BERT)\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlnet.swish": [[195, 197], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_bert.BertConfig.__init__": [[82, 111], ["configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "30522", ",", "\n", "hidden_size", "=", "768", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "intermediate_size", "=", "3072", ",", "\n", "hidden_act", "=", "\"gelu\"", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "type_vocab_size", "=", "2", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "layer_norm_eps", "=", "1e-12", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "BertConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "hidden_act", "=", "hidden_act", "\n", "self", ".", "intermediate_size", "=", "intermediate_size", "\n", "self", ".", "hidden_dropout_prob", "=", "hidden_dropout_prob", "\n", "self", ".", "attention_probs_dropout_prob", "=", "attention_probs_dropout_prob", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "type_vocab_size", "=", "type_vocab_size", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "layer_norm_eps", "=", "layer_norm_eps", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.AdamW.__init__": [[107, 118], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "eps", "=", "1e-6", ",", "weight_decay", "=", "0.0", ",", "correct_bias", "=", "True", ")", ":", "\n", "        ", "if", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "0", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "betas", "[", "0", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "betas", "[", "1", "]", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid beta parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "betas", "[", "1", "]", ")", ")", "\n", "", "if", "not", "0.0", "<=", "eps", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {} - should be >= 0.0\"", ".", "format", "(", "eps", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "betas", "=", "betas", ",", "eps", "=", "eps", ",", "weight_decay", "=", "weight_decay", ",", "correct_bias", "=", "correct_bias", ")", "\n", "super", "(", "AdamW", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.AdamW.step": [[119, 179], ["closure", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "exp_avg_sq.sqrt().add_", "p.data.addcdiv_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "p.data.add_", "exp_avg.mul_", "exp_avg_sq.mul_", "exp_avg_sq.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "\"params\"", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\"Adam does not support sparse gradients, please consider SparseAdam instead\"", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "\"step\"", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "\"exp_avg\"", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "\"exp_avg_sq\"", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "\"exp_avg\"", "]", ",", "state", "[", "\"exp_avg_sq\"", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "\"betas\"", "]", "\n", "\n", "state", "[", "\"step\"", "]", "+=", "1", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# In-place operations to update the averages at the same time", "\n", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1.0", "-", "beta1", ",", "grad", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1.0", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "\"eps\"", "]", ")", "\n", "\n", "step_size", "=", "group", "[", "\"lr\"", "]", "\n", "if", "group", "[", "\"correct_bias\"", "]", ":", "# No bias correction for Bert", "\n", "                    ", "bias_correction1", "=", "1.0", "-", "beta1", "**", "state", "[", "\"step\"", "]", "\n", "bias_correction2", "=", "1.0", "-", "beta2", "**", "state", "[", "\"step\"", "]", "\n", "step_size", "=", "step_size", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "bias_correction1", "\n", "\n", "", "p", ".", "data", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want to decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "# Add weight decay at the end (fixed version)", "\n", "if", "group", "[", "\"weight_decay\"", "]", ">", "0.0", ":", "\n", "                    ", "p", ".", "data", ".", "add_", "(", "-", "group", "[", "\"lr\"", "]", "*", "group", "[", "\"weight_decay\"", "]", ",", "p", ".", "data", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_constant_schedule": [[28, 32], ["torch.optim.lr_scheduler.LambdaLR"], "function", ["None"], ["def", "get_constant_schedule", "(", "optimizer", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\" Create a schedule with a constant learning rate.\n    \"\"\"", "\n", "return", "LambdaLR", "(", "optimizer", ",", "lambda", "_", ":", "1", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_constant_schedule_with_warmup": [[34, 45], ["torch.optim.lr_scheduler.LambdaLR", "float", "float", "max"], "function", ["None"], ["", "def", "get_constant_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\" Create a schedule with a constant learning rate preceded by a warmup\n    period during which the learning rate increases linearly between 0 and 1.\n    \"\"\"", "\n", "\n", "def", "lr_lambda", "(", "current_step", ")", ":", "\n", "        ", "if", "current_step", "<", "num_warmup_steps", ":", "\n", "            ", "return", "float", "(", "current_step", ")", "/", "float", "(", "max", "(", "1.0", ",", "num_warmup_steps", ")", ")", "\n", "", "return", "1.0", "\n", "\n", "", "return", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ",", "last_epoch", "=", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_linear_schedule_with_warmup": [[47, 60], ["torch.optim.lr_scheduler.LambdaLR", "max", "float", "float", "float", "float", "max", "max"], "function", ["None"], ["", "def", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", ",", "num_training_steps", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\" Create a schedule with a learning rate that decreases linearly after\n    linearly increasing during a warmup period.\n    \"\"\"", "\n", "\n", "def", "lr_lambda", "(", "current_step", ")", ":", "\n", "        ", "if", "current_step", "<", "num_warmup_steps", ":", "\n", "            ", "return", "float", "(", "current_step", ")", "/", "float", "(", "max", "(", "1", ",", "num_warmup_steps", ")", ")", "\n", "", "return", "max", "(", "\n", "0.0", ",", "float", "(", "num_training_steps", "-", "current_step", ")", "/", "float", "(", "max", "(", "1", ",", "num_training_steps", "-", "num_warmup_steps", ")", ")", "\n", ")", "\n", "\n", "", "return", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_cosine_schedule_with_warmup": [[62, 75], ["torch.optim.lr_scheduler.LambdaLR", "max", "float", "float", "float", "float", "max", "max", "math.cos", "float"], "function", ["None"], ["", "def", "get_cosine_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", ",", "num_training_steps", ",", "num_cycles", "=", "0.5", ",", "last_epoch", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\" Create a schedule with a learning rate that decreases following the\n    values of the cosine function between 0 and `pi * cycles` after a warmup\n    period during which it increases linearly between 0 and 1.\n    \"\"\"", "\n", "\n", "def", "lr_lambda", "(", "current_step", ")", ":", "\n", "        ", "if", "current_step", "<", "num_warmup_steps", ":", "\n", "            ", "return", "float", "(", "current_step", ")", "/", "float", "(", "max", "(", "1", ",", "num_warmup_steps", ")", ")", "\n", "", "progress", "=", "float", "(", "current_step", "-", "num_warmup_steps", ")", "/", "float", "(", "max", "(", "1", ",", "num_training_steps", "-", "num_warmup_steps", ")", ")", "\n", "return", "max", "(", "0.0", ",", "0.5", "*", "(", "1.0", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "float", "(", "num_cycles", ")", "*", "2.0", "*", "progress", ")", ")", ")", "\n", "\n", "", "return", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_cosine_with_hard_restarts_schedule_with_warmup": [[77, 94], ["torch.optim.lr_scheduler.LambdaLR", "max", "float", "float", "float", "float", "max", "max", "math.cos", "float"], "function", ["None"], ["", "def", "get_cosine_with_hard_restarts_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", ",", "num_training_steps", ",", "num_cycles", "=", "1.0", ",", "last_epoch", "=", "-", "1", "\n", ")", ":", "\n", "    ", "\"\"\" Create a schedule with a learning rate that decreases following the\n    values of the cosine function with several hard restarts, after a warmup\n    period during which it increases linearly between 0 and 1.\n    \"\"\"", "\n", "\n", "def", "lr_lambda", "(", "current_step", ")", ":", "\n", "        ", "if", "current_step", "<", "num_warmup_steps", ":", "\n", "            ", "return", "float", "(", "current_step", ")", "/", "float", "(", "max", "(", "1", ",", "num_warmup_steps", ")", ")", "\n", "", "progress", "=", "float", "(", "current_step", "-", "num_warmup_steps", ")", "/", "float", "(", "max", "(", "1", ",", "num_training_steps", "-", "num_warmup_steps", ")", ")", "\n", "if", "progress", ">=", "1.0", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "max", "(", "0.0", ",", "0.5", "*", "(", "1.0", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "(", "(", "float", "(", "num_cycles", ")", "*", "progress", ")", "%", "1.0", ")", ")", ")", ")", "\n", "\n", "", "return", "LambdaLR", "(", "optimizer", ",", "lr_lambda", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_kcnet_original_pytorch_checkpoint_to_pytorch.convert_kcnet_checkpoint_to_pytorch": [[32, 72], ["torch.load", "state_dict.items", "dict", "dict", "print", "torch.save", "print", "print", "torch.load.keys", "io.open", "f.write", "io.open", "f.write", "k.startswith", "state_dict.items", "dict.items", "dict.items", "json.dumps", "json.dumps", "isinstance", "s.replace", "s.find"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save"], ["def", "convert_kcnet_checkpoint_to_pytorch", "(", "kcnet_checkpoint_path", ",", "pytorch_dump_folder_path", ")", ":", "\n", "# Load checkpoint", "\n", "    ", "chkpt", "=", "torch", ".", "load", "(", "kcnet_checkpoint_path", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "if", "'model'", "in", "chkpt", ".", "keys", "(", ")", ":", "\n", "        ", "state_dict", "=", "chkpt", "[", "'model'", "]", "\n", "", "else", ":", "\n", "        ", "state_dict", "=", "chkpt", "[", "'encoder'", "]", "\n", "\n", "", "state_dict", "=", "{", "(", "k", "[", "7", ":", "]", "if", "k", ".", "startswith", "(", "'module.'", ")", "else", "k", ")", ":", "v", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", "}", "\n", "\n", "# We have the base model one level deeper than the original XLM repository", "\n", "two_levels_state_dict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "'pred_layer'", "in", "k", ":", "\n", "            ", "two_levels_state_dict", "[", "k", "]", "=", "v", "\n", "", "else", ":", "\n", "            ", "two_levels_state_dict", "[", "'transformer.'", "+", "k", "]", "=", "v", "\n", "\n", "", "", "config", "=", "chkpt", "[", "'params'", "]", "\n", "config", "=", "dict", "(", "(", "n", ",", "v", ")", "for", "n", ",", "v", "in", "config", ".", "items", "(", ")", "if", "not", "isinstance", "(", "v", ",", "(", "torch", ".", "FloatTensor", ",", "numpy", ".", "ndarray", ")", ")", ")", "\n", "\n", "vocab", "=", "chkpt", "[", "'dico_word2id'", "]", "\n", "vocab", "=", "dict", "(", "(", "s", "+", "'</w>'", "if", "s", ".", "find", "(", "'@@'", ")", "==", "-", "1", "and", "i", ">", "13", "else", "s", ".", "replace", "(", "'@@'", ",", "''", ")", ",", "i", ")", "for", "s", ",", "i", "in", "vocab", ".", "items", "(", ")", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "WEIGHTS_NAME", "\n", "pytorch_config_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "CONFIG_NAME", "\n", "pytorch_vocab_dump_path", "=", "pytorch_dump_folder_path", "+", "'/'", "+", "VOCAB_FILES_NAMES", "[", "'vocab_file'", "]", "\n", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_weights_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "two_levels_state_dict", ",", "pytorch_weights_dump_path", ")", "\n", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "config", ",", "indent", "=", "2", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "print", "(", "\"Save vocab file to {}\"", ".", "format", "(", "pytorch_vocab_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_vocab_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "vocab", ",", "indent", "=", "2", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_gpt2.GPT2Tokenizer.__init__": [[114, 146], ["tokenization_utils.PreTrainedTokenizer.__init__", "tokenization_gpt2.bytes_to_unicode", "dict", "regex.compile", "open", "json.load", "open", "tuple", "zip", "tokenization_gpt2.GPT2Tokenizer.encoder.items", "tokenization_gpt2.GPT2Tokenizer.byte_encoder.items", "merges_handle.read().split", "merge.split", "range", "len", "merges_handle.read"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_gpt2.bytes_to_unicode"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "merges_file", ",", "\n", "errors", "=", "\"replace\"", ",", "\n", "unk_token", "=", "\"<|endoftext|>\"", ",", "\n", "bos_token", "=", "\"<|endoftext|>\"", ",", "\n", "eos_token", "=", "\"<|endoftext|>\"", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "GPT2Tokenizer", ",", "self", ")", ".", "__init__", "(", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "unk_token", "=", "unk_token", ",", "**", "kwargs", ")", "\n", "self", ".", "max_len_single_sentence", "=", "(", "\n", "self", ".", "max_len", "\n", ")", "# no default special tokens - you can update this value if you add special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "(", "\n", "self", ".", "max_len", "\n", ")", "# no default special tokens - you can update this value if you add special tokens", "\n", "\n", "with", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "vocab_handle", ":", "\n", "            ", "self", ".", "encoder", "=", "json", ".", "load", "(", "vocab_handle", ")", "\n", "", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "errors", "=", "errors", "# how to handle errors in decoding", "\n", "self", ".", "byte_encoder", "=", "bytes_to_unicode", "(", ")", "\n", "self", ".", "byte_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "byte_encoder", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "merges_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "merges_handle", ":", "\n", "            ", "bpe_merges", "=", "merges_handle", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "[", "1", ":", "-", "1", "]", "\n", "", "bpe_merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "bpe_merges", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "bpe_merges", ",", "range", "(", "len", "(", "bpe_merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n", "# Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions", "\n", "self", ".", "pat", "=", "re", ".", "compile", "(", "r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_gpt2.GPT2Tokenizer.vocab_size": [[147, 150], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_gpt2.GPT2Tokenizer.bpe": [[151, 192], ["tuple", "tokenization_gpt2.get_pairs", "min", "tuple", "len", "len", "tokenization_gpt2.get_pairs", "tuple.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_gpt2.GPT2Tokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "word", "=", "tuple", "(", "token", ")", "\n", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "\"inf\"", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "\" \"", ".", "join", "(", "word", ")", "\n", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_gpt2.GPT2Tokenizer._tokenize": [[193, 209], ["regex.findall", "bpe_tokens.extend", "token.encode", "tokenization_gpt2.GPT2Tokenizer.bpe().split", "tokenization_gpt2.GPT2Tokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.OpenAIGPTTokenizer.bpe"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "add_prefix_space", "=", "False", ")", ":", "\n", "        ", "\"\"\" Tokenize a string.\n            Args:\n                - add_prefix_space (boolean, default False):\n                    Begin the sentence with at least one space to get invariance to word order in GPT-2 (and RoBERTa) tokenizers.\n        \"\"\"", "\n", "if", "add_prefix_space", ":", "\n", "            ", "text", "=", "\" \"", "+", "text", "\n", "\n", "", "bpe_tokens", "=", "[", "]", "\n", "for", "token", "in", "re", ".", "findall", "(", "self", ".", "pat", ",", "text", ")", ":", "\n", "            ", "token", "=", "\"\"", ".", "join", "(", "\n", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "\"utf-8\"", ")", "\n", ")", "# Maps all our bytes to unicode strings, avoiding controle tokens of the BPE (spaces in our case)", "\n", "bpe_tokens", ".", "extend", "(", "bpe_token", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "\" \"", ")", ")", "\n", "", "return", "bpe_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_gpt2.GPT2Tokenizer._convert_token_to_id": [[210, 213], ["tokenization_gpt2.GPT2Tokenizer.encoder.get", "tokenization_gpt2.GPT2Tokenizer.encoder.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "encoder", ".", "get", "(", "token", ",", "self", ".", "encoder", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_gpt2.GPT2Tokenizer._convert_id_to_token": [[214, 217], ["tokenization_gpt2.GPT2Tokenizer.decoder.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "get", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_gpt2.GPT2Tokenizer.convert_tokens_to_string": [[218, 223], ["bytearray().decode", "bytearray"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "text", "=", "\"\"", ".", "join", "(", "tokens", ")", "\n", "text", "=", "bytearray", "(", "[", "self", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "text", "]", ")", ".", "decode", "(", "\"utf-8\"", ",", "errors", "=", "self", ".", "errors", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_gpt2.GPT2Tokenizer.save_vocabulary": [[224, 249], ["os.path.join", "os.path.join", "os.path.isdir", "logger.error", "open", "f.write", "open", "writer.write", "sorted", "json.dumps", "tokenization_gpt2.GPT2Tokenizer.bpe_ranks.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary and merge files to a directory.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "merge_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"merges_file\"", "]", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "encoder", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "index", "=", "0", "\n", "with", "open", "(", "merge_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "\"#version: 0.2\\n\"", ")", "\n", "for", "bpe_tokens", ",", "token_index", "in", "sorted", "(", "self", ".", "bpe_ranks", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"Saving vocabulary to {}: BPE merge indices are not consecutive.\"", "\n", "\" Please check that the tokenizer is not corrupted!\"", ".", "format", "(", "merge_file", ")", "\n", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "\" \"", ".", "join", "(", "bpe_tokens", ")", "+", "\"\\n\"", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "return", "vocab_file", ",", "merge_file", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_gpt2.bytes_to_unicode": [[61, 85], ["functools.lru_cache", "range", "dict", "list", "chr", "zip", "list", "list", "range", "bs.append", "cs.append", "range", "range", "ord", "ord", "ord", "ord", "ord", "ord"], "function", ["None"], ["@", "lru_cache", "(", ")", "\n", "def", "bytes_to_unicode", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns list of utf-8 byte and a mapping to unicode strings.\n    We specifically avoids mapping to whitespace/control characters the bpe code barfs on.\n\n    The reversible bpe codes work on unicode strings.\n    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n    This is a signficant percentage of your normal, say, 32K bpe vocab.\n    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n    \"\"\"", "\n", "bs", "=", "(", "\n", "list", "(", "range", "(", "ord", "(", "\"!\"", ")", ",", "ord", "(", "\"~\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00a1\"", ")", ",", "ord", "(", "\"\u00ac\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00ae\"", ")", ",", "ord", "(", "\"\u00ff\"", ")", "+", "1", ")", ")", "\n", ")", "\n", "cs", "=", "bs", "[", ":", "]", "\n", "n", "=", "0", "\n", "for", "b", "in", "range", "(", "2", "**", "8", ")", ":", "\n", "        ", "if", "b", "not", "in", "bs", ":", "\n", "            ", "bs", ".", "append", "(", "b", ")", "\n", "cs", ".", "append", "(", "2", "**", "8", "+", "n", ")", "\n", "n", "+=", "1", "\n", "", "", "cs", "=", "[", "chr", "(", "n", ")", "for", "n", "in", "cs", "]", "\n", "return", "dict", "(", "zip", "(", "bs", ",", "cs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_gpt2.get_pairs": [[87, 98], ["set", "set.add"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.BeamHypotheses.add"], ["", "def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n\n    Word is represented as tuple of symbols (symbols being variable-length strings).\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_t5.T5Config.__init__": [[64, 91], ["configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "32128", ",", "\n", "n_positions", "=", "512", ",", "\n", "d_model", "=", "512", ",", "\n", "d_kv", "=", "64", ",", "\n", "d_ff", "=", "2048", ",", "\n", "num_layers", "=", "6", ",", "\n", "num_heads", "=", "8", ",", "\n", "relative_attention_num_buckets", "=", "32", ",", "\n", "dropout_rate", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-6", ",", "\n", "initializer_factor", "=", "1.0", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "T5Config", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_kv", "=", "d_kv", "\n", "self", ".", "d_ff", "=", "d_ff", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "relative_attention_num_buckets", "=", "relative_attention_num_buckets", "\n", "self", ".", "dropout_rate", "=", "dropout_rate", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_factor", "=", "initializer_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_t5.T5Config.max_position_embeddings": [[92, 95], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_t5.T5Config.hidden_size": [[96, 99], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "d_model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_t5.T5Config.num_attention_heads": [[100, 103], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_heads", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_t5.T5Config.num_hidden_layers": [[104, 107], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_layers", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.PositionalEmbedding.__init__": [[167, 174], ["torch.Module.__init__", "modeling_transfo_xl.PositionalEmbedding.register_buffer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "demb", ")", ":", "\n", "        ", "super", "(", "PositionalEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "demb", "=", "demb", "\n", "\n", "inv_freq", "=", "1", "/", "(", "10000", "**", "(", "torch", ".", "arange", "(", "0.0", ",", "demb", ",", "2.0", ")", "/", "demb", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"inv_freq\"", ",", "inv_freq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.PositionalEmbedding.forward": [[175, 183], ["torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.ger", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pos_emb[].expand", "torch.ger.sin", "torch.ger.sin", "torch.ger.sin", "torch.ger.cos", "torch.ger.cos", "torch.ger.cos"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pos_seq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "torch", ".", "ger", "(", "pos_seq", ",", "self", ".", "inv_freq", ")", "\n", "pos_emb", "=", "torch", ".", "cat", "(", "[", "sinusoid_inp", ".", "sin", "(", ")", ",", "sinusoid_inp", ".", "cos", "(", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.PositionwiseFF.__init__": [[186, 204], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "d_inner", ",", "dropout", ",", "pre_lnorm", "=", "False", ",", "layer_norm_epsilon", "=", "1e-5", ")", ":", "\n", "        ", "super", "(", "PositionwiseFF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "CoreNet", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "d_model", ",", "d_inner", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "d_inner", ",", "d_model", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ",", "\n", ")", "\n", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.PositionwiseFF.forward": [[205, 220], ["modeling_transfo_xl.PositionwiseFF.CoreNet", "modeling_transfo_xl.PositionwiseFF.CoreNet", "modeling_transfo_xl.PositionwiseFF.layer_norm", "modeling_transfo_xl.PositionwiseFF.layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "self", ".", "pre_lnorm", ":", "\n", "# layer normalization + positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "CoreNet", "(", "self", ".", "layer_norm", "(", "inp", ")", ")", "\n", "\n", "# residual connection", "\n", "output", "=", "core_out", "+", "inp", "\n", "", "else", ":", "\n", "# positionwise feed-forward", "\n", "            ", "core_out", "=", "self", ".", "CoreNet", "(", "inp", ")", "\n", "\n", "# residual connection + layer normalization", "\n", "output", "=", "self", ".", "layer_norm", "(", "inp", "+", "core_out", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.__init__": [[223, 267], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "torch.LayerNorm", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "n_head", ",", "\n", "d_model", ",", "\n", "d_head", ",", "\n", "dropout", ",", "\n", "dropatt", "=", "0", ",", "\n", "tgt_len", "=", "None", ",", "\n", "ext_len", "=", "None", ",", "\n", "mem_len", "=", "None", ",", "\n", "pre_lnorm", "=", "False", ",", "\n", "r_r_bias", "=", "None", ",", "\n", "r_w_bias", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableMultiHeadAttn", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "output_attentions", "=", "output_attentions", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "qkv_net", "=", "nn", ".", "Linear", "(", "d_model", ",", "3", "*", "n_head", "*", "d_head", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropatt", "=", "nn", ".", "Dropout", "(", "dropatt", ")", "\n", "self", ".", "o_net", "=", "nn", ".", "Linear", "(", "n_head", "*", "d_head", ",", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "layer_norm", "=", "nn", ".", "LayerNorm", "(", "d_model", ",", "eps", "=", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "scale", "=", "1", "/", "(", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "\n", "if", "r_r_bias", "is", "None", "or", "r_w_bias", "is", "None", ":", "# Biases are not shared", "\n", "            ", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "r_r_bias", "=", "r_r_bias", "\n", "self", ".", "r_w_bias", "=", "r_w_bias", "\n", "\n", "", "self", ".", "r_net", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn._rel_shift": [[268, 279], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_padded.view.view.view", "x_padded[].view_as", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size", "x_padded[].view_as.size"], "methods", ["None"], ["", "def", "_rel_shift", "(", "self", ",", "x", ")", ":", "\n", "        ", "zero_pad_shape", "=", "(", "x", ".", "size", "(", "0", ")", ",", "1", ")", "+", "x", ".", "size", "(", ")", "[", "2", ":", "]", "\n", "zero_pad", "=", "torch", ".", "zeros", "(", "zero_pad_shape", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "x_padded", "=", "torch", ".", "cat", "(", "[", "zero_pad", ",", "x", "]", ",", "dim", "=", "1", ")", "\n", "\n", "x_padded_shape", "=", "(", "x", ".", "size", "(", "1", ")", "+", "1", ",", "x", ".", "size", "(", "0", ")", ")", "+", "x", ".", "size", "(", ")", "[", "2", ":", "]", "\n", "x_padded", "=", "x_padded", ".", "view", "(", "*", "x_padded_shape", ")", "\n", "\n", "x", "=", "x_padded", "[", "1", ":", "]", ".", "view_as", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.forward": [[280, 367], ["w_head_k.view.view.size", "w_head_q.view.view.view", "w_head_k.view.view.view", "w_head_v.view.view.view", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn._rel_shift", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.mul_", "torch.softmax", "torch.softmax", "torch.softmax", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.dropatt", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "attn_vec.contiguous().view.contiguous().view.contiguous().view", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.o_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.drop", "w.size", "r.size", "w.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.r_net", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.chunk", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "torch.sum().item", "attn_vec.contiguous().view.contiguous().view.size", "attn_vec.contiguous().view.contiguous().view.size", "outputs.append", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.qkv_net", "attn_mask.dim", "attn_vec.contiguous().view.contiguous().view.contiguous", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.layer_norm", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_mask.dim", "next", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill().type_as", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.parameters", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "next", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn.parameters", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float().masked_fill", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float", "attn_score.float().masked_fill().type_as.float().masked_fill().type_as.float"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.RelPartialLearnableMultiHeadAttn._rel_shift"], ["", "def", "forward", "(", "self", ",", "w", ",", "r", ",", "attn_mask", "=", "None", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "qlen", ",", "rlen", ",", "bsz", "=", "w", ".", "size", "(", "0", ")", ",", "r", ".", "size", "(", "0", ")", ",", "w", ".", "size", "(", "1", ")", "\n", "\n", "if", "mems", "is", "not", "None", ":", "\n", "            ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "w", "]", ",", "0", ")", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "cat", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "cat", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "w_head_q", "=", "w_head_q", "[", "-", "qlen", ":", "]", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "pre_lnorm", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "self", ".", "layer_norm", "(", "w", ")", ")", "\n", "", "else", ":", "\n", "                ", "w_heads", "=", "self", ".", "qkv_net", "(", "w", ")", "\n", "", "r_head_k", "=", "self", ".", "r_net", "(", "r", ")", "\n", "\n", "w_head_q", ",", "w_head_k", ",", "w_head_v", "=", "torch", ".", "chunk", "(", "w_heads", ",", "3", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "klen", "=", "w_head_k", ".", "size", "(", "0", ")", "\n", "\n", "w_head_q", "=", "w_head_q", ".", "view", "(", "qlen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_k", "=", "w_head_k", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "w_head_v", "=", "w_head_v", ".", "view", "(", "klen", ",", "bsz", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x bsz x n_head x d_head", "\n", "\n", "r_head_k", "=", "r_head_k", ".", "view", "(", "rlen", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", "# qlen x n_head x d_head", "\n", "\n", "# compute attention score", "\n", "rw_head_q", "=", "w_head_q", "+", "self", ".", "r_w_bias", "# qlen x bsz x n_head x d_head", "\n", "AC", "=", "torch", ".", "einsum", "(", "\"ibnd,jbnd->ijbn\"", ",", "(", "rw_head_q", ",", "w_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "\n", "rr_head_q", "=", "w_head_q", "+", "self", ".", "r_r_bias", "\n", "BD", "=", "torch", ".", "einsum", "(", "\"ibnd,jnd->ijbn\"", ",", "(", "rr_head_q", ",", "r_head_k", ")", ")", "# qlen x klen x bsz x n_head", "\n", "BD", "=", "self", ".", "_rel_shift", "(", "BD", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "attn_score", "=", "AC", "+", "BD", "\n", "attn_score", ".", "mul_", "(", "self", ".", "scale", ")", "\n", "\n", "# compute attention probability", "\n", "if", "attn_mask", "is", "not", "None", "and", "torch", ".", "sum", "(", "attn_mask", ")", ".", "item", "(", ")", ":", "\n", "            ", "attn_mask", "=", "attn_mask", "==", "1", "# Switch to bool", "\n", "if", "attn_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "if", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "                    ", "attn_score", "=", "(", "\n", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ",", "-", "65000", ")", ".", "type_as", "(", "attn_score", ")", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "attn_mask", "[", "None", ",", ":", ",", ":", ",", "None", "]", ",", "-", "1e30", ")", ".", "type_as", "(", "attn_score", ")", "\n", "", "", "elif", "attn_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "if", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "                    ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ",", "-", "65000", ")", ".", "type_as", "(", "attn_score", ")", "\n", "", "else", ":", "\n", "                    ", "attn_score", "=", "attn_score", ".", "float", "(", ")", ".", "masked_fill", "(", "attn_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", ",", "-", "1e30", ")", ".", "type_as", "(", "attn_score", ")", "\n", "\n", "# [qlen x klen x bsz x n_head]", "\n", "", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "1", ")", "\n", "attn_prob", "=", "self", ".", "dropatt", "(", "attn_prob", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attn_prob", "=", "attn_prob", "*", "head_mask", "\n", "\n", "# compute attention vector", "\n", "", "attn_vec", "=", "torch", ".", "einsum", "(", "\"ijbn,jbnd->ibnd\"", ",", "(", "attn_prob", ",", "w_head_v", ")", ")", "\n", "\n", "# [qlen x bsz x n_head x d_head]", "\n", "attn_vec", "=", "attn_vec", ".", "contiguous", "(", ")", ".", "view", "(", "attn_vec", ".", "size", "(", "0", ")", ",", "attn_vec", ".", "size", "(", "1", ")", ",", "self", ".", "n_head", "*", "self", ".", "d_head", ")", "\n", "\n", "# linear projection", "\n", "attn_out", "=", "self", ".", "o_net", "(", "attn_vec", ")", "\n", "attn_out", "=", "self", ".", "drop", "(", "attn_out", ")", "\n", "\n", "if", "self", ".", "pre_lnorm", ":", "\n", "# residual connection", "\n", "            ", "outputs", "=", "[", "w", "+", "attn_out", "]", "\n", "", "else", ":", "\n", "# residual connection + layer normalization", "\n", "            ", "outputs", "=", "[", "self", ".", "layer_norm", "(", "w", "+", "attn_out", ")", "]", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "attn_prob", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.RelPartialLearnableDecoderLayer.__init__": [[370, 378], ["torch.Module.__init__", "modeling_transfo_xl.RelPartialLearnableMultiHeadAttn", "modeling_transfo_xl.PositionwiseFF", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_head", ",", "d_model", ",", "d_head", ",", "d_inner", ",", "dropout", ",", "layer_norm_epsilon", "=", "1e-5", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RelPartialLearnableDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dec_attn", "=", "RelPartialLearnableMultiHeadAttn", "(", "\n", "n_head", ",", "d_model", ",", "d_head", ",", "dropout", ",", "layer_norm_epsilon", "=", "layer_norm_epsilon", ",", "**", "kwargs", "\n", ")", "\n", "self", ".", "pos_ff", "=", "PositionwiseFF", "(", "\n", "d_model", ",", "d_inner", ",", "dropout", ",", "pre_lnorm", "=", "kwargs", ".", "get", "(", "\"pre_lnorm\"", ")", ",", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.RelPartialLearnableDecoderLayer.forward": [[380, 388], ["modeling_transfo_xl.RelPartialLearnableDecoderLayer.dec_attn", "modeling_transfo_xl.RelPartialLearnableDecoderLayer.pos_ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "dec_inp", ",", "r", ",", "dec_attn_mask", "=", "None", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "\n", "        ", "attn_outputs", "=", "self", ".", "dec_attn", "(", "dec_inp", ",", "r", ",", "attn_mask", "=", "dec_attn_mask", ",", "mems", "=", "mems", ",", "head_mask", "=", "head_mask", ")", "\n", "ff_output", "=", "self", ".", "pos_ff", "(", "attn_outputs", "[", "0", "]", ")", "\n", "\n", "outputs", "=", "[", "ff_output", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.AdaptiveEmbedding.__init__": [[391, 417], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "modeling_transfo_xl.AdaptiveEmbedding.emb_layers.append", "range", "torch.Embedding", "torch.Embedding", "torch.Embedding", "modeling_transfo_xl.AdaptiveEmbedding.emb_projs.append", "len", "modeling_transfo_xl.AdaptiveEmbedding.emb_layers.append", "modeling_transfo_xl.AdaptiveEmbedding.emb_projs.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "1", ",", "sample_softmax", "=", "False", ")", ":", "\n", "        ", "super", "(", "AdaptiveEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_token", "=", "n_token", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_token", "]", "\n", "self", ".", "div_val", "=", "div_val", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "self", ".", "emb_scale", "=", "d_proj", "**", "0.5", "\n", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "\n", "self", ".", "emb_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "emb_projs", "=", "nn", ".", "ParameterList", "(", ")", "\n", "if", "div_val", "==", "1", ":", "\n", "            ", "self", ".", "emb_layers", ".", "append", "(", "nn", ".", "Embedding", "(", "n_token", ",", "d_embed", ",", "sparse", "=", "sample_softmax", ">", "0", ")", ")", "\n", "if", "d_proj", "!=", "d_embed", ":", "\n", "                ", "self", ".", "emb_projs", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "d_proj", ",", "d_embed", ")", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "self", ".", "emb_layers", ".", "append", "(", "nn", ".", "Embedding", "(", "r_idx", "-", "l_idx", ",", "d_emb_i", ")", ")", "\n", "self", ".", "emb_projs", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "d_proj", ",", "d_emb_i", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.AdaptiveEmbedding.forward": [[418, 448], ["torch.linear.mul_", "next", "inp.view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.zeros.view", "torch.zeros.view", "torch.zeros.view", "torch.linear", "torch.linear", "torch.linear", "modeling_transfo_xl.AdaptiveEmbedding.parameters", "len", "mask_i.nonzero().squeeze", "torch.linear", "torch.linear", "torch.linear", "torch.zeros.index_copy_", "torch.zeros.index_copy_", "torch.zeros.index_copy_", "inp.size", "inp.view.size", "mask_i.nonzero().squeeze.numel", "inp.view.index_select", "mask_i.nonzero"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "            ", "embed", "=", "self", ".", "emb_layers", "[", "0", "]", "(", "inp", ")", "\n", "if", "self", ".", "d_proj", "!=", "self", ".", "d_embed", ":", "\n", "                ", "embed", "=", "F", ".", "linear", "(", "embed", ",", "self", ".", "emb_projs", "[", "0", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "param", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "inp_flat", "=", "inp", ".", "view", "(", "-", "1", ")", "\n", "emb_flat", "=", "torch", ".", "zeros", "(", "[", "inp_flat", ".", "size", "(", "0", ")", ",", "self", ".", "d_proj", "]", ",", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "\n", "mask_i", "=", "(", "inp_flat", ">=", "l_idx", ")", "&", "(", "inp_flat", "<", "r_idx", ")", "\n", "indices_i", "=", "mask_i", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "\n", "if", "indices_i", ".", "numel", "(", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "\n", "", "inp_i", "=", "inp_flat", ".", "index_select", "(", "0", ",", "indices_i", ")", "-", "l_idx", "\n", "emb_i", "=", "self", ".", "emb_layers", "[", "i", "]", "(", "inp_i", ")", "\n", "emb_i", "=", "F", ".", "linear", "(", "emb_i", ",", "self", ".", "emb_projs", "[", "i", "]", ")", "\n", "\n", "emb_flat", ".", "index_copy_", "(", "0", ",", "indices_i", ",", "emb_i", ")", "\n", "\n", "", "embed_shape", "=", "inp", ".", "size", "(", ")", "+", "(", "self", ".", "d_proj", ",", ")", "\n", "embed", "=", "emb_flat", ".", "view", "(", "embed_shape", ")", "\n", "\n", "", "embed", ".", "mul_", "(", "self", ".", "emb_scale", ")", "\n", "\n", "return", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight": [[460, 465], ["torch.init.uniform_", "torch.init.uniform_", "torch.init.uniform_", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["None"], ["def", "_init_weight", "(", "self", ",", "weight", ")", ":", "\n", "        ", "if", "self", ".", "config", ".", "init", "==", "\"uniform\"", ":", "\n", "            ", "nn", ".", "init", ".", "uniform_", "(", "weight", ",", "-", "self", ".", "config", ".", "init_range", ",", "self", ".", "config", ".", "init_range", ")", "\n", "", "elif", "self", ".", "config", ".", "init", "==", "\"normal\"", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "weight", ",", "0.0", ",", "self", ".", "config", ".", "init_std", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias": [[466, 468], ["torch.init.constant_", "torch.init.constant_", "torch.init.constant_"], "methods", ["None"], ["", "", "def", "_init_bias", "(", "self", ",", "bias", ")", ":", "\n", "        ", "nn", ".", "init", ".", "constant_", "(", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weights": [[469, 509], ["classname.find", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "classname.find", "hasattr", "range", "classname.find", "hasattr", "len", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "classname.find", "hasattr", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "range", "classname.find", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr", "len", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "hasattr", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_weight", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLPreTrainedModel._init_bias"], ["", "def", "_init_weights", "(", "self", ",", "m", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "\"Linear\"", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "\"weight\"", ")", "and", "m", ".", "weight", "is", "not", "None", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "\"bias\"", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "_init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "\"AdaptiveEmbedding\"", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "\"emb_projs\"", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "emb_projs", ")", ")", ":", "\n", "                    ", "if", "m", ".", "emb_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                        ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "emb_projs", "[", "i", "]", ",", "0.0", ",", "self", ".", "config", ".", "proj_init_std", ")", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "\"Embedding\"", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "\"weight\"", ")", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "weight", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "\"ProjectedAdaptiveLogSoftmax\"", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "\"cluster_weight\"", ")", "and", "m", ".", "cluster_weight", "is", "not", "None", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "cluster_weight", ")", "\n", "", "if", "hasattr", "(", "m", ",", "\"cluster_bias\"", ")", "and", "m", ".", "cluster_bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "_init_bias", "(", "m", ".", "cluster_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "\"out_projs\"", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "m", ".", "out_projs", ")", ")", ":", "\n", "                    ", "if", "m", ".", "out_projs", "[", "i", "]", "is", "not", "None", ":", "\n", "                        ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "out_projs", "[", "i", "]", ",", "0.0", ",", "self", ".", "config", ".", "proj_init_std", ")", "\n", "", "", "", "", "elif", "classname", ".", "find", "(", "\"LayerNorm\"", ")", "!=", "-", "1", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "\"weight\"", ")", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "1.0", ",", "self", ".", "config", ".", "init_std", ")", "\n", "", "if", "hasattr", "(", "m", ",", "\"bias\"", ")", "and", "m", ".", "bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "_init_bias", "(", "m", ".", "bias", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "hasattr", "(", "m", ",", "\"r_emb\"", ")", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "r_emb", ")", "\n", "", "if", "hasattr", "(", "m", ",", "\"r_w_bias\"", ")", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "r_w_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "\"r_r_bias\"", ")", ":", "\n", "                ", "self", ".", "_init_weight", "(", "m", ".", "r_r_bias", ")", "\n", "", "if", "hasattr", "(", "m", ",", "\"r_bias\"", ")", ":", "\n", "                ", "self", ".", "_init_bias", "(", "m", ".", "r_bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLModel.__init__": [[589, 653], ["modeling_utils.PreTrainedModel.__init__", "modeling_transfo_xl.AdaptiveEmbedding", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "modeling_transfo_xl.TransfoXLModel.init_weights", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "range", "modeling_transfo_xl.PositionalEmbedding", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "modeling_transfo_xl.TransfoXLModel.layers.append", "modeling_transfo_xl.RelPartialLearnableDecoderLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransfoXLModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "self", ".", "n_token", "=", "config", ".", "vocab_size", "\n", "\n", "self", ".", "d_embed", "=", "config", ".", "d_embed", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "d_head", "=", "config", ".", "d_head", "\n", "\n", "self", ".", "word_emb", "=", "AdaptiveEmbedding", "(", "\n", "config", ".", "vocab_size", ",", "config", ".", "d_embed", ",", "config", ".", "d_model", ",", "config", ".", "cutoffs", ",", "div_val", "=", "config", ".", "div_val", "\n", ")", "\n", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n", "self", ".", "n_layer", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "tgt_len", "=", "config", ".", "tgt_len", "\n", "self", ".", "mem_len", "=", "config", ".", "mem_len", "\n", "self", ".", "ext_len", "=", "config", ".", "ext_len", "\n", "self", ".", "max_klen", "=", "config", ".", "tgt_len", "+", "config", ".", "ext_len", "+", "config", ".", "mem_len", "\n", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "\n", "if", "not", "config", ".", "untie_r", ":", "\n", "            ", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "if", "config", ".", "attn_type", "==", "0", ":", "# the default attention", "\n", "            ", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "\n", "RelPartialLearnableDecoderLayer", "(", "\n", "config", ".", "n_head", ",", "\n", "config", ".", "d_model", ",", "\n", "config", ".", "d_head", ",", "\n", "config", ".", "d_inner", ",", "\n", "config", ".", "dropout", ",", "\n", "tgt_len", "=", "config", ".", "tgt_len", ",", "\n", "ext_len", "=", "config", ".", "ext_len", ",", "\n", "mem_len", "=", "config", ".", "mem_len", ",", "\n", "dropatt", "=", "config", ".", "dropatt", ",", "\n", "pre_lnorm", "=", "config", ".", "pre_lnorm", ",", "\n", "r_w_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_w_bias", ",", "\n", "r_r_bias", "=", "None", "if", "config", ".", "untie_r", "else", "self", ".", "r_r_bias", ",", "\n", "output_attentions", "=", "self", ".", "output_attentions", ",", "\n", "layer_norm_epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "\n", ")", "\n", ")", "\n", "", "", "else", ":", "# learnable embeddings and absolute embeddings are not used in our pretrained checkpoints", "\n", "            ", "raise", "NotImplementedError", "# Removed them to avoid maintaining dead code", "\n", "\n", "", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "self", ".", "clamp_len", "=", "config", ".", "clamp_len", "\n", "\n", "if", "self", ".", "attn_type", "==", "0", ":", "# default attention", "\n", "            ", "self", ".", "pos_emb", "=", "PositionalEmbedding", "(", "self", ".", "d_model", ")", "\n", "", "else", ":", "# learnable embeddings and absolute embeddings", "\n", "            ", "raise", "NotImplementedError", "# Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoint", "\n", "\n", "", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLModel.get_input_embeddings": [[654, 656], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "word_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLModel.set_input_embeddings": [[657, 659], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "word_emb", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLModel.backward_compatible": [[660, 662], ["None"], "methods", ["None"], ["", "def", "backward_compatible", "(", "self", ")", ":", "\n", "        ", "self", ".", "sample_softmax", "=", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLModel.reset_length": [[663, 667], ["None"], "methods", ["None"], ["", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLModel._prune_heads": [[668, 671], ["logger.info"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Head pruning is not implemented for Transformer-XL model\"", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLModel.init_mems": [[672, 683], ["next", "range", "modeling_transfo_xl.TransfoXLModel.parameters", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "mems.append"], "methods", ["None"], ["", "def", "init_mems", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "if", "self", ".", "mem_len", ">", "0", ":", "\n", "            ", "mems", "=", "[", "]", "\n", "param", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layer", ")", ":", "\n", "                ", "empty", "=", "torch", ".", "zeros", "(", "self", ".", "mem_len", ",", "bsz", ",", "self", ".", "config", ".", "d_model", ",", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "mems", ".", "append", "(", "empty", ")", "\n", "\n", "", "return", "mems", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLModel._update_mems": [[684, 707], ["len", "len", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "max", "range", "max", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "new_mems.append", "cat[].detach"], "methods", ["None"], ["", "", "def", "_update_mems", "(", "self", ",", "hids", ",", "mems", ",", "qlen", ",", "mlen", ")", ":", "\n", "# does not deal with None", "\n", "        ", "if", "mems", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "# mems is not None", "\n", "", "assert", "len", "(", "hids", ")", "==", "len", "(", "mems", ")", ",", "\"len(hids) != len(mems)\"", "\n", "\n", "# There are `mlen + qlen` steps that can be cached into mems", "\n", "# For the next step, the last `ext_len` of the `qlen` tokens", "\n", "# will be used as the extended context. Hence, we only cache", "\n", "# the tokens from `mlen + qlen - self.ext_len - self.mem_len`", "\n", "# to `mlen + qlen - self.ext_len`.", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "new_mems", "=", "[", "]", "\n", "end_idx", "=", "mlen", "+", "max", "(", "0", ",", "qlen", "-", "0", "-", "self", ".", "ext_len", ")", "\n", "beg_idx", "=", "max", "(", "0", ",", "end_idx", "-", "self", ".", "mem_len", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "hids", ")", ")", ":", "\n", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", "[", "i", "]", ",", "hids", "[", "i", "]", "]", ",", "dim", "=", "0", ")", "\n", "new_mems", ".", "append", "(", "cat", "[", "beg_idx", ":", "end_idx", "]", ".", "detach", "(", ")", ")", "\n", "\n", "", "", "return", "new_mems", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLModel.forward": [[708, 802], ["modeling_transfo_xl.TransfoXLModel.drop", "modeling_transfo_xl.TransfoXLModel._update_mems", "ValueError", "modeling_transfo_xl.TransfoXLModel.init_mems", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "modeling_transfo_xl.TransfoXLModel.word_emb", "mems[].size", "modeling_transfo_xl.TransfoXLModel.new_ones", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "modeling_transfo_xl.TransfoXLModel.pos_emb", "modeling_transfo_xl.TransfoXLModel.drop", "modeling_transfo_xl.TransfoXLModel.drop", "enumerate", "modeling_transfo_xl.TransfoXLModel.transpose().contiguous", "list.append", "list", "outputs.append", "list", "outputs.append", "input_ids.transpose().contiguous.transpose().contiguous.transpose().contiguous", "input_ids.transpose().contiguous.transpose().contiguous.size", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.arange.clamp_", "torch.arange.clamp_", "torch.arange.clamp_", "list.append", "layer", "inputs_embeds.transpose().contiguous.transpose().contiguous.transpose().contiguous", "ValueError", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "modeling_transfo_xl.TransfoXLModel.new_ones", "list.append", "modeling_transfo_xl.TransfoXLModel.transpose", "t.transpose().contiguous", "t.permute().contiguous", "input_ids.transpose().contiguous.transpose().contiguous.transpose", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "inputs_embeds.transpose().contiguous.transpose().contiguous.transpose", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_transfo_xl.TransfoXLModel.parameters", "t.transpose", "t.permute", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLModel._update_mems", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ")", ":", "\n", "# the original code for Transformer-XL used shapes [len, bsz] but we want a unified interface in the library", "\n", "# so we transpose here from shape [bsz, len] to shape [len, bsz]", "\n", "        ", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_ids", "=", "input_ids", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "qlen", ",", "bsz", "=", "input_ids", ".", "size", "(", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "inputs_embeds", "=", "inputs_embeds", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "qlen", ",", "bsz", "=", "inputs_embeds", ".", "shape", "[", "0", "]", ",", "inputs_embeds", ".", "shape", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "mems", "is", "None", ":", "\n", "            ", "mems", "=", "self", ".", "init_mems", "(", "bsz", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads] (a head_mask for each layer)", "\n", "# and head_mask is converted to shape [num_hidden_layers x qlen x klen x bsz x n_head]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layer", "\n", "\n", "", "if", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "word_emb", "=", "inputs_embeds", "\n", "", "else", ":", "\n", "            ", "word_emb", "=", "self", ".", "word_emb", "(", "input_ids", ")", "\n", "\n", "", "mlen", "=", "mems", "[", "0", "]", ".", "size", "(", "0", ")", "if", "mems", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "if", "self", ".", "same_length", ":", "\n", "            ", "all_ones", "=", "word_emb", ".", "new_ones", "(", "(", "qlen", ",", "klen", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", "\n", "mask_len", "=", "klen", "-", "self", ".", "mem_len", "\n", "if", "mask_len", ">", "0", ":", "\n", "                ", "mask_shift_len", "=", "qlen", "-", "mask_len", "\n", "", "else", ":", "\n", "                ", "mask_shift_len", "=", "qlen", "\n", "", "dec_attn_mask", "=", "(", "torch", ".", "triu", "(", "all_ones", ",", "1", "+", "mlen", ")", "+", "torch", ".", "tril", "(", "all_ones", ",", "-", "mask_shift_len", ")", ")", "[", ":", ",", ":", ",", "None", "]", "# -1", "\n", "", "else", ":", "\n", "            ", "dec_attn_mask", "=", "torch", ".", "triu", "(", "word_emb", ".", "new_ones", "(", "(", "qlen", ",", "klen", ")", ",", "dtype", "=", "torch", ".", "uint8", ")", ",", "diagonal", "=", "1", "+", "mlen", ")", "[", "\n", ":", ",", ":", ",", "None", "\n", "]", "\n", "\n", "", "hids", "=", "[", "]", "\n", "attentions", "=", "[", "]", "\n", "if", "self", ".", "attn_type", "==", "0", ":", "# default", "\n", "            ", "pos_seq", "=", "torch", ".", "arange", "(", "klen", "-", "1", ",", "-", "1", ",", "-", "1.0", ",", "device", "=", "word_emb", ".", "device", ",", "dtype", "=", "word_emb", ".", "dtype", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "pos_seq", ".", "clamp_", "(", "max", "=", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "pos_emb", "(", "pos_seq", ")", "\n", "\n", "core_out", "=", "self", ".", "drop", "(", "word_emb", ")", "\n", "pos_emb", "=", "self", ".", "drop", "(", "pos_emb", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "                ", "hids", ".", "append", "(", "core_out", ")", "\n", "mems_i", "=", "None", "if", "mems", "is", "None", "else", "mems", "[", "i", "]", "\n", "layer_outputs", "=", "layer", "(", "\n", "core_out", ",", "pos_emb", ",", "dec_attn_mask", "=", "dec_attn_mask", ",", "mems", "=", "mems_i", ",", "head_mask", "=", "head_mask", "[", "i", "]", "\n", ")", "\n", "core_out", "=", "layer_outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attentions", ".", "append", "(", "layer_outputs", "[", "1", "]", ")", "\n", "", "", "", "else", ":", "# learnable embeddings and absolute embeddings", "\n", "            ", "raise", "NotImplementedError", "# Removed these to avoid maintaining dead code - They are not used in our pretrained checkpoint", "\n", "\n", "", "core_out", "=", "self", ".", "drop", "(", "core_out", ")", "\n", "\n", "new_mems", "=", "self", ".", "_update_mems", "(", "hids", ",", "mems", ",", "mlen", ",", "qlen", ")", "\n", "\n", "# We transpose back here to shape [bsz, len, hidden_dim]", "\n", "outputs", "=", "[", "core_out", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ",", "new_mems", "]", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "# Add last layer and transpose to library standard shape [bsz, len, hidden_dim]", "\n", "            ", "hids", ".", "append", "(", "core_out", ")", "\n", "hids", "=", "list", "(", "t", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "for", "t", "in", "hids", ")", "\n", "outputs", ".", "append", "(", "hids", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# Transpose to library standard shape [bsz, n_heads, query_seq_len, key_seq_len]", "\n", "            ", "attentions", "=", "list", "(", "t", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "for", "t", "in", "attentions", ")", "\n", "outputs", ".", "append", "(", "attentions", ")", "\n", "\n", "", "return", "outputs", "# last hidden state, new_mems, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.__init__": [[847, 861], ["modeling_utils.PreTrainedModel.__init__", "modeling_transfo_xl.TransfoXLModel", "modeling_transfo_xl.TransfoXLLMHeadModel.init_weights", "torch.Linear", "torch.Linear", "torch.Linear", "modeling_transfo_xl_utilities.LogUniformSampler", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransfoXLLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "TransfoXLModel", "(", "config", ")", "\n", "self", ".", "sample_softmax", "=", "config", ".", "sample_softmax", "\n", "# use sampled softmax", "\n", "if", "config", ".", "sample_softmax", ">", "0", ":", "\n", "            ", "self", ".", "out_layer", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "vocab_size", ")", "\n", "self", ".", "sampler", "=", "LogUniformSampler", "(", "config", ".", "vocab_size", ",", "config", ".", "sample_softmax", ")", "\n", "# use adaptive softmax (including standard softmax)", "\n", "", "else", ":", "\n", "            ", "self", ".", "crit", "=", "ProjectedAdaptiveLogSoftmax", "(", "\n", "config", ".", "vocab_size", ",", "config", ".", "d_embed", ",", "config", ".", "d_model", ",", "config", ".", "cutoffs", ",", "div_val", "=", "config", ".", "div_val", "\n", ")", "\n", "", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.tie_weights": [[862, 887], ["range", "enumerate", "len", "modeling_transfo_xl.TransfoXLLMHeadModel._tie_or_clone_weights", "torch.Parameter", "torch.Parameter", "torch.Parameter", "modeling_transfo_xl.TransfoXLLMHeadModel.transformer.word_emb.emb_projs[].clone", "torch.Parameter", "torch.Parameter", "torch.Parameter", "modeling_transfo_xl.TransfoXLLMHeadModel.transformer.word_emb.emb_projs[].clone"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Run this to be sure output and input (adaptive) softmax weights are tied\n        \"\"\"", "\n", "# sampled softmax", "\n", "if", "self", ".", "sample_softmax", ">", "0", ":", "\n", "            ", "if", "self", ".", "config", ".", "tie_weight", ":", "\n", "                ", "self", ".", "out_layer", ".", "weight", "=", "self", ".", "transformer", ".", "word_emb", ".", "weight", "\n", "# adaptive softmax (including standard softmax)", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "config", ".", "tie_weight", ":", "\n", "                ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "crit", ".", "out_layers", ")", ")", ":", "\n", "                    ", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "crit", ".", "out_layers", "[", "i", "]", ",", "self", ".", "transformer", ".", "word_emb", ".", "emb_layers", "[", "i", "]", ")", "\n", "", "", "if", "self", ".", "config", ".", "tie_projs", ":", "\n", "                ", "for", "i", ",", "tie_proj", "in", "enumerate", "(", "self", ".", "config", ".", "tie_projs", ")", ":", "\n", "                    ", "if", "tie_proj", "and", "self", ".", "config", ".", "div_val", "==", "1", "and", "self", ".", "config", ".", "d_model", "!=", "self", ".", "config", ".", "d_embed", ":", "\n", "                        ", "if", "self", ".", "config", ".", "torchscript", ":", "\n", "                            ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "nn", ".", "Parameter", "(", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "0", "]", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "                            ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "0", "]", "\n", "", "", "elif", "tie_proj", "and", "self", ".", "config", ".", "div_val", "!=", "1", ":", "\n", "                        ", "if", "self", ".", "config", ".", "torchscript", ":", "\n", "                            ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "nn", ".", "Parameter", "(", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "i", "]", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "                            ", "self", ".", "crit", ".", "out_projs", "[", "i", "]", "=", "self", ".", "transformer", ".", "word_emb", ".", "emb_projs", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.reset_length": [[888, 890], ["modeling_transfo_xl.TransfoXLLMHeadModel.transformer.reset_length"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.reset_length"], ["", "", "", "", "", "", "def", "reset_length", "(", "self", ",", "tgt_len", ",", "ext_len", ",", "mem_len", ")", ":", "\n", "        ", "self", ".", "transformer", ".", "reset_length", "(", "tgt_len", ",", "ext_len", ",", "mem_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems": [[891, 893], ["modeling_transfo_xl.TransfoXLLMHeadModel.transformer.init_mems"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.init_mems"], ["", "def", "init_mems", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "return", "self", ".", "transformer", ".", "init_mems", "(", "bsz", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.forward": [[894, 925], ["modeling_transfo_xl.TransfoXLLMHeadModel.transformer", "modeling_transfo_xl_utilities.sample_logits", "modeling_transfo_xl.TransfoXLLMHeadModel.crit", "input_ids.size", "input_ids.size", "ValueError", "pred_hid.view", "softmax_output.view.view.view", "softmax_output.view.view.view", "inputs_embeds.size", "inputs_embeds.size", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "pred_hid.size"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.sample_logits"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "mems", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "bsz", ",", "tgt_len", "=", "input_ids", ".", "size", "(", "0", ")", ",", "input_ids", ".", "size", "(", "1", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "bsz", ",", "tgt_len", "=", "inputs_embeds", ".", "size", "(", "0", ")", ",", "inputs_embeds", ".", "size", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "mems", "=", "mems", ",", "head_mask", "=", "head_mask", ",", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "\n", "last_hidden", "=", "transformer_outputs", "[", "0", "]", "\n", "pred_hid", "=", "last_hidden", "[", ":", ",", "-", "tgt_len", ":", "]", "\n", "outputs", "=", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "self", ".", "sample_softmax", ">", "0", "and", "self", ".", "training", ":", "\n", "            ", "assert", "self", ".", "config", ".", "tie_weight", "\n", "logit", "=", "sample_logits", "(", "self", ".", "transformer", ".", "word_emb", ",", "self", ".", "out_layer", ".", "bias", ",", "labels", ",", "pred_hid", ",", "self", ".", "sampler", ")", "\n", "softmax_output", "=", "-", "F", ".", "log_softmax", "(", "logit", ",", "-", "1", ")", "[", ":", ",", ":", ",", "0", "]", "\n", "outputs", "=", "[", "softmax_output", "]", "+", "outputs", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# TODO: This is not implemented", "\n", "                ", "raise", "NotImplementedError", "\n", "", "", "else", ":", "\n", "            ", "softmax_output", "=", "self", ".", "crit", "(", "pred_hid", ".", "view", "(", "-", "1", ",", "pred_hid", ".", "size", "(", "-", "1", ")", ")", ",", "labels", ")", "\n", "if", "labels", "is", "None", ":", "\n", "                ", "softmax_output", "=", "softmax_output", ".", "view", "(", "bsz", ",", "tgt_len", ",", "-", "1", ")", "\n", "outputs", "=", "[", "softmax_output", "]", "+", "outputs", "\n", "", "else", ":", "\n", "                ", "softmax_output", "=", "softmax_output", ".", "view", "(", "bsz", ",", "tgt_len", ")", "\n", "outputs", "=", "[", "softmax_output", ",", "None", "]", "+", "outputs", "\n", "\n", "", "", "return", "outputs", "# (loss), logits or None if labels is not None (speed up adaptive softmax), new_mems, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.TransfoXLLMHeadModel.get_output_embeddings": [[926, 933], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "\"\"\" Double-check if you are using adaptive softmax.\n        \"\"\"", "\n", "if", "self", ".", "sample_softmax", ">", "0", ":", "\n", "            ", "return", "self", ".", "out_layer", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "crit", ".", "out_layers", "[", "-", "1", "]", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.build_tf_to_pytorch_map": [[41, 106], ["hasattr", "enumerate", "enumerate", "tf_to_pt_map.update", "tf_to_pt_map.update", "enumerate", "zip", "tf_to_pt_map.update", "tf_to_pt_map.update", "zip", "r_r_list.append", "r_w_list.append", "tf_to_pt_map.update", "tf_to_pt_map.update", "tf_to_pt_map.update"], "function", ["None"], ["def", "build_tf_to_pytorch_map", "(", "model", ",", "config", ")", ":", "\n", "    ", "\"\"\" A map of modules from TF to PyTorch.\n        This time I use a map to keep the PyTorch model as identical to the original PyTorch model as possible.\n    \"\"\"", "\n", "tf_to_pt_map", "=", "{", "}", "\n", "\n", "if", "hasattr", "(", "model", ",", "\"transformer\"", ")", ":", "\n", "# We are loading in a TransfoXLLMHeadModel => we will load also the Adaptive Softmax", "\n", "        ", "tf_to_pt_map", ".", "update", "(", "\n", "{", "\n", "\"transformer/adaptive_softmax/cutoff_0/cluster_W\"", ":", "model", ".", "crit", ".", "cluster_weight", ",", "\n", "\"transformer/adaptive_softmax/cutoff_0/cluster_b\"", ":", "model", ".", "crit", ".", "cluster_bias", ",", "\n", "}", "\n", ")", "\n", "for", "i", ",", "(", "out_l", ",", "proj_l", ",", "tie_proj", ")", "in", "enumerate", "(", "\n", "zip", "(", "model", ".", "crit", ".", "out_layers", ",", "model", ".", "crit", ".", "out_projs", ",", "config", ".", "tie_projs", ")", "\n", ")", ":", "\n", "            ", "layer_str", "=", "\"transformer/adaptive_softmax/cutoff_%d/\"", "%", "i", "\n", "if", "config", ".", "tie_weight", ":", "\n", "                ", "tf_to_pt_map", ".", "update", "(", "{", "layer_str", "+", "\"b\"", ":", "out_l", ".", "bias", "}", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "# I don't think this is implemented in the TF code", "\n", "tf_to_pt_map", ".", "update", "(", "{", "layer_str", "+", "\"lookup_table\"", ":", "out_l", ".", "weight", ",", "layer_str", "+", "\"b\"", ":", "out_l", ".", "bias", "}", ")", "\n", "", "if", "not", "tie_proj", ":", "\n", "                ", "tf_to_pt_map", ".", "update", "(", "{", "layer_str", "+", "\"proj\"", ":", "proj_l", "}", ")", "\n", "# Now load the rest of the transformer", "\n", "", "", "model", "=", "model", ".", "transformer", "\n", "\n", "# Embeddings", "\n", "", "for", "i", ",", "(", "embed_l", ",", "proj_l", ")", "in", "enumerate", "(", "zip", "(", "model", ".", "word_emb", ".", "emb_layers", ",", "model", ".", "word_emb", ".", "emb_projs", ")", ")", ":", "\n", "        ", "layer_str", "=", "\"transformer/adaptive_embed/cutoff_%d/\"", "%", "i", "\n", "tf_to_pt_map", ".", "update", "(", "{", "layer_str", "+", "\"lookup_table\"", ":", "embed_l", ".", "weight", ",", "layer_str", "+", "\"proj_W\"", ":", "proj_l", "}", ")", "\n", "\n", "# Transformer blocks", "\n", "", "for", "i", ",", "b", "in", "enumerate", "(", "model", ".", "layers", ")", ":", "\n", "        ", "layer_str", "=", "\"transformer/layer_%d/\"", "%", "i", "\n", "tf_to_pt_map", ".", "update", "(", "\n", "{", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/gamma\"", ":", "b", ".", "dec_attn", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/beta\"", ":", "b", ".", "dec_attn", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"rel_attn/o/kernel\"", ":", "b", ".", "dec_attn", ".", "o_net", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/qkv/kernel\"", ":", "b", ".", "dec_attn", ".", "qkv_net", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/r/kernel\"", ":", "b", ".", "dec_attn", ".", "r_net", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/gamma\"", ":", "b", ".", "pos_ff", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/beta\"", ":", "b", ".", "pos_ff", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_1/kernel\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "0", "]", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_1/bias\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "0", "]", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_2/kernel\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "3", "]", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_2/bias\"", ":", "b", ".", "pos_ff", ".", "CoreNet", "[", "3", "]", ".", "bias", ",", "\n", "}", "\n", ")", "\n", "\n", "# Relative positioning biases", "\n", "", "if", "config", ".", "untie_r", ":", "\n", "        ", "r_r_list", "=", "[", "]", "\n", "r_w_list", "=", "[", "]", "\n", "for", "b", "in", "model", ".", "layers", ":", "\n", "            ", "r_r_list", ".", "append", "(", "b", ".", "dec_attn", ".", "r_r_bias", ")", "\n", "r_w_list", ".", "append", "(", "b", ".", "dec_attn", ".", "r_w_bias", ")", "\n", "", "", "else", ":", "\n", "        ", "r_r_list", "=", "[", "model", ".", "r_r_bias", "]", "\n", "r_w_list", "=", "[", "model", ".", "r_w_bias", "]", "\n", "", "tf_to_pt_map", ".", "update", "(", "{", "\"transformer/r_r_bias\"", ":", "r_r_list", ",", "\"transformer/r_w_bias\"", ":", "r_w_list", "}", ")", "\n", "return", "tf_to_pt_map", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.load_tf_weights_in_transfo_xl": [[108, 164], ["modeling_transfo_xl.build_tf_to_pytorch_map", "tf.train.list_variables", "build_tf_to_pytorch_map.items", "logger.info", "logger.info", "tf.train.load_variable", "tf_weights.pop", "tf_weights.pop", "tf_weights.pop", "logger.error", "np.transpose", "enumerate", "logger.info", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "len", "len", "logger.info", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "tf_weights.keys"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.build_tf_to_pytorch_map"], ["", "def", "load_tf_weights_in_transfo_xl", "(", "model", ",", "config", ",", "tf_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow models in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "# Build TF to PyTorch weights loading map", "\n", "", "tf_to_pt_map", "=", "build_tf_to_pytorch_map", "(", "model", ",", "config", ")", "\n", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "tf_weights", "=", "{", "}", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "tf_weights", "[", "name", "]", "=", "array", "\n", "\n", "", "for", "name", ",", "pointer", "in", "tf_to_pt_map", ".", "items", "(", ")", ":", "\n", "        ", "assert", "name", "in", "tf_weights", "\n", "array", "=", "tf_weights", "[", "name", "]", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "\"kernel\"", "in", "name", "or", "\"proj\"", "in", "name", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "if", "(", "\"r_r_bias\"", "in", "name", "or", "\"r_w_bias\"", "in", "name", ")", "and", "len", "(", "pointer", ")", ">", "1", ":", "\n", "# Here we will split the TF weigths", "\n", "            ", "assert", "len", "(", "pointer", ")", "==", "array", ".", "shape", "[", "0", "]", "\n", "for", "i", ",", "p_i", "in", "enumerate", "(", "pointer", ")", ":", "\n", "                ", "arr_i", "=", "array", "[", "i", ",", "...", "]", "\n", "try", ":", "\n", "                    ", "assert", "p_i", ".", "shape", "==", "arr_i", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                    ", "e", ".", "args", "+=", "(", "p_i", ".", "shape", ",", "arr_i", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {} for layer {}\"", ".", "format", "(", "name", ",", "i", ")", ")", "\n", "p_i", ".", "data", "=", "torch", ".", "from_numpy", "(", "arr_i", ")", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "tf_weights", ".", "pop", "(", "name", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "\"/Adam\"", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "\"/Adam_1\"", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Weights not copied to PyTorch model: {}\"", ".", "format", "(", "\", \"", ".", "join", "(", "tf_weights", ".", "keys", "(", ")", ")", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_ctrl.CTRLTokenizer.__init__": [[128, 145], ["tokenization_utils.PreTrainedTokenizer.__init__", "dict", "open", "json.load", "open", "tuple", "zip", "tokenization_ctrl.CTRLTokenizer.encoder.items", "merges_handle.read().split", "merge.split", "range", "len", "merges_handle.read"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "unk_token", "=", "\"<unk>\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CTRLTokenizer", ",", "self", ")", ".", "__init__", "(", "unk_token", "=", "unk_token", ",", "**", "kwargs", ")", "\n", "self", ".", "max_len_single_sentence", "=", "(", "\n", "self", ".", "max_len", "\n", ")", "# no default special tokens - you can update this value if you add special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "(", "\n", "self", ".", "max_len", "\n", ")", "# no default special tokens - you can update this value if you add special tokens", "\n", "\n", "with", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "vocab_handle", ":", "\n", "            ", "self", ".", "encoder", "=", "json", ".", "load", "(", "vocab_handle", ")", "\n", "", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "merges_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "merges_handle", ":", "\n", "            ", "merges", "=", "merges_handle", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "[", "1", ":", "-", "1", "]", "\n", "", "merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "merges", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "merges", ",", "range", "(", "len", "(", "merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_ctrl.CTRLTokenizer.vocab_size": [[146, 149], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_ctrl.CTRLTokenizer.bpe": [[150, 193], ["tuple", "tuple", "tokenization_ctrl.get_pairs", "min", "tuple", "list", "len", "len", "tokenization_ctrl.get_pairs", "tuple.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_ctrl.CTRLTokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "word", "=", "tuple", "(", "token", ")", "\n", "word", "=", "tuple", "(", "list", "(", "word", "[", ":", "-", "1", "]", ")", "+", "[", "word", "[", "-", "1", "]", "+", "\"</w>\"", "]", ")", "\n", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "\"inf\"", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "\"@@ \"", ".", "join", "(", "word", ")", "\n", "word", "=", "word", "[", ":", "-", "4", "]", "\n", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_ctrl.CTRLTokenizer._tokenize": [[194, 204], ["regex.findall", "split_tokens.extend", "tokenization_ctrl.CTRLTokenizer.bpe().split", "tokenization_ctrl.CTRLTokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.OpenAIGPTTokenizer.bpe"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string.\n        \"\"\"", "\n", "split_tokens", "=", "[", "]", "\n", "\n", "words", "=", "re", ".", "findall", "(", "r\"\\S+\\n?\"", ",", "text", ")", "\n", "\n", "for", "token", "in", "words", ":", "\n", "            ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "\" \"", ")", "]", ")", "\n", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_ctrl.CTRLTokenizer._convert_token_to_id": [[205, 208], ["tokenization_ctrl.CTRLTokenizer.encoder.get", "tokenization_ctrl.CTRLTokenizer.encoder.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "encoder", ".", "get", "(", "token", ",", "self", ".", "encoder", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_ctrl.CTRLTokenizer._convert_id_to_token": [[209, 212], ["tokenization_ctrl.CTRLTokenizer.decoder.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_ctrl.CTRLTokenizer.convert_tokens_to_string": [[213, 217], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "\" \"", ".", "join", "(", "tokens", ")", ".", "replace", "(", "\"@@ \"", ",", "\"\"", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_ctrl.CTRLTokenizer.save_vocabulary": [[218, 243], ["os.path.join", "os.path.join", "os.path.isdir", "logger.error", "open", "f.write", "open", "writer.write", "sorted", "json.dumps", "tokenization_ctrl.CTRLTokenizer.bpe_ranks.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary and merge files to a directory.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "merge_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"merges_file\"", "]", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "encoder", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "index", "=", "0", "\n", "with", "open", "(", "merge_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "\"#version: 0.2\\n\"", ")", "\n", "for", "bpe_tokens", ",", "token_index", "in", "sorted", "(", "self", ".", "bpe_ranks", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"Saving vocabulary to {}: BPE merge indices are not consecutive.\"", "\n", "\" Please check that the tokenizer is not corrupted!\"", ".", "format", "(", "merge_file", ")", "\n", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "\" \"", ".", "join", "(", "bpe_tokens", ")", "+", "\"\\n\"", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "return", "vocab_file", ",", "merge_file", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_ctrl.get_pairs": [[102, 115], ["set", "set", "set.add"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.BeamHypotheses.add"], ["def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n\n    Word is represented as tuple of symbols (symbols being variable-length strings).\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "\n", "", "pairs", "=", "set", "(", "pairs", ")", "\n", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_albert_original_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch": [[29, 41], ["transformers.AlbertConfig.from_json_file", "print", "transformers.AlbertForMaskedLM", "transformers.load_tf_weights_in_albert", "print", "torch.save", "transformers.AlbertForMaskedLM.state_dict", "str"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.load_tf_weights_in_albert", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save"], ["def", "convert_tf_checkpoint_to_pytorch", "(", "tf_checkpoint_path", ",", "albert_config_file", ",", "pytorch_dump_path", ")", ":", "\n", "# Initialise PyTorch model", "\n", "    ", "config", "=", "AlbertConfig", ".", "from_json_file", "(", "albert_config_file", ")", "\n", "print", "(", "\"Building PyTorch model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "model", "=", "AlbertForMaskedLM", "(", "config", ")", "\n", "\n", "# Load weights from tf checkpoint", "\n", "load_tf_weights_in_albert", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_dump_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.__init__": [[554, 618], ["tokenization_utils.PreTrainedTokenizer.__init__", "dict", "dict", "set", "dict", "open", "json.load", "open", "tuple", "zip", "len", "len", "tokenization_xlm.XLMTokenizer.encoder.items", "merges_handle.read().split", "range", "merge.split", "len", "merges_handle.read"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "merges_file", ",", "\n", "unk_token", "=", "\"<unk>\"", ",", "\n", "bos_token", "=", "\"<s>\"", ",", "\n", "sep_token", "=", "\"</s>\"", ",", "\n", "pad_token", "=", "\"<pad>\"", ",", "\n", "cls_token", "=", "\"</s>\"", ",", "\n", "mask_token", "=", "\"<special1>\"", ",", "\n", "additional_special_tokens", "=", "[", "\n", "\"<special0>\"", ",", "\n", "\"<special1>\"", ",", "\n", "\"<special2>\"", ",", "\n", "\"<special3>\"", ",", "\n", "\"<special4>\"", ",", "\n", "\"<special5>\"", ",", "\n", "\"<special6>\"", ",", "\n", "\"<special7>\"", ",", "\n", "\"<special8>\"", ",", "\n", "\"<special9>\"", ",", "\n", "]", ",", "\n", "lang2id", "=", "None", ",", "\n", "id2lang", "=", "None", ",", "\n", "do_lowercase_and_remove_accent", "=", "True", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "XLMTokenizer", ",", "self", ")", ".", "__init__", "(", "\n", "unk_token", "=", "unk_token", ",", "\n", "bos_token", "=", "bos_token", ",", "\n", "sep_token", "=", "sep_token", ",", "\n", "pad_token", "=", "pad_token", ",", "\n", "cls_token", "=", "cls_token", ",", "\n", "mask_token", "=", "mask_token", ",", "\n", "additional_special_tokens", "=", "additional_special_tokens", ",", "\n", "**", "kwargs", "\n", ")", "\n", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "-", "2", "# take into account special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "-", "3", "# take into account special tokens", "\n", "\n", "# cache of sm.MosesPunctNormalizer instance", "\n", "self", ".", "cache_moses_punct_normalizer", "=", "dict", "(", ")", "\n", "# cache of sm.MosesTokenizer instance", "\n", "self", ".", "cache_moses_tokenizer", "=", "dict", "(", ")", "\n", "self", ".", "lang_with_custom_tokenizer", "=", "set", "(", "[", "\"zh\"", ",", "\"th\"", ",", "\"ja\"", "]", ")", "\n", "# True for current supported model (v1.2.0), False for XLM-17 & 100", "\n", "self", ".", "do_lowercase_and_remove_accent", "=", "do_lowercase_and_remove_accent", "\n", "self", ".", "lang2id", "=", "lang2id", "\n", "self", ".", "id2lang", "=", "id2lang", "\n", "if", "lang2id", "is", "not", "None", "and", "id2lang", "is", "not", "None", ":", "\n", "            ", "assert", "len", "(", "lang2id", ")", "==", "len", "(", "id2lang", ")", "\n", "\n", "", "self", ".", "ja_word_tokenizer", "=", "None", "\n", "self", ".", "zh_word_tokenizer", "=", "None", "\n", "\n", "with", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "vocab_handle", ":", "\n", "            ", "self", ".", "encoder", "=", "json", ".", "load", "(", "vocab_handle", ")", "\n", "", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "merges_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "merges_handle", ":", "\n", "            ", "merges", "=", "merges_handle", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "[", ":", "-", "1", "]", "\n", "", "merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", "[", ":", "2", "]", ")", "for", "merge", "in", "merges", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "merges", ",", "range", "(", "len", "(", "merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.moses_punct_norm": [[619, 626], ["sacremoses.MosesPunctNormalizer.normalize", "sacremoses.MosesPunctNormalizer"], "methods", ["None"], ["", "def", "moses_punct_norm", "(", "self", ",", "text", ",", "lang", ")", ":", "\n", "        ", "if", "lang", "not", "in", "self", ".", "cache_moses_punct_normalizer", ":", "\n", "            ", "punct_normalizer", "=", "sm", ".", "MosesPunctNormalizer", "(", "lang", "=", "lang", ")", "\n", "self", ".", "cache_moses_punct_normalizer", "[", "lang", "]", "=", "punct_normalizer", "\n", "", "else", ":", "\n", "            ", "punct_normalizer", "=", "self", ".", "cache_moses_punct_normalizer", "[", "lang", "]", "\n", "", "return", "punct_normalizer", ".", "normalize", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.moses_tokenize": [[627, 634], ["sacremoses.MosesTokenizer.tokenize", "sacremoses.MosesTokenizer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "moses_tokenize", "(", "self", ",", "text", ",", "lang", ")", ":", "\n", "        ", "if", "lang", "not", "in", "self", ".", "cache_moses_tokenizer", ":", "\n", "            ", "moses_tokenizer", "=", "sm", ".", "MosesTokenizer", "(", "lang", "=", "lang", ")", "\n", "self", ".", "cache_moses_tokenizer", "[", "lang", "]", "=", "moses_tokenizer", "\n", "", "else", ":", "\n", "            ", "moses_tokenizer", "=", "self", ".", "cache_moses_tokenizer", "[", "lang", "]", "\n", "", "return", "moses_tokenizer", ".", "tokenize", "(", "text", ",", "return_str", "=", "False", ",", "escape", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.moses_pipeline": [[635, 640], ["tokenization_xlm.replace_unicode_punct", "tokenization_xlm.XLMTokenizer.moses_punct_norm", "tokenization_xlm.remove_non_printing_char"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.replace_unicode_punct", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.moses_punct_norm", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.remove_non_printing_char"], ["", "def", "moses_pipeline", "(", "self", ",", "text", ",", "lang", ")", ":", "\n", "        ", "text", "=", "replace_unicode_punct", "(", "text", ")", "\n", "text", "=", "self", ".", "moses_punct_norm", "(", "text", ",", "lang", ")", "\n", "text", "=", "remove_non_printing_char", "(", "text", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.ja_tokenize": [[641, 660], ["list", "tokenization_xlm.XLMTokenizer.ja_word_tokenizer.getWS", "Mykytea.Mykytea", "logger.error", "logger.error", "logger.error", "logger.error", "logger.error", "logger.error", "os.path.expanduser"], "methods", ["None"], ["", "def", "ja_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "self", ".", "ja_word_tokenizer", "is", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "import", "Mykytea", "\n", "\n", "self", ".", "ja_word_tokenizer", "=", "Mykytea", ".", "Mykytea", "(", "\n", "\"-model %s/local/share/kytea/model.bin\"", "%", "os", ".", "path", ".", "expanduser", "(", "\"~\"", ")", "\n", ")", "\n", "", "except", "(", "AttributeError", ",", "ImportError", ")", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Make sure you install KyTea (https://github.com/neubig/kytea) and it's python wrapper (https://github.com/chezou/Mykytea-python) with the following steps\"", "\n", ")", "\n", "logger", ".", "error", "(", "\"1. git clone git@github.com:neubig/kytea.git && cd kytea\"", ")", "\n", "logger", ".", "error", "(", "\"2. autoreconf -i\"", ")", "\n", "logger", ".", "error", "(", "\"3. ./configure --prefix=$HOME/local\"", ")", "\n", "logger", ".", "error", "(", "\"4. make && make install\"", ")", "\n", "logger", ".", "error", "(", "\"5. pip install kytea\"", ")", "\n", "raise", "\n", "", "", "return", "list", "(", "self", ".", "ja_word_tokenizer", ".", "getWS", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.vocab_size": [[661, 664], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.bpe": [[665, 708], ["tokenization_xlm.get_pairs", "tuple", "min", "tuple", "len", "len", "tokenization_xlm.get_pairs", "word.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_xlm.XLMTokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "word", "=", "tuple", "(", "token", "[", ":", "-", "1", "]", ")", "+", "(", "token", "[", "-", "1", "]", "+", "\"</w>\"", ",", ")", "\n", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "+", "\"</w>\"", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "\"inf\"", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "\" \"", ".", "join", "(", "word", ")", "\n", "if", "word", "==", "\"\\n  </w>\"", ":", "\n", "            ", "word", "=", "\"\\n</w>\"", "\n", "", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer._tokenize": [[709, 798], ["logger.error", "tokenization_xlm.XLMTokenizer.split", "tokenization_xlm.lowercase_and_remove_accent", "tokenization_xlm.XLMTokenizer.moses_pipeline", "tokenization_xlm.XLMTokenizer.moses_tokenize", "split_tokens.extend", "tokenization_xlm.romanian_preprocessing", "tokenization_xlm.XLMTokenizer.moses_pipeline", "th_word_tokenize", "tokenization_xlm.XLMTokenizer.moses_pipeline", "tokenization_xlm.XLMTokenizer.split", "logger.error", "logger.error", "jieba.cut", "tokenization_xlm.XLMTokenizer.moses_pipeline", "tokenization_xlm.XLMTokenizer.ja_tokenize", "ValueError", "tokenization_xlm.XLMTokenizer.bpe().split", "logger.error", "logger.error", "tokenization_xlm.XLMTokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.lowercase_and_remove_accent", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.moses_pipeline", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.moses_tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.romanian_preprocessing", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.moses_pipeline", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.moses_pipeline", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.moses_pipeline", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.ja_tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.OpenAIGPTTokenizer.bpe"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "lang", "=", "\"en\"", ",", "bypass_tokenizer", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Tokenize a string given language code. For Chinese, Japanese and Thai, we use a language specific tokenizerself. Otherwise, we use Moses.\n\n        Details of tokenization:\n        - [sacremoses](https://github.com/alvations/sacremoses): port of Moses\n            - Install with `pip install sacremoses`\n        - [pythainlp](https://github.com/PyThaiNLP/pythainlp): Thai tokenizer\n            - Install with `pip install pythainlp`\n        - [kytea](https://github.com/chezou/Mykytea-python): Japanese tokenizer, wrapper of [KyTea](https://github.com/neubig/kytea)\n            - Install with the following steps:\n            ```\n            git clone git@github.com:neubig/kytea.git && cd kytea\n            autoreconf -i\n            ./configure --prefix=$HOME/local\n            make && make install\n            pip install kytea\n            ```\n        - [jieba](https://github.com/fxsjy/jieba): Chinese tokenizer (*)\n            - Install with `pip install jieba`\n\n        (*) The original XLM used [Stanford Segmenter](https://nlp.stanford.edu/software/stanford-segmenter-2018-10-16.zip).\n        However, the wrapper (`nltk.tokenize.stanford_segmenter`) is slow due to JVM overhead, and it will be deprecated.\n        Jieba is a lot faster and pip-installable. Note there is some mismatch with the Stanford Segmenter. It should be fine\n        if you fine-tune the model with Chinese supervisionself. If you want the same exact behaviour, use the original XLM\n        [preprocessing script](https://github.com/facebookresearch/XLM/tree/master/tools) to tokenize the sentence externally,\n        and set `bypass_tokenizer=True` to bypass the tokenizer.\n\n        Args:\n            - lang: ISO language code (default = 'en') (string). Languages should belong of the model supported languages. However, we don't enforce it.\n            - bypass_tokenizer: Allow users to preprocess and tokenize the sentences externally (default = False)  (bool). If True, we only apply BPE.\n\n        Returns:\n            List of tokens.\n        \"\"\"", "\n", "if", "lang", "and", "self", ".", "lang2id", "and", "lang", "not", "in", "self", ".", "lang2id", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Supplied language code not found in lang2id mapping. Please check that your language is supported by the loaded pretrained model.\"", "\n", ")", "\n", "", "if", "bypass_tokenizer", ":", "\n", "            ", "text", "=", "text", ".", "split", "(", ")", "\n", "", "elif", "lang", "not", "in", "self", ".", "lang_with_custom_tokenizer", ":", "\n", "            ", "text", "=", "self", ".", "moses_pipeline", "(", "text", ",", "lang", "=", "lang", ")", "\n", "# TODO: make sure we are using `xlm-mlm-enro-1024`, since XLM-100 doesn't have this step", "\n", "if", "lang", "==", "\"ro\"", ":", "\n", "                ", "text", "=", "romanian_preprocessing", "(", "text", ")", "\n", "", "text", "=", "self", ".", "moses_tokenize", "(", "text", ",", "lang", "=", "lang", ")", "\n", "", "elif", "lang", "==", "\"th\"", ":", "\n", "            ", "text", "=", "self", ".", "moses_pipeline", "(", "text", ",", "lang", "=", "lang", ")", "\n", "try", ":", "\n", "                ", "if", "\"pythainlp\"", "not", "in", "sys", ".", "modules", ":", "\n", "                    ", "from", "pythainlp", ".", "tokenize", "import", "word_tokenize", "as", "th_word_tokenize", "\n", "", "else", ":", "\n", "                    ", "th_word_tokenize", "=", "sys", ".", "modules", "[", "\"pythainlp\"", "]", ".", "word_tokenize", "\n", "", "", "except", "(", "AttributeError", ",", "ImportError", ")", ":", "\n", "                ", "logger", ".", "error", "(", "\n", "\"Make sure you install PyThaiNLP (https://github.com/PyThaiNLP/pythainlp) with the following steps\"", "\n", ")", "\n", "logger", ".", "error", "(", "\"1. pip install pythainlp\"", ")", "\n", "raise", "\n", "", "text", "=", "th_word_tokenize", "(", "text", ")", "\n", "", "elif", "lang", "==", "\"zh\"", ":", "\n", "            ", "try", ":", "\n", "                ", "if", "\"jieba\"", "not", "in", "sys", ".", "modules", ":", "\n", "                    ", "import", "jieba", "\n", "", "else", ":", "\n", "                    ", "jieba", "=", "sys", ".", "modules", "[", "\"jieba\"", "]", "\n", "", "", "except", "(", "AttributeError", ",", "ImportError", ")", ":", "\n", "                ", "logger", ".", "error", "(", "\"Make sure you install Jieba (https://github.com/fxsjy/jieba) with the following steps\"", ")", "\n", "logger", ".", "error", "(", "\"1. pip install jieba\"", ")", "\n", "raise", "\n", "", "text", "=", "\" \"", ".", "join", "(", "jieba", ".", "cut", "(", "text", ")", ")", "\n", "text", "=", "self", ".", "moses_pipeline", "(", "text", ",", "lang", "=", "lang", ")", "\n", "text", "=", "text", ".", "split", "(", ")", "\n", "", "elif", "lang", "==", "\"ja\"", ":", "\n", "            ", "text", "=", "self", ".", "moses_pipeline", "(", "text", ",", "lang", "=", "lang", ")", "\n", "text", "=", "self", ".", "ja_tokenize", "(", "text", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"It should not reach here\"", ")", "\n", "\n", "", "if", "self", ".", "do_lowercase_and_remove_accent", "and", "not", "bypass_tokenizer", ":", "\n", "            ", "text", "=", "lowercase_and_remove_accent", "(", "text", ")", "\n", "\n", "", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "text", ":", "\n", "            ", "if", "token", ":", "\n", "                ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "\" \"", ")", "]", ")", "\n", "\n", "", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer._convert_token_to_id": [[799, 802], ["tokenization_xlm.XLMTokenizer.encoder.get", "tokenization_xlm.XLMTokenizer.encoder.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "encoder", ".", "get", "(", "token", ",", "self", ".", "encoder", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer._convert_id_to_token": [[803, 806], ["tokenization_xlm.XLMTokenizer.decoder.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.convert_tokens_to_string": [[807, 811], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "\"\"", ".", "join", "(", "tokens", ")", ".", "replace", "(", "\"</w>\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.build_inputs_with_special_tokens": [[812, 825], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n        by concatenating and adding special tokens.\n        A XLM sequence has the following format:\n            single sequence: <s> X </s>\n            pair of sequences: <s> A </s> B </s>\n        \"\"\"", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "[", "self", ".", "cls_token_id", "]", "+", "token_ids_0", "+", "[", "self", ".", "sep_token_id", "]", "\n", "", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "return", "cls", "+", "token_ids_0", "+", "sep", "+", "token_ids_1", "+", "sep", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.get_special_tokens_mask": [[826, 853], ["list", "ValueError", "map", "len", "len", "len"], "methods", ["None"], ["", "def", "get_special_tokens_mask", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ",", "already_has_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n\n        Args:\n            token_ids_0: list of ids (must not contain special tokens)\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n                for sequence pairs\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n                special tokens for the model\n\n        Returns:\n            A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.\n        \"\"\"", "\n", "\n", "if", "already_has_special_tokens", ":", "\n", "            ", "if", "token_ids_1", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"You should not supply a second sequence if the provided sequence of \"", "\n", "\"ids is already formated with special tokens for the model.\"", "\n", ")", "\n", "", "return", "list", "(", "map", "(", "lambda", "x", ":", "1", "if", "x", "in", "[", "self", ".", "sep_token_id", ",", "self", ".", "cls_token_id", "]", "else", "0", ",", "token_ids_0", ")", ")", "\n", "\n", "", "if", "token_ids_1", "is", "not", "None", ":", "\n", "            ", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_1", ")", ")", "+", "[", "1", "]", "\n", "", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.create_token_type_ids_from_sequences": [[854, 868], ["len", "len", "len"], "methods", ["None"], ["", "def", "create_token_type_ids_from_sequences", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n        An XLM sequence pair mask has the following format:\n        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n        | first sequence    | second sequence\n\n        if token_ids_1 is None, only returns the first portion of the mask (0's).\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "\n", "", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "+", "len", "(", "token_ids_1", "+", "sep", ")", "*", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.XLMTokenizer.save_vocabulary": [[869, 893], ["os.path.join", "os.path.join", "os.path.isdir", "logger.error", "open", "f.write", "open", "sorted", "json.dumps", "tokenization_xlm.XLMTokenizer.bpe_ranks.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary and merge files to a directory.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "merge_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"merges_file\"", "]", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "encoder", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "index", "=", "0", "\n", "with", "open", "(", "merge_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "for", "bpe_tokens", ",", "token_index", "in", "sorted", "(", "self", ".", "bpe_ranks", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"Saving vocabulary to {}: BPE merge indices are not consecutive.\"", "\n", "\" Please check that the tokenizer is not corrupted!\"", ".", "format", "(", "merge_file", ")", "\n", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "\" \"", ".", "join", "(", "bpe_tokens", ")", "+", "\"\\n\"", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "return", "vocab_file", ",", "merge_file", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.get_pairs": [[429, 440], ["set", "set.add"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.BeamHypotheses.add"], ["def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"\n    Return set of symbol pairs in a word.\n    word is represented as tuple of symbols (symbols being variable-length strings)\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.lowercase_and_remove_accent": [[442, 457], ["unicodedata.normalize.lower", "unicodedata.normalize", "unicodedata.category", "output.append"], "function", ["None"], ["", "def", "lowercase_and_remove_accent", "(", "text", ")", ":", "\n", "    ", "\"\"\"\n    Lowercase and strips accents from a piece of text based on\n    https://github.com/facebookresearch/XLM/blob/master/tools/lowercase_and_remove_accent.py\n    \"\"\"", "\n", "text", "=", "\" \"", ".", "join", "(", "text", ")", "\n", "text", "=", "text", ".", "lower", "(", ")", "\n", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFD\"", ",", "text", ")", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "        ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Mn\"", ":", "\n", "            ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", ".", "lower", "(", ")", ".", "split", "(", "\" \"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.replace_unicode_punct": [[459, 500], ["text.replace.replace", "re.sub", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "re.sub", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace"], "function", ["None"], ["", "def", "replace_unicode_punct", "(", "text", ")", ":", "\n", "    ", "\"\"\"\n    Port of https://github.com/moses-smt/mosesdecoder/blob/master/scripts/tokenizer/replace-unicode-punctuation.perl\n    \"\"\"", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff0c\"", ",", "\",\"", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"\u3002\\s*\"", ",", "\". \"", ",", "text", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u3001\"", ",", "\",\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u201d\"", ",", "'\"'", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u201c\"", ",", "'\"'", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u2236\"", ",", "\":\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff1a\"", ",", "\":\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff1f\"", ",", "\"?\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u300a\"", ",", "'\"'", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u300b\"", ",", "'\"'", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff09\"", ",", "\")\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff01\"", ",", "\"!\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff08\"", ",", "\"(\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff1b\"", ",", "\";\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff11\"", ",", "'\"'", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u300d\"", ",", "'\"'", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u300c\"", ",", "'\"'", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff10\"", ",", "\"0\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff13\"", ",", "\"3\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff12\"", ",", "\"2\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff15\"", ",", "\"5\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff16\"", ",", "\"6\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff19\"", ",", "\"9\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff17\"", ",", "\"7\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff18\"", ",", "\"8\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff14\"", ",", "\"4\"", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"\uff0e\\s*\"", ",", "\". \"", ",", "text", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff5e\"", ",", "\"~\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u2019\"", ",", "\"'\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u2026\"", ",", "\"...\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u2501\"", ",", "\"-\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u3008\"", ",", "\"<\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u3009\"", ",", "\">\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u3010\"", ",", "\"[\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u3011\"", ",", "\"]\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\uff05\"", ",", "\"%\"", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.remove_non_printing_char": [[502, 513], ["unicodedata.category", "unicodedata.category.startswith", "output.append"], "function", ["None"], ["", "def", "remove_non_printing_char", "(", "text", ")", ":", "\n", "    ", "\"\"\"\n    Port of https://github.com/moses-smt/mosesdecoder/blob/master/scripts/tokenizer/remove-non-printing-char.perl\n    \"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "        ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"C\"", ")", ":", "\n", "            ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm.romanian_preprocessing": [[515, 527], ["text.replace().replace.replace().replace", "text.replace().replace.replace().replace", "text.replace().replace.replace().replace", "text.replace().replace.replace().replace", "text.replace().replace.replace().replace", "text.replace().replace.replace().replace", "text.replace().replace.replace().replace", "text.replace().replace.replace", "text.replace().replace.replace", "text.replace().replace.replace", "text.replace().replace.replace", "text.replace().replace.replace", "text.replace().replace.replace", "text.replace().replace.replace"], "function", ["None"], ["", "def", "romanian_preprocessing", "(", "text", ")", ":", "\n", "    ", "\"\"\"Sennrich's WMT16 scripts for Romanian preprocessing, used by model `xlm-mlm-enro-1024`\"\"\"", "\n", "# https://github.com/rsennrich/wmt16-scripts/blob/master/preprocess/normalise-romanian.py", "\n", "text", "=", "text", ".", "replace", "(", "\"\\u015e\"", ",", "\"\\u0218\"", ")", ".", "replace", "(", "\"\\u015f\"", ",", "\"\\u0219\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\\u0162\"", ",", "\"\\u021a\"", ")", ".", "replace", "(", "\"\\u0163\"", ",", "\"\\u021b\"", ")", "\n", "# https://github.com/rsennrich/wmt16-scripts/blob/master/preprocess/remove-diacritics.py", "\n", "text", "=", "text", ".", "replace", "(", "\"\\u0218\"", ",", "\"S\"", ")", ".", "replace", "(", "\"\\u0219\"", ",", "\"s\"", ")", "# s-comma", "\n", "text", "=", "text", ".", "replace", "(", "\"\\u021a\"", ",", "\"T\"", ")", ".", "replace", "(", "\"\\u021b\"", ",", "\"t\"", ")", "# t-comma", "\n", "text", "=", "text", ".", "replace", "(", "\"\\u0102\"", ",", "\"A\"", ")", ".", "replace", "(", "\"\\u0103\"", ",", "\"a\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\\u00C2\"", ",", "\"A\"", ")", ".", "replace", "(", "\"\\u00E2\"", ",", "\"a\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\\u00CE\"", ",", "\"I\"", ")", ".", "replace", "(", "\"\\u00EE\"", ",", "\"i\"", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5LayerNorm.__init__": [[141, 148], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "\"\"\" Construct a layernorm module in the T5 style\n            No bias and no substraction of mean.\n        \"\"\"", "\n", "super", "(", "T5LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "hidden_size", ")", ")", "\n", "self", ".", "variance_epsilon", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5LayerNorm.forward": [[149, 153], ["x.pow().mean", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "x.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "variance", "=", "x", ".", "pow", "(", "2", ")", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "x", "/", "torch", ".", "sqrt", "(", "variance", "+", "self", ".", "variance_epsilon", ")", "\n", "return", "self", ".", "weight", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5DenseReluDense.__init__": [[156, 161], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "T5DenseReluDense", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "wi", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "d_ff", ",", "bias", "=", "False", ")", "\n", "self", ".", "wo", "=", "nn", ".", "Linear", "(", "config", ".", "d_ff", ",", "config", ".", "d_model", ",", "bias", "=", "False", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5DenseReluDense.forward": [[162, 168], ["modeling_t5.T5DenseReluDense.wi", "torch.relu", "torch.relu", "modeling_t5.T5DenseReluDense.dropout", "modeling_t5.T5DenseReluDense.wo"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "h", "=", "self", ".", "wi", "(", "hidden_states", ")", "\n", "h", "=", "F", ".", "relu", "(", "h", ")", "\n", "h", "=", "self", ".", "dropout", "(", "h", ")", "\n", "h", "=", "self", ".", "wo", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5LayerFF.__init__": [[171, 176], ["torch.nn.Module.__init__", "modeling_t5.T5DenseReluDense", "modeling_t5.T5LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "T5LayerFF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "DenseReluDense", "=", "T5DenseReluDense", "(", "config", ")", "\n", "self", ".", "layer_norm", "=", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5LayerFF.forward": [[177, 182], ["modeling_t5.T5LayerFF.layer_norm", "modeling_t5.T5LayerFF.DenseReluDense", "modeling_t5.T5LayerFF.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "norm_x", "=", "self", ".", "layer_norm", "(", "hidden_states", ")", "\n", "y", "=", "self", ".", "DenseReluDense", "(", "norm_x", ")", "\n", "layer_output", "=", "hidden_states", "+", "self", ".", "dropout", "(", "y", ")", "\n", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Attention.__init__": [[187, 210], ["torch.nn.Module.__init__", "next", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "set", "torch.nn.Embedding", "torch.nn.Embedding"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "has_relative_attention_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", "T5Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer_id", "=", "next", "(", "T5Attention", ".", "NEW_ID", ")", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "self", ".", "has_relative_attention_bias", "=", "has_relative_attention_bias", "\n", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "relative_attention_num_buckets", "=", "config", ".", "relative_attention_num_buckets", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "d_kv", "=", "config", ".", "d_kv", "\n", "self", ".", "n_heads", "=", "config", ".", "num_heads", "\n", "self", ".", "dropout", "=", "config", ".", "dropout_rate", "\n", "self", ".", "inner_dim", "=", "self", ".", "n_heads", "*", "self", ".", "d_kv", "\n", "\n", "# Mesh TensorFlow initialization to avoid scaling before softmax", "\n", "self", ".", "q", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "inner_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "k", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "inner_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "v", "=", "nn", ".", "Linear", "(", "self", ".", "d_model", ",", "self", ".", "inner_dim", ",", "bias", "=", "False", ")", "\n", "self", ".", "o", "=", "nn", ".", "Linear", "(", "self", ".", "inner_dim", ",", "self", ".", "d_model", ",", "bias", "=", "False", ")", "\n", "\n", "if", "self", ".", "has_relative_attention_bias", ":", "\n", "            ", "self", ".", "relative_attention_bias", "=", "nn", ".", "Embedding", "(", "self", ".", "relative_attention_num_buckets", ",", "self", ".", "n_heads", ")", "\n", "", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Attention.prune_heads": [[211, 230], ["torch.ones", "torch.ones", "torch.ones", "torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_t5.T5Attention.pruned_heads.union", "len", "set", "sum", "len", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "n_heads", ",", "self", ".", "d_kv", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "\n", "for", "head", "in", "heads", ":", "\n", "            ", "head", "-=", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "# Prune linear layers", "\n", "self", ".", "q", "=", "prune_linear_layer", "(", "self", ".", "q", ",", "index", ")", "\n", "self", ".", "k", "=", "prune_linear_layer", "(", "self", ".", "k", ",", "index", ")", "\n", "self", ".", "v", "=", "prune_linear_layer", "(", "self", ".", "v", ",", "index", ")", "\n", "self", ".", "o", "=", "prune_linear_layer", "(", "self", ".", "o", ",", "index", ",", "dim", "=", "1", ")", "\n", "# Update hyper params", "\n", "self", ".", "n_heads", "=", "self", ".", "n_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "inner_dim", "=", "self", ".", "d_kv", "*", "self", ".", "n_heads", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Attention._relative_position_bucket": [[231, 278], ["torch.min", "torch.min", "torch.min", "torch.min", "torch.where", "torch.where", "torch.where", "torch.where", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.max", "torch.max", "torch.max", "torch.max", "torch.full_like", "torch.full_like", "torch.full_like", "torch.full_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.log", "torch.log", "torch.log", "torch.log", "math.log", "torch.max.float", "torch.max.float"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_relative_position_bucket", "(", "relative_position", ",", "bidirectional", "=", "True", ",", "num_buckets", "=", "32", ",", "max_distance", "=", "128", ")", ":", "\n", "        ", "\"\"\"\n        Adapted from Mesh Tensorflow:\n        https://github.com/tensorflow/mesh/blob/0cb87fe07da627bf0b7e60475d59f95ed6b5be3d/mesh_tensorflow/transformer/transformer_layers.py#L593\n\n        Translate relative position to a bucket number for relative attention.\n        The relative position is defined as memory_position - query_position, i.e.\n        the distance in tokens from the attending position to the attended-to\n        position.  If bidirectional=False, then positive relative positions are\n        invalid.\n        We use smaller buckets for small absolute relative_position and larger buckets\n        for larger absolute relative_positions.  All relative positions >=max_distance\n        map to the same bucket.  All relative positions <=-max_distance map to the\n        same bucket.  This should allow for more graceful generalization to longer\n        sequences than the model has been trained on.\n        Args:\n            relative_position: an int32 Tensor\n            bidirectional: a boolean - whether the attention is bidirectional\n            num_buckets: an integer\n            max_distance: an integer\n        Returns:\n            a Tensor with the same shape as relative_position, containing int32\n            values in the range [0, num_buckets)\n        \"\"\"", "\n", "ret", "=", "0", "\n", "n", "=", "-", "relative_position", "\n", "if", "bidirectional", ":", "\n", "            ", "num_buckets", "//=", "2", "\n", "ret", "+=", "(", "n", "<", "0", ")", ".", "to", "(", "torch", ".", "long", ")", "*", "num_buckets", "# mtf.to_int32(mtf.less(n, 0)) * num_buckets", "\n", "n", "=", "torch", ".", "abs", "(", "n", ")", "\n", "", "else", ":", "\n", "            ", "n", "=", "torch", ".", "max", "(", "n", ",", "torch", ".", "zeros_like", "(", "n", ")", ")", "\n", "# now n is in the range [0, inf)", "\n", "\n", "# half of the buckets are for exact increments in positions", "\n", "", "max_exact", "=", "num_buckets", "//", "2", "\n", "is_small", "=", "n", "<", "max_exact", "\n", "\n", "# The other half of the buckets are for logarithmically bigger bins in positions up to max_distance", "\n", "val_if_large", "=", "max_exact", "+", "(", "\n", "torch", ".", "log", "(", "n", ".", "float", "(", ")", "/", "max_exact", ")", "/", "math", ".", "log", "(", "max_distance", "/", "max_exact", ")", "*", "(", "num_buckets", "-", "max_exact", ")", "\n", ")", ".", "to", "(", "torch", ".", "long", ")", "\n", "val_if_large", "=", "torch", ".", "min", "(", "val_if_large", ",", "torch", ".", "full_like", "(", "val_if_large", ",", "num_buckets", "-", "1", ")", ")", "\n", "\n", "ret", "+=", "torch", ".", "where", "(", "is_small", ",", "n", ",", "val_if_large", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Attention.compute_bias": [[279, 292], ["modeling_t5.T5Attention._relative_position_bucket", "modeling_t5.T5Attention.relative_attention_bias", "values.permute().unsqueeze.permute().unsqueeze.permute().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "values.permute().unsqueeze.permute().unsqueeze.permute"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Attention._relative_position_bucket"], ["", "def", "compute_bias", "(", "self", ",", "qlen", ",", "klen", ")", ":", "\n", "        ", "\"\"\" Compute binned relative position bias \"\"\"", "\n", "context_position", "=", "torch", ".", "arange", "(", "qlen", ",", "dtype", "=", "torch", ".", "long", ")", "[", ":", ",", "None", "]", "\n", "memory_position", "=", "torch", ".", "arange", "(", "klen", ",", "dtype", "=", "torch", ".", "long", ")", "[", "None", ",", ":", "]", "\n", "relative_position", "=", "memory_position", "-", "context_position", "# shape (qlen, klen)", "\n", "rp_bucket", "=", "self", ".", "_relative_position_bucket", "(", "\n", "relative_position", ",", "# shape (qlen, klen)", "\n", "bidirectional", "=", "not", "self", ".", "is_decoder", ",", "\n", "num_buckets", "=", "self", ".", "relative_attention_num_buckets", ",", "\n", ")", "\n", "values", "=", "self", ".", "relative_attention_bias", "(", "rp_bucket", ")", "# shape (qlen, klen, num_heads)", "\n", "values", "=", "values", ".", "permute", "(", "[", "2", ",", "0", ",", "1", "]", ")", ".", "unsqueeze", "(", "0", ")", "# shape (1, num_heads, qlen, klen)", "\n", "return", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Attention.forward": [[293, 361], ["input.size", "modeling_t5.T5Attention.forward.shape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "mask", "=", "None", ",", "kv", "=", "None", ",", "position_bias", "=", "None", ",", "cache", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Self-attention (if kv is None) or attention over source sentence (provided by kv).\n        \"\"\"", "\n", "# Input is (bs, qlen, dim)", "\n", "# Mask is (bs, klen) (non-causal) or (bs, klen, klen)", "\n", "bs", ",", "qlen", ",", "dim", "=", "input", ".", "size", "(", ")", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "klen", "=", "qlen", "if", "cache", "is", "None", "else", "cache", "[", "\"slen\"", "]", "+", "qlen", "\n", "", "else", ":", "\n", "            ", "klen", "=", "kv", ".", "size", "(", "1", ")", "\n", "\n", "", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  projection \"\"\"", "\n", "return", "x", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", ",", "self", ".", "d_kv", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  compute context \"\"\"", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "inner_dim", ")", "\n", "\n", "", "q", "=", "shape", "(", "self", ".", "q", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "k", "=", "shape", "(", "self", ".", "k", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "", "elif", "cache", "is", "None", "or", "self", ".", "layer_id", "not", "in", "cache", ":", "\n", "            ", "k", "=", "v", "=", "kv", "\n", "k", "=", "shape", "(", "self", ".", "k", "(", "k", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v", "(", "v", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "\n", "", "if", "cache", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "layer_id", "in", "cache", ":", "\n", "                ", "if", "kv", "is", "None", ":", "\n", "                    ", "k_", ",", "v_", "=", "cache", "[", "self", ".", "layer_id", "]", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k_", ",", "k", "]", ",", "dim", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v_", ",", "v", "]", ",", "dim", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "", "else", ":", "\n", "                    ", "k", ",", "v", "=", "cache", "[", "self", ".", "layer_id", "]", "\n", "", "", "cache", "[", "self", ".", "layer_id", "]", "=", "(", "k", ",", "v", ")", "\n", "\n", "# q = q / math.sqrt(dim_per_head)                                     # No scaling in T5", "\n", "", "scores", "=", "torch", ".", "einsum", "(", "\"bnqd,bnkd->bnqk\"", ",", "q", ",", "k", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "if", "position_bias", "is", "None", ":", "\n", "            ", "if", "not", "self", ".", "has_relative_attention_bias", ":", "\n", "                ", "raise", "ValueError", "(", "\"No position_bias provided and no weights to compute position_bias\"", ")", "\n", "", "position_bias", "=", "self", ".", "compute_bias", "(", "qlen", ",", "klen", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "                ", "position_bias", "=", "position_bias", "+", "mask", "# (bs, n_heads, qlen, klen)", "\n", "\n", "", "", "scores", "+=", "position_bias", "\n", "weights", "=", "F", ".", "softmax", "(", "scores", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "type_as", "(", "scores", ")", "# (bs, n_heads, qlen, klen)", "\n", "weights", "=", "F", ".", "dropout", "(", "weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "weights", "=", "weights", "*", "head_mask", "\n", "\n", "", "context", "=", "torch", ".", "matmul", "(", "weights", ",", "v", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "context", "=", "unshape", "(", "context", ")", "# (bs, qlen, dim)", "\n", "\n", "context", "=", "self", ".", "o", "(", "context", ")", "\n", "\n", "outputs", "=", "(", "context", ",", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "weights", ",", ")", "\n", "", "if", "self", ".", "has_relative_attention_bias", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "position_bias", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5LayerSelfAttention.__init__": [[364, 369], ["torch.nn.Module.__init__", "modeling_t5.T5Attention", "modeling_t5.T5LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "has_relative_attention_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", "T5LayerSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "SelfAttention", "=", "T5Attention", "(", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ")", "\n", "self", ".", "layer_norm", "=", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5LayerSelfAttention.forward": [[370, 379], ["modeling_t5.T5LayerSelfAttention.layer_norm", "modeling_t5.T5LayerSelfAttention.SelfAttention", "modeling_t5.T5LayerSelfAttention.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", "=", "None", ",", "position_bias", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "norm_x", "=", "self", ".", "layer_norm", "(", "hidden_states", ")", "\n", "attention_output", "=", "self", ".", "SelfAttention", "(", "\n", "norm_x", ",", "mask", "=", "attention_mask", ",", "position_bias", "=", "position_bias", ",", "head_mask", "=", "head_mask", "\n", ")", "\n", "y", "=", "attention_output", "[", "0", "]", "\n", "layer_output", "=", "hidden_states", "+", "self", ".", "dropout", "(", "y", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "attention_output", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5LayerCrossAttention.__init__": [[382, 387], ["torch.nn.Module.__init__", "modeling_t5.T5Attention", "modeling_t5.T5LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "has_relative_attention_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", "T5LayerCrossAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "EncDecAttention", "=", "T5Attention", "(", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ")", "\n", "self", ".", "layer_norm", "=", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5LayerCrossAttention.forward": [[388, 397], ["modeling_t5.T5LayerCrossAttention.layer_norm", "modeling_t5.T5LayerCrossAttention.EncDecAttention", "modeling_t5.T5LayerCrossAttention.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "kv", ",", "attention_mask", "=", "None", ",", "position_bias", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "norm_x", "=", "self", ".", "layer_norm", "(", "hidden_states", ")", "\n", "attention_output", "=", "self", ".", "EncDecAttention", "(", "\n", "norm_x", ",", "mask", "=", "attention_mask", ",", "kv", "=", "kv", ",", "position_bias", "=", "position_bias", ",", "head_mask", "=", "head_mask", "\n", ")", "\n", "y", "=", "attention_output", "[", "0", "]", "\n", "layer_output", "=", "hidden_states", "+", "self", ".", "dropout", "(", "y", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "attention_output", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Block.__init__": [[400, 410], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "modeling_t5.T5Block.layer.append", "modeling_t5.T5LayerSelfAttention", "modeling_t5.T5Block.layer.append", "modeling_t5.T5Block.layer.append", "modeling_t5.T5Block.layer.append", "modeling_t5.T5LayerCrossAttention", "modeling_t5.T5LayerFF", "modeling_t5.T5LayerFF"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "has_relative_attention_bias", "=", "False", ")", ":", "\n", "        ", "super", "(", "T5Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "layer", ".", "append", "(", "T5LayerSelfAttention", "(", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ")", ")", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "self", ".", "layer", ".", "append", "(", "T5LayerCrossAttention", "(", "config", ",", "has_relative_attention_bias", "=", "has_relative_attention_bias", ")", ")", "\n", "self", ".", "layer", ".", "append", "(", "T5LayerFF", "(", "config", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "layer", ".", "append", "(", "T5LayerFF", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Block.forward": [[411, 445], ["None"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "position_bias", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "encoder_decoder_position_bias", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self_attention_outputs", "=", "self", ".", "layer", "[", "0", "]", "(", "\n", "hidden_states", ",", "attention_mask", "=", "attention_mask", ",", "position_bias", "=", "position_bias", ",", "head_mask", "=", "head_mask", "\n", ")", "\n", "hidden_states", "=", "self_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "self_attention_outputs", "[", "1", ":", "]", "# Keep self-attention outputs and relative position weights", "\n", "\n", "if", "not", "self", ".", "is_decoder", ":", "\n", "            ", "hidden_states", "=", "self", ".", "layer", "[", "1", "]", "(", "hidden_states", ")", "\n", "", "else", ":", "\n", "            ", "cross_attention_outputs", "=", "self", ".", "layer", "[", "1", "]", "(", "\n", "hidden_states", ",", "\n", "kv", "=", "encoder_hidden_states", ",", "\n", "attention_mask", "=", "encoder_attention_mask", ",", "\n", "position_bias", "=", "encoder_decoder_position_bias", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", ")", "\n", "hidden_states", "=", "cross_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "(", "\n", "outputs", "+", "cross_attention_outputs", "[", "1", ":", "]", "\n", ")", "# Keep cross-attention outputs and relative position weights", "\n", "hidden_states", "=", "self", ".", "layer", "[", "2", "]", "(", "hidden_states", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "+", "outputs", "# add attentions if we output them", "\n", "return", "outputs", "# hidden-states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5PreTrainedModel.dummy_inputs": [[457, 467], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["@", "property", "\n", "def", "dummy_inputs", "(", "self", ")", ":", "\n", "        ", "input_ids", "=", "torch", ".", "tensor", "(", "DUMMY_INPUTS", ")", "\n", "input_mask", "=", "torch", ".", "tensor", "(", "DUMMY_MASK", ")", "\n", "dummy_inputs", "=", "{", "\n", "\"decoder_input_ids\"", ":", "input_ids", ",", "\n", "\"encoder_input_ids\"", ":", "input_ids", ",", "\n", "\"decoder_attention_mask\"", ":", "input_mask", ",", "\n", "}", "\n", "return", "dummy_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5PreTrainedModel._init_weights": [[468, 499], ["isinstance", "module.weight.data.fill_", "isinstance", "module.shared.weight.data.normal_", "isinstance", "module.wi.weight.data.normal_", "module.wo.weight.data.normal_", "isinstance", "hasattr", "module.wi.bias.data.zero_", "hasattr", "module.wo.bias.data.zero_", "module.q.weight.data.normal_", "module.k.weight.data.normal_", "module.v.weight.data.normal_", "module.o.weight.data.normal_", "module.relative_attention_bias.weight.data.normal_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights \"\"\"", "\n", "factor", "=", "self", ".", "config", ".", "initializer_factor", "# Used for testing weights initialization", "\n", "if", "isinstance", "(", "module", ",", "T5LayerNorm", ")", ":", "\n", "            ", "module", ".", "weight", ".", "data", ".", "fill_", "(", "factor", "*", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "(", "T5Model", ",", "T5WithLMHeadModel", ")", ")", ":", "\n", "# Mesh TensorFlow embeddings initialization", "\n", "# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L1624", "\n", "            ", "module", ".", "shared", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "T5DenseReluDense", ")", ":", "\n", "# Mesh TensorFlow FF initialization", "\n", "# See https://github.com/tensorflow/mesh/blob/master/mesh_tensorflow/transformer/transformer_layers.py#L56", "\n", "# and https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L89", "\n", "            ", "module", ".", "wi", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "self", ".", "config", ".", "d_model", ")", "**", "-", "0.5", ")", ")", "\n", "if", "hasattr", "(", "module", ".", "wi", ",", "\"bias\"", ")", "and", "module", ".", "wi", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "wi", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "module", ".", "wo", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "self", ".", "config", ".", "d_ff", ")", "**", "-", "0.5", ")", ")", "\n", "if", "hasattr", "(", "module", ".", "wo", ",", "\"bias\"", ")", "and", "module", ".", "wo", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "wo", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "T5Attention", ")", ":", "\n", "# Mesh TensorFlow attention initialization to avoid scaling before softmax", "\n", "# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/attention.py#L136", "\n", "            ", "d_model", "=", "self", ".", "config", ".", "d_model", "\n", "d_kv", "=", "self", ".", "config", ".", "d_kv", "\n", "n_heads", "=", "self", ".", "config", ".", "num_heads", "\n", "module", ".", "q", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "d_model", "*", "d_kv", ")", "**", "-", "0.5", ")", ")", "\n", "module", ".", "k", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "d_model", "**", "-", "0.5", ")", ")", "\n", "module", ".", "v", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "d_model", "**", "-", "0.5", ")", ")", "\n", "module", ".", "o", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "n_heads", "*", "d_kv", ")", "**", "-", "0.5", ")", ")", "\n", "if", "module", ".", "has_relative_attention_bias", ":", "\n", "                ", "module", ".", "relative_attention_bias", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "factor", "*", "(", "(", "d_model", ")", "**", "-", "0.5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Stack.__init__": [[502, 515], ["modeling_utils.PreTrainedModel.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "modeling_t5.T5LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "modeling_t5.T5Stack.init_weights", "modeling_t5.T5Block", "range", "bool"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "T5Stack", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "\n", "self", ".", "block", "=", "nn", ".", "ModuleList", "(", "\n", "[", "T5Block", "(", "config", ",", "has_relative_attention_bias", "=", "bool", "(", "i", "==", "0", ")", ")", "for", "i", "in", "range", "(", "config", ".", "num_layers", ")", "]", "\n", ")", "\n", "self", ".", "final_layer_norm", "=", "T5LayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout_rate", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Stack.forward": [[516, 644], ["extended_attention_mask.to.to.to", "modeling_t5.T5Stack.dropout", "enumerate", "modeling_t5.T5Stack.final_layer_norm", "modeling_t5.T5Stack.dropout", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to.dim", "torch.ones().to.dim", "encoder_extended_attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "layer_module", "torch.ones().to.dim", "torch.ones().to.dim", "torch.ones().to.dim", "torch.ones().to.dim", "torch.ones().to.dim", "torch.ones().to.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "causal_mask.to.to.to", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "seq_ids[].repeat", "modeling_t5.T5Stack.parameters", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "modeling_t5.T5Stack.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_t5.T5Stack.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "batch_size", ",", "seq_length", "=", "hidden_states", ".", "shape", "[", "0", "]", ",", "hidden_states", ".", "shape", "[", "1", "]", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "batch_size", ",", "seq_length", ")", ".", "to", "(", "hidden_states", ".", "device", ")", "\n", "", "if", "self", ".", "is_decoder", "and", "encoder_attention_mask", "is", "None", ":", "\n", "            ", "encoder_seq_length", "=", "encoder_hidden_states", ".", "shape", "[", "1", "]", "\n", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "batch_size", ",", "encoder_seq_length", ")", ".", "to", "(", "hidden_states", ".", "device", ")", "\n", "\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "if", "attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "# Provided a padding mask of dimensions [batch_size, seq_length]", "\n", "# - if the model is a decoder, apply a causal mask in addition to the padding mask", "\n", "# - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]", "\n", "            ", "if", "self", ".", "config", ".", "is_decoder", ":", "\n", "                ", "seq_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "device", "=", "hidden_states", ".", "device", ")", "\n", "causal_mask", "=", "seq_ids", "[", "None", ",", "None", ",", ":", "]", ".", "repeat", "(", "batch_size", ",", "seq_length", ",", "1", ")", "<=", "seq_ids", "[", "None", ",", ":", ",", "None", "]", "\n", "causal_mask", "=", "causal_mask", ".", "to", "(", "attention_mask", ")", "\n", "extended_attention_mask", "=", "causal_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "*", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -1e9 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "\n", "# T5 has a mask that can compare sequence ids, we can simulate this here with this transposition", "\n", "# Cf. https://github.com/tensorflow/mesh/blob/8d2465e9bc93129b913b5ccc6a59aa97abd96ec6/mesh_tensorflow/transformer/transformer_layers.py#L270", "\n", "# extended_attention_mask = (extended_attention_mask == extended_attention_mask.transpose(-1, -2))", "\n", "\n", "", "", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "1e9", "\n", "\n", "if", "self", ".", "is_decoder", ":", "\n", "# If a 2D ou 3D attention mask is provided for the cross-attention", "\n", "# we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]", "\n", "            ", "if", "encoder_attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "if", "encoder_attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "\n", "# T5 has a mask that can compare sequence ids, we can simulate this here with this transposition", "\n", "# Cf. https://github.com/tensorflow/mesh/blob/8d2465e9bc93129b913b5ccc6a59aa97abd96ec6/mesh_tensorflow/transformer/transformer_layers.py#L270", "\n", "# encoder_extended_attention_mask = (encoder_extended_attention_mask == encoder_extended_attention_mask.transpose(-1, -2))", "\n", "\n", "", "encoder_extended_attention_mask", "=", "encoder_extended_attention_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# fp16 compatibility", "\n", "encoder_extended_attention_mask", "=", "(", "1.0", "-", "encoder_extended_attention_mask", ")", "*", "-", "1e9", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "num_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_layers", "\n", "\n", "", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "position_bias", "=", "None", "\n", "encoder_decoder_position_bias", "=", "None", "\n", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "block", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "position_bias", "=", "position_bias", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", "encoder_decoder_position_bias", "=", "encoder_decoder_position_bias", ",", "\n", "head_mask", "=", "head_mask", "[", "i", "]", ",", "\n", ")", "\n", "# layer_outputs is a tuple with:", "\n", "# hidden-states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "if", "i", "==", "0", ":", "\n", "# We share the position biases between the layers - the first layer store them", "\n", "# layer_outputs = hidden-states, (self-attention weights), (self-attention position bias), (cross-attention weights), (cross-attention position bias)", "\n", "                ", "position_bias", "=", "layer_outputs", "[", "2", "if", "self", ".", "output_attentions", "else", "1", "]", "\n", "if", "self", ".", "is_decoder", ":", "\n", "                    ", "encoder_decoder_position_bias", "=", "layer_outputs", "[", "4", "if", "self", ".", "output_attentions", "else", "2", "]", "\n", "\n", "", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "# We keep only self-attention weights for now", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "final_layer_norm", "(", "hidden_states", ")", "\n", "layer_output", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "\n", "# Add last layer", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Model.__init__": [[725, 737], ["modeling_utils.PreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "copy.deepcopy", "modeling_t5.T5Stack", "copy.deepcopy", "modeling_t5.T5Stack", "modeling_t5.T5Model.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "T5Model", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "shared", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "d_model", ")", "\n", "\n", "encoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "self", ".", "encoder", "=", "T5Stack", "(", "encoder_config", ")", "\n", "\n", "decoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "decoder_config", ".", "is_decoder", "=", "True", "\n", "self", ".", "decoder", "=", "T5Stack", "(", "decoder_config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Model.get_input_embeddings": [[738, 740], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Model.set_input_embeddings": [[741, 743], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "shared", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Model._prune_heads": [[744, 751], ["heads_to_prune.items", "modeling_t5.T5Model.encoder.layer[].attention.prune_heads"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5Model.forward": [[752, 797], ["dict", "dict.copy", "dict.copy", "dict.copy.update", "dict.copy.update", "dict.copy.pop", "dict.copy.get", "dict.copy.pop", "modeling_t5.T5Model.decoder", "dict", "dict", "dict.copy.pop", "modeling_t5.T5Model.encoder", "dict.copy.pop", "modeling_t5.T5Model.shared", "dict.copy.pop", "modeling_t5.T5Model.shared", "kwargs.items", "kwargs_common.copy.get.unsqueeze", "kwargs.items", "k.startswith", "kwargs.items", "k.startswith", "k.startswith", "k.startswith", "len", "len"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "# keyword arguments come in 3 flavors: encoder-specific (prefixed by", "\n", "# `encoder_`), decoder-specific (prefixed by `decoder_`) and those", "\n", "# that apply to the model as whole.", "\n", "# We let the specific kwargs override the common ones in case of conflict.", "\n", "        ", "kwargs_common", "=", "dict", "(", "\n", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "if", "not", "k", ".", "startswith", "(", "\"encoder_\"", ")", "and", "not", "k", ".", "startswith", "(", "\"decoder_\"", ")", "\n", ")", "\n", "kwargs_encoder", "=", "kwargs_common", ".", "copy", "(", ")", "\n", "kwargs_decoder", "=", "kwargs_common", ".", "copy", "(", ")", "\n", "kwargs_encoder", ".", "update", "(", "dict", "(", "(", "k", "[", "len", "(", "\"encoder_\"", ")", ":", "]", ",", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "if", "k", ".", "startswith", "(", "\"encoder_\"", ")", ")", ")", "\n", "kwargs_decoder", ".", "update", "(", "dict", "(", "(", "k", "[", "len", "(", "\"decoder_\"", ")", ":", "]", ",", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "if", "k", ".", "startswith", "(", "\"decoder_\"", ")", ")", ")", "\n", "\n", "# Encode if needed (training, first prediction pass)", "\n", "encoder_hidden_states", "=", "kwargs_encoder", ".", "pop", "(", "\"hidden_states\"", ",", "None", ")", "\n", "encoder_attention_mask", "=", "kwargs_encoder", ".", "get", "(", "\"attention_mask\"", ",", "None", ")", "\n", "if", "encoder_hidden_states", "is", "None", ":", "\n", "# Convert encoder inputs in embeddings if needed", "\n", "            ", "hidden_states", "=", "kwargs_encoder", ".", "pop", "(", "\"inputs_embeds\"", ",", "None", ")", "\n", "if", "hidden_states", "is", "None", ":", "\n", "                ", "encoder_inputs_ids", "=", "kwargs_encoder", ".", "pop", "(", "\"input_ids\"", ")", "\n", "hidden_states", "=", "self", ".", "shared", "(", "encoder_inputs_ids", ")", "# Convert inputs in embeddings", "\n", "\n", "", "if", "encoder_attention_mask", "is", "not", "None", ":", "\n", "# Apply masking", "\n", "                ", "encoder_attention_mask", "=", "(", "encoder_attention_mask", "!=", "0", ")", ".", "to", "(", "hidden_states", ")", "\n", "hidden_states", "=", "hidden_states", "*", "encoder_attention_mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "encoder_outputs", "=", "self", ".", "encoder", "(", "hidden_states", ",", "**", "kwargs_encoder", ")", "\n", "encoder_hidden_states", "=", "encoder_outputs", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "encoder_outputs", "=", "(", ")", "\n", "\n", "# Decode", "\n", "# Convert decoder inputs in embeddings if needed", "\n", "", "hidden_states", "=", "kwargs_decoder", ".", "pop", "(", "\"inputs_embeds\"", ",", "None", ")", "\n", "if", "hidden_states", "is", "None", ":", "\n", "            ", "decoder_inputs_ids", "=", "kwargs_decoder", ".", "pop", "(", "\"input_ids\"", ")", "\n", "hidden_states", "=", "self", ".", "shared", "(", "decoder_inputs_ids", ")", "\n", "\n", "", "kwargs_decoder", "[", "\"encoder_hidden_states\"", "]", "=", "encoder_hidden_states", "\n", "kwargs_decoder", "[", "\"encoder_attention_mask\"", "]", "=", "encoder_attention_mask", "\n", "decoder_outputs", "=", "self", ".", "decoder", "(", "hidden_states", ",", "**", "kwargs_decoder", ")", "\n", "\n", "return", "decoder_outputs", "+", "encoder_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5WithLMHeadModel.__init__": [[831, 847], ["modeling_utils.PreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "copy.deepcopy", "modeling_t5.T5Stack", "copy.deepcopy", "modeling_t5.T5Stack", "torch.nn.Linear", "torch.nn.Linear", "modeling_t5.T5WithLMHeadModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "T5WithLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "model_dim", "=", "config", ".", "d_model", "\n", "\n", "self", ".", "shared", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "d_model", ")", "\n", "\n", "encoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "self", ".", "encoder", "=", "T5Stack", "(", "encoder_config", ")", "\n", "\n", "decoder_config", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "decoder_config", ".", "is_decoder", "=", "True", "\n", "self", ".", "decoder", "=", "T5Stack", "(", "decoder_config", ")", "\n", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5WithLMHeadModel.get_input_embeddings": [[848, 850], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "shared", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5WithLMHeadModel.set_input_embeddings": [[851, 853], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "shared", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5WithLMHeadModel.get_output_embeddings": [[854, 856], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.T5WithLMHeadModel.forward": [[857, 915], ["kwargs.pop", "dict", "dict.copy", "dict.copy", "dict.copy.update", "dict.copy.update", "dict.copy.pop", "dict.copy.pop", "dict.copy.get", "modeling_t5.T5WithLMHeadModel.decoder", "modeling_t5.T5WithLMHeadModel.lm_head", "dict", "dict", "dict.copy.pop", "modeling_t5.T5WithLMHeadModel.encoder", "dict.copy.pop", "modeling_t5.T5WithLMHeadModel.shared", "lm_logits[].contiguous", "lm_labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "dict.copy.pop", "modeling_t5.T5WithLMHeadModel.shared", "lm_logits[].contiguous.view", "lm_labels[].contiguous.view", "kwargs.items", "lm_logits[].contiguous.size", "kwargs.items", "k.startswith", "kwargs.items", "k.startswith", "k.startswith", "k.startswith", "len", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "# keyword arguments come in 3 flavors: encoder-specific (prefixed by", "\n", "# `encoder_`), decoder-specific (prefixed by `decoder_`) and those", "\n", "# that apply to the model as whole.", "\n", "# We let the specific kwargs override the common ones in case of conflict.", "\n", "\n", "        ", "lm_labels", "=", "kwargs", ".", "pop", "(", "\"decoder_lm_labels\"", ",", "None", ")", "\n", "\n", "kwargs_common", "=", "dict", "(", "\n", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "if", "not", "k", ".", "startswith", "(", "\"encoder_\"", ")", "and", "not", "k", ".", "startswith", "(", "\"decoder_\"", ")", "\n", ")", "\n", "kwargs_encoder", "=", "kwargs_common", ".", "copy", "(", ")", "\n", "kwargs_decoder", "=", "kwargs_common", ".", "copy", "(", ")", "\n", "kwargs_encoder", ".", "update", "(", "dict", "(", "(", "k", "[", "len", "(", "\"encoder_\"", ")", ":", "]", ",", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "if", "k", ".", "startswith", "(", "\"encoder_\"", ")", ")", ")", "\n", "kwargs_decoder", ".", "update", "(", "dict", "(", "(", "k", "[", "len", "(", "\"decoder_\"", ")", ":", "]", ",", "v", ")", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", "if", "k", ".", "startswith", "(", "\"decoder_\"", ")", ")", ")", "\n", "\n", "# Encode if needed (training, first prediction pass)", "\n", "encoder_hidden_states", "=", "kwargs_encoder", ".", "pop", "(", "\"hidden_states\"", ",", "None", ")", "\n", "if", "encoder_hidden_states", "is", "None", ":", "\n", "# Convert encoder inputs in embeddings if needed", "\n", "            ", "hidden_states", "=", "kwargs_encoder", ".", "pop", "(", "\"inputs_embeds\"", ",", "None", ")", "\n", "if", "hidden_states", "is", "None", ":", "\n", "                ", "encoder_inputs_ids", "=", "kwargs_encoder", ".", "pop", "(", "\"input_ids\"", ")", "\n", "hidden_states", "=", "self", ".", "shared", "(", "encoder_inputs_ids", ")", "# Convert inputs in embeddings", "\n", "\n", "", "encoder_outputs", "=", "self", ".", "encoder", "(", "hidden_states", ",", "**", "kwargs_encoder", ")", "\n", "encoder_hidden_states", "=", "encoder_outputs", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "encoder_outputs", "=", "(", ")", "\n", "\n", "# Decode", "\n", "# Convert decoder inputs in embeddings if needed", "\n", "", "hidden_states", "=", "kwargs_decoder", ".", "pop", "(", "\"inputs_embeds\"", ",", "None", ")", "\n", "if", "hidden_states", "is", "None", ":", "\n", "            ", "decoder_inputs_ids", "=", "kwargs_decoder", ".", "pop", "(", "\"input_ids\"", ")", "\n", "hidden_states", "=", "self", ".", "shared", "(", "decoder_inputs_ids", ")", "\n", "\n", "", "kwargs_decoder", "[", "\"encoder_hidden_states\"", "]", "=", "encoder_hidden_states", "\n", "kwargs_decoder", "[", "\"encoder_attention_mask\"", "]", "=", "kwargs_encoder", ".", "get", "(", "\"attention_mask\"", ",", "None", ")", "\n", "decoder_outputs", "=", "self", ".", "decoder", "(", "hidden_states", ",", "**", "kwargs_decoder", ")", "\n", "\n", "sequence_output", "=", "decoder_outputs", "[", "0", "]", "\n", "# Rescale output before projecting on vocab", "\n", "# See https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/transformer/transformer.py#L586", "\n", "sequence_output", "=", "sequence_output", "*", "(", "self", ".", "model_dim", "**", "-", "0.5", ")", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "decoder_outputs", "=", "(", "lm_logits", ",", ")", "+", "decoder_outputs", "[", "1", ":", "]", "# Add hidden states and attention if they are here", "\n", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "lm_labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "decoder_outputs", "=", "(", "\n", "loss", ",", "\n", ")", "+", "decoder_outputs", "# TODO(thom): Add z_loss https://github.com/tensorflow/mesh/blob/fa19d69eafc9a482aff0b59ddd96b025c0cb207d/mesh_tensorflow/layers.py#L666", "\n", "\n", "", "return", "decoder_outputs", "+", "encoder_outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.load_tf_weights_in_t5": [[53, 131], ["os.path.abspath", "logger.info", "tf.train.list_variables", "logger.info", "logger.info", "tf.train.load_variable", "names.append", "txt_name.split", "any", "logger.info", "torch.from_numpy", "torch.from_numpy", "tf_weights.pop", "logger.error", "logger.info", "tf_weights.pop", "logger.info", "tf_weights.pop", "re.fullmatch", "getattr", "logger.info", "np.transpose", "np.transpose.astype", "re.split", "getattr", "len", "int", "tf_weights.keys", "getattr", "logger.info"], "function", ["None"], ["def", "load_tf_weights_in_t5", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "tf_weights", "=", "{", "}", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "tf_weights", "[", "name", "]", "=", "array", "\n", "\n", "", "for", "txt_name", "in", "names", ":", "\n", "        ", "name", "=", "txt_name", ".", "split", "(", "\"/\"", ")", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "any", "(", "n", "in", "[", "\"adam_v\"", ",", "\"adam_m\"", ",", "\"global_step\"", "]", "for", "n", "in", "name", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "tf_weights", ".", "pop", "(", "txt_name", ",", "None", ")", "\n", "continue", "\n", "", "if", "\"_slot_\"", "in", "name", "[", "-", "1", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "tf_weights", ".", "pop", "(", "txt_name", ",", "None", ")", "\n", "continue", "\n", "", "pointer", "=", "model", "\n", "array", "=", "tf_weights", "[", "txt_name", "]", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r\"[A-Za-z]+_\\d+\"", ",", "m_name", ")", ":", "\n", "                ", "scope_names", "=", "re", ".", "split", "(", "r\"_(\\d+)\"", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "scope_names", "=", "[", "m_name", "]", "\n", "", "if", "scope_names", "[", "0", "]", "in", "[", "\"kernel\"", ",", "\"scale\"", ",", "\"embedding\"", "]", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "# elif scope_names[0] == 'scale':", "\n", "#     pointer = getattr(pointer, 'weight')", "\n", "# elif scope_names[0] == 'output_bias' or scope_names[0] == 'beta':", "\n", "#     pointer = getattr(pointer, 'bias')", "\n", "# elif scope_names[0] == 'squad':", "\n", "#     pointer = getattr(pointer, 'classifier')", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "", "if", "len", "(", "scope_names", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "scope_names", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "if", "scope_names", "[", "0", "]", "not", "in", "[", "\"kernel\"", ",", "\"scale\"", ",", "\"embedding\"", "]", ":", "\n", "            ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "if", "scope_names", "[", "0", "]", "!=", "\"embedding\"", ":", "\n", "            ", "logger", ".", "info", "(", "\"Transposing numpy weight of shape {} for {}\"", ".", "format", "(", "array", ".", "shape", ",", "name", ")", ")", "\n", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ".", "astype", "(", "np", ".", "float32", ")", ")", "\n", "tf_weights", ".", "pop", "(", "txt_name", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Weights not copied to PyTorch model: {}\"", ".", "format", "(", "\", \"", ".", "join", "(", "tf_weights", ".", "keys", "(", ")", ")", ")", ")", "\n", "# logger.info(\"Weights not copied to PyTorch model: {}\".format(', '.join(tf_weights.keys())))", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BertTokenizer.__init__": [[133, 188], ["tokenization_utils.PreTrainedTokenizer.__init__", "tokenization_bert.load_vocab", "collections.OrderedDict", "tokenization_bert.WordpieceTokenizer", "os.path.isfile", "ValueError", "tokenization_bert.BasicTokenizer", "tokenization_bert.BertTokenizer.vocab.items"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.load_vocab"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "do_lower_case", "=", "True", ",", "\n", "do_basic_tokenize", "=", "True", ",", "\n", "never_split", "=", "None", ",", "\n", "unk_token", "=", "\"[UNK]\"", ",", "\n", "sep_token", "=", "\"[SEP]\"", ",", "\n", "pad_token", "=", "\"[PAD]\"", ",", "\n", "cls_token", "=", "\"[CLS]\"", ",", "\n", "mask_token", "=", "\"[MASK]\"", ",", "\n", "tokenize_chinese_chars", "=", "True", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs a BertTokenizer.\n\n        Args:\n            **vocab_file**: Path to a one-wordpiece-per-line vocabulary file\n            **do_lower_case**: (`optional`) boolean (default True)\n                Whether to lower case the input\n                Only has an effect when do_basic_tokenize=True\n            **do_basic_tokenize**: (`optional`) boolean (default True)\n                Whether to do basic tokenization before wordpiece.\n            **never_split**: (`optional`) list of string\n                List of tokens which will never be split during tokenization.\n                Only has an effect when do_basic_tokenize=True\n            **tokenize_chinese_chars**: (`optional`) boolean (default True)\n                Whether to tokenize Chinese characters.\n                This should likely be deactivated for Japanese:\n                see: https://github.com/huggingface/pytorch-pretrained-BERT/issues/328\n        \"\"\"", "\n", "super", "(", "BertTokenizer", ",", "self", ")", ".", "__init__", "(", "\n", "unk_token", "=", "unk_token", ",", "\n", "sep_token", "=", "sep_token", ",", "\n", "pad_token", "=", "pad_token", ",", "\n", "cls_token", "=", "cls_token", ",", "\n", "mask_token", "=", "mask_token", ",", "\n", "**", "kwargs", "\n", ")", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "-", "2", "# take into account special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "-", "3", "# take into account special tokens", "\n", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "vocab_file", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Can't find a vocabulary file at path '{}'. To load the vocabulary from a Google pretrained \"", "\n", "\"model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "vocab_file", ")", "\n", ")", "\n", "", "self", ".", "vocab", "=", "load_vocab", "(", "vocab_file", ")", "\n", "self", ".", "ids_to_tokens", "=", "collections", ".", "OrderedDict", "(", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "self", ".", "vocab", ".", "items", "(", ")", "]", ")", "\n", "self", ".", "do_basic_tokenize", "=", "do_basic_tokenize", "\n", "if", "do_basic_tokenize", ":", "\n", "            ", "self", ".", "basic_tokenizer", "=", "BasicTokenizer", "(", "\n", "do_lower_case", "=", "do_lower_case", ",", "never_split", "=", "never_split", ",", "tokenize_chinese_chars", "=", "tokenize_chinese_chars", "\n", ")", "\n", "", "self", ".", "wordpiece_tokenizer", "=", "WordpieceTokenizer", "(", "vocab", "=", "self", ".", "vocab", ",", "unk_token", "=", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BertTokenizer.vocab_size": [[189, 192], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BertTokenizer._tokenize": [[193, 202], ["tokenization_bert.BertTokenizer.basic_tokenizer.tokenize", "tokenization_bert.BertTokenizer.wordpiece_tokenizer.tokenize", "tokenization_bert.BertTokenizer.wordpiece_tokenizer.tokenize", "tokenization_bert.BertTokenizer.append"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "split_tokens", "=", "[", "]", "\n", "if", "self", ".", "do_basic_tokenize", ":", "\n", "            ", "for", "token", "in", "self", ".", "basic_tokenizer", ".", "tokenize", "(", "text", ",", "never_split", "=", "self", ".", "all_special_tokens", ")", ":", "\n", "                ", "for", "sub_token", "in", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", ":", "\n", "                    ", "split_tokens", ".", "append", "(", "sub_token", ")", "\n", "", "", "", "else", ":", "\n", "            ", "split_tokens", "=", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "text", ")", "\n", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BertTokenizer._convert_token_to_id": [[203, 206], ["tokenization_bert.BertTokenizer.vocab.get", "tokenization_bert.BertTokenizer.vocab.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "vocab", ".", "get", "(", "token", ",", "self", ".", "vocab", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BertTokenizer._convert_id_to_token": [[207, 210], ["tokenization_bert.BertTokenizer.ids_to_tokens.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"", "\n", "return", "self", ".", "ids_to_tokens", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BertTokenizer.convert_tokens_to_string": [[211, 215], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "\" \"", ".", "join", "(", "tokens", ")", ".", "replace", "(", "\" ##\"", ",", "\"\"", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BertTokenizer.build_inputs_with_special_tokens": [[216, 229], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n        by concatenating and adding special tokens.\n        A BERT sequence has the following format:\n            single sequence: [CLS] X [SEP]\n            pair of sequences: [CLS] A [SEP] B [SEP]\n        \"\"\"", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "[", "self", ".", "cls_token_id", "]", "+", "token_ids_0", "+", "[", "self", ".", "sep_token_id", "]", "\n", "", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "return", "cls", "+", "token_ids_0", "+", "sep", "+", "token_ids_1", "+", "sep", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BertTokenizer.get_special_tokens_mask": [[230, 257], ["list", "ValueError", "map", "len", "len", "len"], "methods", ["None"], ["", "def", "get_special_tokens_mask", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ",", "already_has_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n\n        Args:\n            token_ids_0: list of ids (must not contain special tokens)\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n                for sequence pairs\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n                special tokens for the model\n\n        Returns:\n            A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.\n        \"\"\"", "\n", "\n", "if", "already_has_special_tokens", ":", "\n", "            ", "if", "token_ids_1", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"You should not supply a second sequence if the provided sequence of \"", "\n", "\"ids is already formated with special tokens for the model.\"", "\n", ")", "\n", "", "return", "list", "(", "map", "(", "lambda", "x", ":", "1", "if", "x", "in", "[", "self", ".", "sep_token_id", ",", "self", ".", "cls_token_id", "]", "else", "0", ",", "token_ids_0", ")", ")", "\n", "\n", "", "if", "token_ids_1", "is", "not", "None", ":", "\n", "            ", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_1", ")", ")", "+", "[", "1", "]", "\n", "", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BertTokenizer.create_token_type_ids_from_sequences": [[258, 272], ["len", "len", "len"], "methods", ["None"], ["", "def", "create_token_type_ids_from_sequences", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n        A BERT sequence pair mask has the following format:\n        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n        | first sequence    | second sequence\n\n        if token_ids_1 is None, only returns the first portion of the mask (0's).\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "\n", "", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "+", "len", "(", "token_ids_1", "+", "sep", ")", "*", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BertTokenizer.save_vocabulary": [[273, 291], ["os.path.isdir", "os.path.join", "open", "sorted", "tokenization_bert.BertTokenizer.vocab.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "vocab_path", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary to a directory or file.\"\"\"", "\n", "index", "=", "0", "\n", "if", "os", ".", "path", ".", "isdir", "(", "vocab_path", ")", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "vocab_path", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "vocab_file", "=", "vocab_path", "\n", "", "with", "open", "(", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "for", "token", ",", "token_index", "in", "sorted", "(", "self", ".", "vocab", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"Saving vocabulary to {}: vocabulary indices are not consecutive.\"", "\n", "\" Please check that the vocabulary is not corrupted!\"", ".", "format", "(", "vocab_file", ")", "\n", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "token", "+", "\"\\n\"", ")", "\n", "index", "+=", "1", "\n", "", "", "return", "(", "vocab_file", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BasicTokenizer.__init__": [[296, 315], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "do_lower_case", "=", "True", ",", "never_split", "=", "None", ",", "tokenize_chinese_chars", "=", "True", ")", ":", "\n", "        ", "\"\"\" Constructs a BasicTokenizer.\n\n        Args:\n            **do_lower_case**: Whether to lower case the input.\n            **never_split**: (`optional`) list of str\n                Kept for backward compatibility purposes.\n                Now implemented directly at the base class level (see :func:`PreTrainedTokenizer.tokenize`)\n                List of token not to split.\n            **tokenize_chinese_chars**: (`optional`) boolean (default True)\n                Whether to tokenize Chinese characters.\n                This should likely be deactivated for Japanese:\n                see: https://github.com/huggingface/pytorch-pretrained-BERT/issues/328\n        \"\"\"", "\n", "if", "never_split", "is", "None", ":", "\n", "            ", "never_split", "=", "[", "]", "\n", "", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "self", ".", "never_split", "=", "never_split", "\n", "self", ".", "tokenize_chinese_chars", "=", "tokenize_chinese_chars", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BasicTokenizer.tokenize": [[316, 346], ["tokenization_bert.BasicTokenizer._clean_text", "tokenization_bert.whitespace_tokenize", "tokenization_bert.whitespace_tokenize", "tokenization_bert.BasicTokenizer._tokenize_chinese_chars", "split_tokens.extend", "tokenization_bert.BasicTokenizer.lower", "tokenization_bert.BasicTokenizer._run_strip_accents", "tokenization_bert.BasicTokenizer._run_split_on_punc"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BasicTokenizer._clean_text", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.whitespace_tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.whitespace_tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BasicTokenizer._tokenize_chinese_chars", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BasicTokenizer._run_strip_accents", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BasicTokenizer._run_split_on_punc"], ["", "def", "tokenize", "(", "self", ",", "text", ",", "never_split", "=", "None", ")", ":", "\n", "        ", "\"\"\" Basic Tokenization of a piece of text.\n            Split on \"white spaces\" only, for sub-word tokenization, see WordPieceTokenizer.\n\n        Args:\n            **never_split**: (`optional`) list of str\n                Kept for backward compatibility purposes.\n                Now implemented directly at the base class level (see :func:`PreTrainedTokenizer.tokenize`)\n                List of token not to split.\n        \"\"\"", "\n", "never_split", "=", "self", ".", "never_split", "+", "(", "never_split", "if", "never_split", "is", "not", "None", "else", "[", "]", ")", "\n", "text", "=", "self", ".", "_clean_text", "(", "text", ")", "\n", "# This was added on November 1st, 2018 for the multilingual and Chinese", "\n", "# models. This is also applied to the English models now, but it doesn't", "\n", "# matter since the English models were not trained on any Chinese data", "\n", "# and generally don't have any Chinese data in them (there are Chinese", "\n", "# characters in the vocabulary because Wikipedia does have some Chinese", "\n", "# words in the English Wikipedia.).", "\n", "if", "self", ".", "tokenize_chinese_chars", ":", "\n", "            ", "text", "=", "self", ".", "_tokenize_chinese_chars", "(", "text", ")", "\n", "", "orig_tokens", "=", "whitespace_tokenize", "(", "text", ")", "\n", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "orig_tokens", ":", "\n", "            ", "if", "self", ".", "do_lower_case", "and", "token", "not", "in", "never_split", ":", "\n", "                ", "token", "=", "token", ".", "lower", "(", ")", "\n", "token", "=", "self", ".", "_run_strip_accents", "(", "token", ")", "\n", "", "split_tokens", ".", "extend", "(", "self", ".", "_run_split_on_punc", "(", "token", ")", ")", "\n", "\n", "", "output_tokens", "=", "whitespace_tokenize", "(", "\" \"", ".", "join", "(", "split_tokens", ")", ")", "\n", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BasicTokenizer._run_strip_accents": [[347, 357], ["unicodedata.normalize", "unicodedata.category", "output.append"], "methods", ["None"], ["", "def", "_run_strip_accents", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Strips accents from a piece of text.\"\"\"", "\n", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFD\"", ",", "text", ")", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Mn\"", ":", "\n", "                ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BasicTokenizer._run_split_on_punc": [[358, 379], ["list", "len", "tokenization_bert._is_punctuation", "output.append", "output[].append", "output.append"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_punctuation"], ["", "def", "_run_split_on_punc", "(", "self", ",", "text", ",", "never_split", "=", "None", ")", ":", "\n", "        ", "\"\"\"Splits punctuation on a piece of text.\"\"\"", "\n", "if", "never_split", "is", "not", "None", "and", "text", "in", "never_split", ":", "\n", "            ", "return", "[", "text", "]", "\n", "", "chars", "=", "list", "(", "text", ")", "\n", "i", "=", "0", "\n", "start_new_word", "=", "True", "\n", "output", "=", "[", "]", "\n", "while", "i", "<", "len", "(", "chars", ")", ":", "\n", "            ", "char", "=", "chars", "[", "i", "]", "\n", "if", "_is_punctuation", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "[", "char", "]", ")", "\n", "start_new_word", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "start_new_word", ":", "\n", "                    ", "output", ".", "append", "(", "[", "]", ")", "\n", "", "start_new_word", "=", "False", "\n", "output", "[", "-", "1", "]", ".", "append", "(", "char", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "return", "[", "\"\"", ".", "join", "(", "x", ")", "for", "x", "in", "output", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BasicTokenizer._tokenize_chinese_chars": [[380, 392], ["ord", "tokenization_bert.BasicTokenizer._is_chinese_char", "output.append", "output.append", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BasicTokenizer._is_chinese_char"], ["", "def", "_tokenize_chinese_chars", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Adds whitespace around any CJK character.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "self", ".", "_is_chinese_char", "(", "cp", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "output", ".", "append", "(", "char", ")", "\n", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BasicTokenizer._is_chinese_char": [[393, 416], ["None"], "methods", ["None"], ["", "def", "_is_chinese_char", "(", "self", ",", "cp", ")", ":", "\n", "        ", "\"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"", "\n", "# This defines a \"chinese character\" as anything in the CJK Unicode block:", "\n", "#   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)", "\n", "#", "\n", "# Note that the CJK Unicode block is NOT all Japanese and Korean characters,", "\n", "# despite its name. The modern Korean Hangul alphabet is a different block,", "\n", "# as is Japanese Hiragana and Katakana. Those alphabets are used to write", "\n", "# space-separated words, so they are not treated specially and handled", "\n", "# like the all of the other languages.", "\n", "if", "(", "\n", "(", "cp", ">=", "0x4E00", "and", "cp", "<=", "0x9FFF", ")", "\n", "or", "(", "cp", ">=", "0x3400", "and", "cp", "<=", "0x4DBF", ")", "#", "\n", "or", "(", "cp", ">=", "0x20000", "and", "cp", "<=", "0x2A6DF", ")", "#", "\n", "or", "(", "cp", ">=", "0x2A700", "and", "cp", "<=", "0x2B73F", ")", "#", "\n", "or", "(", "cp", ">=", "0x2B740", "and", "cp", "<=", "0x2B81F", ")", "#", "\n", "or", "(", "cp", ">=", "0x2B820", "and", "cp", "<=", "0x2CEAF", ")", "#", "\n", "or", "(", "cp", ">=", "0xF900", "and", "cp", "<=", "0xFAFF", ")", "\n", "or", "(", "cp", ">=", "0x2F800", "and", "cp", "<=", "0x2FA1F", ")", "#", "\n", ")", ":", "#", "\n", "            ", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.BasicTokenizer._clean_text": [[417, 429], ["ord", "tokenization_bert._is_whitespace", "tokenization_bert._is_control", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad._is_whitespace", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_control"], ["", "def", "_clean_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "cp", "==", "0", "or", "cp", "==", "0xFFFD", "or", "_is_control", "(", "char", ")", ":", "\n", "                ", "continue", "\n", "", "if", "_is_whitespace", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.WordpieceTokenizer.__init__": [[434, 438], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab", ",", "unk_token", ",", "max_input_chars_per_word", "=", "100", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "unk_token", "=", "unk_token", "\n", "self", ".", "max_input_chars_per_word", "=", "max_input_chars_per_word", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.WordpieceTokenizer.tokenize": [[439, 489], ["tokenization_bert.whitespace_tokenize", "list", "len", "output_tokens.append", "len", "len", "sub_tokens.append", "output_tokens.append", "output_tokens.extend"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.whitespace_tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text into its word pieces.\n\n        This uses a greedy longest-match-first algorithm to perform tokenization\n        using the given vocabulary.\n\n        For example:\n          input = \"unaffable\"\n          output = [\"un\", \"##aff\", \"##able\"]\n\n        Args:\n          text: A single token or whitespace separated tokens. This should have\n            already been passed through `BasicTokenizer`.\n\n        Returns:\n          A list of wordpiece tokens.\n        \"\"\"", "\n", "\n", "output_tokens", "=", "[", "]", "\n", "for", "token", "in", "whitespace_tokenize", "(", "text", ")", ":", "\n", "            ", "chars", "=", "list", "(", "token", ")", "\n", "if", "len", "(", "chars", ")", ">", "self", ".", "max_input_chars_per_word", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "continue", "\n", "\n", "", "is_bad", "=", "False", "\n", "start", "=", "0", "\n", "sub_tokens", "=", "[", "]", "\n", "while", "start", "<", "len", "(", "chars", ")", ":", "\n", "                ", "end", "=", "len", "(", "chars", ")", "\n", "cur_substr", "=", "None", "\n", "while", "start", "<", "end", ":", "\n", "                    ", "substr", "=", "\"\"", ".", "join", "(", "chars", "[", "start", ":", "end", "]", ")", "\n", "if", "start", ">", "0", ":", "\n", "                        ", "substr", "=", "\"##\"", "+", "substr", "\n", "", "if", "substr", "in", "self", ".", "vocab", ":", "\n", "                        ", "cur_substr", "=", "substr", "\n", "break", "\n", "", "end", "-=", "1", "\n", "", "if", "cur_substr", "is", "None", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "sub_tokens", ".", "append", "(", "cur_substr", ")", "\n", "start", "=", "end", "\n", "\n", "", "if", "is_bad", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "", "else", ":", "\n", "                ", "output_tokens", ".", "extend", "(", "sub_tokens", ")", "\n", "", "", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.load_vocab": [[93, 102], ["collections.OrderedDict", "enumerate", "open", "reader.readlines", "token.rstrip.rstrip"], "function", ["None"], ["def", "load_vocab", "(", "vocab_file", ")", ":", "\n", "    ", "\"\"\"Loads a vocabulary file into a dictionary.\"\"\"", "\n", "vocab", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "with", "open", "(", "vocab_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "        ", "tokens", "=", "reader", ".", "readlines", "(", ")", "\n", "", "for", "index", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "        ", "token", "=", "token", ".", "rstrip", "(", "\"\\n\"", ")", "\n", "vocab", "[", "token", "]", "=", "index", "\n", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.whitespace_tokenize": [[104, 111], ["text.strip.strip", "text.strip.split"], "function", ["None"], ["", "def", "whitespace_tokenize", "(", "text", ")", ":", "\n", "    ", "\"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "        ", "return", "[", "]", "\n", "", "tokens", "=", "text", ".", "split", "(", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_whitespace": [[491, 501], ["unicodedata.category"], "function", ["None"], ["", "", "def", "_is_whitespace", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a whitespace character.\"\"\"", "\n", "# \\t, \\n, and \\r are technically contorl characters but we treat them", "\n", "# as whitespace since they are generally considered as such.", "\n", "if", "char", "==", "\" \"", "or", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Zs\"", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_control": [[503, 513], ["unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_control", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a control character.\"\"\"", "\n", "# These are technically control characters but we count them as whitespace", "\n", "# characters.", "\n", "if", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "False", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"C\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_punctuation": [[515, 528], ["ord", "unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_punctuation", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a punctuation character.\"\"\"", "\n", "cp", "=", "ord", "(", "char", ")", "\n", "# We treat all non-letter/number ASCII as punctuation.", "\n", "# Characters such as \"^\", \"$\", and \"`\" are not in the Unicode", "\n", "# Punctuation class but we treat them as punctuation anyways, for", "\n", "# consistency.", "\n", "if", "(", "cp", ">=", "33", "and", "cp", "<=", "47", ")", "or", "(", "cp", ">=", "58", "and", "cp", "<=", "64", ")", "or", "(", "cp", ">=", "91", "and", "cp", "<=", "96", ")", "or", "(", "cp", ">=", "123", "and", "cp", "<=", "126", ")", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"P\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.__init__": [[31, 71], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "len", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "range", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_layers.append", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "len", "torch.Linear", "torch.Linear", "torch.Linear", "len", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_projs.append", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_layers.append", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_projs.append", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.out_projs.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_token", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "1", ",", "keep_order", "=", "False", ")", ":", "\n", "        ", "super", "(", "ProjectedAdaptiveLogSoftmax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_token", "=", "n_token", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_token", "]", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "self", ".", "div_val", "=", "div_val", "\n", "\n", "self", ".", "shortlist_size", "=", "self", ".", "cutoffs", "[", "0", "]", "\n", "self", ".", "n_clusters", "=", "len", "(", "self", ".", "cutoffs", ")", "-", "1", "\n", "self", ".", "head_size", "=", "self", ".", "shortlist_size", "+", "self", ".", "n_clusters", "\n", "\n", "if", "self", ".", "n_clusters", ">", "0", ":", "\n", "            ", "self", ".", "cluster_weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "n_clusters", ",", "self", ".", "d_embed", ")", ")", "\n", "self", ".", "cluster_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "n_clusters", ")", ")", "\n", "\n", "", "self", ".", "out_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "out_projs", "=", "nn", ".", "ParameterList", "(", ")", "\n", "\n", "if", "div_val", "==", "1", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "d_proj", "!=", "d_embed", ":", "\n", "                    ", "self", ".", "out_projs", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "d_proj", ",", "d_embed", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "out_projs", ".", "append", "(", "None", ")", "\n", "\n", "", "", "self", ".", "out_layers", ".", "append", "(", "nn", ".", "Linear", "(", "d_embed", ",", "n_token", ")", ")", "\n", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "\n", "self", ".", "out_projs", ".", "append", "(", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "d_proj", ",", "d_emb_i", ")", ")", ")", "\n", "\n", "self", ".", "out_layers", ".", "append", "(", "nn", ".", "Linear", "(", "d_emb_i", ",", "r_idx", "-", "l_idx", ")", ")", "\n", "\n", "", "", "self", ".", "keep_order", "=", "keep_order", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit": [[72, 85], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "proj.t().contiguous", "proj.t"], "methods", ["None"], ["", "def", "_compute_logit", "(", "self", ",", "hidden", ",", "weight", ",", "bias", ",", "proj", ")", ":", "\n", "        ", "if", "proj", "is", "None", ":", "\n", "            ", "logit", "=", "F", ".", "linear", "(", "hidden", ",", "weight", ",", "bias", "=", "bias", ")", "\n", "", "else", ":", "\n", "# if CUDA_MAJOR <= 9 and CUDA_MINOR <= 1:", "\n", "            ", "proj_hid", "=", "F", ".", "linear", "(", "hidden", ",", "proj", ".", "t", "(", ")", ".", "contiguous", "(", ")", ")", "\n", "logit", "=", "F", ".", "linear", "(", "proj_hid", ",", "weight", ",", "bias", "=", "bias", ")", "\n", "# else:", "\n", "#     logit = torch.einsum('bd,de,ev->bv', (hidden, proj, weight.t()))", "\n", "#     if bias is not None:", "\n", "#         logit = logit + bias", "\n", "\n", "", "return", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.forward": [[86, 186], ["labels.view.view.view", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "range", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "range", "hidden.size", "labels.view.view.size", "RuntimeError", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "len", "weights.append", "biases.append", "hidden.new_empty", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.log_softmax().gather().squeeze", "torch.log_softmax().gather().squeeze", "torch.log_softmax().gather().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "mask_i.nonzero().squeeze", "torch.log_softmax.index_select", "hidden.index_select", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "head_logprob.index_select.gather().squeeze.size", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.size", "mask_i.nonzero().squeeze.numel", "labels.view.view.index_select", "F.log_softmax.index_select.gather().squeeze", "torch.zeros_like.index_copy_", "torch.zeros_like.index_copy_", "torch.zeros_like.index_copy_", "out[].copy_", "torch.log_softmax().gather", "torch.log_softmax().gather", "torch.log_softmax().gather", "mask_i.nonzero", "torch.log_softmax.gather().squeeze", "hasattr", "labels.view.view.unsqueeze", "F.log_softmax.index_select.gather", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax.gather", "head_logprob.index_select.gather().squeeze.size"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit"], ["", "def", "forward", "(", "self", ",", "hidden", ",", "labels", "=", "None", ",", "keep_order", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            Params:\n                hidden :: [len*bsz x d_proj]\n                labels :: [len*bsz]\n            Return:\n                if labels is None:\n                    out :: [len*bsz] Negative log likelihood\n                else:\n                    out :: [len*bsz x n_tokens] log probabilities of tokens over the vocabulary\n            We could replace this implementation by the native PyTorch one\n            if their's had an option to set bias on all clusters in the native one.\n            here: https://github.com/pytorch/pytorch/blob/dbe6a7a9ff1a364a8706bf5df58a1ca96d2fd9da/torch/nn/modules/adaptive.py#L138\n        \"\"\"", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "labels", "=", "labels", ".", "view", "(", "-", "1", ")", "\n", "if", "hidden", ".", "size", "(", "0", ")", "!=", "labels", ".", "size", "(", "0", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Input and labels should have the same size \"", "\"in the batch dimension.\"", ")", "\n", "\n", "", "", "if", "self", ".", "n_clusters", "==", "0", ":", "\n", "            ", "logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "self", ".", "out_layers", "[", "0", "]", ".", "weight", ",", "self", ".", "out_layers", "[", "0", "]", ".", "bias", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "if", "labels", "is", "not", "None", ":", "\n", "                ", "out", "=", "-", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", ".", "gather", "(", "1", ",", "labels", ".", "unsqueeze", "(", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", "\n", "", "", "else", ":", "\n", "# construct weights and biases", "\n", "            ", "weights", ",", "biases", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "                    ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "weight_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "weight", "[", "l_idx", ":", "r_idx", "]", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "bias", "[", "l_idx", ":", "r_idx", "]", "\n", "", "else", ":", "\n", "                    ", "weight_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "weight", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "bias", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "weight_i", "=", "torch", ".", "cat", "(", "[", "weight_i", ",", "self", ".", "cluster_weight", "]", ",", "dim", "=", "0", ")", "\n", "bias_i", "=", "torch", ".", "cat", "(", "[", "bias_i", ",", "self", ".", "cluster_bias", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "weights", ".", "append", "(", "weight_i", ")", "\n", "biases", ".", "append", "(", "bias_i", ")", "\n", "\n", "", "head_weight", ",", "head_bias", ",", "head_proj", "=", "weights", "[", "0", "]", ",", "biases", "[", "0", "]", ",", "self", ".", "out_projs", "[", "0", "]", "\n", "\n", "head_logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "head_weight", ",", "head_bias", ",", "head_proj", ")", "\n", "head_logprob", "=", "F", ".", "log_softmax", "(", "head_logit", ",", "dim", "=", "1", ")", "\n", "\n", "if", "labels", "is", "None", ":", "\n", "                ", "out", "=", "hidden", ".", "new_empty", "(", "(", "head_logit", ".", "size", "(", "0", ")", ",", "self", ".", "n_token", ")", ")", "\n", "", "else", ":", "\n", "                ", "out", "=", "torch", ".", "zeros_like", "(", "labels", ",", "dtype", "=", "hidden", ".", "dtype", ",", "device", "=", "hidden", ".", "device", ")", "\n", "\n", "", "offset", "=", "0", "\n", "cutoff_values", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "for", "i", "in", "range", "(", "len", "(", "cutoff_values", ")", "-", "1", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "cutoff_values", "[", "i", "]", ",", "cutoff_values", "[", "i", "+", "1", "]", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "                    ", "mask_i", "=", "(", "labels", ">=", "l_idx", ")", "&", "(", "labels", "<", "r_idx", ")", "\n", "indices_i", "=", "mask_i", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "\n", "if", "indices_i", ".", "numel", "(", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "\n", "", "target_i", "=", "labels", ".", "index_select", "(", "0", ",", "indices_i", ")", "-", "l_idx", "\n", "head_logprob_i", "=", "head_logprob", ".", "index_select", "(", "0", ",", "indices_i", ")", "\n", "hidden_i", "=", "hidden", ".", "index_select", "(", "0", ",", "indices_i", ")", "\n", "", "else", ":", "\n", "                    ", "hidden_i", "=", "hidden", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "if", "labels", "is", "not", "None", ":", "\n", "                        ", "logprob_i", "=", "head_logprob_i", ".", "gather", "(", "1", ",", "target_i", "[", ":", ",", "None", "]", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "out", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "=", "head_logprob", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "\n", "", "", "else", ":", "\n", "                    ", "weight_i", ",", "bias_i", ",", "proj_i", "=", "weights", "[", "i", "]", ",", "biases", "[", "i", "]", ",", "self", ".", "out_projs", "[", "i", "]", "\n", "\n", "tail_logit_i", "=", "self", ".", "_compute_logit", "(", "hidden_i", ",", "weight_i", ",", "bias_i", ",", "proj_i", ")", "\n", "tail_logprob_i", "=", "F", ".", "log_softmax", "(", "tail_logit_i", ",", "dim", "=", "1", ")", "\n", "cluster_prob_idx", "=", "self", ".", "cutoffs", "[", "0", "]", "+", "i", "-", "1", "# No probability for the head cluster", "\n", "if", "labels", "is", "not", "None", ":", "\n", "                        ", "logprob_i", "=", "head_logprob_i", "[", ":", ",", "cluster_prob_idx", "]", "+", "tail_logprob_i", ".", "gather", "(", "\n", "1", ",", "target_i", "[", ":", ",", "None", "]", "\n", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "logprob_i", "=", "head_logprob", "[", ":", ",", "cluster_prob_idx", ",", "None", "]", "+", "tail_logprob_i", "\n", "out", "[", ":", ",", "l_idx", ":", "r_idx", "]", "=", "logprob_i", "\n", "\n", "", "", "if", "labels", "is", "not", "None", ":", "\n", "                    ", "if", "(", "hasattr", "(", "self", ",", "\"keep_order\"", ")", "and", "self", ".", "keep_order", ")", "or", "keep_order", ":", "\n", "                        ", "out", ".", "index_copy_", "(", "0", ",", "indices_i", ",", "-", "logprob_i", ")", "\n", "", "else", ":", "\n", "                        ", "out", "[", "offset", ":", "offset", "+", "logprob_i", ".", "size", "(", "0", ")", "]", ".", "copy_", "(", "-", "logprob_i", ")", "\n", "", "offset", "+=", "logprob_i", ".", "size", "(", "0", ")", "\n", "\n", "", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.log_prob": [[187, 244], ["modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "range", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "hidden.new_empty", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "range", "len", "weights.append", "biases.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.size", "len", "modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax._compute_logit"], ["", "def", "log_prob", "(", "self", ",", "hidden", ")", ":", "\n", "        ", "r\"\"\" Computes log probabilities for all :math:`n\\_classes`\n        From: https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/adaptive.py\n        Args:\n            hidden (Tensor): a minibatch of examples\n        Returns:\n            log-probabilities of for each class :math:`c`\n            in range :math:`0 <= c <= n\\_classes`, where :math:`n\\_classes` is a\n            parameter passed to ``AdaptiveLogSoftmaxWithLoss`` constructor.\n        Shape:\n            - Input: :math:`(N, in\\_features)`\n            - Output: :math:`(N, n\\_classes)`\n        \"\"\"", "\n", "if", "self", ".", "n_clusters", "==", "0", ":", "\n", "            ", "logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "self", ".", "out_layers", "[", "0", "]", ".", "weight", ",", "self", ".", "out_layers", "[", "0", "]", ".", "bias", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "return", "F", ".", "log_softmax", "(", "logit", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "# construct weights and biases", "\n", "            ", "weights", ",", "biases", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "self", ".", "div_val", "==", "1", ":", "\n", "                    ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "weight_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "weight", "[", "l_idx", ":", "r_idx", "]", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "0", "]", ".", "bias", "[", "l_idx", ":", "r_idx", "]", "\n", "", "else", ":", "\n", "                    ", "weight_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "weight", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "bias", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "weight_i", "=", "torch", ".", "cat", "(", "[", "weight_i", ",", "self", ".", "cluster_weight", "]", ",", "dim", "=", "0", ")", "\n", "bias_i", "=", "torch", ".", "cat", "(", "[", "bias_i", ",", "self", ".", "cluster_bias", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "weights", ".", "append", "(", "weight_i", ")", "\n", "biases", ".", "append", "(", "bias_i", ")", "\n", "\n", "", "head_weight", ",", "head_bias", ",", "head_proj", "=", "weights", "[", "0", "]", ",", "biases", "[", "0", "]", ",", "self", ".", "out_projs", "[", "0", "]", "\n", "head_logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "head_weight", ",", "head_bias", ",", "head_proj", ")", "\n", "\n", "out", "=", "hidden", ".", "new_empty", "(", "(", "head_logit", ".", "size", "(", "0", ")", ",", "self", ".", "n_token", ")", ")", "\n", "head_logprob", "=", "F", ".", "log_softmax", "(", "head_logit", ",", "dim", "=", "1", ")", "\n", "\n", "cutoff_values", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "for", "i", "in", "range", "(", "len", "(", "cutoff_values", ")", "-", "1", ")", ":", "\n", "                ", "start_idx", ",", "stop_idx", "=", "cutoff_values", "[", "i", "]", ",", "cutoff_values", "[", "i", "+", "1", "]", "\n", "\n", "if", "i", "==", "0", ":", "\n", "                    ", "out", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "=", "head_logprob", "[", ":", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "                    ", "weight_i", ",", "bias_i", ",", "proj_i", "=", "weights", "[", "i", "]", ",", "biases", "[", "i", "]", ",", "self", ".", "out_projs", "[", "i", "]", "\n", "\n", "tail_logit_i", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "weight_i", ",", "bias_i", ",", "proj_i", ")", "\n", "tail_logprob_i", "=", "F", ".", "log_softmax", "(", "tail_logit_i", ",", "dim", "=", "1", ")", "\n", "\n", "logprob_i", "=", "head_logprob", "[", ":", ",", "-", "i", "]", "+", "tail_logprob_i", "\n", "out", "[", ":", ",", "start_idx", ",", "stop_idx", "]", "=", "logprob_i", "\n", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.LogUniformSampler.__init__": [[247, 265], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange().log_", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "modeling_transfo_xl_utilities.LogUniformSampler.dist.double().log1p_", "modeling_transfo_xl_utilities.LogUniformSampler.dist.double"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "range_max", ",", "n_sample", ")", ":", "\n", "        ", "\"\"\"\n        Reference : https://github.com/tensorflow/tensorflow/blob/r1.10/tensorflow/python/ops/candidate_sampling_ops.py\n            `P(class) = (log(class + 2) - log(class + 1)) / log(range_max + 1)`\n\n        expected count can be approximated by 1 - (1 - p)^n\n        and we use a numerically stable version -expm1(num_tries * log1p(-p))\n\n        Our implementation fixes num_tries at 2 * n_sample, and the actual #samples will vary from run to run\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "range_max", "=", "range_max", "\n", "log_indices", "=", "torch", ".", "arange", "(", "1.0", ",", "range_max", "+", "2.0", ",", "1.0", ")", ".", "log_", "(", ")", "\n", "self", ".", "dist", "=", "(", "log_indices", "[", "1", ":", "]", "-", "log_indices", "[", ":", "-", "1", "]", ")", "/", "log_indices", "[", "-", "1", "]", "\n", "\n", "self", ".", "log_q", "=", "(", "-", "(", "-", "self", ".", "dist", ".", "double", "(", ")", ".", "log1p_", "(", ")", "*", "2", "*", "n_sample", ")", ".", "expm1_", "(", ")", ")", ".", "log_", "(", ")", ".", "float", "(", ")", "\n", "\n", "", "self", ".", "n_sample", "=", "n_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.LogUniformSampler.sample": [[266, 286], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "torch.multinomial().unique", "neg_samples.to.to.to", "modeling_transfo_xl_utilities.LogUniformSampler.log_q[].to", "modeling_transfo_xl_utilities.LogUniformSampler.log_q[].to", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "labels", ")", ":", "\n", "        ", "\"\"\"\n            labels: [b1, b2]\n        Return\n            true_log_probs: [b1, b2]\n            samp_log_probs: [n_sample]\n            neg_samples: [n_sample]\n        \"\"\"", "\n", "\n", "# neg_samples = torch.empty(0).long()", "\n", "n_sample", "=", "self", ".", "n_sample", "\n", "n_tries", "=", "2", "*", "n_sample", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "neg_samples", "=", "torch", ".", "multinomial", "(", "self", ".", "dist", ",", "n_tries", ",", "replacement", "=", "True", ")", ".", "unique", "(", ")", "\n", "device", "=", "labels", ".", "device", "\n", "neg_samples", "=", "neg_samples", ".", "to", "(", "device", ")", "\n", "true_log_probs", "=", "self", ".", "log_q", "[", "labels", "]", ".", "to", "(", "device", ")", "\n", "samp_log_probs", "=", "self", ".", "log_q", "[", "neg_samples", "]", ".", "to", "(", "device", ")", "\n", "return", "true_log_probs", ",", "samp_log_probs", ",", "neg_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.sample_logits": [[288, 318], ["sampler.sample", "neg_samples.size", "torch.cat", "torch.cat", "torch.cat", "embedding", "all_w[].view", "all_w[].view", "all_b[].view", "sample_logits.masked_fill_", "torch.cat", "torch.cat", "torch.cat", "labels.size", "labels.size", "labels.view", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.LogUniformSampler.sample"], ["", "", "", "def", "sample_logits", "(", "embedding", ",", "bias", ",", "labels", ",", "inputs", ",", "sampler", ")", ":", "\n", "    ", "\"\"\"\n        embedding: an nn.Embedding layer\n        bias: [n_vocab]\n        labels: [b1, b2]\n        inputs: [b1, b2, n_emb]\n        sampler: you may use a LogUniformSampler\n    Return\n        logits: [b1, b2, 1 + n_sample]\n    \"\"\"", "\n", "true_log_probs", ",", "samp_log_probs", ",", "neg_samples", "=", "sampler", ".", "sample", "(", "labels", ")", "\n", "n_sample", "=", "neg_samples", ".", "size", "(", "0", ")", "\n", "b1", ",", "b2", "=", "labels", ".", "size", "(", "0", ")", ",", "labels", ".", "size", "(", "1", ")", "\n", "all_ids", "=", "torch", ".", "cat", "(", "[", "labels", ".", "view", "(", "-", "1", ")", ",", "neg_samples", "]", ")", "\n", "all_w", "=", "embedding", "(", "all_ids", ")", "\n", "true_w", "=", "all_w", "[", ":", "-", "n_sample", "]", ".", "view", "(", "b1", ",", "b2", ",", "-", "1", ")", "\n", "sample_w", "=", "all_w", "[", "-", "n_sample", ":", "]", ".", "view", "(", "n_sample", ",", "-", "1", ")", "\n", "\n", "all_b", "=", "bias", "[", "all_ids", "]", "\n", "true_b", "=", "all_b", "[", ":", "-", "n_sample", "]", ".", "view", "(", "b1", ",", "b2", ")", "\n", "sample_b", "=", "all_b", "[", "-", "n_sample", ":", "]", "\n", "\n", "hit", "=", "(", "labels", "[", ":", ",", ":", ",", "None", "]", "==", "neg_samples", ")", ".", "detach", "(", ")", "\n", "\n", "true_logits", "=", "torch", ".", "einsum", "(", "\"ijk,ijk->ij\"", ",", "[", "true_w", ",", "inputs", "]", ")", "+", "true_b", "-", "true_log_probs", "\n", "sample_logits", "=", "torch", ".", "einsum", "(", "\"lk,ijk->ijl\"", ",", "[", "sample_w", ",", "inputs", "]", ")", "+", "sample_b", "-", "samp_log_probs", "\n", "sample_logits", ".", "masked_fill_", "(", "hit", ",", "-", "1e30", ")", "\n", "logits", "=", "torch", ".", "cat", "(", "[", "true_logits", "[", ":", ",", ":", ",", "None", "]", ",", "sample_logits", "]", ",", "-", "1", ")", "\n", "\n", "return", "logits", "\n", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_torch_available": [[96, 98], ["None"], "function", ["None"], ["def", "is_torch_available", "(", ")", ":", "\n", "    ", "return", "_torch_available", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_tf_available": [[100, 103], ["None"], "function", ["None"], ["", "def", "is_tf_available", "(", ")", ":", "\n", "\n", "    ", "return", "_tf_available", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.add_start_docstrings": [[105, 111], ["None"], "function", ["None"], ["", "def", "add_start_docstrings", "(", "*", "docstr", ")", ":", "\n", "    ", "def", "docstring_decorator", "(", "fn", ")", ":", "\n", "        ", "fn", ".", "__doc__", "=", "\"\"", ".", "join", "(", "docstr", ")", "+", "fn", ".", "__doc__", "\n", "return", "fn", "\n", "\n", "", "return", "docstring_decorator", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.add_end_docstrings": [[113, 119], ["None"], "function", ["None"], ["", "def", "add_end_docstrings", "(", "*", "docstr", ")", ":", "\n", "    ", "def", "docstring_decorator", "(", "fn", ")", ":", "\n", "        ", "fn", ".", "__doc__", "=", "fn", ".", "__doc__", "+", "\"\"", ".", "join", "(", "docstr", ")", "\n", "return", "fn", "\n", "\n", "", "return", "docstring_decorator", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_remote_url": [[121, 124], ["urllib.parse.urlparse"], "function", ["None"], ["", "def", "is_remote_url", "(", "url_or_filename", ")", ":", "\n", "    ", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "return", "parsed", ".", "scheme", "in", "(", "\"http\"", ",", "\"https\"", ",", "\"s3\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.hf_bucket_url": [[126, 132], ["None"], "function", ["None"], ["", "def", "hf_bucket_url", "(", "identifier", ",", "postfix", "=", "None", ",", "cdn", "=", "False", ")", ":", "\n", "    ", "endpoint", "=", "CLOUDFRONT_DISTRIB_PREFIX", "if", "cdn", "else", "S3_BUCKET_PREFIX", "\n", "if", "postfix", "is", "None", ":", "\n", "        ", "return", "\"/\"", ".", "join", "(", "(", "endpoint", ",", "identifier", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "\"/\"", ".", "join", "(", "(", "endpoint", ",", "identifier", ",", "postfix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.url_to_filename": [[134, 156], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "url.endswith", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode"], ["", "", "def", "url_to_filename", "(", "url", ",", "etag", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    If the url ends with .h5 (Keras HDF5 weights) adds '.h5' to the name\n    so that TF 2.0 can identify it as a HDF5 file\n    (see https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/keras/engine/network.py#L1380)\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "\"utf-8\"", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "\"utf-8\"", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "\".\"", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "if", "url", ".", "endswith", "(", "\".h5\"", ")", ":", "\n", "        ", "filename", "+=", "\".h5\"", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.filename_to_url": [[158, 182], ["isinstance", "os.path.join", "str", "os.path.exists", "EnvironmentError", "os.path.exists", "EnvironmentError", "open", "json.load"], "function", ["None"], ["", "def", "filename_to_url", "(", "filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``EnvironmentError`` if `filename` or its stored metadata do not exist.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "TRANSFORMERS_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "\".json\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "\"url\"", "]", "\n", "etag", "=", "metadata", "[", "\"etag\"", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.cached_path": [[184, 224], ["isinstance", "isinstance", "file_utils.is_remote_url", "str", "str", "file_utils.get_from_cache", "os.path.exists", "EnvironmentError", "ValueError", "urllib.parse.urlparse"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_remote_url", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.get_from_cache"], ["", "def", "cached_path", "(", "\n", "url_or_filename", ",", "cache_dir", "=", "None", ",", "force_download", "=", "False", ",", "proxies", "=", "None", ",", "resume_download", "=", "False", ",", "user_agent", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    Args:\n        cache_dir: specify a cache directory to save the file to (overwrite the default cache dir).\n        force_download: if True, re-dowload the file even if it's already cached in the cache dir.\n        resume_download: if True, resume the download if incompletly recieved file is found.\n        user_agent: Optional string or dict that will be appended to the user-agent on remote requests.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "TRANSFORMERS_CACHE", "\n", "", "if", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "is_remote_url", "(", "url_or_filename", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "return", "get_from_cache", "(", "\n", "url_or_filename", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "force_download", "=", "force_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", "user_agent", "=", "user_agent", ",", "\n", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "return", "url_or_filename", "\n", "", "elif", "urlparse", "(", "url_or_filename", ")", ".", "scheme", "==", "\"\"", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.split_s3_path": [[226, 237], ["urllib.parse.urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "", "def", "split_s3_path", "(", "url", ")", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.s3_request": [[239, 256], ["functools.wraps", "func", "int", "EnvironmentError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.s3_etag": [[258, 265], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Object", "botocore.config.Config"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ",", "proxies", "=", "None", ")", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ",", "config", "=", "Config", "(", "proxies", "=", "proxies", ")", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.s3_get": [[267, 273], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "botocore.config.Config", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "None", ")", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ",", "config", "=", "Config", "(", "proxies", "=", "proxies", ")", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.http_get": [[275, 302], ["isinstance", "requests.get", "requests.get.headers.get", "tqdm.auto.tqdm", "requests.get.iter_content", "tqdm.auto.tqdm.close", "isinstance", "sys.version.split", "int", "bool", "tqdm.auto.tqdm.update", "temp_file.write", "len", "logger.getEffectiveLevel", "user_agent.items"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.TqdmProgressFileReader.close"], ["", "def", "http_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "None", ",", "resume_size", "=", "0", ",", "user_agent", "=", "None", ")", ":", "\n", "    ", "ua", "=", "\"transformers/{}; python/{}\"", ".", "format", "(", "__version__", ",", "sys", ".", "version", ".", "split", "(", ")", "[", "0", "]", ")", "\n", "if", "isinstance", "(", "user_agent", ",", "dict", ")", ":", "\n", "        ", "ua", "+=", "\"; \"", "+", "\"; \"", ".", "join", "(", "\"{}/{}\"", ".", "format", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "user_agent", ".", "items", "(", ")", ")", "\n", "", "elif", "isinstance", "(", "user_agent", ",", "str", ")", ":", "\n", "        ", "ua", "+=", "\"; \"", "+", "user_agent", "\n", "", "headers", "=", "{", "\"user-agent\"", ":", "ua", "}", "\n", "if", "resume_size", ">", "0", ":", "\n", "        ", "headers", "[", "\"Range\"", "]", "=", "\"bytes=%d-\"", "%", "(", "resume_size", ",", ")", "\n", "", "response", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ",", "proxies", "=", "proxies", ",", "headers", "=", "headers", ")", "\n", "if", "response", ".", "status_code", "==", "416", ":", "# Range not satisfiable", "\n", "        ", "return", "\n", "", "content_length", "=", "response", ".", "headers", ".", "get", "(", "\"Content-Length\"", ")", "\n", "total", "=", "resume_size", "+", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "\n", "unit", "=", "\"B\"", ",", "\n", "unit_scale", "=", "True", ",", "\n", "total", "=", "total", ",", "\n", "initial", "=", "resume_size", ",", "\n", "desc", "=", "\"Downloading\"", ",", "\n", "disable", "=", "bool", "(", "logger", ".", "getEffectiveLevel", "(", ")", "==", "logging", ".", "NOTSET", ")", ",", "\n", ")", "\n", "for", "chunk", "in", "response", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.get_from_cache": [[304, 398], ["isinstance", "url.startswith", "file_utils.url_to_filename", "os.path.join", "str", "os.path.exists", "os.makedirs", "file_utils.s3_etag", "filelock.FileLock", "requests.head", "os.path.exists", "os.path.join", "os.path.exists", "functools.partial", "requests.head.headers.get", "fnmatch.filter", "functools.partial.", "logger.info", "url.startswith", "temp_file.flush", "logger.info", "os.rename", "logger.info", "os.listdir", "open", "os.stat", "os.path.exists", "file_utils.s3_get", "file_utils.http_get", "open", "json.dump", "file.endswith", "file.endswith", "logger.warn"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.url_to_filename", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.s3_etag", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.s3_get", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.http_get"], ["", "def", "get_from_cache", "(", "\n", "url", ",", "cache_dir", "=", "None", ",", "force_download", "=", "False", ",", "proxies", "=", "None", ",", "etag_timeout", "=", "10", ",", "resume_download", "=", "False", ",", "user_agent", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding dataset in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "TRANSFORMERS_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "cache_dir", ")", "\n", "\n", "# Get eTag to add to filename, if it exists.", "\n", "", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "        ", "etag", "=", "s3_etag", "(", "url", ",", "proxies", "=", "proxies", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "response", "=", "requests", ".", "head", "(", "url", ",", "allow_redirects", "=", "True", ",", "proxies", "=", "proxies", ",", "timeout", "=", "etag_timeout", ")", "\n", "if", "response", ".", "status_code", "!=", "200", ":", "\n", "                ", "etag", "=", "None", "\n", "", "else", ":", "\n", "                ", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "", "", "except", "(", "EnvironmentError", ",", "requests", ".", "exceptions", ".", "Timeout", ")", ":", "\n", "            ", "etag", "=", "None", "\n", "\n", "", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "# If we don't have a connection (etag is None) and can't identify the file", "\n", "# try to get the last downloaded one", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", "and", "etag", "is", "None", ":", "\n", "        ", "matching_files", "=", "[", "\n", "file", "\n", "for", "file", "in", "fnmatch", ".", "filter", "(", "os", ".", "listdir", "(", "cache_dir", ")", ",", "filename", "+", "\".*\"", ")", "\n", "if", "not", "file", ".", "endswith", "(", "\".json\"", ")", "and", "not", "file", ".", "endswith", "(", "\".lock\"", ")", "\n", "]", "\n", "if", "matching_files", ":", "\n", "            ", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "matching_files", "[", "-", "1", "]", ")", "\n", "\n", "# Prevent parallel downloads of the same file with a lock.", "\n", "", "", "lock_path", "=", "cache_path", "+", "\".lock\"", "\n", "with", "FileLock", "(", "lock_path", ")", ":", "\n", "\n", "        ", "if", "resume_download", ":", "\n", "            ", "incomplete_path", "=", "cache_path", "+", "\".incomplete\"", "\n", "\n", "@", "contextmanager", "\n", "def", "_resumable_file_manager", "(", ")", ":", "\n", "                ", "with", "open", "(", "incomplete_path", ",", "\"a+b\"", ")", "as", "f", ":", "\n", "                    ", "yield", "f", "\n", "\n", "", "", "temp_file_manager", "=", "_resumable_file_manager", "\n", "if", "os", ".", "path", ".", "exists", "(", "incomplete_path", ")", ":", "\n", "                ", "resume_size", "=", "os", ".", "stat", "(", "incomplete_path", ")", ".", "st_size", "\n", "", "else", ":", "\n", "                ", "resume_size", "=", "0", "\n", "", "", "else", ":", "\n", "            ", "temp_file_manager", "=", "partial", "(", "tempfile", ".", "NamedTemporaryFile", ",", "dir", "=", "cache_dir", ",", "delete", "=", "False", ")", "\n", "resume_size", "=", "0", "\n", "\n", "", "if", "etag", "is", "not", "None", "and", "(", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", "or", "force_download", ")", ":", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "            ", "with", "temp_file_manager", "(", ")", "as", "temp_file", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"%s not found in cache or force_download set to True, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", "\n", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                    ", "if", "resume_download", ":", "\n", "                        ", "logger", ".", "warn", "(", "'Warning: resumable downloads are not implemented for \"s3://\" urls'", ")", "\n", "", "s3_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "proxies", ")", "\n", "", "else", ":", "\n", "                    ", "http_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "proxies", ",", "resume_size", "=", "resume_size", ",", "user_agent", "=", "user_agent", ")", "\n", "\n", "# we are copying the file before closing it, so flush to avoid truncation", "\n", "", "temp_file", ".", "flush", "(", ")", "\n", "\n", "logger", ".", "info", "(", "\"storing %s in cache at %s\"", ",", "url", ",", "cache_path", ")", "\n", "os", ".", "rename", "(", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "\n", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "\"url\"", ":", "url", ",", "\"etag\"", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "\".json\"", "\n", "with", "open", "(", "meta_path", ",", "\"w\"", ")", "as", "meta_file", ":", "\n", "                    ", "json", ".", "dump", "(", "meta", ",", "meta_file", ")", "\n", "\n", "", "", "", "", "return", "cache_path", "\n", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_camembert.CamembertTokenizer.__init__": [[56, 92], ["transformers.tokenization_utils.PreTrainedTokenizer.__init__", "sentencepiece.SentencePieceProcessor", "tokenization_camembert.CamembertTokenizer.sp_model.Load", "len", "str", "len", "len", "tokenization_camembert.CamembertTokenizer.fairseq_tokens_to_ids.items"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "bos_token", "=", "\"<s>\"", ",", "\n", "eos_token", "=", "\"</s>\"", ",", "\n", "sep_token", "=", "\"</s>\"", ",", "\n", "cls_token", "=", "\"<s>\"", ",", "\n", "unk_token", "=", "\"<unk>\"", ",", "\n", "pad_token", "=", "\"<pad>\"", ",", "\n", "mask_token", "=", "\"<mask>\"", ",", "\n", "additional_special_tokens", "=", "[", "\"<s>NOTUSED\"", ",", "\"</s>NOTUSED\"", "]", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "CamembertTokenizer", ",", "self", ")", ".", "__init__", "(", "\n", "max_len", "=", "512", ",", "\n", "bos_token", "=", "bos_token", ",", "\n", "eos_token", "=", "eos_token", ",", "\n", "unk_token", "=", "unk_token", ",", "\n", "sep_token", "=", "sep_token", ",", "\n", "cls_token", "=", "cls_token", ",", "\n", "pad_token", "=", "pad_token", ",", "\n", "mask_token", "=", "mask_token", ",", "\n", "additional_special_tokens", "=", "additional_special_tokens", ",", "\n", "**", "kwargs", "\n", ")", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "-", "2", "# take into account special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "-", "4", "# take into account special tokens", "\n", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "str", "(", "vocab_file", ")", ")", "\n", "self", ".", "vocab_file", "=", "vocab_file", "\n", "# HACK: These tokens were added by fairseq but don't seem to be actually used when duplicated in the actual", "\n", "# sentencepiece vocabulary (this is the case for <s> and </s>", "\n", "self", ".", "fairseq_tokens_to_ids", "=", "{", "\"<s>NOTUSED\"", ":", "0", ",", "\"<pad>\"", ":", "1", ",", "\"</s>NOTUSED\"", ":", "2", ",", "\"<unk>\"", ":", "3", "}", "\n", "self", ".", "fairseq_offset", "=", "len", "(", "self", ".", "fairseq_tokens_to_ids", ")", "\n", "self", ".", "fairseq_tokens_to_ids", "[", "\"<mask>\"", "]", "=", "len", "(", "self", ".", "sp_model", ")", "+", "len", "(", "self", ".", "fairseq_tokens_to_ids", ")", "\n", "self", ".", "fairseq_ids_to_tokens", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "fairseq_tokens_to_ids", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_camembert.CamembertTokenizer.build_inputs_with_special_tokens": [[93, 106], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n        by concatenating and adding special tokens.\n        A RoBERTa sequence has the following format:\n            single sequence: <s> X </s>\n            pair of sequences: <s> A </s></s> B </s>\n        \"\"\"", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "[", "self", ".", "cls_token_id", "]", "+", "token_ids_0", "+", "[", "self", ".", "sep_token_id", "]", "\n", "", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "return", "cls", "+", "token_ids_0", "+", "sep", "+", "sep", "+", "token_ids_1", "+", "sep", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_camembert.CamembertTokenizer.get_special_tokens_mask": [[107, 133], ["list", "ValueError", "map", "len", "len", "len"], "methods", ["None"], ["", "def", "get_special_tokens_mask", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ",", "already_has_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n\n        Args:\n            token_ids_0: list of ids (must not contain special tokens)\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n                for sequence pairs\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n                special tokens for the model\n\n        Returns:\n            A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.\n        \"\"\"", "\n", "if", "already_has_special_tokens", ":", "\n", "            ", "if", "token_ids_1", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"You should not supply a second sequence if the provided sequence of \"", "\n", "\"ids is already formated with special tokens for the model.\"", "\n", ")", "\n", "", "return", "list", "(", "map", "(", "lambda", "x", ":", "1", "if", "x", "in", "[", "self", ".", "sep_token_id", ",", "self", ".", "cls_token_id", "]", "else", "0", ",", "token_ids_0", ")", ")", "\n", "\n", "", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "\n", "", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", ",", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_1", ")", ")", "+", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_camembert.CamembertTokenizer.create_token_type_ids_from_sequences": [[134, 149], ["len", "len", "len"], "methods", ["None"], ["", "def", "create_token_type_ids_from_sequences", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n        A RoBERTa sequence pair mask has the following format:\n        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n        | first sequence    | second sequence\n\n        if token_ids_1 is None, only returns the first portion of the mask (0's).\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "\n", "", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", "+", "sep", ")", "*", "[", "0", "]", "+", "len", "(", "token_ids_1", "+", "sep", ")", "*", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_camembert.CamembertTokenizer.vocab_size": [[150, 153], ["len", "len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "fairseq_tokens_to_ids", ")", "+", "len", "(", "self", ".", "sp_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_camembert.CamembertTokenizer._tokenize": [[154, 156], ["tokenization_camembert.CamembertTokenizer.sp_model.EncodeAsPieces"], "methods", ["None"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "return", "self", ".", "sp_model", ".", "EncodeAsPieces", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_camembert.CamembertTokenizer._convert_token_to_id": [[157, 165], ["tokenization_camembert.CamembertTokenizer.sp_model.PieceToId", "tokenization_camembert.CamembertTokenizer.sp_model.PieceToId"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "if", "token", "in", "self", ".", "fairseq_tokens_to_ids", ":", "\n", "            ", "return", "self", ".", "fairseq_tokens_to_ids", "[", "token", "]", "\n", "", "elif", "self", ".", "sp_model", ".", "PieceToId", "(", "token", ")", "==", "0", ":", "\n", "# Convert sentence piece unk token to fairseq unk token index", "\n", "            ", "return", "self", ".", "unk_token_id", "\n", "", "return", "self", ".", "fairseq_offset", "+", "self", ".", "sp_model", ".", "PieceToId", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_camembert.CamembertTokenizer._convert_id_to_token": [[166, 171], ["tokenization_camembert.CamembertTokenizer.sp_model.IdToPiece"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"", "\n", "if", "index", "in", "self", ".", "fairseq_ids_to_tokens", ":", "\n", "            ", "return", "self", ".", "fairseq_ids_to_tokens", "[", "index", "]", "\n", "", "return", "self", ".", "sp_model", ".", "IdToPiece", "(", "index", "-", "self", ".", "fairseq_offset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_camembert.CamembertTokenizer.convert_tokens_to_string": [[172, 176], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"", "\n", "out_string", "=", "\"\"", ".", "join", "(", "tokens", ")", ".", "replace", "(", "SPIECE_UNDERLINE", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_camembert.CamembertTokenizer.save_vocabulary": [[177, 190], ["os.path.join", "os.path.isdir", "logger.error", "os.path.abspath", "os.path.abspath", "shutil.copyfile"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n            to a directory.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "out_vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "\n", "if", "os", ".", "path", ".", "abspath", "(", "self", ".", "vocab_file", ")", "!=", "os", ".", "path", ".", "abspath", "(", "out_vocab_file", ")", ":", "\n", "            ", "copyfile", "(", "self", ".", "vocab_file", ",", "out_vocab_file", ")", "\n", "\n", "", "return", "(", "out_vocab_file", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm_roberta.XLMRobertaTokenizer.__init__": [[66, 108], ["transformers.tokenization_utils.PreTrainedTokenizer.__init__", "sentencepiece.SentencePieceProcessor", "tokenization_xlm_roberta.XLMRobertaTokenizer.sp_model.Load", "str", "len", "len", "tokenization_xlm_roberta.XLMRobertaTokenizer.fairseq_tokens_to_ids.items"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "bos_token", "=", "\"<s>\"", ",", "\n", "eos_token", "=", "\"</s>\"", ",", "\n", "sep_token", "=", "\"</s>\"", ",", "\n", "cls_token", "=", "\"<s>\"", ",", "\n", "unk_token", "=", "\"<unk>\"", ",", "\n", "pad_token", "=", "\"<pad>\"", ",", "\n", "mask_token", "=", "\"<mask>\"", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "XLMRobertaTokenizer", ",", "self", ")", ".", "__init__", "(", "\n", "bos_token", "=", "bos_token", ",", "\n", "eos_token", "=", "eos_token", ",", "\n", "unk_token", "=", "unk_token", ",", "\n", "sep_token", "=", "sep_token", ",", "\n", "cls_token", "=", "cls_token", ",", "\n", "pad_token", "=", "pad_token", ",", "\n", "mask_token", "=", "mask_token", ",", "\n", "**", "kwargs", "\n", ")", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "-", "2", "# take into account special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "-", "4", "# take into account special tokens", "\n", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "str", "(", "vocab_file", ")", ")", "\n", "self", ".", "vocab_file", "=", "vocab_file", "\n", "\n", "# Original fairseq vocab and spm vocab must be \"aligned\":", "\n", "# Vocab    |    0    |    1    |   2    |    3    |  4  |  5  |  6  |   7   |   8   |  9", "\n", "# -------- | ------- | ------- | ------ | ------- | --- | --- | --- | ----- | ----- | ----", "\n", "# fairseq  | '<s>'   | '<pad>' | '</s>' | '<unk>' | ',' | '.' | '\u2581' | 's'   | '\u2581de' | '-'", "\n", "# spm      | '<unk>' | '<s>'   | '</s>' | ','     | '.' | '\u2581' | 's' | '\u2581de' | '-'   | '\u2581a'", "\n", "\n", "# Mimic fairseq token-to-id alignment for the first 4 token", "\n", "self", ".", "fairseq_tokens_to_ids", "=", "{", "\"<s>\"", ":", "0", ",", "\"<pad>\"", ":", "1", ",", "\"</s>\"", ":", "2", ",", "\"<unk>\"", ":", "3", "}", "\n", "\n", "# The first \"real\" token \",\" has position 4 in the original fairseq vocab and position 3 in the spm vocab", "\n", "self", ".", "fairseq_offset", "=", "1", "\n", "\n", "self", ".", "fairseq_tokens_to_ids", "[", "\"<mask>\"", "]", "=", "len", "(", "self", ".", "sp_model", ")", "+", "len", "(", "self", ".", "fairseq_tokens_to_ids", ")", "\n", "self", ".", "fairseq_ids_to_tokens", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "fairseq_tokens_to_ids", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm_roberta.XLMRobertaTokenizer.build_inputs_with_special_tokens": [[109, 122], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n        by concatenating and adding special tokens.\n        A RoBERTa sequence has the following format:\n            single sequence: <s> X </s>\n            pair of sequences: <s> A </s></s> B </s>\n        \"\"\"", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "[", "self", ".", "cls_token_id", "]", "+", "token_ids_0", "+", "[", "self", ".", "sep_token_id", "]", "\n", "", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "return", "cls", "+", "token_ids_0", "+", "sep", "+", "sep", "+", "token_ids_1", "+", "sep", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm_roberta.XLMRobertaTokenizer.get_special_tokens_mask": [[123, 149], ["list", "ValueError", "map", "len", "len", "len"], "methods", ["None"], ["", "def", "get_special_tokens_mask", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ",", "already_has_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n\n        Args:\n            token_ids_0: list of ids (must not contain special tokens)\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n                for sequence pairs\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n                special tokens for the model\n\n        Returns:\n            A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.\n        \"\"\"", "\n", "if", "already_has_special_tokens", ":", "\n", "            ", "if", "token_ids_1", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"You should not supply a second sequence if the provided sequence of \"", "\n", "\"ids is already formated with special tokens for the model.\"", "\n", ")", "\n", "", "return", "list", "(", "map", "(", "lambda", "x", ":", "1", "if", "x", "in", "[", "self", ".", "sep_token_id", ",", "self", ".", "cls_token_id", "]", "else", "0", ",", "token_ids_0", ")", ")", "\n", "\n", "", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "\n", "", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", ",", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_1", ")", ")", "+", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm_roberta.XLMRobertaTokenizer.create_token_type_ids_from_sequences": [[150, 165], ["len", "len", "len"], "methods", ["None"], ["", "def", "create_token_type_ids_from_sequences", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n        A RoBERTa sequence pair mask has the following format:\n        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n        | first sequence    | second sequence\n\n        if token_ids_1 is None, only returns the first portion of the mask (0's).\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "\n", "", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", "+", "sep", ")", "*", "[", "0", "]", "+", "len", "(", "token_ids_1", "+", "sep", ")", "*", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm_roberta.XLMRobertaTokenizer.vocab_size": [[166, 169], ["len", "len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sp_model", ")", "+", "len", "(", "self", ".", "fairseq_tokens_to_ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm_roberta.XLMRobertaTokenizer._tokenize": [[170, 172], ["tokenization_xlm_roberta.XLMRobertaTokenizer.sp_model.EncodeAsPieces"], "methods", ["None"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "return", "self", ".", "sp_model", ".", "EncodeAsPieces", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm_roberta.XLMRobertaTokenizer._convert_token_to_id": [[173, 178], ["tokenization_xlm_roberta.XLMRobertaTokenizer.sp_model.PieceToId"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "if", "token", "in", "self", ".", "fairseq_tokens_to_ids", ":", "\n", "            ", "return", "self", ".", "fairseq_tokens_to_ids", "[", "token", "]", "\n", "", "return", "self", ".", "sp_model", ".", "PieceToId", "(", "token", ")", "+", "self", ".", "fairseq_offset", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm_roberta.XLMRobertaTokenizer._convert_id_to_token": [[179, 184], ["tokenization_xlm_roberta.XLMRobertaTokenizer.sp_model.IdToPiece"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"", "\n", "if", "index", "in", "self", ".", "fairseq_ids_to_tokens", ":", "\n", "            ", "return", "self", ".", "fairseq_ids_to_tokens", "[", "index", "]", "\n", "", "return", "self", ".", "sp_model", ".", "IdToPiece", "(", "index", "-", "self", ".", "fairseq_offset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm_roberta.XLMRobertaTokenizer.convert_tokens_to_string": [[185, 189], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"", "\n", "out_string", "=", "\"\"", ".", "join", "(", "tokens", ")", ".", "replace", "(", "SPIECE_UNDERLINE", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_xlm_roberta.XLMRobertaTokenizer.save_vocabulary": [[190, 203], ["os.path.join", "os.path.isdir", "logger.error", "os.path.abspath", "os.path.abspath", "shutil.copyfile"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n            to a directory.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "out_vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "\n", "if", "os", ".", "path", ".", "abspath", "(", "self", ".", "vocab_file", ")", "!=", "os", ".", "path", ".", "abspath", "(", "out_vocab_file", ")", ":", "\n", "            ", "copyfile", "(", "self", ".", "vocab_file", ",", "out_vocab_file", ")", "\n", "\n", "", "return", "(", "out_vocab_file", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_t5.T5Tokenizer.__init__": [[78, 117], ["tokenization_utils.PreTrainedTokenizer.__init__", "spm.SentencePieceProcessor", "tokenization_t5.T5Tokenizer.sp_model.Load", "additional_special_tokens.extend", "logger.warning", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "eos_token", "=", "\"</s>\"", ",", "\n", "unk_token", "=", "\"<unk>\"", ",", "\n", "pad_token", "=", "\"<pad>\"", ",", "\n", "extra_ids", "=", "100", ",", "\n", "additional_special_tokens", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "# Add extra_ids to the special token list", "\n", "        ", "if", "extra_ids", ">", "0", ":", "\n", "            ", "if", "additional_special_tokens", "is", "None", ":", "\n", "                ", "additional_special_tokens", "=", "[", "]", "\n", "", "additional_special_tokens", ".", "extend", "(", "[", "\"<extra_id_{}>\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "extra_ids", ")", "]", ")", "\n", "\n", "", "super", "(", "T5Tokenizer", ",", "self", ")", ".", "__init__", "(", "\n", "eos_token", "=", "eos_token", ",", "\n", "unk_token", "=", "unk_token", ",", "\n", "pad_token", "=", "pad_token", ",", "\n", "additional_special_tokens", "=", "additional_special_tokens", ",", "\n", "**", "kwargs", "\n", ")", "\n", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"You need to install SentencePiece to use T5Tokenizer:\"", "\n", "\"https://github.com/google/sentencepiece\"", "\n", "\"pip install sentencepiece\"", "\n", ")", "\n", "raise", "\n", "\n", "", "self", ".", "vocab_file", "=", "vocab_file", "\n", "self", ".", "_extra_ids", "=", "extra_ids", "\n", "\n", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_t5.T5Tokenizer.vocab_size": [[118, 121], ["tokenization_t5.T5Tokenizer.sp_model.get_piece_size"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sp_model", ".", "get_piece_size", "(", ")", "+", "self", ".", "_extra_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_t5.T5Tokenizer.__getstate__": [[122, 126], ["tokenization_t5.T5Tokenizer.__dict__.copy"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "state", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "state", "[", "\"sp_model\"", "]", "=", "None", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_t5.T5Tokenizer.__setstate__": [[127, 139], ["spm.SentencePieceProcessor", "tokenization_t5.T5Tokenizer.sp_model.Load", "logger.warning"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "d", ")", ":", "\n", "        ", "self", ".", "__dict__", "=", "d", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"You need to install SentencePiece to use XLNetTokenizer: https://github.com/google/sentencepiece\"", "\n", "\"pip install sentencepiece\"", "\n", ")", "\n", "raise", "\n", "", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "self", ".", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_t5.T5Tokenizer._tokenize": [[140, 148], ["tokenization_t5.T5Tokenizer.sp_model.EncodeAsPieces", "tokenization_t5.T5Tokenizer.sp_model.SampleEncodeAsPieces"], "methods", ["None"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "sample", "=", "False", ")", ":", "\n", "        ", "\"\"\" Take as input a string and return a list of strings (tokens) for words/sub-words\n        \"\"\"", "\n", "if", "not", "sample", ":", "\n", "            ", "pieces", "=", "self", ".", "sp_model", ".", "EncodeAsPieces", "(", "text", ")", "\n", "", "else", ":", "\n", "            ", "pieces", "=", "self", ".", "sp_model", ".", "SampleEncodeAsPieces", "(", "text", ",", "64", ",", "0.1", ")", "\n", "", "return", "pieces", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_t5.T5Tokenizer._convert_token_to_id": [[149, 156], ["token.startswith", "tokenization_t5.T5Tokenizer.sp_model.piece_to_id", "re.match", "int", "re.match.group"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "if", "token", ".", "startswith", "(", "\"<extra_id_\"", ")", ":", "\n", "            ", "match", "=", "re", ".", "match", "(", "r\"<extra_id_(\\d+)>\"", ",", "token", ")", "\n", "num", "=", "int", "(", "match", ".", "group", "(", "1", ")", ")", "\n", "return", "self", ".", "vocab_size", "-", "num", "-", "1", "\n", "", "return", "self", ".", "sp_model", ".", "piece_to_id", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_t5.T5Tokenizer._convert_id_to_token": [[157, 164], ["tokenization_t5.T5Tokenizer.sp_model.get_piece_size", "tokenization_t5.T5Tokenizer.sp_model.IdToPiece"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"", "\n", "if", "index", "<", "self", ".", "sp_model", ".", "get_piece_size", "(", ")", ":", "\n", "            ", "token", "=", "self", ".", "sp_model", ".", "IdToPiece", "(", "index", ")", "\n", "", "else", ":", "\n", "            ", "token", "=", "\"<extra_id_{}>\"", ".", "format", "(", "self", ".", "vocab_size", "-", "1", "-", "index", ")", "\n", "", "return", "token", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_t5.T5Tokenizer.convert_tokens_to_string": [[165, 169], ["tokenization_t5.T5Tokenizer.sp_model.decode_pieces"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "self", ".", "sp_model", ".", "decode_pieces", "(", "tokens", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_t5.T5Tokenizer.save_vocabulary": [[170, 183], ["os.path.join", "os.path.isdir", "logger.error", "os.path.abspath", "os.path.abspath", "shutil.copyfile"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n            to a directory.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "out_vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "\n", "if", "os", ".", "path", ".", "abspath", "(", "self", ".", "vocab_file", ")", "!=", "os", ".", "path", ".", "abspath", "(", "out_vocab_file", ")", ":", "\n", "            ", "copyfile", "(", "self", ".", "vocab_file", ",", "out_vocab_file", ")", "\n", "\n", "", "return", "(", "out_vocab_file", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_transfo_xl_original_tf_checkpoint_to_pytorch.convert_transfo_xl_checkpoint_to_pytorch": [[47, 89], ["print", "torch.save", "corpus_dict_no_vocab.pop", "print", "torch.save", "os.path.abspath", "os.path.abspath", "print", "print", "transformers.TransfoXLLMHeadModel", "transformers.load_tf_weights_in_transfo_xl", "os.path.join", "os.path.join", "print", "torch.save", "print", "open", "pickle.load", "transformers.TransfoXLConfig", "transformers.TransfoXLConfig.from_json_file", "transformers.load_tf_weights_in_transfo_xl.state_dict", "open", "f.write", "str", "os.path.abspath", "os.path.abspath", "TransfoXLConfig.from_json_file.to_json_string"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl.load_tf_weights_in_transfo_xl", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_json_string"], ["def", "convert_transfo_xl_checkpoint_to_pytorch", "(", "\n", "tf_checkpoint_path", ",", "transfo_xl_config_file", ",", "pytorch_dump_folder_path", ",", "transfo_xl_dataset_file", "\n", ")", ":", "\n", "    ", "if", "transfo_xl_dataset_file", ":", "\n", "# Convert a pre-processed corpus (see original TensorFlow repo)", "\n", "        ", "with", "open", "(", "transfo_xl_dataset_file", ",", "\"rb\"", ")", "as", "fp", ":", "\n", "            ", "corpus", "=", "pickle", ".", "load", "(", "fp", ",", "encoding", "=", "\"latin1\"", ")", "\n", "# Save vocabulary and dataset cache as Dictionaries (should be better than pickles for the long-term)", "\n", "", "pytorch_vocab_dump_path", "=", "pytorch_dump_folder_path", "+", "\"/\"", "+", "VOCAB_FILES_NAMES", "[", "\"pretrained_vocab_file\"", "]", "\n", "print", "(", "\"Save vocabulary to {}\"", ".", "format", "(", "pytorch_vocab_dump_path", ")", ")", "\n", "corpus_vocab_dict", "=", "corpus", ".", "vocab", ".", "__dict__", "\n", "torch", ".", "save", "(", "corpus_vocab_dict", ",", "pytorch_vocab_dump_path", ")", "\n", "\n", "corpus_dict_no_vocab", "=", "corpus", ".", "__dict__", "\n", "corpus_dict_no_vocab", ".", "pop", "(", "\"vocab\"", ",", "None", ")", "\n", "pytorch_dataset_dump_path", "=", "pytorch_dump_folder_path", "+", "\"/\"", "+", "CORPUS_NAME", "\n", "print", "(", "\"Save dataset to {}\"", ".", "format", "(", "pytorch_dataset_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "corpus_dict_no_vocab", ",", "pytorch_dataset_dump_path", ")", "\n", "\n", "", "if", "tf_checkpoint_path", ":", "\n", "# Convert a pre-trained TensorFlow model", "\n", "        ", "config_path", "=", "os", ".", "path", ".", "abspath", "(", "transfo_xl_config_file", ")", "\n", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "\n", "print", "(", "\"Converting Transformer XL checkpoint from {} with config at {}\"", ".", "format", "(", "tf_path", ",", "config_path", ")", ")", "\n", "# Initialise PyTorch model", "\n", "if", "transfo_xl_config_file", "==", "\"\"", ":", "\n", "            ", "config", "=", "TransfoXLConfig", "(", ")", "\n", "", "else", ":", "\n", "            ", "config", "=", "TransfoXLConfig", ".", "from_json_file", "(", "transfo_xl_config_file", ")", "\n", "", "print", "(", "\"Building PyTorch model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "model", "=", "TransfoXLLMHeadModel", "(", "config", ")", "\n", "\n", "model", "=", "load_tf_weights_in_transfo_xl", "(", "model", ",", "config", ",", "tf_path", ")", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "WEIGHTS_NAME", ")", "\n", "pytorch_config_dump_path", "=", "os", ".", "path", ".", "join", "(", "pytorch_dump_folder_path", ",", "CONFIG_NAME", ")", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_weights_dump_path", ")", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "os", ".", "path", ".", "abspath", "(", "pytorch_config_dump_path", ")", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_auto.AutoModel.__init__": [[153, 156], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\n", "\"AutoModel is designed to be instantiated \"", "\n", "\"using the `AutoModel.from_pretrained(pretrained_model_name_or_path)` or \"", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_auto.AutoModel.from_config": [[160, 207], ["isinstance", "ValueError", "modeling_distilbert.DistilBertModel", "isinstance", "modeling_roberta.RobertaModel", "isinstance", "modeling_bert.BertModel", "isinstance", "modeling_openai.OpenAIGPTModel", "isinstance", "modeling_gpt2.GPT2Model", "isinstance", "modeling_transfo_xl.TransfoXLModel", "isinstance", "modeling_xlnet.XLNetModel", "isinstance", "modeling_xlm.XLMModel", "isinstance", "modeling_ctrl.CTRLModel", "isinstance", "modeling_albert.AlbertModel", "isinstance", "modeling_camembert.CamembertModel", "isinstance", "modeling_xlm_roberta.XLMRobertaModel"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "config", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the base model classes of the library\n        from a configuration.\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                The model class to instantiate is selected based on the configuration class:\n                    - isInstance of `distilbert` configuration class: DistilBertModel (DistilBERT model)\n                    - isInstance of `roberta` configuration class: RobertaModel (RoBERTa model)\n                    - isInstance of `bert` configuration class: BertModel (Bert model)\n                    - isInstance of `openai-gpt` configuration class: OpenAIGPTModel (OpenAI GPT model)\n                    - isInstance of `gpt2` configuration class: GPT2Model (OpenAI GPT-2 model)\n                    - isInstance of `ctrl` configuration class: CTRLModel (Salesforce CTRL  model)\n                    - isInstance of `transfo-xl` configuration class: TransfoXLModel (Transformer-XL model)\n                    - isInstance of `xlnet` configuration class: XLNetModel (XLNet model)\n                    - isInstance of `xlm` configuration class: XLMModel (XLM model)\n\n        Examples::\n\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            model = AutoModel.from_config(config)  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n        \"\"\"", "\n", "if", "isinstance", "(", "config", ",", "DistilBertConfig", ")", ":", "\n", "            ", "return", "DistilBertModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "RobertaConfig", ")", ":", "\n", "            ", "return", "RobertaModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "return", "BertModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "OpenAIGPTConfig", ")", ":", "\n", "            ", "return", "OpenAIGPTModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "GPT2Config", ")", ":", "\n", "            ", "return", "GPT2Model", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "TransfoXLConfig", ")", ":", "\n", "            ", "return", "TransfoXLModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLNetConfig", ")", ":", "\n", "            ", "return", "XLNetModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLMConfig", ")", ":", "\n", "            ", "return", "XLMModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "CTRLConfig", ")", ":", "\n", "            ", "return", "CTRLModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "AlbertConfig", ")", ":", "\n", "            ", "return", "AlbertModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "CamembertConfig", ")", ":", "\n", "            ", "return", "CamembertModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLMRobertaConfig", ")", ":", "\n", "            ", "return", "XLMRobertaModel", "(", "config", ")", "\n", "", "raise", "ValueError", "(", "\"Unrecognized configuration class {}\"", ".", "format", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_auto.AutoModel.from_pretrained": [[208, 320], ["ValueError", "modeling_t5.T5Model.from_pretrained", "modeling_distilbert.DistilBertModel.from_pretrained", "modeling_albert.AlbertModel.from_pretrained", "modeling_camembert.CamembertModel.from_pretrained", "modeling_xlm_roberta.XLMRobertaModel.from_pretrained", "modeling_roberta.RobertaModel.from_pretrained", "modeling_bert.BertModel.from_pretrained", "modeling_openai.OpenAIGPTModel.from_pretrained", "modeling_gpt2.GPT2Model.from_pretrained", "modeling_transfo_xl.TransfoXLModel.from_pretrained", "modeling_xlnet.XLNetModel.from_pretrained", "modeling_xlm.XLMModel.from_pretrained", "modeling_ctrl.CTRLModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the base model classes of the library\n        from a pre-trained model configuration.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `t5`: T5Model (T5 model)\n            - contains `distilbert`: DistilBertModel (DistilBERT model)\n            - contains `albert`: AlbertModel (ALBERT model)\n            - contains `camembert`: CamembertModel (CamemBERT model)\n            - contains `xlm-roberta`: XLMRobertaModel (XLM-RoBERTa model)\n            - contains `roberta`: RobertaModel (RoBERTa model)\n            - contains `bert`: BertModel (Bert model)\n            - contains `openai-gpt`: OpenAIGPTModel (OpenAI GPT model)\n            - contains `gpt2`: GPT2Model (OpenAI GPT-2 model)\n            - contains `transfo-xl`: TransfoXLModel (Transformer-XL model)\n            - contains `xlnet`: XLNetModel (XLNet model)\n            - contains `xlm`: XLMModel (XLM model)\n            - contains `ctrl`: CTRLModel (Salesforce CTRL model)\n\n            The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n            To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = AutoModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = AutoModel.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = AutoModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = AutoModel.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "if", "\"t5\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "T5Model", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"distilbert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "DistilBertModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"albert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "AlbertModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"camembert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "CamembertModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlm-roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMRobertaModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "RobertaModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"bert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"openai-gpt\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "OpenAIGPTModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"gpt2\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "GPT2Model", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"transfo-xl\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TransfoXLModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlnet\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlm\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"ctrl\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "CTRLModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "raise", "ValueError", "(", "\n", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm-roberta', 'xlm', 'roberta, 'ctrl', 'distilbert', 'camembert', 'albert'\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_auto.AutoModelWithLMHead.__init__": [[353, 356], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\n", "\"AutoModelWithLMHead is designed to be instantiated \"", "\n", "\"using the `AutoModelWithLMHead.from_pretrained(pretrained_model_name_or_path)` or \"", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_auto.AutoModelWithLMHead.from_config": [[360, 403], ["isinstance", "ValueError", "modeling_distilbert.DistilBertForMaskedLM", "isinstance", "modeling_roberta.RobertaForMaskedLM", "isinstance", "modeling_bert.BertForMaskedLM", "isinstance", "modeling_openai.OpenAIGPTLMHeadModel", "isinstance", "modeling_gpt2.GPT2LMHeadModel", "isinstance", "modeling_transfo_xl.TransfoXLLMHeadModel", "isinstance", "modeling_xlnet.XLNetLMHeadModel", "isinstance", "modeling_xlm.XLMWithLMHeadModel", "isinstance", "modeling_ctrl.CTRLLMHeadModel", "isinstance", "modeling_xlm_roberta.XLMRobertaForMaskedLM"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "config", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the base model classes of the library\n        from a configuration.\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                The model class to instantiate is selected based on the configuration class:\n                    - isInstance of `distilbert` configuration class: DistilBertModel (DistilBERT model)\n                    - isInstance of `roberta` configuration class: RobertaModel (RoBERTa model)\n                    - isInstance of `bert` configuration class: BertModel (Bert model)\n                    - isInstance of `openai-gpt` configuration class: OpenAIGPTModel (OpenAI GPT model)\n                    - isInstance of `gpt2` configuration class: GPT2Model (OpenAI GPT-2 model)\n                    - isInstance of `ctrl` configuration class: CTRLModel (Salesforce CTRL  model)\n                    - isInstance of `transfo-xl` configuration class: TransfoXLModel (Transformer-XL model)\n                    - isInstance of `xlnet` configuration class: XLNetModel (XLNet model)\n                    - isInstance of `xlm` configuration class: XLMModel (XLM model)\n\n        Examples::\n\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            model = AutoModelWithLMHead.from_config(config)  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n        \"\"\"", "\n", "if", "isinstance", "(", "config", ",", "DistilBertConfig", ")", ":", "\n", "            ", "return", "DistilBertForMaskedLM", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "RobertaConfig", ")", ":", "\n", "            ", "return", "RobertaForMaskedLM", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "return", "BertForMaskedLM", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "OpenAIGPTConfig", ")", ":", "\n", "            ", "return", "OpenAIGPTLMHeadModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "GPT2Config", ")", ":", "\n", "            ", "return", "GPT2LMHeadModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "TransfoXLConfig", ")", ":", "\n", "            ", "return", "TransfoXLLMHeadModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLNetConfig", ")", ":", "\n", "            ", "return", "XLNetLMHeadModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLMConfig", ")", ":", "\n", "            ", "return", "XLMWithLMHeadModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "CTRLConfig", ")", ":", "\n", "            ", "return", "CTRLLMHeadModel", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLMRobertaConfig", ")", ":", "\n", "            ", "return", "XLMRobertaForMaskedLM", "(", "config", ")", "\n", "", "raise", "ValueError", "(", "\"Unrecognized configuration class {}\"", ".", "format", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_auto.AutoModelWithLMHead.from_pretrained": [[404, 518], ["ValueError", "modeling_t5.T5WithLMHeadModel.from_pretrained", "modeling_distilbert.DistilBertForMaskedLM.from_pretrained", "modeling_albert.AlbertForMaskedLM.from_pretrained", "modeling_camembert.CamembertForMaskedLM.from_pretrained", "modeling_xlm_roberta.XLMRobertaForMaskedLM.from_pretrained", "modeling_roberta.RobertaForMaskedLM.from_pretrained", "modeling_bert.BertForMaskedLM.from_pretrained", "modeling_openai.OpenAIGPTLMHeadModel.from_pretrained", "modeling_gpt2.GPT2LMHeadModel.from_pretrained", "modeling_transfo_xl.TransfoXLLMHeadModel.from_pretrained", "modeling_xlnet.XLNetLMHeadModel.from_pretrained", "modeling_xlm.XLMWithLMHeadModel.from_pretrained", "modeling_ctrl.CTRLLMHeadModel.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the language modeling model classes of the library\n        from a pre-trained model configuration.\n\n        The `from_pretrained()` method takes care of returning the correct model class instance\n        using pattern matching on the `pretrained_model_name_or_path` string.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `t5`: T5ModelWithLMHead (T5 model)\n            - contains `distilbert`: DistilBertForMaskedLM (DistilBERT model)\n            - contains `albert`: AlbertForMaskedLM (ALBERT model)\n            - contains `camembert`: CamembertForMaskedLM (CamemBERT model)\n            - contains `xlm-roberta`: XLMRobertaForMaskedLM (XLM-RoBERTa model)\n            - contains `roberta`: RobertaForMaskedLM (RoBERTa model)\n            - contains `bert`: BertForMaskedLM (Bert model)\n            - contains `openai-gpt`: OpenAIGPTLMHeadModel (OpenAI GPT model)\n            - contains `gpt2`: GPT2LMHeadModel (OpenAI GPT-2 model)\n            - contains `transfo-xl`: TransfoXLLMHeadModel (Transformer-XL model)\n            - contains `xlnet`: XLNetLMHeadModel (XLNet model)\n            - contains `xlm`: XLMWithLMHeadModel (XLM model)\n            - contains `ctrl`: CTRLLMHeadModel (Salesforce CTRL model)\n\n        The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = AutoModelWithLMHead.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = AutoModelWithLMHead.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = AutoModelWithLMHead.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = AutoModelWithLMHead.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "if", "\"t5\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "T5WithLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"distilbert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "DistilBertForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"albert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "AlbertForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"camembert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "CamembertForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlm-roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMRobertaForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "RobertaForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"bert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertForMaskedLM", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"openai-gpt\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "OpenAIGPTLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"gpt2\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "GPT2LMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"transfo-xl\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TransfoXLLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlnet\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlm\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMWithLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"ctrl\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "CTRLLMHeadModel", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "raise", "ValueError", "(", "\n", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm-roberta', 'xlm', 'roberta','ctrl', 'distilbert', 'camembert', 'albert'\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_auto.AutoModelForSequenceClassification.__init__": [[546, 549], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\n", "\"AutoModelForSequenceClassification is designed to be instantiated \"", "\n", "\"using the `AutoModelForSequenceClassification.from_pretrained(pretrained_model_name_or_path)` or \"", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_auto.AutoModelForSequenceClassification.from_config": [[553, 588], ["isinstance", "ValueError", "modeling_albert.AlbertForSequenceClassification", "isinstance", "modeling_camembert.CamembertForSequenceClassification", "isinstance", "modeling_distilbert.DistilBertForSequenceClassification", "isinstance", "modeling_roberta.RobertaForSequenceClassification", "isinstance", "modeling_bert.BertForSequenceClassification", "isinstance", "modeling_xlnet.XLNetForSequenceClassification", "isinstance", "modeling_xlm.XLMForSequenceClassification", "isinstance", "modeling_xlm_roberta.XLMRobertaForSequenceClassification"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "config", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the base model classes of the library\n        from a configuration.\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                The model class to instantiate is selected based on the configuration class:\n                    - isInstance of `distilbert` configuration class: DistilBertModel (DistilBERT model)\n                    - isInstance of `roberta` configuration class: RobertaModel (RoBERTa model)\n                    - isInstance of `bert` configuration class: BertModel (Bert model)\n                    - isInstance of `xlnet` configuration class: XLNetModel (XLNet model)\n                    - isInstance of `xlm` configuration class: XLMModel (XLM model)\n\n        Examples::\n\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            model = AutoModelForSequenceClassification.from_config(config)  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n        \"\"\"", "\n", "if", "isinstance", "(", "config", ",", "AlbertConfig", ")", ":", "\n", "            ", "return", "AlbertForSequenceClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "CamembertConfig", ")", ":", "\n", "            ", "return", "CamembertForSequenceClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "DistilBertConfig", ")", ":", "\n", "            ", "return", "DistilBertForSequenceClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "RobertaConfig", ")", ":", "\n", "            ", "return", "RobertaForSequenceClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "return", "BertForSequenceClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLNetConfig", ")", ":", "\n", "            ", "return", "XLNetForSequenceClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLMConfig", ")", ":", "\n", "            ", "return", "XLMForSequenceClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLMRobertaConfig", ")", ":", "\n", "            ", "return", "XLMRobertaForSequenceClassification", "(", "config", ")", "\n", "", "raise", "ValueError", "(", "\"Unrecognized configuration class {}\"", ".", "format", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_auto.AutoModelForSequenceClassification.from_pretrained": [[589, 699], ["ValueError", "modeling_distilbert.DistilBertForSequenceClassification.from_pretrained", "modeling_albert.AlbertForSequenceClassification.from_pretrained", "modeling_camembert.CamembertForSequenceClassification.from_pretrained", "modeling_xlm_roberta.XLMRobertaForSequenceClassification.from_pretrained", "modeling_roberta.RobertaForSequenceClassification.from_pretrained", "modeling_bert.BertForSequenceClassification.from_pretrained", "modeling_xlnet.XLNetForSequenceClassification.from_pretrained", "modeling_xlm.XLMForSequenceClassification.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the sequence classification model classes of the library\n        from a pre-trained model configuration.\n\n        The `from_pretrained()` method takes care of returning the correct model class instance\n        using pattern matching on the `pretrained_model_name_or_path` string.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `distilbert`: DistilBertForSequenceClassification (DistilBERT model)\n            - contains `albert`: AlbertForSequenceClassification (ALBERT model)\n            - contains `camembert`: CamembertForSequenceClassification (CamemBERT model)\n            - contains `xlm-roberta`: XLMRobertaForSequenceClassification (XLM-RoBERTa model)\n            - contains `roberta`: RobertaForSequenceClassification (RoBERTa model)\n            - contains `bert`: BertForSequenceClassification (Bert model)\n            - contains `xlnet`: XLNetForSequenceClassification (XLNet model)\n            - contains `xlm`: XLMForSequenceClassification (XLM model)\n\n        The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = AutoModelForSequenceClassification.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = AutoModelForSequenceClassification.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "if", "\"distilbert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "DistilBertForSequenceClassification", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"albert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "AlbertForSequenceClassification", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"camembert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "CamembertForSequenceClassification", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"xlm-roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMRobertaForSequenceClassification", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "RobertaForSequenceClassification", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"bert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlnet\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlm\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMForSequenceClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "\n", "", "raise", "ValueError", "(", "\n", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'xlnet', 'xlm-roberta', 'xlm', 'roberta', 'distilbert', 'camembert', 'albert'\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_auto.AutoModelForQuestionAnswering.__init__": [[724, 727], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\n", "\"AutoModelForQuestionAnswering is designed to be instantiated \"", "\n", "\"using the `AutoModelForQuestionAnswering.from_pretrained(pretrained_model_name_or_path)` or \"", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_auto.AutoModelForQuestionAnswering.from_config": [[731, 759], ["isinstance", "ValueError", "modeling_albert.AlbertForQuestionAnswering", "isinstance", "modeling_distilbert.DistilBertForQuestionAnswering", "isinstance", "modeling_bert.BertForQuestionAnswering", "isinstance", "modeling_xlnet.XLNetForQuestionAnswering", "isinstance", "modeling_xlm.XLMForQuestionAnswering"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "config", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the base model classes of the library\n        from a configuration.\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                The model class to instantiate is selected based on the configuration class:\n                    - isInstance of `distilbert` configuration class: DistilBertModel (DistilBERT model)\n                    - isInstance of `bert` configuration class: BertModel (Bert model)\n                    - isInstance of `xlnet` configuration class: XLNetModel (XLNet model)\n                    - isInstance of `xlm` configuration class: XLMModel (XLM model)\n\n        Examples::\n\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            model = AutoModelForSequenceClassification.from_config(config)  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n        \"\"\"", "\n", "if", "isinstance", "(", "config", ",", "AlbertConfig", ")", ":", "\n", "            ", "return", "AlbertForQuestionAnswering", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "DistilBertConfig", ")", ":", "\n", "            ", "return", "DistilBertForQuestionAnswering", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "return", "BertForQuestionAnswering", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLNetConfig", ")", ":", "\n", "            ", "return", "XLNetForQuestionAnswering", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLMConfig", ")", ":", "\n", "            ", "return", "XLMForQuestionAnswering", "(", "config", ")", "\n", "", "raise", "ValueError", "(", "\"Unrecognized configuration class {}\"", ".", "format", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_auto.AutoModelForQuestionAnswering.from_pretrained": [[760, 847], ["ValueError", "modeling_distilbert.DistilBertForQuestionAnswering.from_pretrained", "modeling_albert.AlbertForQuestionAnswering.from_pretrained", "modeling_bert.BertForQuestionAnswering.from_pretrained", "modeling_xlnet.XLNetForQuestionAnswering.from_pretrained", "modeling_xlm.XLMForQuestionAnswering.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the question answering model classes of the library\n        from a pre-trained model configuration.\n\n        The `from_pretrained()` method takes care of returning the correct model class instance\n        using pattern matching on the `pretrained_model_name_or_path` string.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `distilbert`: DistilBertForQuestionAnswering (DistilBERT model)\n            - contains `albert`: AlbertForQuestionAnswering (ALBERT model)\n            - contains `bert`: BertForQuestionAnswering (Bert model)\n            - contains `xlnet`: XLNetForQuestionAnswering (XLNet model)\n            - contains `xlm`: XLMForQuestionAnswering (XLM model)\n\n        The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = AutoModelForQuestionAnswering.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = AutoModelForQuestionAnswering.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = AutoModelForQuestionAnswering.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = AutoModelForQuestionAnswering.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "if", "\"distilbert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "DistilBertForQuestionAnswering", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"albert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "AlbertForQuestionAnswering", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"bert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertForQuestionAnswering", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlnet\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetForQuestionAnswering", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlm\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMForQuestionAnswering", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "\n", "", "raise", "ValueError", "(", "\n", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'xlnet', 'xlm', 'distilbert', 'albert'\"", ".", "format", "(", "pretrained_model_name_or_path", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_auto.AutoModelForTokenClassification.__init__": [[851, 854], ["EnvironmentError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\n", "\"AutoModelForTokenClassification is designed to be instantiated \"", "\n", "\"using the `AutoModelForTokenClassification.from_pretrained(pretrained_model_name_or_path)` or \"", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_auto.AutoModelForTokenClassification.from_config": [[858, 889], ["isinstance", "ValueError", "modeling_camembert.CamembertForTokenClassification", "isinstance", "modeling_distilbert.DistilBertForTokenClassification", "isinstance", "modeling_bert.BertForTokenClassification", "isinstance", "modeling_xlnet.XLNetForTokenClassification", "isinstance", "modeling_roberta.RobertaForTokenClassification", "isinstance", "modeling_xlm_roberta.XLMRobertaForTokenClassification"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "config", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the base model classes of the library\n        from a configuration.\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                The model class to instantiate is selected based on the configuration class:\n                    - isInstance of `distilbert` configuration class: DistilBertModel (DistilBERT model)\n                    - isInstance of `bert` configuration class: BertModel (Bert model)\n                    - isInstance of `xlnet` configuration class: XLNetModel (XLNet model)\n                    - isInstance of `camembert` configuration class: CamembertModel (Camembert model)\n                    - isInstance of `roberta` configuration class: RobertaModel (Roberta model)\n\n        Examples::\n\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            model = AutoModelForTokenClassification.from_config(config)  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n        \"\"\"", "\n", "if", "isinstance", "(", "config", ",", "CamembertConfig", ")", ":", "\n", "            ", "return", "CamembertForTokenClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "DistilBertConfig", ")", ":", "\n", "            ", "return", "DistilBertForTokenClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "return", "BertForTokenClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLNetConfig", ")", ":", "\n", "            ", "return", "XLNetForTokenClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "RobertaConfig", ")", ":", "\n", "            ", "return", "RobertaForTokenClassification", "(", "config", ")", "\n", "", "elif", "isinstance", "(", "config", ",", "XLMRobertaConfig", ")", ":", "\n", "            ", "return", "XLMRobertaForTokenClassification", "(", "config", ")", "\n", "", "raise", "ValueError", "(", "\"Unrecognized configuration class {}\"", ".", "format", "(", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_auto.AutoModelForTokenClassification.from_pretrained": [[890, 985], ["ValueError", "modeling_camembert.CamembertForTokenClassification.from_pretrained", "modeling_distilbert.DistilBertForTokenClassification.from_pretrained", "modeling_xlm_roberta.XLMRobertaForTokenClassification.from_pretrained", "modeling_roberta.RobertaForTokenClassification.from_pretrained", "modeling_bert.BertForTokenClassification.from_pretrained", "modeling_xlnet.XLNetForTokenClassification.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiates one of the question answering model classes of the library\n        from a pre-trained model configuration.\n\n        The `from_pretrained()` method takes care of returning the correct model class instance\n        using pattern matching on the `pretrained_model_name_or_path` string.\n\n        The model class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `distilbert`: DistilBertForTokenClassification (DistilBERT model)\n            - contains `camembert`: CamembertForTokenClassification (Camembert model)\n            - contains `bert`: BertForTokenClassification (Bert model)\n            - contains `xlnet`: XLNetForTokenClassification (XLNet model)\n            - contains `roberta`: RobertaForTokenClassification (Roberta model)\n\n        The model is set in evaluation mode by default using `model.eval()` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with `model.train()`\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) instance of a class derived from :class:`~transformers.PretrainedConfig`:\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = AutoModelForTokenClassification.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = AutoModelForTokenClassification.from_pretrained('./test/bert_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = AutoModelForTokenClassification.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = AutoConfig.from_json_file('./tf_model/bert_tf_model_config.json')\n            model = AutoModelForTokenClassification.from_pretrained('./tf_model/bert_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "if", "\"camembert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "CamembertForTokenClassification", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"distilbert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "DistilBertForTokenClassification", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"xlm-roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMRobertaForTokenClassification", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", "\n", ")", "\n", "", "elif", "\"roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "RobertaForTokenClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"bert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertForTokenClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlnet\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetForTokenClassification", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", "\n", "\n", "", "raise", "ValueError", "(", "\n", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'xlnet', 'camembert', 'distilbert', 'xlm-roberta', 'roberta'\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_gpt2_original_tf_checkpoint_to_pytorch.convert_gpt2_checkpoint_to_pytorch": [[29, 48], ["transformers.GPT2Model", "transformers.load_tf_weights_in_gpt2", "print", "torch.save", "print", "transformers.GPT2Config", "transformers.GPT2Config.from_json_file", "transformers.GPT2Model.state_dict", "open", "f.write", "GPT2Config.from_json_file.to_json_string"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_gpt2.load_tf_weights_in_gpt2", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_json_string"], ["def", "convert_gpt2_checkpoint_to_pytorch", "(", "gpt2_checkpoint_path", ",", "gpt2_config_file", ",", "pytorch_dump_folder_path", ")", ":", "\n", "# Construct model", "\n", "    ", "if", "gpt2_config_file", "==", "\"\"", ":", "\n", "        ", "config", "=", "GPT2Config", "(", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "GPT2Config", ".", "from_json_file", "(", "gpt2_config_file", ")", "\n", "", "model", "=", "GPT2Model", "(", "config", ")", "\n", "\n", "# Load weights from numpy", "\n", "load_tf_weights_in_gpt2", "(", "model", ",", "config", ",", "gpt2_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "pytorch_dump_folder_path", "+", "\"/\"", "+", "WEIGHTS_NAME", "\n", "pytorch_config_dump_path", "=", "pytorch_dump_folder_path", "+", "\"/\"", "+", "CONFIG_NAME", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_weights_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaEmbeddings.__init__": [[47, 53], ["modeling_bert.BertEmbeddings.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaEmbeddings", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "padding_idx", "=", "1", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "self", ".", "padding_idx", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "self", ".", "padding_idx", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaEmbeddings.forward": [[55, 65], ["super().forward", "modeling_roberta.RobertaEmbeddings.create_position_ids_from_input_ids().to", "modeling_roberta.RobertaEmbeddings.create_position_ids_from_inputs_embeds", "modeling_roberta.RobertaEmbeddings.create_position_ids_from_input_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.modeling.modeling_bert.BertForDependencyParsingWithOrder.forward", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaEmbeddings.create_position_ids_from_inputs_embeds", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaEmbeddings.create_position_ids_from_input_ids"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "inputs_embeds", "=", "None", ")", ":", "\n", "        ", "if", "position_ids", "is", "None", ":", "\n", "            ", "if", "input_ids", "is", "not", "None", ":", "\n", "# Create the position ids from the input token ids. Any padded tokens remain padded.", "\n", "                ", "position_ids", "=", "self", ".", "create_position_ids_from_input_ids", "(", "input_ids", ")", ".", "to", "(", "input_ids", ".", "device", ")", "\n", "", "else", ":", "\n", "                ", "position_ids", "=", "self", ".", "create_position_ids_from_inputs_embeds", "(", "inputs_embeds", ")", "\n", "\n", "", "", "return", "super", "(", "RobertaEmbeddings", ",", "self", ")", ".", "forward", "(", "\n", "input_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "position_ids", "=", "position_ids", ",", "inputs_embeds", "=", "inputs_embeds", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaEmbeddings.create_position_ids_from_input_ids": [[67, 78], ["x.ne().long", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "x.ne"], "methods", ["None"], ["", "def", "create_position_ids_from_input_ids", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" Replace non-padding symbols with their position numbers. Position numbers begin at\n        padding_idx+1. Padding symbols are ignored. This is modified from fairseq's\n        `utils.make_positions`.\n\n        :param torch.Tensor x:\n        :return torch.Tensor:\n        \"\"\"", "\n", "mask", "=", "x", ".", "ne", "(", "self", ".", "padding_idx", ")", ".", "long", "(", ")", "\n", "incremental_indicies", "=", "torch", ".", "cumsum", "(", "mask", ",", "dim", "=", "1", ")", "*", "mask", "\n", "return", "incremental_indicies", "+", "self", ".", "padding_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaEmbeddings.create_position_ids_from_inputs_embeds": [[79, 93], ["torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange.unsqueeze().expand", "torch.arange.unsqueeze().expand", "inputs_embeds.size", "torch.arange.unsqueeze", "torch.arange.unsqueeze"], "methods", ["None"], ["", "def", "create_position_ids_from_inputs_embeds", "(", "self", ",", "inputs_embeds", ")", ":", "\n", "        ", "\"\"\" We are provided embeddings directly. We cannot infer which are padded so just generate\n        sequential position ids.\n\n        :param torch.Tensor inputs_embeds:\n        :return torch.Tensor:\n        \"\"\"", "\n", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "sequence_length", "=", "input_shape", "[", "1", "]", "\n", "\n", "position_ids", "=", "torch", ".", "arange", "(", "\n", "self", ".", "padding_idx", "+", "1", ",", "sequence_length", "+", "self", ".", "padding_idx", "+", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "inputs_embeds", ".", "device", "\n", ")", "\n", "return", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaModel.__init__": [[206, 211], ["modeling_bert.BertModel.__init__", "modeling_roberta.RobertaEmbeddings", "modeling_roberta.RobertaModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embeddings", "=", "RobertaEmbeddings", "(", "config", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaModel.get_input_embeddings": [[212, 214], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaModel.set_input_embeddings": [[215, 217], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "embeddings", ".", "word_embeddings", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaForMaskedLM.__init__": [[256, 263], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "modeling_roberta.RobertaLMHead", "modeling_roberta.RobertaForMaskedLM.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "RobertaLMHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaForMaskedLM.get_output_embeddings": [[264, 266], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaForMaskedLM.forward": [[267, 296], ["modeling_roberta.RobertaForMaskedLM.roberta", "modeling_roberta.RobertaForMaskedLM.lm_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_roberta.RobertaForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "masked_lm_labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (masked_lm_loss), prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaLMHead.__init__": [[301, 308], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "modeling_bert.BertLayerNorm", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "layer_norm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "config", ".", "vocab_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaLMHead.forward": [[309, 318], ["modeling_roberta.RobertaLMHead.dense", "modeling_bert.gelu", "modeling_roberta.RobertaLMHead.layer_norm", "modeling_roberta.RobertaLMHead.decoder"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.gelu"], ["", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "dense", "(", "features", ")", "\n", "x", "=", "gelu", "(", "x", ")", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# project back to size of vocabulary with bias", "\n", "x", "=", "self", ".", "decoder", "(", "x", ")", "+", "self", ".", "bias", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaForSequenceClassification.__init__": [[361, 367], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "modeling_roberta.RobertaClassificationHead"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "classifier", "=", "RobertaClassificationHead", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaForSequenceClassification.forward": [[368, 401], ["modeling_roberta.RobertaForSequenceClassification.roberta", "modeling_roberta.RobertaForSequenceClassification.classifier", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_roberta.RobertaForSequenceClassification.view", "labels.view", "modeling_roberta.RobertaForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaForMultipleChoice.__init__": [[483, 491], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "modeling_roberta.RobertaForMultipleChoice.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaForMultipleChoice.forward": [[492, 529], ["input_ids.view", "modeling_roberta.RobertaForMultipleChoice.roberta", "modeling_roberta.RobertaForMultipleChoice.dropout", "modeling_roberta.RobertaForMultipleChoice.classifier", "modeling_roberta.RobertaForMultipleChoice.view", "input_ids.size", "position_ids.view", "token_type_ids.view", "attention_mask.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "position_ids.size", "token_type_ids.size", "attention_mask.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", ")", ":", "\n", "        ", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "\n", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "outputs", "=", "self", ".", "roberta", "(", "\n", "flat_input_ids", ",", "\n", "position_ids", "=", "flat_position_ids", ",", "\n", "token_type_ids", "=", "flat_token_type_ids", ",", "\n", "attention_mask", "=", "flat_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", ")", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "num_choices", ")", "\n", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), reshaped_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaForTokenClassification.__init__": [[570, 579], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "modeling_roberta.RobertaForTokenClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaForTokenClassification.forward": [[580, 619], ["modeling_roberta.RobertaForTokenClassification.roberta", "modeling_roberta.RobertaForTokenClassification.dropout", "modeling_roberta.RobertaForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "modeling_roberta.RobertaForTokenClassification.view", "labels.view", "modeling_roberta.RobertaForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaClassificationHead.__init__": [[624, 629], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaClassificationHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaClassificationHead.forward": [[630, 638], ["modeling_roberta.RobertaClassificationHead.dropout", "modeling_roberta.RobertaClassificationHead.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "modeling_roberta.RobertaClassificationHead.dropout", "modeling_roberta.RobertaClassificationHead.out_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "features", "[", ":", ",", "0", ",", ":", "]", "# take <s> token (equiv. to [CLS])", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaForQuestionAnswering.__init__": [[683, 691], ["modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "torch.Linear", "torch.Linear", "modeling_roberta.RobertaForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaForQuestionAnswering.forward": [[692, 737], ["modeling_roberta.RobertaForQuestionAnswering.roberta", "modeling_roberta.RobertaForQuestionAnswering.qa_outputs", "modeling_roberta.RobertaForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "\n", "end_positions", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_ctrl.CTRLConfig.__init__": [[52, 112], ["configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "246534", ",", "\n", "n_positions", "=", "256", ",", "\n", "n_ctx", "=", "256", ",", "\n", "n_embd", "=", "1280", ",", "\n", "dff", "=", "8192", ",", "\n", "n_layer", "=", "48", ",", "\n", "n_head", "=", "16", ",", "\n", "resid_pdrop", "=", "0.1", ",", "\n", "embd_pdrop", "=", "0.1", ",", "\n", "attn_pdrop", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-6", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "summary_type", "=", "\"cls_index\"", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs CTRLConfig.\n\n        Args:\n            vocab_size: Vocabulary size of `inputs_ids` in `CTRLModel` or a configuration json file.\n            n_positions: Number of positional embeddings.\n            n_ctx: Size of the causal mask (usually same as n_positions).\n            dff: Size of the inner dimension of the FFN.\n            n_embd: Dimensionality of the embeddings and hidden states.\n            n_layer: Number of hidden layers in the Transformer encoder.\n            n_head: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            layer_norm_epsilon: epsilon to use in the layer norm layers\n            resid_pdrop: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            attn_pdrop: The dropout ratio for the attention\n                probabilities.\n            embd_pdrop: The dropout ratio for the embeddings.\n            initializer_range: The sttdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n        \"\"\"", "\n", "super", "(", "CTRLConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "dff", "=", "dff", "\n", "self", ".", "resid_pdrop", "=", "resid_pdrop", "\n", "self", ".", "embd_pdrop", "=", "embd_pdrop", "\n", "self", ".", "attn_pdrop", "=", "attn_pdrop", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_ctrl.CTRLConfig.max_position_embeddings": [[113, 116], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_ctrl.CTRLConfig.hidden_size": [[117, 120], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_embd", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_ctrl.CTRLConfig.num_attention_heads": [[121, 124], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_ctrl.CTRLConfig.num_hidden_layers": [[125, 128], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.bos_token": [[146, 149], ["None"], "methods", ["None"], ["", "@", "bos_token", ".", "setter", "\n", "def", "bos_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_bos_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.eos_token": [[150, 153], ["None"], "methods", ["None"], ["", "@", "eos_token", ".", "setter", "\n", "def", "eos_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_eos_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.unk_token": [[154, 157], ["None"], "methods", ["None"], ["", "@", "unk_token", ".", "setter", "\n", "def", "unk_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_unk_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.sep_token": [[158, 161], ["None"], "methods", ["None"], ["", "@", "sep_token", ".", "setter", "\n", "def", "sep_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_sep_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.pad_token": [[162, 165], ["None"], "methods", ["None"], ["", "@", "pad_token", ".", "setter", "\n", "def", "pad_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_pad_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.cls_token": [[166, 169], ["None"], "methods", ["None"], ["", "@", "cls_token", ".", "setter", "\n", "def", "cls_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_cls_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.mask_token": [[170, 173], ["None"], "methods", ["None"], ["", "@", "mask_token", ".", "setter", "\n", "def", "mask_token", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_mask_token", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.additional_special_tokens": [[174, 177], ["None"], "methods", ["None"], ["", "@", "additional_special_tokens", ".", "setter", "\n", "def", "additional_special_tokens", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "_additional_special_tokens", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.bos_token_id": [[178, 182], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "bos_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\" Id of the beginning of sentence token in the vocabulary. Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "bos_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.eos_token_id": [[183, 187], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "eos_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\" Id of the end of sentence token in the vocabulary. Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "eos_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.unk_token_id": [[188, 192], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "unk_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\" Id of the unknown token in the vocabulary. Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.sep_token_id": [[193, 197], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "sep_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\" Id of the separation token in the vocabulary. E.g. separate context and query in an input sequence. Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "sep_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.pad_token_id": [[198, 202], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "pad_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\" Id of the padding token in the vocabulary. Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "pad_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.pad_token_type_id": [[203, 207], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "pad_token_type_id", "(", "self", ")", ":", "\n", "        ", "\"\"\" Id of the padding token type in the vocabulary.\"\"\"", "\n", "return", "self", ".", "_pad_token_type_id", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.cls_token_id": [[208, 212], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "cls_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\" Id of the classification token in the vocabulary. E.g. to extract a summary of an input sequence leveraging self-attention along the full depth of the model. Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "cls_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.mask_token_id": [[213, 217], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "mask_token_id", "(", "self", ")", ":", "\n", "        ", "\"\"\" Id of the mask token in the vocabulary. E.g. when training a model with masked-language modeling. Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "mask_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.additional_special_tokens_ids": [[218, 222], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "additional_special_tokens_ids", "(", "self", ")", ":", "\n", "        ", "\"\"\" Ids of all the additional special tokens in the vocabulary (list of integers). Log an error if used while not having been set. \"\"\"", "\n", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "additional_special_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.__init__": [[223, 255], ["kwargs.pop", "set", "kwargs.items", "int", "setattr", "isinstance", "isinstance", "all", "isinstance"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "max_len", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_bos_token", "=", "None", "\n", "self", ".", "_eos_token", "=", "None", "\n", "self", ".", "_unk_token", "=", "None", "\n", "self", ".", "_sep_token", "=", "None", "\n", "self", ".", "_pad_token", "=", "None", "\n", "self", ".", "_cls_token", "=", "None", "\n", "self", ".", "_mask_token", "=", "None", "\n", "self", ".", "_pad_token_type_id", "=", "0", "\n", "self", ".", "_additional_special_tokens", "=", "[", "]", "\n", "\n", "self", ".", "max_len", "=", "max_len", "if", "max_len", "is", "not", "None", "else", "int", "(", "1e12", ")", "\n", "\n", "# Padding side is right by default and over-riden in subclasses. If specified in the kwargs, it is changed.", "\n", "self", ".", "padding_side", "=", "kwargs", ".", "pop", "(", "\"padding_side\"", ",", "self", ".", "padding_side", ")", "\n", "\n", "# Added tokens", "\n", "self", ".", "added_tokens_encoder", "=", "{", "}", "\n", "self", ".", "unique_added_tokens_encoder", "=", "set", "(", ")", "\n", "self", ".", "added_tokens_decoder", "=", "{", "}", "\n", "\n", "# inputs and kwargs for saving and re-loading (see ``from_pretrained`` and ``save_pretrained``)", "\n", "self", ".", "init_inputs", "=", "(", ")", "\n", "self", ".", "init_kwargs", "=", "{", "}", "\n", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "in", "self", ".", "SPECIAL_TOKENS_ATTRIBUTES", ":", "\n", "                ", "if", "key", "==", "\"additional_special_tokens\"", ":", "\n", "                    ", "assert", "isinstance", "(", "value", ",", "(", "list", ",", "tuple", ")", ")", "and", "all", "(", "isinstance", "(", "t", ",", "str", ")", "for", "t", "in", "value", ")", "\n", "", "else", ":", "\n", "                    ", "assert", "isinstance", "(", "value", ",", "str", ")", "\n", "", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.from_pretrained": [[256, 310], ["cls._from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer._from_pretrained"], ["", "", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"\n        Instantiate a :class:`~transformers.PreTrainedTokenizer` (or a derived class) from a predefined tokenizer.\n\n        Args:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a predefined tokenizer to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a predefined tokenizer that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing vocabulary files required by the tokenizer, for instance saved using the :func:`~transformers.PreTrainedTokenizer.save_pretrained` method, e.g.: ``./my_model_directory/``.\n                - (not applicable to all derived classes) a path or url to a single saved vocabulary file if and only if the tokenizer only requires a single vocabulary file (e.g. Bert, XLNet), e.g.: ``./my_model_directory/vocab.txt``.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded predefined tokenizer vocabulary files should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the vocabulary files and override the cached versions if they exists.\n\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            inputs: (`optional`) positional arguments: will be passed to the Tokenizer ``__init__`` method.\n\n            kwargs: (`optional`) keyword arguments: will be passed to the Tokenizer ``__init__`` method. Can be used to set special tokens like ``bos_token``, ``eos_token``, ``unk_token``, ``sep_token``, ``pad_token``, ``cls_token``, ``mask_token``, ``additional_special_tokens``. See parameters in the doc string of :class:`~transformers.PreTrainedTokenizer` for details.\n\n        Examples::\n\n            # We can't instantiate directly the base class `PreTrainedTokenizer` so let's show our examples on a derived class: BertTokenizer\n\n            # Download vocabulary from S3 and cache.\n            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n\n            # Download vocabulary from S3 (user-uploaded) and cache.\n            tokenizer = BertTokenizer.from_pretrained('dbmdz/bert-base-german-cased')\n\n            # If vocabulary files are in a directory (e.g. tokenizer was saved using `save_pretrained('./test/saved_model/')`)\n            tokenizer = BertTokenizer.from_pretrained('./test/saved_model/')\n\n            # If the tokenizer uses a single vocabulary file, you can point directly to this file\n            tokenizer = BertTokenizer.from_pretrained('./test/saved_model/my_vocab.txt')\n\n            # You can link tokens to special vocabulary when instantiating\n            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', unk_token='<unk>')\n            # You should be sure '<unk>' is in the vocabulary when doing that.\n            # Otherwise use tokenizer.add_special_tokens({'unk_token': '<unk>'}) instead)\n            assert tokenizer.unk_token == '<unk>'\n\n        \"\"\"", "\n", "return", "cls", ".", "_from_pretrained", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer._from_pretrained": [[311, 481], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "list", "vocab_files.items", "resolved_vocab_files.pop", "json.load.update", "resolved_vocab_files.pop", "resolved_vocab_files.pop", "resolved_vocab_files.items", "cls.max_model_input_sizes.keys", "cls.pretrained_vocab_files_map.items", "logger.info", "cls.vocab_files_names.items", "additional_files_names.items", "all", "vocab_files.items", "json.load.pop", "json.load.items", "cls", "cls.added_tokens_encoder.update", "cls.added_tokens_decoder.update", "os.path.isdir", "os.path.exists", "os.path.dirname", "os.path.join", "EnvironmentError", "EnvironmentError", "logger.info", "logger.info", "open", "json.load", "isinstance", "min", "open", "json.load", "OSError", "open", "json.load", "os.path.join", "os.path.isdir", "os.path.exists", "logger.info", "file_utils.cached_path", "json.load.get", "json.load.items", "os.path.exists", "logger.info", "os.path.isfile", "file_utils.is_remote_url", "file_utils.hf_bucket_url", "vocab_files.values", "list", "list", "int", "cls.vocab_files_names.values", "cls.vocab_files_names.values"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_remote_url", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.hf_bucket_url"], ["", "@", "classmethod", "\n", "def", "_from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "init_inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "cache_dir", "=", "kwargs", ".", "pop", "(", "\"cache_dir\"", ",", "None", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "\"force_download\"", ",", "False", ")", "\n", "resume_download", "=", "kwargs", ".", "pop", "(", "\"resume_download\"", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "\"proxies\"", ",", "None", ")", "\n", "\n", "s3_models", "=", "list", "(", "cls", ".", "max_model_input_sizes", ".", "keys", "(", ")", ")", "\n", "vocab_files", "=", "{", "}", "\n", "init_configuration", "=", "{", "}", "\n", "if", "pretrained_model_name_or_path", "in", "s3_models", ":", "\n", "# Get the vocabulary from AWS S3 bucket", "\n", "            ", "for", "file_id", ",", "map_list", "in", "cls", ".", "pretrained_vocab_files_map", ".", "items", "(", ")", ":", "\n", "                ", "vocab_files", "[", "file_id", "]", "=", "map_list", "[", "pretrained_model_name_or_path", "]", "\n", "", "if", "(", "\n", "cls", ".", "pretrained_init_configuration", "\n", "and", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_init_configuration", "\n", ")", ":", "\n", "                ", "init_configuration", "=", "cls", ".", "pretrained_init_configuration", "[", "pretrained_model_name_or_path", "]", "\n", "", "", "else", ":", "\n", "# Get the vocabulary from local files", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Model name '{}' not found in model shortcut name list ({}). \"", "\n", "\"Assuming '{}' is a path or url to a directory containing tokenizer files.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\", \"", ".", "join", "(", "s3_models", ")", ",", "pretrained_model_name_or_path", "\n", ")", "\n", ")", "\n", "\n", "# Look for the tokenizer main vocabulary files", "\n", "for", "file_id", ",", "file_name", "in", "cls", ".", "vocab_files_names", ".", "items", "(", ")", ":", "\n", "                ", "if", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "# If a directory is provided we look for the standard filenames", "\n", "                    ", "full_file_name", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "file_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "full_file_name", ")", ":", "\n", "                        ", "logger", ".", "info", "(", "\"Didn't find file {}. We won't load it.\"", ".", "format", "(", "full_file_name", ")", ")", "\n", "full_file_name", "=", "None", "\n", "", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", ")", "or", "is_remote_url", "(", "pretrained_model_name_or_path", ")", ":", "\n", "# If a path to a file is provided we use it (will only work for non-BPE tokenizer using a single vocabulary file)", "\n", "                    ", "full_file_name", "=", "pretrained_model_name_or_path", "\n", "", "else", ":", "\n", "                    ", "full_file_name", "=", "hf_bucket_url", "(", "pretrained_model_name_or_path", ",", "postfix", "=", "file_name", ")", "\n", "\n", "", "vocab_files", "[", "file_id", "]", "=", "full_file_name", "\n", "\n", "# Look for the additional tokens files", "\n", "", "additional_files_names", "=", "{", "\n", "\"added_tokens_file\"", ":", "ADDED_TOKENS_FILE", ",", "\n", "\"special_tokens_map_file\"", ":", "SPECIAL_TOKENS_MAP_FILE", ",", "\n", "\"tokenizer_config_file\"", ":", "TOKENIZER_CONFIG_FILE", ",", "\n", "}", "\n", "\n", "# If a path to a file was provided, get the parent directory", "\n", "saved_directory", "=", "pretrained_model_name_or_path", "\n", "if", "os", ".", "path", ".", "exists", "(", "saved_directory", ")", "and", "not", "os", ".", "path", ".", "isdir", "(", "saved_directory", ")", ":", "\n", "                ", "saved_directory", "=", "os", ".", "path", ".", "dirname", "(", "saved_directory", ")", "\n", "\n", "", "for", "file_id", ",", "file_name", "in", "additional_files_names", ".", "items", "(", ")", ":", "\n", "                ", "full_file_name", "=", "os", ".", "path", ".", "join", "(", "saved_directory", ",", "file_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "full_file_name", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Didn't find file {}. We won't load it.\"", ".", "format", "(", "full_file_name", ")", ")", "\n", "full_file_name", "=", "None", "\n", "", "vocab_files", "[", "file_id", "]", "=", "full_file_name", "\n", "\n", "", "if", "all", "(", "full_file_name", "is", "None", "for", "full_file_name", "in", "vocab_files", ".", "values", "(", ")", ")", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\n", "\"Model name '{}' was not found in tokenizers model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url to a directory containing vocabulary files \"", "\n", "\"named {} but couldn't find such vocabulary files at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "\", \"", ".", "join", "(", "s3_models", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "list", "(", "cls", ".", "vocab_files_names", ".", "values", "(", ")", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "# Get files from url, cache, or disk depending on the case", "\n", "", "", "try", ":", "\n", "            ", "resolved_vocab_files", "=", "{", "}", "\n", "for", "file_id", ",", "file_path", "in", "vocab_files", ".", "items", "(", ")", ":", "\n", "                ", "if", "file_path", "is", "None", ":", "\n", "                    ", "resolved_vocab_files", "[", "file_id", "]", "=", "None", "\n", "", "else", ":", "\n", "                    ", "resolved_vocab_files", "[", "file_id", "]", "=", "cached_path", "(", "\n", "file_path", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "force_download", "=", "force_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", ")", "\n", "", "", "", "except", "EnvironmentError", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "s3_models", ":", "\n", "                ", "msg", "=", "\"Couldn't reach server at '{}' to download vocabulary files.\"", "\n", "", "else", ":", "\n", "                ", "msg", "=", "(", "\n", "\"Model name '{}' was not found in tokenizers model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url to a directory containing vocabulary files \"", "\n", "\"named {}, but couldn't find such vocabulary files at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "\", \"", ".", "join", "(", "s3_models", ")", ",", "\n", "pretrained_model_name_or_path", ",", "\n", "list", "(", "cls", ".", "vocab_files_names", ".", "values", "(", ")", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "", "raise", "EnvironmentError", "(", "msg", ")", "\n", "\n", "", "for", "file_id", ",", "file_path", "in", "vocab_files", ".", "items", "(", ")", ":", "\n", "            ", "if", "file_path", "==", "resolved_vocab_files", "[", "file_id", "]", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading file {}\"", ".", "format", "(", "file_path", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading file {} from cache at {}\"", ".", "format", "(", "file_path", ",", "resolved_vocab_files", "[", "file_id", "]", ")", ")", "\n", "\n", "# Prepare tokenizer initialization kwargs", "\n", "# Did we saved some inputs and kwargs to reload ?", "\n", "", "", "tokenizer_config_file", "=", "resolved_vocab_files", ".", "pop", "(", "\"tokenizer_config_file\"", ",", "None", ")", "\n", "if", "tokenizer_config_file", "is", "not", "None", ":", "\n", "            ", "with", "open", "(", "tokenizer_config_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "tokenizer_config_handle", ":", "\n", "                ", "init_kwargs", "=", "json", ".", "load", "(", "tokenizer_config_handle", ")", "\n", "", "saved_init_inputs", "=", "init_kwargs", ".", "pop", "(", "\"init_inputs\"", ",", "(", ")", ")", "\n", "if", "not", "init_inputs", ":", "\n", "                ", "init_inputs", "=", "saved_init_inputs", "\n", "", "", "else", ":", "\n", "            ", "init_kwargs", "=", "init_configuration", "\n", "\n", "# Update with newly provided kwargs", "\n", "", "init_kwargs", ".", "update", "(", "kwargs", ")", "\n", "\n", "# Set max length if needed", "\n", "if", "pretrained_model_name_or_path", "in", "cls", ".", "max_model_input_sizes", ":", "\n", "# if we're using a pretrained model, ensure the tokenizer", "\n", "# wont index sequences longer than the number of positional embeddings", "\n", "            ", "max_len", "=", "cls", ".", "max_model_input_sizes", "[", "pretrained_model_name_or_path", "]", "\n", "if", "max_len", "is", "not", "None", "and", "isinstance", "(", "max_len", ",", "(", "int", ",", "float", ")", ")", ":", "\n", "                ", "init_kwargs", "[", "\"max_len\"", "]", "=", "min", "(", "init_kwargs", ".", "get", "(", "\"max_len\"", ",", "int", "(", "1e12", ")", ")", ",", "max_len", ")", "\n", "\n", "# Merge resolved_vocab_files arguments in init_kwargs.", "\n", "", "", "added_tokens_file", "=", "resolved_vocab_files", ".", "pop", "(", "\"added_tokens_file\"", ",", "None", ")", "\n", "special_tokens_map_file", "=", "resolved_vocab_files", ".", "pop", "(", "\"special_tokens_map_file\"", ",", "None", ")", "\n", "for", "args_name", ",", "file_path", "in", "resolved_vocab_files", ".", "items", "(", ")", ":", "\n", "            ", "if", "args_name", "not", "in", "init_kwargs", ":", "\n", "                ", "init_kwargs", "[", "args_name", "]", "=", "file_path", "\n", "", "", "if", "special_tokens_map_file", "is", "not", "None", ":", "\n", "            ", "with", "open", "(", "special_tokens_map_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "special_tokens_map_handle", ":", "\n", "                ", "special_tokens_map", "=", "json", ".", "load", "(", "special_tokens_map_handle", ")", "\n", "", "for", "key", ",", "value", "in", "special_tokens_map", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "not", "in", "init_kwargs", ":", "\n", "                    ", "init_kwargs", "[", "key", "]", "=", "value", "\n", "\n", "# Instantiate tokenizer.", "\n", "", "", "", "try", ":", "\n", "            ", "tokenizer", "=", "cls", "(", "*", "init_inputs", ",", "**", "init_kwargs", ")", "\n", "", "except", "OSError", ":", "\n", "            ", "OSError", "(", "\n", "\"Unable to load vocabulary from file. \"", "\n", "\"Please check that the provided vocabulary is accessible and not corrupted.\"", "\n", ")", "\n", "\n", "# Save inputs and kwargs for saving and re-loading with ``save_pretrained``", "\n", "", "tokenizer", ".", "init_inputs", "=", "init_inputs", "\n", "tokenizer", ".", "init_kwargs", "=", "init_kwargs", "\n", "\n", "# Add supplementary tokens.", "\n", "if", "added_tokens_file", "is", "not", "None", ":", "\n", "            ", "with", "open", "(", "added_tokens_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "added_tokens_handle", ":", "\n", "                ", "added_tok_encoder", "=", "json", ".", "load", "(", "added_tokens_handle", ")", "\n", "", "added_tok_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "added_tok_encoder", ".", "items", "(", ")", "}", "\n", "tokenizer", ".", "added_tokens_encoder", ".", "update", "(", "added_tok_encoder", ")", "\n", "tokenizer", ".", "added_tokens_decoder", ".", "update", "(", "added_tok_decoder", ")", "\n", "\n", "", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.save_pretrained": [[482, 522], ["os.path.join", "os.path.join", "os.path.join", "copy.deepcopy", "copy.deepcopy", "tokenization_utils.PreTrainedTokenizer.vocab_files_names.keys", "tokenization_utils.PreTrainedTokenizer.save_vocabulary", "os.path.isdir", "logger.error", "copy.deepcopy.pop", "open", "f.write", "open", "f.write", "open", "f.write", "json.dumps", "json.dumps", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.save_vocabulary"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the tokenizer vocabulary files together with:\n                - added tokens,\n                - special-tokens-to-class-attributes-mapping,\n                - tokenizer instantiation positional and keywords inputs (e.g. do_lower_case for Bert).\n\n            This won't save modifications other than (added tokens and special token mapping) you may have\n            applied to the tokenizer after the instantiation (e.g. modifying tokenizer.do_lower_case after creation).\n\n            This method make sure the full tokenizer can then be re-loaded using the :func:`~transformers.PreTrainedTokenizer.from_pretrained` class method.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Saving directory ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "\n", "", "special_tokens_map_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "SPECIAL_TOKENS_MAP_FILE", ")", "\n", "added_tokens_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "ADDED_TOKENS_FILE", ")", "\n", "tokenizer_config_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "TOKENIZER_CONFIG_FILE", ")", "\n", "\n", "tokenizer_config", "=", "copy", ".", "deepcopy", "(", "self", ".", "init_kwargs", ")", "\n", "tokenizer_config", "[", "\"init_inputs\"", "]", "=", "copy", ".", "deepcopy", "(", "self", ".", "init_inputs", ")", "\n", "for", "file_id", "in", "self", ".", "vocab_files_names", ".", "keys", "(", ")", ":", "\n", "            ", "tokenizer_config", ".", "pop", "(", "file_id", ",", "None", ")", "\n", "\n", "", "with", "open", "(", "tokenizer_config_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "tokenizer_config", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "with", "open", "(", "special_tokens_map_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "special_tokens_map", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "with", "open", "(", "added_tokens_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "if", "self", ".", "added_tokens_encoder", ":", "\n", "                ", "out_str", "=", "json", ".", "dumps", "(", "self", ".", "added_tokens_encoder", ",", "ensure_ascii", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "out_str", "=", "\"{}\"", "\n", "", "f", ".", "write", "(", "out_str", ")", "\n", "\n", "", "vocab_files", "=", "self", ".", "save_vocabulary", "(", "save_directory", ")", "\n", "\n", "return", "vocab_files", "+", "(", "special_tokens_map_file", ",", "added_tokens_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.save_vocabulary": [[523, 530], ["None"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the tokenizer vocabulary to a directory. This method does *NOT* save added tokens\n            and special token mappings.\n\n            Please use :func:`~transformers.PreTrainedTokenizer.save_pretrained` `()` to save the full Tokenizer state if you want to reload it using the :func:`~transformers.PreTrainedTokenizer.from_pretrained` class method.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.vocab_size": [[531, 534], ["None"], "methods", ["None"], ["", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "\"\"\" Size of the base vocabulary (without the added tokens) \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.__len__": [[535, 538], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\" Size of the full vocabulary with the added tokens \"\"\"", "\n", "return", "self", ".", "vocab_size", "+", "len", "(", "self", ".", "added_tokens_encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.add_tokens": [[539, 583], ["dict", "tokenization_utils.PreTrainedTokenizer.added_tokens_encoder.update", "set().union", "tokenization_utils.PreTrainedTokenizer.added_tokens_decoder.update", "len", "isinstance", "set", "tokenization_utils.PreTrainedTokenizer.init_kwargs.get", "token.lower.lower.lower", "to_add_tokens.append", "logger.info", "dict.items", "set", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "enumerate", "tokenization_utils.PreTrainedTokenizer.added_tokens_encoder.keys", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "add_tokens", "(", "self", ",", "new_tokens", ")", ":", "\n", "        ", "\"\"\"\n        Add a list of new tokens to the tokenizer class. If the new tokens are not in the\n        vocabulary, they are added to it with indices starting from length of the current vocabulary.\n\n        Args:\n            new_tokens: list of string. Each string is a token to add. Tokens are only added if they are not already in the vocabulary (tested by checking if the tokenizer assign the index of the ``unk_token`` to them).\n\n        Returns:\n            Number of tokens added to the vocabulary.\n\n        Examples::\n\n            # Let's see how to increase the vocabulary of Bert model and tokenizer\n            tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n            model = BertModel.from_pretrained('bert-base-uncased')\n\n            num_added_toks = tokenizer.add_tokens(['new_tok1', 'my_new-tok2'])\n            print('We have added', num_added_toks, 'tokens')\n            model.resize_token_embeddings(len(tokenizer))  # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e. the length of the tokenizer.\n        \"\"\"", "\n", "if", "not", "new_tokens", ":", "\n", "            ", "return", "0", "\n", "\n", "", "to_add_tokens", "=", "[", "]", "\n", "for", "token", "in", "new_tokens", ":", "\n", "            ", "assert", "isinstance", "(", "token", ",", "str", ")", "\n", "if", "self", ".", "init_kwargs", ".", "get", "(", "\"do_lower_case\"", ",", "False", ")", "and", "token", "not", "in", "self", ".", "all_special_tokens", ":", "\n", "                ", "token", "=", "token", ".", "lower", "(", ")", "\n", "", "if", "(", "\n", "token", "!=", "self", ".", "unk_token", "\n", "and", "self", ".", "convert_tokens_to_ids", "(", "token", ")", "==", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "unk_token", ")", "\n", "and", "token", "not", "in", "to_add_tokens", "\n", ")", ":", "\n", "                ", "to_add_tokens", ".", "append", "(", "token", ")", "\n", "logger", ".", "info", "(", "\"Adding %s to the vocabulary\"", ",", "token", ")", "\n", "\n", "", "", "added_tok_encoder", "=", "dict", "(", "(", "tok", ",", "len", "(", "self", ")", "+", "i", ")", "for", "i", ",", "tok", "in", "enumerate", "(", "to_add_tokens", ")", ")", "\n", "added_tok_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "added_tok_encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "added_tokens_encoder", ".", "update", "(", "added_tok_encoder", ")", "\n", "self", ".", "unique_added_tokens_encoder", "=", "set", "(", "self", ".", "added_tokens_encoder", ".", "keys", "(", ")", ")", ".", "union", "(", "set", "(", "self", ".", "all_special_tokens", ")", ")", "\n", "self", ".", "added_tokens_decoder", ".", "update", "(", "added_tok_decoder", ")", "\n", "\n", "return", "len", "(", "to_add_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.num_added_tokens": [[584, 602], ["len", "tokenization_utils.PreTrainedTokenizer.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens"], ["", "def", "num_added_tokens", "(", "self", ",", "pair", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Returns the number of added tokens when encoding a sequence with special tokens.\n\n        Note:\n            This encodes inputs and checks the number of added tokens, and is therefore not efficient. Do not put this\n            inside your training loop.\n\n        Args:\n            pair: Returns the number of added tokens in the case of a sequence pair if set to True, returns the\n                number of added tokens in the case of a single sequence if set to False.\n\n        Returns:\n            Number of tokens added to sequences\n        \"\"\"", "\n", "token_ids_0", "=", "[", "]", "\n", "token_ids_1", "=", "[", "]", "\n", "return", "len", "(", "self", ".", "build_inputs_with_special_tokens", "(", "token_ids_0", ",", "token_ids_1", "if", "pair", "else", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.add_special_tokens": [[603, 656], ["special_tokens_dict.items", "logger.info", "setattr", "tokenization_utils.PreTrainedTokenizer.add_tokens", "isinstance", "tokenization_utils.PreTrainedTokenizer.add_tokens", "isinstance", "all", "isinstance"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.add_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.add_tokens"], ["", "def", "add_special_tokens", "(", "self", ",", "special_tokens_dict", ")", ":", "\n", "        ", "\"\"\"\n        Add a dictionary of special tokens (eos, pad, cls...) to the encoder and link them\n        to class attributes. If special tokens are NOT in the vocabulary, they are added\n        to it (indexed starting from the last index of the current vocabulary).\n\n        Using `add_special_tokens` will ensure your special tokens can be used in several ways:\n\n        - special tokens are carefully handled by the tokenizer (they are never split)\n        - you can easily refer to special tokens using tokenizer class attributes like `tokenizer.cls_token`. This makes it easy to develop model-agnostic training and fine-tuning scripts.\n\n        When possible, special tokens are already registered for provided pretrained models (ex: BertTokenizer cls_token is already registered to be '[CLS]' and XLM's one is also registered to be '</s>')\n\n        Args:\n            special_tokens_dict: dict of string. Keys should be in the list of predefined special attributes:\n                [``bos_token``, ``eos_token``, ``unk_token``, ``sep_token``, ``pad_token``, ``cls_token``, ``mask_token``,\n                ``additional_special_tokens``].\n\n                Tokens are only added if they are not already in the vocabulary (tested by checking if the tokenizer assign the index of the ``unk_token`` to them).\n\n        Returns:\n            Number of tokens added to the vocabulary.\n\n        Examples::\n\n            # Let's see how to add a new classification token to GPT-2\n            tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n            model = GPT2Model.from_pretrained('gpt2')\n\n            special_tokens_dict = {'cls_token': '<CLS>'}\n\n            num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n            print('We have added', num_added_toks, 'tokens')\n            model.resize_token_embeddings(len(tokenizer))  # Notice: resize_token_embeddings expect to receive the full size of the new vocabulary, i.e. the length of the tokenizer.\n\n            assert tokenizer.cls_token == '<CLS>'\n        \"\"\"", "\n", "if", "not", "special_tokens_dict", ":", "\n", "            ", "return", "0", "\n", "\n", "", "added_tokens", "=", "0", "\n", "for", "key", ",", "value", "in", "special_tokens_dict", ".", "items", "(", ")", ":", "\n", "            ", "assert", "key", "in", "self", ".", "SPECIAL_TOKENS_ATTRIBUTES", "\n", "if", "key", "==", "\"additional_special_tokens\"", ":", "\n", "                ", "assert", "isinstance", "(", "value", ",", "(", "list", ",", "tuple", ")", ")", "and", "all", "(", "isinstance", "(", "t", ",", "str", ")", "for", "t", "in", "value", ")", "\n", "added_tokens", "+=", "self", ".", "add_tokens", "(", "value", ")", "\n", "", "else", ":", "\n", "                ", "assert", "isinstance", "(", "value", ",", "str", ")", "\n", "added_tokens", "+=", "self", ".", "add_tokens", "(", "[", "value", "]", ")", "\n", "", "logger", ".", "info", "(", "\"Assigning %s to the %s key of the tokenizer\"", ",", "value", ",", "key", ")", "\n", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "\n", "", "return", "added_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.tokenize": [[657, 725], ["tokenization_utils.PreTrainedTokenizer.init_kwargs.get", "tokenization_utils.PreTrainedTokenizer.tokenize.split_on_tokens"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "text", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Converts a string in a sequence of tokens (string), using the tokenizer.\n            Split in words for word-based vocabulary or sub-words for sub-word-based\n            vocabularies (BPE/SentencePieces/WordPieces).\n\n            Take care of added tokens.\n\n            text: The sequence to be encoded.\n            **kwargs: passed to the child `self.tokenize()` method\n        \"\"\"", "\n", "all_special_tokens", "=", "self", ".", "all_special_tokens", "\n", "\n", "def", "lowercase_text", "(", "t", ")", ":", "\n", "# convert non-special tokens to lowercase", "\n", "            ", "escaped_special_toks", "=", "[", "re", ".", "escape", "(", "s_tok", ")", "for", "s_tok", "in", "all_special_tokens", "]", "\n", "pattern", "=", "r\"(\"", "+", "r\"|\"", ".", "join", "(", "escaped_special_toks", ")", "+", "r\")|\"", "+", "r\"(.+?)\"", "\n", "return", "re", ".", "sub", "(", "pattern", ",", "lambda", "m", ":", "m", ".", "groups", "(", ")", "[", "0", "]", "or", "m", ".", "groups", "(", ")", "[", "1", "]", ".", "lower", "(", ")", ",", "t", ")", "\n", "\n", "", "if", "self", ".", "init_kwargs", ".", "get", "(", "\"do_lower_case\"", ",", "False", ")", ":", "\n", "            ", "text", "=", "lowercase_text", "(", "text", ")", "\n", "\n", "", "def", "split_on_token", "(", "tok", ",", "text", ")", ":", "\n", "            ", "result", "=", "[", "]", "\n", "split_text", "=", "text", ".", "split", "(", "tok", ")", "\n", "for", "i", ",", "sub_text", "in", "enumerate", "(", "split_text", ")", ":", "\n", "                ", "sub_text", "=", "sub_text", ".", "strip", "(", ")", "\n", "if", "i", "==", "0", "and", "not", "sub_text", ":", "\n", "                    ", "result", "+=", "[", "tok", "]", "\n", "", "elif", "i", "==", "len", "(", "split_text", ")", "-", "1", ":", "\n", "                    ", "if", "sub_text", ":", "\n", "                        ", "result", "+=", "[", "sub_text", "]", "\n", "", "else", ":", "\n", "                        ", "pass", "\n", "", "", "else", ":", "\n", "                    ", "if", "sub_text", ":", "\n", "                        ", "result", "+=", "[", "sub_text", "]", "\n", "", "result", "+=", "[", "tok", "]", "\n", "", "", "return", "result", "\n", "\n", "", "def", "split_on_tokens", "(", "tok_list", ",", "text", ")", ":", "\n", "            ", "if", "not", "text", ".", "strip", "(", ")", ":", "\n", "                ", "return", "[", "]", "\n", "", "if", "not", "tok_list", ":", "\n", "                ", "return", "self", ".", "_tokenize", "(", "text", ",", "**", "kwargs", ")", "\n", "\n", "", "tokenized_text", "=", "[", "]", "\n", "text_list", "=", "[", "text", "]", "\n", "for", "tok", "in", "tok_list", ":", "\n", "                ", "tokenized_text", "=", "[", "]", "\n", "for", "sub_text", "in", "text_list", ":", "\n", "                    ", "if", "sub_text", "not", "in", "self", ".", "unique_added_tokens_encoder", ":", "\n", "                        ", "tokenized_text", "+=", "split_on_token", "(", "tok", ",", "sub_text", ")", "\n", "", "else", ":", "\n", "                        ", "tokenized_text", "+=", "[", "sub_text", "]", "\n", "", "", "text_list", "=", "tokenized_text", "\n", "\n", "", "return", "list", "(", "\n", "itertools", ".", "chain", ".", "from_iterable", "(", "\n", "(", "\n", "self", ".", "_tokenize", "(", "token", ",", "**", "kwargs", ")", "if", "token", "not", "in", "self", ".", "unique_added_tokens_encoder", "else", "[", "token", "]", "\n", "for", "token", "in", "tokenized_text", "\n", ")", "\n", ")", "\n", ")", "\n", "\n", "", "added_tokens", "=", "self", ".", "unique_added_tokens_encoder", "\n", "tokenized_text", "=", "split_on_tokens", "(", "added_tokens", ",", "text", ")", "\n", "return", "tokenized_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer._tokenize": [[726, 734], ["None"], "methods", ["None"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Converts a string in a sequence of tokens (string), using the tokenizer.\n            Split in words for word-based vocabulary or sub-words for sub-word-based\n            vocabularies (BPE/SentencePieces/WordPieces).\n\n            Do NOT take care of added tokens.\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids": [[735, 749], ["isinstance", "tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc", "ids.append", "tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a single token, or a sequence of tokens, (str) in a single integer id\n            (resp. a sequence of ids), using the vocabulary.\n        \"\"\"", "\n", "if", "tokens", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "isinstance", "(", "tokens", ",", "str", ")", ":", "\n", "            ", "return", "self", ".", "_convert_token_to_id_with_added_voc", "(", "tokens", ")", "\n", "\n", "", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "ids", ".", "append", "(", "self", ".", "_convert_token_to_id_with_added_voc", "(", "token", ")", ")", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer._convert_token_to_id_with_added_voc": [[750, 757], ["tokenization_utils.PreTrainedTokenizer._convert_token_to_id"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer._convert_token_to_id"], ["", "def", "_convert_token_to_id_with_added_voc", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "is", "None", ":", "\n", "            ", "return", "None", "\n", "\n", "", "if", "token", "in", "self", ".", "added_tokens_encoder", ":", "\n", "            ", "return", "self", ".", "added_tokens_encoder", "[", "token", "]", "\n", "", "return", "self", ".", "_convert_token_to_id", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer._convert_token_to_id": [[758, 760], ["None"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode": [[761, 820], ["tokenization_utils.PreTrainedTokenizer.encode_plus"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus"], ["", "def", "encode", "(", "\n", "self", ",", "\n", "text", ",", "\n", "text_pair", "=", "None", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", "max_length", "=", "None", ",", "\n", "stride", "=", "0", ",", "\n", "truncation_strategy", "=", "\"longest_first\"", ",", "\n", "pad_to_max_length", "=", "False", ",", "\n", "return_tensors", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Converts a string in a sequence of ids (integer), using the tokenizer and vocabulary.\n\n        Same as doing ``self.convert_tokens_to_ids(self.tokenize(text))``.\n\n        Args:\n            text: The first sequence to be encoded. This can be a string, a list of strings (tokenized string using\n                the `tokenize` method) or a list of integers (tokenized string ids using the `convert_tokens_to_ids`\n                method)\n            text_pair: Optional second sequence to be encoded. This can be a string, a list of strings (tokenized\n                string using the `tokenize` method) or a list of integers (tokenized string ids using the\n                `convert_tokens_to_ids` method)\n            add_special_tokens: if set to ``True``, the sequences will be encoded with the special tokens relative\n                to their model.\n            max_length: if set to a number, will limit the total sequence returned so that it has a maximum length.\n                If there are overflowing tokens, those will be added to the returned dictionary\n            stride: if set to a number along with max_length, the overflowing tokens returned will contain some tokens\n                from the main sequence returned. The value of this argument defines the number of additional tokens.\n            truncation_strategy: string selected in the following options:\n                - 'longest_first' (default) Iteratively reduce the inputs sequence until the input is under max_length\n                    starting from the longest one at each token (when there is a pair of input sequences)\n                - 'only_first': Only truncate the first sequence\n                - 'only_second': Only truncate the second sequence\n                - 'do_not_truncate': Does not truncate (raise an error if the input sequence is longer than max_length)\n            pad_to_max_length: if set to True, the returned sequences will be padded according to the model's padding side and\n                padding index, up to their max length. If no max length is specified, the padding is done up to the model's max length.\n                The tokenizer padding sides are handled by the following strings:\n                - 'left': pads on the left of the sequences\n                - 'right': pads on the right of the sequences\n                Defaults to False: no padding.\n            return_tensors: (optional) can be set to 'tf' or 'pt' to return respectively TensorFlow tf.constant\n                or PyTorch torch.Tensor instead of a list of python integers.\n            **kwargs: passed to the `self.tokenize()` method\n        \"\"\"", "\n", "encoded_inputs", "=", "self", ".", "encode_plus", "(", "\n", "text", ",", "\n", "text_pair", "=", "text_pair", ",", "\n", "max_length", "=", "max_length", ",", "\n", "add_special_tokens", "=", "add_special_tokens", ",", "\n", "stride", "=", "stride", ",", "\n", "truncation_strategy", "=", "truncation_strategy", ",", "\n", "pad_to_max_length", "=", "pad_to_max_length", ",", "\n", "return_tensors", "=", "return_tensors", ",", "\n", "**", "kwargs", "\n", ")", "\n", "\n", "return", "encoded_inputs", "[", "\"input_ids\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus": [[821, 924], ["tokenization_utils.PreTrainedTokenizer.encode_plus.get_input_ids"], "methods", ["None"], ["", "def", "encode_plus", "(", "\n", "self", ",", "\n", "text", ",", "\n", "text_pair", "=", "None", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", "max_length", "=", "None", ",", "\n", "stride", "=", "0", ",", "\n", "truncation_strategy", "=", "\"longest_first\"", ",", "\n", "pad_to_max_length", "=", "False", ",", "\n", "return_tensors", "=", "None", ",", "\n", "return_token_type_ids", "=", "True", ",", "\n", "return_attention_mask", "=", "True", ",", "\n", "return_overflowing_tokens", "=", "False", ",", "\n", "return_special_tokens_mask", "=", "False", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Returns a dictionary containing the encoded sequence or sequence pair and additional informations:\n        the mask for sequence classification and the overflowing elements if a ``max_length`` is specified.\n\n        Args:\n            text: The first sequence to be encoded. This can be a string, a list of strings (tokenized string using\n                the `tokenize` method) or a list of integers (tokenized string ids using the `convert_tokens_to_ids`\n                method)\n            text_pair: Optional second sequence to be encoded. This can be a string, a list of strings (tokenized\n                string using the `tokenize` method) or a list of integers (tokenized string ids using the\n                `convert_tokens_to_ids` method)\n            add_special_tokens: if set to ``True``, the sequences will be encoded with the special tokens relative\n                to their model.\n            max_length: if set to a number, will limit the total sequence returned so that it has a maximum length.\n                If there are overflowing tokens, those will be added to the returned dictionary\n            stride: if set to a number along with max_length, the overflowing tokens returned will contain some tokens\n                from the main sequence returned. The value of this argument defines the number of additional tokens.\n            truncation_strategy: string selected in the following options:\n                - 'longest_first' (default) Iteratively reduce the inputs sequence until the input is under max_length\n                    starting from the longest one at each token (when there is a pair of input sequences)\n                - 'only_first': Only truncate the first sequence\n                - 'only_second': Only truncate the second sequence\n                - 'do_not_truncate': Does not truncate (raise an error if the input sequence is longer than max_length)\n            pad_to_max_length: if set to True, the returned sequences will be padded according to the model's padding side and\n                padding index, up to their max length. If no max length is specified, the padding is done up to the model's max length.\n                The tokenizer padding sides are handled by the following strings:\n                - 'left': pads on the left of the sequences\n                - 'right': pads on the right of the sequences\n                Defaults to False: no padding.\n            return_tensors: (optional) can be set to 'tf' or 'pt' to return respectively TensorFlow tf.constant\n                or PyTorch torch.Tensor instead of a list of python integers.\n            return_token_type_ids: (optional) Set to False to avoid returning token_type_ids (default True).\n            return_attention_mask: (optional) Set to False to avoir returning attention mask (default True)\n            return_overflowing_tokens: (optional) Set to True to return overflowing token information (default False).\n            return_special_tokens_mask: (optional) Set to True to return special tokens mask information (default False).\n            **kwargs: passed to the `self.tokenize()` method\n\n        Return:\n            A Dictionary of shape::\n\n                {\n                    input_ids: list[int],\n                    token_type_ids: list[int] if return_token_type_ids is True (default)\n                    attention_mask: list[int] if return_attention_mask is True (default)\n                    overflowing_tokens: list[int] if a ``max_length`` is specified and return_overflowing_tokens is True\n                    num_truncated_tokens: int if a ``max_length`` is specified and return_overflowing_tokens is True\n                    special_tokens_mask: list[int] if ``add_special_tokens`` if set to ``True`` and return_special_tokens_mask is True\n                }\n\n            With the fields:\n                ``input_ids``: list of token ids to be fed to a model\n                ``token_type_ids``: list of token type ids to be fed to a model\n                ``attention_mask``: list of indices specifying which tokens should be attended to by the model\n                ``overflowing_tokens``: list of overflowing tokens if a max length is specified.\n                ``num_truncated_tokens``: number of overflowing tokens a ``max_length`` is specified\n                ``special_tokens_mask``: if adding special tokens, this is a list of [0, 1], with 0 specifying special added\n                tokens and 1 specifying sequence tokens.\n        \"\"\"", "\n", "\n", "def", "get_input_ids", "(", "text", ")", ":", "\n", "            ", "if", "isinstance", "(", "text", ",", "str", ")", ":", "\n", "                ", "return", "self", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenize", "(", "text", ",", "**", "kwargs", ")", ")", "\n", "", "elif", "isinstance", "(", "text", ",", "(", "list", ",", "tuple", ")", ")", "and", "len", "(", "text", ")", ">", "0", "and", "isinstance", "(", "text", "[", "0", "]", ",", "str", ")", ":", "\n", "                ", "return", "self", ".", "convert_tokens_to_ids", "(", "text", ")", "\n", "", "elif", "isinstance", "(", "text", ",", "(", "list", ",", "tuple", ")", ")", "and", "len", "(", "text", ")", ">", "0", "and", "isinstance", "(", "text", "[", "0", "]", ",", "int", ")", ":", "\n", "                ", "return", "text", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Input is not valid. Should be a string, a list/tuple of strings or a list/tuple of integers.\"", "\n", ")", "\n", "\n", "", "", "first_ids", "=", "get_input_ids", "(", "text", ")", "\n", "second_ids", "=", "get_input_ids", "(", "text_pair", ")", "if", "text_pair", "is", "not", "None", "else", "None", "\n", "\n", "return", "self", ".", "prepare_for_model", "(", "\n", "first_ids", ",", "\n", "pair_ids", "=", "second_ids", ",", "\n", "max_length", "=", "max_length", ",", "\n", "pad_to_max_length", "=", "pad_to_max_length", ",", "\n", "add_special_tokens", "=", "add_special_tokens", ",", "\n", "stride", "=", "stride", ",", "\n", "truncation_strategy", "=", "truncation_strategy", ",", "\n", "return_tensors", "=", "return_tensors", ",", "\n", "return_attention_mask", "=", "return_attention_mask", ",", "\n", "return_token_type_ids", "=", "return_token_type_ids", ",", "\n", "return_overflowing_tokens", "=", "return_overflowing_tokens", ",", "\n", "return_special_tokens_mask", "=", "return_special_tokens_mask", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.batch_encode_plus": [[926, 1027], ["max", "isinstance", "tokenization_utils.PreTrainedTokenizer.encode_plus", "tokenization_utils.PreTrainedTokenizer.items", "map", "batch_outputs.items", "file_utils.is_tf_available", "len", "batch_outputs[].append", "tf.abs", "torch.abs", "len", "len", "file_utils.is_tf_available", "tf.constant", "file_utils.is_torch_available", "torch.tensor", "logger.warning", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_tf_available", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_tf_available", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_torch_available"], ["", "def", "batch_encode_plus", "(", "\n", "self", ",", "\n", "batch_text_or_text_pairs", "=", "None", ",", "\n", "add_special_tokens", "=", "False", ",", "\n", "max_length", "=", "None", ",", "\n", "stride", "=", "0", ",", "\n", "truncation_strategy", "=", "\"longest_first\"", ",", "\n", "return_tensors", "=", "None", ",", "\n", "return_input_lengths", "=", "False", ",", "\n", "return_attention_masks", "=", "False", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Returns a dictionary containing the encoded sequence or sequence pair and additional information:\n        the mask for sequence classification and the overflowing elements if a ``max_length`` is specified.\n\n        Args:\n            batch_text_or_text_pairs: Batch of sequences or pair of sequences to be encoded.\n                This can be a list of string/string-sequences/int-sequences or a list of pair of\n                string/string-sequences/int-sequence (see details in encode_plus)\n            add_special_tokens: if set to ``True``, the sequences will be encoded with the special tokens relative\n                to their model.\n            max_length: if set to a number, will limit the total sequence returned so that it has a maximum length.\n                If there are overflowing tokens, those will be added to the returned dictionary`\n            stride: if set to a number along with max_length, the overflowing tokens returned will contain some tokens\n                from the main sequence returned. The value of this argument defines the number of additional tokens.\n            truncation_strategy: string selected in the following options:\n                - 'longest_first' (default) Iteratively reduce the inputs sequence until the input is under max_length\n                    starting from the longest one at each token (when there is a pair of input sequences)\n                - 'only_first': Only truncate the first sequence\n                - 'only_second': Only truncate the second sequence\n                - 'do_not_truncate': Does not truncate (raise an error if the input sequence is longer than max_length)\n            return_tensors: (optional) can be set to 'tf' or 'pt' to return respectively TensorFlow tf.constant\n                or PyTorch torch.Tensor instead of a list of python integers.\n            **kwargs: passed to the `self.tokenize()` method\n        \"\"\"", "\n", "batch_outputs", "=", "{", "}", "\n", "for", "ids_or_pair_ids", "in", "batch_text_or_text_pairs", ":", "\n", "            ", "if", "isinstance", "(", "ids_or_pair_ids", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "                ", "assert", "len", "(", "ids_or_pair_ids", ")", "==", "2", "\n", "ids", ",", "pair_ids", "=", "ids_or_pair_ids", "\n", "", "else", ":", "\n", "                ", "ids", ",", "pair_ids", "=", "ids_or_pair_ids", ",", "None", "\n", "", "outputs", "=", "self", ".", "encode_plus", "(", "\n", "ids", ",", "\n", "pair_ids", ",", "\n", "add_special_tokens", "=", "add_special_tokens", ",", "\n", "max_length", "=", "max_length", ",", "\n", "stride", "=", "stride", ",", "\n", "truncation_strategy", "=", "truncation_strategy", ",", "\n", "return_tensors", "=", "None", ",", "\n", ")", "\n", "\n", "# Append the non-padded length to the output", "\n", "if", "return_input_lengths", ":", "\n", "                ", "outputs", "[", "\"input_len\"", "]", "=", "len", "(", "outputs", "[", "\"input_ids\"", "]", ")", "\n", "\n", "", "for", "key", ",", "value", "in", "outputs", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "not", "in", "batch_outputs", ":", "\n", "                    ", "batch_outputs", "[", "key", "]", "=", "[", "]", "\n", "", "batch_outputs", "[", "key", "]", ".", "append", "(", "value", ")", "\n", "\n", "# Compute longest sequence size", "\n", "", "", "max_seq_len", "=", "max", "(", "map", "(", "len", ",", "batch_outputs", "[", "\"input_ids\"", "]", ")", ")", "\n", "\n", "if", "return_attention_masks", ":", "\n", "# Allow the model to not give any special attention to padded input", "\n", "            ", "batch_outputs", "[", "\"attention_mask\"", "]", "=", "[", "[", "0", "]", "*", "len", "(", "v", ")", "for", "v", "in", "batch_outputs", "[", "\"input_ids\"", "]", "]", "\n", "\n", "", "if", "return_tensors", "is", "not", "None", ":", "\n", "\n", "# Do the tensor conversion in batch", "\n", "            ", "for", "key", ",", "value", "in", "batch_outputs", ".", "items", "(", ")", ":", "\n", "\n", "                ", "padded_value", "=", "value", "\n", "if", "key", "!=", "\"input_len\"", ":", "\n", "# Padding handle", "\n", "                    ", "padded_value", "=", "[", "\n", "v", "+", "[", "self", ".", "pad_token_id", "if", "key", "==", "\"input_ids\"", "else", "1", "]", "*", "(", "max_seq_len", "-", "len", "(", "v", ")", ")", "\n", "for", "v", "in", "padded_value", "\n", "]", "\n", "\n", "", "if", "return_tensors", "==", "\"tf\"", "and", "is_tf_available", "(", ")", ":", "\n", "                    ", "batch_outputs", "[", "key", "]", "=", "tf", ".", "constant", "(", "padded_value", ")", "\n", "", "elif", "return_tensors", "==", "\"pt\"", "and", "is_torch_available", "(", ")", ":", "\n", "                    ", "batch_outputs", "[", "key", "]", "=", "torch", ".", "tensor", "(", "padded_value", ")", "\n", "", "elif", "return_tensors", "is", "not", "None", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"Unable to convert output to tensors format {}, PyTorch or TensorFlow is not available.\"", ".", "format", "(", "\n", "return_tensors", "\n", ")", "\n", ")", "\n", "\n", "# encoder_attention_mask requires 1 for real token, 0 for padding, just invert value", "\n", "", "", "", "if", "return_attention_masks", ":", "\n", "            ", "if", "is_tf_available", "(", ")", ":", "\n", "                ", "batch_outputs", "[", "\"attention_mask\"", "]", "=", "tf", ".", "abs", "(", "batch_outputs", "[", "\"attention_mask\"", "]", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "batch_outputs", "[", "\"attention_mask\"", "]", "=", "torch", ".", "abs", "(", "batch_outputs", "[", "\"attention_mask\"", "]", "-", "1", ")", "\n", "\n", "", "", "return", "batch_outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.prepare_for_model": [[1028, 1212], ["bool", "len", "len", "tokenization_utils.PreTrainedTokenizer.truncate_sequences", "tokenization_utils.PreTrainedTokenizer.build_inputs_with_special_tokens", "tokenization_utils.PreTrainedTokenizer.create_token_type_ids_from_sequences", "tokenization_utils.PreTrainedTokenizer.get_special_tokens_mask", "logger.warning", "logger.warning", "file_utils.is_tf_available", "tf.constant", "tf.constant", "tokenization_utils.PreTrainedTokenizer.num_added_tokens", "len", "len", "len", "tf.constant", "file_utils.is_torch_available", "torch.tensor", "torch.tensor", "len", "len", "ValueError", "len", "torch.tensor", "logger.warning", "len", "len", "len", "len", "str", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.truncate_sequences", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.create_token_type_ids_from_sequences", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.get_special_tokens_mask", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_tf_available", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.num_added_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_torch_available"], ["", "def", "prepare_for_model", "(", "\n", "self", ",", "\n", "ids", ",", "\n", "pair_ids", "=", "None", ",", "\n", "max_length", "=", "None", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", "stride", "=", "0", ",", "\n", "truncation_strategy", "=", "\"longest_first\"", ",", "\n", "pad_to_max_length", "=", "False", ",", "\n", "return_tensors", "=", "None", ",", "\n", "return_token_type_ids", "=", "True", ",", "\n", "return_attention_mask", "=", "True", ",", "\n", "return_overflowing_tokens", "=", "False", ",", "\n", "return_special_tokens_mask", "=", "False", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Prepares a sequence of input id, or a pair of sequences of inputs ids so that it can be used by the model.\n        It adds special tokens, truncates\n        sequences if overflowing while taking into account the special tokens and manages a window stride for\n        overflowing tokens\n\n        Args:\n            ids: list of tokenized input ids. Can be obtained from a string by chaining the\n                `tokenize` and `convert_tokens_to_ids` methods.\n            pair_ids: Optional second list of input ids. Can be obtained from a string by chaining the\n                `tokenize` and `convert_tokens_to_ids` methods.\n            max_length: maximum length of the returned list. Will truncate by taking into account the special tokens.\n            add_special_tokens: if set to ``True``, the sequences will be encoded with the special tokens relative\n                to their model.\n            stride: window stride for overflowing tokens. Can be useful for edge effect removal when using sequential\n                list of inputs.\n            truncation_strategy: string selected in the following options:\n                - 'longest_first' (default) Iteratively reduce the inputs sequence until the input is under max_length\n                    starting from the longest one at each token (when there is a pair of input sequences)\n                - 'only_first': Only truncate the first sequence\n                - 'only_second': Only truncate the second sequence\n                - 'do_not_truncate': Does not truncate (raise an error if the input sequence is longer than max_length)\n            pad_to_max_length: if set to True, the returned sequences will be padded according to the model's padding side and\n                padding index, up to their max length. If no max length is specified, the padding is done up to the model's max length.\n                The tokenizer padding sides are handled by the following strings:\n                - 'left': pads on the left of the sequences\n                - 'right': pads on the right of the sequences\n                Defaults to False: no padding.\n            return_tensors: (optional) can be set to 'tf' or 'pt' to return respectively TensorFlow tf.constant\n                or PyTorch torch.Tensor instead of a list of python integers.\n            return_token_type_ids: (optional) Set to False to avoid returning token_type_ids (default True).\n            return_attention_mask: (optional) Set to False to avoid returning attention mask (default True)\n            return_overflowing_tokens: (optional) Set to True to return overflowing token information (default False).\n            return_special_tokens_mask: (optional) Set to True to return special tokens mask information (default False).\n\n        Return:\n            A Dictionary of shape::\n\n                {\n                    input_ids: list[int],\n                    token_type_ids: list[int] if return_token_type_ids is True (default)\n                    overflowing_tokens: list[int] if a ``max_length`` is specified and return_overflowing_tokens is True\n                    num_truncated_tokens: int if a ``max_length`` is specified and return_overflowing_tokens is True\n                    special_tokens_mask: list[int] if ``add_special_tokens`` if set to ``True`` and return_special_tokens_mask is True\n                }\n\n            With the fields:\n                ``input_ids``: list of token ids to be fed to a model\n                ``token_type_ids``: list of token type ids to be fed to a model\n\n                ``overflowing_tokens``: list of overflowing tokens if a max length is specified.\n                ``num_truncated_tokens``: number of overflowing tokens a ``max_length`` is specified\n                ``special_tokens_mask``: if adding special tokens, this is a list of [0, 1], with 0 specifying special added\n                tokens and 1 specifying sequence tokens.\n        \"\"\"", "\n", "pair", "=", "bool", "(", "pair_ids", "is", "not", "None", ")", "\n", "len_ids", "=", "len", "(", "ids", ")", "\n", "len_pair_ids", "=", "len", "(", "pair_ids", ")", "if", "pair", "else", "0", "\n", "\n", "encoded_inputs", "=", "{", "}", "\n", "\n", "# Handle max sequence length", "\n", "total_len", "=", "len_ids", "+", "len_pair_ids", "+", "(", "self", ".", "num_added_tokens", "(", "pair", "=", "pair", ")", "if", "add_special_tokens", "else", "0", ")", "\n", "if", "max_length", "and", "total_len", ">", "max_length", ":", "\n", "            ", "ids", ",", "pair_ids", ",", "overflowing_tokens", "=", "self", ".", "truncate_sequences", "(", "\n", "ids", ",", "\n", "pair_ids", "=", "pair_ids", ",", "\n", "num_tokens_to_remove", "=", "total_len", "-", "max_length", ",", "\n", "truncation_strategy", "=", "truncation_strategy", ",", "\n", "stride", "=", "stride", ",", "\n", ")", "\n", "if", "return_overflowing_tokens", ":", "\n", "                ", "encoded_inputs", "[", "\"overflowing_tokens\"", "]", "=", "overflowing_tokens", "\n", "encoded_inputs", "[", "\"num_truncated_tokens\"", "]", "=", "total_len", "-", "max_length", "\n", "\n", "# Handle special_tokens", "\n", "", "", "if", "add_special_tokens", ":", "\n", "            ", "sequence", "=", "self", ".", "build_inputs_with_special_tokens", "(", "ids", ",", "pair_ids", ")", "\n", "token_type_ids", "=", "self", ".", "create_token_type_ids_from_sequences", "(", "ids", ",", "pair_ids", ")", "\n", "", "else", ":", "\n", "            ", "sequence", "=", "ids", "+", "pair_ids", "if", "pair", "else", "ids", "\n", "token_type_ids", "=", "[", "0", "]", "*", "len", "(", "ids", ")", "+", "(", "[", "1", "]", "*", "len", "(", "pair_ids", ")", "if", "pair", "else", "[", "]", ")", "\n", "\n", "", "if", "return_special_tokens_mask", ":", "\n", "            ", "encoded_inputs", "[", "\"special_tokens_mask\"", "]", "=", "self", ".", "get_special_tokens_mask", "(", "ids", ",", "pair_ids", ")", "\n", "\n", "", "encoded_inputs", "[", "\"input_ids\"", "]", "=", "sequence", "\n", "if", "return_token_type_ids", ":", "\n", "            ", "encoded_inputs", "[", "\"token_type_ids\"", "]", "=", "token_type_ids", "\n", "\n", "", "if", "max_length", "and", "len", "(", "encoded_inputs", "[", "\"input_ids\"", "]", ")", ">", "max_length", ":", "\n", "            ", "encoded_inputs", "[", "\"input_ids\"", "]", "=", "encoded_inputs", "[", "\"input_ids\"", "]", "[", ":", "max_length", "]", "\n", "if", "return_token_type_ids", ":", "\n", "                ", "encoded_inputs", "[", "\"token_type_ids\"", "]", "=", "encoded_inputs", "[", "\"token_type_ids\"", "]", "[", ":", "max_length", "]", "\n", "", "if", "return_special_tokens_mask", ":", "\n", "                ", "encoded_inputs", "[", "\"special_tokens_mask\"", "]", "=", "encoded_inputs", "[", "\"special_tokens_mask\"", "]", "[", ":", "max_length", "]", "\n", "\n", "", "", "if", "max_length", "is", "None", "and", "len", "(", "encoded_inputs", "[", "\"input_ids\"", "]", ")", ">", "self", ".", "max_len", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Token indices sequence length is longer than the specified maximum sequence length \"", "\n", "\"for this model ({} > {}). Running this sequence through the model will result in \"", "\n", "\"indexing errors\"", ".", "format", "(", "len", "(", "ids", ")", ",", "self", ".", "max_len", ")", "\n", ")", "\n", "\n", "", "needs_to_be_padded", "=", "pad_to_max_length", "and", "(", "\n", "max_length", "\n", "and", "len", "(", "encoded_inputs", "[", "\"input_ids\"", "]", ")", "<", "max_length", "\n", "or", "max_length", "is", "None", "\n", "and", "len", "(", "encoded_inputs", "[", "\"input_ids\"", "]", ")", "<", "self", ".", "max_len", "\n", "and", "self", ".", "max_len", "<=", "10000", "\n", ")", "\n", "\n", "if", "pad_to_max_length", "and", "max_length", "is", "None", "and", "self", ".", "max_len", ">", "10000", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Sequence can't be padded as no maximum length is specified and the model maximum length is too high.\"", "\n", ")", "\n", "\n", "", "if", "needs_to_be_padded", ":", "\n", "            ", "difference", "=", "(", "max_length", "if", "max_length", "is", "not", "None", "else", "self", ".", "max_len", ")", "-", "len", "(", "encoded_inputs", "[", "\"input_ids\"", "]", ")", "\n", "\n", "if", "self", ".", "padding_side", "==", "\"right\"", ":", "\n", "                ", "if", "return_attention_mask", ":", "\n", "                    ", "encoded_inputs", "[", "\"attention_mask\"", "]", "=", "[", "1", "]", "*", "len", "(", "encoded_inputs", "[", "\"input_ids\"", "]", ")", "+", "[", "0", "]", "*", "difference", "\n", "", "if", "return_token_type_ids", ":", "\n", "                    ", "encoded_inputs", "[", "\"token_type_ids\"", "]", "=", "(", "\n", "encoded_inputs", "[", "\"token_type_ids\"", "]", "+", "[", "self", ".", "pad_token_type_id", "]", "*", "difference", "\n", ")", "\n", "", "if", "return_special_tokens_mask", ":", "\n", "                    ", "encoded_inputs", "[", "\"special_tokens_mask\"", "]", "=", "encoded_inputs", "[", "\"special_tokens_mask\"", "]", "+", "[", "1", "]", "*", "difference", "\n", "", "encoded_inputs", "[", "\"input_ids\"", "]", "=", "encoded_inputs", "[", "\"input_ids\"", "]", "+", "[", "self", ".", "pad_token_id", "]", "*", "difference", "\n", "", "elif", "self", ".", "padding_side", "==", "\"left\"", ":", "\n", "                ", "if", "return_attention_mask", ":", "\n", "                    ", "encoded_inputs", "[", "\"attention_mask\"", "]", "=", "[", "0", "]", "*", "difference", "+", "[", "1", "]", "*", "len", "(", "encoded_inputs", "[", "\"input_ids\"", "]", ")", "\n", "", "if", "return_token_type_ids", ":", "\n", "                    ", "encoded_inputs", "[", "\"token_type_ids\"", "]", "=", "[", "self", ".", "pad_token_type_id", "]", "*", "difference", "+", "encoded_inputs", "[", "\n", "\"token_type_ids\"", "\n", "]", "\n", "", "if", "return_special_tokens_mask", ":", "\n", "                    ", "encoded_inputs", "[", "\"special_tokens_mask\"", "]", "=", "[", "1", "]", "*", "difference", "+", "encoded_inputs", "[", "\"special_tokens_mask\"", "]", "\n", "", "encoded_inputs", "[", "\"input_ids\"", "]", "=", "[", "self", ".", "pad_token_id", "]", "*", "difference", "+", "encoded_inputs", "[", "\"input_ids\"", "]", "\n", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Invalid padding strategy:\"", "+", "str", "(", "self", ".", "padding_side", ")", ")", "\n", "\n", "", "", "elif", "return_attention_mask", ":", "\n", "            ", "encoded_inputs", "[", "\"attention_mask\"", "]", "=", "[", "1", "]", "*", "len", "(", "encoded_inputs", "[", "\"input_ids\"", "]", ")", "\n", "\n", "# Prepare inputs as tensors if asked", "\n", "", "if", "return_tensors", "==", "\"tf\"", "and", "is_tf_available", "(", ")", ":", "\n", "            ", "encoded_inputs", "[", "\"input_ids\"", "]", "=", "tf", ".", "constant", "(", "[", "encoded_inputs", "[", "\"input_ids\"", "]", "]", ")", "\n", "encoded_inputs", "[", "\"token_type_ids\"", "]", "=", "tf", ".", "constant", "(", "[", "encoded_inputs", "[", "\"token_type_ids\"", "]", "]", ")", "\n", "\n", "if", "\"attention_mask\"", "in", "encoded_inputs", ":", "\n", "                ", "encoded_inputs", "[", "\"attention_mask\"", "]", "=", "tf", ".", "constant", "(", "[", "encoded_inputs", "[", "\"attention_mask\"", "]", "]", ")", "\n", "\n", "", "", "elif", "return_tensors", "==", "\"pt\"", "and", "is_torch_available", "(", ")", ":", "\n", "            ", "encoded_inputs", "[", "\"input_ids\"", "]", "=", "torch", ".", "tensor", "(", "[", "encoded_inputs", "[", "\"input_ids\"", "]", "]", ")", "\n", "encoded_inputs", "[", "\"token_type_ids\"", "]", "=", "torch", ".", "tensor", "(", "[", "encoded_inputs", "[", "\"token_type_ids\"", "]", "]", ")", "\n", "\n", "if", "\"attention_mask\"", "in", "encoded_inputs", ":", "\n", "                ", "encoded_inputs", "[", "\"attention_mask\"", "]", "=", "torch", ".", "tensor", "(", "[", "encoded_inputs", "[", "\"attention_mask\"", "]", "]", ")", "\n", "", "", "elif", "return_tensors", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Unable to convert output to tensors format {}, PyTorch or TensorFlow is not available.\"", ".", "format", "(", "\n", "return_tensors", "\n", ")", "\n", ")", "\n", "\n", "", "return", "encoded_inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.truncate_sequences": [[1213, 1256], ["range", "min", "len", "min", "len", "len", "min", "len", "len", "len", "ValueError", "ValueError", "len"], "methods", ["None"], ["", "def", "truncate_sequences", "(", "\n", "self", ",", "ids", ",", "pair_ids", "=", "None", ",", "num_tokens_to_remove", "=", "0", ",", "truncation_strategy", "=", "\"longest_first\"", ",", "stride", "=", "0", "\n", ")", ":", "\n", "        ", "\"\"\"Truncates a sequence pair in place to the maximum length.\n            truncation_strategy: string selected in the following options:\n                - 'longest_first' (default) Iteratively reduce the inputs sequence until the input is under max_length\n                    starting from the longest one at each token (when there is a pair of input sequences).\n                    Overflowing tokens only contains overflow from the first sequence.\n                - 'only_first': Only truncate the first sequence. raise an error if the first sequence is shorter or equal to than num_tokens_to_remove.\n                - 'only_second': Only truncate the second sequence\n                - 'do_not_truncate': Does not truncate (raise an error if the input sequence is longer than max_length)\n        \"\"\"", "\n", "if", "num_tokens_to_remove", "<=", "0", ":", "\n", "            ", "return", "ids", ",", "pair_ids", ",", "[", "]", "\n", "\n", "", "if", "truncation_strategy", "==", "\"longest_first\"", ":", "\n", "            ", "overflowing_tokens", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_tokens_to_remove", ")", ":", "\n", "                ", "if", "pair_ids", "is", "None", "or", "len", "(", "ids", ")", ">", "len", "(", "pair_ids", ")", ":", "\n", "                    ", "overflowing_tokens", "=", "[", "ids", "[", "-", "1", "]", "]", "+", "overflowing_tokens", "\n", "ids", "=", "ids", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                    ", "pair_ids", "=", "pair_ids", "[", ":", "-", "1", "]", "\n", "", "", "window_len", "=", "min", "(", "len", "(", "ids", ")", ",", "stride", ")", "\n", "if", "window_len", ">", "0", ":", "\n", "                ", "overflowing_tokens", "=", "ids", "[", "-", "window_len", ":", "]", "+", "overflowing_tokens", "\n", "", "", "elif", "truncation_strategy", "==", "\"only_first\"", ":", "\n", "            ", "assert", "len", "(", "ids", ")", ">", "num_tokens_to_remove", "\n", "window_len", "=", "min", "(", "len", "(", "ids", ")", ",", "stride", "+", "num_tokens_to_remove", ")", "\n", "overflowing_tokens", "=", "ids", "[", "-", "window_len", ":", "]", "\n", "ids", "=", "ids", "[", ":", "-", "num_tokens_to_remove", "]", "\n", "", "elif", "truncation_strategy", "==", "\"only_second\"", ":", "\n", "            ", "assert", "pair_ids", "is", "not", "None", "and", "len", "(", "pair_ids", ")", ">", "num_tokens_to_remove", "\n", "window_len", "=", "min", "(", "len", "(", "pair_ids", ")", ",", "stride", "+", "num_tokens_to_remove", ")", "\n", "overflowing_tokens", "=", "pair_ids", "[", "-", "window_len", ":", "]", "\n", "pair_ids", "=", "pair_ids", "[", ":", "-", "num_tokens_to_remove", "]", "\n", "", "elif", "truncation_strategy", "==", "\"do_not_truncate\"", ":", "\n", "            ", "raise", "ValueError", "(", "\"Input sequence are too long for max_length. Please select a truncation strategy.\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Truncation_strategy should be selected in ['longest_first', 'only_first', 'only_second', 'do_not_truncate']\"", "\n", ")", "\n", "", "return", "(", "ids", ",", "pair_ids", ",", "overflowing_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.create_token_type_ids_from_sequences": [[1257, 1261], ["len", "len", "len"], "methods", ["None"], ["", "def", "create_token_type_ids_from_sequences", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "len", "(", "token_ids_0", ")", "*", "[", "0", "]", "\n", "", "return", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", "+", "[", "1", "]", "*", "len", "(", "token_ids_1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.build_inputs_with_special_tokens": [[1262, 1273], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n        by concatenating and adding special tokens.\n        A RoBERTa sequence has the following format:\n            single sequence: <s> X </s>\n            pair of sequences: <s> A </s></s> B </s>\n        \"\"\"", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "token_ids_0", "\n", "", "return", "token_ids_0", "+", "token_ids_1", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.get_special_tokens_mask": [[1274, 1290], ["len", "len"], "methods", ["None"], ["", "def", "get_special_tokens_mask", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ",", "already_has_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n\n        Args:\n            token_ids_0: list of ids (must not contain special tokens)\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n                for sequence pairs\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n                special tokens for the model\n\n        Returns:\n            A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.\n        \"\"\"", "\n", "return", "[", "0", "]", "*", "(", "(", "len", "(", "token_ids_1", ")", "if", "token_ids_1", "else", "0", ")", "+", "len", "(", "token_ids_0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens": [[1291, 1313], ["isinstance", "int", "tokenization_utils.PreTrainedTokenizer._convert_id_to_token", "tokens.append", "tokens.append", "tokenization_utils.PreTrainedTokenizer._convert_id_to_token"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer._convert_id_to_token", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer._convert_id_to_token"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ",", "skip_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\" Converts a single index or a sequence of indices (integers) in a token \"\n            (resp.) a sequence of tokens (str), using the vocabulary and added tokens.\n\n            Args:\n                skip_special_tokens: Don't decode special tokens (self.all_special_tokens). Default: False\n        \"\"\"", "\n", "if", "isinstance", "(", "ids", ",", "int", ")", ":", "\n", "            ", "if", "ids", "in", "self", ".", "added_tokens_decoder", ":", "\n", "                ", "return", "self", ".", "added_tokens_decoder", "[", "ids", "]", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "_convert_id_to_token", "(", "ids", ")", "\n", "", "", "tokens", "=", "[", "]", "\n", "for", "index", "in", "ids", ":", "\n", "            ", "index", "=", "int", "(", "index", ")", "\n", "if", "skip_special_tokens", "and", "index", "in", "self", ".", "all_special_ids", ":", "\n", "                ", "continue", "\n", "", "if", "index", "in", "self", ".", "added_tokens_decoder", ":", "\n", "                ", "tokens", ".", "append", "(", "self", ".", "added_tokens_decoder", "[", "index", "]", ")", "\n", "", "else", ":", "\n", "                ", "tokens", ".", "append", "(", "self", ".", "_convert_id_to_token", "(", "index", ")", ")", "\n", "", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer._convert_id_to_token": [[1314, 1316], ["None"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_string": [[1317, 1323], ["tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string.\n            The most simple way to do it is ' '.join(self.convert_ids_to_tokens(token_ids))\n            but we often want to remove sub-word tokenization artifacts at the same time.\n        \"\"\"", "\n", "return", "\" \"", ".", "join", "(", "self", ".", "convert_ids_to_tokens", "(", "tokens", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode": [[1324, 1361], ["tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens", "sub_texts.append", "tokenization_utils.PreTrainedTokenizer.clean_up_tokenization", "sub_texts.append", "current_sub_text.append", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_string", "sub_texts.append", "tokenization_utils.PreTrainedTokenizer.convert_tokens_to_string"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.clean_up_tokenization", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.convert_tokens_to_string", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.convert_tokens_to_string"], ["", "def", "decode", "(", "self", ",", "token_ids", ",", "skip_special_tokens", "=", "False", ",", "clean_up_tokenization_spaces", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Converts a sequence of ids (integer) in a string, using the tokenizer and vocabulary\n        with options to remove special tokens and clean up tokenization spaces.\n        Similar to doing ``self.convert_tokens_to_string(self.convert_ids_to_tokens(token_ids))``.\n\n        Args:\n            token_ids: list of tokenized input ids. Can be obtained using the `encode` or `encode_plus` methods.\n            skip_special_tokens: if set to True, will replace special tokens.\n            clean_up_tokenization_spaces: if set to True, will clean up the tokenization spaces.\n        \"\"\"", "\n", "filtered_tokens", "=", "self", ".", "convert_ids_to_tokens", "(", "token_ids", ",", "skip_special_tokens", "=", "skip_special_tokens", ")", "\n", "\n", "# To avoid mixing byte-level and unicode for byte-level BPT", "\n", "# we need to build string separatly for added tokens and byte-level tokens", "\n", "# cf. https://github.com/huggingface/transformers/issues/1133", "\n", "sub_texts", "=", "[", "]", "\n", "current_sub_text", "=", "[", "]", "\n", "for", "token", "in", "filtered_tokens", ":", "\n", "            ", "if", "skip_special_tokens", "and", "token", "in", "self", ".", "all_special_ids", ":", "\n", "                ", "continue", "\n", "", "if", "token", "in", "self", ".", "added_tokens_encoder", ":", "\n", "                ", "if", "current_sub_text", ":", "\n", "                    ", "sub_texts", ".", "append", "(", "self", ".", "convert_tokens_to_string", "(", "current_sub_text", ")", ")", "\n", "current_sub_text", "=", "[", "]", "\n", "", "sub_texts", ".", "append", "(", "token", ")", "\n", "", "else", ":", "\n", "                ", "current_sub_text", ".", "append", "(", "token", ")", "\n", "", "", "if", "current_sub_text", ":", "\n", "            ", "sub_texts", ".", "append", "(", "self", ".", "convert_tokens_to_string", "(", "current_sub_text", ")", ")", "\n", "", "text", "=", "\" \"", ".", "join", "(", "sub_texts", ")", "\n", "\n", "if", "clean_up_tokenization_spaces", ":", "\n", "            ", "clean_text", "=", "self", ".", "clean_up_tokenization", "(", "text", ")", "\n", "return", "clean_text", "\n", "", "else", ":", "\n", "            ", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.special_tokens_map": [[1362, 1373], ["getattr"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "special_tokens_map", "(", "self", ")", ":", "\n", "        ", "\"\"\" A dictionary mapping special token class attribute (cls_token, unk_token...) to their\n            values ('<unk>', '<cls>'...)\n        \"\"\"", "\n", "set_attr", "=", "{", "}", "\n", "for", "attr", "in", "self", ".", "SPECIAL_TOKENS_ATTRIBUTES", ":", "\n", "            ", "attr_value", "=", "getattr", "(", "self", ",", "\"_\"", "+", "attr", ")", "\n", "if", "attr_value", ":", "\n", "                ", "set_attr", "[", "attr", "]", "=", "attr_value", "\n", "", "", "return", "set_attr", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.all_special_tokens": [[1374, 1385], ["set_attr.values", "list", "set", "isinstance", "list"], "methods", ["None"], ["", "@", "property", "\n", "def", "all_special_tokens", "(", "self", ")", ":", "\n", "        ", "\"\"\" List all the special tokens ('<unk>', '<cls>'...) mapped to class attributes\n            (cls_token, unk_token...).\n        \"\"\"", "\n", "all_toks", "=", "[", "]", "\n", "set_attr", "=", "self", ".", "special_tokens_map", "\n", "for", "attr_value", "in", "set_attr", ".", "values", "(", ")", ":", "\n", "            ", "all_toks", "=", "all_toks", "+", "(", "list", "(", "attr_value", ")", "if", "isinstance", "(", "attr_value", ",", "(", "list", ",", "tuple", ")", ")", "else", "[", "attr_value", "]", ")", "\n", "", "all_toks", "=", "list", "(", "set", "(", "all_toks", ")", ")", "\n", "return", "all_toks", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.all_special_ids": [[1386, 1394], ["tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "@", "property", "\n", "def", "all_special_ids", "(", "self", ")", ":", "\n", "        ", "\"\"\" List the vocabulary indices of the special tokens ('<unk>', '<cls>'...) mapped to\n            class attributes (cls_token, unk_token...).\n        \"\"\"", "\n", "all_toks", "=", "self", ".", "all_special_tokens", "\n", "all_ids", "=", "self", ".", "convert_tokens_to_ids", "(", "all_toks", ")", "\n", "return", "all_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.clean_up_tokenization": [[1395, 1413], ["out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace", "out_string.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace().replace().replace().replace().replace().replace().replace().replace().replace().replace().replace.replace"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "clean_up_tokenization", "(", "out_string", ")", ":", "\n", "        ", "\"\"\" Clean up a list of simple English tokenization artifacts like spaces before punctuations and abreviated forms.\n        \"\"\"", "\n", "out_string", "=", "(", "\n", "out_string", ".", "replace", "(", "\" .\"", ",", "\".\"", ")", "\n", ".", "replace", "(", "\" ?\"", ",", "\"?\"", ")", "\n", ".", "replace", "(", "\" !\"", ",", "\"!\"", ")", "\n", ".", "replace", "(", "\" ,\"", ",", "\",\"", ")", "\n", ".", "replace", "(", "\" ' \"", ",", "\"'\"", ")", "\n", ".", "replace", "(", "\" n't\"", ",", "\"n't\"", ")", "\n", ".", "replace", "(", "\" 'm\"", ",", "\"'m\"", ")", "\n", ".", "replace", "(", "\" do not\"", ",", "\" don't\"", ")", "\n", ".", "replace", "(", "\" 's\"", ",", "\"'s\"", ")", "\n", ".", "replace", "(", "\" 've\"", ",", "\"'ve\"", ")", "\n", ".", "replace", "(", "\" 're\"", ",", "\"'re\"", ")", "\n", ")", "\n", "return", "out_string", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.dummy_inputs": [[77, 85], ["torch.tensor"], "methods", ["None"], ["@", "property", "\n", "def", "dummy_inputs", "(", "self", ")", ":", "\n", "        ", "\"\"\" Dummy inputs to do a forward pass in the network.\n\n        Returns:\n            torch.Tensor with dummy inputs\n        \"\"\"", "\n", "return", "{", "\"input_ids\"", ":", "torch", ".", "tensor", "(", "DUMMY_INPUTS", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.__init__": [[86, 98], ["torch.nn.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["", "def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "PreTrainedModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "PretrainedConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `PretrainedConfig`. \"", "\n", "\"To create a model from a pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", ")", "\n", "# Save config in model", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.base_model": [[99, 102], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "base_model", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.get_input_embeddings": [[103, 111], ["getattr", "getattr.get_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.get_input_embeddings"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "\"\"\" Get model's input embeddings\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "\n", "if", "base_model", "is", "not", "self", ":", "\n", "            ", "return", "base_model", ".", "get_input_embeddings", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.set_input_embeddings": [[112, 120], ["getattr", "getattr.set_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.set_input_embeddings"], ["", "", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\" Set model's input embeddings\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "\n", "if", "base_model", "is", "not", "self", ":", "\n", "            ", "base_model", ".", "set_input_embeddings", "(", "value", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.get_output_embeddings": [[121, 126], ["None"], "methods", ["None"], ["", "", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "\"\"\" Get model's output embeddings\n            Return None if the model doesn't have output embeddings\n        \"\"\"", "\n", "return", "None", "# Overwrite for models with output embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.tie_weights": [[127, 134], ["modeling_utils.PreTrainedModel.get_output_embeddings", "modeling_utils.PreTrainedModel._tie_or_clone_weights", "modeling_utils.PreTrainedModel.get_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxForMaskedLM.get_output_embeddings", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.get_input_embeddings"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "output_embeddings", "=", "self", ".", "get_output_embeddings", "(", ")", "\n", "if", "output_embeddings", "is", "not", "None", ":", "\n", "            ", "self", ".", "_tie_or_clone_weights", "(", "output_embeddings", ",", "self", ".", "get_input_embeddings", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights": [[135, 152], ["torch.nn.Parameter", "hasattr", "torch.nn.functional.pad", "hasattr", "hasattr", "input_embeddings.weight.clone"], "methods", ["None"], ["", "", "def", "_tie_or_clone_weights", "(", "self", ",", "output_embeddings", ",", "input_embeddings", ")", ":", "\n", "        ", "\"\"\" Tie or clone module weights depending of weither we are using TorchScript or not\n        \"\"\"", "\n", "if", "self", ".", "config", ".", "torchscript", ":", "\n", "            ", "output_embeddings", ".", "weight", "=", "nn", ".", "Parameter", "(", "input_embeddings", ".", "weight", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "output_embeddings", ".", "weight", "=", "input_embeddings", ".", "weight", "\n", "\n", "", "if", "hasattr", "(", "output_embeddings", ",", "\"bias\"", ")", "and", "output_embeddings", ".", "bias", "is", "not", "None", ":", "\n", "            ", "output_embeddings", ".", "bias", ".", "data", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "\n", "output_embeddings", ".", "bias", ".", "data", ",", "\n", "(", "0", ",", "output_embeddings", ".", "weight", ".", "shape", "[", "0", "]", "-", "output_embeddings", ".", "bias", ".", "shape", "[", "0", "]", ")", ",", "\n", "\"constant\"", ",", "\n", "0", ",", "\n", ")", "\n", "", "if", "hasattr", "(", "output_embeddings", ",", "\"out_features\"", ")", "and", "hasattr", "(", "input_embeddings", ",", "\"num_embeddings\"", ")", ":", "\n", "            ", "output_embeddings", ".", "out_features", "=", "input_embeddings", ".", "num_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.resize_token_embeddings": [[153, 179], ["getattr", "getattr._resize_token_embeddings", "modeling_utils.PreTrainedModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxMainLayer._resize_token_embeddings", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertForMaskedLM.tie_weights"], ["", "", "def", "resize_token_embeddings", "(", "self", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Resize input token embeddings matrix of the model if new_num_tokens != config.vocab_size.\n        Take care of tying weights embeddings afterwards if the model class has a `tie_weights()` method.\n\n        Arguments:\n\n            new_num_tokens: (`optional`) int:\n                New number of tokens in the embedding matrix. Increasing the size will add newly initialized vectors at the end. Reducing the size will remove vectors from the end.\n                If not provided or None: does nothing and just returns a pointer to the input tokens ``torch.nn.Embeddings`` Module of the model.\n\n        Return: ``torch.nn.Embeddings``\n            Pointer to the input tokens Embeddings Module of the model\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "# get the base model if needed", "\n", "model_embeds", "=", "base_model", ".", "_resize_token_embeddings", "(", "new_num_tokens", ")", "\n", "if", "new_num_tokens", "is", "None", ":", "\n", "            ", "return", "model_embeds", "\n", "\n", "# Update base model and current model config", "\n", "", "self", ".", "config", ".", "vocab_size", "=", "new_num_tokens", "\n", "base_model", ".", "vocab_size", "=", "new_num_tokens", "\n", "\n", "# Tie weights again if needed", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n", "return", "model_embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel._resize_token_embeddings": [[180, 185], ["modeling_utils.PreTrainedModel.get_input_embeddings", "modeling_utils.PreTrainedModel._get_resized_embeddings", "modeling_utils.PreTrainedModel.set_input_embeddings", "modeling_utils.PreTrainedModel.get_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.get_input_embeddings", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel._get_resized_embeddings", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.set_input_embeddings", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.get_input_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "old_embeddings", "=", "self", ".", "get_input_embeddings", "(", ")", "\n", "new_embeddings", "=", "self", ".", "_get_resized_embeddings", "(", "old_embeddings", ",", "new_num_tokens", ")", "\n", "self", ".", "set_input_embeddings", "(", "new_embeddings", ")", "\n", "return", "self", ".", "get_input_embeddings", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel._get_resized_embeddings": [[186, 219], ["old_embeddings.weight.size", "torch.nn.Embedding", "torch.nn.Embedding.to", "modeling_utils.PreTrainedModel._init_weights", "min"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxPreTrainedModel._init_weights"], ["", "def", "_get_resized_embeddings", "(", "self", ",", "old_embeddings", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Build a resized Embedding Module from a provided token Embedding Module.\n            Increasing the size will add newly initialized vectors at the end\n            Reducing the size will remove vectors from the end\n\n        Args:\n            new_num_tokens: (`optional`) int\n                New number of tokens in the embedding matrix.\n                Increasing the size will add newly initialized vectors at the end\n                Reducing the size will remove vectors from the end\n                If not provided or None: return the provided token Embedding Module.\n        Return: ``torch.nn.Embeddings``\n            Pointer to the resized Embedding Module or the old Embedding Module if new_num_tokens is None\n        \"\"\"", "\n", "if", "new_num_tokens", "is", "None", ":", "\n", "            ", "return", "old_embeddings", "\n", "\n", "", "old_num_tokens", ",", "old_embedding_dim", "=", "old_embeddings", ".", "weight", ".", "size", "(", ")", "\n", "if", "old_num_tokens", "==", "new_num_tokens", ":", "\n", "            ", "return", "old_embeddings", "\n", "\n", "# Build new embeddings", "\n", "", "new_embeddings", "=", "nn", ".", "Embedding", "(", "new_num_tokens", ",", "old_embedding_dim", ")", "\n", "new_embeddings", ".", "to", "(", "old_embeddings", ".", "weight", ".", "device", ")", "\n", "\n", "# initialize all new embeddings (in particular added tokens)", "\n", "self", ".", "_init_weights", "(", "new_embeddings", ")", "\n", "\n", "# Copy word embeddings from the previous weights", "\n", "num_tokens_to_copy", "=", "min", "(", "old_num_tokens", ",", "new_num_tokens", ")", "\n", "new_embeddings", ".", "weight", ".", "data", "[", ":", "num_tokens_to_copy", ",", ":", "]", "=", "old_embeddings", ".", "weight", ".", "data", "[", ":", "num_tokens_to_copy", ",", ":", "]", "\n", "\n", "return", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights": [[220, 231], ["modeling_utils.PreTrainedModel.apply", "modeling_utils.PreTrainedModel.tie_weights", "modeling_utils.PreTrainedModel.prune_heads"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertForMaskedLM.tie_weights", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Initialize and prunes weights if needed. \"\"\"", "\n", "# Initialize weights", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n", "# Prune heads if needed", "\n", "if", "self", ".", "config", ".", "pruned_heads", ":", "\n", "            ", "self", ".", "prune_heads", "(", "self", ".", "config", ".", "pruned_heads", ")", "\n", "\n", "# Tie weights if needed", "\n", "", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.prune_heads": [[232, 246], ["heads_to_prune.items", "modeling_utils.PreTrainedModel.base_model._prune_heads", "list", "set", "set", "modeling_utils.PreTrainedModel.config.pruned_heads.get"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel._prune_heads"], ["", "def", "prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the base model.\n\n            Arguments:\n\n                heads_to_prune: dict with keys being selected layer indices (`int`) and associated values being the list of heads to prune in said layer (list of `int`).\n                E.g. {1: [0, 2], 2: [2, 3]} will prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\n        \"\"\"", "\n", "# save new sets of pruned heads as union of previously stored pruned heads and newly pruned heads", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "union_heads", "=", "set", "(", "self", ".", "config", ".", "pruned_heads", ".", "get", "(", "layer", ",", "[", "]", ")", ")", "|", "set", "(", "heads", ")", "\n", "self", ".", "config", ".", "pruned_heads", "[", "layer", "]", "=", "list", "(", "union_heads", ")", "# Unfortunately we have to store it as list for JSON", "\n", "\n", "", "self", ".", "base_model", ".", "_prune_heads", "(", "heads_to_prune", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.save_pretrained": [[247, 265], ["os.path.isdir", "model_to_save.config.save_pretrained", "os.path.join", "torch.save", "logger.info", "hasattr", "model_to_save.state_dict"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a model and its configuration file to a directory, so that it\n            can be re-loaded using the `:func:`~transformers.PreTrainedModel.from_pretrained`` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "\n", "save_directory", "\n", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# Only save the model itself if we are using distributed training", "\n", "model_to_save", "=", "self", ".", "module", "if", "hasattr", "(", "self", ",", "\"module\"", ")", "else", "self", "\n", "\n", "# Save configuration file", "\n", "model_to_save", ".", "config", ".", "save_pretrained", "(", "save_directory", ")", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "WEIGHTS_NAME", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_model_file", ")", "\n", "logger", ".", "info", "(", "\"Model weights saved in {}\"", ".", "format", "(", "output_model_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.from_pretrained": [[266, 538], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "cls", "load_tf2_checkpoint_in_pytorch_model.tie_weights", "load_tf2_checkpoint_in_pytorch_model.eval", "isinstance", "cls.config_class.from_pretrained", "file_utils.cached_path.endswith", "torch.load.keys", "zip", "getattr", "torch.load.copy", "modeling_utils.PreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertForMaskedLM.tie_weights", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Instantiate a pretrained pytorch model from a pre-trained model configuration.\n\n        The model is set in evaluation mode by default using ``model.eval()`` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with ``model.train()``\n\n        The warning ``Weights from XXX not initialized from pretrained model`` means that the weights of XXX do not come pre-trained with the rest of the model.\n        It is up to you to train those weights with a downstream fine-tuning task.\n\n        The warning ``Weights from XXX not used in YYY`` means that the layer XXX is not used by YYY, therefore those weights are discarded.\n\n        Parameters:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n                - None if you are both providing the configuration and state dictionary (resp. with keyword arguments ``config`` and ``state_dict``)\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) one of:\n                    - an instance of a class derived from :class:`~transformers.PretrainedConfig`, or\n                    - a string valid as input to :func:`~transformers.PretrainedConfig.from_pretrained()`\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = BertModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = BertModel.from_pretrained('./test/saved_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = BertModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = BertConfig.from_json_file('./tf_model/my_tf_model_config.json')\n            model = BertModel.from_pretrained('./tf_model/my_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "config", "=", "kwargs", ".", "pop", "(", "\"config\"", ",", "None", ")", "\n", "state_dict", "=", "kwargs", ".", "pop", "(", "\"state_dict\"", ",", "None", ")", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "\"cache_dir\"", ",", "None", ")", "\n", "from_tf", "=", "kwargs", ".", "pop", "(", "\"from_tf\"", ",", "False", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "\"force_download\"", ",", "False", ")", "\n", "resume_download", "=", "kwargs", ".", "pop", "(", "\"resume_download\"", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "\"proxies\"", ",", "None", ")", "\n", "output_loading_info", "=", "kwargs", ".", "pop", "(", "\"output_loading_info\"", ",", "False", ")", "\n", "\n", "# Load config if we don't provide a configuration", "\n", "if", "not", "isinstance", "(", "config", ",", "PretrainedConfig", ")", ":", "\n", "            ", "config_path", "=", "config", "if", "config", "is", "not", "None", "else", "pretrained_model_name_or_path", "\n", "config", ",", "model_kwargs", "=", "cls", ".", "config_class", ".", "from_pretrained", "(", "\n", "config_path", ",", "\n", "*", "model_args", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "return_unused_kwargs", "=", "True", ",", "\n", "force_download", "=", "force_download", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "**", "kwargs", "\n", ")", "\n", "", "else", ":", "\n", "            ", "model_kwargs", "=", "kwargs", "\n", "\n", "# Load model", "\n", "", "if", "pretrained_model_name_or_path", "is", "not", "None", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                ", "archive_file", "=", "cls", ".", "pretrained_model_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "                ", "if", "from_tf", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", ")", ":", "\n", "# Load from a TF 1.0 checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", "\n", "", "elif", "from_tf", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a TF 2.0 checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a PyTorch checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "EnvironmentError", "(", "\n", "\"Error no file named {} found in directory {} or `from_tf` set to False\"", ".", "format", "(", "\n", "[", "WEIGHTS_NAME", ",", "TF2_WEIGHTS_NAME", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", "]", ",", "pretrained_model_name_or_path", "\n", ")", "\n", ")", "\n", "", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", ")", "or", "is_remote_url", "(", "pretrained_model_name_or_path", ")", ":", "\n", "                ", "archive_file", "=", "pretrained_model_name_or_path", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", "+", "\".index\"", ")", ":", "\n", "                ", "assert", "(", "\n", "from_tf", "\n", ")", ",", "\"We found a TensorFlow checkpoint at {}, please set from_tf to True to load from this checkpoint\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", "+", "\".index\"", "\n", ")", "\n", "archive_file", "=", "pretrained_model_name_or_path", "+", "\".index\"", "\n", "", "else", ":", "\n", "                ", "archive_file", "=", "hf_bucket_url", "(", "pretrained_model_name_or_path", ",", "postfix", "=", "WEIGHTS_NAME", ")", "\n", "if", "from_tf", ":", "\n", "                    ", "raise", "EnvironmentError", "(", "\n", "\"Loading a PyTorch model from a TF checkpoint is not supported when using a model identifier name.\"", "\n", ")", "\n", "\n", "# redirect to the cache, if necessary", "\n", "", "", "try", ":", "\n", "                ", "resolved_archive_file", "=", "cached_path", "(", "\n", "archive_file", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "force_download", "=", "force_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "                ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                    ", "msg", "=", "\"Couldn't reach server at '{}' to download pretrained weights.\"", ".", "format", "(", "archive_file", ")", "\n", "", "else", ":", "\n", "                    ", "msg", "=", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url to model weight files named one of {} but \"", "\n", "\"couldn't find any such file at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "\", \"", ".", "join", "(", "cls", ".", "pretrained_model_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ",", "\n", "[", "WEIGHTS_NAME", ",", "TF2_WEIGHTS_NAME", ",", "TF_WEIGHTS_NAME", "]", ",", "\n", ")", "\n", ")", "\n", "", "raise", "EnvironmentError", "(", "msg", ")", "\n", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "resolved_archive_file", "=", "None", "\n", "\n", "# Instantiate model.", "\n", "", "model", "=", "cls", "(", "config", ",", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "try", ":", "\n", "                ", "state_dict", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "\"cpu\"", ")", "\n", "", "except", "Exception", ":", "\n", "                ", "raise", "OSError", "(", "\n", "\"Unable to load weights from pytorch checkpoint file. \"", "\n", "\"If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. \"", "\n", ")", "\n", "\n", "", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "\n", "if", "from_tf", ":", "\n", "            ", "if", "resolved_archive_file", ".", "endswith", "(", "\".index\"", ")", ":", "\n", "# Load from a TensorFlow 1.X checkpoint - provided by original authors", "\n", "                ", "model", "=", "cls", ".", "load_tf_weights", "(", "model", ",", "config", ",", "resolved_archive_file", "[", ":", "-", "6", "]", ")", "# Remove the '.index'", "\n", "", "else", ":", "\n", "# Load from our TensorFlow 2.0 checkpoints", "\n", "                ", "try", ":", "\n", "                    ", "from", "transformers", "import", "load_tf2_checkpoint_in_pytorch_model", "\n", "\n", "model", "=", "load_tf2_checkpoint_in_pytorch_model", "(", "model", ",", "resolved_archive_file", ",", "allow_missing_keys", "=", "True", ")", "\n", "", "except", "ImportError", ":", "\n", "                    ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires both PyTorch and TensorFlow to be installed. Please see \"", "\n", "\"https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "", "", "", "else", ":", "\n", "# Convert old format to new format if needed from a PyTorch state_dict", "\n", "            ", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "                ", "new_key", "=", "None", "\n", "if", "\"gamma\"", "in", "key", ":", "\n", "                    ", "new_key", "=", "key", ".", "replace", "(", "\"gamma\"", ",", "\"weight\"", ")", "\n", "", "if", "\"beta\"", "in", "key", ":", "\n", "                    ", "new_key", "=", "key", ".", "replace", "(", "\"beta\"", ",", "\"bias\"", ")", "\n", "", "if", "new_key", ":", "\n", "                    ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "                ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "", "metadata", "=", "getattr", "(", "state_dict", ",", "\"_metadata\"", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "                ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "# PyTorch's `_load_from_state_dict` does not copy parameters in a module's descendants", "\n", "# so we need to apply the function recursively.", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "\"\"", ")", ":", "\n", "                ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", "\n", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                    ", "if", "child", "is", "not", "None", ":", "\n", "                        ", "load", "(", "child", ",", "prefix", "+", "name", "+", "\".\"", ")", "\n", "\n", "# Make sure we are able to load base models as well as derived models (with heads)", "\n", "", "", "", "start_prefix", "=", "\"\"", "\n", "model_to_load", "=", "model", "\n", "if", "not", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "any", "(", "\n", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", "\n", ")", ":", "\n", "                ", "start_prefix", "=", "cls", ".", "base_model_prefix", "+", "\".\"", "\n", "", "if", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "not", "any", "(", "\n", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", "\n", ")", ":", "\n", "                ", "model_to_load", "=", "getattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "\n", "\n", "", "load", "(", "model_to_load", ",", "prefix", "=", "start_prefix", ")", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", "\n", ")", "\n", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", "\n", ")", "\n", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"Error(s) in loading state_dict for {}:\\n\\t{}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", "\n", ")", "\n", ")", "\n", "\n", "", "", "model", ".", "tie_weights", "(", ")", "# make sure word embedding weights are still tied if needed", "\n", "\n", "# Set model in evaluation mode to desactivate DropOut modules by default", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "output_loading_info", ":", "\n", "            ", "loading_info", "=", "{", "\"missing_keys\"", ":", "missing_keys", ",", "\"unexpected_keys\"", ":", "unexpected_keys", ",", "\"error_msgs\"", ":", "error_msgs", "}", "\n", "return", "model", ",", "loading_info", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.prepare_inputs_for_generation": [[539, 541], ["None"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "{", "\"input_ids\"", ":", "input_ids", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.generate": [[542, 698], ["torch.no_grad", "isinstance", "isinstance", "modeling_utils.PreTrainedModel.get_output_embeddings", "AttributeError", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "torch.full", "input_ids.contiguous().view.contiguous().view.unsqueeze().expand", "input_ids.contiguous().view.contiguous().view.contiguous().view", "modeling_utils.PreTrainedModel._generate_beam_search", "modeling_utils.PreTrainedModel._generate_no_beam_search", "output.view.view.view", "input_ids.contiguous().view.contiguous().view.dim", "input_ids.contiguous().view.contiguous().view.unsqueeze", "input_ids.contiguous().view.contiguous().view.contiguous", "next", "modeling_utils.PreTrainedModel.parameters"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxForMaskedLM.get_output_embeddings", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel._generate_beam_search", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel._generate_no_beam_search"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "max_length", "=", "None", ",", "\n", "do_sample", "=", "None", ",", "\n", "num_beams", "=", "None", ",", "\n", "temperature", "=", "None", ",", "\n", "top_k", "=", "None", ",", "\n", "top_p", "=", "None", ",", "\n", "repetition_penalty", "=", "None", ",", "\n", "bos_token_id", "=", "None", ",", "\n", "pad_token_id", "=", "None", ",", "\n", "eos_token_ids", "=", "None", ",", "\n", "length_penalty", "=", "None", ",", "\n", "num_return_sequences", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Sequence generator for models with a LM head.\n\n        The method currently supports greedy or penalized greedy decoding, sampling with top-k or nucleus sampling\n        and beam-search.\n\n        Adapted in part from Facebook's XLM beam search code: https://github.com/facebookresearch/XLM\n\n        Params:\n            **input_ids**: (`optional`) `torch.LongTensor` of shape (1, sequence_length)\n                The sequence used as a prompt for the generation. If `None` the method initializes\n                it as an empty `torch.LongTensor` of shape (1,)\n            **max_length**: (`optional`) int\n                The max length of the sequence to be generated.  Between 1 and infinity. Default to 20.\n            **do_sample**: (`optional`) bool\n                If set to `False` we use greedy decoding; otherwise sampling. Default to greedy sampling.\n            **num_beams**: (`optional`) int\n                Number of beams for beam search. 1 means no beam serach. Default to 1.\n            **temperature**: (`optional`) float\n                The value used to module the next token probabilities.\n            **top_k**: (`optional`) int\n                The number of highest probability vocabulary tokens to keep for top-k-filtering. Between 1 and infinity. Default to 50.\n            **top_p**: (`optional`) float\n                The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Must be between 0 and 1. Default to 1.\n            **repetition_penalty**: (`optional`) float\n                The parameter for repetition penalty. Between 1.0 and + infinity. 1.0 means no penalty. Default to 1.\n            **bos_token_id**: (`optional`) int\n                Beginning of sentence token if no prompt is provided. Default to 0.\n            **eos_token_ids**: (`optional`) int or list of int\n                End of sequence token or list of tokens to stop the generation. Default to 0.\n            **length_penalty**: (`optional`) int\n                Exponential penalty to the length. Default to 0.\n            **length_penalty**: (`optional`) float\n                Exponential penalty to the length. Default to 1.\n            **num_return_sequences**: (`optional`) int\n                The number of independantly computed returned sequences for each element in the batch. Default to 1.\n        \"\"\"", "\n", "\n", "# We cannot generate if the model does not have a LM head", "\n", "if", "self", ".", "get_output_embeddings", "(", ")", "is", "None", ":", "\n", "            ", "raise", "AttributeError", "(", "\n", "\"You tried to generate sequences with a model that does not have a LM Head.\"", "\n", "\"Please use another model class (e.g. `OpenAIGPTLMHeadModel`)\"", "\n", ")", "\n", "\n", "", "max_length", "=", "max_length", "if", "max_length", "is", "not", "None", "else", "self", ".", "config", ".", "max_length", "\n", "do_sample", "=", "do_sample", "if", "do_sample", "is", "not", "None", "else", "self", ".", "config", ".", "do_sample", "\n", "num_beams", "=", "num_beams", "if", "num_beams", "is", "not", "None", "else", "self", ".", "config", ".", "num_beams", "\n", "temperature", "=", "temperature", "if", "temperature", "is", "not", "None", "else", "self", ".", "config", ".", "temperature", "\n", "top_k", "=", "top_k", "if", "top_k", "is", "not", "None", "else", "self", ".", "config", ".", "top_k", "\n", "top_p", "=", "top_p", "if", "top_p", "is", "not", "None", "else", "self", ".", "config", ".", "top_p", "\n", "repetition_penalty", "=", "repetition_penalty", "if", "repetition_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "repetition_penalty", "\n", "bos_token_id", "=", "bos_token_id", "if", "bos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "bos_token_id", "\n", "pad_token_id", "=", "pad_token_id", "if", "pad_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "pad_token_id", "\n", "eos_token_ids", "=", "eos_token_ids", "if", "eos_token_ids", "is", "not", "None", "else", "self", ".", "config", ".", "eos_token_ids", "\n", "length_penalty", "=", "length_penalty", "if", "length_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "length_penalty", "\n", "num_return_sequences", "=", "(", "\n", "num_return_sequences", "if", "num_return_sequences", "is", "not", "None", "else", "self", ".", "config", ".", "num_return_sequences", "\n", ")", "\n", "\n", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "batch_size", "=", "input_ids", ".", "shape", "[", "0", "]", "# overriden by the input batch_size", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "1", "\n", "", "if", "isinstance", "(", "eos_token_ids", ",", "int", ")", ":", "\n", "            ", "eos_token_ids", "=", "[", "eos_token_ids", "]", "\n", "\n", "", "assert", "isinstance", "(", "max_length", ",", "int", ")", "and", "max_length", ">", "0", ",", "\"`max_length` should be a strictely positive integer.\"", "\n", "assert", "isinstance", "(", "do_sample", ",", "bool", ")", ",", "\"`do_sample` should be a boolean.\"", "\n", "assert", "isinstance", "(", "num_beams", ",", "int", ")", "and", "num_beams", ">", "0", ",", "\"`num_beams` should be a strictely positive integer.\"", "\n", "# assert temperature >= 0, \"`temperature` should be positive.\"", "\n", "assert", "isinstance", "(", "top_k", ",", "int", ")", "and", "top_k", ">=", "0", ",", "\"`top_k` should be a positive integer.\"", "\n", "assert", "0", "<=", "top_p", "<=", "1", ",", "\"`top_p` should be between 0 and 1.\"", "\n", "assert", "repetition_penalty", ">=", "1.0", ",", "\"`repetition_penalty` should be >= 1.\"", "\n", "assert", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", ",", "\"`bos_token_id` should be a positive integer.\"", "\n", "assert", "isinstance", "(", "pad_token_id", ",", "int", ")", "and", "pad_token_id", ">=", "0", ",", "\"`pad_token_id` should be a positive integer.\"", "\n", "assert", "isinstance", "(", "eos_token_ids", ",", "(", "list", ",", "tuple", ")", ")", "and", "(", "\n", "e", ">=", "0", "for", "e", "in", "eos_token_ids", "\n", ")", ",", "\"`eos_token_ids` should be a positive integer or a list/tuple of positive integers.\"", "\n", "assert", "length_penalty", ">", "0", ",", "\"`length_penalty` should be strictely positive.\"", "\n", "assert", "(", "\n", "isinstance", "(", "num_return_sequences", ",", "int", ")", "and", "num_return_sequences", ">", "0", "\n", ")", ",", "\"`num_return_sequences` should be a strictely positive integer.\"", "\n", "\n", "if", "input_ids", "is", "None", ":", "\n", "            ", "input_ids", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ")", ",", "bos_token_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", ")", "\n", "", "else", ":", "\n", "            ", "assert", "input_ids", ".", "dim", "(", ")", "==", "2", ",", "\"Input prompt should be of shape (batch_size, sequence length).\"", "\n", "\n", "# current position and vocab size", "\n", "", "cur_len", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "vocab_size", "=", "self", ".", "config", ".", "vocab_size", "\n", "\n", "if", "num_return_sequences", "!=", "1", ":", "\n", "# Expand input to num return sequences", "\n", "            ", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_return_sequences", ",", "cur_len", ")", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch_size", "*", "num_return_sequences", ",", "cur_len", "\n", ")", "# (batch_size * num_return_sequences, cur_len)", "\n", "effective_batch_size", "=", "batch_size", "*", "num_return_sequences", "\n", "", "else", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "\n", "\n", "", "if", "num_beams", ">", "1", ":", "\n", "            ", "output", "=", "self", ".", "_generate_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_generate_no_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", ")", "\n", "\n", "", "if", "num_return_sequences", "!=", "1", ":", "\n", "            ", "output", "=", "output", ".", "view", "(", "batch_size", ",", "num_return_sequences", ",", "-", "1", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel._generate_no_beam_search": [[699, 761], ["torch.cat.new().fill_", "modeling_utils.PreTrainedModel.prepare_inputs_for_generation", "modeling_utils.PreTrainedModel.", "torch.cat", "input_ids[].masked_fill_", "torch.cat.new", "range", "modeling_utils.top_k_top_p_filtering", "torch.multinomial().squeeze", "torch.argmax", "torch.cat.new().fill_.mul_", "torch.cat.new().fill_.max", "torch.cat.new().fill_.to", "set", "tokens_to_add.unsqueeze", "tokens_to_add.ne().long", "input_ids[].tolist", "torch.multinomial", "torch.nn.functional.softmax", "tokens_to_add.ne"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMWithLMHeadModel.prepare_inputs_for_generation", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.top_k_top_p_filtering"], ["", "def", "_generate_no_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example without beam search (num_beams == 1).\n            All returned sequence are generated independantly.\n        \"\"\"", "\n", "# current position / max lengths / length of generated sentences / unfinished sentences", "\n", "unfinished_sents", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "1", ")", "\n", "\n", "# TODO: add cached compute states", "\n", "pasts", "=", "None", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "            ", "model_inputs", "=", "self", ".", "prepare_inputs_for_generation", "(", "input_ids", ",", "pasts", "=", "pasts", ")", "\n", "outputs", "=", "self", "(", "**", "model_inputs", ")", "\n", "next_token_logits", "=", "outputs", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "\n", "# repetition penalty from CTRL paper (https://arxiv.org/abs/1909.05858)", "\n", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "for", "previous_tokens", "in", "set", "(", "input_ids", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "                        ", "next_token_logits", "[", "i", ",", "previous_tokens", "]", "/=", "repetition_penalty", "\n", "\n", "", "", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", ">", "0", "and", "temperature", "!=", "1.0", ":", "\n", "                    ", "next_token_logits", "=", "next_token_logits", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "next_token_logits", "=", "top_k_top_p_filtering", "(", "next_token_logits", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ")", "\n", "# Sample", "\n", "next_token", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "# Greedy decoding", "\n", "                ", "next_token", "=", "torch", ".", "argmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# update generations and finished sentences", "\n", "", "tokens_to_add", "=", "next_token", "*", "unfinished_sents", "+", "pad_token_id", "*", "(", "1", "-", "unfinished_sents", ")", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", ",", "tokens_to_add", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "for", "eos_token_id", "in", "eos_token_ids", ":", "\n", "                ", "unfinished_sents", ".", "mul_", "(", "tokens_to_add", ".", "ne", "(", "eos_token_id", ")", ".", "long", "(", ")", ")", "\n", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# stop when there is a </s> in each sentence, or if we exceed the maximul length", "\n", "if", "unfinished_sents", ".", "max", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "# add eos_token_ids to unfinished sentences", "\n", "", "", "if", "cur_len", "==", "max_length", ":", "\n", "            ", "input_ids", "[", ":", ",", "-", "1", "]", ".", "masked_fill_", "(", "unfinished_sents", ".", "to", "(", "dtype", "=", "torch", ".", "bool", ")", ",", "eos_token_ids", "[", "0", "]", ")", "\n", "\n", "", "return", "input_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel._generate_beam_search": [[762, 929], ["torch.cat.unsqueeze().expand", "torch.cat.contiguous().view", "torch.zeros", "beam_scores.new.new.view", "torch.cat.new", "enumerate", "torch.cat.new().fill_", "enumerate", "modeling_utils.BeamHypotheses", "modeling_utils.PreTrainedModel.prepare_inputs_for_generation", "range", "beam_scores.new.new.new", "torch.cat.new", "torch.cat.new", "torch.cat", "all", "best.append", "torch.cat.unsqueeze", "torch.cat.contiguous", "range", "range", "modeling_utils.PreTrainedModel.", "range", "modeling_utils.top_k_top_p_filtering", "torch.multinomial", "torch.nn.functional.log_softmax", "torch.gather", "next_words.view.view.view", "next_scores.view.view.view", "torch.nn.functional.log_softmax", "_scores.view.view.view", "torch.topk", "next_scores.view.view.size", "next_words.view.view.size", "zip", "next_batch_beam.extend", "len", "max", "len", "torch.cat.new", "set", "torch.nn.functional.softmax", "beam_scores[].expand_as", "torch.nn.functional.log_softmax.size", "beam_scores[].expand_as", "generated_hyps[].is_done", "next_batch_beam.extend", "len", "len", "torch.cat.new.unsqueeze", "torch.cat.new.max().item", "input_ids[].tolist", "next_scores[].max().item", "generated_hyps[].add", "next_sent_beam.append", "len", "len", "word_id.item", "input_ids[].clone", "score.item", "torch.cat.new.max", "next_scores[].max"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMWithLMHeadModel.prepare_inputs_for_generation", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.top_k_top_p_filtering", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.BeamHypotheses.is_done", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.BeamHypotheses.add"], ["", "def", "_generate_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example with beam search.\n        \"\"\"", "\n", "# Expand input to num beams", "\n", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_beams", ",", "cur_len", ")", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", "*", "num_beams", ",", "cur_len", ")", "# (batch_size * num_beams, cur_len)", "\n", "\n", "# generated hypotheses", "\n", "generated_hyps", "=", "[", "\n", "BeamHypotheses", "(", "num_beams", ",", "max_length", ",", "length_penalty", ",", "early_stopping", "=", "False", ")", "for", "_", "in", "range", "(", "batch_size", ")", "\n", "]", "\n", "\n", "# scores for each sentence in the beam", "\n", "beam_scores", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "num_beams", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "beam_scores", "[", ":", ",", "1", ":", "]", "=", "-", "1e9", "\n", "beam_scores", "=", "beam_scores", ".", "view", "(", "-", "1", ")", "# shape (batch_size * num_beams,)", "\n", "\n", "# cache compute states", "\n", "pasts", "=", "None", "# self.prepare_pasts()", "\n", "\n", "# done sentences", "\n", "done", "=", "[", "False", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "            ", "model_inputs", "=", "self", ".", "prepare_inputs_for_generation", "(", "input_ids", ",", "pasts", "=", "pasts", ")", "\n", "scores", "=", "self", "(", "**", "model_inputs", ")", "[", "0", "]", "# (batch_size * num_beams, cur_len, vocab_size)", "\n", "scores", "=", "scores", "[", ":", ",", "-", "1", ",", ":", "]", "# (batch_size * num_beams, vocab_size)", "\n", "\n", "# repetition penalty (from CTRL paper https://arxiv.org/abs/1909.05858)", "\n", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_size", "*", "num_beams", ")", ":", "\n", "                    ", "for", "previous_tokens", "in", "set", "(", "input_ids", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "                        ", "scores", "[", "i", ",", "previous_tokens", "]", "/=", "repetition_penalty", "\n", "\n", "", "", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", ">", "0", "and", "temperature", "!=", "1.0", ":", "\n", "                    ", "scores", "=", "scores", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "scores", "=", "top_k_top_p_filtering", "(", "\n", "scores", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ",", "min_tokens_to_keep", "=", "2", "\n", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# Sample 2 next words for each beam (so we have some spare tokens and match output of greedy beam search)", "\n", "next_words", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "2", ")", "# (batch_size * num_beams, 2)", "\n", "# Compute next scores", "\n", "_scores", "=", "F", ".", "log_softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "_scores", "=", "torch", ".", "gather", "(", "_scores", ",", "-", "1", ",", "next_words", ")", "# (batch_size * num_beams, 2)", "\n", "next_scores", "=", "_scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "_scores", ")", "# (batch_size * num_beams, 2)", "\n", "# Match shape of greedy beam search", "\n", "next_words", "=", "next_words", ".", "view", "(", "batch_size", ",", "2", "*", "num_beams", ")", "# (batch_size, 2 * num_beams)", "\n", "next_scores", "=", "next_scores", ".", "view", "(", "batch_size", ",", "2", "*", "num_beams", ")", "# (batch_size, 2 * num_beams)", "\n", "", "else", ":", "\n", "# do greedy beam search", "\n", "                ", "scores", "=", "F", ".", "log_softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "assert", "scores", ".", "size", "(", ")", "==", "(", "batch_size", "*", "num_beams", ",", "vocab_size", ")", "\n", "# Add the log prob of the new beams to the log prob of the beginning of the sequence (sum of logs == log of the product)", "\n", "_scores", "=", "scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "scores", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# re-organize to group the beam together (we are keeping top hypothesis accross beams)", "\n", "_scores", "=", "_scores", ".", "view", "(", "batch_size", ",", "num_beams", "*", "vocab_size", ")", "# (batch_size, num_beams * vocab_size)", "\n", "next_scores", ",", "next_words", "=", "torch", ".", "topk", "(", "_scores", ",", "2", "*", "num_beams", ",", "dim", "=", "1", ",", "largest", "=", "True", ",", "sorted", "=", "True", ")", "\n", "\n", "", "assert", "next_scores", ".", "size", "(", ")", "==", "next_words", ".", "size", "(", ")", "==", "(", "batch_size", ",", "2", "*", "num_beams", ")", "\n", "\n", "# next batch beam content", "\n", "# list of (batch_size * num_beams) tuple(next hypothesis score, next word, current position in the batch)", "\n", "next_batch_beam", "=", "[", "]", "\n", "\n", "# for each sentence", "\n", "for", "batch_ex", "in", "range", "(", "batch_size", ")", ":", "\n", "\n", "# if we are done with this sentence", "\n", "                ", "done", "[", "batch_ex", "]", "=", "done", "[", "batch_ex", "]", "or", "generated_hyps", "[", "batch_ex", "]", ".", "is_done", "(", "next_scores", "[", "batch_ex", "]", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "if", "done", "[", "batch_ex", "]", ":", "\n", "                    ", "next_batch_beam", ".", "extend", "(", "[", "(", "0", ",", "pad_token_id", ",", "0", ")", "]", "*", "num_beams", ")", "# pad the batch", "\n", "continue", "\n", "\n", "# next sentence beam content", "\n", "", "next_sent_beam", "=", "[", "]", "\n", "\n", "# next words for this sentence", "\n", "for", "idx", ",", "score", "in", "zip", "(", "next_words", "[", "batch_ex", "]", ",", "next_scores", "[", "batch_ex", "]", ")", ":", "\n", "\n", "# get beam and word IDs", "\n", "                    ", "beam_id", "=", "idx", "//", "vocab_size", "\n", "word_id", "=", "idx", "%", "vocab_size", "\n", "\n", "# end of sentence, or next word", "\n", "if", "word_id", ".", "item", "(", ")", "in", "eos_token_ids", "or", "cur_len", "+", "1", "==", "max_length", ":", "\n", "                        ", "generated_hyps", "[", "batch_ex", "]", ".", "add", "(", "\n", "input_ids", "[", "batch_ex", "*", "num_beams", "+", "beam_id", ",", ":", "cur_len", "]", ".", "clone", "(", ")", ",", "score", ".", "item", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "next_sent_beam", ".", "append", "(", "(", "score", ",", "word_id", ",", "batch_ex", "*", "num_beams", "+", "beam_id", ")", ")", "\n", "\n", "# the beam for next step is full", "\n", "", "if", "len", "(", "next_sent_beam", ")", "==", "num_beams", ":", "\n", "                        ", "break", "\n", "\n", "# update next beam content", "\n", "", "", "assert", "len", "(", "next_sent_beam", ")", "==", "0", "if", "cur_len", "+", "1", "==", "max_length", "else", "num_beams", "\n", "if", "len", "(", "next_sent_beam", ")", "==", "0", ":", "\n", "                    ", "next_sent_beam", "=", "[", "(", "0", ",", "pad_token_id", ",", "0", ")", "]", "*", "num_beams", "# pad the batch", "\n", "", "next_batch_beam", ".", "extend", "(", "next_sent_beam", ")", "\n", "assert", "len", "(", "next_batch_beam", ")", "==", "num_beams", "*", "(", "batch_ex", "+", "1", ")", "\n", "\n", "# sanity check / prepare next batch", "\n", "", "assert", "len", "(", "next_batch_beam", ")", "==", "batch_size", "*", "num_beams", "\n", "beam_scores", "=", "beam_scores", ".", "new", "(", "[", "x", "[", "0", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_words", "=", "input_ids", ".", "new", "(", "[", "x", "[", "1", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_idx", "=", "input_ids", ".", "new", "(", "[", "x", "[", "2", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "\n", "# re-order batch and internal states", "\n", "input_ids", "=", "input_ids", "[", "beam_idx", ",", ":", "]", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", ",", "beam_words", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "# TODO: Activate cache", "\n", "# for k in cache.keys():", "\n", "#     if k != 'slen':", "\n", "#         cache[k] = (cache[k][0][beam_idx], cache[k][1][beam_idx])", "\n", "\n", "# update current length", "\n", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# stop when we are done with each sentence", "\n", "if", "all", "(", "done", ")", ":", "\n", "                ", "break", "\n", "\n", "# visualize hypotheses", "\n", "# print([len(x) for x in generated_hyps], cur_len)", "\n", "# globals().update( locals() );", "\n", "# !import code; code.interact(local=vars())", "\n", "# for ii in range(batch_size):", "\n", "#     for ss, ww in sorted(generated_hyps[ii].hyp, key=lambda x: x[0], reverse=True):", "\n", "#         print(\"%.3f \" % ss + \" \".join(self.dico[x] for x in ww.tolist()))", "\n", "#     print(\"\")", "\n", "\n", "# select the best hypotheses", "\n", "", "", "tgt_len", "=", "input_ids", ".", "new", "(", "batch_size", ")", "\n", "best", "=", "[", "]", "\n", "\n", "for", "i", ",", "hypotheses", "in", "enumerate", "(", "generated_hyps", ")", ":", "\n", "            ", "best_hyp", "=", "max", "(", "hypotheses", ".", "hyp", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "[", "1", "]", "\n", "tgt_len", "[", "i", "]", "=", "len", "(", "best_hyp", ")", "+", "1", "# +1 for the <EOS> symbol", "\n", "best", ".", "append", "(", "best_hyp", ")", "\n", "\n", "# generate target batch", "\n", "", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "tgt_len", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "for", "i", ",", "hypo", "in", "enumerate", "(", "best", ")", ":", "\n", "            ", "decoded", "[", "i", ",", ":", "tgt_len", "[", "i", "]", "-", "1", "]", "=", "hypo", "\n", "decoded", "[", "i", ",", "tgt_len", "[", "i", "]", "-", "1", "]", "=", "eos_token_ids", "[", "0", "]", "\n", "\n", "", "return", "decoded", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.BeamHypotheses.__init__": [[969, 979], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n_hyp", ",", "max_length", ",", "length_penalty", ",", "early_stopping", ")", ":", "\n", "        ", "\"\"\"\n        Initialize n-best list of hypotheses.\n        \"\"\"", "\n", "self", ".", "max_length", "=", "max_length", "-", "1", "# ignoring bos_token", "\n", "self", ".", "length_penalty", "=", "length_penalty", "\n", "self", ".", "early_stopping", "=", "early_stopping", "\n", "self", ".", "n_hyp", "=", "n_hyp", "\n", "self", ".", "hyp", "=", "[", "]", "\n", "self", ".", "worst_score", "=", "1e9", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.BeamHypotheses.__len__": [[980, 985], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Number of hypotheses in the list.\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "hyp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.BeamHypotheses.add": [[986, 999], ["modeling_utils.BeamHypotheses.hyp.append", "len", "len", "len", "sorted", "min", "enumerate"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "hyp", ",", "sum_logprobs", ")", ":", "\n", "        ", "\"\"\"\n        Add a new hypothesis to the list.\n        \"\"\"", "\n", "score", "=", "sum_logprobs", "/", "len", "(", "hyp", ")", "**", "self", ".", "length_penalty", "\n", "if", "len", "(", "self", ")", "<", "self", ".", "n_hyp", "or", "score", ">", "self", ".", "worst_score", ":", "\n", "            ", "self", ".", "hyp", ".", "append", "(", "(", "score", ",", "hyp", ")", ")", "\n", "if", "len", "(", "self", ")", ">", "self", ".", "n_hyp", ":", "\n", "                ", "sorted_scores", "=", "sorted", "(", "[", "(", "s", ",", "idx", ")", "for", "idx", ",", "(", "s", ",", "_", ")", "in", "enumerate", "(", "self", ".", "hyp", ")", "]", ")", "\n", "del", "self", ".", "hyp", "[", "sorted_scores", "[", "0", "]", "[", "1", "]", "]", "\n", "self", ".", "worst_score", "=", "sorted_scores", "[", "1", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "worst_score", "=", "min", "(", "score", ",", "self", ".", "worst_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.BeamHypotheses.is_done": [[1000, 1011], ["len"], "methods", ["None"], ["", "", "", "def", "is_done", "(", "self", ",", "best_sum_logprobs", ")", ":", "\n", "        ", "\"\"\"\n        If there are enough hypotheses and that none of the hypotheses being generated\n        can become better than the worst one in the heap, then we are done with this sentence.\n        \"\"\"", "\n", "if", "len", "(", "self", ")", "<", "self", ".", "n_hyp", ":", "\n", "            ", "return", "False", "\n", "", "elif", "self", ".", "early_stopping", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "worst_score", ">=", "best_sum_logprobs", "/", "self", ".", "max_length", "**", "self", ".", "length_penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.Conv1D.__init__": [[1014, 1024], ["torch.nn.Module.__init__", "torch.empty", "torch.nn.init.normal_", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "nx", ")", ":", "\n", "        ", "\"\"\" Conv1D layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2)\n            Basically works like a Linear layer but the weights are transposed\n        \"\"\"", "\n", "super", "(", "Conv1D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nf", "=", "nf", "\n", "w", "=", "torch", ".", "empty", "(", "nx", ",", "nf", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "w", ",", "std", "=", "0.02", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "w", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "nf", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.Conv1D.forward": [[1025, 1030], ["torch.addmm", "x.view.view.view", "x.view.view.view", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "size_out", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "nf", ",", ")", "\n", "x", "=", "torch", ".", "addmm", "(", "self", ".", "bias", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ",", "self", ".", "weight", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "size_out", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PoolerStartLogits.__init__": [[1035, 1038], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PoolerStartLogits", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PoolerStartLogits.forward": [[1039, 1054], ["modeling_utils.PoolerStartLogits.dense().squeeze", "modeling_utils.PoolerStartLogits.dense", "next", "modeling_utils.PoolerStartLogits.parameters"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Args:\n            **p_mask**: (`optional`) ``torch.FloatTensor`` of shape `(batch_size, seq_len)`\n                invalid position mask such as query and special symbols (PAD, SEP, CLS)\n                1.0 means token should be masked.\n        \"\"\"", "\n", "x", "=", "self", ".", "dense", "(", "hidden_states", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "p_mask", "is", "not", "None", ":", "\n", "            ", "if", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "65500", "*", "p_mask", "\n", "", "else", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "1e30", "*", "p_mask", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PoolerEndLogits.__init__": [[1060, 1066], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.LayerNorm", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PoolerEndLogits", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_0", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dense_1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PoolerEndLogits.forward": [[1067, 1101], ["modeling_utils.PoolerEndLogits.dense_0", "modeling_utils.PoolerEndLogits.activation", "modeling_utils.PoolerEndLogits.LayerNorm", "modeling_utils.PoolerEndLogits.dense_1().squeeze", "start_positions[].expand", "hidden_states.gather", "start_states.expand.expand.expand", "torch.cat", "modeling_utils.PoolerEndLogits.dense_1", "next", "modeling_utils.PoolerEndLogits.parameters"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_states", "=", "None", ",", "start_positions", "=", "None", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Args:\n            One of ``start_states``, ``start_positions`` should be not None.\n            If both are set, ``start_positions`` overrides ``start_states``.\n\n            **start_states**: ``torch.LongTensor`` of shape identical to hidden_states\n                hidden states of the first tokens for the labeled span.\n            **start_positions**: ``torch.LongTensor`` of shape ``(batch_size,)``\n                position of the first token for the labeled span:\n            **p_mask**: (`optional`) ``torch.FloatTensor`` of shape ``(batch_size, seq_len)``\n                Mask of invalid position such as query and special symbols (PAD, SEP, CLS)\n                1.0 means token should be masked.\n        \"\"\"", "\n", "assert", "(", "\n", "start_states", "is", "not", "None", "or", "start_positions", "is", "not", "None", "\n", ")", ",", "\"One of start_states, start_positions should be not None\"", "\n", "if", "start_positions", "is", "not", "None", ":", "\n", "            ", "slen", ",", "hsz", "=", "hidden_states", ".", "shape", "[", "-", "2", ":", "]", "\n", "start_positions", "=", "start_positions", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "start_positions", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "start_states", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ")", "# shape (bsz, slen, hsz)", "\n", "\n", "", "x", "=", "self", ".", "dense_0", "(", "torch", ".", "cat", "(", "[", "hidden_states", ",", "start_states", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "LayerNorm", "(", "x", ")", "\n", "x", "=", "self", ".", "dense_1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "p_mask", "is", "not", "None", ":", "\n", "            ", "if", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "65500", "*", "p_mask", "\n", "", "else", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "1e30", "*", "p_mask", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PoolerAnswerClass.__init__": [[1106, 1111], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "PoolerAnswerClass", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_0", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "dense_1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PoolerAnswerClass.forward": [[1112, 1148], ["modeling_utils.PoolerAnswerClass.dense_0", "modeling_utils.PoolerAnswerClass.activation", "modeling_utils.PoolerAnswerClass.dense_1().squeeze", "start_positions[].expand", "hidden_states.gather().squeeze", "cls_index[].expand", "hidden_states.gather().squeeze", "torch.cat", "modeling_utils.PoolerAnswerClass.dense_1", "hidden_states.gather", "hidden_states.gather"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_states", "=", "None", ",", "start_positions", "=", "None", ",", "cls_index", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            One of ``start_states``, ``start_positions`` should be not None.\n            If both are set, ``start_positions`` overrides ``start_states``.\n\n            **start_states**: ``torch.LongTensor`` of shape identical to ``hidden_states``.\n                hidden states of the first tokens for the labeled span.\n            **start_positions**: ``torch.LongTensor`` of shape ``(batch_size,)``\n                position of the first token for the labeled span.\n            **cls_index**: torch.LongTensor of shape ``(batch_size,)``\n                position of the CLS token. If None, take the last token.\n\n            note(Original repo):\n                no dependency on end_feature so that we can obtain one single `cls_logits`\n                for each sample\n        \"\"\"", "\n", "hsz", "=", "hidden_states", ".", "shape", "[", "-", "1", "]", "\n", "assert", "(", "\n", "start_states", "is", "not", "None", "or", "start_positions", "is", "not", "None", "\n", ")", ",", "\"One of start_states, start_positions should be not None\"", "\n", "if", "start_positions", "is", "not", "None", ":", "\n", "            ", "start_positions", "=", "start_positions", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "start_positions", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, hsz)", "\n", "\n", "", "if", "cls_index", "is", "not", "None", ":", "\n", "            ", "cls_index", "=", "cls_index", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "cls_token_state", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "cls_index", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, hsz)", "\n", "", "else", ":", "\n", "            ", "cls_token_state", "=", "hidden_states", "[", ":", ",", "-", "1", ",", ":", "]", "# shape (bsz, hsz)", "\n", "\n", "", "x", "=", "self", ".", "dense_0", "(", "torch", ".", "cat", "(", "[", "start_states", ",", "cls_token_state", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "dense_1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.SQuADHead.__init__": [[1191, 1199], ["torch.nn.Module.__init__", "modeling_utils.PoolerStartLogits", "modeling_utils.PoolerEndLogits", "modeling_utils.PoolerAnswerClass"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "SQuADHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "start_n_top", "=", "config", ".", "start_n_top", "\n", "self", ".", "end_n_top", "=", "config", ".", "end_n_top", "\n", "\n", "self", ".", "start_logits", "=", "PoolerStartLogits", "(", "config", ")", "\n", "self", ".", "end_logits", "=", "PoolerEndLogits", "(", "config", ")", "\n", "self", ".", "answer_class", "=", "PoolerAnswerClass", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.SQuADHead.forward": [[1200, 1265], ["modeling_utils.SQuADHead.start_logits", "modeling_utils.SQuADHead.end_logits", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "hidden_states.size", "torch.nn.functional.softmax", "torch.topk", "start_top_index.unsqueeze().expand", "torch.gather", "torch.einsum.unsqueeze().expand", "hidden_states.unsqueeze().expand_as", "modeling_utils.SQuADHead.end_logits", "torch.nn.functional.softmax", "torch.topk", "end_top_log_probs.view.view.view", "end_top_index.view.view.view", "torch.einsum", "modeling_utils.SQuADHead.answer_class", "modeling_utils.SQuADHead.answer_class", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "p_mask.unsqueeze", "x.squeeze_", "start_top_index.unsqueeze", "torch.einsum.unsqueeze", "hidden_states.unsqueeze", "x.dim"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "hidden_states", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "cls_index", "=", "None", ",", "is_impossible", "=", "None", ",", "p_mask", "=", "None", "\n", ")", ":", "\n", "        ", "outputs", "=", "(", ")", "\n", "\n", "start_logits", "=", "self", ".", "start_logits", "(", "hidden_states", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, let's remove the dimension added by batch splitting", "\n", "            ", "for", "x", "in", "(", "start_positions", ",", "end_positions", ",", "cls_index", ",", "is_impossible", ")", ":", "\n", "                ", "if", "x", "is", "not", "None", "and", "x", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "x", ".", "squeeze_", "(", "-", "1", ")", "\n", "\n", "# during training, compute the end logits based on the ground truth of the start position", "\n", "", "", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "if", "cls_index", "is", "not", "None", "and", "is_impossible", "is", "not", "None", ":", "\n", "# Predict answerability from the representation of CLS and START", "\n", "                ", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "cls_index", "=", "cls_index", ")", "\n", "loss_fct_cls", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "cls_loss", "=", "loss_fct_cls", "(", "cls_logits", ",", "is_impossible", ")", "\n", "\n", "# note(zhiliny): by default multiply the loss by 0.5 so that the scale is comparable to start_loss and end_loss", "\n", "total_loss", "+=", "cls_loss", "*", "0.5", "\n", "\n", "", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "else", ":", "\n", "# during inference, compute the end logits based on beam search", "\n", "            ", "bsz", ",", "slen", ",", "hsz", "=", "hidden_states", ".", "size", "(", ")", "\n", "start_log_probs", "=", "F", ".", "softmax", "(", "start_logits", ",", "dim", "=", "-", "1", ")", "# shape (bsz, slen)", "\n", "\n", "start_top_log_probs", ",", "start_top_index", "=", "torch", ".", "topk", "(", "\n", "start_log_probs", ",", "self", ".", "start_n_top", ",", "dim", "=", "-", "1", "\n", ")", "# shape (bsz, start_n_top)", "\n", "start_top_index_exp", "=", "start_top_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "torch", ".", "gather", "(", "hidden_states", ",", "-", "2", ",", "start_top_index_exp", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "start_states", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ",", "-", "1", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "\n", "hidden_states_expanded", "=", "hidden_states", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "\n", "start_states", "\n", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "p_mask", "=", "p_mask", ".", "unsqueeze", "(", "-", "1", ")", "if", "p_mask", "is", "not", "None", "else", "None", "\n", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states_expanded", ",", "start_states", "=", "start_states", ",", "p_mask", "=", "p_mask", ")", "\n", "end_log_probs", "=", "F", ".", "softmax", "(", "end_logits", ",", "dim", "=", "1", ")", "# shape (bsz, slen, start_n_top)", "\n", "\n", "end_top_log_probs", ",", "end_top_index", "=", "torch", ".", "topk", "(", "\n", "end_log_probs", ",", "self", ".", "end_n_top", ",", "dim", "=", "1", "\n", ")", "# shape (bsz, end_n_top, start_n_top)", "\n", "end_top_log_probs", "=", "end_top_log_probs", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "end_top_index", "=", "end_top_index", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "\n", "start_states", "=", "torch", ".", "einsum", "(", "\"blh,bl->bh\"", ",", "hidden_states", ",", "start_log_probs", ")", "\n", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_states", "=", "start_states", ",", "cls_index", "=", "cls_index", ")", "\n", "\n", "outputs", "=", "(", "start_top_log_probs", ",", "start_top_index", ",", "end_top_log_probs", ",", "end_top_index", ",", "cls_logits", ")", "+", "outputs", "\n", "\n", "# return start_top_log_probs, start_top_index, end_top_log_probs, end_top_index, cls_logits", "\n", "# or (if labels are provided) (total_loss,)", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.SequenceSummary.__init__": [[1283, 1312], ["torch.nn.Module.__init__", "Identity", "Identity", "Identity", "Identity", "hasattr", "hasattr", "torch.nn.Linear", "hasattr", "torch.nn.Tanh", "hasattr", "torch.nn.Dropout", "hasattr", "torch.nn.Dropout", "hasattr"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "SequenceSummary", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "summary_type", "=", "config", ".", "summary_type", "if", "hasattr", "(", "config", ",", "\"summary_type\"", ")", "else", "\"last\"", "\n", "if", "self", ".", "summary_type", "==", "\"attn\"", ":", "\n", "# We should use a standard multi-head attention module with absolute positional embedding for that.", "\n", "# Cf. https://github.com/zihangdai/xlnet/blob/master/modeling.py#L253-L276", "\n", "# We can probably just use the multi-head attention module of PyTorch >=1.1.0", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "summary", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "\"summary_use_proj\"", ")", "and", "config", ".", "summary_use_proj", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "\"summary_proj_to_labels\"", ")", "and", "config", ".", "summary_proj_to_labels", "and", "config", ".", "num_labels", ">", "0", ":", "\n", "                ", "num_classes", "=", "config", ".", "num_labels", "\n", "", "else", ":", "\n", "                ", "num_classes", "=", "config", ".", "hidden_size", "\n", "", "self", ".", "summary", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_classes", ")", "\n", "\n", "", "self", ".", "activation", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "\"summary_activation\"", ")", "and", "config", ".", "summary_activation", "==", "\"tanh\"", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n", "", "self", ".", "first_dropout", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "\"summary_first_dropout\"", ")", "and", "config", ".", "summary_first_dropout", ">", "0", ":", "\n", "            ", "self", ".", "first_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_first_dropout", ")", "\n", "\n", "", "self", ".", "last_dropout", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "\"summary_last_dropout\"", ")", "and", "config", ".", "summary_last_dropout", ">", "0", ":", "\n", "            ", "self", ".", "last_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_last_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.SequenceSummary.forward": [[1313, 1343], ["modeling_utils.SequenceSummary.first_dropout", "modeling_utils.SequenceSummary.summary", "modeling_utils.SequenceSummary.activation", "modeling_utils.SequenceSummary.last_dropout", "hidden_states.mean", "hidden_states.gather().squeeze", "torch.full_like", "cls_index.expand.expand.unsqueeze().unsqueeze", "cls_index.expand.expand.expand", "hidden_states.gather", "cls_index.expand.expand.unsqueeze", "hidden_states.size", "cls_index.expand.expand.dim"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ",", "cls_index", "=", "None", ")", ":", "\n", "        ", "\"\"\" hidden_states: float Tensor in shape [bsz, ..., seq_len, hidden_size], the hidden-states of the last layer.\n            cls_index: [optional] position of the classification token if summary_type == 'cls_index',\n                shape (bsz,) or more generally (bsz, ...) where ... are optional leading dimensions of hidden_states.\n                if summary_type == 'cls_index' and cls_index is None:\n                    we take the last token of the sequence as classification token\n        \"\"\"", "\n", "if", "self", ".", "summary_type", "==", "\"last\"", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "-", "1", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "\"first\"", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "\"mean\"", ":", "\n", "            ", "output", "=", "hidden_states", ".", "mean", "(", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "summary_type", "==", "\"cls_index\"", ":", "\n", "            ", "if", "cls_index", "is", "None", ":", "\n", "                ", "cls_index", "=", "torch", ".", "full_like", "(", "hidden_states", "[", "...", ",", ":", "1", ",", ":", "]", ",", "hidden_states", ".", "shape", "[", "-", "2", "]", "-", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "else", ":", "\n", "                ", "cls_index", "=", "cls_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "cls_index", "=", "cls_index", ".", "expand", "(", "(", "-", "1", ",", ")", "*", "(", "cls_index", ".", "dim", "(", ")", "-", "1", ")", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", ")", "\n", "# shape of cls_index: (bsz, XX, 1, hidden_size) where XX are optional leading dim of hidden_states", "\n", "", "output", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "cls_index", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, XX, hidden_size)", "\n", "", "elif", "self", ".", "summary_type", "==", "\"attn\"", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "output", "=", "self", ".", "first_dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "summary", "(", "output", ")", "\n", "output", "=", "self", ".", "activation", "(", "output", ")", "\n", "output", "=", "self", ".", "last_dropout", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.top_k_top_p_filtering": [[931, 966], ["float", "min", "torch.sort", "torch.cumsum", "sorted_indices_to_remove[].clone", "sorted_indices_to_remove.scatter", "max", "logits.size", "torch.nn.functional.softmax", "torch.topk"], "function", ["None"], ["", "", "def", "top_k_top_p_filtering", "(", "logits", ",", "top_k", "=", "0", ",", "top_p", "=", "1.0", ",", "filter_value", "=", "-", "float", "(", "\"Inf\"", ")", ",", "min_tokens_to_keep", "=", "1", ")", ":", "\n", "    ", "\"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n        Args:\n            logits: logits distribution shape (batch size, vocabulary size)\n            if top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n            if top_p < 1.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n            Make sure we keep at least min_tokens_to_keep per batch example in the output\n        From: https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317\n    \"\"\"", "\n", "if", "top_k", ">", "0", ":", "\n", "        ", "top_k", "=", "min", "(", "max", "(", "top_k", ",", "min_tokens_to_keep", ")", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "# Safety check", "\n", "# Remove all tokens with a probability less than the last token of the top-k", "\n", "indices_to_remove", "=", "logits", "<", "torch", ".", "topk", "(", "logits", ",", "top_k", ")", "[", "0", "]", "[", "...", ",", "-", "1", ",", "None", "]", "\n", "logits", "[", "indices_to_remove", "]", "=", "filter_value", "\n", "\n", "", "if", "top_p", "<", "1.0", ":", "\n", "        ", "sorted_logits", ",", "sorted_indices", "=", "torch", ".", "sort", "(", "logits", ",", "descending", "=", "True", ")", "\n", "cumulative_probs", "=", "torch", ".", "cumsum", "(", "F", ".", "softmax", "(", "sorted_logits", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Remove tokens with cumulative probability above the threshold (token with 0 are kept)", "\n", "sorted_indices_to_remove", "=", "cumulative_probs", ">", "top_p", "\n", "if", "min_tokens_to_keep", ">", "1", ":", "\n", "# Keep at least min_tokens_to_keep (set to min_tokens_to_keep-1 because we add the first one below)", "\n", "            ", "sorted_indices_to_remove", "[", "...", ",", ":", "min_tokens_to_keep", "]", "=", "0", "\n", "# Shift the indices to the right to keep also the first token above the threshold", "\n", "", "sorted_indices_to_remove", "[", "...", ",", "1", ":", "]", "=", "sorted_indices_to_remove", "[", "...", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "sorted_indices_to_remove", "[", "...", ",", "0", "]", "=", "0", "\n", "\n", "# scatter sorted tensors to original indexing", "\n", "indices_to_remove", "=", "sorted_indices_to_remove", ".", "scatter", "(", "\n", "dim", "=", "1", ",", "index", "=", "sorted_indices", ",", "source", "=", "sorted_indices_to_remove", "\n", ")", "\n", "logits", "[", "indices_to_remove", "]", "=", "filter_value", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer": [[1345, 1368], ["index.to.to", "layer.weight.index_select().clone().detach", "list", "len", "torch.nn.Linear().to", "nn.Linear().to.weight.copy_", "layer.weight.size", "layer.weight.index_select().clone().detach.contiguous", "nn.Linear().to.bias.copy_", "layer.weight.index_select().clone", "layer.bias.clone().detach", "layer.bias[].clone().detach", "torch.nn.Linear", "layer.bias[].clone().detach.contiguous", "layer.weight.index_select", "layer.bias.clone", "layer.bias[].clone"], "function", ["None"], ["", "", "def", "prune_linear_layer", "(", "layer", ",", "index", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\" Prune a linear layer (a model parameters) to keep only entries in index.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "index", "=", "index", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "W", "=", "layer", ".", "weight", ".", "index_select", "(", "dim", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "        ", "if", "dim", "==", "1", ":", "\n", "            ", "b", "=", "layer", ".", "bias", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "            ", "b", "=", "layer", ".", "bias", "[", "index", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "", "new_size", "=", "list", "(", "layer", ".", "weight", ".", "size", "(", ")", ")", "\n", "new_size", "[", "dim", "]", "=", "len", "(", "index", ")", "\n", "new_layer", "=", "nn", ".", "Linear", "(", "new_size", "[", "1", "]", ",", "new_size", "[", "0", "]", ",", "bias", "=", "layer", ".", "bias", "is", "not", "None", ")", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "weight", ".", "copy_", "(", "W", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "True", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "        ", "new_layer", ".", "bias", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "bias", ".", "copy_", "(", "b", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "True", "\n", "", "return", "new_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_conv1d_layer": [[1370, 1392], ["index.to.to", "layer.weight.index_select().clone().detach", "list", "len", "Conv1D().to", "Conv1D().to.weight.copy_", "Conv1D().to.bias.copy_", "layer.bias.clone().detach", "layer.bias[].clone().detach", "layer.weight.size", "layer.weight.index_select().clone().detach.contiguous", "layer.bias[].clone().detach.contiguous", "layer.weight.index_select().clone", "modeling_utils.Conv1D", "layer.bias.clone", "layer.bias[].clone", "layer.weight.index_select"], "function", ["None"], ["", "def", "prune_conv1d_layer", "(", "layer", ",", "index", ",", "dim", "=", "1", ")", ":", "\n", "    ", "\"\"\" Prune a Conv1D layer (a model parameters) to keep only entries in index.\n        A Conv1D work as a Linear layer (see e.g. BERT) but the weights are transposed.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "index", "=", "index", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "W", "=", "layer", ".", "weight", ".", "index_select", "(", "dim", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "dim", "==", "0", ":", "\n", "        ", "b", "=", "layer", ".", "bias", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "        ", "b", "=", "layer", ".", "bias", "[", "index", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "new_size", "=", "list", "(", "layer", ".", "weight", ".", "size", "(", ")", ")", "\n", "new_size", "[", "dim", "]", "=", "len", "(", "index", ")", "\n", "new_layer", "=", "Conv1D", "(", "new_size", "[", "1", "]", ",", "new_size", "[", "0", "]", ")", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "weight", ".", "copy_", "(", "W", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "True", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "bias", ".", "copy_", "(", "b", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "True", "\n", "return", "new_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_layer": [[1394, 1405], ["isinstance", "modeling_utils.prune_linear_layer", "isinstance", "modeling_utils.prune_conv1d_layer", "ValueError"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_layer", "(", "layer", ",", "index", ",", "dim", "=", "None", ")", ":", "\n", "    ", "\"\"\" Prune a Conv1D or nn.Linear layer (a model parameters) to keep only entries in index.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "if", "isinstance", "(", "layer", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "return", "prune_linear_layer", "(", "layer", ",", "index", ",", "dim", "=", "0", "if", "dim", "is", "None", "else", "dim", ")", "\n", "", "elif", "isinstance", "(", "layer", ",", "Conv1D", ")", ":", "\n", "        ", "return", "prune_conv1d_layer", "(", "layer", ",", "index", ",", "dim", "=", "1", "if", "dim", "is", "None", "else", "dim", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Can't prune layer of class {}\"", ".", "format", "(", "layer", ".", "__class__", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFMultiHeadAttention.__init__": [[77, 90], ["super().__init__", "int", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model_size", ",", "num_heads", ",", "output_attentions", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFMultiHeadAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "output_attentions", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "d_model_size", "=", "d_model_size", "\n", "\n", "self", ".", "depth", "=", "int", "(", "d_model_size", "/", "self", ".", "num_heads", ")", "\n", "\n", "self", ".", "Wq", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "d_model_size", ",", "name", "=", "\"Wq\"", ")", "\n", "self", ".", "Wk", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "d_model_size", ",", "name", "=", "\"Wk\"", ")", "\n", "self", ".", "Wv", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "d_model_size", ",", "name", "=", "\"Wv\"", ")", "\n", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "d_model_size", ",", "name", "=", "\"dense\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFMultiHeadAttention.split_into_heads": [[91, 94], ["tensorflow.reshape", "tensorflow.transpose"], "methods", ["None"], ["", "def", "split_into_heads", "(", "self", ",", "x", ",", "batch_size", ")", ":", "\n", "        ", "x", "=", "tf", ".", "reshape", "(", "x", ",", "(", "batch_size", ",", "-", "1", ",", "self", ".", "num_heads", ",", "self", ".", "depth", ")", ")", "\n", "return", "tf", ".", "transpose", "(", "x", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFMultiHeadAttention.call": [[95, 122], ["modeling_tf_ctrl.TFMultiHeadAttention.Wq", "modeling_tf_ctrl.TFMultiHeadAttention.Wk", "modeling_tf_ctrl.TFMultiHeadAttention.Wv", "modeling_tf_ctrl.TFMultiHeadAttention.split_into_heads", "modeling_tf_ctrl.TFMultiHeadAttention.split_into_heads", "modeling_tf_ctrl.TFMultiHeadAttention.split_into_heads", "tensorflow.stack", "modeling_tf_ctrl.scaled_dot_product_attention", "tensorflow.transpose", "tensorflow.reshape", "modeling_tf_ctrl.TFMultiHeadAttention.dense", "modeling_tf_utils.shape_list", "tensorflow.unstack", "tensorflow.concat", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.MultiHeadAttention.split_into_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.MultiHeadAttention.split_into_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.MultiHeadAttention.split_into_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.scaled_dot_product_attention", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "v", ",", "k", ",", "q", ",", "mask", ",", "layer_past", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "batch_size", "=", "shape_list", "(", "q", ")", "[", "0", "]", "\n", "\n", "q", "=", "self", ".", "Wq", "(", "q", ")", "\n", "k", "=", "self", ".", "Wk", "(", "k", ")", "\n", "v", "=", "self", ".", "Wv", "(", "v", ")", "\n", "\n", "q", "=", "self", ".", "split_into_heads", "(", "q", ",", "batch_size", ")", "\n", "k", "=", "self", ".", "split_into_heads", "(", "k", ",", "batch_size", ")", "\n", "v", "=", "self", ".", "split_into_heads", "(", "v", ",", "batch_size", ")", "\n", "if", "layer_past", "is", "not", "None", ":", "\n", "            ", "past_key", ",", "past_value", "=", "tf", ".", "unstack", "(", "layer_past", ",", "axis", "=", "1", ")", "\n", "k", "=", "tf", ".", "concat", "(", "(", "past_key", ",", "k", ")", ",", "dim", "=", "-", "2", ")", "\n", "v", "=", "tf", ".", "concat", "(", "(", "past_value", ",", "v", ")", ",", "dim", "=", "-", "2", ")", "\n", "", "present", "=", "tf", ".", "stack", "(", "(", "k", ",", "v", ")", ",", "axis", "=", "1", ")", "\n", "\n", "output", "=", "scaled_dot_product_attention", "(", "q", ",", "k", ",", "v", ",", "mask", ",", "attention_mask", ",", "head_mask", ")", "\n", "scaled_attention", "=", "tf", ".", "transpose", "(", "output", "[", "0", "]", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "attn", "=", "output", "[", "1", "]", "\n", "original_size_attention", "=", "tf", ".", "reshape", "(", "scaled_attention", ",", "(", "batch_size", ",", "-", "1", ",", "self", ".", "d_model_size", ")", ")", "\n", "output", "=", "self", ".", "dense", "(", "original_size_attention", ")", "\n", "\n", "outputs", "=", "(", "output", ",", "present", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attn", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFEncoderLayer.__init__": [[132, 147], ["super().__init__", "modeling_tf_ctrl.TFMultiHeadAttention", "modeling_tf_ctrl.point_wise_feed_forward_network", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.point_wise_feed_forward_network"], ["    ", "def", "__init__", "(", "\n", "self", ",", "d_model_size", ",", "num_heads", ",", "dff", ",", "rate", "=", "0.1", ",", "layer_norm_epsilon", "=", "1e-6", ",", "output_attentions", "=", "False", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "TFEncoderLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "multi_head_attention", "=", "TFMultiHeadAttention", "(", "\n", "d_model_size", ",", "num_heads", ",", "output_attentions", ",", "name", "=", "\"multi_head_attention\"", "\n", ")", "\n", "self", ".", "ffn", "=", "point_wise_feed_forward_network", "(", "d_model_size", ",", "dff", ",", "name", "=", "\"ffn\"", ")", "\n", "\n", "self", ".", "layernorm1", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "layer_norm_epsilon", ",", "name", "=", "\"layernorm1\"", ")", "\n", "self", ".", "layernorm2", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "layer_norm_epsilon", ",", "name", "=", "\"layernorm2\"", ")", "\n", "\n", "self", ".", "dropout1", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "rate", ")", "\n", "self", ".", "dropout2", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFEncoderLayer.call": [[148, 165], ["modeling_tf_ctrl.TFEncoderLayer.layernorm1", "modeling_tf_ctrl.TFEncoderLayer.multi_head_attention", "modeling_tf_ctrl.TFEncoderLayer.dropout1", "modeling_tf_ctrl.TFEncoderLayer.layernorm2", "modeling_tf_ctrl.TFEncoderLayer.ffn", "modeling_tf_ctrl.TFEncoderLayer.dropout2"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", ",", "mask", ",", "layer_past", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "normed", "=", "self", ".", "layernorm1", "(", "x", ")", "\n", "attn_outputs", "=", "self", ".", "multi_head_attention", "(", "\n", "[", "normed", ",", "normed", ",", "normed", ",", "mask", ",", "layer_past", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", "\n", ")", "\n", "attn_output", "=", "attn_outputs", "[", "0", "]", "\n", "attn_output", "=", "self", ".", "dropout1", "(", "attn_output", ",", "training", "=", "training", ")", "\n", "out1", "=", "x", "+", "attn_output", "\n", "\n", "out2", "=", "self", ".", "layernorm2", "(", "out1", ")", "\n", "ffn_output", "=", "self", ".", "ffn", "(", "out2", ")", "\n", "ffn_output", "=", "self", ".", "dropout2", "(", "ffn_output", ",", "training", "=", "training", ")", "\n", "out2", "=", "out1", "+", "ffn_output", "\n", "\n", "outputs", "=", "(", "out2", ",", ")", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFCTRLMainLayer.__init__": [[168, 197], ["super().__init__", "modeling_tf_ctrl.positional_encoding", "modeling_tf_utils.TFSharedEmbeddings", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_ctrl.TFEncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.positional_encoding"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFCTRLMainLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "\n", "self", ".", "d_model_size", "=", "config", ".", "n_embd", "\n", "self", ".", "num_layers", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "pos_encoding", "=", "positional_encoding", "(", "config", ".", "n_positions", ",", "self", ".", "d_model_size", ")", "\n", "\n", "self", ".", "w", "=", "TFSharedEmbeddings", "(", "\n", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"w\"", "\n", ")", "\n", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "[", "\n", "TFEncoderLayer", "(", "\n", "config", ".", "n_embd", ",", "\n", "config", ".", "n_head", ",", "\n", "config", ".", "dff", ",", "\n", "config", ".", "resid_pdrop", ",", "\n", "config", ".", "layer_norm_epsilon", ",", "\n", "config", ".", "output_attentions", ",", "\n", "name", "=", "\"h_._{}\"", ".", "format", "(", "i", ")", ",", "\n", ")", "\n", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", "\n", "]", "\n", "self", ".", "layernorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "\"layernorm\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFCTRLMainLayer.get_input_embeddings": [[198, 200], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFCTRLMainLayer._resize_token_embeddings": [[201, 203], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFCTRLMainLayer._prune_heads": [[204, 209], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n                heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFCTRLMainLayer.call": [[210, 343], ["isinstance", "tensorflow.reshape", "tensorflow.math.sqrt", "tensorflow.gather", "modeling_tf_ctrl.TFCTRLMainLayer.dropout", "enumerate", "modeling_tf_ctrl.TFCTRLMainLayer.layernorm", "tensorflow.reshape", "isinstance", "ValueError", "tensorflow.tile", "tensorflow.cast", "tensorflow.reshape", "modeling_tf_ctrl.TFCTRLMainLayer.w", "tensorflow.math.sqrt", "modeling_tf_ctrl.TFCTRLMainLayer.w", "tensorflow.linalg.band_part", "tensorflow.cast", "zip", "h", "tuple", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "modeling_tf_utils.shape_list", "tensorflow.reshape", "len", "modeling_tf_utils.shape_list", "tensorflow.range", "tensorflow.cast", "tensorflow.ones", "tuple.append", "len", "len", "len", "len", "len", "len", "len", "ValueError", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "tensorflow.reshape", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "\n", "self", ",", "\n", "inputs", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "training", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "past", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "past", "\n", "attention_mask", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "head_mask", "\n", "inputs_embeds", "=", "inputs", "[", "6", "]", "if", "len", "(", "inputs", ")", ">", "6", "else", "inputs_embeds", "\n", "assert", "len", "(", "inputs", ")", "<=", "7", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "\"input_ids\"", ")", "\n", "past", "=", "inputs", ".", "get", "(", "\"past\"", ",", "past", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "\"attention_mask\"", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "\"token_type_ids\"", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "\"position_ids\"", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "\"head_mask\"", ",", "head_mask", ")", "\n", "inputs_embeds", "=", "inputs", ".", "get", "(", "\"inputs_embeds\"", ",", "inputs_embeds", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "7", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "input_ids", ")", "\n", "input_ids", "=", "tf", ".", "reshape", "(", "input_ids", ",", "[", "-", "1", ",", "input_shape", "[", "-", "1", "]", "]", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "inputs_embeds", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "past", "is", "None", ":", "\n", "            ", "past_length", "=", "0", "\n", "past", "=", "[", "None", "]", "*", "len", "(", "self", ".", "h", ")", "\n", "", "else", ":", "\n", "            ", "past_length", "=", "shape_list", "(", "past", "[", "0", "]", "[", "0", "]", ")", "[", "-", "2", "]", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "tf", ".", "range", "(", "past_length", ",", "input_shape", "[", "-", "1", "]", "+", "past_length", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "tf", ".", "newaxis", ",", ":", "]", "\n", "position_ids", "=", "tf", ".", "tile", "(", "position_ids", ",", "[", "input_shape", "[", "0", "]", ",", "1", "]", ")", "\n", "\n", "# Attention mask.", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "            ", "attention_mask", "=", "attention_mask", "[", ":", ",", "tf", ".", "newaxis", ",", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "\n", "attention_mask", "=", "tf", ".", "cast", "(", "attention_mask", ",", "tf", ".", "float32", ")", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "", "else", ":", "\n", "            ", "attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# head_mask has shape n_layer x batch x n_heads x N x N", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "num_layers", "\n", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "tf", ".", "reshape", "(", "token_type_ids", ",", "[", "-", "1", ",", "shape_list", "(", "token_type_ids", ")", "[", "-", "1", "]", "]", ")", "\n", "token_type_embeds", "=", "self", ".", "w", "(", "token_type_ids", ",", "mode", "=", "\"embedding\"", ")", "\n", "token_type_embeds", "*=", "tf", ".", "math", ".", "sqrt", "(", "tf", ".", "cast", "(", "self", ".", "d_model_size", ",", "tf", ".", "float32", ")", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "position_ids", "=", "tf", ".", "reshape", "(", "position_ids", ",", "[", "-", "1", ",", "shape_list", "(", "position_ids", ")", "[", "-", "1", "]", "]", ")", "\n", "\n", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "w", "(", "input_ids", ",", "mode", "=", "\"embedding\"", ")", "\n", "", "seq_len", "=", "input_shape", "[", "-", "1", "]", "\n", "mask", "=", "1", "-", "tf", ".", "linalg", ".", "band_part", "(", "tf", ".", "ones", "(", "(", "seq_len", ",", "seq_len", ")", ")", ",", "-", "1", ",", "0", ")", "\n", "\n", "inputs_embeds", "*=", "tf", ".", "math", ".", "sqrt", "(", "tf", ".", "cast", "(", "self", ".", "d_model_size", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "pos_embeds", "=", "tf", ".", "gather", "(", "self", ".", "pos_encoding", ",", "position_ids", ")", "\n", "\n", "hidden_states", "=", "inputs_embeds", "+", "pos_embeds", "+", "token_type_embeds", "\n", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "[", "shape_list", "(", "hidden_states", ")", "[", "-", "1", "]", "]", "\n", "presents", "=", "(", ")", "\n", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "[", "]", "\n", "for", "i", ",", "(", "h", ",", "layer_past", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "h", ",", "past", ")", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "tf", ".", "reshape", "(", "hidden_states", ",", "output_shape", ")", ",", ")", "\n", "", "outputs", "=", "h", "(", "[", "hidden_states", ",", "mask", ",", "layer_past", ",", "attention_mask", ",", "head_mask", "[", "i", "]", "]", ",", "training", "=", "training", ")", "\n", "hidden_states", ",", "present", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "self", ".", "output_past", ":", "\n", "                ", "presents", "=", "presents", "+", "(", "present", ",", ")", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "layernorm", "(", "hidden_states", ")", "\n", "hidden_states", "=", "tf", ".", "reshape", "(", "hidden_states", ",", "output_shape", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_past", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "presents", ",", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# let the number of heads free (-1) so we can extract attention even after head pruning", "\n", "            ", "attention_output_shape", "=", "input_shape", "[", ":", "-", "1", "]", "+", "[", "-", "1", "]", "+", "shape_list", "(", "all_attentions", "[", "0", "]", ")", "[", "-", "2", ":", "]", "\n", "all_attentions", "=", "tuple", "(", "tf", ".", "reshape", "(", "t", ",", "attention_output_shape", ")", "for", "t", "in", "all_attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFCTRLModel.__init__": [[445, 448], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_ctrl.TFCTRLMainLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFCTRLModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFCTRLMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFCTRLModel.call": [[449, 452], ["modeling_tf_ctrl.TFCTRLModel.transformer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFCTRLLMHead.__init__": [[455, 462], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "input_embeddings", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFCTRLLMHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "input_embeddings", "=", "input_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFCTRLLMHead.build": [[463, 466], ["modeling_tf_ctrl.TFCTRLLMHead.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "vocab_size", ",", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"bias\"", ")", "\n", "super", "(", "TFCTRLLMHead", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFCTRLLMHead.call": [[467, 471], ["modeling_tf_ctrl.TFCTRLLMHead.input_embeddings"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "input_embeddings", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "hidden_states", "=", "hidden_states", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFCTRLLMHeadModel.__init__": [[510, 515], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_ctrl.TFCTRLMainLayer", "modeling_tf_ctrl.TFCTRLLMHead"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFCTRLLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFCTRLMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "\n", "self", ".", "lm_head", "=", "TFCTRLLMHead", "(", "config", ",", "self", ".", "transformer", ".", "w", ",", "name", "=", "\"lm_head\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFCTRLLMHeadModel.get_output_embeddings": [[516, 518], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", ".", "input_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.TFCTRLLMHeadModel.call": [[519, 528], ["modeling_tf_ctrl.TFCTRLLMHeadModel.transformer", "modeling_tf_ctrl.TFCTRLLMHeadModel.lm_head"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "# lm_logits, presents, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.angle_defn": [[34, 37], ["numpy.power", "numpy.float32"], "function", ["None"], ["def", "angle_defn", "(", "pos", ",", "i", ",", "d_model_size", ")", ":", "\n", "    ", "angle_rates", "=", "1", "/", "np", ".", "power", "(", "10000", ",", "(", "2", "*", "(", "i", "//", "2", ")", ")", "/", "np", ".", "float32", "(", "d_model_size", ")", ")", "\n", "return", "pos", "*", "angle_rates", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.positional_encoding": [[39, 49], ["modeling_tf_ctrl.angle_defn", "numpy.sin", "numpy.cos", "tensorflow.cast", "numpy.concatenate", "numpy.arange", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.angle_defn"], ["", "def", "positional_encoding", "(", "position", ",", "d_model_size", ")", ":", "\n", "# create the sinusoidal pattern for the positional encoding", "\n", "    ", "angle_rads", "=", "angle_defn", "(", "np", ".", "arange", "(", "position", ")", "[", ":", ",", "np", ".", "newaxis", "]", ",", "np", ".", "arange", "(", "d_model_size", ")", "[", "np", ".", "newaxis", ",", ":", "]", ",", "d_model_size", ")", "\n", "\n", "sines", "=", "np", ".", "sin", "(", "angle_rads", "[", ":", ",", "0", ":", ":", "2", "]", ")", "\n", "cosines", "=", "np", ".", "cos", "(", "angle_rads", "[", ":", ",", "1", ":", ":", "2", "]", ")", "\n", "\n", "# pos_encoding = tf.cast(np.concatenate([sines, cosines], axis=-1)[np.newaxis, ...], dtype=tf.float32)", "\n", "pos_encoding", "=", "tf", ".", "cast", "(", "np", ".", "concatenate", "(", "[", "sines", ",", "cosines", "]", ",", "axis", "=", "-", "1", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "return", "pos_encoding", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.scaled_dot_product_attention": [[51, 74], ["tensorflow.matmul", "tensorflow.cast", "tensorflow.nn.softmax", "tensorflow.matmul", "tensorflow.math.sqrt", "modeling_tf_utils.shape_list"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "scaled_dot_product_attention", "(", "q", ",", "k", ",", "v", ",", "mask", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "# calculate attention", "\n", "    ", "matmul_qk", "=", "tf", ".", "matmul", "(", "q", ",", "k", ",", "transpose_b", "=", "True", ")", "\n", "\n", "dk", "=", "tf", ".", "cast", "(", "shape_list", "(", "k", ")", "[", "-", "1", "]", ",", "tf", ".", "float32", ")", "\n", "scaled_attention_logits", "=", "matmul_qk", "/", "tf", ".", "math", ".", "sqrt", "(", "dk", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "scaled_attention_logits", "+=", "mask", "*", "-", "1e4", "\n", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "        ", "scaled_attention_logits", "=", "scaled_attention_logits", "+", "attention_mask", "\n", "\n", "", "attention_weights", "=", "tf", ".", "nn", ".", "softmax", "(", "scaled_attention_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "        ", "attention_weights", "=", "attention_weights", "*", "head_mask", "\n", "\n", "", "output", "=", "tf", ".", "matmul", "(", "attention_weights", ",", "v", ")", "\n", "\n", "return", "output", ",", "attention_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_ctrl.point_wise_feed_forward_network": [[124, 128], ["tensorflow.keras.Sequential", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense"], "function", ["None"], ["", "", "def", "point_wise_feed_forward_network", "(", "d_model_size", ",", "dff", ",", "name", "=", "\"\"", ")", ":", "\n", "    ", "return", "tf", ".", "keras", ".", "Sequential", "(", "\n", "[", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "dff", ",", "activation", "=", "\"relu\"", ",", "name", "=", "\"0\"", ")", ",", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "d_model_size", ",", "name", "=", "\"2\"", ")", "]", ",", "\n", "name", "=", "\"ffn\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_t5_original_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch": [[29, 41], ["transformers.T5Config.from_json_file", "print", "transformers.T5Model", "transformers.load_tf_weights_in_t5", "print", "torch.save", "transformers.T5Model.state_dict", "str"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_t5.load_tf_weights_in_t5", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save"], ["def", "convert_tf_checkpoint_to_pytorch", "(", "tf_checkpoint_path", ",", "config_file", ",", "pytorch_dump_path", ")", ":", "\n", "# Initialise PyTorch model", "\n", "    ", "config", "=", "T5Config", ".", "from_json_file", "(", "config_file", ")", "\n", "print", "(", "\"Building PyTorch model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "model", "=", "T5Model", "(", "config", ")", "\n", "\n", "# Load weights from tf checkpoint", "\n", "load_tf_weights_in_t5", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_dump_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertEmbeddings.__init__": [[162, 172], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertEmbeddings.forward": [[173, 196], ["modeling_bert.BertEmbeddings.position_embeddings", "modeling_bert.BertEmbeddings.token_type_embeddings", "modeling_bert.BertEmbeddings.LayerNorm", "modeling_bert.BertEmbeddings.dropout", "input_ids.size", "torch.arange", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.zeros", "modeling_bert.BertEmbeddings.word_embeddings", "modeling_bert.BertEmbeddings.size", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "inputs_embeds", "=", "None", ")", ":", "\n", "        ", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "seq_length", "=", "input_shape", "[", "1", "]", "\n", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "input_shape", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "inputs_embeds", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertSelfAttention.__init__": [[199, 217], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "ValueError"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", "\n", ")", "\n", "", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertSelfAttention.transpose_for_scores": [[218, 222], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertSelfAttention.forward": [[223, 274], ["modeling_bert.BertSelfAttention.query", "modeling_bert.BertSelfAttention.transpose_for_scores", "modeling_bert.BertSelfAttention.transpose_for_scores", "modeling_bert.BertSelfAttention.transpose_for_scores", "torch.matmul", "modeling_bert.BertSelfAttention.dropout", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "modeling_bert.BertSelfAttention.key", "modeling_bert.BertSelfAttention.value", "modeling_bert.BertSelfAttention.key", "modeling_bert.BertSelfAttention.value", "modeling_bert.BertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "\n", "# If this is instantiated as a cross-attention module, the keys", "\n", "# and values come from an encoder; the attention mask needs to be", "\n", "# such that the encoder's padding tokens are not attended to.", "\n", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "mixed_key_layer", "=", "self", ".", "key", "(", "encoder_hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "encoder_hidden_states", ")", "\n", "attention_mask", "=", "encoder_attention_mask", "\n", "", "else", ":", "\n", "            ", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "self", ".", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertSelfOutput.__init__": [[277, 282], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertSelfOutput.forward": [[283, 288], ["modeling_bert.BertSelfOutput.dense", "modeling_bert.BertSelfOutput.dropout", "modeling_bert.BertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertAttention.__init__": [[291, 296], ["torch.nn.Module.__init__", "modeling_bert.BertSelfAttention", "modeling_bert.BertSelfOutput", "set"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertAttention.prune_heads": [[297, 319], ["torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_bert.BertAttention.pruned_heads.union", "len", "set", "len", "sum", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "self", ".", "num_attention_heads", ",", "self", ".", "self", ".", "attention_head_size", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "# Convert to set and remove already pruned heads", "\n", "for", "head", "in", "heads", ":", "\n", "# Compute how many pruned heads are before the head and move the index accordingly", "\n", "            ", "head", "=", "head", "-", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "\n", "# Prune linear layers", "\n", "self", ".", "self", ".", "query", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "query", ",", "index", ")", "\n", "self", ".", "self", ".", "key", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "key", ",", "index", ")", "\n", "self", ".", "self", ".", "value", "=", "prune_linear_layer", "(", "self", ".", "self", ".", "value", ",", "index", ")", "\n", "self", ".", "output", ".", "dense", "=", "prune_linear_layer", "(", "self", ".", "output", ".", "dense", ",", "index", ",", "dim", "=", "1", ")", "\n", "\n", "# Update hyper params and store pruned heads", "\n", "self", ".", "self", ".", "num_attention_heads", "=", "self", ".", "self", ".", "num_attention_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "self", ".", "all_head_size", "=", "self", ".", "self", ".", "attention_head_size", "*", "self", ".", "self", ".", "num_attention_heads", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertAttention.forward": [[320, 334], ["modeling_bert.BertAttention.self", "modeling_bert.BertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self_outputs", "=", "self", ".", "self", "(", "\n", "hidden_states", ",", "attention_mask", ",", "head_mask", ",", "encoder_hidden_states", ",", "encoder_attention_mask", "\n", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "self_outputs", "[", "0", "]", ",", "hidden_states", ")", "\n", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertIntermediate.__init__": [[337, 344], ["torch.nn.Module.__init__", "torch.nn.Linear", "isinstance"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertIntermediate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertIntermediate.forward": [[345, 349], ["modeling_bert.BertIntermediate.dense", "modeling_bert.BertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertOutput.__init__": [[352, 357], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertOutput.forward": [[358, 363], ["modeling_bert.BertOutput.dense", "modeling_bert.BertOutput.dropout", "modeling_bert.BertOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertLayer.__init__": [[366, 374], ["torch.nn.Module.__init__", "modeling_bert.BertAttention", "modeling_bert.BertIntermediate", "modeling_bert.BertOutput", "modeling_bert.BertAttention"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "BertAttention", "(", "config", ")", "\n", "self", ".", "is_decoder", "=", "config", ".", "is_decoder", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "self", ".", "crossattention", "=", "BertAttention", "(", "config", ")", "\n", "", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertLayer.forward": [[375, 398], ["modeling_bert.BertLayer.attention", "modeling_bert.BertLayer.intermediate", "modeling_bert.BertLayer.output", "modeling_bert.BertLayer.crossattention"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self_attention_outputs", "=", "self", ".", "attention", "(", "hidden_states", ",", "attention_mask", ",", "head_mask", ")", "\n", "attention_output", "=", "self_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "self_attention_outputs", "[", "1", ":", "]", "# add self attentions if we output attention weights", "\n", "\n", "if", "self", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "cross_attention_outputs", "=", "self", ".", "crossattention", "(", "\n", "attention_output", ",", "attention_mask", ",", "head_mask", ",", "encoder_hidden_states", ",", "encoder_attention_mask", "\n", ")", "\n", "attention_output", "=", "cross_attention_outputs", "[", "0", "]", "\n", "outputs", "=", "outputs", "+", "cross_attention_outputs", "[", "1", ":", "]", "# add cross attentions if we output attention weights", "\n", "\n", "", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "outputs", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertEncoder.__init__": [[401, 406], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "modeling_bert.BertLayer", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "BertLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertEncoder.forward": [[407, 439], ["enumerate", "layer_module"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "\n", "hidden_states", ",", "attention_mask", ",", "head_mask", "[", "i", "]", ",", "encoder_hidden_states", ",", "encoder_attention_mask", "\n", ")", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertPooler.__init__": [[442, 446], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPooler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertPooler.forward": [[447, 454], ["modeling_bert.BertPooler.dense", "modeling_bert.BertPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertPredictionHeadTransform.__init__": [[457, 465], ["torch.nn.Module.__init__", "torch.nn.Linear", "isinstance", "BertLayerNorm"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPredictionHeadTransform", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "config", ".", "hidden_act", "\n", "", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertPredictionHeadTransform.forward": [[466, 471], ["modeling_bert.BertPredictionHeadTransform.dense", "modeling_bert.BertPredictionHeadTransform.transform_act_fn", "modeling_bert.BertPredictionHeadTransform.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "transform_act_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertLMPredictionHead.__init__": [[474, 483], ["torch.nn.Module.__init__", "modeling_bert.BertPredictionHeadTransform", "torch.nn.Linear", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertLMPredictionHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "BertPredictionHeadTransform", "(", "config", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "config", ".", "vocab_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertLMPredictionHead.forward": [[484, 488], ["modeling_bert.BertLMPredictionHead.transform", "modeling_bert.BertLMPredictionHead.decoder"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline.transform"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transform", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "decoder", "(", "hidden_states", ")", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertOnlyMLMHead.__init__": [[491, 494], ["torch.nn.Module.__init__", "modeling_bert.BertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOnlyMLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertOnlyMLMHead.forward": [[495, 498], ["modeling_bert.BertOnlyMLMHead.predictions"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertOnlyNSPHead.__init__": [[501, 504], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOnlyNSPHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertOnlyNSPHead.forward": [[505, 508], ["modeling_bert.BertOnlyNSPHead.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pooled_output", ")", ":", "\n", "        ", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertPreTrainingHeads.__init__": [[511, 515], ["torch.nn.Module.__init__", "modeling_bert.BertLMPredictionHead", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPreTrainingHeads", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertPreTrainingHeads.forward": [[516, 520], ["modeling_bert.BertPreTrainingHeads.predictions", "modeling_bert.BertPreTrainingHeads.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ",", "pooled_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertPreTrainedModel._init_weights": [[532, 543], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "BertLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertModel.__init__": [[656, 665], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertEmbeddings", "modeling_bert.BertEncoder", "modeling_bert.BertPooler", "modeling_bert.BertModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "config", "=", "config", "\n", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertModel.get_input_embeddings": [[666, 668], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertModel.set_input_embeddings": [[669, 671], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "embeddings", ".", "word_embeddings", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertModel._prune_heads": [[672, 679], ["heads_to_prune.items", "modeling_bert.BertModel.encoder.layer[].attention.prune_heads"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertModel.forward": [[680, 817], ["extended_attention_mask.to.to.to", "modeling_bert.BertModel.embeddings", "modeling_bert.BertModel.encoder", "modeling_bert.BertModel.pooler", "ValueError", "torch.ones", "torch.zeros", "torch.ones.dim", "encoder_hidden_states.size", "encoder_extended_attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "input_ids.size", "torch.ones.dim", "ValueError", "torch.ones", "torch.ones.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "ValueError", "torch.arange", "causal_mask.to.to.to", "next", "torch.ones.dim", "ValueError", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "inputs_embeds.size", "seq_ids[].repeat", "modeling_bert.BertModel.parameters", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "modeling_bert.BertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_bert.BertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Forward pass on the Model.\n\n        The model can behave as an encoder (with only self-attention) as well\n        as a decoder, in which case a layer of cross-attention is added between\n        the self-attention layers, following the architecture described in `Attention is all you need`_ by Ashish Vaswani,\n        Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser and Illia Polosukhin.\n\n        To behave as an decoder the model needs to be initialized with the\n        `is_decoder` argument of the configuration set to `True`; an\n        `encoder_hidden_states` is expected as an input to the forward pass.\n\n        .. _`Attention is all you need`:\n            https://arxiv.org/abs/1706.03762\n\n        \"\"\"", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "input_shape", ",", "device", "=", "device", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "if", "attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "# Provided a padding mask of dimensions [batch_size, seq_length]", "\n", "# - if the model is a decoder, apply a causal mask in addition to the padding mask", "\n", "# - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]", "\n", "            ", "if", "self", ".", "config", ".", "is_decoder", ":", "\n", "                ", "batch_size", ",", "seq_length", "=", "input_shape", "\n", "seq_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "device", "=", "device", ")", "\n", "causal_mask", "=", "seq_ids", "[", "None", ",", "None", ",", ":", "]", ".", "repeat", "(", "batch_size", ",", "seq_length", ",", "1", ")", "<=", "seq_ids", "[", "None", ",", ":", ",", "None", "]", "\n", "causal_mask", "=", "causal_mask", ".", "to", "(", "\n", "torch", ".", "long", "\n", ")", "# not converting to long will cause errors with pytorch version < 1.3", "\n", "extended_attention_mask", "=", "causal_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "*", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Wrong shape for input_ids (shape {}) or attention_mask (shape {})\"", ".", "format", "(", "\n", "input_shape", ",", "attention_mask", ".", "shape", "\n", ")", "\n", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# If a 2D ou 3D attention mask is provided for the cross-attention", "\n", "# we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]", "\n", "if", "self", ".", "config", ".", "is_decoder", "and", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "encoder_batch_size", ",", "encoder_sequence_length", ",", "_", "=", "encoder_hidden_states", ".", "size", "(", ")", "\n", "encoder_hidden_shape", "=", "(", "encoder_batch_size", ",", "encoder_sequence_length", ")", "\n", "if", "encoder_attention_mask", "is", "None", ":", "\n", "                ", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "encoder_hidden_shape", ",", "device", "=", "device", ")", "\n", "\n", "", "if", "encoder_attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "elif", "encoder_attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Wrong shape for encoder_hidden_shape (shape {}) or encoder_attention_mask (shape {})\"", ".", "format", "(", "\n", "encoder_hidden_shape", ",", "encoder_attention_mask", ".", "shape", "\n", ")", "\n", ")", "\n", "\n", "", "encoder_extended_attention_mask", "=", "encoder_extended_attention_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# fp16 compatibility", "\n", "encoder_extended_attention_mask", "=", "(", "1.0", "-", "encoder_extended_attention_mask", ")", "*", "-", "10000.0", "\n", "", "else", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "num_hidden_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "\n", "input_ids", "=", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "inputs_embeds", "=", "inputs_embeds", "\n", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ",", ")", "+", "encoder_outputs", "[", "\n", "1", ":", "\n", "]", "# add hidden_states and attentions if they are here", "\n", "return", "outputs", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForPreTraining.__init__": [[863, 870], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertPreTrainingHeads", "modeling_bert.BertForPreTraining.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForPreTraining", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertPreTrainingHeads", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForPreTraining.get_output_embeddings": [[871, 873], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cls", ".", "predictions", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForPreTraining.forward": [[874, 910], ["modeling_bert.BertForPreTraining.bert", "modeling_bert.BertForPreTraining.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "prediction_scores.view", "masked_lm_labels.view", "seq_relationship_score.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "masked_lm_labels", "=", "None", ",", "\n", "next_sentence_label", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "outputs", "[", ":", "2", "]", "\n", "prediction_scores", ",", "seq_relationship_score", "=", "self", ".", "cls", "(", "sequence_output", ",", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", "seq_relationship_score", ",", ")", "+", "outputs", "[", "\n", "2", ":", "\n", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", "and", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "total_loss", "=", "masked_lm_loss", "+", "next_sentence_loss", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), prediction_scores, seq_relationship_score, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForMaskedLM.__init__": [[953, 960], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertOnlyMLMHead", "modeling_bert.BertForMaskedLM.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyMLMHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForMaskedLM.get_output_embeddings": [[961, 963], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cls", ".", "predictions", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForMaskedLM.forward": [[964, 1014], ["modeling_bert.BertForMaskedLM.bert", "modeling_bert.BertForMaskedLM.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "prediction_scores[].contiguous", "lm_labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "prediction_scores[].contiguous.view", "masked_lm_labels.view", "prediction_scores[].contiguous.view", "lm_labels[].contiguous.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "masked_lm_labels", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", "lm_labels", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_attention_mask", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "cls", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "\n", "# Although this may seem awkward, BertForMaskedLM supports two scenarios:", "\n", "# 1. If a tensor that contains the indices of masked labels is provided,", "\n", "#    the cross-entropy is the MLM cross-entropy that measures the likelihood", "\n", "#    of predictions for masked words.", "\n", "# 2. If `lm_labels` is provided we are in a causal scenario where we", "\n", "#    try to predict the next token for each input in the decoder.", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "# -100 index = padding token", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "if", "lm_labels", "is", "not", "None", ":", "\n", "# we are doing next-token prediction; shift prediction scores and input ids by one", "\n", "            ", "prediction_scores", "=", "prediction_scores", "[", ":", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "lm_labels", "=", "lm_labels", "[", ":", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "ltr_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "ltr_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (masked_lm_loss), (ltr_lm_loss), prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForNextSentencePrediction.__init__": [[1052, 1059], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "modeling_bert.BertOnlyNSPHead", "modeling_bert.BertForNextSentencePrediction.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForNextSentencePrediction", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyNSPHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForNextSentencePrediction.forward": [[1060, 1091], ["modeling_bert.BertForNextSentencePrediction.bert", "modeling_bert.BertForNextSentencePrediction.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_bert.BertForNextSentencePrediction.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "next_sentence_label", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "seq_relationship_score", "=", "self", ".", "cls", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "seq_relationship_score", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "next_sentence_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (next_sentence_loss), seq_relationship_score, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForSequenceClassification.__init__": [[1131, 1140], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling_bert.BertForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForSequenceClassification.forward": [[1141, 1179], ["modeling_bert.BertForSequenceClassification.bert", "modeling_bert.BertForSequenceClassification.dropout", "modeling_bert.BertForSequenceClassification.classifier", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_bert.BertForSequenceClassification.view", "labels.view", "modeling_bert.BertForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForMultipleChoice.__init__": [[1220, 1228], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling_bert.BertForMultipleChoice.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForMultipleChoice.forward": [[1229, 1269], ["input_ids.view.view.view", "modeling_bert.BertForMultipleChoice.bert", "modeling_bert.BertForMultipleChoice.dropout", "modeling_bert.BertForMultipleChoice.classifier", "modeling_bert.BertForMultipleChoice.view", "input_ids.view.view.size", "attention_mask.view", "token_type_ids.view", "position_ids.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "attention_mask.size", "token_type_ids.size", "position_ids.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "num_choices", ")", "\n", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), reshaped_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForTokenClassification.__init__": [[1307, 1316], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling_bert.BertForTokenClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForTokenClassification.forward": [[1317, 1356], ["modeling_bert.BertForTokenClassification.bert", "modeling_bert.BertForTokenClassification.dropout", "modeling_bert.BertForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "modeling_bert.BertForTokenClassification.view", "labels.view", "modeling_bert.BertForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForQuestionAnswering.__init__": [[1406, 1414], ["modeling_utils.PreTrainedModel.__init__", "modeling_bert.BertModel", "torch.nn.Linear", "modeling_bert.BertForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.BertForQuestionAnswering.forward": [[1415, 1462], ["modeling_bert.BertForQuestionAnswering.bert", "modeling_bert.BertForQuestionAnswering.qa_outputs", "modeling_bert.BertForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "\n", "end_positions", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.load_tf_weights_in_bert": [[59, 126], ["os.path.abspath", "logger.info", "tf.train.list_variables", "zip", "logger.info", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "any", "logger.info", "torch.from_numpy", "logger.error", "logger.info", "re.fullmatch", "getattr", "re.split", "getattr", "len", "int", "np.transpose", "getattr", "getattr", "getattr", "getattr", "logger.info"], "function", ["None"], ["def", "load_tf_weights_in_bert", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", ".", "split", "(", "\"/\"", ")", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "any", "(", "n", "in", "[", "\"adam_v\"", ",", "\"adam_m\"", ",", "\"global_step\"", "]", "for", "n", "in", "name", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r\"[A-Za-z]+_\\d+\"", ",", "m_name", ")", ":", "\n", "                ", "scope_names", "=", "re", ".", "split", "(", "r\"_(\\d+)\"", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "scope_names", "=", "[", "m_name", "]", "\n", "", "if", "scope_names", "[", "0", "]", "==", "\"kernel\"", "or", "scope_names", "[", "0", "]", "==", "\"gamma\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"output_bias\"", "or", "scope_names", "[", "0", "]", "==", "\"beta\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"bias\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"output_weights\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"squad\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"classifier\"", ")", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "", "if", "len", "(", "scope_names", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "scope_names", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "if", "m_name", "[", "-", "11", ":", "]", "==", "\"_embeddings\"", ":", "\n", "            ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "m_name", "==", "\"kernel\"", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.gelu": [[128, 135], ["torch.erf", "math.sqrt"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Original Implementation of the gelu activation function in Google Bert repo when initially created.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.gelu_new": [[137, 142], ["torch.tanh", "math.sqrt", "torch.pow"], "function", ["None"], ["", "def", "gelu_new", "(", "x", ")", ":", "\n", "    ", "\"\"\" Implementation of the gelu activation function currently in Google Bert repo (identical to OpenAI GPT).\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.swish": [[144, 146], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.mish": [[148, 150], ["torch.tanh", "torch.nn.functional.softplus"], "function", ["None"], ["", "def", "mish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "tanh", "(", "nn", ".", "functional", ".", "softplus", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertEmbeddings.__init__": [[95, 118], ["super().__init__", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertEmbeddings", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "self", ".", "hidden_size", "=", "config", ".", "hidden_size", "\n", "self", ".", "initializer_range", "=", "config", ".", "initializer_range", "\n", "\n", "self", ".", "position_embeddings", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "\n", "config", ".", "hidden_size", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"position_embeddings\"", ",", "\n", ")", "\n", "self", ".", "token_type_embeddings", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "\n", "config", ".", "type_vocab_size", ",", "\n", "config", ".", "hidden_size", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"token_type_embeddings\"", ",", "\n", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "\"LayerNorm\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertEmbeddings.build": [[119, 130], ["super().build", "tensorflow.name_scope", "modeling_tf_bert.TFBertEmbeddings.add_weight", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "\"\"\"Build shared word embedding layer \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"word_embeddings\"", ")", ":", "\n", "# Create and initialize weights. The random normal initializer was chosen", "\n", "# arbitrarily, and works well.", "\n", "            ", "self", ".", "word_embeddings", "=", "self", ".", "add_weight", "(", "\n", "\"weight\"", ",", "\n", "shape", "=", "[", "self", ".", "vocab_size", ",", "self", ".", "hidden_size", "]", ",", "\n", "initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", ",", "\n", ")", "\n", "", "super", "(", "TFBertEmbeddings", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertEmbeddings.call": [[131, 152], ["modeling_tf_bert.TFBertEmbeddings._embedding", "modeling_tf_bert.TFBertEmbeddings._linear", "ValueError"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertEmbeddings._embedding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertEmbeddings._linear"], ["", "def", "call", "(", "self", ",", "inputs", ",", "mode", "=", "\"embedding\"", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Get token embeddings of inputs.\n        Args:\n            inputs: list of three int64 tensors with shape [batch_size, length]: (input_ids, position_ids, token_type_ids)\n            mode: string, a valid value is one of \"embedding\" and \"linear\".\n        Returns:\n            outputs: (1) If mode == \"embedding\", output embedding tensor, float32 with\n                shape [batch_size, length, embedding_size]; (2) mode == \"linear\", output\n                linear tensor, float32 with shape [batch_size, length, vocab_size].\n        Raises:\n            ValueError: if mode is not valid.\n\n        Shared weights logic adapted from\n            https://github.com/tensorflow/models/blob/a009f4fb9d2fc4949e32192a944688925ef78659/official/transformer/v2/embedding_layer.py#L24\n        \"\"\"", "\n", "if", "mode", "==", "\"embedding\"", ":", "\n", "            ", "return", "self", ".", "_embedding", "(", "inputs", ",", "training", "=", "training", ")", "\n", "", "elif", "mode", "==", "\"linear\"", ":", "\n", "            ", "return", "self", ".", "_linear", "(", "inputs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"mode {} is not valid.\"", ".", "format", "(", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertEmbeddings._embedding": [[153, 177], ["modeling_tf_bert.TFBertEmbeddings.position_embeddings", "modeling_tf_bert.TFBertEmbeddings.token_type_embeddings", "modeling_tf_bert.TFBertEmbeddings.LayerNorm", "modeling_tf_bert.TFBertEmbeddings.dropout", "modeling_tf_utils.shape_list", "tensorflow.fill", "tensorflow.gather", "modeling_tf_utils.shape_list", "tensorflow.range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "", "def", "_embedding", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Applies embedding based on inputs tensor.\"\"\"", "\n", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "inputs_embeds", "=", "inputs", "\n", "\n", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "input_ids", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "inputs_embeds", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "seq_length", "=", "input_shape", "[", "1", "]", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "tf", ".", "range", "(", "seq_length", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "tf", ".", "newaxis", ",", ":", "]", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "tf", ".", "fill", "(", "input_shape", ",", "0", ")", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "tf", ".", "gather", "(", "self", ".", "word_embeddings", ",", "input_ids", ")", "\n", "", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "inputs_embeds", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ",", "training", "=", "training", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertEmbeddings._linear": [[178, 192], ["tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "_linear", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Computes logits by running inputs through a linear layer.\n            Args:\n                inputs: A float32 tensor with shape [batch_size, length, hidden_size]\n            Returns:\n                float32 tensor with shape [batch_size, length, vocab_size].\n        \"\"\"", "\n", "batch_size", "=", "shape_list", "(", "inputs", ")", "[", "0", "]", "\n", "length", "=", "shape_list", "(", "inputs", ")", "[", "1", "]", "\n", "\n", "x", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "-", "1", ",", "self", ".", "hidden_size", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "x", ",", "self", ".", "word_embeddings", ",", "transpose_b", "=", "True", ")", "\n", "\n", "return", "tf", ".", "reshape", "(", "logits", ",", "[", "batch_size", ",", "length", ",", "self", ".", "vocab_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertSelfAttention.__init__": [[195, 220], ["super().__init__", "int", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "ValueError", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertSelfAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", "\n", ")", "\n", "", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "assert", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "==", "0", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "all_head_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"query\"", "\n", ")", "\n", "self", ".", "key", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "all_head_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"key\"", "\n", ")", "\n", "self", ".", "value", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "all_head_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"value\"", "\n", ")", "\n", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertSelfAttention.transpose_for_scores": [[221, 224], ["tensorflow.reshape", "tensorflow.transpose"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ",", "batch_size", ")", ":", "\n", "        ", "x", "=", "tf", ".", "reshape", "(", "x", ",", "(", "batch_size", ",", "-", "1", ",", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", ")", "\n", "return", "tf", ".", "transpose", "(", "x", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertSelfAttention.call": [[225, 268], ["modeling_tf_bert.TFBertSelfAttention.query", "modeling_tf_bert.TFBertSelfAttention.key", "modeling_tf_bert.TFBertSelfAttention.value", "modeling_tf_bert.TFBertSelfAttention.transpose_for_scores", "modeling_tf_bert.TFBertSelfAttention.transpose_for_scores", "modeling_tf_bert.TFBertSelfAttention.transpose_for_scores", "tensorflow.matmul", "tensorflow.cast", "tensorflow.nn.softmax", "modeling_tf_bert.TFBertSelfAttention.dropout", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.reshape", "modeling_tf_utils.shape_list", "tensorflow.math.sqrt", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "batch_size", "=", "shape_list", "(", "hidden_states", ")", "[", "0", "]", "\n", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ",", "batch_size", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ",", "batch_size", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ",", "batch_size", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "tf", ".", "matmul", "(", "\n", "query_layer", ",", "key_layer", ",", "transpose_b", "=", "True", "\n", ")", "# (batch size, num_heads, seq_len_q, seq_len_k)", "\n", "dk", "=", "tf", ".", "cast", "(", "shape_list", "(", "key_layer", ")", "[", "-", "1", "]", ",", "tf", ".", "float32", ")", "# scale attention_scores", "\n", "attention_scores", "=", "attention_scores", "/", "tf", ".", "math", ".", "sqrt", "(", "dk", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask is (precomputed for all layers in TFBertModel call() function)", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "", "attention_probs", "=", "tf", ".", "nn", ".", "softmax", "(", "attention_scores", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ",", "training", "=", "training", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "tf", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "tf", ".", "transpose", "(", "context_layer", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "context_layer", "=", "tf", ".", "reshape", "(", "\n", "context_layer", ",", "(", "batch_size", ",", "-", "1", ",", "self", ".", "all_head_size", ")", "\n", ")", "# (batch_size, seq_len_q, all_head_size)", "\n", "\n", "outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "self", ".", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertSelfOutput.__init__": [[271, 278], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertSelfOutput", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "hidden_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"dense\"", "\n", ")", "\n", "self", ".", "LayerNorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "\"LayerNorm\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertSelfOutput.call": [[279, 286], ["modeling_tf_bert.TFBertSelfOutput.dense", "modeling_tf_bert.TFBertSelfOutput.dropout", "modeling_tf_bert.TFBertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "input_tensor", "=", "inputs", "\n", "\n", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertAttention.__init__": [[289, 293], ["super().__init__", "modeling_tf_bert.TFBertSelfAttention", "modeling_tf_bert.TFBertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "self_attention", "=", "TFBertSelfAttention", "(", "config", ",", "name", "=", "\"self\"", ")", "\n", "self", ".", "dense_output", "=", "TFBertSelfOutput", "(", "config", ",", "name", "=", "\"output\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertAttention.prune_heads": [[294, 296], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertAttention.call": [[297, 304], ["modeling_tf_bert.TFBertAttention.self_attention", "modeling_tf_bert.TFBertAttention.dense_output"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "input_tensor", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "self_outputs", "=", "self", ".", "self_attention", "(", "[", "input_tensor", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "attention_output", "=", "self", ".", "dense_output", "(", "[", "self_outputs", "[", "0", "]", ",", "input_tensor", "]", ",", "training", "=", "training", ")", "\n", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertIntermediate.__init__": [[307, 316], ["super().__init__", "tensorflow.keras.layers.Dense", "isinstance", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertIntermediate", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "intermediate_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"dense\"", "\n", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertIntermediate.call": [[317, 321], ["modeling_tf_bert.TFBertIntermediate.dense", "modeling_tf_bert.TFBertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertOutput.__init__": [[324, 331], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertOutput", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "hidden_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"dense\"", "\n", ")", "\n", "self", ".", "LayerNorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "\"LayerNorm\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertOutput.call": [[332, 339], ["modeling_tf_bert.TFBertOutput.dense", "modeling_tf_bert.TFBertOutput.dropout", "modeling_tf_bert.TFBertOutput.LayerNorm"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "input_tensor", "=", "inputs", "\n", "\n", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertLayer.__init__": [[342, 347], ["super().__init__", "modeling_tf_bert.TFBertAttention", "modeling_tf_bert.TFBertIntermediate", "modeling_tf_bert.TFBertOutput"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "attention", "=", "TFBertAttention", "(", "config", ",", "name", "=", "\"attention\"", ")", "\n", "self", ".", "intermediate", "=", "TFBertIntermediate", "(", "config", ",", "name", "=", "\"intermediate\"", ")", "\n", "self", ".", "bert_output", "=", "TFBertOutput", "(", "config", ",", "name", "=", "\"output\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertLayer.call": [[348, 357], ["modeling_tf_bert.TFBertLayer.attention", "modeling_tf_bert.TFBertLayer.intermediate", "modeling_tf_bert.TFBertLayer.bert_output"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "attention_outputs", "=", "self", ".", "attention", "(", "[", "hidden_states", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "attention_output", "=", "attention_outputs", "[", "0", "]", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "bert_output", "(", "[", "intermediate_output", ",", "attention_output", "]", ",", "training", "=", "training", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "attention_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertEncoder.__init__": [[360, 365], ["super().__init__", "modeling_tf_bert.TFBertLayer", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertEncoder", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "layer", "=", "[", "TFBertLayer", "(", "config", ",", "name", "=", "\"layer_._{}\"", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertEncoder.call": [[366, 391], ["enumerate", "layer_module"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "(", ")", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "layer_outputs", "=", "layer_module", "(", "[", "hidden_states", ",", "attention_mask", ",", "head_mask", "[", "i", "]", "]", ",", "training", "=", "training", ")", "\n", "hidden_states", "=", "layer_outputs", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "layer_outputs", "[", "1", "]", ",", ")", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# outputs, (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertPooler.__init__": [[394, 401], ["super().__init__", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertPooler", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "hidden_size", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "activation", "=", "\"tanh\"", ",", "\n", "name", "=", "\"dense\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertPooler.call": [[403, 409], ["modeling_tf_bert.TFBertPooler.dense"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertPredictionHeadTransform.__init__": [[412, 422], ["super().__init__", "tensorflow.keras.layers.Dense", "isinstance", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertPredictionHeadTransform", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "hidden_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"dense\"", "\n", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "config", ".", "hidden_act", "\n", "", "self", ".", "LayerNorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "\"LayerNorm\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertPredictionHeadTransform.call": [[423, 428], ["modeling_tf_bert.TFBertPredictionHeadTransform.dense", "modeling_tf_bert.TFBertPredictionHeadTransform.transform_act_fn", "modeling_tf_bert.TFBertPredictionHeadTransform.LayerNorm"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "transform_act_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertLMPredictionHead.__init__": [[431, 439], ["super().__init__", "modeling_tf_bert.TFBertPredictionHeadTransform"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "input_embeddings", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertLMPredictionHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "self", ".", "transform", "=", "TFBertPredictionHeadTransform", "(", "config", ",", "name", "=", "\"transform\"", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "input_embeddings", "=", "input_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertLMPredictionHead.build": [[440, 443], ["modeling_tf_bert.TFBertLMPredictionHead.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "vocab_size", ",", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"bias\"", ")", "\n", "super", "(", "TFBertLMPredictionHead", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertLMPredictionHead.call": [[444, 449], ["modeling_tf_bert.TFBertLMPredictionHead.transform", "modeling_tf_bert.TFBertLMPredictionHead.input_embeddings"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.Pipeline.transform"], ["", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transform", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "input_embeddings", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "hidden_states", "=", "hidden_states", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertMLMHead.__init__": [[452, 455], ["super().__init__", "modeling_tf_bert.TFBertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "input_embeddings", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertMLMHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "predictions", "=", "TFBertLMPredictionHead", "(", "config", ",", "input_embeddings", ",", "name", "=", "\"predictions\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertMLMHead.call": [[456, 459], ["modeling_tf_bert.TFBertMLMHead.predictions"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "sequence_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertNSPHead.__init__": [[462, 466], ["super().__init__", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertNSPHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "seq_relationship", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "2", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"seq_relationship\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertNSPHead.call": [[468, 471], ["modeling_tf_bert.TFBertNSPHead.seq_relationship"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "pooled_output", ")", ":", "\n", "        ", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertMainLayer.__init__": [[474, 481], ["super().__init__", "modeling_tf_bert.TFBertEmbeddings", "modeling_tf_bert.TFBertEncoder", "modeling_tf_bert.TFBertPooler"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertMainLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "num_hidden_layers", "=", "config", ".", "num_hidden_layers", "\n", "\n", "self", ".", "embeddings", "=", "TFBertEmbeddings", "(", "config", ",", "name", "=", "\"embeddings\"", ")", "\n", "self", ".", "encoder", "=", "TFBertEncoder", "(", "config", ",", "name", "=", "\"encoder\"", ")", "\n", "self", ".", "pooler", "=", "TFBertPooler", "(", "config", ",", "name", "=", "\"pooler\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertMainLayer.get_input_embeddings": [[482, 484], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertMainLayer._resize_token_embeddings": [[485, 487], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertMainLayer._prune_heads": [[488, 494], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertMainLayer.call": [[495, 575], ["isinstance", "tensorflow.cast", "modeling_tf_bert.TFBertMainLayer.embeddings", "modeling_tf_bert.TFBertMainLayer.encoder", "modeling_tf_bert.TFBertMainLayer.pooler", "isinstance", "ValueError", "tensorflow.fill", "tensorflow.fill", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "modeling_tf_utils.shape_list", "len", "len", "len", "len", "len", "len", "ValueError", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "\n", "self", ",", "\n", "inputs", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "training", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "head_mask", "\n", "inputs_embeds", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "inputs_embeds", "\n", "assert", "len", "(", "inputs", ")", "<=", "6", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "\"input_ids\"", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "\"attention_mask\"", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "\"token_type_ids\"", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "\"position_ids\"", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "\"head_mask\"", ",", "head_mask", ")", "\n", "inputs_embeds", "=", "inputs", ".", "get", "(", "\"inputs_embeds\"", ",", "inputs_embeds", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "6", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "input_ids", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "inputs_embeds", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "tf", ".", "fill", "(", "input_shape", ",", "1", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "tf", ".", "fill", "(", "input_shape", ",", "0", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "tf", ".", "newaxis", ",", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "\n", "extended_attention_mask", "=", "tf", ".", "cast", "(", "extended_attention_mask", ",", "tf", ".", "float32", ")", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "num_hidden_layers", "\n", "# head_mask = tf.constant([0] * self.num_hidden_layers)", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "[", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "inputs_embeds", "]", ",", "training", "=", "training", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "[", "embedding_output", ",", "extended_attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ",", ")", "+", "encoder_outputs", "[", "\n", "1", ":", "\n", "]", "# add hidden_states and attentions if they are here", "\n", "return", "outputs", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertModel.__init__": [[709, 712], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "\"bert\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertModel.call": [[713, 716], ["modeling_tf_bert.TFBertModel.bert"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForPreTraining.__init__": [[752, 758], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer", "modeling_tf_bert.TFBertNSPHead", "modeling_tf_bert.TFBertMLMHead"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertForPreTraining", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "\"bert\"", ")", "\n", "self", ".", "nsp", "=", "TFBertNSPHead", "(", "config", ",", "name", "=", "\"nsp___cls\"", ")", "\n", "self", ".", "mlm", "=", "TFBertMLMHead", "(", "config", ",", "self", ".", "bert", ".", "embeddings", ",", "name", "=", "\"mlm___cls\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForPreTraining.get_output_embeddings": [[759, 761], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "bert", ".", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForPreTraining.call": [[762, 774], ["modeling_tf_bert.TFBertForPreTraining.bert", "modeling_tf_bert.TFBertForPreTraining.mlm", "modeling_tf_bert.TFBertForPreTraining.nsp", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", ",", "pooled_output", "=", "outputs", "[", ":", "2", "]", "\n", "prediction_scores", "=", "self", ".", "mlm", "(", "sequence_output", ",", "training", "=", "kwargs", ".", "get", "(", "\"training\"", ",", "False", ")", ")", "\n", "seq_relationship_score", "=", "self", ".", "nsp", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", "seq_relationship_score", ",", ")", "+", "outputs", "[", "\n", "2", ":", "\n", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# prediction_scores, seq_relationship_score, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForMaskedLM.__init__": [[805, 810], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer", "modeling_tf_bert.TFBertMLMHead"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "\"bert\"", ")", "\n", "self", ".", "mlm", "=", "TFBertMLMHead", "(", "config", ",", "self", ".", "bert", ".", "embeddings", ",", "name", "=", "\"mlm___cls\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForMaskedLM.get_output_embeddings": [[811, 813], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "bert", ".", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForMaskedLM.call": [[814, 823], ["modeling_tf_bert.TFBertForMaskedLM.bert", "modeling_tf_bert.TFBertForMaskedLM.mlm", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "mlm", "(", "sequence_output", ",", "training", "=", "kwargs", ".", "get", "(", "\"training\"", ",", "False", ")", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForNextSentencePrediction.__init__": [[856, 861], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer", "modeling_tf_bert.TFBertNSPHead"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertForNextSentencePrediction", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "\"bert\"", ")", "\n", "self", ".", "nsp", "=", "TFBertNSPHead", "(", "config", ",", "name", "=", "\"nsp___cls\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForNextSentencePrediction.call": [[862, 871], ["modeling_tf_bert.TFBertForNextSentencePrediction.bert", "modeling_tf_bert.TFBertForNextSentencePrediction.nsp"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "seq_relationship_score", "=", "self", ".", "nsp", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "seq_relationship_score", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# seq_relationship_score, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForSequenceClassification.__init__": [[905, 913], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "\"bert\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"classifier\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForSequenceClassification.call": [[915, 926], ["modeling_tf_bert.TFBertForSequenceClassification.bert", "modeling_tf_bert.TFBertForSequenceClassification.dropout", "modeling_tf_bert.TFBertForSequenceClassification.classifier", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ",", "training", "=", "kwargs", ".", "get", "(", "\"training\"", ",", "False", ")", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForMultipleChoice.__init__": [[962, 969], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "\"bert\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "1", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"classifier\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForMultipleChoice.call": [[971, 1032], ["isinstance", "modeling_tf_bert.TFBertForMultipleChoice.bert", "modeling_tf_bert.TFBertForMultipleChoice.dropout", "modeling_tf_bert.TFBertForMultipleChoice.classifier", "tensorflow.reshape", "isinstance", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "\n", "self", ",", "\n", "inputs", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "training", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "head_mask", "\n", "inputs_embeds", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "inputs_embeds", "\n", "assert", "len", "(", "inputs", ")", "<=", "6", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "\"input_ids\"", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "\"attention_mask\"", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "\"token_type_ids\"", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "\"position_ids\"", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "\"head_mask\"", ",", "head_mask", ")", "\n", "inputs_embeds", "=", "inputs", ".", "get", "(", "\"inputs_embeds\"", ",", "inputs_embeds", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "6", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "num_choices", "=", "shape_list", "(", "input_ids", ")", "[", "1", "]", "\n", "seq_length", "=", "shape_list", "(", "input_ids", ")", "[", "2", "]", "\n", "", "else", ":", "\n", "            ", "num_choices", "=", "shape_list", "(", "inputs_embeds", ")", "[", "1", "]", "\n", "seq_length", "=", "shape_list", "(", "inputs_embeds", ")", "[", "2", "]", "\n", "\n", "", "flat_input_ids", "=", "tf", ".", "reshape", "(", "input_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "input_ids", "is", "not", "None", "else", "None", "\n", "flat_attention_mask", "=", "tf", ".", "reshape", "(", "attention_mask", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "flat_token_type_ids", "=", "tf", ".", "reshape", "(", "token_type_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_position_ids", "=", "tf", ".", "reshape", "(", "position_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "\n", "flat_inputs", "=", "[", "\n", "flat_input_ids", ",", "\n", "flat_attention_mask", ",", "\n", "flat_token_type_ids", ",", "\n", "flat_position_ids", ",", "\n", "head_mask", ",", "\n", "inputs_embeds", ",", "\n", "]", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "flat_inputs", ",", "training", "=", "training", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ",", "training", "=", "training", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "tf", ".", "reshape", "(", "logits", ",", "(", "-", "1", ",", "num_choices", ")", ")", "\n", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# reshaped_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForTokenClassification.__init__": [[1066, 1074], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "\"bert\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"classifier\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForTokenClassification.call": [[1076, 1087], ["modeling_tf_bert.TFBertForTokenClassification.bert", "modeling_tf_bert.TFBertForTokenClassification.dropout", "modeling_tf_bert.TFBertForTokenClassification.classifier", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ",", "training", "=", "kwargs", ".", "get", "(", "\"training\"", ",", "False", ")", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForQuestionAnswering.__init__": [[1123, 1130], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_bert.TFBertMainLayer", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "bert", "=", "TFBertMainLayer", "(", "config", ",", "name", "=", "\"bert\"", ")", "\n", "self", ".", "qa_outputs", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"qa_outputs\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.TFBertForQuestionAnswering.call": [[1132, 1145], ["modeling_tf_bert.TFBertForQuestionAnswering.bert", "modeling_tf_bert.TFBertForQuestionAnswering.qa_outputs", "tensorflow.split", "tensorflow.squeeze", "tensorflow.squeeze"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "tf", ".", "split", "(", "logits", ",", "2", ",", "axis", "=", "-", "1", ")", "\n", "start_logits", "=", "tf", ".", "squeeze", "(", "start_logits", ",", "axis", "=", "-", "1", ")", "\n", "end_logits", "=", "tf", ".", "squeeze", "(", "end_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "\n", "return", "outputs", "# start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.gelu": [[55, 64], ["tensorflow.math.erf", "tensorflow.math.sqrt"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Gaussian Error Linear Unit.\n    Original Implementation of the gelu activation function in Google Bert repo when initially created.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "math", ".", "erf", "(", "x", "/", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.gelu_new": [[66, 77], ["tensorflow.tanh", "numpy.sqrt", "tensorflow.pow"], "function", ["None"], ["", "def", "gelu_new", "(", "x", ")", ":", "\n", "    ", "\"\"\"Gaussian Error Linear Unit.\n    This is a smoother version of the RELU.\n    Original paper: https://arxiv.org/abs/1606.08415\n    Args:\n        x: float Tensor to perform activation.\n    Returns:\n        `x` with the GELU activation applied.\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "tanh", "(", "(", "np", ".", "sqrt", "(", "2", "/", "np", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "tf", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_bert.swish": [[79, 81], ["tensorflow.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "tf", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertEmbeddings.__init__": [[47, 68], ["super().__init__", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAlbertEmbeddings", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "position_embeddings", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "\n", "config", ".", "embedding_size", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "self", ".", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"position_embeddings\"", ",", "\n", ")", "\n", "self", ".", "token_type_embeddings", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "\n", "config", ".", "type_vocab_size", ",", "\n", "config", ".", "embedding_size", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "self", ".", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"token_type_embeddings\"", ",", "\n", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "\"LayerNorm\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertEmbeddings.build": [[69, 80], ["super().build", "tensorflow.name_scope", "modeling_tf_albert.TFAlbertEmbeddings.add_weight", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "\"\"\"Build shared word embedding layer \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\"word_embeddings\"", ")", ":", "\n", "# Create and initialize weights. The random normal initializer was chosen", "\n", "# arbitrarily, and works well.", "\n", "            ", "self", ".", "word_embeddings", "=", "self", ".", "add_weight", "(", "\n", "\"weight\"", ",", "\n", "shape", "=", "[", "self", ".", "config", ".", "vocab_size", ",", "self", ".", "config", ".", "embedding_size", "]", ",", "\n", "initializer", "=", "get_initializer", "(", "self", ".", "config", ".", "initializer_range", ")", ",", "\n", ")", "\n", "", "super", "(", "TFAlbertEmbeddings", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertEmbeddings.call": [[81, 102], ["modeling_tf_albert.TFAlbertEmbeddings._embedding", "modeling_tf_albert.TFAlbertEmbeddings._linear", "ValueError"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertEmbeddings._embedding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertEmbeddings._linear"], ["", "def", "call", "(", "self", ",", "inputs", ",", "mode", "=", "\"embedding\"", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Get token embeddings of inputs.\n        Args:\n            inputs: list of three int64 tensors with shape [batch_size, length]: (input_ids, position_ids, token_type_ids)\n            mode: string, a valid value is one of \"embedding\" and \"linear\".\n        Returns:\n            outputs: (1) If mode == \"embedding\", output embedding tensor, float32 with\n                shape [batch_size, length, embedding_size]; (2) mode == \"linear\", output\n                linear tensor, float32 with shape [batch_size, length, vocab_size].\n        Raises:\n            ValueError: if mode is not valid.\n\n        Shared weights logic adapted from\n            https://github.com/tensorflow/models/blob/a009f4fb9d2fc4949e32192a944688925ef78659/official/transformer/v2/embedding_layer.py#L24\n        \"\"\"", "\n", "if", "mode", "==", "\"embedding\"", ":", "\n", "            ", "return", "self", ".", "_embedding", "(", "inputs", ",", "training", "=", "training", ")", "\n", "", "elif", "mode", "==", "\"linear\"", ":", "\n", "            ", "return", "self", ".", "_linear", "(", "inputs", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"mode {} is not valid.\"", ".", "format", "(", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertEmbeddings._embedding": [[103, 127], ["modeling_tf_albert.TFAlbertEmbeddings.position_embeddings", "modeling_tf_albert.TFAlbertEmbeddings.token_type_embeddings", "modeling_tf_albert.TFAlbertEmbeddings.LayerNorm", "modeling_tf_albert.TFAlbertEmbeddings.dropout", "modeling_tf_utils.shape_list", "tensorflow.fill", "tensorflow.gather", "modeling_tf_utils.shape_list", "tensorflow.range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "", "def", "_embedding", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Applies embedding based on inputs tensor.\"\"\"", "\n", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "inputs_embeds", "=", "inputs", "\n", "\n", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "input_ids", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "inputs_embeds", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "seq_length", "=", "input_shape", "[", "1", "]", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "tf", ".", "range", "(", "seq_length", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "tf", ".", "newaxis", ",", ":", "]", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "tf", ".", "fill", "(", "input_shape", ",", "0", ")", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "tf", ".", "gather", "(", "self", ".", "word_embeddings", ",", "input_ids", ")", "\n", "", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "inputs_embeds", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ",", "training", "=", "training", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertEmbeddings._linear": [[128, 140], ["tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "_linear", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "\"\"\"Computes logits by running inputs through a linear layer.\n            Args:\n                inputs: A float32 tensor with shape [batch_size, length, embedding_size]\n            Returns:\n                float32 tensor with shape [batch_size, length, vocab_size].\n        \"\"\"", "\n", "batch_size", "=", "shape_list", "(", "inputs", ")", "[", "0", "]", "\n", "length", "=", "shape_list", "(", "inputs", ")", "[", "1", "]", "\n", "x", "=", "tf", ".", "reshape", "(", "inputs", ",", "[", "-", "1", ",", "self", ".", "config", ".", "embedding_size", "]", ")", "\n", "logits", "=", "tf", ".", "matmul", "(", "x", ",", "self", ".", "word_embeddings", ",", "transpose_b", "=", "True", ")", "\n", "return", "tf", ".", "reshape", "(", "logits", ",", "[", "batch_size", ",", "length", ",", "self", ".", "config", ".", "vocab_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.__init__": [[143, 168], ["super().__init__", "int", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "ValueError", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAlbertSelfAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", "\n", ")", "\n", "", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "assert", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "==", "0", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "all_head_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"query\"", "\n", ")", "\n", "self", ".", "key", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "all_head_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"key\"", "\n", ")", "\n", "self", ".", "value", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "self", ".", "all_head_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"value\"", "\n", ")", "\n", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores": [[169, 172], ["tensorflow.reshape", "tensorflow.transpose"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ",", "batch_size", ")", ":", "\n", "        ", "x", "=", "tf", ".", "reshape", "(", "x", ",", "(", "batch_size", ",", "-", "1", ",", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", ")", "\n", "return", "tf", ".", "transpose", "(", "x", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.call": [[173, 216], ["modeling_tf_albert.TFAlbertSelfAttention.query", "modeling_tf_albert.TFAlbertSelfAttention.key", "modeling_tf_albert.TFAlbertSelfAttention.value", "modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "tensorflow.matmul", "tensorflow.cast", "tensorflow.nn.softmax", "modeling_tf_albert.TFAlbertSelfAttention.dropout", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.reshape", "modeling_tf_utils.shape_list", "tensorflow.math.sqrt", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "batch_size", "=", "shape_list", "(", "hidden_states", ")", "[", "0", "]", "\n", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ",", "batch_size", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ",", "batch_size", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ",", "batch_size", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "# (batch size, num_heads, seq_len_q, seq_len_k)", "\n", "attention_scores", "=", "tf", ".", "matmul", "(", "query_layer", ",", "key_layer", ",", "transpose_b", "=", "True", ")", "\n", "# scale attention_scores", "\n", "dk", "=", "tf", ".", "cast", "(", "shape_list", "(", "key_layer", ")", "[", "-", "1", "]", ",", "tf", ".", "float32", ")", "\n", "attention_scores", "=", "attention_scores", "/", "tf", ".", "math", ".", "sqrt", "(", "dk", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask is (precomputed for all layers in TFAlbertModel call() function)", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "", "attention_probs", "=", "tf", ".", "nn", ".", "softmax", "(", "attention_scores", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ",", "training", "=", "training", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "tf", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "tf", ".", "transpose", "(", "context_layer", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "context_layer", "=", "tf", ".", "reshape", "(", "\n", "context_layer", ",", "(", "batch_size", ",", "-", "1", ",", "self", ".", "all_head_size", ")", "\n", ")", "# (batch_size, seq_len_q, all_head_size)", "\n", "\n", "outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "self", ".", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfOutput.__init__": [[219, 226], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAlbertSelfOutput", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "hidden_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"dense\"", "\n", ")", "\n", "self", ".", "LayerNorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "\"LayerNorm\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfOutput.call": [[227, 234], ["modeling_tf_albert.TFAlbertSelfOutput.dense", "modeling_tf_albert.TFAlbertSelfOutput.dropout", "modeling_tf_albert.TFAlbertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "input_tensor", "=", "inputs", "\n", "\n", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertAttention.__init__": [[237, 246], ["modeling_tf_bert.TFBertSelfAttention.__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LayerNormalization", "set", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAlbertAttention", ",", "self", ")", ".", "__init__", "(", "config", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "hidden_size", "=", "config", ".", "hidden_size", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "hidden_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"dense\"", "\n", ")", "\n", "self", ".", "LayerNorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "\"LayerNorm\"", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertAttention.prune_heads": [[247, 249], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertAttention.call": [[250, 302], ["modeling_tf_albert.TFAlbertAttention.query", "modeling_tf_albert.TFAlbertAttention.key", "modeling_tf_albert.TFAlbertAttention.value", "modeling_tf_albert.TFAlbertAttention.transpose_for_scores", "modeling_tf_albert.TFAlbertAttention.transpose_for_scores", "modeling_tf_albert.TFAlbertAttention.transpose_for_scores", "tensorflow.matmul", "tensorflow.cast", "tensorflow.nn.softmax", "modeling_tf_albert.TFAlbertAttention.dropout", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.reshape", "modeling_tf_albert.TFAlbertAttention.dense", "modeling_tf_albert.TFAlbertAttention.dropout", "modeling_tf_albert.TFAlbertAttention.LayerNorm", "modeling_tf_utils.shape_list", "tensorflow.math.sqrt", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "input_tensor", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "batch_size", "=", "shape_list", "(", "input_tensor", ")", "[", "0", "]", "\n", "mixed_query_layer", "=", "self", ".", "query", "(", "input_tensor", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "input_tensor", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "input_tensor", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ",", "batch_size", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ",", "batch_size", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ",", "batch_size", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "# (batch size, num_heads, seq_len_q, seq_len_k)", "\n", "attention_scores", "=", "tf", ".", "matmul", "(", "query_layer", ",", "key_layer", ",", "transpose_b", "=", "True", ")", "\n", "# scale attention_scores", "\n", "dk", "=", "tf", ".", "cast", "(", "shape_list", "(", "key_layer", ")", "[", "-", "1", "]", ",", "tf", ".", "float32", ")", "\n", "attention_scores", "=", "attention_scores", "/", "tf", ".", "math", ".", "sqrt", "(", "dk", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask is (precomputed for all layers in TFBertModel call() function)", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "", "attention_probs", "=", "tf", ".", "nn", ".", "softmax", "(", "attention_scores", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ",", "training", "=", "training", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "tf", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "tf", ".", "transpose", "(", "context_layer", ",", "perm", "=", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "context_layer", "=", "tf", ".", "reshape", "(", "\n", "context_layer", ",", "(", "batch_size", ",", "-", "1", ",", "self", ".", "all_head_size", ")", "\n", ")", "# (batch_size, seq_len_q, all_head_size)", "\n", "\n", "self_outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "self", ".", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "\n", "hidden_states", "=", "self_outputs", "[", "0", "]", "\n", "\n", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "attention_output", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "\n", "# add attentions if we output them", "\n", "outputs", "=", "(", "attention_output", ",", ")", "+", "self_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertLayer.__init__": [[305, 325], ["super().__init__", "modeling_tf_albert.TFAlbertAttention", "tensorflow.keras.layers.Dense", "isinstance", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAlbertLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "attention", "=", "TFAlbertAttention", "(", "config", ",", "name", "=", "\"attention\"", ")", "\n", "\n", "self", ".", "ffn", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "intermediate_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"ffn\"", "\n", ")", "\n", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", ":", "\n", "            ", "self", ".", "activation", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "activation", "=", "config", ".", "hidden_act", "\n", "\n", "", "self", ".", "ffn_output", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "hidden_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"ffn_output\"", "\n", ")", "\n", "self", ".", "full_layer_layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "\n", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "\"full_layer_layer_norm\"", "\n", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertLayer.call": [[326, 340], ["modeling_tf_albert.TFAlbertLayer.attention", "modeling_tf_albert.TFAlbertLayer.ffn", "modeling_tf_albert.TFAlbertLayer.activation", "modeling_tf_albert.TFAlbertLayer.ffn_output", "modeling_tf_albert.TFAlbertLayer.dropout", "modeling_tf_albert.TFAlbertLayer.full_layer_layer_norm"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "attention_outputs", "=", "self", ".", "attention", "(", "[", "hidden_states", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "ffn_output", "=", "self", ".", "ffn", "(", "attention_outputs", "[", "0", "]", ")", "\n", "ffn_output", "=", "self", ".", "activation", "(", "ffn_output", ")", "\n", "ffn_output", "=", "self", ".", "ffn_output", "(", "ffn_output", ")", "\n", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "hidden_states", "=", "self", ".", "full_layer_layer_norm", "(", "ffn_output", "+", "attention_outputs", "[", "0", "]", ")", "\n", "\n", "# add attentions if we output them", "\n", "outputs", "=", "(", "hidden_states", ",", ")", "+", "attention_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertLayerGroup.__init__": [[343, 350], ["super().__init__", "modeling_tf_albert.TFAlbertLayer", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAlbertLayerGroup", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "albert_layers", "=", "[", "\n", "TFAlbertLayer", "(", "config", ",", "name", "=", "\"albert_layers_._{}\"", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "config", ".", "inner_group_num", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertLayerGroup.call": [[352, 375], ["enumerate", "albert_layer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "layer_hidden_states", "=", "(", ")", "\n", "layer_attentions", "=", "(", ")", "\n", "\n", "for", "layer_index", ",", "albert_layer", "in", "enumerate", "(", "self", ".", "albert_layers", ")", ":", "\n", "            ", "layer_output", "=", "albert_layer", "(", "[", "hidden_states", ",", "attention_mask", ",", "head_mask", "[", "layer_index", "]", "]", ",", "training", "=", "training", ")", "\n", "hidden_states", "=", "layer_output", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "layer_attentions", "=", "layer_attentions", "+", "(", "layer_output", "[", "1", "]", ",", ")", "\n", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "layer_hidden_states", "=", "layer_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "layer_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "layer_attentions", ",", ")", "\n", "# last-layer hidden state, (layer hidden states), (layer attentions)", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertTransformer.__init__": [[378, 392], ["super().__init__", "tensorflow.keras.layers.Dense", "modeling_tf_albert.TFAlbertLayerGroup", "modeling_tf_utils.get_initializer", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAlbertTransformer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "embedding_hidden_mapping_in", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "hidden_size", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"embedding_hidden_mapping_in\"", ",", "\n", ")", "\n", "self", ".", "albert_layer_groups", "=", "[", "\n", "TFAlbertLayerGroup", "(", "config", ",", "name", "=", "\"albert_layer_groups_._{}\"", ".", "format", "(", "i", ")", ")", "\n", "for", "i", "in", "range", "(", "config", ".", "num_hidden_groups", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertTransformer.call": [[394, 434], ["modeling_tf_albert.TFAlbertTransformer.embedding_hidden_mapping_in", "range", "int", "int"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "hidden_states", "=", "self", ".", "embedding_hidden_mapping_in", "(", "hidden_states", ")", "\n", "all_attentions", "=", "(", ")", "\n", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "(", "hidden_states", ",", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "config", ".", "num_hidden_layers", ")", ":", "\n", "# Number of layers in a hidden group", "\n", "            ", "layers_per_group", "=", "int", "(", "self", ".", "config", ".", "num_hidden_layers", "/", "self", ".", "config", ".", "num_hidden_groups", ")", "\n", "\n", "# Index of the hidden group", "\n", "group_idx", "=", "int", "(", "i", "/", "(", "self", ".", "config", ".", "num_hidden_layers", "/", "self", ".", "config", ".", "num_hidden_groups", ")", ")", "\n", "\n", "layer_group_output", "=", "self", ".", "albert_layer_groups", "[", "group_idx", "]", "(", "\n", "[", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", "[", "group_idx", "*", "layers_per_group", ":", "(", "group_idx", "+", "1", ")", "*", "layers_per_group", "]", ",", "\n", "]", ",", "\n", "training", "=", "training", ",", "\n", ")", "\n", "hidden_states", "=", "layer_group_output", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "layer_group_output", "[", "-", "1", "]", "\n", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "\n", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertMLMHead.__init__": [[447, 464], ["super().__init__", "tensorflow.keras.layers.Dense", "isinstance", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "input_embeddings", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAlbertMLMHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "\n", "self", ".", "dense", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "embedding_size", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"dense\"", "\n", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", ":", "\n", "            ", "self", ".", "activation", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "activation", "=", "config", ".", "hidden_act", "\n", "\n", "", "self", ".", "LayerNorm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "\"LayerNorm\"", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "decoder", "=", "input_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertMLMHead.build": [[465, 471], ["modeling_tf_albert.TFAlbertMLMHead.add_weight", "modeling_tf_albert.TFAlbertMLMHead.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "vocab_size", ",", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"bias\"", ")", "\n", "self", ".", "decoder_bias", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "vocab_size", ",", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"decoder/bias\"", "\n", ")", "\n", "super", "(", "TFAlbertMLMHead", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertMLMHead.call": [[472, 479], ["modeling_tf_albert.TFAlbertMLMHead.dense", "modeling_tf_albert.TFAlbertMLMHead.activation", "modeling_tf_albert.TFAlbertMLMHead.LayerNorm", "modeling_tf_albert.TFAlbertMLMHead.decoder"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "activation", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "decoder", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "+", "self", ".", "decoder_bias", "\n", "hidden_states", "=", "hidden_states", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertModel.__init__": [[598, 609], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_albert.TFAlbertEmbeddings", "modeling_tf_albert.TFAlbertTransformer", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAlbertModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "**", "kwargs", ")", "\n", "self", ".", "num_hidden_layers", "=", "config", ".", "num_hidden_layers", "\n", "\n", "self", ".", "embeddings", "=", "TFAlbertEmbeddings", "(", "config", ",", "name", "=", "\"embeddings\"", ")", "\n", "self", ".", "encoder", "=", "TFAlbertTransformer", "(", "config", ",", "name", "=", "\"encoder\"", ")", "\n", "self", ".", "pooler", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "hidden_size", ",", "\n", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "activation", "=", "\"tanh\"", ",", "\n", "name", "=", "\"pooler\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertModel.get_input_embeddings": [[611, 613], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertModel._resize_token_embeddings": [[614, 616], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertModel._prune_heads": [[617, 623], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertModel.call": [[624, 704], ["isinstance", "tensorflow.cast", "modeling_tf_albert.TFAlbertModel.embeddings", "modeling_tf_albert.TFAlbertModel.encoder", "modeling_tf_albert.TFAlbertModel.pooler", "isinstance", "ValueError", "tensorflow.fill", "tensorflow.fill", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "modeling_tf_utils.shape_list", "len", "len", "len", "len", "len", "len", "ValueError", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "\n", "self", ",", "\n", "inputs", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "training", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "head_mask", "\n", "inputs_embeds", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "inputs_embeds", "\n", "assert", "len", "(", "inputs", ")", "<=", "6", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "\"input_ids\"", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "\"attention_mask\"", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "\"token_type_ids\"", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "\"position_ids\"", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "\"head_mask\"", ",", "head_mask", ")", "\n", "inputs_embeds", "=", "inputs", ".", "get", "(", "\"inputs_embeds\"", ",", "inputs_embeds", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "6", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "input_ids", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "inputs_embeds", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "tf", ".", "fill", "(", "input_shape", ",", "1", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "tf", ".", "fill", "(", "input_shape", ",", "0", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "tf", ".", "newaxis", ",", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "\n", "extended_attention_mask", "=", "tf", ".", "cast", "(", "extended_attention_mask", ",", "tf", ".", "float32", ")", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "num_hidden_layers", "\n", "# head_mask = tf.constant([0] * self.num_hidden_layers)", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "[", "input_ids", ",", "position_ids", ",", "token_type_ids", ",", "inputs_embeds", "]", ",", "training", "=", "training", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "[", "embedding_output", ",", "extended_attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", "[", ":", ",", "0", "]", ")", "\n", "\n", "# add hidden_states and attentions if they are here", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ",", ")", "+", "encoder_outputs", "[", "1", ":", "]", "\n", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertForMaskedLM.__init__": [[735, 740], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_albert.TFAlbertModel", "modeling_tf_albert.TFAlbertMLMHead"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAlbertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "albert", "=", "TFAlbertModel", "(", "config", ",", "name", "=", "\"albert\"", ")", "\n", "self", ".", "predictions", "=", "TFAlbertMLMHead", "(", "config", ",", "self", ".", "albert", ".", "embeddings", ",", "name", "=", "\"predictions\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertForMaskedLM.get_output_embeddings": [[741, 743], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "albert", ".", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertForMaskedLM.call": [[744, 754], ["modeling_tf_albert.TFAlbertForMaskedLM.albert", "modeling_tf_albert.TFAlbertForMaskedLM.predictions", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "albert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ",", "training", "=", "kwargs", ".", "get", "(", "\"training\"", ",", "False", ")", ")", "\n", "\n", "# Add hidden states and attention if they are here", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "\n", "return", "outputs", "# prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertForSequenceClassification.__init__": [[788, 796], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_albert.TFAlbertModel", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAlbertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "albert", "=", "TFAlbertModel", "(", "config", ",", "name", "=", "\"albert\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"classifier\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertForSequenceClassification.call": [[798, 809], ["modeling_tf_albert.TFAlbertForSequenceClassification.albert", "modeling_tf_albert.TFAlbertForSequenceClassification.dropout", "modeling_tf_albert.TFAlbertForSequenceClassification.classifier", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "albert", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ",", "training", "=", "kwargs", ".", "get", "(", "\"training\"", ",", "False", ")", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFMultiHeadAttention.__init__": [[99, 113], ["super().__init__", "next", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "set", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "n_heads", ",", "dim", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFMultiHeadAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "layer_id", "=", "next", "(", "TFMultiHeadAttention", ".", "NEW_ID", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "n_heads", "=", "n_heads", "\n", "assert", "self", ".", "dim", "%", "self", ".", "n_heads", "==", "0", "\n", "\n", "self", ".", "q_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "init_std", ")", ",", "name", "=", "\"q_lin\"", ")", "\n", "self", ".", "k_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "init_std", ")", ",", "name", "=", "\"k_lin\"", ")", "\n", "self", ".", "v_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "init_std", ")", ",", "name", "=", "\"v_lin\"", ")", "\n", "self", ".", "out_lin", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "init_std", ")", ",", "name", "=", "\"out_lin\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "attention_dropout", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFMultiHeadAttention.prune_heads": [[114, 116], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFMultiHeadAttention.call": [[117, 181], ["modeling_tf_utils.shape_list", "modeling_tf_xlm.TFMultiHeadAttention.call.shape"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Self-attention (if kv is None) or attention over source sentence (provided by kv).\n        \"\"\"", "\n", "input", ",", "mask", ",", "kv", ",", "cache", ",", "head_mask", "=", "inputs", "\n", "# Input is (bs, qlen, dim)", "\n", "# Mask is (bs, klen) (non-causal) or (bs, klen, klen)", "\n", "bs", ",", "qlen", ",", "dim", "=", "shape_list", "(", "input", ")", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "klen", "=", "qlen", "if", "cache", "is", "None", "else", "cache", "[", "\"slen\"", "]", "+", "qlen", "\n", "", "else", ":", "\n", "            ", "klen", "=", "shape_list", "(", "kv", ")", "[", "1", "]", "\n", "# assert dim == self.dim, 'Dimensions do not match: %s input vs %s configured' % (dim, self.dim)", "\n", "", "n_heads", "=", "self", ".", "n_heads", "\n", "dim_per_head", "=", "self", ".", "dim", "//", "n_heads", "\n", "mask_reshape", "=", "(", "bs", ",", "1", ",", "qlen", ",", "klen", ")", "if", "len", "(", "shape_list", "(", "mask", ")", ")", "==", "3", "else", "(", "bs", ",", "1", ",", "1", ",", "klen", ")", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  projection \"\"\"", "\n", "return", "tf", ".", "transpose", "(", "tf", ".", "reshape", "(", "x", ",", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", ",", "dim_per_head", ")", ")", ",", "perm", "=", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  compute context \"\"\"", "\n", "return", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "x", ",", "perm", "=", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", ",", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", "*", "dim_per_head", ")", ")", "\n", "\n", "", "q", "=", "shape", "(", "self", ".", "q_lin", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "k", "=", "shape", "(", "self", ".", "k_lin", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v_lin", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "", "elif", "cache", "is", "None", "or", "self", ".", "layer_id", "not", "in", "cache", ":", "\n", "            ", "k", "=", "v", "=", "kv", "\n", "k", "=", "shape", "(", "self", ".", "k_lin", "(", "k", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v_lin", "(", "v", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "\n", "", "if", "cache", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "layer_id", "in", "cache", ":", "\n", "                ", "if", "kv", "is", "None", ":", "\n", "                    ", "k_", ",", "v_", "=", "cache", "[", "self", ".", "layer_id", "]", "\n", "k", "=", "tf", ".", "concat", "(", "[", "k_", ",", "k", "]", ",", "axis", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "v", "=", "tf", ".", "concat", "(", "[", "v_", ",", "v", "]", ",", "axis", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "", "else", ":", "\n", "                    ", "k", ",", "v", "=", "cache", "[", "self", ".", "layer_id", "]", "\n", "", "", "cache", "[", "self", ".", "layer_id", "]", "=", "(", "k", ",", "v", ")", "\n", "\n", "", "q", "=", "q", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "scores", "=", "tf", ".", "matmul", "(", "q", ",", "k", ",", "transpose_b", "=", "True", ")", "# (bs, n_heads, qlen, klen)", "\n", "mask", "=", "tf", ".", "reshape", "(", "mask", ",", "mask_reshape", ")", "# (bs, n_heads, qlen, klen)", "\n", "# scores.masked_fill_(mask, -float('inf'))                            # (bs, n_heads, qlen, klen)", "\n", "scores", "=", "scores", "-", "1e30", "*", "(", "1.0", "-", "mask", ")", "\n", "\n", "weights", "=", "tf", ".", "nn", ".", "softmax", "(", "scores", ",", "axis", "=", "-", "1", ")", "# (bs, n_heads, qlen, klen)", "\n", "weights", "=", "self", ".", "dropout", "(", "weights", ",", "training", "=", "training", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "weights", "=", "weights", "*", "head_mask", "\n", "\n", "", "context", "=", "tf", ".", "matmul", "(", "weights", ",", "v", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "context", "=", "unshape", "(", "context", ")", "# (bs, qlen, dim)", "\n", "\n", "outputs", "=", "(", "self", ".", "out_lin", "(", "context", ")", ",", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "weights", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFTransformerFFN.__init__": [[184, 190], ["super().__init__", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Activation", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", ",", "dim_hidden", ",", "out_dim", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFTransformerFFN", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "lin1", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "dim_hidden", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "init_std", ")", ",", "name", "=", "\"lin1\"", ")", "\n", "self", ".", "lin2", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "out_dim", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "init_std", ")", ",", "name", "=", "\"lin2\"", ")", "\n", "self", ".", "act", "=", "tf", ".", "keras", ".", "layers", ".", "Activation", "(", "gelu", ")", "if", "config", ".", "gelu_activation", "else", "tf", ".", "keras", ".", "activations", ".", "relu", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFTransformerFFN.call": [[191, 197], ["modeling_tf_xlm.TFTransformerFFN.lin1", "modeling_tf_xlm.TFTransformerFFN.act", "modeling_tf_xlm.TFTransformerFFN.lin2", "modeling_tf_xlm.TFTransformerFFN.dropout"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "input", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", "=", "self", ".", "lin1", "(", "input", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "lin2", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ",", "training", "=", "training", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMMainLayer.__init__": [[200, 289], ["super().__init__", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Embedding", "modeling_tf_utils.TFSharedEmbeddings", "tensorflow.keras.layers.LayerNormalization", "range", "hasattr", "NotImplementedError", "tensorflow.keras.layers.Embedding", "modeling_tf_xlm.TFXLMMainLayer.attentions.append", "modeling_tf_xlm.TFXLMMainLayer.layer_norm1.append", "modeling_tf_xlm.TFXLMMainLayer.ffns.append", "modeling_tf_xlm.TFXLMMainLayer.layer_norm2.append", "config.pruned_heads.copy().items", "modeling_tf_utils.get_initializer", "modeling_tf_xlm.TFMultiHeadAttention", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_xlm.TFTransformerFFN", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_utils.get_initializer", "config.pruned_heads.copy", "modeling_tf_xlm.TFXLMMainLayer.prune_heads", "int", "list", "int", "map"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLMMainLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "# encoder / decoder, output layer", "\n", "self", ".", "is_encoder", "=", "config", ".", "is_encoder", "\n", "self", ".", "is_decoder", "=", "not", "config", ".", "is_encoder", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Currently XLM can only be used as an encoder\"", ")", "\n", "# self.with_output = with_output", "\n", "", "self", ".", "causal", "=", "config", ".", "causal", "\n", "\n", "# dictionary / languages", "\n", "self", ".", "n_langs", "=", "config", ".", "n_langs", "\n", "self", ".", "use_lang_emb", "=", "config", ".", "use_lang_emb", "\n", "self", ".", "n_words", "=", "config", ".", "n_words", "\n", "self", ".", "eos_index", "=", "config", ".", "eos_index", "\n", "self", ".", "pad_index", "=", "config", ".", "pad_index", "\n", "# self.dico = dico", "\n", "# self.id2lang = config.id2lang", "\n", "# self.lang2id = config.lang2id", "\n", "# assert len(self.dico) == self.n_words", "\n", "# assert len(self.id2lang) == len(self.lang2id) == self.n_langs", "\n", "\n", "# model parameters", "\n", "self", ".", "dim", "=", "config", ".", "emb_dim", "# 512 by default", "\n", "self", ".", "hidden_dim", "=", "self", ".", "dim", "*", "4", "# 2048 by default", "\n", "self", ".", "n_heads", "=", "config", ".", "n_heads", "# 8 by default", "\n", "self", ".", "n_layers", "=", "config", ".", "n_layers", "\n", "assert", "self", ".", "dim", "%", "self", ".", "n_heads", "==", "0", ",", "\"transformer dim must be a multiple of n_heads\"", "\n", "\n", "# embeddings", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "self", ".", "attention_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "attention_dropout", ")", "\n", "\n", "self", ".", "position_embeddings", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "\n", "config", ".", "max_position_embeddings", ",", "\n", "self", ".", "dim", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "config", ".", "embed_init_std", ")", ",", "\n", "name", "=", "\"position_embeddings\"", ",", "\n", ")", "\n", "if", "config", ".", "sinusoidal_embeddings", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "# create_sinusoidal_embeddings(config.max_position_embeddings, self.dim, out=self.position_embeddings.weight)", "\n", "", "if", "config", ".", "n_langs", ">", "1", "and", "config", ".", "use_lang_emb", ":", "\n", "            ", "self", ".", "lang_embeddings", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "\n", "self", ".", "n_langs", ",", "\n", "self", ".", "dim", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "config", ".", "embed_init_std", ")", ",", "\n", "name", "=", "\"lang_embeddings\"", ",", "\n", ")", "\n", "", "self", ".", "embeddings", "=", "TFSharedEmbeddings", "(", "\n", "self", ".", "n_words", ",", "self", ".", "dim", ",", "initializer_range", "=", "config", ".", "embed_init_std", ",", "name", "=", "\"embeddings\"", "\n", ")", "# padding_idx=self.pad_index)", "\n", "self", ".", "layer_norm_emb", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "\"layer_norm_emb\"", ")", "\n", "\n", "# transformer layers", "\n", "self", ".", "attentions", "=", "[", "]", "\n", "self", ".", "layer_norm1", "=", "[", "]", "\n", "self", ".", "ffns", "=", "[", "]", "\n", "self", ".", "layer_norm2", "=", "[", "]", "\n", "# if self.is_decoder:", "\n", "#     self.layer_norm15 = []", "\n", "#     self.encoder_attn = []", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "            ", "self", ".", "attentions", ".", "append", "(", "\n", "TFMultiHeadAttention", "(", "self", ".", "n_heads", ",", "self", ".", "dim", ",", "config", "=", "config", ",", "name", "=", "\"attentions_._{}\"", ".", "format", "(", "i", ")", ")", "\n", ")", "\n", "self", ".", "layer_norm1", ".", "append", "(", "\n", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "\"layer_norm1_._{}\"", ".", "format", "(", "i", ")", ")", "\n", ")", "\n", "# if self.is_decoder:", "\n", "#     self.layer_norm15.append(nn.LayerNorm(self.dim, eps=config.layer_norm_eps))", "\n", "#     self.encoder_attn.append(MultiHeadAttention(self.n_heads, self.dim, dropout=self.attention_dropout))", "\n", "self", ".", "ffns", ".", "append", "(", "\n", "TFTransformerFFN", "(", "self", ".", "dim", ",", "self", ".", "hidden_dim", ",", "self", ".", "dim", ",", "config", "=", "config", ",", "name", "=", "\"ffns_._{}\"", ".", "format", "(", "i", ")", ")", "\n", ")", "\n", "self", ".", "layer_norm2", ".", "append", "(", "\n", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "\"layer_norm2_._{}\"", ".", "format", "(", "i", ")", ")", "\n", ")", "\n", "\n", "", "if", "hasattr", "(", "config", ",", "\"pruned_heads\"", ")", ":", "\n", "            ", "pruned_heads", "=", "config", ".", "pruned_heads", ".", "copy", "(", ")", ".", "items", "(", ")", "\n", "config", ".", "pruned_heads", "=", "{", "}", "\n", "for", "layer", ",", "heads", "in", "pruned_heads", ":", "\n", "                ", "if", "self", ".", "attentions", "[", "int", "(", "layer", ")", "]", ".", "n_heads", "==", "config", ".", "n_heads", ":", "\n", "                    ", "self", ".", "prune_heads", "(", "{", "int", "(", "layer", ")", ":", "list", "(", "map", "(", "int", ",", "heads", ")", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMMainLayer.get_input_embeddings": [[290, 292], ["None"], "methods", ["None"], ["", "", "", "", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMMainLayer._resize_token_embeddings": [[293, 295], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMMainLayer._prune_heads": [[296, 302], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMMainLayer.call": [[303, 464], ["isinstance", "tensorflow.debugging.assert_equal", "modeling_tf_xlm.get_masks", "modeling_tf_xlm.TFXLMMainLayer.layer_norm_emb", "modeling_tf_xlm.TFXLMMainLayer.dropout", "range", "isinstance", "ValueError", "tensorflow.expand_dims", "tensorflow.debugging.assert_equal", "tensorflow.debugging.assert_equal", "modeling_tf_xlm.TFXLMMainLayer.embeddings", "modeling_tf_xlm.TFXLMMainLayer.position_embeddings", "modeling_tf_xlm.TFXLMMainLayer.dropout", "modeling_tf_xlm.TFXLMMainLayer.size", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "modeling_tf_utils.shape_list", "tensorflow.reduce_sum", "tensorflow.convert_to_tensor", "modeling_tf_utils.shape_list", "tensorflow.range", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "modeling_tf_xlm.TFXLMMainLayer.lang_embeddings", "modeling_tf_xlm.TFXLMMainLayer.embeddings", "len", "len", "len", "len", "len", "len", "len", "len", "len", "ValueError", "tensorflow.cast", "modeling_tf_utils.shape_list", "tensorflow.not_equal"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.get_masks", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_transfo_xl.TransfoXLTokenizer.convert_to_tensor", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "\n", "self", ",", "\n", "inputs", ",", "\n", "attention_mask", "=", "None", ",", "\n", "langs", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "lengths", "=", "None", ",", "\n", "cache", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "training", "=", "False", ",", "\n", ")", ":", "# removed: src_enc=None, src_len=None", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "langs", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "langs", "\n", "token_type_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "position_ids", "\n", "lengths", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "lengths", "\n", "cache", "=", "inputs", "[", "6", "]", "if", "len", "(", "inputs", ")", ">", "6", "else", "cache", "\n", "head_mask", "=", "inputs", "[", "7", "]", "if", "len", "(", "inputs", ")", ">", "7", "else", "head_mask", "\n", "inputs_embeds", "=", "inputs", "[", "8", "]", "if", "len", "(", "inputs", ")", ">", "8", "else", "inputs_embeds", "\n", "assert", "len", "(", "inputs", ")", "<=", "9", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "\"input_ids\"", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "\"attention_mask\"", ",", "attention_mask", ")", "\n", "langs", "=", "inputs", ".", "get", "(", "\"langs\"", ",", "langs", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "\"token_type_ids\"", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "\"position_ids\"", ",", "position_ids", ")", "\n", "lengths", "=", "inputs", ".", "get", "(", "\"lengths\"", ",", "lengths", ")", "\n", "cache", "=", "inputs", ".", "get", "(", "\"cache\"", ",", "cache", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "\"head_mask\"", ",", "head_mask", ")", "\n", "inputs_embeds", "=", "inputs", ".", "get", "(", "\"inputs_embeds\"", ",", "inputs_embeds", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "9", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "bs", ",", "slen", "=", "shape_list", "(", "input_ids", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "bs", ",", "slen", "=", "shape_list", "(", "inputs_embeds", ")", "[", ":", "2", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "lengths", "is", "None", ":", "\n", "            ", "if", "input_ids", "is", "not", "None", ":", "\n", "                ", "lengths", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "cast", "(", "tf", ".", "not_equal", "(", "input_ids", ",", "self", ".", "pad_index", ")", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "lengths", "=", "tf", ".", "convert_to_tensor", "(", "[", "slen", "]", "*", "bs", ",", "tf", ".", "int32", ")", "\n", "# mask = input_ids != self.pad_index", "\n", "\n", "# check inputs", "\n", "# assert shape_list(lengths)[0] == bs", "\n", "", "", "tf", ".", "debugging", ".", "assert_equal", "(", "shape_list", "(", "lengths", ")", "[", "0", "]", ",", "bs", ")", "\n", "# assert lengths.max().item() <= slen", "\n", "# input_ids = input_ids.transpose(0, 1)  # batch size as dimension 0", "\n", "# assert (src_enc is None) == (src_len is None)", "\n", "# if src_enc is not None:", "\n", "#     assert self.is_decoder", "\n", "#     assert src_enc.size(0) == bs", "\n", "\n", "# generate masks", "\n", "mask", ",", "attn_mask", "=", "get_masks", "(", "slen", ",", "lengths", ",", "self", ".", "causal", ",", "padding_mask", "=", "attention_mask", ")", "\n", "# if self.is_decoder and src_enc is not None:", "\n", "#     src_mask = torch.arange(src_len.max(), dtype=torch.long, device=lengths.device) < src_len[:, None]", "\n", "\n", "# position_ids", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "tf", ".", "expand_dims", "(", "tf", ".", "range", "(", "slen", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "# assert shape_list(position_ids) == [bs, slen]  # (slen, bs)", "\n", "            ", "tf", ".", "debugging", ".", "assert_equal", "(", "shape_list", "(", "position_ids", ")", ",", "[", "bs", ",", "slen", "]", ")", "\n", "# position_ids = position_ids.transpose(0, 1)", "\n", "\n", "# langs", "\n", "", "if", "langs", "is", "not", "None", ":", "\n", "# assert shape_list(langs) == [bs, slen]  # (slen, bs)", "\n", "            ", "tf", ".", "debugging", ".", "assert_equal", "(", "shape_list", "(", "langs", ")", ",", "[", "bs", ",", "slen", "]", ")", "\n", "# langs = langs.transpose(0, 1)", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x qlen x klen]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layers", "\n", "\n", "# do not recompute cached elements", "\n", "", "if", "cache", "is", "not", "None", "and", "input_ids", "is", "not", "None", ":", "\n", "            ", "_slen", "=", "slen", "-", "cache", "[", "\"slen\"", "]", "\n", "input_ids", "=", "input_ids", "[", ":", ",", "-", "_slen", ":", "]", "\n", "position_ids", "=", "position_ids", "[", ":", ",", "-", "_slen", ":", "]", "\n", "if", "langs", "is", "not", "None", ":", "\n", "                ", "langs", "=", "langs", "[", ":", ",", "-", "_slen", ":", "]", "\n", "", "mask", "=", "mask", "[", ":", ",", "-", "_slen", ":", "]", "\n", "attn_mask", "=", "attn_mask", "[", ":", ",", "-", "_slen", ":", "]", "\n", "\n", "# embeddings", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "embeddings", "(", "input_ids", ")", "\n", "\n", "", "tensor", "=", "inputs_embeds", "+", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "if", "langs", "is", "not", "None", "and", "self", ".", "use_lang_emb", ":", "\n", "            ", "tensor", "=", "tensor", "+", "self", ".", "lang_embeddings", "(", "langs", ")", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "tensor", "=", "tensor", "+", "self", ".", "embeddings", "(", "token_type_ids", ")", "\n", "", "tensor", "=", "self", ".", "layer_norm_emb", "(", "tensor", ")", "\n", "tensor", "=", "self", ".", "dropout", "(", "tensor", ",", "training", "=", "training", ")", "\n", "tensor", "=", "tensor", "*", "mask", "[", "...", ",", "tf", ".", "newaxis", "]", "\n", "\n", "# transformer layers", "\n", "hidden_states", "=", "(", ")", "\n", "attentions", "=", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "hidden_states", "=", "hidden_states", "+", "(", "tensor", ",", ")", "\n", "\n", "# self attention", "\n", "", "attn_outputs", "=", "self", ".", "attentions", "[", "i", "]", "(", "[", "tensor", ",", "attn_mask", ",", "None", ",", "cache", ",", "head_mask", "[", "i", "]", "]", ",", "training", "=", "training", ")", "\n", "attn", "=", "attn_outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attentions", "=", "attentions", "+", "(", "attn_outputs", "[", "1", "]", ",", ")", "\n", "", "attn", "=", "self", ".", "dropout", "(", "attn", ",", "training", "=", "training", ")", "\n", "tensor", "=", "tensor", "+", "attn", "\n", "tensor", "=", "self", ".", "layer_norm1", "[", "i", "]", "(", "tensor", ")", "\n", "\n", "# encoder attention (for decoder only)", "\n", "# if self.is_decoder and src_enc is not None:", "\n", "#     attn = self.encoder_attn[i](tensor, src_mask, kv=src_enc, cache=cache)", "\n", "#     attn = F.dropout(attn, p=self.dropout, training=self.training)", "\n", "#     tensor = tensor + attn", "\n", "#     tensor = self.layer_norm15[i](tensor)", "\n", "\n", "# FFN", "\n", "tensor", "=", "tensor", "+", "self", ".", "ffns", "[", "i", "]", "(", "tensor", ")", "\n", "tensor", "=", "self", ".", "layer_norm2", "[", "i", "]", "(", "tensor", ")", "\n", "tensor", "=", "tensor", "*", "mask", "[", "...", ",", "tf", ".", "newaxis", "]", "\n", "\n", "# Add last hidden state", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "hidden_states", "=", "hidden_states", "+", "(", "tensor", ",", ")", "\n", "\n", "# update cache length", "\n", "", "if", "cache", "is", "not", "None", ":", "\n", "            ", "cache", "[", "\"slen\"", "]", "+=", "tensor", ".", "size", "(", "1", ")", "\n", "\n", "# move back sequence length to dimension 0", "\n", "# tensor = tensor.transpose(0, 1)", "\n", "\n", "", "outputs", "=", "(", "tensor", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attentions", ",", ")", "\n", "", "return", "outputs", "# outputs, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMPreTrainedModel.dummy_inputs": [[475, 485], ["tensorflow.constant", "tensorflow.constant", "tensorflow.constant"], "methods", ["None"], ["@", "property", "\n", "def", "dummy_inputs", "(", "self", ")", ":", "\n", "# Sometimes XLM has language embeddings so don't forget to build them as well if needed", "\n", "        ", "inputs_list", "=", "tf", ".", "constant", "(", "[", "[", "7", ",", "6", ",", "0", ",", "0", ",", "1", "]", ",", "[", "1", ",", "2", ",", "3", ",", "0", ",", "0", "]", ",", "[", "0", ",", "0", ",", "0", ",", "4", ",", "5", "]", "]", ")", "\n", "attns_list", "=", "tf", ".", "constant", "(", "[", "[", "1", ",", "1", ",", "0", ",", "0", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", ",", "0", ",", "0", "]", ",", "[", "1", ",", "0", ",", "0", ",", "1", ",", "1", "]", "]", ")", "\n", "if", "self", ".", "config", ".", "use_lang_emb", "and", "self", ".", "config", ".", "n_langs", ">", "1", ":", "\n", "            ", "langs_list", "=", "tf", ".", "constant", "(", "[", "[", "1", ",", "1", ",", "0", ",", "0", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", ",", "0", ",", "0", "]", ",", "[", "1", ",", "0", ",", "0", ",", "1", ",", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "langs_list", "=", "None", "\n", "", "return", "{", "\"input_ids\"", ":", "inputs_list", ",", "\"attention_mask\"", ":", "attns_list", ",", "\"langs\"", ":", "langs_list", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMModel.__init__": [[610, 613], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlm.TFXLMMainLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLMModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFXLMMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMModel.call": [[614, 617], ["modeling_tf_xlm.TFXLMModel.transformer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMPredLayer.__init__": [[624, 633], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "input_embeddings", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLMPredLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "asm", "=", "config", ".", "asm", "\n", "self", ".", "n_words", "=", "config", ".", "n_words", "\n", "self", ".", "pad_index", "=", "config", ".", "pad_index", "\n", "if", "config", ".", "asm", "is", "False", ":", "\n", "            ", "self", ".", "input_embeddings", "=", "input_embeddings", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "# self.proj = nn.AdaptiveLogSoftmaxWithLoss(", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMPredLayer.build": [[641, 645], ["modeling_tf_xlm.TFXLMPredLayer.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "# The output weights are the same as the input embeddings, but there is an output-only bias for each token.", "\n", "        ", "self", ".", "bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "n_words", ",", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"bias\"", ")", "\n", "super", "(", "TFXLMPredLayer", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMPredLayer.call": [[646, 650], ["modeling_tf_xlm.TFXLMPredLayer.input_embeddings"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "input_embeddings", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "hidden_states", "=", "hidden_states", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMWithLMHeadModel.__init__": [[684, 688], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlm.TFXLMMainLayer", "modeling_tf_xlm.TFXLMPredLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLMWithLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFXLMMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "self", ".", "pred_layer", "=", "TFXLMPredLayer", "(", "config", ",", "self", ".", "transformer", ".", "embeddings", ",", "name", "=", "\"pred_layer_._proj\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMWithLMHeadModel.get_output_embeddings": [[689, 691], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pred_layer", ".", "input_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMWithLMHeadModel.call": [[692, 700], ["modeling_tf_xlm.TFXLMWithLMHeadModel.transformer", "modeling_tf_xlm.TFXLMWithLMHeadModel.pred_layer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "outputs", "=", "self", ".", "pred_layer", "(", "output", ")", "\n", "outputs", "=", "(", "outputs", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep new_mems and attention/hidden states if they are here", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMForSequenceClassification.__init__": [[735, 741], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlm.TFXLMMainLayer", "modeling_tf_utils.TFSequenceSummary"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLMForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "TFXLMMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "self", ".", "sequence_summary", "=", "TFSequenceSummary", "(", "config", ",", "initializer_range", "=", "config", ".", "init_std", ",", "name", "=", "\"sequence_summary\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMForSequenceClassification.call": [[742, 750], ["modeling_tf_xlm.TFXLMForSequenceClassification.transformer", "modeling_tf_xlm.TFXLMForSequenceClassification.sequence_summary"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "sequence_summary", "(", "output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep new_mems and attention/hidden states if they are here", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMForQuestionAnsweringSimple.__init__": [[786, 791], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlm.TFXLMMainLayer", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLMForQuestionAnsweringSimple", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFXLMMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "self", ".", "qa_outputs", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "init_std", ")", ",", "name", "=", "\"qa_outputs\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.TFXLMForQuestionAnsweringSimple.call": [[793, 808], ["modeling_tf_xlm.TFXLMForQuestionAnsweringSimple.transformer", "modeling_tf_xlm.TFXLMForQuestionAnsweringSimple.qa_outputs", "tensorflow.split", "tensorflow.squeeze", "tensorflow.squeeze"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "tf", ".", "split", "(", "logits", ",", "2", ",", "axis", "=", "-", "1", ")", "\n", "start_logits", "=", "tf", ".", "squeeze", "(", "start_logits", ",", "axis", "=", "-", "1", ")", "\n", "end_logits", "=", "tf", ".", "squeeze", "(", "end_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "transformer_outputs", "[", "\n", "1", ":", "\n", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "return", "outputs", "# start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.create_sinusoidal_embeddings": [[47, 51], ["numpy.array", "tensorflow.constant", "tensorflow.constant", "numpy.sin", "numpy.cos", "range", "numpy.power", "range"], "function", ["None"], ["def", "create_sinusoidal_embeddings", "(", "n_pos", ",", "dim", ",", "out", ")", ":", "\n", "    ", "position_enc", "=", "np", ".", "array", "(", "[", "[", "pos", "/", "np", ".", "power", "(", "10000", ",", "2", "*", "(", "j", "//", "2", ")", "/", "dim", ")", "for", "j", "in", "range", "(", "dim", ")", "]", "for", "pos", "in", "range", "(", "n_pos", ")", "]", ")", "\n", "out", "[", ":", ",", "0", ":", ":", "2", "]", "=", "tf", ".", "constant", "(", "np", ".", "sin", "(", "position_enc", "[", ":", ",", "0", ":", ":", "2", "]", ")", ")", "\n", "out", "[", ":", ",", "1", ":", ":", "2", "]", "=", "tf", ".", "constant", "(", "np", ".", "cos", "(", "position_enc", "[", ":", ",", "1", ":", ":", "2", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.gelu": [[53, 62], ["tensorflow.math.erf", "tensorflow.math.sqrt"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Gaussian Error Linear Unit.\n    Original Implementation of the gelu activation function in Google Bert repo when initially created.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "math", ".", "erf", "(", "x", "/", "tf", ".", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlm.get_masks": [[64, 93], ["tensorflow.debugging.assert_equal", "tensorflow.cast", "tensorflow.cast", "modeling_tf_utils.shape_list", "tensorflow.range", "tensorflow.math.less", "tensorflow.less_equal", "modeling_tf_utils.shape_list", "tensorflow.tile", "modeling_tf_utils.shape_list"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "get_masks", "(", "slen", ",", "lengths", ",", "causal", ",", "padding_mask", "=", "None", ",", "dtype", "=", "tf", ".", "float32", ")", ":", "\n", "    ", "\"\"\"\n    Generate hidden states mask, and optionally an attention mask.\n    \"\"\"", "\n", "bs", "=", "shape_list", "(", "lengths", ")", "[", "0", "]", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "        ", "mask", "=", "padding_mask", "\n", "", "else", ":", "\n", "# assert lengths.max().item() <= slen", "\n", "        ", "alen", "=", "tf", ".", "range", "(", "slen", ")", "\n", "mask", "=", "tf", ".", "math", ".", "less", "(", "alen", ",", "lengths", "[", ":", ",", "tf", ".", "newaxis", "]", ")", "\n", "\n", "# attention mask is the same as mask, or triangular inferior attention (causal)", "\n", "", "if", "causal", ":", "\n", "        ", "attn_mask", "=", "tf", ".", "less_equal", "(", "\n", "tf", ".", "tile", "(", "alen", "[", "tf", ".", "newaxis", ",", "tf", ".", "newaxis", ",", ":", "]", ",", "(", "bs", ",", "slen", ",", "1", ")", ")", ",", "alen", "[", "tf", ".", "newaxis", ",", ":", ",", "tf", ".", "newaxis", "]", "\n", ")", "\n", "", "else", ":", "\n", "        ", "attn_mask", "=", "mask", "\n", "\n", "# sanity check", "\n", "# assert shape_list(mask) == [bs, slen]", "\n", "", "tf", ".", "debugging", ".", "assert_equal", "(", "shape_list", "(", "mask", ")", ",", "[", "bs", ",", "slen", "]", ")", "\n", "assert", "causal", "is", "False", "or", "shape_list", "(", "attn_mask", ")", "==", "[", "bs", ",", "slen", ",", "slen", "]", "\n", "\n", "mask", "=", "tf", ".", "cast", "(", "mask", ",", "dtype", "=", "dtype", ")", "\n", "attn_mask", "=", "tf", ".", "cast", "(", "attn_mask", ",", "dtype", "=", "dtype", ")", "\n", "\n", "return", "mask", ",", "attn_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_albert.AlbertTokenizer.__init__": [[67, 112], ["tokenization_utils.PreTrainedTokenizer.__init__", "spm.SentencePieceProcessor", "tokenization_albert.AlbertTokenizer.sp_model.Load", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "do_lower_case", "=", "True", ",", "\n", "remove_space", "=", "True", ",", "\n", "keep_accents", "=", "False", ",", "\n", "bos_token", "=", "\"[CLS]\"", ",", "\n", "eos_token", "=", "\"[SEP]\"", ",", "\n", "unk_token", "=", "\"<unk>\"", ",", "\n", "sep_token", "=", "\"[SEP]\"", ",", "\n", "pad_token", "=", "\"<pad>\"", ",", "\n", "cls_token", "=", "\"[CLS]\"", ",", "\n", "mask_token", "=", "\"[MASK]\"", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "AlbertTokenizer", ",", "self", ")", ".", "__init__", "(", "\n", "bos_token", "=", "bos_token", ",", "\n", "eos_token", "=", "eos_token", ",", "\n", "unk_token", "=", "unk_token", ",", "\n", "sep_token", "=", "sep_token", ",", "\n", "pad_token", "=", "pad_token", ",", "\n", "cls_token", "=", "cls_token", ",", "\n", "mask_token", "=", "mask_token", ",", "\n", "**", "kwargs", "\n", ")", "\n", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "-", "2", "# take into account special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "-", "3", "# take into account special tokens", "\n", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"You need to install SentencePiece to use AlbertTokenizer: https://github.com/google/sentencepiece\"", "\n", "\"pip install sentencepiece\"", "\n", ")", "\n", "raise", "\n", "\n", "", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "self", ".", "remove_space", "=", "remove_space", "\n", "self", ".", "keep_accents", "=", "keep_accents", "\n", "self", ".", "vocab_file", "=", "vocab_file", "\n", "\n", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_albert.AlbertTokenizer.vocab_size": [[113, 116], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sp_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_albert.AlbertTokenizer.__getstate__": [[117, 121], ["tokenization_albert.AlbertTokenizer.__dict__.copy"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "state", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "state", "[", "\"sp_model\"", "]", "=", "None", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_albert.AlbertTokenizer.__setstate__": [[122, 134], ["spm.SentencePieceProcessor", "tokenization_albert.AlbertTokenizer.sp_model.Load", "logger.warning"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "d", ")", ":", "\n", "        ", "self", ".", "__dict__", "=", "d", "\n", "try", ":", "\n", "            ", "import", "sentencepiece", "as", "spm", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"You need to install SentencePiece to use AlbertTokenizer: https://github.com/google/sentencepiece\"", "\n", "\"pip install sentencepiece\"", "\n", ")", "\n", "raise", "\n", "", "self", ".", "sp_model", "=", "spm", ".", "SentencePieceProcessor", "(", ")", "\n", "self", ".", "sp_model", ".", "Load", "(", "self", ".", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_albert.AlbertTokenizer.preprocess_text": [[135, 149], ["outputs.lower.lower.replace().replace", "unicodedata.normalize", "outputs.lower.lower.lower", "inputs.strip().split", "outputs.lower.lower.replace", "inputs.strip", "unicodedata.combining"], "methods", ["None"], ["", "def", "preprocess_text", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "if", "self", ".", "remove_space", ":", "\n", "            ", "outputs", "=", "\" \"", ".", "join", "(", "inputs", ".", "strip", "(", ")", ".", "split", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "inputs", "\n", "", "outputs", "=", "outputs", ".", "replace", "(", "\"``\"", ",", "'\"'", ")", ".", "replace", "(", "\"''\"", ",", "'\"'", ")", "\n", "\n", "if", "not", "self", ".", "keep_accents", ":", "\n", "            ", "outputs", "=", "unicodedata", ".", "normalize", "(", "\"NFKD\"", ",", "outputs", ")", "\n", "outputs", "=", "\"\"", ".", "join", "(", "[", "c", "for", "c", "in", "outputs", "if", "not", "unicodedata", ".", "combining", "(", "c", ")", "]", ")", "\n", "", "if", "self", ".", "do_lower_case", ":", "\n", "            ", "outputs", "=", "outputs", ".", "lower", "(", ")", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_albert.AlbertTokenizer._tokenize": [[150, 173], ["tokenization_albert.AlbertTokenizer.preprocess_text", "tokenization_albert.AlbertTokenizer.sp_model.EncodeAsPieces", "tokenization_albert.AlbertTokenizer.sp_model.SampleEncodeAsPieces", "piece[].isdigit", "tokenization_albert.AlbertTokenizer.sp_model.EncodeAsPieces", "tokenization_albert.AlbertTokenizer.append", "new_pieces.extend", "new_pieces.append", "len", "str", "piece[].replace", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_albert.AlbertTokenizer.preprocess_text"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "sample", "=", "False", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. \"\"\"", "\n", "text", "=", "self", ".", "preprocess_text", "(", "text", ")", "\n", "\n", "if", "not", "sample", ":", "\n", "            ", "pieces", "=", "self", ".", "sp_model", ".", "EncodeAsPieces", "(", "text", ")", "\n", "", "else", ":", "\n", "            ", "pieces", "=", "self", ".", "sp_model", ".", "SampleEncodeAsPieces", "(", "text", ",", "64", ",", "0.1", ")", "\n", "", "new_pieces", "=", "[", "]", "\n", "for", "piece", "in", "pieces", ":", "\n", "            ", "if", "len", "(", "piece", ")", ">", "1", "and", "piece", "[", "-", "1", "]", "==", "str", "(", "\",\"", ")", "and", "piece", "[", "-", "2", "]", ".", "isdigit", "(", ")", ":", "\n", "                ", "cur_pieces", "=", "self", ".", "sp_model", ".", "EncodeAsPieces", "(", "piece", "[", ":", "-", "1", "]", ".", "replace", "(", "SPIECE_UNDERLINE", ",", "\"\"", ")", ")", "\n", "if", "piece", "[", "0", "]", "!=", "SPIECE_UNDERLINE", "and", "cur_pieces", "[", "0", "]", "[", "0", "]", "==", "SPIECE_UNDERLINE", ":", "\n", "                    ", "if", "len", "(", "cur_pieces", "[", "0", "]", ")", "==", "1", ":", "\n", "                        ", "cur_pieces", "=", "cur_pieces", "[", "1", ":", "]", "\n", "", "else", ":", "\n", "                        ", "cur_pieces", "[", "0", "]", "=", "cur_pieces", "[", "0", "]", "[", "1", ":", "]", "\n", "", "", "cur_pieces", ".", "append", "(", "piece", "[", "-", "1", "]", ")", "\n", "new_pieces", ".", "extend", "(", "cur_pieces", ")", "\n", "", "else", ":", "\n", "                ", "new_pieces", ".", "append", "(", "piece", ")", "\n", "\n", "", "", "return", "new_pieces", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_albert.AlbertTokenizer._convert_token_to_id": [[174, 177], ["tokenization_albert.AlbertTokenizer.sp_model.PieceToId"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "sp_model", ".", "PieceToId", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_albert.AlbertTokenizer._convert_id_to_token": [[178, 181], ["tokenization_albert.AlbertTokenizer.sp_model.IdToPiece"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"", "\n", "return", "self", ".", "sp_model", ".", "IdToPiece", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_albert.AlbertTokenizer.convert_tokens_to_string": [[182, 186], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"", "\n", "out_string", "=", "\"\"", ".", "join", "(", "tokens", ")", ".", "replace", "(", "SPIECE_UNDERLINE", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_albert.AlbertTokenizer.build_inputs_with_special_tokens": [[187, 200], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n        by concatenating and adding special tokens.\n        An ALBERT sequence has the following format:\n            single sequence: [CLS] X [SEP]\n            pair of sequences: [CLS] A [SEP] B [SEP]\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "cls", "+", "token_ids_0", "+", "sep", "\n", "", "return", "cls", "+", "token_ids_0", "+", "sep", "+", "token_ids_1", "+", "sep", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_albert.AlbertTokenizer.get_special_tokens_mask": [[201, 228], ["list", "ValueError", "map", "len", "len", "len"], "methods", ["None"], ["", "def", "get_special_tokens_mask", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ",", "already_has_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n\n        Args:\n            token_ids_0: list of ids (must not contain special tokens)\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n                for sequence pairs\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n                special tokens for the model\n\n        Returns:\n            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n        \"\"\"", "\n", "\n", "if", "already_has_special_tokens", ":", "\n", "            ", "if", "token_ids_1", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"You should not supply a second sequence if the provided sequence of \"", "\n", "\"ids is already formated with special tokens for the model.\"", "\n", ")", "\n", "", "return", "list", "(", "map", "(", "lambda", "x", ":", "1", "if", "x", "in", "[", "self", ".", "sep_token_id", ",", "self", ".", "cls_token_id", "]", "else", "0", ",", "token_ids_0", ")", ")", "\n", "\n", "", "if", "token_ids_1", "is", "not", "None", ":", "\n", "            ", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_1", ")", ")", "+", "[", "1", "]", "\n", "", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_albert.AlbertTokenizer.create_token_type_ids_from_sequences": [[229, 244], ["len", "len", "len"], "methods", ["None"], ["", "def", "create_token_type_ids_from_sequences", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n        An ALBERT sequence pair mask has the following format:\n        0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1\n        | first sequence    | second sequence\n\n        if token_ids_1 is None, only returns the first portion of the mask (0's).\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "\n", "", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "+", "len", "(", "token_ids_1", "+", "sep", ")", "*", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_albert.AlbertTokenizer.save_vocabulary": [[245, 258], ["os.path.join", "os.path.isdir", "logger.error", "os.path.abspath", "os.path.abspath", "shutil.copyfile"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n            to a directory.\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "out_vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "\n", "if", "os", ".", "path", ".", "abspath", "(", "self", ".", "vocab_file", ")", "!=", "os", ".", "path", ".", "abspath", "(", "out_vocab_file", ")", ":", "\n", "            ", "copyfile", "(", "self", ".", "vocab_file", ",", "out_vocab_file", ")", "\n", "\n", "", "return", "(", "out_vocab_file", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.S3Obj.__init__": [[30, 35], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename", ":", "str", ",", "LastModified", ":", "str", ",", "ETag", ":", "str", ",", "Size", ":", "int", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "filename", "=", "filename", "\n", "self", ".", "LastModified", "=", "LastModified", "\n", "self", ".", "ETag", "=", "ETag", "\n", "self", ".", "Size", "=", "Size", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.PresignedUrl.__init__": [[38, 42], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "write", ":", "str", ",", "access", ":", "str", ",", "type", ":", "str", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "write", "=", "write", "\n", "self", ".", "access", "=", "access", "\n", "self", ".", "type", "=", "type", "# mime-type to send to S3.", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.__init__": [[45, 47], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "endpoint", "=", "None", ")", ":", "\n", "        ", "self", ".", "endpoint", "=", "endpoint", "if", "endpoint", "is", "not", "None", "else", "ENDPOINT", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.login": [[48, 63], ["requests.post", "requests.post.raise_for_status", "requests.post.json"], "methods", ["None"], ["", "def", "login", "(", "self", ",", "username", ":", "str", ",", "password", ":", "str", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Call HF API to sign in a user and get a token if credentials are valid.\n\n        Outputs:\n            token if credentials are valid\n\n        Throws:\n            requests.exceptions.HTTPError if credentials are invalid\n        \"\"\"", "\n", "path", "=", "\"{}/api/login\"", ".", "format", "(", "self", ".", "endpoint", ")", "\n", "r", "=", "requests", ".", "post", "(", "path", ",", "json", "=", "{", "\"username\"", ":", "username", ",", "\"password\"", ":", "password", "}", ")", "\n", "r", ".", "raise_for_status", "(", ")", "\n", "d", "=", "r", ".", "json", "(", ")", "\n", "return", "d", "[", "\"token\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.whoami": [[64, 73], ["requests.get", "requests.get.raise_for_status", "requests.get.json"], "methods", ["None"], ["", "def", "whoami", "(", "self", ",", "token", ":", "str", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Call HF API to know \"whoami\"\n        \"\"\"", "\n", "path", "=", "\"{}/api/whoami\"", ".", "format", "(", "self", ".", "endpoint", ")", "\n", "r", "=", "requests", ".", "get", "(", "path", ",", "headers", "=", "{", "\"authorization\"", ":", "\"Bearer {}\"", ".", "format", "(", "token", ")", "}", ")", "\n", "r", ".", "raise_for_status", "(", ")", "\n", "d", "=", "r", ".", "json", "(", ")", "\n", "return", "d", "[", "\"user\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.logout": [[74, 81], ["requests.post", "requests.post.raise_for_status"], "methods", ["None"], ["", "def", "logout", "(", "self", ",", "token", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Call HF API to log out.\n        \"\"\"", "\n", "path", "=", "\"{}/api/logout\"", ".", "format", "(", "self", ".", "endpoint", ")", "\n", "r", "=", "requests", ".", "post", "(", "path", ",", "headers", "=", "{", "\"authorization\"", ":", "\"Bearer {}\"", ".", "format", "(", "token", ")", "}", ")", "\n", "r", ".", "raise_for_status", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.presign": [[82, 91], ["requests.post", "requests.post.raise_for_status", "requests.post.json", "hf_api.PresignedUrl"], "methods", ["None"], ["", "def", "presign", "(", "self", ",", "token", ":", "str", ",", "filename", ")", "->", "PresignedUrl", ":", "\n", "        ", "\"\"\"\n        Call HF API to get a presigned url to upload `filename` to S3.\n        \"\"\"", "\n", "path", "=", "\"{}/api/presign\"", ".", "format", "(", "self", ".", "endpoint", ")", "\n", "r", "=", "requests", ".", "post", "(", "path", ",", "headers", "=", "{", "\"authorization\"", ":", "\"Bearer {}\"", ".", "format", "(", "token", ")", "}", ",", "json", "=", "{", "\"filename\"", ":", "filename", "}", ")", "\n", "r", ".", "raise_for_status", "(", ")", "\n", "d", "=", "r", ".", "json", "(", ")", "\n", "return", "PresignedUrl", "(", "**", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.presign_and_upload": [[92, 113], ["hf_api.HfApi.presign", "open", "hf_api.TqdmProgressFileReader", "requests.put", "requests.put.raise_for_status", "hf_api.TqdmProgressFileReader.close"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.presign", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.TqdmProgressFileReader.close"], ["", "def", "presign_and_upload", "(", "self", ",", "token", ":", "str", ",", "filename", ",", "filepath", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Get a presigned url, then upload file to S3.\n\n        Outputs:\n            url: Read-only url for the stored file on S3.\n        \"\"\"", "\n", "urls", "=", "self", ".", "presign", "(", "token", ",", "filename", "=", "filename", ")", "\n", "# streaming upload:", "\n", "# https://2.python-requests.org/en/master/user/advanced/#streaming-uploads", "\n", "#", "\n", "# Even though we presign with the correct content-type,", "\n", "# the client still has to specify it when uploading the file.", "\n", "with", "open", "(", "filepath", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "pf", "=", "TqdmProgressFileReader", "(", "f", ")", "\n", "data", "=", "f", "if", "pf", ".", "total_size", ">", "0", "else", "\"\"", "\n", "\n", "r", "=", "requests", ".", "put", "(", "urls", ".", "write", ",", "data", "=", "data", ",", "headers", "=", "{", "\"content-type\"", ":", "urls", ".", "type", "}", ")", "\n", "r", ".", "raise_for_status", "(", ")", "\n", "pf", ".", "close", "(", ")", "\n", "", "return", "urls", ".", "access", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.list_objs": [[114, 123], ["requests.get", "requests.get.raise_for_status", "requests.get.json", "hf_api.S3Obj"], "methods", ["None"], ["", "def", "list_objs", "(", "self", ",", "token", ")", "->", "List", "[", "S3Obj", "]", ":", "\n", "        ", "\"\"\"\n        Call HF API to list all stored files for user.\n        \"\"\"", "\n", "path", "=", "\"{}/api/listObjs\"", ".", "format", "(", "self", ".", "endpoint", ")", "\n", "r", "=", "requests", ".", "get", "(", "path", ",", "headers", "=", "{", "\"authorization\"", ":", "\"Bearer {}\"", ".", "format", "(", "token", ")", "}", ")", "\n", "r", ".", "raise_for_status", "(", ")", "\n", "d", "=", "r", ".", "json", "(", ")", "\n", "return", "[", "S3Obj", "(", "**", "x", ")", "for", "x", "in", "d", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.TqdmProgressFileReader.__init__": [[134, 140], ["tqdm.tqdm.tqdm", "os.fstat", "f.fileno"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "f", ":", "io", ".", "BufferedReader", ")", ":", "\n", "        ", "self", ".", "f", "=", "f", "\n", "self", ".", "total_size", "=", "os", ".", "fstat", "(", "f", ".", "fileno", "(", ")", ")", ".", "st_size", "\n", "self", ".", "pbar", "=", "tqdm", "(", "total", "=", "self", ".", "total_size", ",", "leave", "=", "False", ")", "\n", "self", ".", "read", "=", "f", ".", "read", "\n", "f", ".", "read", "=", "self", ".", "_read", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.TqdmProgressFileReader._read": [[141, 144], ["hf_api.TqdmProgressFileReader.pbar.update", "hf_api.TqdmProgressFileReader.read"], "methods", ["None"], ["", "def", "_read", "(", "self", ",", "n", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "pbar", ".", "update", "(", "n", ")", "\n", "return", "self", ".", "read", "(", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.TqdmProgressFileReader.close": [[145, 147], ["hf_api.TqdmProgressFileReader.pbar.close"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.TqdmProgressFileReader.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "pbar", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfFolder.save_token": [[152, 160], ["os.makedirs", "os.path.dirname", "open", "f.write"], "methods", ["None"], ["@", "classmethod", "\n", "def", "save_token", "(", "cls", ",", "token", ")", ":", "\n", "        ", "\"\"\"\n        Save token, creating folder as needed.\n        \"\"\"", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "cls", ".", "path_token", ")", ",", "exist_ok", "=", "True", ")", "\n", "with", "open", "(", "cls", ".", "path_token", ",", "\"w+\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfFolder.get_token": [[161, 171], ["open", "f.read"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "get_token", "(", "cls", ")", ":", "\n", "        ", "\"\"\"\n        Get token or None if not existent.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "with", "open", "(", "cls", ".", "path_token", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "return", "f", ".", "read", "(", ")", "\n", "", "", "except", "FileNotFoundError", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfFolder.delete_token": [[172, 182], ["os.remove"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "delete_token", "(", "cls", ")", ":", "\n", "        ", "\"\"\"\n        Delete token.\n        Do not fail if token does not exist.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "os", ".", "remove", "(", "cls", ".", "path_token", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "            ", "pass", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modelcard.ModelCard.__init__": [[55, 74], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.items", "setattr", "logger.error"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "# Recomended attributes from https://arxiv.org/abs/1810.03993 (see papers)", "\n", "        ", "self", ".", "model_details", "=", "kwargs", ".", "pop", "(", "\"model_details\"", ",", "{", "}", ")", "\n", "self", ".", "intended_use", "=", "kwargs", ".", "pop", "(", "\"intended_use\"", ",", "{", "}", ")", "\n", "self", ".", "factors", "=", "kwargs", ".", "pop", "(", "\"factors\"", ",", "{", "}", ")", "\n", "self", ".", "metrics", "=", "kwargs", ".", "pop", "(", "\"metrics\"", ",", "{", "}", ")", "\n", "self", ".", "evaluation_data", "=", "kwargs", ".", "pop", "(", "\"evaluation_data\"", ",", "{", "}", ")", "\n", "self", ".", "training_data", "=", "kwargs", ".", "pop", "(", "\"training_data\"", ",", "{", "}", ")", "\n", "self", ".", "quantitative_analyses", "=", "kwargs", ".", "pop", "(", "\"quantitative_analyses\"", ",", "{", "}", ")", "\n", "self", ".", "ethical_considerations", "=", "kwargs", ".", "pop", "(", "\"ethical_considerations\"", ",", "{", "}", ")", "\n", "self", ".", "caveats_and_recommendations", "=", "kwargs", ".", "pop", "(", "\"caveats_and_recommendations\"", ",", "{", "}", ")", "\n", "\n", "# Open additional attributes", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "", "except", "AttributeError", "as", "err", ":", "\n", "                ", "logger", ".", "error", "(", "\"Can't set {} with value {} for {}\"", ".", "format", "(", "key", ",", "value", ",", "self", ")", ")", "\n", "raise", "err", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modelcard.ModelCard.save_pretrained": [[75, 86], ["os.path.isdir", "modelcard.ModelCard.to_json_file", "logger.info", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.to_json_file"], ["", "", "", "def", "save_pretrained", "(", "self", ",", "save_directory_or_file", ")", ":", "\n", "        ", "\"\"\" Save a model card object to the directory or file `save_directory_or_file`.\n        \"\"\"", "\n", "if", "os", ".", "path", ".", "isdir", "(", "save_directory_or_file", ")", ":", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "            ", "output_model_card_file", "=", "os", ".", "path", ".", "join", "(", "save_directory_or_file", ",", "MODEL_CARD_NAME", ")", "\n", "", "else", ":", "\n", "            ", "output_model_card_file", "=", "save_directory_or_file", "\n", "\n", "", "self", ".", "to_json_file", "(", "output_model_card_file", ")", "\n", "logger", ".", "info", "(", "\"Model card saved in {}\"", ".", "format", "(", "output_model_card_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modelcard.ModelCard.from_pretrained": [[87, 208], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.items", "logger.info", "os.path.isdir", "file_utils.hf_bucket_url.replace", "file_utils.hf_bucket_url.replace", "file_utils.hf_bucket_url.replace", "file_utils.cached_path", "cls.from_json_file", "hasattr", "kwargs.pop", "str", "os.path.join", "logger.info", "logger.info", "logger.warning", "cls", "logger.warning", "logger.warning", "cls", "setattr", "to_remove.append", "os.path.isfile", "file_utils.is_remote_url", "file_utils.hf_bucket_url", "logger.warning", "logger.warning", "configuration_auto.ALL_PRETRAINED_CONFIG_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_remote_url", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.hf_bucket_url"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiate a :class:`~transformers.ModelCard` from a pre-trained model model card.\n\n        Parameters:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model card to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model card that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing a mode card file saved using the :func:`~transformers.ModelCard.save_pretrained` method, e.g.: ``./my_model_directory/``.\n                - a path or url to a saved model card JSON `file`, e.g.: ``./my_model_directory/modelcard.json``.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                card should be cached if the standard cache should not be used.\n\n            kwargs: (`optional`) dict: key/value pairs with which to update the ModelCard object after loading.\n\n                - The values in kwargs of any keys which are model card attributes will be used to override the loaded values.\n                - Behavior concerning key/value pairs whose keys are *not* model card attributes is controlled by the `return_unused_kwargs` keyword parameter.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            find_from_standard_name: (`optional`) boolean, default True:\n                If the pretrained_model_name_or_path ends with our standard model or config filenames, replace them with our standard modelcard filename.\n                Can be used to directly feed a model/config url and access the colocated modelcard.\n\n            return_unused_kwargs: (`optional`) bool:\n\n                - If False, then this function returns just the final model card object.\n                - If True, then this functions returns a tuple `(model card, unused_kwargs)` where `unused_kwargs` is a dictionary consisting of the key/value pairs whose keys are not model card attributes: ie the part of kwargs which has not been used to update `ModelCard` and is otherwise ignored.\n\n        Examples::\n\n            modelcard = ModelCard.from_pretrained('bert-base-uncased')    # Download model card from S3 and cache.\n            modelcard = ModelCard.from_pretrained('./test/saved_model/')  # E.g. model card was saved using `save_pretrained('./test/saved_model/')`\n            modelcard = ModelCard.from_pretrained('./test/saved_model/modelcard.json')\n            modelcard = ModelCard.from_pretrained('bert-base-uncased', output_attention=True, foo=False)\n\n        \"\"\"", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "\"cache_dir\"", ",", "None", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "\"proxies\"", ",", "None", ")", "\n", "find_from_standard_name", "=", "kwargs", ".", "pop", "(", "\"find_from_standard_name\"", ",", "True", ")", "\n", "return_unused_kwargs", "=", "kwargs", ".", "pop", "(", "\"return_unused_kwargs\"", ",", "False", ")", "\n", "\n", "if", "pretrained_model_name_or_path", "in", "ALL_PRETRAINED_CONFIG_ARCHIVE_MAP", ":", "\n", "# For simplicity we use the same pretrained url than the configuration files", "\n", "# but with a different suffix (modelcard.json). This suffix is replaced below.", "\n", "            ", "model_card_file", "=", "ALL_PRETRAINED_CONFIG_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "model_card_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "MODEL_CARD_NAME", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", ")", "or", "is_remote_url", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "model_card_file", "=", "pretrained_model_name_or_path", "\n", "", "else", ":", "\n", "            ", "model_card_file", "=", "hf_bucket_url", "(", "pretrained_model_name_or_path", ",", "postfix", "=", "MODEL_CARD_NAME", ")", "\n", "\n", "", "if", "find_from_standard_name", "or", "pretrained_model_name_or_path", "in", "ALL_PRETRAINED_CONFIG_ARCHIVE_MAP", ":", "\n", "            ", "model_card_file", "=", "model_card_file", ".", "replace", "(", "CONFIG_NAME", ",", "MODEL_CARD_NAME", ")", "\n", "model_card_file", "=", "model_card_file", ".", "replace", "(", "WEIGHTS_NAME", ",", "MODEL_CARD_NAME", ")", "\n", "model_card_file", "=", "model_card_file", ".", "replace", "(", "TF2_WEIGHTS_NAME", ",", "MODEL_CARD_NAME", ")", "\n", "\n", "", "try", ":", "\n", "# Load from URL or cache if already cached", "\n", "            ", "resolved_model_card_file", "=", "cached_path", "(", "\n", "model_card_file", ",", "cache_dir", "=", "cache_dir", ",", "force_download", "=", "True", ",", "proxies", "=", "proxies", ",", "resume_download", "=", "False", "\n", ")", "\n", "if", "resolved_model_card_file", "==", "model_card_file", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading model card file {}\"", ".", "format", "(", "model_card_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"loading model card file {} from cache at {}\"", ".", "format", "(", "model_card_file", ",", "resolved_model_card_file", ")", "\n", ")", "\n", "# Load model card", "\n", "", "modelcard", "=", "cls", ".", "from_json_file", "(", "resolved_model_card_file", ")", "\n", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "ALL_PRETRAINED_CONFIG_ARCHIVE_MAP", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Couldn't reach server at '{}' to download model card file.\"", ".", "format", "(", "model_card_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url to a model card file named {} or \"", "\n", "\"a directory containing such a file but couldn't find any such file at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "\", \"", ".", "join", "(", "ALL_PRETRAINED_CONFIG_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "model_card_file", ",", "\n", "MODEL_CARD_NAME", ",", "\n", ")", "\n", ")", "\n", "", "logger", ".", "warning", "(", "\"Creating an empty model card.\"", ")", "\n", "\n", "# We fall back on creating an empty model card", "\n", "modelcard", "=", "cls", "(", ")", "\n", "\n", "", "except", "json", ".", "JSONDecodeError", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Couldn't reach server at '{}' to download model card file or \"", "\n", "\"model card file is not a valid JSON file. \"", "\n", "\"Please check network or file content here: {}.\"", ".", "format", "(", "model_card_file", ",", "resolved_model_card_file", ")", "\n", ")", "\n", "logger", ".", "warning", "(", "\"Creating an empty model card.\"", ")", "\n", "\n", "# We fall back on creating an empty model card", "\n", "modelcard", "=", "cls", "(", ")", "\n", "\n", "# Update model card with kwargs if needed", "\n", "", "to_remove", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "modelcard", ",", "key", ")", ":", "\n", "                ", "setattr", "(", "modelcard", ",", "key", ",", "value", ")", "\n", "to_remove", ".", "append", "(", "key", ")", "\n", "", "", "for", "key", "in", "to_remove", ":", "\n", "            ", "kwargs", ".", "pop", "(", "key", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Model card: %s\"", ",", "str", "(", "modelcard", ")", ")", "\n", "if", "return_unused_kwargs", ":", "\n", "            ", "return", "modelcard", ",", "kwargs", "\n", "", "else", ":", "\n", "            ", "return", "modelcard", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modelcard.ModelCard.from_dict": [[209, 213], ["cls"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `ModelCard` from a Python dictionary of parameters.\"\"\"", "\n", "return", "cls", "(", "**", "json_object", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modelcard.ModelCard.from_json_file": [[214, 221], ["json.loads", "cls", "open", "reader.read"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `ModelCard` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "dict_obj", "=", "json", ".", "loads", "(", "text", ")", "\n", "return", "cls", "(", "**", "dict_obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modelcard.ModelCard.__eq__": [[222, 224], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modelcard.ModelCard.__repr__": [[225, 227], ["str", "modelcard.ModelCard.to_json_string"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modelcard.ModelCard.to_dict": [[228, 232], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modelcard.ModelCard.to_json_string": [[233, 236], ["json.dumps", "modelcard.ModelCard.to_dict"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modelcard.ModelCard.to_json_file": [[237, 241], ["open", "writer.write", "modelcard.ModelCard.to_json_string"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_json_string"], ["", "def", "to_json_file", "(", "self", ",", "json_file_path", ")", ":", "\n", "        ", "\"\"\" Save this instance to a json file.\"\"\"", "\n", "with", "open", "(", "json_file_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.WarmUp.__init__": [[26, 33], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "initial_learning_rate", ",", "decay_schedule_fn", ",", "warmup_steps", ",", "power", "=", "1.0", ",", "name", "=", "None", ")", ":", "\n", "        ", "super", "(", "WarmUp", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "initial_learning_rate", "=", "initial_learning_rate", "\n", "self", ".", "warmup_steps", "=", "warmup_steps", "\n", "self", ".", "power", "=", "power", "\n", "self", ".", "decay_schedule_fn", "=", "decay_schedule_fn", "\n", "self", ".", "name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.WarmUp.__call__": [[34, 47], ["tensorflow.name_scope", "tensorflow.cast", "tensorflow.cast", "tensorflow.cond", "tensorflow.math.pow", "optimization_tf.WarmUp.decay_schedule_fn"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "step", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "self", ".", "name", "or", "\"WarmUp\"", ")", "as", "name", ":", "\n", "# Implements polynomial warmup. i.e., if global_step < warmup_steps, the", "\n", "# learning rate will be `global_step/num_warmup_steps * init_lr`.", "\n", "            ", "global_step_float", "=", "tf", ".", "cast", "(", "step", ",", "tf", ".", "float32", ")", "\n", "warmup_steps_float", "=", "tf", ".", "cast", "(", "self", ".", "warmup_steps", ",", "tf", ".", "float32", ")", "\n", "warmup_percent_done", "=", "global_step_float", "/", "warmup_steps_float", "\n", "warmup_learning_rate", "=", "self", ".", "initial_learning_rate", "*", "tf", ".", "math", ".", "pow", "(", "warmup_percent_done", ",", "self", ".", "power", ")", "\n", "return", "tf", ".", "cond", "(", "\n", "global_step_float", "<", "warmup_steps_float", ",", "\n", "lambda", ":", "warmup_learning_rate", ",", "\n", "lambda", ":", "self", ".", "decay_schedule_fn", "(", "step", ")", ",", "\n", "name", "=", "name", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.WarmUp.get_config": [[49, 56], ["None"], "methods", ["None"], ["", "", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"initial_learning_rate\"", ":", "self", ".", "initial_learning_rate", ",", "\n", "\"decay_schedule_fn\"", ":", "self", ".", "decay_schedule_fn", ",", "\n", "\"warmup_steps\"", ":", "self", ".", "warmup_steps", ",", "\n", "\"power\"", ":", "self", ".", "power", ",", "\n", "\"name\"", ":", "self", ".", "name", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay.__init__": [[92, 109], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "learning_rate", "=", "0.001", ",", "\n", "beta_1", "=", "0.9", ",", "\n", "beta_2", "=", "0.999", ",", "\n", "epsilon", "=", "1e-7", ",", "\n", "amsgrad", "=", "False", ",", "\n", "weight_decay_rate", "=", "0.0", ",", "\n", "include_in_weight_decay", "=", "None", ",", "\n", "exclude_from_weight_decay", "=", "None", ",", "\n", "name", "=", "\"AdamWeightDecay\"", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "AdamWeightDecay", ",", "self", ")", ".", "__init__", "(", "learning_rate", ",", "beta_1", ",", "beta_2", ",", "epsilon", ",", "amsgrad", ",", "name", ",", "**", "kwargs", ")", "\n", "self", ".", "weight_decay_rate", "=", "weight_decay_rate", "\n", "self", ".", "_include_in_weight_decay", "=", "include_in_weight_decay", "\n", "self", ".", "_exclude_from_weight_decay", "=", "exclude_from_weight_decay", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay.from_config": [[110, 115], ["super().from_config"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay.from_config"], ["", "@", "classmethod", "\n", "def", "from_config", "(", "cls", ",", "config", ")", ":", "\n", "        ", "\"\"\"Creates an optimizer from its config with WarmUp custom object.\"\"\"", "\n", "custom_objects", "=", "{", "\"WarmUp\"", ":", "WarmUp", "}", "\n", "return", "super", "(", "AdamWeightDecay", ",", "cls", ")", ".", "from_config", "(", "config", ",", "custom_objects", "=", "custom_objects", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay._prepare_local": [[116, 119], ["super()._prepare_local", "tensorflow.constant"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay._prepare_local"], ["", "def", "_prepare_local", "(", "self", ",", "var_device", ",", "var_dtype", ",", "apply_state", ")", ":", "\n", "        ", "super", "(", "AdamWeightDecay", ",", "self", ")", ".", "_prepare_local", "(", "var_device", ",", "var_dtype", ",", "apply_state", ")", "\n", "apply_state", "[", "\"weight_decay_rate\"", "]", "=", "tf", ".", "constant", "(", "self", ".", "weight_decay_rate", ",", "name", "=", "\"adam_weight_decay_rate\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay._decay_weights_op": [[120, 127], ["optimization_tf.AdamWeightDecay._do_use_weight_decay", "tensorflow.no_op", "var.assign_sub"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay._do_use_weight_decay"], ["", "def", "_decay_weights_op", "(", "self", ",", "var", ",", "learning_rate", ",", "apply_state", ")", ":", "\n", "        ", "do_decay", "=", "self", ".", "_do_use_weight_decay", "(", "var", ".", "name", ")", "\n", "if", "do_decay", ":", "\n", "            ", "return", "var", ".", "assign_sub", "(", "\n", "learning_rate", "*", "var", "*", "apply_state", "[", "\"weight_decay_rate\"", "]", ",", "use_locking", "=", "self", ".", "_use_locking", "\n", ")", "\n", "", "return", "tf", ".", "no_op", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay.apply_gradients": [[128, 132], ["list", "tensorflow.clip_by_global_norm", "super().apply_gradients", "zip", "zip"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay.apply_gradients"], ["", "def", "apply_gradients", "(", "self", ",", "grads_and_vars", ",", "clip_norm", ",", "name", "=", "None", ")", ":", "\n", "        ", "grads", ",", "tvars", "=", "list", "(", "zip", "(", "*", "grads_and_vars", ")", ")", "\n", "(", "grads", ",", "_", ")", "=", "tf", ".", "clip_by_global_norm", "(", "grads", ",", "clip_norm", "=", "clip_norm", ")", "\n", "return", "super", "(", "AdamWeightDecay", ",", "self", ")", ".", "apply_gradients", "(", "zip", "(", "grads", ",", "tvars", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay._get_lr": [[133, 145], ["apply_state.get", "optimization_tf.AdamWeightDecay._fallback_apply_state", "dict"], "methods", ["None"], ["", "def", "_get_lr", "(", "self", ",", "var_device", ",", "var_dtype", ",", "apply_state", ")", ":", "\n", "        ", "\"\"\"Retrieves the learning rate with the given state.\"\"\"", "\n", "if", "apply_state", "is", "None", ":", "\n", "            ", "return", "self", ".", "_decayed_lr_t", "[", "var_dtype", "]", ",", "{", "}", "\n", "\n", "", "apply_state", "=", "apply_state", "or", "{", "}", "\n", "coefficients", "=", "apply_state", ".", "get", "(", "(", "var_device", ",", "var_dtype", ")", ")", "\n", "if", "coefficients", "is", "None", ":", "\n", "            ", "coefficients", "=", "self", ".", "_fallback_apply_state", "(", "var_device", ",", "var_dtype", ")", "\n", "apply_state", "[", "(", "var_device", ",", "var_dtype", ")", "]", "=", "coefficients", "\n", "\n", "", "return", "coefficients", "[", "\"lr_t\"", "]", ",", "dict", "(", "apply_state", "=", "apply_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay._resource_apply_dense": [[146, 151], ["optimization_tf.AdamWeightDecay._get_lr", "optimization_tf.AdamWeightDecay._decay_weights_op", "tensorflow.control_dependencies", "super()._resource_apply_dense"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay._get_lr", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay._decay_weights_op", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay._resource_apply_dense"], ["", "def", "_resource_apply_dense", "(", "self", ",", "grad", ",", "var", ",", "apply_state", "=", "None", ")", ":", "\n", "        ", "lr_t", ",", "kwargs", "=", "self", ".", "_get_lr", "(", "var", ".", "device", ",", "var", ".", "dtype", ".", "base_dtype", ",", "apply_state", ")", "\n", "decay", "=", "self", ".", "_decay_weights_op", "(", "var", ",", "lr_t", ",", "apply_state", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "decay", "]", ")", ":", "\n", "            ", "return", "super", "(", "AdamWeightDecay", ",", "self", ")", ".", "_resource_apply_dense", "(", "grad", ",", "var", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay._resource_apply_sparse": [[152, 157], ["optimization_tf.AdamWeightDecay._get_lr", "optimization_tf.AdamWeightDecay._decay_weights_op", "tensorflow.control_dependencies", "super()._resource_apply_sparse"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay._get_lr", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay._decay_weights_op", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay._resource_apply_sparse"], ["", "", "def", "_resource_apply_sparse", "(", "self", ",", "grad", ",", "var", ",", "indices", ",", "apply_state", "=", "None", ")", ":", "\n", "        ", "lr_t", ",", "kwargs", "=", "self", ".", "_get_lr", "(", "var", ".", "device", ",", "var", ".", "dtype", ".", "base_dtype", ",", "apply_state", ")", "\n", "decay", "=", "self", ".", "_decay_weights_op", "(", "var", ",", "lr_t", ",", "apply_state", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "decay", "]", ")", ":", "\n", "            ", "return", "super", "(", "AdamWeightDecay", ",", "self", ")", ".", "_resource_apply_sparse", "(", "grad", ",", "var", ",", "indices", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay.get_config": [[158, 162], ["super().get_config", "super().get_config.update"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay.get_config"], ["", "", "def", "get_config", "(", "self", ")", ":", "\n", "        ", "config", "=", "super", "(", "AdamWeightDecay", ",", "self", ")", ".", "get_config", "(", ")", "\n", "config", ".", "update", "(", "{", "\"weight_decay_rate\"", ":", "self", ".", "weight_decay_rate", "}", ")", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.AdamWeightDecay._do_use_weight_decay": [[163, 178], ["re.search", "re.search"], "methods", ["None"], ["", "def", "_do_use_weight_decay", "(", "self", ",", "param_name", ")", ":", "\n", "        ", "\"\"\"Whether to use L2 weight decay for `param_name`.\"\"\"", "\n", "if", "self", ".", "weight_decay_rate", "==", "0", ":", "\n", "            ", "return", "False", "\n", "\n", "", "if", "self", ".", "_include_in_weight_decay", ":", "\n", "            ", "for", "r", "in", "self", ".", "_include_in_weight_decay", ":", "\n", "                ", "if", "re", ".", "search", "(", "r", ",", "param_name", ")", "is", "not", "None", ":", "\n", "                    ", "return", "True", "\n", "\n", "", "", "", "if", "self", ".", "_exclude_from_weight_decay", ":", "\n", "            ", "for", "r", "in", "self", ".", "_exclude_from_weight_decay", ":", "\n", "                ", "if", "re", ".", "search", "(", "r", ",", "param_name", ")", "is", "not", "None", ":", "\n", "                    ", "return", "False", "\n", "", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator.__init__": [[184, 189], ["tensorflow.Variable"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Initializes the accumulator.\"\"\"", "\n", "self", ".", "_gradients", "=", "[", "]", "\n", "self", ".", "_accum_steps", "=", "tf", ".", "Variable", "(", "\n", "initial_value", "=", "0", ",", "dtype", "=", "tf", ".", "int64", ",", "trainable", "=", "False", ",", "aggregation", "=", "tf", ".", "VariableAggregation", ".", "ONLY_FIRST_REPLICA", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator.step": [[191, 195], ["optimization_tf.GradientAccumulator._accum_steps.value"], "methods", ["None"], ["", "@", "property", "\n", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\"Number of accumulated steps.\"\"\"", "\n", "return", "self", ".", "_accum_steps", ".", "value", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator.gradients": [[196, 201], ["list", "gradient.value", "optimization_tf.GradientAccumulator._get_replica_gradients"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator._get_replica_gradients"], ["", "@", "property", "\n", "def", "gradients", "(", "self", ")", ":", "\n", "        ", "\"\"\"The accumulated gradients.\"\"\"", "\n", "return", "list", "(", "\n", "gradient", ".", "value", "(", ")", "if", "gradient", "is", "not", "None", "else", "gradient", "for", "gradient", "in", "self", ".", "_get_replica_gradients", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator.__call__": [[203, 221], ["zip", "optimization_tf.GradientAccumulator._accum_steps.assign_add", "optimization_tf.GradientAccumulator._gradients.extend", "len", "len", "ValueError", "optimization_tf.GradientAccumulator._get_replica_gradients", "accum_gradient.assign_add", "tensorflow.Variable", "len", "len", "tensorflow.zeros_like"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator._get_replica_gradients"], ["", "def", "__call__", "(", "self", ",", "gradients", ")", ":", "\n", "        ", "\"\"\"Accumulates :obj:`gradients`.\"\"\"", "\n", "if", "not", "self", ".", "_gradients", ":", "\n", "            ", "self", ".", "_gradients", ".", "extend", "(", "\n", "[", "\n", "tf", ".", "Variable", "(", "tf", ".", "zeros_like", "(", "gradient", ")", ",", "trainable", "=", "False", ")", "if", "gradient", "is", "not", "None", "else", "gradient", "\n", "for", "gradient", "in", "gradients", "\n", "]", "\n", ")", "\n", "\n", "", "if", "len", "(", "gradients", ")", "!=", "len", "(", "self", ".", "_gradients", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Expected %s gradients, but got %d\"", "%", "(", "len", "(", "self", ".", "_gradients", ")", ",", "len", "(", "gradients", ")", ")", ")", "\n", "\n", "", "for", "accum_gradient", ",", "gradient", "in", "zip", "(", "self", ".", "_get_replica_gradients", "(", ")", ",", "gradients", ")", ":", "\n", "            ", "if", "accum_gradient", "is", "not", "None", ":", "\n", "                ", "accum_gradient", ".", "assign_add", "(", "gradient", ")", "\n", "\n", "", "", "self", ".", "_accum_steps", ".", "assign_add", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator.reset": [[222, 230], ["optimization_tf.GradientAccumulator._get_replica_gradients", "optimization_tf.GradientAccumulator._accum_steps.assign", "gradient.assign", "tensorflow.zeros_like"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator._get_replica_gradients"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets the accumulated gradients.\"\"\"", "\n", "if", "self", ".", "_gradients", ":", "\n", "            ", "self", ".", "_accum_steps", ".", "assign", "(", "0", ")", "\n", "\n", "", "for", "gradient", "in", "self", ".", "_get_replica_gradients", "(", ")", ":", "\n", "            ", "if", "gradient", "is", "not", "None", ":", "\n", "                ", "gradient", ".", "assign", "(", "tf", ".", "zeros_like", "(", "gradient", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator._get_replica_gradients": [[231, 247], ["tensorflow.distribute.has_strategy", "tensorflow.distribute.get_replica_context", "gradient.device_map.select_for_current_replica", "tensorflow.distribute.get_strategy"], "methods", ["None"], ["", "", "", "def", "_get_replica_gradients", "(", "self", ")", ":", "\n", "        ", "if", "tf", ".", "distribute", ".", "has_strategy", "(", ")", ":", "\n", "# In a replica context, we want to accumulate gradients on each replica", "\n", "# without synchronization, so we directly assign the value of the", "\n", "# current replica.", "\n", "            ", "replica_context", "=", "tf", ".", "distribute", ".", "get_replica_context", "(", ")", "\n", "\n", "if", "replica_context", "is", "None", "or", "tf", ".", "distribute", ".", "get_strategy", "(", ")", ".", "num_replicas_in_sync", "==", "1", ":", "\n", "                ", "return", "self", ".", "_gradients", "\n", "\n", "", "return", "(", "\n", "gradient", ".", "device_map", ".", "select_for_current_replica", "(", "gradient", ".", "values", ",", "replica_context", ")", "\n", "for", "gradient", "in", "self", ".", "_gradients", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_gradients", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.create_optimizer": [[59, 78], ["tensorflow.keras.optimizers.schedules.PolynomialDecay", "optimization_tf.AdamWeightDecay", "optimization_tf.WarmUp"], "function", ["None"], ["", "", "def", "create_optimizer", "(", "init_lr", ",", "num_train_steps", ",", "num_warmup_steps", ")", ":", "\n", "    ", "\"\"\"Creates an optimizer with learning rate schedule.\"\"\"", "\n", "# Implements linear decay of the learning rate.", "\n", "learning_rate_fn", "=", "tf", ".", "keras", ".", "optimizers", ".", "schedules", ".", "PolynomialDecay", "(", "\n", "initial_learning_rate", "=", "init_lr", ",", "decay_steps", "=", "num_train_steps", ",", "end_learning_rate", "=", "0.0", "\n", ")", "\n", "if", "num_warmup_steps", ":", "\n", "        ", "learning_rate_fn", "=", "WarmUp", "(", "\n", "initial_learning_rate", "=", "init_lr", ",", "decay_schedule_fn", "=", "learning_rate_fn", ",", "warmup_steps", "=", "num_warmup_steps", "\n", ")", "\n", "", "optimizer", "=", "AdamWeightDecay", "(", "\n", "learning_rate", "=", "learning_rate_fn", ",", "\n", "weight_decay_rate", "=", "0.01", ",", "\n", "beta_1", "=", "0.9", ",", "\n", "beta_2", "=", "0.999", ",", "\n", "epsilon", "=", "1e-6", ",", "\n", "exclude_from_weight_decay", "=", "[", "\"layer_norm\"", ",", "\"bias\"", "]", ",", "\n", ")", "\n", "return", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.__main__.main": [[4, 22], ["print", "convert", "len", "train"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.train"], ["def", "main", "(", ")", ":", "\n", "    ", "import", "sys", "\n", "\n", "if", "len", "(", "sys", ".", "argv", ")", "<", "2", "or", "sys", ".", "argv", "[", "1", "]", "not", "in", "[", "\"convert\"", ",", "\"train\"", ",", "\"predict\"", ",", "\"serve\"", "]", ":", "\n", "        ", "print", "(", "\n", "\"First argument to `transformers` command line interface should be one of: \\n\"", "\n", "\">> convert serve train predict\"", "\n", ")", "\n", "", "if", "sys", ".", "argv", "[", "1", "]", "==", "\"convert\"", ":", "\n", "        ", "from", "transformers", ".", "commands", "import", "convert", "\n", "\n", "convert", "(", "sys", ".", "argv", ")", "\n", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"train\"", ":", "\n", "        ", "from", "transformers", ".", "commands", "import", "train", "\n", "\n", "train", "(", "sys", ".", "argv", ")", "\n", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "\"serve\"", ":", "\n", "        ", "pass", "\n", "# from argparse import ArgumentParser", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_distilbert.DistilBertConfig.__init__": [[36, 69], ["configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "30522", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "sinusoidal_pos_embds", "=", "False", ",", "\n", "n_layers", "=", "6", ",", "\n", "n_heads", "=", "12", ",", "\n", "dim", "=", "768", ",", "\n", "hidden_dim", "=", "4", "*", "768", ",", "\n", "dropout", "=", "0.1", ",", "\n", "attention_dropout", "=", "0.1", ",", "\n", "activation", "=", "\"gelu\"", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "tie_weights_", "=", "True", ",", "\n", "qa_dropout", "=", "0.1", ",", "\n", "seq_classif_dropout", "=", "0.2", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "DistilBertConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "sinusoidal_pos_embds", "=", "sinusoidal_pos_embds", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "n_heads", "=", "n_heads", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "attention_dropout", "=", "attention_dropout", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "tie_weights_", "=", "tie_weights_", "\n", "self", ".", "qa_dropout", "=", "qa_dropout", "\n", "self", ".", "seq_classif_dropout", "=", "seq_classif_dropout", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_distilbert.DistilBertConfig.hidden_size": [[70, 73], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_distilbert.DistilBertConfig.num_attention_heads": [[74, 77], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_heads", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_distilbert.DistilBertConfig.num_hidden_layers": [[78, 81], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layers", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_transfo_xl.TransfoXLConfig.__init__": [[69, 136], ["configuration_utils.PretrainedConfig.__init__", "configuration_transfo_xl.TransfoXLConfig.cutoffs.extend", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "267735", ",", "\n", "cutoffs", "=", "[", "20000", ",", "40000", ",", "200000", "]", ",", "\n", "d_model", "=", "1024", ",", "\n", "d_embed", "=", "1024", ",", "\n", "n_head", "=", "16", ",", "\n", "d_head", "=", "64", ",", "\n", "d_inner", "=", "4096", ",", "\n", "div_val", "=", "4", ",", "\n", "pre_lnorm", "=", "False", ",", "\n", "n_layer", "=", "18", ",", "\n", "tgt_len", "=", "128", ",", "\n", "ext_len", "=", "0", ",", "\n", "mem_len", "=", "1600", ",", "\n", "clamp_len", "=", "1000", ",", "\n", "same_length", "=", "True", ",", "\n", "proj_share_all_but_first", "=", "True", ",", "\n", "attn_type", "=", "0", ",", "\n", "sample_softmax", "=", "-", "1", ",", "\n", "adaptive", "=", "True", ",", "\n", "tie_weight", "=", "True", ",", "\n", "dropout", "=", "0.1", ",", "\n", "dropatt", "=", "0.0", ",", "\n", "untie_r", "=", "True", ",", "\n", "init", "=", "\"normal\"", ",", "\n", "init_range", "=", "0.01", ",", "\n", "proj_init_std", "=", "0.01", ",", "\n", "init_std", "=", "0.02", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs TransfoXLConfig.\n        \"\"\"", "\n", "super", "(", "TransfoXLConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "cutoffs", "=", "[", "]", "\n", "self", ".", "cutoffs", ".", "extend", "(", "cutoffs", ")", "\n", "self", ".", "tie_weight", "=", "tie_weight", "\n", "if", "proj_share_all_but_first", ":", "\n", "            ", "self", ".", "tie_projs", "=", "[", "False", "]", "+", "[", "True", "]", "*", "len", "(", "self", ".", "cutoffs", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tie_projs", "=", "[", "False", "]", "+", "[", "False", "]", "*", "len", "(", "self", ".", "cutoffs", ")", "\n", "", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_head", "=", "d_head", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "div_val", "=", "div_val", "\n", "self", ".", "pre_lnorm", "=", "pre_lnorm", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "tgt_len", "=", "tgt_len", "\n", "self", ".", "ext_len", "=", "ext_len", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "same_length", "=", "same_length", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "self", ".", "clamp_len", "=", "clamp_len", "\n", "self", ".", "sample_softmax", "=", "sample_softmax", "\n", "self", ".", "adaptive", "=", "adaptive", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "dropatt", "=", "dropatt", "\n", "self", ".", "untie_r", "=", "untie_r", "\n", "self", ".", "init", "=", "init", "\n", "self", ".", "init_range", "=", "init_range", "\n", "self", ".", "proj_init_std", "=", "proj_init_std", "\n", "self", ".", "init_std", "=", "init_std", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_transfo_xl.TransfoXLConfig.max_position_embeddings": [[137, 140], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tgt_len", "+", "self", ".", "ext_len", "+", "self", ".", "mem_len", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_transfo_xl.TransfoXLConfig.n_token": [[145, 148], ["None"], "methods", ["None"], ["", "@", "n_token", ".", "setter", "\n", "def", "n_token", "(", "self", ",", "value", ")", ":", "# Backward compatibility", "\n", "        ", "self", ".", "vocab_size", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_transfo_xl.TransfoXLConfig.hidden_size": [[149, 152], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "d_model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_transfo_xl.TransfoXLConfig.num_attention_heads": [[153, 156], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_transfo_xl.TransfoXLConfig.num_hidden_layers": [[157, 160], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.MultiHeadAttention.__init__": [[98, 112], ["torch.nn.Module.__init__", "next", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "set"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "n_heads", ",", "dim", ",", "config", ")", ":", "\n", "        ", "super", "(", "MultiHeadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer_id", "=", "next", "(", "MultiHeadAttention", ".", "NEW_ID", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "n_heads", "=", "n_heads", "\n", "self", ".", "dropout", "=", "config", ".", "attention_dropout", "\n", "assert", "self", ".", "dim", "%", "self", ".", "n_heads", "==", "0", "\n", "\n", "self", ".", "q_lin", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "k_lin", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "v_lin", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "out_lin", "=", "nn", ".", "Linear", "(", "dim", ",", "dim", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.MultiHeadAttention.prune_heads": [[113, 133], ["torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_utils.prune_linear_layer", "modeling_xlm.MultiHeadAttention.pruned_heads.union", "len", "set", "sum", "len", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "attention_head_size", "=", "self", ".", "dim", "//", "self", ".", "n_heads", "\n", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "n_heads", ",", "attention_head_size", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "\n", "for", "head", "in", "heads", ":", "\n", "            ", "head", "-=", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "# Prune linear layers", "\n", "self", ".", "q_lin", "=", "prune_linear_layer", "(", "self", ".", "q_lin", ",", "index", ")", "\n", "self", ".", "k_lin", "=", "prune_linear_layer", "(", "self", ".", "k_lin", ",", "index", ")", "\n", "self", ".", "v_lin", "=", "prune_linear_layer", "(", "self", ".", "v_lin", ",", "index", ")", "\n", "self", ".", "out_lin", "=", "prune_linear_layer", "(", "self", ".", "out_lin", ",", "index", ",", "dim", "=", "1", ")", "\n", "# Update hyper params", "\n", "self", ".", "n_heads", "=", "self", ".", "n_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "dim", "=", "attention_head_size", "*", "self", ".", "n_heads", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.MultiHeadAttention.forward": [[134, 196], ["input.size", "modeling_xlm.MultiHeadAttention.forward.shape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "mask", ",", "kv", "=", "None", ",", "cache", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Self-attention (if kv is None) or attention over source sentence (provided by kv).\n        \"\"\"", "\n", "# Input is (bs, qlen, dim)", "\n", "# Mask is (bs, klen) (non-causal) or (bs, klen, klen)", "\n", "bs", ",", "qlen", ",", "dim", "=", "input", ".", "size", "(", ")", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "klen", "=", "qlen", "if", "cache", "is", "None", "else", "cache", "[", "\"slen\"", "]", "+", "qlen", "\n", "", "else", ":", "\n", "            ", "klen", "=", "kv", ".", "size", "(", "1", ")", "\n", "# assert dim == self.dim, 'Dimensions do not match: %s input vs %s configured' % (dim, self.dim)", "\n", "", "n_heads", "=", "self", ".", "n_heads", "\n", "dim_per_head", "=", "self", ".", "dim", "//", "n_heads", "\n", "mask_reshape", "=", "(", "bs", ",", "1", ",", "qlen", ",", "klen", ")", "if", "mask", ".", "dim", "(", ")", "==", "3", "else", "(", "bs", ",", "1", ",", "1", ",", "klen", ")", "\n", "\n", "def", "shape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  projection \"\"\"", "\n", "return", "x", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", ",", "dim_per_head", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "", "def", "unshape", "(", "x", ")", ":", "\n", "            ", "\"\"\"  compute context \"\"\"", "\n", "return", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "n_heads", "*", "dim_per_head", ")", "\n", "\n", "", "q", "=", "shape", "(", "self", ".", "q_lin", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "if", "kv", "is", "None", ":", "\n", "            ", "k", "=", "shape", "(", "self", ".", "k_lin", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v_lin", "(", "input", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "", "elif", "cache", "is", "None", "or", "self", ".", "layer_id", "not", "in", "cache", ":", "\n", "            ", "k", "=", "v", "=", "kv", "\n", "k", "=", "shape", "(", "self", ".", "k_lin", "(", "k", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "v", "=", "shape", "(", "self", ".", "v_lin", "(", "v", ")", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "\n", "", "if", "cache", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "layer_id", "in", "cache", ":", "\n", "                ", "if", "kv", "is", "None", ":", "\n", "                    ", "k_", ",", "v_", "=", "cache", "[", "self", ".", "layer_id", "]", "\n", "k", "=", "torch", ".", "cat", "(", "[", "k_", ",", "k", "]", ",", "dim", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "v", "=", "torch", ".", "cat", "(", "[", "v_", ",", "v", "]", ",", "dim", "=", "2", ")", "# (bs, n_heads, klen, dim_per_head)", "\n", "", "else", ":", "\n", "                    ", "k", ",", "v", "=", "cache", "[", "self", ".", "layer_id", "]", "\n", "", "", "cache", "[", "self", ".", "layer_id", "]", "=", "(", "k", ",", "v", ")", "\n", "\n", "", "q", "=", "q", "/", "math", ".", "sqrt", "(", "dim_per_head", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "scores", "=", "torch", ".", "matmul", "(", "q", ",", "k", ".", "transpose", "(", "2", ",", "3", ")", ")", "# (bs, n_heads, qlen, klen)", "\n", "mask", "=", "(", "mask", "==", "0", ")", ".", "view", "(", "mask_reshape", ")", ".", "expand_as", "(", "scores", ")", "# (bs, n_heads, qlen, klen)", "\n", "scores", ".", "masked_fill_", "(", "mask", ",", "-", "float", "(", "\"inf\"", ")", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "weights", "=", "F", ".", "softmax", "(", "scores", ".", "float", "(", ")", ",", "dim", "=", "-", "1", ")", ".", "type_as", "(", "scores", ")", "# (bs, n_heads, qlen, klen)", "\n", "weights", "=", "F", ".", "dropout", "(", "weights", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "# (bs, n_heads, qlen, klen)", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "weights", "=", "weights", "*", "head_mask", "\n", "\n", "", "context", "=", "torch", ".", "matmul", "(", "weights", ",", "v", ")", "# (bs, n_heads, qlen, dim_per_head)", "\n", "context", "=", "unshape", "(", "context", ")", "# (bs, qlen, dim)", "\n", "\n", "outputs", "=", "(", "self", ".", "out_lin", "(", "context", ")", ",", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "weights", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.TransformerFFN.__init__": [[199, 205], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_dim", ",", "dim_hidden", ",", "out_dim", ",", "config", ")", ":", "\n", "        ", "super", "(", "TransformerFFN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "lin1", "=", "nn", ".", "Linear", "(", "in_dim", ",", "dim_hidden", ")", "\n", "self", ".", "lin2", "=", "nn", ".", "Linear", "(", "dim_hidden", ",", "out_dim", ")", "\n", "self", ".", "act", "=", "gelu", "if", "config", ".", "gelu_activation", "else", "F", ".", "relu", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.TransformerFFN.forward": [[206, 212], ["modeling_xlm.TransformerFFN.lin1", "modeling_xlm.TransformerFFN.act", "modeling_xlm.TransformerFFN.lin2", "torch.nn.functional.dropout"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "x", "=", "self", ".", "lin1", "(", "input", ")", "\n", "x", "=", "self", ".", "act", "(", "x", ")", "\n", "x", "=", "self", ".", "lin2", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMPreTrainedModel.__init__": [[224, 226], ["modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "XLMPreTrainedModel", ",", "self", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMPreTrainedModel.dummy_inputs": [[227, 236], ["torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "@", "property", "\n", "def", "dummy_inputs", "(", "self", ")", ":", "\n", "        ", "inputs_list", "=", "torch", ".", "tensor", "(", "[", "[", "7", ",", "6", ",", "0", ",", "0", ",", "1", "]", ",", "[", "1", ",", "2", ",", "3", ",", "0", ",", "0", "]", ",", "[", "0", ",", "0", ",", "0", ",", "4", ",", "5", "]", "]", ")", "\n", "attns_list", "=", "torch", ".", "tensor", "(", "[", "[", "1", ",", "1", ",", "0", ",", "0", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", ",", "0", ",", "0", "]", ",", "[", "1", ",", "0", ",", "0", ",", "1", ",", "1", "]", "]", ")", "\n", "if", "self", ".", "config", ".", "use_lang_emb", "and", "self", ".", "config", ".", "n_langs", ">", "1", ":", "\n", "            ", "langs_list", "=", "torch", ".", "tensor", "(", "[", "[", "1", ",", "1", ",", "0", ",", "0", ",", "1", "]", ",", "[", "1", ",", "1", ",", "1", ",", "0", ",", "0", "]", ",", "[", "1", ",", "0", ",", "0", ",", "1", ",", "1", "]", "]", ")", "\n", "", "else", ":", "\n", "            ", "langs_list", "=", "None", "\n", "", "return", "{", "\"input_ids\"", ":", "inputs_list", ",", "\"attention_mask\"", ":", "attns_list", ",", "\"langs\"", ":", "langs_list", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMPreTrainedModel._init_weights": [[237, 250], ["isinstance", "isinstance", "isinstance", "module.bias.data.zero_", "module.weight.data.fill_", "torch.nn.init.normal_", "torch.nn.init.normal_", "hasattr", "torch.nn.init.constant_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights. \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Embedding", ")", ":", "\n", "            ", "if", "self", ".", "config", "is", "not", "None", "and", "self", ".", "config", ".", "embed_init_std", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "module", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "self", ".", "config", ".", "embed_init_std", ")", "\n", "", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "if", "self", ".", "config", "is", "not", "None", "and", "self", ".", "config", ".", "init_std", "is", "not", "None", ":", "\n", "                ", "nn", ".", "init", ".", "normal_", "(", "module", ".", "weight", ",", "mean", "=", "0", ",", "std", "=", "self", ".", "config", ".", "init_std", ")", "\n", "if", "hasattr", "(", "module", ",", "\"bias\"", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "module", ".", "bias", ",", "0.0", ")", "\n", "", "", "", "if", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMModel.__init__": [[356, 425], ["modeling_xlm.XLMPreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.LayerNorm", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "range", "hasattr", "modeling_xlm.XLMModel.init_weights", "NotImplementedError", "modeling_xlm.create_sinusoidal_embeddings", "torch.nn.Embedding", "modeling_xlm.XLMModel.attentions.append", "modeling_xlm.XLMModel.layer_norm1.append", "modeling_xlm.XLMModel.ffns.append", "modeling_xlm.XLMModel.layer_norm2.append", "config.pruned_heads.copy().items", "modeling_xlm.MultiHeadAttention", "torch.nn.LayerNorm", "modeling_xlm.TransformerFFN", "torch.nn.LayerNorm", "config.pruned_heads.copy", "modeling_xlm.XLMModel.prune_heads", "int", "list", "int", "map"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.create_sinusoidal_embeddings", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "# , dico, is_encoder, with_output):", "\n", "        ", "super", "(", "XLMModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "# encoder / decoder, output layer", "\n", "self", ".", "is_encoder", "=", "config", ".", "is_encoder", "\n", "self", ".", "is_decoder", "=", "not", "config", ".", "is_encoder", "\n", "if", "self", ".", "is_decoder", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Currently XLM can only be used as an encoder\"", ")", "\n", "# self.with_output = with_output", "\n", "", "self", ".", "causal", "=", "config", ".", "causal", "\n", "\n", "# dictionary / languages", "\n", "self", ".", "n_langs", "=", "config", ".", "n_langs", "\n", "self", ".", "use_lang_emb", "=", "config", ".", "use_lang_emb", "\n", "self", ".", "n_words", "=", "config", ".", "n_words", "\n", "self", ".", "eos_index", "=", "config", ".", "eos_index", "\n", "self", ".", "pad_index", "=", "config", ".", "pad_index", "\n", "# self.dico = dico", "\n", "# self.id2lang = config.id2lang", "\n", "# self.lang2id = config.lang2id", "\n", "# assert len(self.dico) == self.n_words", "\n", "# assert len(self.id2lang) == len(self.lang2id) == self.n_langs", "\n", "\n", "# model parameters", "\n", "self", ".", "dim", "=", "config", ".", "emb_dim", "# 512 by default", "\n", "self", ".", "hidden_dim", "=", "self", ".", "dim", "*", "4", "# 2048 by default", "\n", "self", ".", "n_heads", "=", "config", ".", "n_heads", "# 8 by default", "\n", "self", ".", "n_layers", "=", "config", ".", "n_layers", "\n", "self", ".", "dropout", "=", "config", ".", "dropout", "\n", "self", ".", "attention_dropout", "=", "config", ".", "attention_dropout", "\n", "assert", "self", ".", "dim", "%", "self", ".", "n_heads", "==", "0", ",", "\"transformer dim must be a multiple of n_heads\"", "\n", "\n", "# embeddings", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "self", ".", "dim", ")", "\n", "if", "config", ".", "sinusoidal_embeddings", ":", "\n", "            ", "create_sinusoidal_embeddings", "(", "config", ".", "max_position_embeddings", ",", "self", ".", "dim", ",", "out", "=", "self", ".", "position_embeddings", ".", "weight", ")", "\n", "", "if", "config", ".", "n_langs", ">", "1", "and", "config", ".", "use_lang_emb", ":", "\n", "            ", "self", ".", "lang_embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "n_langs", ",", "self", ".", "dim", ")", "\n", "", "self", ".", "embeddings", "=", "nn", ".", "Embedding", "(", "self", ".", "n_words", ",", "self", ".", "dim", ",", "padding_idx", "=", "self", ".", "pad_index", ")", "\n", "self", ".", "layer_norm_emb", "=", "nn", ".", "LayerNorm", "(", "self", ".", "dim", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "# transformer layers", "\n", "self", ".", "attentions", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "layer_norm1", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "ffns", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "layer_norm2", "=", "nn", ".", "ModuleList", "(", ")", "\n", "# if self.is_decoder:", "\n", "#     self.layer_norm15 = nn.ModuleList()", "\n", "#     self.encoder_attn = nn.ModuleList()", "\n", "\n", "for", "_", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "            ", "self", ".", "attentions", ".", "append", "(", "MultiHeadAttention", "(", "self", ".", "n_heads", ",", "self", ".", "dim", ",", "config", "=", "config", ")", ")", "\n", "self", ".", "layer_norm1", ".", "append", "(", "nn", ".", "LayerNorm", "(", "self", ".", "dim", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", ")", "\n", "# if self.is_decoder:", "\n", "#     self.layer_norm15.append(nn.LayerNorm(self.dim, eps=config.layer_norm_eps))", "\n", "#     self.encoder_attn.append(MultiHeadAttention(self.n_heads, self.dim, dropout=self.attention_dropout))", "\n", "self", ".", "ffns", ".", "append", "(", "TransformerFFN", "(", "self", ".", "dim", ",", "self", ".", "hidden_dim", ",", "self", ".", "dim", ",", "config", "=", "config", ")", ")", "\n", "self", ".", "layer_norm2", ".", "append", "(", "nn", ".", "LayerNorm", "(", "self", ".", "dim", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", ")", "\n", "\n", "", "if", "hasattr", "(", "config", ",", "\"pruned_heads\"", ")", ":", "\n", "            ", "pruned_heads", "=", "config", ".", "pruned_heads", ".", "copy", "(", ")", ".", "items", "(", ")", "\n", "config", ".", "pruned_heads", "=", "{", "}", "\n", "for", "layer", ",", "heads", "in", "pruned_heads", ":", "\n", "                ", "if", "self", ".", "attentions", "[", "int", "(", "layer", ")", "]", ".", "n_heads", "==", "config", ".", "n_heads", ":", "\n", "                    ", "self", ".", "prune_heads", "(", "{", "int", "(", "layer", ")", ":", "list", "(", "map", "(", "int", ",", "heads", ")", ")", "}", ")", "\n", "\n", "", "", "", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMModel.get_input_embeddings": [[426, 428], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMModel.set_input_embeddings": [[429, 431], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "embeddings", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMModel._prune_heads": [[432, 439], ["heads_to_prune.items", "modeling_xlm.XLMModel.attentions[].prune_heads"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "attentions", "[", "layer", "]", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMModel.forward": [[440, 580], ["modeling_xlm.get_masks", "modeling_xlm.XLMModel.layer_norm_emb", "torch.nn.functional.dropout", "mask.unsqueeze().to", "range", "input_ids.size", "torch.LongTensor.size", "torch.LongTensor.max().item", "torch.arange", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "modeling_xlm.XLMModel.embeddings", "modeling_xlm.XLMModel.position_embeddings().expand_as", "torch.nn.functional.dropout", "mask.unsqueeze().to", "torch.nn.functional.dropout.size", "modeling_xlm.XLMModel.size", "torch.LongTensor", "position_ids.unsqueeze().expand.unsqueeze().expand.size", "langs.size", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "modeling_xlm.XLMModel.lang_embeddings", "modeling_xlm.XLMModel.embeddings", "mask.unsqueeze", "torch.LongTensor.max", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_xlm.XLMModel.position_embeddings", "mask.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_xlm.XLMModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.get_masks"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "langs", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "lengths", "=", "None", ",", "\n", "cache", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", ")", ":", "# removed: src_enc=None, src_len=None", "\n", "        ", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "bs", ",", "slen", "=", "input_ids", ".", "size", "(", ")", "\n", "", "else", ":", "\n", "            ", "bs", ",", "slen", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "if", "lengths", "is", "None", ":", "\n", "            ", "if", "input_ids", "is", "not", "None", ":", "\n", "                ", "lengths", "=", "(", "input_ids", "!=", "self", ".", "pad_index", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                ", "lengths", "=", "torch", ".", "LongTensor", "(", "[", "slen", "]", "*", "bs", ")", "\n", "# mask = input_ids != self.pad_index", "\n", "\n", "# check inputs", "\n", "", "", "assert", "lengths", ".", "size", "(", "0", ")", "==", "bs", "\n", "assert", "lengths", ".", "max", "(", ")", ".", "item", "(", ")", "<=", "slen", "\n", "# input_ids = input_ids.transpose(0, 1)  # batch size as dimension 0", "\n", "# assert (src_enc is None) == (src_len is None)", "\n", "# if src_enc is not None:", "\n", "#     assert self.is_decoder", "\n", "#     assert src_enc.size(0) == bs", "\n", "\n", "# generate masks", "\n", "mask", ",", "attn_mask", "=", "get_masks", "(", "slen", ",", "lengths", ",", "self", ".", "causal", ",", "padding_mask", "=", "attention_mask", ")", "\n", "# if self.is_decoder and src_enc is not None:", "\n", "#     src_mask = torch.arange(src_len.max(), dtype=torch.long, device=lengths.device) < src_len[:, None]", "\n", "\n", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "# position_ids", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "slen", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "(", "bs", ",", "slen", ")", ")", "\n", "", "else", ":", "\n", "            ", "assert", "position_ids", ".", "size", "(", ")", "==", "(", "bs", ",", "slen", ")", "# (slen, bs)", "\n", "# position_ids = position_ids.transpose(0, 1)", "\n", "\n", "# langs", "\n", "", "if", "langs", "is", "not", "None", ":", "\n", "            ", "assert", "langs", ".", "size", "(", ")", "==", "(", "bs", ",", "slen", ")", "# (slen, bs)", "\n", "# langs = langs.transpose(0, 1)", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x qlen x klen]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "n_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layers", "\n", "\n", "# do not recompute cached elements", "\n", "", "if", "cache", "is", "not", "None", "and", "input_ids", "is", "not", "None", ":", "\n", "            ", "_slen", "=", "slen", "-", "cache", "[", "\"slen\"", "]", "\n", "input_ids", "=", "input_ids", "[", ":", ",", "-", "_slen", ":", "]", "\n", "position_ids", "=", "position_ids", "[", ":", ",", "-", "_slen", ":", "]", "\n", "if", "langs", "is", "not", "None", ":", "\n", "                ", "langs", "=", "langs", "[", ":", ",", "-", "_slen", ":", "]", "\n", "", "mask", "=", "mask", "[", ":", ",", "-", "_slen", ":", "]", "\n", "attn_mask", "=", "attn_mask", "[", ":", ",", "-", "_slen", ":", "]", "\n", "\n", "# embeddings", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "embeddings", "(", "input_ids", ")", "\n", "\n", "", "tensor", "=", "inputs_embeds", "+", "self", ".", "position_embeddings", "(", "position_ids", ")", ".", "expand_as", "(", "inputs_embeds", ")", "\n", "if", "langs", "is", "not", "None", "and", "self", ".", "use_lang_emb", ":", "\n", "            ", "tensor", "=", "tensor", "+", "self", ".", "lang_embeddings", "(", "langs", ")", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "tensor", "=", "tensor", "+", "self", ".", "embeddings", "(", "token_type_ids", ")", "\n", "", "tensor", "=", "self", ".", "layer_norm_emb", "(", "tensor", ")", "\n", "tensor", "=", "F", ".", "dropout", "(", "tensor", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "tensor", "*=", "mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "to", "(", "tensor", ".", "dtype", ")", "\n", "\n", "# transformer layers", "\n", "hidden_states", "=", "(", ")", "\n", "attentions", "=", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "n_layers", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "hidden_states", "=", "hidden_states", "+", "(", "tensor", ",", ")", "\n", "\n", "# self attention", "\n", "", "attn_outputs", "=", "self", ".", "attentions", "[", "i", "]", "(", "tensor", ",", "attn_mask", ",", "cache", "=", "cache", ",", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "attn", "=", "attn_outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attentions", "=", "attentions", "+", "(", "attn_outputs", "[", "1", "]", ",", ")", "\n", "", "attn", "=", "F", ".", "dropout", "(", "attn", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "tensor", "=", "tensor", "+", "attn", "\n", "tensor", "=", "self", ".", "layer_norm1", "[", "i", "]", "(", "tensor", ")", "\n", "\n", "# encoder attention (for decoder only)", "\n", "# if self.is_decoder and src_enc is not None:", "\n", "#     attn = self.encoder_attn[i](tensor, src_mask, kv=src_enc, cache=cache)", "\n", "#     attn = F.dropout(attn, p=self.dropout, training=self.training)", "\n", "#     tensor = tensor + attn", "\n", "#     tensor = self.layer_norm15[i](tensor)", "\n", "\n", "# FFN", "\n", "tensor", "=", "tensor", "+", "self", ".", "ffns", "[", "i", "]", "(", "tensor", ")", "\n", "tensor", "=", "self", ".", "layer_norm2", "[", "i", "]", "(", "tensor", ")", "\n", "tensor", "*=", "mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "to", "(", "tensor", ".", "dtype", ")", "\n", "\n", "# Add last hidden state", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "hidden_states", "=", "hidden_states", "+", "(", "tensor", ",", ")", "\n", "\n", "# update cache length", "\n", "", "if", "cache", "is", "not", "None", ":", "\n", "            ", "cache", "[", "\"slen\"", "]", "+=", "tensor", ".", "size", "(", "1", ")", "\n", "\n", "# move back sequence length to dimension 0", "\n", "# tensor = tensor.transpose(0, 1)", "\n", "\n", "", "outputs", "=", "(", "tensor", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attentions", ",", ")", "\n", "", "return", "outputs", "# outputs, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMPredLayer.__init__": [[587, 603], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.AdaptiveLogSoftmaxWithLoss"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLMPredLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "asm", "=", "config", ".", "asm", "\n", "self", ".", "n_words", "=", "config", ".", "n_words", "\n", "self", ".", "pad_index", "=", "config", ".", "pad_index", "\n", "dim", "=", "config", ".", "emb_dim", "\n", "\n", "if", "config", ".", "asm", "is", "False", ":", "\n", "            ", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "dim", ",", "config", ".", "n_words", ",", "bias", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "proj", "=", "nn", ".", "AdaptiveLogSoftmaxWithLoss", "(", "\n", "in_features", "=", "dim", ",", "\n", "n_classes", "=", "config", ".", "n_words", ",", "\n", "cutoffs", "=", "config", ".", "asm_cutoffs", ",", "\n", "div_value", "=", "config", ".", "asm_div_value", ",", "\n", "head_bias", "=", "True", ",", "# default is False", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMPredLayer.forward": [[605, 623], ["modeling_xlm.XLMPredLayer.proj", "modeling_xlm.XLMPredLayer.proj.log_prob", "torch.nn.functional.cross_entropy", "modeling_xlm.XLMPredLayer.proj", "modeling_xlm.XLMPredLayer.view", "y.view"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_transfo_xl_utilities.ProjectedAdaptiveLogSoftmax.log_prob"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "y", "=", "None", ")", ":", "\n", "        ", "\"\"\" Compute the loss, and optionally the scores.\n        \"\"\"", "\n", "outputs", "=", "(", ")", "\n", "if", "self", ".", "asm", "is", "False", ":", "\n", "            ", "scores", "=", "self", ".", "proj", "(", "x", ")", "\n", "outputs", "=", "(", "scores", ",", ")", "+", "outputs", "\n", "if", "y", "is", "not", "None", ":", "\n", "                ", "loss", "=", "F", ".", "cross_entropy", "(", "scores", ".", "view", "(", "-", "1", ",", "self", ".", "n_words", ")", ",", "y", ".", "view", "(", "-", "1", ")", ",", "reduction", "=", "\"elementwise_mean\"", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "", "else", ":", "\n", "            ", "scores", "=", "self", ".", "proj", ".", "log_prob", "(", "x", ")", "\n", "outputs", "=", "(", "scores", ",", ")", "+", "outputs", "\n", "if", "y", "is", "not", "None", ":", "\n", "                ", "_", ",", "loss", "=", "self", ".", "proj", "(", "x", ",", "y", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMWithLMHeadModel.__init__": [[663, 669], ["modeling_xlm.XLMPreTrainedModel.__init__", "modeling_xlm.XLMModel", "modeling_xlm.XLMPredLayer", "modeling_xlm.XLMWithLMHeadModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLMWithLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "XLMModel", "(", "config", ")", "\n", "self", ".", "pred_layer", "=", "XLMPredLayer", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMWithLMHeadModel.get_output_embeddings": [[670, 672], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "pred_layer", ".", "proj", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMWithLMHeadModel.prepare_inputs_for_generation": [[673, 684], ["torch.full", "torch.cat", "torch.full_like"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "**", "kwargs", ")", ":", "\n", "        ", "mask_token_id", "=", "self", ".", "config", ".", "mask_token_id", "\n", "lang_id", "=", "self", ".", "config", ".", "lang_id", "\n", "\n", "mask_token", "=", "torch", ".", "full", "(", "(", "1", ",", "1", ")", ",", "mask_token_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", ",", "mask_token", "]", ",", "dim", "=", "1", ")", "\n", "if", "lang_id", "is", "not", "None", ":", "\n", "            ", "langs", "=", "torch", ".", "full_like", "(", "input_ids", ",", "lang_id", ")", "\n", "", "else", ":", "\n", "            ", "langs", "=", "None", "\n", "", "return", "{", "\"input_ids\"", ":", "input_ids", ",", "\"langs\"", ":", "langs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMWithLMHeadModel.forward": [[685, 715], ["modeling_xlm.XLMWithLMHeadModel.transformer", "modeling_xlm.XLMWithLMHeadModel.pred_layer"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "langs", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "lengths", "=", "None", ",", "\n", "cache", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "langs", "=", "langs", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "lengths", "=", "lengths", ",", "\n", "cache", "=", "cache", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "outputs", "=", "self", ".", "pred_layer", "(", "output", ",", "labels", ")", "\n", "outputs", "=", "outputs", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep new_mems and attention/hidden states if they are here", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMForSequenceClassification.__init__": [[755, 763], ["modeling_xlm.XLMPreTrainedModel.__init__", "modeling_xlm.XLMModel", "modeling_utils.SequenceSummary", "modeling_xlm.XLMForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLMForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "XLMModel", "(", "config", ")", "\n", "self", ".", "sequence_summary", "=", "SequenceSummary", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMForSequenceClassification.forward": [[764, 805], ["modeling_xlm.XLMForSequenceClassification.transformer", "modeling_xlm.XLMForSequenceClassification.sequence_summary", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_xlm.XLMForSequenceClassification.view", "labels.view", "modeling_xlm.XLMForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "langs", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "lengths", "=", "None", ",", "\n", "cache", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "langs", "=", "langs", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "lengths", "=", "lengths", ",", "\n", "cache", "=", "cache", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "logits", "=", "self", ".", "sequence_summary", "(", "output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep new_mems and attention/hidden states if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMForQuestionAnsweringSimple.__init__": [[857, 864], ["modeling_xlm.XLMPreTrainedModel.__init__", "modeling_xlm.XLMModel", "torch.nn.Linear", "modeling_xlm.XLMForQuestionAnsweringSimple.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLMForQuestionAnsweringSimple", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "transformer", "=", "XLMModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMForQuestionAnsweringSimple.forward": [[865, 922], ["modeling_xlm.XLMForQuestionAnsweringSimple.transformer", "modeling_xlm.XLMForQuestionAnsweringSimple.qa_outputs", "modeling_xlm.XLMForQuestionAnsweringSimple.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "langs", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "lengths", "=", "None", ",", "\n", "cache", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "\n", "end_positions", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "langs", "=", "langs", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "lengths", "=", "lengths", ",", "\n", "cache", "=", "cache", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "\n", "start_logits", ",", "\n", "end_logits", ",", "\n", ")", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "outputs", "=", "outputs", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep new_mems and attention/hidden states if they are here", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMForQuestionAnswering.__init__": [[974, 981], ["modeling_xlm.XLMPreTrainedModel.__init__", "modeling_xlm.XLMModel", "modeling_utils.SQuADHead", "modeling_xlm.XLMForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLMForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "transformer", "=", "XLMModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "SQuADHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.XLMForQuestionAnswering.forward": [[982, 1025], ["modeling_xlm.XLMForQuestionAnswering.transformer", "modeling_xlm.XLMForQuestionAnswering.qa_outputs"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "langs", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "lengths", "=", "None", ",", "\n", "cache", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "\n", "end_positions", "=", "None", ",", "\n", "is_impossible", "=", "None", ",", "\n", "cls_index", "=", "None", ",", "\n", "p_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "langs", "=", "langs", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "lengths", "=", "lengths", ",", "\n", "cache", "=", "cache", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "outputs", "=", "self", ".", "qa_outputs", "(", "\n", "output", ",", "\n", "start_positions", "=", "start_positions", ",", "\n", "end_positions", "=", "end_positions", ",", "\n", "cls_index", "=", "cls_index", ",", "\n", "is_impossible", "=", "is_impossible", ",", "\n", "p_mask", "=", "p_mask", ",", "\n", ")", "\n", "\n", "outputs", "=", "outputs", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep new_mems and attention/hidden states if they are here", "\n", "\n", "return", "outputs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.create_sinusoidal_embeddings": [[50, 56], ["numpy.array", "torch.FloatTensor", "torch.FloatTensor", "out.detach_", "numpy.sin", "numpy.cos", "range", "numpy.power", "range"], "function", ["None"], ["def", "create_sinusoidal_embeddings", "(", "n_pos", ",", "dim", ",", "out", ")", ":", "\n", "    ", "position_enc", "=", "np", ".", "array", "(", "[", "[", "pos", "/", "np", ".", "power", "(", "10000", ",", "2", "*", "(", "j", "//", "2", ")", "/", "dim", ")", "for", "j", "in", "range", "(", "dim", ")", "]", "for", "pos", "in", "range", "(", "n_pos", ")", "]", ")", "\n", "out", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "FloatTensor", "(", "np", ".", "sin", "(", "position_enc", "[", ":", ",", "0", ":", ":", "2", "]", ")", ")", "\n", "out", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "FloatTensor", "(", "np", ".", "cos", "(", "position_enc", "[", ":", ",", "1", ":", ":", "2", "]", ")", ")", "\n", "out", ".", "detach_", "(", ")", "\n", "out", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.gelu": [[58, 67], ["torch.erf", "math.sqrt"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    GELU activation\n    https://arxiv.org/abs/1606.08415\n    https://github.com/huggingface/pytorch-openai-transformer-lm/blob/master/model_pytorch.py#L14\n    https://github.com/huggingface/transformers/blob/master/modeling.py\n    \"\"\"", "\n", "# return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))", "\n", "return", "0.5", "*", "x", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_xlm.get_masks": [[69, 92], ["torch.arange", "lengths.size", "mask.size", "lengths.max().item", "alen[].repeat", "attn_mask.size", "lengths.max"], "function", ["None"], ["", "def", "get_masks", "(", "slen", ",", "lengths", ",", "causal", ",", "padding_mask", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Generate hidden states mask, and optionally an attention mask.\n    \"\"\"", "\n", "alen", "=", "torch", ".", "arange", "(", "slen", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "lengths", ".", "device", ")", "\n", "if", "padding_mask", "is", "not", "None", ":", "\n", "        ", "mask", "=", "padding_mask", "\n", "", "else", ":", "\n", "        ", "assert", "lengths", ".", "max", "(", ")", ".", "item", "(", ")", "<=", "slen", "\n", "mask", "=", "alen", "<", "lengths", "[", ":", ",", "None", "]", "\n", "\n", "# attention mask is the same as mask, or triangular inferior attention (causal)", "\n", "", "bs", "=", "lengths", ".", "size", "(", "0", ")", "\n", "if", "causal", ":", "\n", "        ", "attn_mask", "=", "alen", "[", "None", ",", "None", ",", ":", "]", ".", "repeat", "(", "bs", ",", "slen", ",", "1", ")", "<=", "alen", "[", "None", ",", ":", ",", "None", "]", "\n", "", "else", ":", "\n", "        ", "attn_mask", "=", "mask", "\n", "\n", "# sanity check", "\n", "", "assert", "mask", ".", "size", "(", ")", "==", "(", "bs", ",", "slen", ")", "\n", "assert", "causal", "is", "False", "or", "attn_mask", ".", "size", "(", ")", "==", "(", "bs", ",", "slen", ",", "slen", ")", "\n", "\n", "return", "mask", ",", "attn_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_xlm_original_pytorch_checkpoint_to_pytorch.convert_xlm_checkpoint_to_pytorch": [[32, 67], ["torch.load", "state_dict.items", "dict", "dict", "print", "torch.save", "print", "print", "open", "f.write", "open", "f.write", "dict.items", "dict.items", "json.dumps", "json.dumps", "isinstance", "s.replace", "s.find"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save"], ["def", "convert_xlm_checkpoint_to_pytorch", "(", "xlm_checkpoint_path", ",", "pytorch_dump_folder_path", ")", ":", "\n", "# Load checkpoint", "\n", "    ", "chkpt", "=", "torch", ".", "load", "(", "xlm_checkpoint_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "\n", "state_dict", "=", "chkpt", "[", "\"model\"", "]", "\n", "\n", "# We have the base model one level deeper than the original XLM repository", "\n", "two_levels_state_dict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "if", "\"pred_layer\"", "in", "k", ":", "\n", "            ", "two_levels_state_dict", "[", "k", "]", "=", "v", "\n", "", "else", ":", "\n", "            ", "two_levels_state_dict", "[", "\"transformer.\"", "+", "k", "]", "=", "v", "\n", "\n", "", "", "config", "=", "chkpt", "[", "\"params\"", "]", "\n", "config", "=", "dict", "(", "(", "n", ",", "v", ")", "for", "n", ",", "v", "in", "config", ".", "items", "(", ")", "if", "not", "isinstance", "(", "v", ",", "(", "torch", ".", "FloatTensor", ",", "numpy", ".", "ndarray", ")", ")", ")", "\n", "\n", "vocab", "=", "chkpt", "[", "\"dico_word2id\"", "]", "\n", "vocab", "=", "dict", "(", "(", "s", "+", "\"</w>\"", "if", "s", ".", "find", "(", "\"@@\"", ")", "==", "-", "1", "and", "i", ">", "13", "else", "s", ".", "replace", "(", "\"@@\"", ",", "\"\"", ")", ",", "i", ")", "for", "s", ",", "i", "in", "vocab", ".", "items", "(", ")", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "pytorch_dump_folder_path", "+", "\"/\"", "+", "WEIGHTS_NAME", "\n", "pytorch_config_dump_path", "=", "pytorch_dump_folder_path", "+", "\"/\"", "+", "CONFIG_NAME", "\n", "pytorch_vocab_dump_path", "=", "pytorch_dump_folder_path", "+", "\"/\"", "+", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", "\n", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_weights_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "two_levels_state_dict", ",", "pytorch_weights_dump_path", ")", "\n", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "config", ",", "indent", "=", "2", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "print", "(", "\"Save vocab file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_vocab_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json", ".", "dumps", "(", "vocab", ",", "indent", "=", "2", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.__init__": [[50, 91], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "dict", "kwargs.pop", "dict", "kwargs.items", "dict", "zip", "setattr", "range", "int", "configuration_utils.PretrainedConfig.id2label.items", "configuration_utils.PretrainedConfig.id2label.values", "configuration_utils.PretrainedConfig.id2label.keys", "int", "configuration_utils.PretrainedConfig.label2id.items", "logger.error"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "# Attributes with defaults", "\n", "        ", "self", ".", "output_attentions", "=", "kwargs", ".", "pop", "(", "\"output_attentions\"", ",", "False", ")", "\n", "self", ".", "output_hidden_states", "=", "kwargs", ".", "pop", "(", "\"output_hidden_states\"", ",", "False", ")", "\n", "self", ".", "output_past", "=", "kwargs", ".", "pop", "(", "\"output_past\"", ",", "True", ")", "# Not used by all models", "\n", "self", ".", "torchscript", "=", "kwargs", ".", "pop", "(", "\"torchscript\"", ",", "False", ")", "# Only used by PyTorch models", "\n", "self", ".", "use_bfloat16", "=", "kwargs", ".", "pop", "(", "\"use_bfloat16\"", ",", "False", ")", "\n", "self", ".", "pruned_heads", "=", "kwargs", ".", "pop", "(", "\"pruned_heads\"", ",", "{", "}", ")", "\n", "\n", "# Is decoder is used in encoder-decoder models to differentiate encoder from decoder", "\n", "self", ".", "is_decoder", "=", "kwargs", ".", "pop", "(", "\"is_decoder\"", ",", "False", ")", "\n", "\n", "# Parameters for sequence generation", "\n", "self", ".", "max_length", "=", "kwargs", ".", "pop", "(", "\"max_length\"", ",", "20", ")", "\n", "self", ".", "do_sample", "=", "kwargs", ".", "pop", "(", "\"do_sample\"", ",", "False", ")", "\n", "self", ".", "num_beams", "=", "kwargs", ".", "pop", "(", "\"num_beams\"", ",", "1", ")", "\n", "self", ".", "temperature", "=", "kwargs", ".", "pop", "(", "\"temperature\"", ",", "1.0", ")", "\n", "self", ".", "top_k", "=", "kwargs", ".", "pop", "(", "\"top_k\"", ",", "50", ")", "\n", "self", ".", "top_p", "=", "kwargs", ".", "pop", "(", "\"top_p\"", ",", "1.0", ")", "\n", "self", ".", "repetition_penalty", "=", "kwargs", ".", "pop", "(", "\"repetition_penalty\"", ",", "1.0", ")", "\n", "self", ".", "bos_token_id", "=", "kwargs", ".", "pop", "(", "\"bos_token_id\"", ",", "0", ")", "\n", "self", ".", "pad_token_id", "=", "kwargs", ".", "pop", "(", "\"pad_token_id\"", ",", "0", ")", "\n", "self", ".", "eos_token_ids", "=", "kwargs", ".", "pop", "(", "\"eos_token_ids\"", ",", "0", ")", "\n", "self", ".", "length_penalty", "=", "kwargs", ".", "pop", "(", "\"length_penalty\"", ",", "1.0", ")", "\n", "self", ".", "num_return_sequences", "=", "kwargs", ".", "pop", "(", "\"num_return_sequences\"", ",", "1", ")", "\n", "\n", "# Fine-tuning task arguments", "\n", "self", ".", "finetuning_task", "=", "kwargs", ".", "pop", "(", "\"finetuning_task\"", ",", "None", ")", "\n", "self", ".", "num_labels", "=", "kwargs", ".", "pop", "(", "\"num_labels\"", ",", "2", ")", "\n", "self", ".", "id2label", "=", "kwargs", ".", "pop", "(", "\"id2label\"", ",", "{", "i", ":", "\"LABEL_{}\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "self", ".", "num_labels", ")", "}", ")", "\n", "self", ".", "id2label", "=", "dict", "(", "(", "int", "(", "key", ")", ",", "value", ")", "for", "key", ",", "value", "in", "self", ".", "id2label", ".", "items", "(", ")", ")", "\n", "self", ".", "label2id", "=", "kwargs", ".", "pop", "(", "\"label2id\"", ",", "dict", "(", "zip", "(", "self", ".", "id2label", ".", "values", "(", ")", ",", "self", ".", "id2label", ".", "keys", "(", ")", ")", ")", ")", "\n", "self", ".", "label2id", "=", "dict", "(", "(", "key", ",", "int", "(", "value", ")", ")", "for", "key", ",", "value", "in", "self", ".", "label2id", ".", "items", "(", ")", ")", "\n", "\n", "# Additional attributes without default values", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "", "except", "AttributeError", "as", "err", ":", "\n", "                ", "logger", ".", "error", "(", "\"Can't set {} with value {} for {}\"", ".", "format", "(", "key", ",", "value", ",", "self", ")", ")", "\n", "raise", "err", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained": [[92, 105], ["os.path.isdir", "os.path.join", "configuration_utils.PretrainedConfig.to_json_file", "logger.info"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.to_json_file"], ["", "", "", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a configuration object to the directory `save_directory`, so that it\n            can be re-loaded using the :func:`~transformers.PretrainedConfig.from_pretrained` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "\n", "save_directory", "\n", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "CONFIG_NAME", ")", "\n", "\n", "self", ".", "to_json_file", "(", "output_config_file", ")", "\n", "logger", ".", "info", "(", "\"Configuration saved in {}\"", ".", "format", "(", "output_config_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_pretrained": [[106, 232], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "hasattr", "kwargs.items", "logger.info", "os.path.isdir", "file_utils.cached_path", "cls.from_json_file", "logger.info", "logger.info", "dict", "hasattr", "kwargs.pop", "str", "os.path.join", "EnvironmentError", "EnvironmentError", "setattr", "to_remove.append", "os.path.isfile", "file_utils.is_remote_url", "file_utils.hf_bucket_url", "int", "cls.from_json_file.pruned_heads.items", "cls.pretrained_config_archive_map.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_remote_url", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.hf_bucket_url"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiate a :class:`~transformers.PretrainedConfig` (or a derived class) from a pre-trained model configuration.\n\n        Parameters:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model configuration to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model configuration that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing a configuration file saved using the :func:`~transformers.PretrainedConfig.save_pretrained` method, e.g.: ``./my_model_directory/``.\n                - a path or url to a saved configuration JSON `file`, e.g.: ``./my_model_directory/configuration.json``.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            kwargs: (`optional`) dict: key/value pairs with which to update the configuration object after loading.\n\n                - The values in kwargs of any keys which are configuration attributes will be used to override the loaded values.\n                - Behavior concerning key/value pairs whose keys are *not* configuration attributes is controlled by the `return_unused_kwargs` keyword parameter.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            return_unused_kwargs: (`optional`) bool:\n\n                - If False, then this function returns just the final configuration object.\n                - If True, then this functions returns a tuple `(config, unused_kwargs)` where `unused_kwargs` is a dictionary consisting of the key/value pairs whose keys are not configuration attributes: ie the part of kwargs which has not been used to update `config` and is otherwise ignored.\n\n        Examples::\n\n            # We can't instantiate directly the base class `PretrainedConfig` so let's show the examples on a\n            # derived class: BertConfig\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            config = BertConfig.from_pretrained('./test/saved_model/')  # E.g. config (or model) was saved using `save_pretrained('./test/saved_model/')`\n            config = BertConfig.from_pretrained('./test/saved_model/my_configuration.json')\n            config = BertConfig.from_pretrained('bert-base-uncased', output_attention=True, foo=False)\n            assert config.output_attention == True\n            config, unused_kwargs = BertConfig.from_pretrained('bert-base-uncased', output_attention=True,\n                                                               foo=False, return_unused_kwargs=True)\n            assert config.output_attention == True\n            assert unused_kwargs == {'foo': False}\n\n        \"\"\"", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "\"cache_dir\"", ",", "None", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "\"force_download\"", ",", "False", ")", "\n", "resume_download", "=", "kwargs", ".", "pop", "(", "\"resume_download\"", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "\"proxies\"", ",", "None", ")", "\n", "return_unused_kwargs", "=", "kwargs", ".", "pop", "(", "\"return_unused_kwargs\"", ",", "False", ")", "\n", "\n", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_config_archive_map", ":", "\n", "            ", "config_file", "=", "cls", ".", "pretrained_config_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "config_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CONFIG_NAME", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", ")", "or", "is_remote_url", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "config_file", "=", "pretrained_model_name_or_path", "\n", "", "else", ":", "\n", "            ", "config_file", "=", "hf_bucket_url", "(", "pretrained_model_name_or_path", ",", "postfix", "=", "CONFIG_NAME", ")", "\n", "\n", "", "try", ":", "\n", "# Load from URL or cache if already cached", "\n", "            ", "resolved_config_file", "=", "cached_path", "(", "\n", "config_file", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "force_download", "=", "force_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", ")", "\n", "# Load config", "\n", "config", "=", "cls", ".", "from_json_file", "(", "resolved_config_file", ")", "\n", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_config_archive_map", ":", "\n", "                ", "msg", "=", "\"Couldn't reach server at '{}' to download pretrained model configuration file.\"", ".", "format", "(", "\n", "config_file", "\n", ")", "\n", "", "else", ":", "\n", "                ", "msg", "=", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url to a configuration file named {} or \"", "\n", "\"a directory containing such a file but couldn't find any such file at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "\", \"", ".", "join", "(", "cls", ".", "pretrained_config_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "config_file", ",", "\n", "CONFIG_NAME", ",", "\n", ")", "\n", ")", "\n", "", "raise", "EnvironmentError", "(", "msg", ")", "\n", "\n", "", "except", "json", ".", "JSONDecodeError", ":", "\n", "            ", "msg", "=", "(", "\n", "\"Couldn't reach server at '{}' to download configuration file or \"", "\n", "\"configuration file is not a valid JSON file. \"", "\n", "\"Please check network or file content here: {}.\"", ".", "format", "(", "config_file", ",", "resolved_config_file", ")", "\n", ")", "\n", "raise", "EnvironmentError", "(", "msg", ")", "\n", "\n", "", "if", "resolved_config_file", "==", "config_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading configuration file {}\"", ".", "format", "(", "config_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading configuration file {} from cache at {}\"", ".", "format", "(", "config_file", ",", "resolved_config_file", ")", ")", "\n", "\n", "", "if", "hasattr", "(", "config", ",", "\"pruned_heads\"", ")", ":", "\n", "            ", "config", ".", "pruned_heads", "=", "dict", "(", "(", "int", "(", "key", ")", ",", "value", ")", "for", "key", ",", "value", "in", "config", ".", "pruned_heads", ".", "items", "(", ")", ")", "\n", "\n", "# Update config with kwargs if needed", "\n", "", "to_remove", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "key", ")", ":", "\n", "                ", "setattr", "(", "config", ",", "key", ",", "value", ")", "\n", "to_remove", ".", "append", "(", "key", ")", "\n", "", "", "for", "key", "in", "to_remove", ":", "\n", "            ", "kwargs", ".", "pop", "(", "key", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Model config %s\"", ",", "str", "(", "config", ")", ")", "\n", "if", "return_unused_kwargs", ":", "\n", "            ", "return", "config", ",", "kwargs", "\n", "", "else", ":", "\n", "            ", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_dict": [[233, 237], ["cls"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `Config` from a Python dictionary of parameters.\"\"\"", "\n", "return", "cls", "(", "**", "json_object", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_json_file": [[238, 245], ["json.loads", "cls", "open", "reader.read"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `Config` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "dict_obj", "=", "json", ".", "loads", "(", "text", ")", "\n", "return", "cls", "(", "**", "dict_obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.__eq__": [[246, 248], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.__repr__": [[249, 251], ["str", "configuration_utils.PretrainedConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.to_dict": [[252, 256], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.to_json_string": [[257, 260], ["json.dumps", "configuration_utils.PretrainedConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.to_json_file": [[261, 265], ["open", "writer.write", "configuration_utils.PretrainedConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_json_string"], ["", "def", "to_json_file", "(", "self", ",", "json_file_path", ")", ":", "\n", "        ", "\"\"\" Save this instance to a json file.\"\"\"", "\n", "with", "open", "(", "json_file_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.MultiHeadAttention.__init__": [[83, 96], ["super().__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model_size", ",", "num_heads", ",", "output_attentions", "=", "False", ")", ":", "\n", "        ", "super", "(", "MultiHeadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "output_attentions", "\n", "self", ".", "num_heads", "=", "num_heads", "\n", "self", ".", "d_model_size", "=", "d_model_size", "\n", "\n", "self", ".", "depth", "=", "int", "(", "d_model_size", "/", "self", ".", "num_heads", ")", "\n", "\n", "self", ".", "Wq", "=", "torch", ".", "nn", ".", "Linear", "(", "d_model_size", ",", "d_model_size", ")", "\n", "self", ".", "Wk", "=", "torch", ".", "nn", ".", "Linear", "(", "d_model_size", ",", "d_model_size", ")", "\n", "self", ".", "Wv", "=", "torch", ".", "nn", ".", "Linear", "(", "d_model_size", ",", "d_model_size", ")", "\n", "\n", "self", ".", "dense", "=", "torch", ".", "nn", ".", "Linear", "(", "d_model_size", ",", "d_model_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.MultiHeadAttention.split_into_heads": [[97, 100], ["x.reshape.reshape.reshape", "x.reshape.reshape.permute"], "methods", ["None"], ["", "def", "split_into_heads", "(", "self", ",", "x", ",", "batch_size", ")", ":", "\n", "        ", "x", "=", "x", ".", "reshape", "(", "batch_size", ",", "-", "1", ",", "self", ".", "num_heads", ",", "self", ".", "depth", ")", "\n", "return", "x", ".", "permute", "(", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.MultiHeadAttention.forward": [[101, 127], ["modeling_ctrl.MultiHeadAttention.Wq", "modeling_ctrl.MultiHeadAttention.Wk", "modeling_ctrl.MultiHeadAttention.Wv", "modeling_ctrl.MultiHeadAttention.split_into_heads", "modeling_ctrl.MultiHeadAttention.split_into_heads", "modeling_ctrl.MultiHeadAttention.split_into_heads", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "modeling_ctrl.scaled_dot_product_attention", "output[].permute", "output[].permute.reshape", "modeling_ctrl.MultiHeadAttention.dense", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.MultiHeadAttention.split_into_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.MultiHeadAttention.split_into_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.MultiHeadAttention.split_into_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.scaled_dot_product_attention"], ["", "def", "forward", "(", "self", ",", "v", ",", "k", ",", "q", ",", "mask", ",", "layer_past", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "q", ".", "shape", "[", "0", "]", "\n", "\n", "q", "=", "self", ".", "Wq", "(", "q", ")", "\n", "k", "=", "self", ".", "Wk", "(", "k", ")", "\n", "v", "=", "self", ".", "Wv", "(", "v", ")", "\n", "\n", "q", "=", "self", ".", "split_into_heads", "(", "q", ",", "batch_size", ")", "\n", "k", "=", "self", ".", "split_into_heads", "(", "k", ",", "batch_size", ")", "\n", "v", "=", "self", ".", "split_into_heads", "(", "v", ",", "batch_size", ")", "\n", "if", "layer_past", "is", "not", "None", ":", "\n", "            ", "past_key", ",", "past_value", "=", "layer_past", "[", "0", "]", ",", "layer_past", "[", "1", "]", "\n", "k", "=", "torch", ".", "cat", "(", "(", "past_key", ",", "k", ")", ",", "dim", "=", "-", "2", ")", "\n", "v", "=", "torch", ".", "cat", "(", "(", "past_value", ",", "v", ")", ",", "dim", "=", "-", "2", ")", "\n", "", "present", "=", "torch", ".", "stack", "(", "(", "k", ",", "v", ")", ")", "\n", "\n", "output", "=", "scaled_dot_product_attention", "(", "q", ",", "k", ",", "v", ",", "mask", ",", "attention_mask", ",", "head_mask", ")", "\n", "scaled_attention", "=", "output", "[", "0", "]", ".", "permute", "(", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "attn", "=", "output", "[", "1", "]", "\n", "original_size_attention", "=", "scaled_attention", ".", "reshape", "(", "batch_size", ",", "-", "1", ",", "self", ".", "d_model_size", ")", "\n", "output", "=", "self", ".", "dense", "(", "original_size_attention", ")", "\n", "\n", "outputs", "=", "(", "output", ",", "present", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attn", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.EncoderLayer.__init__": [[134, 145], ["super().__init__", "modeling_ctrl.MultiHeadAttention", "modeling_ctrl.point_wise_feed_forward_network", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.point_wise_feed_forward_network"], ["    ", "def", "__init__", "(", "self", ",", "d_model_size", ",", "num_heads", ",", "dff", ",", "rate", "=", "0.1", ",", "output_attentions", "=", "False", ")", ":", "\n", "        ", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "multi_head_attention", "=", "MultiHeadAttention", "(", "d_model_size", ",", "num_heads", ",", "output_attentions", ")", "\n", "self", ".", "ffn", "=", "point_wise_feed_forward_network", "(", "d_model_size", ",", "dff", ")", "\n", "\n", "self", ".", "layernorm1", "=", "torch", ".", "nn", ".", "LayerNorm", "(", "d_model_size", ",", "eps", "=", "1e-6", ")", "\n", "self", ".", "layernorm2", "=", "torch", ".", "nn", ".", "LayerNorm", "(", "d_model_size", ",", "eps", "=", "1e-6", ")", "\n", "\n", "self", ".", "dropout1", "=", "torch", ".", "nn", ".", "Dropout", "(", "rate", ")", "\n", "self", ".", "dropout2", "=", "torch", ".", "nn", ".", "Dropout", "(", "rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.EncoderLayer.forward": [[146, 162], ["modeling_ctrl.EncoderLayer.layernorm1", "modeling_ctrl.EncoderLayer.multi_head_attention", "modeling_ctrl.EncoderLayer.dropout1", "modeling_ctrl.EncoderLayer.layernorm2", "modeling_ctrl.EncoderLayer.ffn", "modeling_ctrl.EncoderLayer.dropout2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ",", "layer_past", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "normed", "=", "self", ".", "layernorm1", "(", "x", ")", "\n", "attn_outputs", "=", "self", ".", "multi_head_attention", "(", "\n", "normed", ",", "normed", ",", "normed", ",", "mask", ",", "layer_past", "=", "layer_past", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", "\n", ")", "\n", "attn_output", "=", "attn_outputs", "[", "0", "]", "\n", "attn_output", "=", "self", ".", "dropout1", "(", "attn_output", ")", "\n", "out1", "=", "x", "+", "attn_output", "\n", "\n", "out2", "=", "self", ".", "layernorm2", "(", "out1", ")", "\n", "ffn_output", "=", "self", ".", "ffn", "(", "out2", ")", "\n", "ffn_output", "=", "self", ".", "dropout2", "(", "ffn_output", ")", "\n", "out2", "=", "out1", "+", "ffn_output", "\n", "\n", "outputs", "=", "(", "out2", ",", ")", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.CTRLPreTrainedModel._init_weights": [[173, 185], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "Conv1D", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "Conv1D", ")", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.CTRLModel.__init__": [[276, 299], ["modeling_utils.PreTrainedModel.__init__", "modeling_ctrl.positional_encoding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.LayerNorm", "torch.LayerNorm", "modeling_ctrl.CTRLModel.init_weights", "modeling_ctrl.EncoderLayer", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.positional_encoding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "CTRLModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "\n", "self", ".", "d_model_size", "=", "config", ".", "n_embd", "\n", "self", ".", "num_layers", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "pos_encoding", "=", "positional_encoding", "(", "config", ".", "n_positions", ",", "self", ".", "d_model_size", ",", "torch", ".", "float", ")", "\n", "\n", "self", ".", "w", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "EncoderLayer", "(", "config", ".", "n_embd", ",", "config", ".", "n_head", ",", "config", ".", "dff", ",", "config", ".", "resid_pdrop", ",", "config", ".", "output_attentions", ")", "\n", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "\n", "]", "\n", ")", "\n", "self", ".", "layernorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "n_embd", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.CTRLModel.get_input_embeddings": [[300, 302], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "w", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.CTRLModel.set_input_embeddings": [[303, 305], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "w", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.CTRLModel._prune_heads": [[306, 312], ["heads_to_prune.items", "modeling_ctrl.CTRLModel.h[].attn.prune_heads"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n                heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "h", "[", "layer", "]", ".", "attn", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.CTRLModel.forward": [[313, 434], ["position_ids.unsqueeze().view.unsqueeze().view.view", "torch.triu().to", "torch.triu().to", "torch.triu().to", "torch.triu().to", "numpy.sqrt", "modeling_ctrl.CTRLModel.pos_encoding[].to", "modeling_ctrl.CTRLModel.dropout", "enumerate", "modeling_ctrl.CTRLModel.layernorm", "hidden_states.view.view.view", "ValueError", "[].size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze().view", "attention_mask.to.to.view", "attention_mask.to.to.unsqueeze().unsqueeze", "attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "token_type_ids.view.view.view", "modeling_ctrl.CTRLModel.w", "numpy.sqrt", "modeling_ctrl.CTRLModel.w", "zip", "h", "tuple", "input_ids.view.view.size", "input_ids.view.view.view", "len", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "modeling_ctrl.CTRLModel.size", "tuple.append", "ValueError", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze", "attention_mask.to.to.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "t.view", "modeling_ctrl.CTRLModel.size", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "hidden_states.view.view.view", "modeling_ctrl.CTRLModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_ctrl.CTRLModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "past", "is", "None", ":", "\n", "            ", "past_length", "=", "0", "\n", "past", "=", "[", "None", "]", "*", "len", "(", "self", ".", "h", ")", "\n", "", "else", ":", "\n", "            ", "past_length", "=", "past", "[", "0", "]", "[", "0", "]", ".", "size", "(", "-", "2", ")", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "position_ids", "=", "torch", ".", "arange", "(", "past_length", ",", "input_shape", "[", "-", "1", "]", "+", "past_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "# Attention mask.", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "attention_mask", "=", "attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# head_mask has shape n_layer x batch x n_heads x N x N", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "n_layer", "\n", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "token_type_embeds", "=", "self", ".", "w", "(", "token_type_ids", ")", "\n", "token_type_embeds", "*=", "np", ".", "sqrt", "(", "self", ".", "d_model_size", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "w", "(", "input_ids", ")", "\n", "# inputs_embeds = embedded.unsqueeze(0) if len(input_ids.shape)<2 else embedded", "\n", "", "seq_len", "=", "input_shape", "[", "-", "1", "]", "\n", "mask", "=", "torch", ".", "triu", "(", "torch", ".", "ones", "(", "seq_len", "+", "past_length", ",", "seq_len", "+", "past_length", ")", ",", "1", ")", ".", "to", "(", "inputs_embeds", ".", "device", ")", "\n", "\n", "inputs_embeds", "*=", "np", ".", "sqrt", "(", "self", ".", "d_model_size", ")", "\n", "\n", "pos_embeds", "=", "self", ".", "pos_encoding", "[", "position_ids", ",", ":", "]", ".", "to", "(", "inputs_embeds", ".", "device", ")", "\n", "\n", "hidden_states", "=", "inputs_embeds", "+", "pos_embeds", "+", "token_type_embeds", "\n", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "(", "inputs_embeds", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "presents", "=", "(", ")", "\n", "all_hidden_states", "=", "(", ")", "\n", "all_attentions", "=", "[", "]", "\n", "for", "i", ",", "(", "h", ",", "layer_past", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "h", ",", "past", ")", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "", "outputs", "=", "h", "(", "\n", "hidden_states", ",", "mask", ",", "layer_past", "=", "layer_past", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", "[", "i", "]", "\n", ")", "\n", "hidden_states", ",", "present", "=", "outputs", "[", ":", "2", "]", "\n", "if", "self", ".", "output_past", ":", "\n", "                ", "presents", "=", "presents", "+", "(", "present", ",", ")", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "layernorm", "(", "hidden_states", ")", "\n", "hidden_states", "=", "hidden_states", ".", "view", "(", "*", "output_shape", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_past", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "presents", ",", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# let the number of heads free (-1) so we can extract attention even after head pruning", "\n", "            ", "attention_output_shape", "=", "input_shape", "[", ":", "-", "1", "]", "+", "(", "-", "1", ",", ")", "+", "all_attentions", "[", "0", "]", ".", "shape", "[", "-", "2", ":", "]", "\n", "all_attentions", "=", "tuple", "(", "t", ".", "view", "(", "*", "attention_output_shape", ")", "for", "t", "in", "all_attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.CTRLLMHeadModel.__init__": [[483, 489], ["modeling_utils.PreTrainedModel.__init__", "modeling_ctrl.CTRLModel", "torch.Linear", "torch.Linear", "modeling_ctrl.CTRLLMHeadModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "CTRLLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "CTRLModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.CTRLLMHeadModel.get_output_embeddings": [[490, 492], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.CTRLLMHeadModel.forward": [[493, 530], ["modeling_ctrl.CTRLLMHeadModel.transformer", "modeling_ctrl.CTRLLMHeadModel.lm_head", "lm_logits[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous.view", "labels[].contiguous.view", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "past", "=", "past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Shift so that tokens < n predict n", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), lm_logits, presents, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.angle_defn": [[36, 39], ["torch.pow", "torch.pow"], "function", ["None"], ["def", "angle_defn", "(", "pos", ",", "i", ",", "d_model_size", ")", ":", "\n", "    ", "angle_rates", "=", "1", "/", "torch", ".", "pow", "(", "10000", ",", "(", "2", "*", "(", "i", "//", "2", ")", ")", "/", "d_model_size", ")", "\n", "return", "pos", "*", "angle_rates", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.positional_encoding": [[41, 54], ["modeling_ctrl.angle_defn", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cat", "torch.cat", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.float", "torch.float"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.angle_defn"], ["", "def", "positional_encoding", "(", "position", ",", "d_model_size", ",", "dtype", ")", ":", "\n", "# create the sinusoidal pattern for the positional encoding", "\n", "    ", "angle_rads", "=", "angle_defn", "(", "\n", "torch", ".", "arange", "(", "position", ",", "dtype", "=", "dtype", ")", ".", "unsqueeze", "(", "1", ")", ",", "\n", "torch", ".", "arange", "(", "d_model_size", ",", "dtype", "=", "dtype", ")", ".", "unsqueeze", "(", "0", ")", ",", "\n", "d_model_size", ",", "\n", ")", "\n", "\n", "sines", "=", "torch", ".", "sin", "(", "angle_rads", "[", ":", ",", "0", ":", ":", "2", "]", ")", "\n", "cosines", "=", "torch", ".", "cos", "(", "angle_rads", "[", ":", ",", "1", ":", ":", "2", "]", ")", "\n", "\n", "pos_encoding", "=", "torch", ".", "cat", "(", "[", "sines", ",", "cosines", "]", ",", "dim", "=", "-", "1", ")", "\n", "return", "pos_encoding", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.scaled_dot_product_attention": [[56, 80], ["torch.matmul", "torch.matmul", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "k.permute", "numpy.sqrt", "scaled_attention_logits.size", "scaled_attention_logits.size"], "function", ["None"], ["", "def", "scaled_dot_product_attention", "(", "q", ",", "k", ",", "v", ",", "mask", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "# calculate attention", "\n", "    ", "matmul_qk", "=", "torch", ".", "matmul", "(", "q", ",", "k", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "2", ")", ")", "\n", "\n", "dk", "=", "k", ".", "shape", "[", "-", "1", "]", "\n", "scaled_attention_logits", "=", "matmul_qk", "/", "np", ".", "sqrt", "(", "dk", ")", "\n", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "nd", ",", "ns", "=", "scaled_attention_logits", ".", "size", "(", "-", "2", ")", ",", "scaled_attention_logits", ".", "size", "(", "-", "1", ")", "\n", "scaled_attention_logits", "+=", "mask", "[", "ns", "-", "nd", ":", "ns", ",", ":", "ns", "]", "*", "-", "1e4", "\n", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "        ", "scaled_attention_logits", "=", "scaled_attention_logits", "+", "attention_mask", "\n", "\n", "", "attention_weights", "=", "torch", ".", "softmax", "(", "scaled_attention_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "        ", "attention_weights", "=", "attention_weights", "*", "head_mask", "\n", "\n", "", "output", "=", "torch", ".", "matmul", "(", "attention_weights", ",", "v", ")", "\n", "\n", "return", "output", ",", "attention_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_ctrl.point_wise_feed_forward_network": [[129, 131], ["torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear"], "function", ["None"], ["", "", "def", "point_wise_feed_forward_network", "(", "d_model_size", ",", "dff", ")", ":", "\n", "    ", "return", "torch", ".", "nn", ".", "Sequential", "(", "torch", ".", "nn", ".", "Linear", "(", "d_model_size", ",", "dff", ")", ",", "torch", ".", "nn", ".", "ReLU", "(", ")", ",", "torch", ".", "nn", ".", "Linear", "(", "dff", ",", "d_model_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.__init__": [[59, 77], ["super().__init__", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dropout", "ValueError"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetRelativeAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "if", "config", ".", "d_model", "%", "config", ".", "n_head", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "d_model", ",", "config", ".", "n_head", ")", "\n", ")", "\n", "\n", "", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "d_head", "=", "config", ".", "d_head", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "scale", "=", "1", "/", "(", "config", ".", "d_head", "**", "0.5", ")", "\n", "self", ".", "initializer_range", "=", "config", ".", "initializer_range", "\n", "\n", "self", ".", "layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "\"layer_norm\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.build": [[78, 108], ["modeling_tf_utils.get_initializer", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "modeling_tf_xlnet.TFXLNetRelativeAttention.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", "\n", "self", ".", "q", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "initializer", "=", "initializer", ",", "trainable", "=", "True", ",", "name", "=", "\"q\"", "\n", ")", "\n", "self", ".", "k", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "initializer", "=", "initializer", ",", "trainable", "=", "True", ",", "name", "=", "\"k\"", "\n", ")", "\n", "self", ".", "v", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "initializer", "=", "initializer", ",", "trainable", "=", "True", ",", "name", "=", "\"v\"", "\n", ")", "\n", "self", ".", "o", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "initializer", "=", "initializer", ",", "trainable", "=", "True", ",", "name", "=", "\"o\"", "\n", ")", "\n", "self", ".", "r", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "initializer", "=", "initializer", ",", "trainable", "=", "True", ",", "name", "=", "\"r\"", "\n", ")", "\n", "self", ".", "r_r_bias", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"r_r_bias\"", "\n", ")", "\n", "self", ".", "r_s_bias", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"r_s_bias\"", "\n", ")", "\n", "self", ".", "r_w_bias", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"r_w_bias\"", "\n", ")", "\n", "self", ".", "seg_embed", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "2", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ",", "initializer", "=", "initializer", ",", "trainable", "=", "True", ",", "name", "=", "\"seg_embed\"", "\n", ")", "\n", "super", "(", "TFXLNetRelativeAttention", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.prune_heads": [[109, 111], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_shift": [[112, 123], ["modeling_tf_utils.shape_list", "tensorflow.reshape", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "rel_shift", "(", "self", ",", "x", ",", "klen", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"perform relative shift to form the relative attention score.\"\"\"", "\n", "x_size", "=", "shape_list", "(", "x", ")", "\n", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "(", "x_size", "[", "1", "]", ",", "x_size", "[", "0", "]", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", ")", ")", "\n", "x", "=", "x", "[", "1", ":", ",", "...", "]", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "(", "x_size", "[", "0", "]", ",", "x_size", "[", "1", "]", "-", "1", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", ")", ")", "\n", "x", "=", "x", "[", ":", ",", "0", ":", "klen", ",", ":", ",", ":", "]", "\n", "# x = torch.index_select(x, 1, torch.arange(klen, device=x.device, dtype=torch.long))", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core": [[124, 168], ["tensorflow.einsum", "tensorflow.einsum", "modeling_tf_xlnet.TFXLNetRelativeAttention.rel_shift", "tensorflow.nn.softmax", "modeling_tf_xlnet.TFXLNetRelativeAttention.dropout", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.einsum", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_shift", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "rel_attn_core", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Core relative positional attention operations.\"\"\"", "\n", "\n", "q_head", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", ",", "attn_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "# content based attention score", "\n", "ac", "=", "tf", ".", "einsum", "(", "\"ibnd,jbnd->ijbn\"", ",", "q_head", "+", "self", ".", "r_w_bias", ",", "k_head_h", ")", "\n", "\n", "# position based attention score", "\n", "bd", "=", "tf", ".", "einsum", "(", "\"ibnd,jbnd->ijbn\"", ",", "q_head", "+", "self", ".", "r_r_bias", ",", "k_head_r", ")", "\n", "bd", "=", "self", ".", "rel_shift", "(", "bd", ",", "klen", "=", "shape_list", "(", "ac", ")", "[", "1", "]", ")", "\n", "\n", "# segment based attention score", "\n", "if", "seg_mat", "is", "None", ":", "\n", "            ", "ef", "=", "0", "\n", "", "else", ":", "\n", "            ", "ef", "=", "tf", ".", "einsum", "(", "\"ibnd,snd->ibns\"", ",", "q_head", "+", "self", ".", "r_s_bias", ",", "self", ".", "seg_embed", ")", "\n", "ef", "=", "tf", ".", "einsum", "(", "\"ijbs,ibns->ijbn\"", ",", "seg_mat", ",", "ef", ")", "\n", "\n", "# merge attention scores and perform masking", "\n", "", "attn_score", "=", "(", "ac", "+", "bd", "+", "ef", ")", "*", "self", ".", "scale", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "# attn_score = attn_score * (1 - attn_mask) - 1e30 * attn_mask", "\n", "            ", "if", "attn_mask", ".", "dtype", "==", "tf", ".", "float16", ":", "\n", "                ", "attn_score", "=", "attn_score", "-", "65500", "*", "attn_mask", "\n", "", "else", ":", "\n", "                ", "attn_score", "=", "attn_score", "-", "1e30", "*", "attn_mask", "\n", "\n", "# attention probability", "\n", "", "", "attn_prob", "=", "tf", ".", "nn", ".", "softmax", "(", "attn_score", ",", "axis", "=", "1", ")", "\n", "\n", "attn_prob", "=", "self", ".", "dropout", "(", "attn_prob", ",", "training", "=", "training", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attn_prob", "=", "attn_prob", "*", "head_mask", "\n", "\n", "# attention output", "\n", "", "attn_vec", "=", "tf", ".", "einsum", "(", "\"ijbn,jbnd->ibnd\"", ",", "attn_prob", ",", "v_head_h", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "return", "attn_vec", ",", "attn_prob", "\n", "\n", "", "return", "attn_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention": [[169, 183], ["tensorflow.einsum", "modeling_tf_xlnet.TFXLNetRelativeAttention.dropout", "modeling_tf_xlnet.TFXLNetRelativeAttention.layer_norm"], "methods", ["None"], ["", "def", "post_attention", "(", "self", ",", "inputs", ",", "residual", "=", "True", ",", "training", "=", "False", ")", ":", "\n", "        ", "\"\"\"Post-attention processing.\"\"\"", "\n", "# post-attention projection (back to `d_model`)", "\n", "h", ",", "attn_vec", "=", "inputs", "\n", "\n", "attn_out", "=", "tf", ".", "einsum", "(", "\"ibnd,hnd->ibh\"", ",", "attn_vec", ",", "self", ".", "o", ")", "\n", "\n", "attn_out", "=", "self", ".", "dropout", "(", "attn_out", ",", "training", "=", "training", ")", "\n", "\n", "if", "residual", ":", "\n", "            ", "attn_out", "=", "attn_out", "+", "h", "\n", "", "output", "=", "self", ".", "layer_norm", "(", "attn_out", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.call": [[184, 279], ["tensorflow.einsum", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.einsum", "modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "tensorflow.einsum", "modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.einsum", "tensorflow.einsum", "modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "tensorflow.concat", "tensorflow.einsum", "modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "tensorflow.einsum", "modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "tensorflow.concat", "len", "len", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "(", "h", ",", "g", ",", "attn_mask_h", ",", "attn_mask_g", ",", "r", ",", "seg_mat", ",", "mems", ",", "target_mapping", ",", "head_mask", ")", "=", "inputs", "\n", "\n", "if", "g", "is", "not", "None", ":", "\n", "# Two-stream attention with relative positional encoding.", "\n", "# content based attention score", "\n", "            ", "if", "mems", "is", "not", "None", "and", "len", "(", "shape_list", "(", "mems", ")", ")", ">", "1", ":", "\n", "                ", "cat", "=", "tf", ".", "concat", "(", "[", "mems", ",", "h", "]", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat", "=", "h", "\n", "\n", "# content-based key head", "\n", "", "k_head_h", "=", "tf", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "cat", ",", "self", ".", "k", ")", "\n", "\n", "# content-based value head", "\n", "v_head_h", "=", "tf", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "cat", ",", "self", ".", "v", ")", "\n", "\n", "# position-based key head", "\n", "k_head_r", "=", "tf", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "r", ",", "self", ".", "r", ")", "\n", "\n", "# h-stream", "\n", "# content-stream query head", "\n", "q_head_h", "=", "tf", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "h", ",", "self", ".", "q", ")", "\n", "\n", "# core attention ops", "\n", "attn_vec_h", "=", "self", ".", "rel_attn_core", "(", "\n", "[", "q_head_h", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", ",", "attn_mask_h", ",", "head_mask", "]", ",", "training", "=", "training", "\n", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_vec_h", ",", "attn_prob_h", "=", "attn_vec_h", "\n", "\n", "# post processing", "\n", "", "output_h", "=", "self", ".", "post_attention", "(", "[", "h", ",", "attn_vec_h", "]", ",", "training", "=", "training", ")", "\n", "\n", "# g-stream", "\n", "# query-stream query head", "\n", "q_head_g", "=", "tf", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "g", ",", "self", ".", "q", ")", "\n", "\n", "# core attention ops", "\n", "if", "target_mapping", "is", "not", "None", ":", "\n", "                ", "q_head_g", "=", "tf", ".", "einsum", "(", "\"mbnd,mlb->lbnd\"", ",", "q_head_g", ",", "target_mapping", ")", "\n", "attn_vec_g", "=", "self", ".", "rel_attn_core", "(", "\n", "[", "q_head_g", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", ",", "attn_mask_g", ",", "head_mask", "]", ",", "training", "=", "training", "\n", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attn_vec_g", ",", "attn_prob_g", "=", "attn_vec_g", "\n", "\n", "", "attn_vec_g", "=", "tf", ".", "einsum", "(", "\"lbnd,mlb->mbnd\"", ",", "attn_vec_g", ",", "target_mapping", ")", "\n", "", "else", ":", "\n", "                ", "attn_vec_g", "=", "self", ".", "rel_attn_core", "(", "\n", "[", "q_head_g", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", ",", "attn_mask_g", ",", "head_mask", "]", ",", "training", "=", "training", "\n", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attn_vec_g", ",", "attn_prob_g", "=", "attn_vec_g", "\n", "\n", "# post processing", "\n", "", "", "output_g", "=", "self", ".", "post_attention", "(", "[", "g", ",", "attn_vec_g", "]", ",", "training", "=", "training", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_prob", "=", "attn_prob_h", ",", "attn_prob_g", "\n", "\n", "", "", "else", ":", "\n", "# Multi-head attention with relative positional encoding", "\n", "            ", "if", "mems", "is", "not", "None", "and", "len", "(", "shape_list", "(", "mems", ")", ")", ">", "1", ":", "\n", "                ", "cat", "=", "tf", ".", "concat", "(", "[", "mems", ",", "h", "]", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat", "=", "h", "\n", "\n", "# content heads", "\n", "", "q_head_h", "=", "tf", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "h", ",", "self", ".", "q", ")", "\n", "k_head_h", "=", "tf", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "cat", ",", "self", ".", "k", ")", "\n", "v_head_h", "=", "tf", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "cat", ",", "self", ".", "v", ")", "\n", "\n", "# positional heads", "\n", "k_head_r", "=", "tf", ".", "einsum", "(", "\"ibh,hnd->ibnd\"", ",", "r", ",", "self", ".", "r", ")", "\n", "\n", "# core attention ops", "\n", "attn_vec", "=", "self", ".", "rel_attn_core", "(", "\n", "[", "q_head_h", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", ",", "attn_mask_h", ",", "head_mask", "]", ",", "training", "=", "training", "\n", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_vec", ",", "attn_prob", "=", "attn_vec", "\n", "\n", "# post processing", "\n", "", "output_h", "=", "self", ".", "post_attention", "(", "[", "h", ",", "attn_vec", "]", ",", "training", "=", "training", ")", "\n", "output_g", "=", "None", "\n", "\n", "", "outputs", "=", "(", "output_h", ",", "output_g", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attn_prob", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetFeedForward.__init__": [[282, 296], ["super().__init__", "tensorflow.keras.layers.LayerNormalization", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dense", "tensorflow.keras.layers.Dropout", "isinstance", "modeling_tf_utils.get_initializer", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetFeedForward", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "layer_norm", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_eps", ",", "name", "=", "\"layer_norm\"", ")", "\n", "self", ".", "layer_1", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "d_inner", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"layer_1\"", "\n", ")", "\n", "self", ".", "layer_2", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "d_model", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"layer_2\"", "\n", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "if", "isinstance", "(", "config", ".", "ff_activation", ",", "str", ")", ":", "\n", "            ", "self", ".", "activation_function", "=", "ACT2FN", "[", "config", ".", "ff_activation", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "activation_function", "=", "config", ".", "ff_activation", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetFeedForward.call": [[297, 306], ["modeling_tf_xlnet.TFXLNetFeedForward.layer_1", "modeling_tf_xlnet.TFXLNetFeedForward.activation_function", "modeling_tf_xlnet.TFXLNetFeedForward.dropout", "modeling_tf_xlnet.TFXLNetFeedForward.layer_2", "modeling_tf_xlnet.TFXLNetFeedForward.dropout", "modeling_tf_xlnet.TFXLNetFeedForward.layer_norm"], "methods", ["None"], ["", "", "def", "call", "(", "self", ",", "inp", ",", "training", "=", "False", ")", ":", "\n", "        ", "output", "=", "inp", "\n", "output", "=", "self", ".", "layer_1", "(", "output", ")", "\n", "output", "=", "self", ".", "activation_function", "(", "output", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ",", "training", "=", "training", ")", "\n", "output", "=", "self", ".", "layer_2", "(", "output", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ",", "training", "=", "training", ")", "\n", "output", "=", "self", ".", "layer_norm", "(", "output", "+", "inp", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetLayer.__init__": [[309, 314], ["super().__init__", "modeling_tf_xlnet.TFXLNetRelativeAttention", "modeling_tf_xlnet.TFXLNetFeedForward", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "rel_attn", "=", "TFXLNetRelativeAttention", "(", "config", ",", "name", "=", "\"rel_attn\"", ")", "\n", "self", ".", "ff", "=", "TFXLNetFeedForward", "(", "config", ",", "name", "=", "\"ff\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetLayer.call": [[315, 325], ["modeling_tf_xlnet.TFXLNetLayer.rel_attn", "modeling_tf_xlnet.TFXLNetLayer.ff", "modeling_tf_xlnet.TFXLNetLayer.ff"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "rel_attn", "(", "inputs", ",", "training", "=", "training", ")", "\n", "output_h", ",", "output_g", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "output_g", "is", "not", "None", ":", "\n", "            ", "output_g", "=", "self", ".", "ff", "(", "output_g", ",", "training", "=", "training", ")", "\n", "", "output_h", "=", "self", ".", "ff", "(", "output_h", ",", "training", "=", "training", ")", "\n", "\n", "outputs", "=", "(", "output_h", ",", "output_g", ")", "+", "outputs", "[", "2", ":", "]", "# Add again attentions if there are there", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetLMHead.__init__": [[328, 334], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "input_embeddings", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetLMHead", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "input_embeddings", "=", "input_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetLMHead.build": [[335, 338], ["modeling_tf_xlnet.TFXLNetLMHead.add_weight", "super().build"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "self", ".", "bias", "=", "self", ".", "add_weight", "(", "shape", "=", "(", "self", ".", "vocab_size", ",", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"bias\"", ")", "\n", "super", "(", "TFXLNetLMHead", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetLMHead.call": [[339, 343], ["modeling_tf_xlnet.TFXLNetLMHead.input_embeddings"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "input_embeddings", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "hidden_states", "=", "hidden_states", "+", "self", ".", "bias", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.__init__": [[346, 368], ["super().__init__", "modeling_tf_utils.TFSharedEmbeddings", "tensorflow.keras.layers.Dropout", "modeling_tf_xlnet.TFXLNetLayer", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetMainLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "\n", "self", ".", "mem_len", "=", "config", ".", "mem_len", "\n", "self", ".", "reuse_len", "=", "config", ".", "reuse_len", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "self", ".", "bi_data", "=", "config", ".", "bi_data", "\n", "self", ".", "clamp_len", "=", "config", ".", "clamp_len", "\n", "self", ".", "n_layer", "=", "config", ".", "n_layer", "\n", "self", ".", "use_bfloat16", "=", "config", ".", "use_bfloat16", "\n", "self", ".", "initializer_range", "=", "config", ".", "initializer_range", "\n", "\n", "self", ".", "word_embedding", "=", "TFSharedEmbeddings", "(", "\n", "config", ".", "vocab_size", ",", "config", ".", "d_model", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"word_embedding\"", "\n", ")", "\n", "self", ".", "layer", "=", "[", "TFXLNetLayer", "(", "config", ",", "name", "=", "\"layer_._{}\"", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", "]", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.get_input_embeddings": [[369, 371], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "word_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.build": [[372, 376], ["modeling_tf_utils.get_initializer", "modeling_tf_xlnet.TFXLNetMainLayer.add_weight"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "initializer", "=", "get_initializer", "(", "self", ".", "initializer_range", ")", "\n", "self", ".", "mask_emb", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "1", ",", "1", ",", "self", ".", "d_model", ")", ",", "initializer", "=", "initializer", ",", "trainable", "=", "True", ",", "name", "=", "\"mask_emb\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer._resize_token_embeddings": [[378, 380], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer._prune_heads": [[381, 383], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.create_mask": [[384, 412], ["tensorflow.ones", "tensorflow.matrix_band_part", "tensorflow.matrix_band_part", "tensorflow.zeros", "tensorflow.concat", "tensorflow.matrix_band_part", "tensorflow.concat"], "methods", ["None"], ["", "def", "create_mask", "(", "self", ",", "qlen", ",", "mlen", ",", "dtype", "=", "tf", ".", "float32", ")", ":", "\n", "        ", "\"\"\"\n        Creates causal attention mask. Float mask where 1.0 indicates masked, 0.0 indicates not-masked.\n\n        Args:\n            qlen: TODO Lysandre didn't fill\n            mlen: TODO Lysandre didn't fill\n\n        ::\n\n                  same_length=False:      same_length=True:\n                  <mlen > <  qlen >       <mlen > <  qlen >\n               ^ [0 0 0 0 0 1 1 1 1]     [0 0 0 0 0 1 1 1 1]\n                 [0 0 0 0 0 0 1 1 1]     [1 0 0 0 0 0 1 1 1]\n            qlen [0 0 0 0 0 0 0 1 1]     [1 1 0 0 0 0 0 1 1]\n                 [0 0 0 0 0 0 0 0 1]     [1 1 1 0 0 0 0 0 1]\n               v [0 0 0 0 0 0 0 0 0]     [1 1 1 1 0 0 0 0 0]\n\n        \"\"\"", "\n", "attn_mask", "=", "tf", ".", "ones", "(", "[", "qlen", ",", "qlen", "]", ",", "dtype", "=", "dtype", ")", "\n", "mask_u", "=", "tf", ".", "matrix_band_part", "(", "attn_mask", ",", "0", ",", "-", "1", ")", "\n", "mask_dia", "=", "tf", ".", "matrix_band_part", "(", "attn_mask", ",", "0", ",", "0", ")", "\n", "attn_mask_pad", "=", "tf", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ",", "dtype", "=", "dtype", ")", "\n", "ret", "=", "tf", ".", "concat", "(", "[", "attn_mask_pad", ",", "mask_u", "-", "mask_dia", "]", ",", "1", ")", "\n", "if", "self", ".", "same_length", ":", "\n", "            ", "mask_l", "=", "tf", ".", "matrix_band_part", "(", "attn_mask", ",", "-", "1", ",", "0", ")", "\n", "ret", "=", "tf", ".", "concat", "(", "[", "ret", "[", ":", ",", ":", "qlen", "]", "+", "mask_l", "-", "mask_dia", ",", "ret", "[", ":", ",", "qlen", ":", "]", "]", ",", "1", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.cache_mem": [[413, 424], ["tensorflow.stop_gradient", "tensorflow.concat"], "methods", ["None"], ["", "def", "cache_mem", "(", "self", ",", "curr_out", ",", "prev_mem", ")", ":", "\n", "        ", "\"\"\"cache hidden states into memory.\"\"\"", "\n", "if", "self", ".", "reuse_len", "is", "not", "None", "and", "self", ".", "reuse_len", ">", "0", ":", "\n", "            ", "curr_out", "=", "curr_out", "[", ":", "self", ".", "reuse_len", "]", "\n", "\n", "", "if", "prev_mem", "is", "None", ":", "\n", "            ", "new_mem", "=", "curr_out", "[", "-", "self", ".", "mem_len", ":", "]", "\n", "", "else", ":", "\n", "            ", "new_mem", "=", "tf", ".", "concat", "(", "[", "prev_mem", ",", "curr_out", "]", ",", "0", ")", "[", "-", "self", ".", "mem_len", ":", "]", "\n", "\n", "", "return", "tf", ".", "stop_gradient", "(", "new_mem", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding": [[425, 435], ["tensorflow.einsum", "tensorflow.concat", "tensorflow.tile", "tensorflow.sin", "tensorflow.cos"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "positional_embedding", "(", "pos_seq", ",", "inv_freq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "tf", ".", "einsum", "(", "\"i,d->id\"", ",", "pos_seq", ",", "inv_freq", ")", "\n", "pos_emb", "=", "tf", ".", "concat", "(", "[", "tf", ".", "sin", "(", "sinusoid_inp", ")", ",", "tf", ".", "cos", "(", "sinusoid_inp", ")", "]", ",", "axis", "=", "-", "1", ")", "\n", "pos_emb", "=", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "pos_emb", "=", "tf", ".", "tile", "(", "pos_emb", ",", "[", "1", ",", "bsz", ",", "1", "]", ")", "\n", "\n", "", "return", "pos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.relative_positional_encoding": [[436, 483], ["tensorflow.range", "tensorflow.cast", "tensorflow.range", "tensorflow.range", "tensorflow.concat", "tensorflow.range", "modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "ValueError", "tensorflow.cast", "tensorflow.cast", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "tensorflow.cast", "tensorflow.clip_by_value"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.positional_embedding"], ["", "def", "relative_positional_encoding", "(", "self", ",", "qlen", ",", "klen", ",", "bsz", "=", "None", ",", "dtype", "=", "None", ")", ":", "\n", "        ", "\"\"\"create relative positional encoding.\"\"\"", "\n", "freq_seq", "=", "tf", ".", "range", "(", "0", ",", "self", ".", "d_model", ",", "2.0", ")", "\n", "if", "dtype", "is", "not", "None", "and", "dtype", "!=", "tf", ".", "float32", ":", "\n", "            ", "freq_seq", "=", "tf", ".", "cast", "(", "freq_seq", ",", "dtype", "=", "dtype", ")", "\n", "", "inv_freq", "=", "1", "/", "(", "10000", "**", "(", "freq_seq", "/", "self", ".", "d_model", ")", ")", "\n", "\n", "if", "self", ".", "attn_type", "==", "\"bi\"", ":", "\n", "# beg, end = klen - 1, -qlen", "\n", "            ", "beg", ",", "end", "=", "klen", ",", "-", "qlen", "\n", "", "elif", "self", ".", "attn_type", "==", "\"uni\"", ":", "\n", "# beg, end = klen - 1, -1", "\n", "            ", "beg", ",", "end", "=", "klen", ",", "-", "1", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unknown `attn_type` {}.\"", ".", "format", "(", "self", ".", "attn_type", ")", ")", "\n", "\n", "", "if", "self", ".", "bi_data", ":", "\n", "            ", "fwd_pos_seq", "=", "tf", ".", "range", "(", "beg", ",", "end", ",", "-", "1.0", ")", "\n", "bwd_pos_seq", "=", "tf", ".", "range", "(", "-", "beg", ",", "-", "end", ",", "1.0", ")", "\n", "\n", "if", "dtype", "is", "not", "None", "and", "dtype", "!=", "tf", ".", "float32", ":", "\n", "                ", "fwd_pos_seq", "=", "tf", ".", "cast", "(", "fwd_pos_seq", ",", "dtype", "=", "dtype", ")", "\n", "bwd_pos_seq", "=", "tf", ".", "cast", "(", "bwd_pos_seq", ",", "dtype", "=", "dtype", ")", "\n", "\n", "", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "fwd_pos_seq", "=", "tf", ".", "clip_by_value", "(", "fwd_pos_seq", ",", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "bwd_pos_seq", "=", "tf", ".", "clip_by_value", "(", "bwd_pos_seq", ",", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "\n", "", "if", "bsz", "is", "not", "None", ":", "\n", "# With bi_data, the batch size should be divisible by 2.", "\n", "                ", "assert", "bsz", "%", "2", "==", "0", "\n", "fwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ",", "bsz", "//", "2", ")", "\n", "bwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "bwd_pos_seq", ",", "inv_freq", ",", "bsz", "//", "2", ")", "\n", "", "else", ":", "\n", "                ", "fwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ")", "\n", "bwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "bwd_pos_seq", ",", "inv_freq", ")", "\n", "\n", "", "pos_emb", "=", "tf", ".", "concat", "(", "[", "fwd_pos_emb", ",", "bwd_pos_emb", "]", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "fwd_pos_seq", "=", "tf", ".", "range", "(", "beg", ",", "end", ",", "-", "1.0", ")", "\n", "if", "dtype", "is", "not", "None", "and", "dtype", "!=", "tf", ".", "float32", ":", "\n", "                ", "fwd_pos_seq", "=", "tf", ".", "cast", "(", "fwd_pos_seq", ",", "dtype", "=", "dtype", ")", "\n", "", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "fwd_pos_seq", "=", "tf", ".", "clip_by_value", "(", "fwd_pos_seq", ",", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ",", "bsz", ")", "\n", "\n", "", "return", "pos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.call": [[484, 685], ["isinstance", "modeling_tf_xlnet.TFXLNetMainLayer.dropout", "modeling_tf_xlnet.TFXLNetMainLayer.relative_positional_encoding", "modeling_tf_xlnet.TFXLNetMainLayer.dropout", "enumerate", "modeling_tf_xlnet.TFXLNetMainLayer.dropout", "isinstance", "ValueError", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "tensorflow.transpose", "modeling_tf_xlnet.TFXLNetMainLayer.create_mask", "tensorflow.zeros", "tensorflow.concat", "tensorflow.cast", "tensorflow.concat", "tensorflow.cast", "modeling_tf_xlnet.TFXLNetMainLayer.word_embedding", "tensorflow.tile", "modeling_tf_xlnet.TFXLNetMainLayer.dropout", "tensorflow.zeros", "tensorflow.concat", "tensorflow.cast", "tensorflow.one_hot", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "layer_module", "tuple.append", "tensorflow.transpose", "tuple", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "tensorflow.transpose", "modeling_tf_utils.shape_list", "ValueError", "tensorflow.cast", "tensorflow.eye", "tensorflow.logical_not", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "len", "tuple.append", "tuple.append", "tuple", "tuple", "len", "len", "len", "len", "len", "len", "len", "len", "len", "modeling_tf_utils.shape_list", "tensorflow.transpose", "ValueError", "tensorflow.zeros", "tensorflow.equal", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "tensorflow.transpose", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "modeling_tf_xlnet.TFXLNetMainLayer.cache_mem", "tensorflow.transpose", "tensorflow.transpose", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_tf_xlnet.TFXLNetMainLayer.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.relative_positional_encoding", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.create_mask", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetMainLayer.cache_mem"], ["", "def", "call", "(", "\n", "self", ",", "\n", "inputs", ",", "\n", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "\n", "perm_mask", "=", "None", ",", "\n", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "input_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "training", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "mems", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "mems", "\n", "perm_mask", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "perm_mask", "\n", "target_mapping", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "target_mapping", "\n", "token_type_ids", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "token_type_ids", "\n", "input_mask", "=", "inputs", "[", "6", "]", "if", "len", "(", "inputs", ")", ">", "6", "else", "input_mask", "\n", "head_mask", "=", "inputs", "[", "7", "]", "if", "len", "(", "inputs", ")", ">", "7", "else", "head_mask", "\n", "inputs_embeds", "=", "inputs", "[", "8", "]", "if", "len", "(", "inputs", ")", ">", "8", "else", "inputs_embeds", "\n", "assert", "len", "(", "inputs", ")", "<=", "9", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "\"input_ids\"", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "\"attention_mask\"", ",", "attention_mask", ")", "\n", "mems", "=", "inputs", ".", "get", "(", "\"mems\"", ",", "mems", ")", "\n", "perm_mask", "=", "inputs", ".", "get", "(", "\"perm_mask\"", ",", "perm_mask", ")", "\n", "target_mapping", "=", "inputs", ".", "get", "(", "\"target_mapping\"", ",", "target_mapping", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "\"token_type_ids\"", ",", "token_type_ids", ")", "\n", "input_mask", "=", "inputs", ".", "get", "(", "\"input_mask\"", ",", "input_mask", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "\"head_mask\"", ",", "head_mask", ")", "\n", "inputs_embeds", "=", "inputs", ".", "get", "(", "\"inputs_embeds\"", ",", "inputs_embeds", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "9", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "# the original code for XLNet uses shapes [len, bsz] with the batch dimension at the end", "\n", "# but we want a unified interface in the library with the batch size on the first dimension", "\n", "# so we move here the first dimension (batch) to the end", "\n", "\n", "", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_ids", "=", "tf", ".", "transpose", "(", "input_ids", ",", "perm", "=", "(", "1", ",", "0", ")", ")", "\n", "qlen", ",", "bsz", "=", "shape_list", "(", "input_ids", ")", "[", ":", "2", "]", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "inputs_embeds", "=", "tf", ".", "transpose", "(", "inputs_embeds", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", "\n", "qlen", ",", "bsz", "=", "shape_list", "(", "inputs_embeds", ")", "[", ":", "2", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "token_type_ids", "=", "tf", ".", "transpose", "(", "token_type_ids", ",", "perm", "=", "(", "1", ",", "0", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "input_mask", "=", "tf", ".", "transpose", "(", "input_mask", ",", "perm", "=", "(", "1", ",", "0", ")", ")", "if", "input_mask", "is", "not", "None", "else", "None", "\n", "attention_mask", "=", "tf", ".", "transpose", "(", "attention_mask", ",", "perm", "=", "(", "1", ",", "0", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "perm_mask", "=", "tf", ".", "transpose", "(", "perm_mask", ",", "perm", "=", "(", "1", ",", "2", ",", "0", ")", ")", "if", "perm_mask", "is", "not", "None", "else", "None", "\n", "target_mapping", "=", "tf", ".", "transpose", "(", "target_mapping", ",", "perm", "=", "(", "1", ",", "2", ",", "0", ")", ")", "if", "target_mapping", "is", "not", "None", "else", "None", "\n", "\n", "mlen", "=", "shape_list", "(", "mems", "[", "0", "]", ")", "[", "0", "]", "if", "mems", "is", "not", "None", "and", "mems", "[", "0", "]", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "\n", "dtype_float", "=", "tf", ".", "bfloat16", "if", "self", ".", "use_bfloat16", "else", "tf", ".", "float32", "\n", "\n", "# Attention mask", "\n", "# causal attention mask", "\n", "if", "self", ".", "attn_type", "==", "\"uni\"", ":", "\n", "            ", "attn_mask", "=", "self", ".", "create_mask", "(", "qlen", ",", "mlen", ")", "\n", "attn_mask", "=", "attn_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "", "elif", "self", ".", "attn_type", "==", "\"bi\"", ":", "\n", "            ", "attn_mask", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Unsupported attention type: {}\"", ".", "format", "(", "self", ".", "attn_type", ")", ")", "\n", "\n", "# data mask: input mask & perm mask", "\n", "", "assert", "input_mask", "is", "None", "or", "attention_mask", "is", "None", ",", "(", "\n", "\"You can only use one of input_mask (uses 1 for padding) \"", "\n", "\"or attention_mask (uses 0 for padding, added for compatbility with BERT). Please choose one.\"", "\n", ")", "\n", "if", "input_mask", "is", "None", "and", "attention_mask", "is", "not", "None", ":", "\n", "            ", "input_mask", "=", "1.0", "-", "tf", ".", "cast", "(", "attention_mask", ",", "dtype", "=", "dtype_float", ")", "\n", "", "if", "input_mask", "is", "not", "None", "and", "perm_mask", "is", "not", "None", ":", "\n", "            ", "data_mask", "=", "input_mask", "[", "None", "]", "+", "perm_mask", "\n", "", "elif", "input_mask", "is", "not", "None", "and", "perm_mask", "is", "None", ":", "\n", "            ", "data_mask", "=", "input_mask", "[", "None", "]", "\n", "", "elif", "input_mask", "is", "None", "and", "perm_mask", "is", "not", "None", ":", "\n", "            ", "data_mask", "=", "perm_mask", "\n", "", "else", ":", "\n", "            ", "data_mask", "=", "None", "\n", "\n", "", "if", "data_mask", "is", "not", "None", ":", "\n", "# all mems can be attended to", "\n", "            ", "mems_mask", "=", "tf", ".", "zeros", "(", "[", "shape_list", "(", "data_mask", ")", "[", "0", "]", ",", "mlen", ",", "bsz", "]", ",", "dtype", "=", "dtype_float", ")", "\n", "data_mask", "=", "tf", ".", "concat", "(", "[", "mems_mask", ",", "data_mask", "]", ",", "axis", "=", "1", ")", "\n", "if", "attn_mask", "is", "None", ":", "\n", "                ", "attn_mask", "=", "data_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "", "else", ":", "\n", "                ", "attn_mask", "+=", "data_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "tf", ".", "cast", "(", "attn_mask", ">", "0", ",", "dtype", "=", "dtype_float", ")", "\n", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "non_tgt_mask", "=", "-", "tf", ".", "eye", "(", "qlen", ",", "dtype", "=", "dtype_float", ")", "\n", "non_tgt_mask", "=", "tf", ".", "concat", "(", "[", "tf", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ",", "dtype", "=", "dtype_float", ")", ",", "non_tgt_mask", "]", ",", "axis", "=", "-", "1", ")", "\n", "non_tgt_mask", "=", "tf", ".", "cast", "(", "(", "attn_mask", "+", "non_tgt_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", ")", ">", "0", ",", "dtype", "=", "dtype_float", ")", "\n", "", "else", ":", "\n", "            ", "non_tgt_mask", "=", "None", "\n", "\n", "# Word embeddings and prepare h & g hidden states", "\n", "", "if", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "word_emb_k", "=", "inputs_embeds", "\n", "", "else", ":", "\n", "            ", "word_emb_k", "=", "self", ".", "word_embedding", "(", "input_ids", ")", "\n", "", "output_h", "=", "self", ".", "dropout", "(", "word_emb_k", ",", "training", "=", "training", ")", "\n", "if", "target_mapping", "is", "not", "None", ":", "\n", "            ", "word_emb_q", "=", "tf", ".", "tile", "(", "self", ".", "mask_emb", ",", "[", "shape_list", "(", "target_mapping", ")", "[", "0", "]", ",", "bsz", ",", "1", "]", ")", "\n", "# else:  # We removed the inp_q input which was same as target mapping", "\n", "#     inp_q_ext = inp_q[:, :, None]", "\n", "#     word_emb_q = inp_q_ext * self.mask_emb + (1 - inp_q_ext) * word_emb_k", "\n", "output_g", "=", "self", ".", "dropout", "(", "word_emb_q", ",", "training", "=", "training", ")", "\n", "", "else", ":", "\n", "            ", "output_g", "=", "None", "\n", "\n", "# Segment embedding", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "# Convert `token_type_ids` to one-hot `seg_mat`", "\n", "            ", "mem_pad", "=", "tf", ".", "zeros", "(", "[", "mlen", ",", "bsz", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "cat_ids", "=", "tf", ".", "concat", "(", "[", "mem_pad", ",", "token_type_ids", "]", ",", "0", ")", "\n", "\n", "# `1` indicates not in the same segment [qlen x klen x bsz]", "\n", "seg_mat", "=", "tf", ".", "cast", "(", "tf", ".", "logical_not", "(", "tf", ".", "equal", "(", "token_type_ids", "[", ":", ",", "None", "]", ",", "cat_ids", "[", "None", ",", ":", "]", ")", ")", ",", "tf", ".", "int32", ")", "\n", "seg_mat", "=", "tf", ".", "one_hot", "(", "seg_mat", ",", "2", ",", "dtype", "=", "dtype_float", ")", "\n", "", "else", ":", "\n", "            ", "seg_mat", "=", "None", "\n", "\n", "# Positional encoding", "\n", "", "pos_emb", "=", "self", ".", "relative_positional_encoding", "(", "qlen", ",", "klen", ",", "bsz", "=", "bsz", ",", "dtype", "=", "dtype_float", ")", "\n", "pos_emb", "=", "self", ".", "dropout", "(", "pos_emb", ",", "training", "=", "training", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads] (a head_mask for each layer)", "\n", "# and head_mask is converted to shape [num_hidden_layers x qlen x klen x bsz x n_head]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layer", "\n", "\n", "", "new_mems", "=", "(", ")", "\n", "if", "mems", "is", "None", ":", "\n", "            ", "mems", "=", "[", "None", "]", "*", "len", "(", "self", ".", "layer", ")", "\n", "\n", "", "attentions", "=", "[", "]", "\n", "hidden_states", "=", "[", "]", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "# cache new mems", "\n", "            ", "if", "self", ".", "mem_len", "is", "not", "None", "and", "self", ".", "mem_len", ">", "0", "and", "self", ".", "output_past", ":", "\n", "                ", "new_mems", "=", "new_mems", "+", "(", "self", ".", "cache_mem", "(", "output_h", ",", "mems", "[", "i", "]", ")", ",", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "hidden_states", ".", "append", "(", "(", "output_h", ",", "output_g", ")", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "", "outputs", "=", "layer_module", "(", "\n", "[", "output_h", ",", "output_g", ",", "non_tgt_mask", ",", "attn_mask", ",", "pos_emb", ",", "seg_mat", ",", "mems", "[", "i", "]", ",", "target_mapping", ",", "head_mask", "[", "i", "]", "]", ",", "\n", "training", "=", "training", ",", "\n", ")", "\n", "output_h", ",", "output_g", "=", "outputs", "[", ":", "2", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "# Add last hidden state", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "hidden_states", ".", "append", "(", "(", "output_h", ",", "output_g", ")", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "", "output", "=", "self", ".", "dropout", "(", "output_g", "if", "output_g", "is", "not", "None", "else", "output_h", ",", "training", "=", "training", ")", "\n", "\n", "# Prepare outputs, we transpose back here to shape [bsz, len, hidden_dim] (cf. beginning of forward() method)", "\n", "outputs", "=", "(", "tf", ".", "transpose", "(", "output", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", ",", ")", "\n", "\n", "if", "self", ".", "mem_len", "is", "not", "None", "and", "self", ".", "mem_len", ">", "0", "and", "self", ".", "output_past", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "new_mems", ",", ")", "\n", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "if", "output_g", "is", "not", "None", ":", "\n", "                ", "hidden_states", "=", "tuple", "(", "tf", ".", "transpose", "(", "h", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", "for", "hs", "in", "hidden_states", "for", "h", "in", "hs", ")", "\n", "", "else", ":", "\n", "                ", "hidden_states", "=", "tuple", "(", "tf", ".", "transpose", "(", "hs", ",", "perm", "=", "(", "1", ",", "0", ",", "2", ")", ")", "for", "hs", "in", "hidden_states", ")", "\n", "", "outputs", "=", "outputs", "+", "(", "hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "attentions", "=", "tuple", "(", "tf", ".", "transpose", "(", "t", ",", "perm", "=", "(", "2", ",", "3", ",", "0", ",", "1", ")", ")", "for", "t", "in", "attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "attentions", ",", ")", "\n", "\n", "", "return", "outputs", "# outputs, (new_mems), (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetModel.__init__": [[834, 837], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlnet.TFXLNetMainLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFXLNetMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetModel.call": [[838, 841], ["modeling_tf_xlnet.TFXLNetModel.transformer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetLMHeadModel.__init__": [[887, 891], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlnet.TFXLNetMainLayer", "modeling_tf_xlnet.TFXLNetLMHead"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFXLNetMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "self", ".", "lm_loss", "=", "TFXLNetLMHead", "(", "config", ",", "self", ".", "transformer", ".", "word_embedding", ",", "name", "=", "\"lm_loss\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetLMHeadModel.get_output_embeddings": [[892, 894], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_loss", ".", "input_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetLMHeadModel.call": [[895, 903], ["modeling_tf_xlnet.TFXLNetLMHeadModel.transformer", "modeling_tf_xlnet.TFXLNetLMHeadModel.lm_loss"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "hidden_state", "=", "transformer_outputs", "[", "0", "]", "\n", "logits", "=", "self", ".", "lm_loss", "(", "hidden_state", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "return", "outputs", "# return logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetForSequenceClassification.__init__": [[942, 952], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlnet.TFXLNetMainLayer", "modeling_tf_utils.TFSequenceSummary", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "TFXLNetMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "self", ".", "sequence_summary", "=", "TFSequenceSummary", "(", "\n", "config", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"sequence_summary\"", "\n", ")", "\n", "self", ".", "logits_proj", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"logits_proj\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetForSequenceClassification.call": [[954, 964], ["modeling_tf_xlnet.TFXLNetForSequenceClassification.transformer", "modeling_tf_xlnet.TFXLNetForSequenceClassification.sequence_summary", "modeling_tf_xlnet.TFXLNetForSequenceClassification.logits_proj"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "output", "=", "self", ".", "sequence_summary", "(", "output", ")", "\n", "logits", "=", "self", ".", "logits_proj", "(", "output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "return", "outputs", "# return logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetForTokenClassification.__init__": [[1003, 1010], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlnet.TFXLNetMainLayer", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "TFXLNetMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "self", ".", "classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"classifier\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetForTokenClassification.call": [[1012, 1021], ["modeling_tf_xlnet.TFXLNetForTokenClassification.transformer", "modeling_tf_xlnet.TFXLNetForTokenClassification.classifier"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "classifier", "(", "output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "return", "outputs", "# return logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimple.__init__": [[1060, 1065], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xlnet.TFXLNetMainLayer", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXLNetForQuestionAnsweringSimple", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFXLNetMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "self", ".", "qa_outputs", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"qa_outputs\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimple.call": [[1067, 1082], ["modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimple.transformer", "modeling_tf_xlnet.TFXLNetForQuestionAnsweringSimple.qa_outputs", "tensorflow.split", "tensorflow.squeeze", "tensorflow.squeeze"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "tf", ".", "split", "(", "logits", ",", "2", ",", "axis", "=", "-", "1", ")", "\n", "start_logits", "=", "tf", ".", "squeeze", "(", "start_logits", ",", "axis", "=", "-", "1", ")", "\n", "end_logits", "=", "tf", ".", "squeeze", "(", "end_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "transformer_outputs", "[", "\n", "1", ":", "\n", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "return", "outputs", "# start_logits, end_logits, (mems), (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.gelu": [[38, 45], ["tensorflow.tanh", "numpy.sqrt", "tensorflow.pow"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Implementation of the gelu activation function.\n        XLNet is using OpenAI GPT's gelu\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "tanh", "(", "(", "np", ".", "sqrt", "(", "2", "/", "np", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "tf", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_xlnet.swish": [[47, 49], ["tensorflow.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "tf", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_openai.OpenAIGPTConfig.__init__": [[58, 101], ["configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "40478", ",", "\n", "n_positions", "=", "512", ",", "\n", "n_ctx", "=", "512", ",", "\n", "n_embd", "=", "768", ",", "\n", "n_layer", "=", "12", ",", "\n", "n_head", "=", "12", ",", "\n", "afn", "=", "\"gelu\"", ",", "\n", "resid_pdrop", "=", "0.1", ",", "\n", "embd_pdrop", "=", "0.1", ",", "\n", "attn_pdrop", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "predict_special_tokens", "=", "True", ",", "\n", "summary_type", "=", "\"cls_index\"", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs OpenAIGPTConfig.\n        \"\"\"", "\n", "super", "(", "OpenAIGPTConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "afn", "=", "afn", "\n", "self", ".", "resid_pdrop", "=", "resid_pdrop", "\n", "self", ".", "embd_pdrop", "=", "embd_pdrop", "\n", "self", ".", "attn_pdrop", "=", "attn_pdrop", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "predict_special_tokens", "=", "predict_special_tokens", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_openai.OpenAIGPTConfig.max_position_embeddings": [[102, 105], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_openai.OpenAIGPTConfig.hidden_size": [[106, 109], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_embd", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_openai.OpenAIGPTConfig.num_attention_heads": [[110, 113], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_openai.OpenAIGPTConfig.num_hidden_layers": [[114, 117], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_mmbt.ModalEmbeddings.__init__": [[35, 45], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "encoder", ",", "embeddings", ")", ":", "\n", "        ", "super", "(", "ModalEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "proj_embeddings", "=", "nn", ".", "Linear", "(", "config", ".", "modal_hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "position_embeddings", "=", "embeddings", ".", "position_embeddings", "\n", "self", ".", "token_type_embeddings", "=", "embeddings", ".", "token_type_embeddings", "\n", "self", ".", "word_embeddings", "=", "embeddings", ".", "word_embeddings", "\n", "self", ".", "LayerNorm", "=", "embeddings", ".", "LayerNorm", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_mmbt.ModalEmbeddings.forward": [[46, 75], ["modeling_mmbt.ModalEmbeddings.proj_embeddings", "torch.cat.size", "torch.cat.size", "modeling_mmbt.ModalEmbeddings.position_embeddings", "modeling_mmbt.ModalEmbeddings.token_type_embeddings", "modeling_mmbt.ModalEmbeddings.LayerNorm", "modeling_mmbt.ModalEmbeddings.dropout", "modeling_mmbt.ModalEmbeddings.encoder", "modeling_mmbt.ModalEmbeddings.word_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_mmbt.ModalEmbeddings.word_embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "input_modal.size", "modeling_mmbt.ModalEmbeddings.unsqueeze", "modeling_mmbt.ModalEmbeddings.unsqueeze", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze", "input_modal.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_modal", ",", "start_token", "=", "None", ",", "end_token", "=", "None", ",", "position_ids", "=", "None", ",", "token_type_ids", "=", "None", ")", ":", "\n", "        ", "token_embeddings", "=", "self", ".", "proj_embeddings", "(", "self", ".", "encoder", "(", "input_modal", ")", ")", "\n", "seq_length", "=", "token_embeddings", ".", "size", "(", "1", ")", "\n", "\n", "if", "start_token", "is", "not", "None", ":", "\n", "            ", "start_token_embeds", "=", "self", ".", "word_embeddings", "(", "start_token", ")", "\n", "seq_length", "+=", "1", "\n", "token_embeddings", "=", "torch", ".", "cat", "(", "[", "start_token_embeds", ".", "unsqueeze", "(", "1", ")", ",", "token_embeddings", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "if", "end_token", "is", "not", "None", ":", "\n", "            ", "end_token_embeds", "=", "self", ".", "word_embeddings", "(", "end_token", ")", "\n", "seq_length", "+=", "1", "\n", "token_embeddings", "=", "torch", ".", "cat", "(", "[", "token_embeddings", ",", "end_token_embeds", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_modal", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "input_modal", ".", "size", "(", "0", ")", ",", "seq_length", ")", "\n", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "\n", "(", "input_modal", ".", "size", "(", "0", ")", ",", "seq_length", ")", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_modal", ".", "device", "\n", ")", "\n", "\n", "", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "embeddings", "=", "token_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_mmbt.MMBTModel.__init__": [[177, 182], ["torch.Module.__init__", "modeling_mmbt.ModalEmbeddings"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "transformer", ",", "encoder", ")", ":", "\n", "        ", "super", "(", "MMBTModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "transformer", "=", "transformer", "\n", "self", ".", "modal_encoder", "=", "ModalEmbeddings", "(", "config", ",", "encoder", ",", "transformer", ".", "embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_mmbt.MMBTModel.forward": [[183, 317], ["modeling_mmbt.MMBTModel.modal_encoder", "modeling_mmbt.MMBTModel.transformer.embeddings", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "extended_attention_mask.to.to.to", "encoder_extended_attention_mask.to.to.to", "modeling_mmbt.MMBTModel.transformer.encoder", "modeling_mmbt.MMBTModel.transformer.pooler", "ValueError", "modeling_mmbt.MMBTModel.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.cat.size", "torch.cat.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.dim", "torch.cat.dim", "torch.cat.dim", "torch.cat.dim", "torch.cat.dim", "torch.cat.dim", "torch.cat.dim", "torch.cat.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "input_ids.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "seq_ids[].repeat", "next", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "inputs_embeds.size", "modeling_mmbt.MMBTModel.parameters", "modeling_mmbt.MMBTModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_mmbt.MMBTModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_modal", ",", "\n", "input_ids", "=", "None", ",", "\n", "modal_start_tokens", "=", "None", ",", "\n", "modal_end_tokens", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "modal_token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "modal_position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_txt_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_txt_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "modal_embeddings", "=", "self", ".", "modal_encoder", "(", "\n", "input_modal", ",", "\n", "start_token", "=", "modal_start_tokens", ",", "\n", "end_token", "=", "modal_end_tokens", ",", "\n", "position_ids", "=", "modal_position_ids", ",", "\n", "token_type_ids", "=", "modal_token_type_ids", ",", "\n", ")", "\n", "\n", "input_modal_shape", "=", "modal_embeddings", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "ones", "(", "input_txt_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "", "txt_embeddings", "=", "self", ".", "transformer", ".", "embeddings", "(", "\n", "input_ids", "=", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "inputs_embeds", "=", "inputs_embeds", "\n", ")", "\n", "\n", "embedding_output", "=", "torch", ".", "cat", "(", "[", "modal_embeddings", ",", "txt_embeddings", "]", ",", "1", ")", "\n", "\n", "input_shape", "=", "embedding_output", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "input_shape", ",", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "cat", "(", "\n", "[", "torch", ".", "ones", "(", "input_modal_shape", ",", "device", "=", "device", ",", "dtype", "=", "torch", ".", "long", ")", ",", "attention_mask", "]", ",", "dim", "=", "1", "\n", ")", "\n", "\n", "", "if", "encoder_attention_mask", "is", "None", ":", "\n", "            ", "encoder_attention_mask", "=", "torch", ".", "ones", "(", "input_shape", ",", "device", "=", "device", ")", "\n", "", "else", ":", "\n", "            ", "encoder_attention_mask", "=", "torch", ".", "cat", "(", "\n", "[", "torch", ".", "ones", "(", "input_modal_shape", ",", "device", "=", "device", ")", ",", "encoder_attention_mask", "]", ",", "dim", "=", "1", "\n", ")", "\n", "\n", "# We can provide a self-attention mask of dimensions [batch_size, from_seq_length, to_seq_length]", "\n", "# ourselves in which case we just need to make it broadcastable to all heads.", "\n", "", "if", "attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "\n", "# Provided a padding mask of dimensions [batch_size, seq_length]", "\n", "# - if the model is a decoder, apply a causal mask in addition to the padding mask", "\n", "# - if the model is an encoder, make the mask broadcastable to [batch_size, num_heads, seq_length, seq_length]", "\n", "", "if", "attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "if", "self", ".", "config", ".", "is_decoder", ":", "\n", "                ", "batch_size", ",", "seq_length", "=", "input_shape", "\n", "seq_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "device", "=", "device", ")", "\n", "causal_mask", "=", "seq_ids", "[", "None", ",", "None", ",", ":", "]", ".", "repeat", "(", "batch_size", ",", "seq_length", ",", "1", ")", "<=", "seq_ids", "[", "None", ",", ":", ",", "None", "]", "\n", "extended_attention_mask", "=", "causal_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "*", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "", "", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# If a 2D ou 3D attention mask is provided for the cross-attention", "\n", "# we need to make broadcastabe to [batch_size, num_heads, seq_length, seq_length]", "\n", "if", "encoder_attention_mask", ".", "dim", "(", ")", "==", "3", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", ":", ",", ":", "]", "\n", "", "if", "encoder_attention_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "encoder_extended_attention_mask", "=", "encoder_attention_mask", "[", ":", ",", "None", ",", "None", ",", ":", "]", "\n", "\n", "", "encoder_extended_attention_mask", "=", "encoder_extended_attention_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# fp16 compatibility", "\n", "encoder_extended_attention_mask", "=", "(", "1.0", "-", "encoder_extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "num_hidden_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "", "encoder_outputs", "=", "self", ".", "transformer", ".", "encoder", "(", "\n", "embedding_output", ",", "\n", "attention_mask", "=", "extended_attention_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "encoder_hidden_states", "=", "encoder_hidden_states", ",", "\n", "encoder_attention_mask", "=", "encoder_extended_attention_mask", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "pooled_output", "=", "self", ".", "transformer", ".", "pooler", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ",", ")", "+", "encoder_outputs", "[", "\n", "1", ":", "\n", "]", "# add hidden_states and attentions if they are here", "\n", "return", "outputs", "# sequence_output, pooled_output, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_mmbt.MMBTModel.get_input_embeddings": [[318, 320], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_mmbt.MMBTModel.set_input_embeddings": [[321, 323], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "embeddings", ".", "word_embeddings", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_mmbt.MMBTForClassification.__init__": [[361, 368], ["torch.Module.__init__", "modeling_mmbt.MMBTModel", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "transformer", ",", "encoder", ")", ":", "\n", "        ", "super", "(", "MMBTForClassification", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "mmbt", "=", "MMBTModel", "(", "config", ",", "transformer", ",", "encoder", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_mmbt.MMBTForClassification.forward": [[369, 417], ["modeling_mmbt.MMBTForClassification.mmbt", "modeling_mmbt.MMBTForClassification.dropout", "modeling_mmbt.MMBTForClassification.classifier", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_mmbt.MMBTForClassification.view", "labels.view", "modeling_mmbt.MMBTForClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_modal", ",", "\n", "input_ids", "=", "None", ",", "\n", "modal_start_tokens", "=", "None", ",", "\n", "modal_end_tokens", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "modal_token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "modal_position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "mmbt", "(", "\n", "input_modal", "=", "input_modal", ",", "\n", "input_ids", "=", "input_ids", ",", "\n", "modal_start_tokens", "=", "modal_start_tokens", ",", "\n", "modal_end_tokens", "=", "modal_end_tokens", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "modal_token_type_ids", "=", "modal_token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "modal_position_ids", "=", "modal_position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.__init__": [[26, 44], ["super().__init__", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "1", ",", "keep_order", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAdaptiveSoftmaxMask", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "vocab_size", "]", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "self", ".", "div_val", "=", "div_val", "\n", "\n", "self", ".", "shortlist_size", "=", "self", ".", "cutoffs", "[", "0", "]", "\n", "self", ".", "n_clusters", "=", "len", "(", "self", ".", "cutoffs", ")", "-", "1", "\n", "self", ".", "head_size", "=", "self", ".", "shortlist_size", "+", "self", ".", "n_clusters", "\n", "self", ".", "keep_order", "=", "keep_order", "\n", "\n", "self", ".", "out_layers", "=", "[", "]", "\n", "self", ".", "out_projs", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build": [[45, 102], ["super().build", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "range", "range", "len", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.out_layers.append", "len", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.out_projs.append", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.out_layers.append", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_weight", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.out_projs.append", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.out_projs.append"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.build"], ["", "def", "build", "(", "self", ",", "input_shape", ")", ":", "\n", "        ", "if", "self", ".", "n_clusters", ">", "0", ":", "\n", "            ", "self", ".", "cluster_weight", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "n_clusters", ",", "self", ".", "d_embed", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"cluster_weight\"", "\n", ")", "\n", "self", ".", "cluster_bias", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "n_clusters", ",", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"cluster_bias\"", "\n", ")", "\n", "\n", "", "if", "self", ".", "div_val", "==", "1", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "if", "self", ".", "d_proj", "!=", "self", ".", "d_embed", ":", "\n", "                    ", "weight", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "d_embed", ",", "self", ".", "d_proj", ")", ",", "\n", "initializer", "=", "\"zeros\"", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "\"out_projs_._{}\"", ".", "format", "(", "i", ")", ",", "\n", ")", "\n", "self", ".", "out_projs", ".", "append", "(", "weight", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "out_projs", ".", "append", "(", "None", ")", "\n", "", "weight", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "vocab_size", ",", "self", ".", "d_embed", ",", ")", ",", "\n", "initializer", "=", "\"zeros\"", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "\"out_layers_._{}_._weight\"", ".", "format", "(", "i", ")", ",", "\n", ")", "\n", "bias", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "self", ".", "vocab_size", ",", ")", ",", "\n", "initializer", "=", "\"zeros\"", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "\"out_layers_._{}_._bias\"", ".", "format", "(", "i", ")", ",", "\n", ")", "\n", "self", ".", "out_layers", ".", "append", "(", "(", "weight", ",", "bias", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "self", ".", "d_embed", "//", "(", "self", ".", "div_val", "**", "i", ")", "\n", "\n", "weight", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "d_emb_i", ",", "self", ".", "d_proj", ")", ",", "initializer", "=", "\"zeros\"", ",", "trainable", "=", "True", ",", "name", "=", "\"out_projs_._{}\"", ".", "format", "(", "i", ")", "\n", ")", "\n", "self", ".", "out_projs", ".", "append", "(", "weight", ")", "\n", "weight", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "r_idx", "-", "l_idx", ",", "d_emb_i", ",", ")", ",", "\n", "initializer", "=", "\"zeros\"", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "\"out_layers_._{}_._weight\"", ".", "format", "(", "i", ")", ",", "\n", ")", "\n", "bias", "=", "self", ".", "add_weight", "(", "\n", "shape", "=", "(", "r_idx", "-", "l_idx", ",", ")", ",", "\n", "initializer", "=", "\"zeros\"", ",", "\n", "trainable", "=", "True", ",", "\n", "name", "=", "\"out_layers_._{}_._bias\"", ".", "format", "(", "i", ")", ",", "\n", ")", "\n", "self", ".", "out_layers", ".", "append", "(", "(", "weight", ",", "bias", ")", ")", "\n", "", "", "super", "(", "TFAdaptiveSoftmaxMask", ",", "self", ")", ".", "build", "(", "input_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._logit": [[103, 109], ["tensorflow.einsum", "tensorflow.einsum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_logit", "(", "x", ",", "W", ",", "b", ",", "proj", "=", "None", ")", ":", "\n", "        ", "y", "=", "x", "\n", "if", "proj", "is", "not", "None", ":", "\n", "            ", "y", "=", "tf", ".", "einsum", "(", "\"ibd,ed->ibe\"", ",", "y", ",", "proj", ")", "\n", "", "return", "tf", ".", "einsum", "(", "\"ibd,nd->ibn\"", ",", "y", ",", "W", ")", "+", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._gather_logprob": [[110, 116], ["modeling_tf_utils.shape_list", "tensorflow.range", "tensorflow.stack", "tensorflow.gather_nd"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "@", "staticmethod", "\n", "def", "_gather_logprob", "(", "logprob", ",", "target", ")", ":", "\n", "        ", "lp_size", "=", "shape_list", "(", "logprob", ")", "\n", "r", "=", "tf", ".", "range", "(", "lp_size", "[", "0", "]", ")", "\n", "idx", "=", "tf", ".", "stack", "(", "[", "r", ",", "target", "]", ",", "1", ")", "\n", "return", "tf", ".", "gather_nd", "(", "logprob", ",", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.call": [[117, 180], ["tensorflow.get_variable", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._logit", "tensorflow.nn.log_softmax", "modeling_tf_utils.shape_list", "tensorflow.zeros", "range", "tensorflow.concat", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_loss", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask.add_metric", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "len", "tensorflow.reduce_mean", "tensorflow.zeros_initializer", "tensorflow.where", "tensorflow.concat", "tensorflow.concat", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._logit", "tensorflow.nn.log_softmax", "tensorflow.concat.append", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._logit", "tensorflow.nn.log_softmax", "tensorflow.concat.append", "tensorflow.scatter_nd", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._gather_logprob", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._gather_logprob", "tensorflow.cast", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._logit", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._logit", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._logit", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._gather_logprob", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_transfo_xl_utilities.TFAdaptiveSoftmaxMask._gather_logprob", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "self", ",", "inputs", ",", "return_mean", "=", "True", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden", ",", "target", "=", "inputs", "\n", "head_logprob", "=", "0", "\n", "if", "self", ".", "n_clusters", "==", "0", ":", "\n", "            ", "softmax_b", "=", "tf", ".", "get_variable", "(", "\"bias\"", ",", "[", "self", ".", "config", ".", "vocab_size", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "output", "=", "self", ".", "_logit", "(", "hidden", ",", "self", ".", "out_layers", "[", "0", "]", "[", "0", "]", ",", "self", ".", "out_layers", "[", "0", "]", "[", "1", "]", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "if", "target", "is", "not", "None", ":", "\n", "                ", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "labels", "=", "target", ",", "logits", "=", "output", ")", "\n", "", "out", "=", "tf", ".", "nn", ".", "log_softmax", "(", "output", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "hidden_sizes", "=", "shape_list", "(", "hidden", ")", "\n", "out", "=", "[", "]", "\n", "loss", "=", "tf", ".", "zeros", "(", "hidden_sizes", "[", ":", "2", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "                ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "if", "target", "is", "not", "None", ":", "\n", "                    ", "mask", "=", "(", "target", ">=", "l_idx", ")", "&", "(", "target", "<", "r_idx", ")", "\n", "mask_idx", "=", "tf", ".", "where", "(", "mask", ")", "\n", "cur_target", "=", "tf", ".", "boolean_mask", "(", "target", ",", "mask", ")", "-", "l_idx", "\n", "\n", "", "if", "self", ".", "div_val", "==", "1", ":", "\n", "                    ", "cur_W", "=", "self", ".", "out_layers", "[", "0", "]", "[", "0", "]", "[", "l_idx", ":", "r_idx", "]", "\n", "cur_b", "=", "self", ".", "out_layers", "[", "0", "]", "[", "1", "]", "[", "l_idx", ":", "r_idx", "]", "\n", "", "else", ":", "\n", "                    ", "cur_W", "=", "self", ".", "out_layers", "[", "i", "]", "[", "0", "]", "\n", "cur_b", "=", "self", ".", "out_layers", "[", "i", "]", "[", "1", "]", "\n", "\n", "", "if", "i", "==", "0", ":", "\n", "                    ", "cur_W", "=", "tf", ".", "concat", "(", "[", "cur_W", ",", "self", ".", "cluster_weight", "]", ",", "0", ")", "\n", "cur_b", "=", "tf", ".", "concat", "(", "[", "cur_b", ",", "self", ".", "cluster_bias", "]", ",", "0", ")", "\n", "\n", "head_logit", "=", "self", ".", "_logit", "(", "hidden", ",", "cur_W", ",", "cur_b", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "head_logprob", "=", "tf", ".", "nn", ".", "log_softmax", "(", "head_logit", ")", "\n", "out", ".", "append", "(", "head_logprob", "[", "...", ",", ":", "self", ".", "cutoffs", "[", "0", "]", "]", ")", "\n", "if", "target", "is", "not", "None", ":", "\n", "                        ", "cur_head_logprob", "=", "tf", ".", "boolean_mask", "(", "head_logprob", ",", "mask", ")", "\n", "cur_logprob", "=", "self", ".", "_gather_logprob", "(", "cur_head_logprob", ",", "cur_target", ")", "\n", "", "", "else", ":", "\n", "                    ", "tail_logit", "=", "self", ".", "_logit", "(", "hidden", ",", "cur_W", ",", "cur_b", ",", "self", ".", "out_projs", "[", "i", "]", ")", "\n", "tail_logprob", "=", "tf", ".", "nn", ".", "log_softmax", "(", "tail_logit", ")", "\n", "cluster_prob_idx", "=", "self", ".", "cutoffs", "[", "0", "]", "+", "i", "-", "1", "# No probability for the head cluster", "\n", "logprob_i", "=", "head_logprob", "[", "...", ",", "cluster_prob_idx", ",", "None", "]", "+", "tail_logprob", "\n", "out", ".", "append", "(", "logprob_i", ")", "\n", "if", "target", "is", "not", "None", ":", "\n", "                        ", "cur_head_logprob", "=", "tf", ".", "boolean_mask", "(", "head_logprob", ",", "mask", ")", "\n", "cur_tail_logprob", "=", "tf", ".", "boolean_mask", "(", "tail_logprob", ",", "mask", ")", "\n", "cur_logprob", "=", "self", ".", "_gather_logprob", "(", "cur_tail_logprob", ",", "cur_target", ")", "\n", "cur_logprob", "+=", "cur_head_logprob", "[", ":", ",", "self", ".", "cutoff_ends", "[", "1", "]", "+", "i", "-", "1", "]", "\n", "", "", "if", "target", "is", "not", "None", ":", "\n", "                    ", "loss", "+=", "tf", ".", "scatter_nd", "(", "mask_idx", ",", "-", "cur_logprob", ",", "tf", ".", "cast", "(", "shape_list", "(", "loss", ")", ",", "dtype", "=", "tf", ".", "int64", ")", ")", "\n", "", "", "out", "=", "tf", ".", "concat", "(", "out", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "if", "target", "is", "not", "None", ":", "\n", "            ", "if", "return_mean", ":", "\n", "                ", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "# Add the training-time loss value to the layer using `self.add_loss()`.", "\n", "", "self", ".", "add_loss", "(", "loss", ")", "\n", "\n", "# Log the loss as a metric (we could log arbitrary metrics,", "\n", "# including different metrics for training and inference.", "\n", "self", ".", "add_metric", "(", "loss", ",", "name", "=", "self", ".", "name", ",", "aggregation", "=", "\"mean\"", "if", "return_mean", "else", "\"\"", ")", "\n", "\n", "", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertEmbeddings.__init__": [[169, 176], ["transformers.modeling_bert.BertEmbeddings.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "AlbertEmbeddings", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "embedding_size", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "embedding_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "embedding_size", ")", "\n", "self", ".", "LayerNorm", "=", "torch", ".", "nn", ".", "LayerNorm", "(", "config", ".", "embedding_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertAttention.__init__": [[179, 190], ["transformers.modeling_bert.BertSelfAttention.__init__", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.LayerNorm", "torch.LayerNorm", "set"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "AlbertAttention", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "hidden_size", "=", "config", ".", "hidden_size", "\n", "self", ".", "attention_head_size", "=", "config", ".", "hidden_size", "//", "config", ".", "num_attention_heads", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertAttention.prune_heads": [[191, 213], ["torch.ones", "torch.ones", "torch.ones", "torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "transformers.modeling_bert.prune_linear_layer", "transformers.modeling_bert.prune_linear_layer", "transformers.modeling_bert.prune_linear_layer", "transformers.modeling_bert.prune_linear_layer", "modeling_albert.AlbertAttention.pruned_heads.union", "len", "set", "len", "sum", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_linear_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "# Convert to set and emove already pruned heads", "\n", "for", "head", "in", "heads", ":", "\n", "# Compute how many pruned heads are before the head and move the index accordingly", "\n", "            ", "head", "=", "head", "-", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "\n", "# Prune linear layers", "\n", "self", ".", "query", "=", "prune_linear_layer", "(", "self", ".", "query", ",", "index", ")", "\n", "self", ".", "key", "=", "prune_linear_layer", "(", "self", ".", "key", ",", "index", ")", "\n", "self", ".", "value", "=", "prune_linear_layer", "(", "self", ".", "value", ",", "index", ")", "\n", "self", ".", "dense", "=", "prune_linear_layer", "(", "self", ".", "dense", ",", "index", ",", "dim", "=", "1", ")", "\n", "\n", "# Update hyper params and store pruned heads", "\n", "self", ".", "num_attention_heads", "=", "self", ".", "num_attention_heads", "-", "len", "(", "heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "attention_head_size", "*", "self", ".", "num_attention_heads", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertAttention.forward": [[214, 259], ["modeling_albert.AlbertAttention.query", "modeling_albert.AlbertAttention.key", "modeling_albert.AlbertAttention.value", "modeling_albert.AlbertAttention.transpose_for_scores", "modeling_albert.AlbertAttention.transpose_for_scores", "modeling_albert.AlbertAttention.transpose_for_scores", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "modeling_albert.AlbertAttention.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "context_layer.permute().contiguous.permute().contiguous.permute().contiguous", "context_layer.permute().contiguous.permute().contiguous.view", "modeling_albert.AlbertAttention.dense.weight.t().view().to", "modeling_albert.AlbertAttention.dense.bias.to", "modeling_albert.AlbertAttention.dropout", "modeling_albert.AlbertAttention.LayerNorm", "modeling_albert.AlbertAttention.transpose", "math.sqrt", "torch.Softmax", "torch.Softmax", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "context_layer.permute().contiguous.permute().contiguous.permute", "context_layer.permute().contiguous.permute().contiguous.size", "modeling_albert.AlbertAttention.dense.weight.t().view", "modeling_albert.AlbertAttention.dense.weight.t"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_albert.TFAlbertSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "input_ids", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "input_ids", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "input_ids", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "reshaped_context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "# Should find a better way to do this", "\n", "w", "=", "(", "\n", "self", ".", "dense", ".", "weight", ".", "t", "(", ")", "\n", ".", "view", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ",", "self", ".", "hidden_size", ")", "\n", ".", "to", "(", "context_layer", ".", "dtype", ")", "\n", ")", "\n", "b", "=", "self", ".", "dense", ".", "bias", ".", "to", "(", "context_layer", ".", "dtype", ")", "\n", "\n", "projected_context_layer", "=", "torch", ".", "einsum", "(", "\"bfnd,ndh->bfh\"", ",", "context_layer", ",", "w", ")", "+", "b", "\n", "projected_context_layer_dropout", "=", "self", ".", "dropout", "(", "projected_context_layer", ")", "\n", "layernormed_context_layer", "=", "self", ".", "LayerNorm", "(", "input_ids", "+", "projected_context_layer_dropout", ")", "\n", "return", "(", "layernormed_context_layer", ",", "attention_probs", ")", "if", "self", ".", "output_attentions", "else", "(", "layernormed_context_layer", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertLayer.__init__": [[262, 271], ["torch.Module.__init__", "torch.LayerNorm", "torch.LayerNorm", "modeling_albert.AlbertAttention", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "AlbertLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "full_layer_layer_norm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "attention", "=", "AlbertAttention", "(", "config", ")", "\n", "self", ".", "ffn", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "self", ".", "ffn_output", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertLayer.forward": [[272, 280], ["modeling_albert.AlbertLayer.attention", "modeling_albert.AlbertLayer.ffn", "modeling_albert.AlbertLayer.activation", "modeling_albert.AlbertLayer.ffn_output", "modeling_albert.AlbertLayer.full_layer_layer_norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "attention_output", "=", "self", ".", "attention", "(", "hidden_states", ",", "attention_mask", ",", "head_mask", ")", "\n", "ffn_output", "=", "self", ".", "ffn", "(", "attention_output", "[", "0", "]", ")", "\n", "ffn_output", "=", "self", ".", "activation", "(", "ffn_output", ")", "\n", "ffn_output", "=", "self", ".", "ffn_output", "(", "ffn_output", ")", "\n", "hidden_states", "=", "self", ".", "full_layer_layer_norm", "(", "ffn_output", "+", "attention_output", "[", "0", "]", ")", "\n", "\n", "return", "(", "hidden_states", ",", ")", "+", "attention_output", "[", "1", ":", "]", "# add attentions if we output them", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertLayerGroup.__init__": [[283, 289], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "modeling_albert.AlbertLayer", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "AlbertLayerGroup", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "albert_layers", "=", "nn", ".", "ModuleList", "(", "[", "AlbertLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "inner_group_num", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertLayerGroup.forward": [[290, 310], ["enumerate", "albert_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "layer_hidden_states", "=", "(", ")", "\n", "layer_attentions", "=", "(", ")", "\n", "\n", "for", "layer_index", ",", "albert_layer", "in", "enumerate", "(", "self", ".", "albert_layers", ")", ":", "\n", "            ", "layer_output", "=", "albert_layer", "(", "hidden_states", ",", "attention_mask", ",", "head_mask", "[", "layer_index", "]", ")", "\n", "hidden_states", "=", "layer_output", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "layer_attentions", "=", "layer_attentions", "+", "(", "layer_output", "[", "1", "]", ",", ")", "\n", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "layer_hidden_states", "=", "layer_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "layer_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "layer_attentions", ",", ")", "\n", "", "return", "outputs", "# last-layer hidden state, (layer hidden states), (layer attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertTransformer.__init__": [[313, 321], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.ModuleList", "torch.ModuleList", "modeling_albert.AlbertLayerGroup", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "AlbertTransformer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "embedding_hidden_mapping_in", "=", "nn", ".", "Linear", "(", "config", ".", "embedding_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "albert_layer_groups", "=", "nn", ".", "ModuleList", "(", "[", "AlbertLayerGroup", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_groups", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertTransformer.forward": [[322, 359], ["modeling_albert.AlbertTransformer.embedding_hidden_mapping_in", "range", "int", "int", "int"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "embedding_hidden_mapping_in", "(", "hidden_states", ")", "\n", "\n", "all_attentions", "=", "(", ")", "\n", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "(", "hidden_states", ",", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "self", ".", "config", ".", "num_hidden_layers", ")", ":", "\n", "# Number of layers in a hidden group", "\n", "            ", "layers_per_group", "=", "int", "(", "self", ".", "config", ".", "num_hidden_layers", "/", "self", ".", "config", ".", "num_hidden_groups", ")", "\n", "\n", "# Index of the hidden group", "\n", "group_idx", "=", "int", "(", "i", "/", "(", "self", ".", "config", ".", "num_hidden_layers", "/", "self", ".", "config", ".", "num_hidden_groups", ")", ")", "\n", "\n", "# Index of the layer inside the group", "\n", "layer_idx", "=", "int", "(", "i", "-", "group_idx", "*", "layers_per_group", ")", "\n", "\n", "layer_group_output", "=", "self", ".", "albert_layer_groups", "[", "group_idx", "]", "(", "\n", "hidden_states", ",", "\n", "attention_mask", ",", "\n", "head_mask", "[", "group_idx", "*", "layers_per_group", ":", "(", "group_idx", "+", "1", ")", "*", "layers_per_group", "]", ",", "\n", ")", "\n", "hidden_states", "=", "layer_group_output", "[", "0", "]", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "layer_group_output", "[", "-", "1", "]", "\n", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last-layer hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertPreTrainedModel._init_weights": [[370, 382], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ")", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertModel.__init__": [[478, 488], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_albert.AlbertEmbeddings", "modeling_albert.AlbertTransformer", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "modeling_albert.AlbertModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "AlbertModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "embeddings", "=", "AlbertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "AlbertTransformer", "(", "config", ")", "\n", "self", ".", "pooler", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "pooler_activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertModel.get_input_embeddings": [[489, 491], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertModel.set_input_embeddings": [[492, 494], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "embeddings", ".", "word_embeddings", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertModel._resize_token_embeddings": [[495, 500], ["modeling_albert.AlbertModel._get_resized_embeddings"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel._get_resized_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "old_embeddings", "=", "self", ".", "embeddings", ".", "word_embeddings", "\n", "new_embeddings", "=", "self", ".", "_get_resized_embeddings", "(", "old_embeddings", ",", "new_num_tokens", ")", "\n", "self", ".", "embeddings", ".", "word_embeddings", "=", "new_embeddings", "\n", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertModel._prune_heads": [[501, 518], ["heads_to_prune.items", "int", "int", "modeling_albert.AlbertModel.encoder.albert_layer_groups[].albert_layers[].attention.prune_heads"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            ALBERT has a different architecture in that its layers are shared across groups, which then has inner groups.\n            If an ALBERT model has 12 hidden layers and 2 hidden groups, with two inner groups, there\n            is a total of 4 different layers.\n\n            These layers are flattened: the indices [0,1] correspond to the two inner groups of the first hidden layer,\n            while [2,3] correspond to the two inner groups of the second hidden layer.\n\n            Any layer with in index other than [0,1,2,3] will result in an error.\n            See base class PreTrainedModel for more information about head pruning\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "group_idx", "=", "int", "(", "layer", "/", "self", ".", "config", ".", "inner_group_num", ")", "\n", "inner_group_idx", "=", "int", "(", "layer", "-", "group_idx", "*", "self", ".", "config", ".", "inner_group_num", ")", "\n", "self", ".", "encoder", ".", "albert_layer_groups", "[", "group_idx", "]", ".", "albert_layers", "[", "inner_group_idx", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertModel.forward": [[519, 575], ["torch.ones.unsqueeze().unsqueeze", "torch.ones.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "modeling_albert.AlbertModel.embeddings", "modeling_albert.AlbertModel.encoder", "modeling_albert.AlbertModel.pooler_activation", "ValueError", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "modeling_albert.AlbertModel.pooler", "input_ids.size", "torch.ones.unsqueeze", "torch.ones.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "ValueError", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "inputs_embeds.size", "modeling_albert.AlbertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_albert.AlbertModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "input_shape", ",", "device", "=", "device", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "num_hidden_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "\n", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "inputs_embeds", "=", "inputs_embeds", "\n", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "embedding_output", ",", "extended_attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "\n", "pooled_output", "=", "self", ".", "pooler_activation", "(", "self", ".", "pooler", "(", "sequence_output", "[", ":", ",", "0", "]", ")", ")", "\n", "\n", "outputs", "=", "(", "sequence_output", ",", "pooled_output", ")", "+", "encoder_outputs", "[", "\n", "1", ":", "\n", "]", "# add hidden_states and attentions if they are here", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertMLMHead.__init__": [[578, 586], ["torch.Module.__init__", "torch.LayerNorm", "torch.LayerNorm", "torch.Parameter", "torch.Parameter", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "AlbertMLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "embedding_size", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "config", ".", "vocab_size", ")", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "embedding_size", ")", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "config", ".", "embedding_size", ",", "config", ".", "vocab_size", ")", "\n", "self", ".", "activation", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertMLMHead.forward": [[587, 596], ["modeling_albert.AlbertMLMHead.dense", "modeling_albert.AlbertMLMHead.activation", "modeling_albert.AlbertMLMHead.LayerNorm", "modeling_albert.AlbertMLMHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "activation", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "decoder", "(", "hidden_states", ")", "\n", "\n", "prediction_scores", "=", "hidden_states", "+", "self", ".", "bias", "\n", "\n", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertForMaskedLM.__init__": [[623, 631], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_albert.AlbertModel", "modeling_albert.AlbertMLMHead", "modeling_albert.AlbertForMaskedLM.init_weights", "modeling_albert.AlbertForMaskedLM.tie_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertForMaskedLM.tie_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "AlbertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "albert", "=", "AlbertModel", "(", "config", ")", "\n", "self", ".", "predictions", "=", "AlbertMLMHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertForMaskedLM.tie_weights": [[632, 637], ["modeling_albert.AlbertForMaskedLM._tie_or_clone_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel._tie_or_clone_weights"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "self", ".", "_tie_or_clone_weights", "(", "self", ".", "predictions", ".", "decoder", ",", "self", ".", "albert", ".", "embeddings", ".", "word_embeddings", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertForMaskedLM.get_output_embeddings": [[638, 640], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "predictions", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertForMaskedLM.forward": [[641, 670], ["modeling_albert.AlbertForMaskedLM.albert", "modeling_albert.AlbertForMaskedLM.predictions", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_albert.AlbertForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "masked_lm_labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "albert", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "sequence_outputs", "=", "outputs", "[", "0", "]", "\n", "\n", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_outputs", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertForSequenceClassification.__init__": [[710, 719], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_albert.AlbertModel", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "modeling_albert.AlbertForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "AlbertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "albert", "=", "AlbertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertForSequenceClassification.forward": [[720, 758], ["modeling_albert.AlbertForSequenceClassification.albert", "modeling_albert.AlbertForSequenceClassification.dropout", "modeling_albert.AlbertForSequenceClassification.classifier", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_albert.AlbertForSequenceClassification.view", "labels.view", "modeling_albert.AlbertForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "albert", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertForQuestionAnswering.__init__": [[808, 816], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_albert.AlbertModel", "torch.Linear", "torch.Linear", "modeling_albert.AlbertForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "AlbertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "albert", "=", "AlbertModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.AlbertForQuestionAnswering.forward": [[817, 864], ["modeling_albert.AlbertForQuestionAnswering.albert", "modeling_albert.AlbertForQuestionAnswering.qa_outputs", "modeling_albert.AlbertForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "\n", "end_positions", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "albert", "(", "\n", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_albert.load_tf_weights_in_albert": [[47, 162], ["os.path.abspath", "logger.info", "tf.train.list_variables", "zip", "zip", "logger.info", "tf.train.load_variable", "names.append", "arrays.append", "print", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.replace", "name.split.split", "print", "torch.from_numpy", "torch.from_numpy", "logger.error", "logger.info", "re.fullmatch", "getattr", "len", "re.split", "getattr", "len", "int", "np.transpose", "name.split.split", "getattr", "getattr", "getattr", "getattr", "logger.info"], "function", ["None"], ["def", "load_tf_weights_in_albert", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model.\"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "print", "(", "name", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "original_name", "=", "name", "\n", "\n", "# If saved from the TF HUB module", "\n", "name", "=", "name", ".", "replace", "(", "\"module/\"", ",", "\"\"", ")", "\n", "\n", "# Renaming and simplifying", "\n", "name", "=", "name", ".", "replace", "(", "\"ffn_1\"", ",", "\"ffn\"", ")", "\n", "name", "=", "name", ".", "replace", "(", "\"bert/\"", ",", "\"albert/\"", ")", "\n", "name", "=", "name", ".", "replace", "(", "\"attention_1\"", ",", "\"attention\"", ")", "\n", "name", "=", "name", ".", "replace", "(", "\"transform/\"", ",", "\"\"", ")", "\n", "name", "=", "name", ".", "replace", "(", "\"LayerNorm_1\"", ",", "\"full_layer_layer_norm\"", ")", "\n", "name", "=", "name", ".", "replace", "(", "\"LayerNorm\"", ",", "\"attention/LayerNorm\"", ")", "\n", "name", "=", "name", ".", "replace", "(", "\"transformer/\"", ",", "\"\"", ")", "\n", "\n", "# The feed forward layer had an 'intermediate' step which has been abstracted away", "\n", "name", "=", "name", ".", "replace", "(", "\"intermediate/dense/\"", ",", "\"\"", ")", "\n", "name", "=", "name", ".", "replace", "(", "\"ffn/intermediate/output/dense/\"", ",", "\"ffn_output/\"", ")", "\n", "\n", "# ALBERT attention was split between self and output which have been abstracted away", "\n", "name", "=", "name", ".", "replace", "(", "\"/output/\"", ",", "\"/\"", ")", "\n", "name", "=", "name", ".", "replace", "(", "\"/self/\"", ",", "\"/\"", ")", "\n", "\n", "# The pooler is a linear layer", "\n", "name", "=", "name", ".", "replace", "(", "\"pooler/dense\"", ",", "\"pooler\"", ")", "\n", "\n", "# The classifier was simplified to predictions from cls/predictions", "\n", "name", "=", "name", ".", "replace", "(", "\"cls/predictions\"", ",", "\"predictions\"", ")", "\n", "name", "=", "name", ".", "replace", "(", "\"predictions/attention\"", ",", "\"predictions\"", ")", "\n", "\n", "# Naming was changed to be more explicit", "\n", "name", "=", "name", ".", "replace", "(", "\"embeddings/attention\"", ",", "\"embeddings\"", ")", "\n", "name", "=", "name", ".", "replace", "(", "\"inner_group_\"", ",", "\"albert_layers/\"", ")", "\n", "name", "=", "name", ".", "replace", "(", "\"group_\"", ",", "\"albert_layer_groups/\"", ")", "\n", "\n", "# Classifier", "\n", "if", "len", "(", "name", ".", "split", "(", "\"/\"", ")", ")", "==", "1", "and", "(", "\"output_bias\"", "in", "name", "or", "\"output_weights\"", "in", "name", ")", ":", "\n", "            ", "name", "=", "\"classifier/\"", "+", "name", "\n", "\n", "# No ALBERT model currently handles the next sentence prediction task", "\n", "", "if", "\"seq_relationship\"", "in", "name", ":", "\n", "            ", "continue", "\n", "\n", "", "name", "=", "name", ".", "split", "(", "\"/\"", ")", "\n", "\n", "# Ignore the gradients applied by the LAMB/ADAM optimizers.", "\n", "if", "\"adam_m\"", "in", "name", "or", "\"adam_v\"", "in", "name", "or", "\"global_step\"", "in", "name", ":", "\n", "            ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "\n", "", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r\"[A-Za-z]+_\\d+\"", ",", "m_name", ")", ":", "\n", "                ", "scope_names", "=", "re", ".", "split", "(", "r\"_(\\d+)\"", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "scope_names", "=", "[", "m_name", "]", "\n", "\n", "", "if", "scope_names", "[", "0", "]", "==", "\"kernel\"", "or", "scope_names", "[", "0", "]", "==", "\"gamma\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"output_bias\"", "or", "scope_names", "[", "0", "]", "==", "\"beta\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"bias\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"output_weights\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"squad\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"classifier\"", ")", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "", "if", "len", "(", "scope_names", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "scope_names", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "\n", "", "", "if", "m_name", "[", "-", "11", ":", "]", "==", "\"_embeddings\"", ":", "\n", "            ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "m_name", "==", "\"kernel\"", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "print", "(", "\"Initialize PyTorch weight {} from {}\"", ".", "format", "(", "name", ",", "original_name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFAttention.__init__": [[60, 77], ["super().__init__", "modeling_tf_utils.TFConv1D", "modeling_tf_utils.TFConv1D", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dropout", "set"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFAttention", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "c_attn", "=", "TFConv1D", "(", "n_state", "*", "3", ",", "nx", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"c_attn\"", ")", "\n", "self", ".", "c_proj", "=", "TFConv1D", "(", "n_state", ",", "nx", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"c_proj\"", ")", "\n", "self", ".", "attn_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFAttention.prune_heads": [[78, 80], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFAttention.causal_attention_mask": [[81, 90], ["tensorflow.range", "tensorflow.cast", "tensorflow.range"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "causal_attention_mask", "(", "nd", ",", "ns", ",", "dtype", ")", ":", "\n", "        ", "\"\"\"1's in the lower triangle, counting from the lower right corner.\n        Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n        \"\"\"", "\n", "i", "=", "tf", ".", "range", "(", "nd", ")", "[", ":", ",", "None", "]", "\n", "j", "=", "tf", ".", "range", "(", "ns", ")", "\n", "m", "=", "i", ">=", "j", "-", "ns", "+", "nd", "\n", "return", "tf", ".", "cast", "(", "m", ",", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFAttention._attn": [[91, 120], ["tensorflow.matmul", "modeling_tf_utils.shape_list", "modeling_tf_gpt2.TFAttention.causal_attention_mask", "tensorflow.reshape", "tensorflow.nn.softmax", "modeling_tf_gpt2.TFAttention.attn_dropout", "tensorflow.cast", "tensorflow.matmul", "outputs.append", "tensorflow.math.sqrt", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFAttention.causal_attention_mask", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "_attn", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "q", ",", "k", ",", "v", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "# q, k, v have shape [batch, heads, sequence, features]", "\n", "w", "=", "tf", ".", "matmul", "(", "q", ",", "k", ",", "transpose_b", "=", "True", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "dk", "=", "tf", ".", "cast", "(", "shape_list", "(", "k", ")", "[", "-", "1", "]", ",", "tf", ".", "float32", ")", "# scale attention_scores", "\n", "w", "=", "w", "/", "tf", ".", "math", ".", "sqrt", "(", "dk", ")", "\n", "\n", "# w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.", "\n", "", "_", ",", "_", ",", "nd", ",", "ns", "=", "shape_list", "(", "w", ")", "\n", "b", "=", "self", ".", "causal_attention_mask", "(", "nd", ",", "ns", ",", "dtype", "=", "w", ".", "dtype", ")", "\n", "b", "=", "tf", ".", "reshape", "(", "b", ",", "[", "1", ",", "1", ",", "nd", ",", "ns", "]", ")", "\n", "w", "=", "w", "*", "b", "-", "1e4", "*", "(", "1", "-", "b", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "            ", "w", "=", "w", "+", "attention_mask", "\n", "\n", "", "w", "=", "tf", ".", "nn", ".", "softmax", "(", "w", ",", "axis", "=", "-", "1", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ",", "training", "=", "training", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "w", "=", "w", "*", "head_mask", "\n", "\n", "", "outputs", "=", "[", "tf", ".", "matmul", "(", "w", ",", "v", ")", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "w", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFAttention.merge_heads": [[121, 126], ["tensorflow.transpose", "modeling_tf_utils.shape_list", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "tf", ".", "transpose", "(", "x", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "x_shape", "=", "shape_list", "(", "x", ")", "\n", "new_x_shape", "=", "x_shape", "[", ":", "-", "2", "]", "+", "[", "x_shape", "[", "-", "2", "]", "*", "x_shape", "[", "-", "1", "]", "]", "\n", "return", "tf", ".", "reshape", "(", "x", ",", "new_x_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFAttention.split_heads": [[127, 132], ["modeling_tf_utils.shape_list", "tensorflow.reshape", "tensorflow.transpose"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "split_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x_shape", "=", "shape_list", "(", "x", ")", "\n", "new_x_shape", "=", "x_shape", "[", ":", "-", "1", "]", "+", "[", "self", ".", "n_head", ",", "x_shape", "[", "-", "1", "]", "//", "self", ".", "n_head", "]", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "new_x_shape", ")", "\n", "return", "tf", ".", "transpose", "(", "x", ",", "(", "0", ",", "2", ",", "1", ",", "3", ")", ")", "# (batch, head, seq_length, head_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFAttention.call": [[133, 156], ["modeling_tf_gpt2.TFAttention.c_attn", "tensorflow.split", "modeling_tf_gpt2.TFAttention.split_heads", "modeling_tf_gpt2.TFAttention.split_heads", "modeling_tf_gpt2.TFAttention.split_heads", "tensorflow.stack", "modeling_tf_gpt2.TFAttention._attn", "modeling_tf_gpt2.TFAttention.merge_heads", "modeling_tf_gpt2.TFAttention.c_proj", "modeling_tf_gpt2.TFAttention.resid_dropout", "tensorflow.unstack", "tensorflow.concat", "tensorflow.concat"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention._attn", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.merge_heads"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", ",", "layer_past", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "tf", ".", "split", "(", "x", ",", "3", ",", "axis", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "if", "layer_past", "is", "not", "None", ":", "\n", "            ", "past_key", ",", "past_value", "=", "tf", ".", "unstack", "(", "layer_past", ",", "axis", "=", "1", ")", "\n", "key", "=", "tf", ".", "concat", "(", "[", "past_key", ",", "key", "]", ",", "axis", "=", "-", "2", ")", "\n", "value", "=", "tf", ".", "concat", "(", "[", "past_value", ",", "value", "]", ",", "axis", "=", "-", "2", ")", "\n", "", "present", "=", "tf", ".", "stack", "(", "[", "key", ",", "value", "]", ",", "axis", "=", "1", ")", "\n", "\n", "attn_outputs", "=", "self", ".", "_attn", "(", "[", "query", ",", "key", ",", "value", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ",", "training", "=", "training", ")", "\n", "\n", "outputs", "=", "[", "a", ",", "present", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "# a, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFMLP.__init__": [[159, 166], ["super().__init__", "modeling_tf_utils.TFConv1D", "modeling_tf_utils.TFConv1D", "tensorflow.keras.layers.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFMLP", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "TFConv1D", "(", "n_state", ",", "nx", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"c_fc\"", ")", "\n", "self", ".", "c_proj", "=", "TFConv1D", "(", "nx", ",", "n_state", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"c_proj\"", ")", "\n", "self", ".", "act", "=", "gelu", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFMLP.call": [[167, 172], ["modeling_tf_gpt2.TFMLP.act", "modeling_tf_gpt2.TFMLP.c_proj", "modeling_tf_gpt2.TFMLP.dropout", "modeling_tf_gpt2.TFMLP.c_fc"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "x", ",", "training", "=", "False", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "h2", "=", "self", ".", "dropout", "(", "h2", ",", "training", "=", "training", ")", "\n", "return", "h2", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFBlock.__init__": [[175, 182], ["super().__init__", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_gpt2.TFAttention", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_gpt2.TFMLP"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFBlock", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "ln_1", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "\"ln_1\"", ")", "\n", "self", ".", "attn", "=", "TFAttention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ",", "name", "=", "\"attn\"", ")", "\n", "self", ".", "ln_2", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "\"ln_2\"", ")", "\n", "self", ".", "mlp", "=", "TFMLP", "(", "4", "*", "nx", ",", "config", ",", "name", "=", "\"mlp\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFBlock.call": [[183, 197], ["modeling_tf_gpt2.TFBlock.ln_1", "modeling_tf_gpt2.TFBlock.attn", "modeling_tf_gpt2.TFBlock.ln_2", "modeling_tf_gpt2.TFBlock.mlp"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "x", ",", "layer_past", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "a", "=", "self", ".", "ln_1", "(", "x", ")", "\n", "output_attn", "=", "self", ".", "attn", "(", "[", "a", ",", "layer_past", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "a", "=", "output_attn", "[", "0", "]", "# output_attn: a, present, (attentions)", "\n", "x", "=", "x", "+", "a", "\n", "\n", "m", "=", "self", ".", "ln_2", "(", "x", ")", "\n", "m", "=", "self", ".", "mlp", "(", "m", ",", "training", "=", "training", ")", "\n", "x", "=", "x", "+", "m", "\n", "\n", "outputs", "=", "[", "x", "]", "+", "output_attn", "[", "1", ":", "]", "\n", "return", "outputs", "# x, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFGPT2MainLayer.__init__": [[200, 220], ["super().__init__", "modeling_tf_utils.TFSharedEmbeddings", "tensorflow.keras.layers.Embedding", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.LayerNormalization", "modeling_tf_gpt2.TFBlock", "modeling_tf_utils.get_initializer", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFGPT2MainLayer", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "num_hidden_layers", "=", "config", ".", "n_layer", "\n", "self", ".", "vocab_size", "=", "config", ".", "vocab_size", "\n", "self", ".", "n_embd", "=", "config", ".", "n_embd", "\n", "\n", "self", ".", "wte", "=", "TFSharedEmbeddings", "(", "\n", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"wte\"", "\n", ")", "\n", "self", ".", "wpe", "=", "tf", ".", "keras", ".", "layers", ".", "Embedding", "(", "\n", "config", ".", "n_positions", ",", "\n", "config", ".", "n_embd", ",", "\n", "embeddings_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "\n", "name", "=", "\"wpe\"", ",", "\n", ")", "\n", "self", ".", "drop", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "[", "TFBlock", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ",", "name", "=", "\"h_._{}\"", ".", "format", "(", "i", ")", ")", "for", "i", "in", "range", "(", "config", ".", "n_layer", ")", "]", "\n", "self", ".", "ln_f", "=", "tf", ".", "keras", ".", "layers", ".", "LayerNormalization", "(", "epsilon", "=", "config", ".", "layer_norm_epsilon", ",", "name", "=", "\"ln_f\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFGPT2MainLayer.get_input_embeddings": [[221, 223], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wte", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFGPT2MainLayer._resize_token_embeddings": [[224, 226], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFGPT2MainLayer._prune_heads": [[227, 232], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFGPT2MainLayer.call": [[233, 359], ["isinstance", "tensorflow.reshape", "modeling_tf_gpt2.TFGPT2MainLayer.wpe", "modeling_tf_gpt2.TFGPT2MainLayer.drop", "enumerate", "modeling_tf_gpt2.TFGPT2MainLayer.ln_f", "tensorflow.reshape", "isinstance", "ValueError", "tensorflow.cast", "modeling_tf_gpt2.TFGPT2MainLayer.wte", "tensorflow.reshape", "modeling_tf_gpt2.TFGPT2MainLayer.wte", "zip", "block", "tuple", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "modeling_tf_utils.shape_list", "tensorflow.reshape", "len", "modeling_tf_utils.shape_list", "tensorflow.range", "tuple.append", "len", "len", "len", "len", "len", "len", "len", "ValueError", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "tensorflow.reshape", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "\n", "self", ",", "\n", "inputs", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "training", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "past", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "past", "\n", "attention_mask", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "head_mask", "\n", "inputs_embeds", "=", "inputs", "[", "6", "]", "if", "len", "(", "inputs", ")", ">", "6", "else", "inputs_embeds", "\n", "assert", "len", "(", "inputs", ")", "<=", "7", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "\"input_ids\"", ")", "\n", "past", "=", "inputs", ".", "get", "(", "\"past\"", ",", "past", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "\"attention_mask\"", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "\"token_type_ids\"", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "\"position_ids\"", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "\"head_mask\"", ",", "head_mask", ")", "\n", "inputs_embeds", "=", "inputs", ".", "get", "(", "\"inputs_embeds\"", ",", "inputs_embeds", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "7", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "input_ids", ")", "\n", "input_ids", "=", "tf", ".", "reshape", "(", "input_ids", ",", "[", "-", "1", ",", "input_shape", "[", "-", "1", "]", "]", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "shape_list", "(", "inputs_embeds", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "past", "is", "None", ":", "\n", "            ", "past_length", "=", "0", "\n", "past", "=", "[", "None", "]", "*", "len", "(", "self", ".", "h", ")", "\n", "", "else", ":", "\n", "            ", "past_length", "=", "shape_list", "(", "past", "[", "0", "]", "[", "0", "]", ")", "[", "-", "2", "]", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "tf", ".", "range", "(", "past_length", ",", "input_shape", "[", "-", "1", "]", "+", "past_length", ",", "dtype", "=", "tf", ".", "int32", ")", "[", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "            ", "attention_mask", "=", "attention_mask", "[", ":", ",", "tf", ".", "newaxis", ",", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "\n", "attention_mask", "=", "tf", ".", "cast", "(", "attention_mask", ",", "tf", ".", "float32", ")", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "", "else", ":", "\n", "            ", "attention_mask", "=", "None", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "num_hidden_layers", "\n", "# head_mask = tf.constant([0] * self.num_hidden_layers)", "\n", "\n", "", "position_ids", "=", "tf", ".", "reshape", "(", "position_ids", ",", "[", "-", "1", ",", "shape_list", "(", "position_ids", ")", "[", "-", "1", "]", "]", ")", "\n", "\n", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "wte", "(", "input_ids", ",", "mode", "=", "\"embedding\"", ")", "\n", "", "position_embeds", "=", "self", ".", "wpe", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "tf", ".", "reshape", "(", "token_type_ids", ",", "[", "-", "1", ",", "shape_list", "(", "token_type_ids", ")", "[", "-", "1", "]", "]", ")", "\n", "token_type_embeds", "=", "self", ".", "wte", "(", "token_type_ids", ",", "mode", "=", "\"embedding\"", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "hidden_states", "=", "self", ".", "drop", "(", "hidden_states", ",", "training", "=", "training", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "[", "shape_list", "(", "hidden_states", ")", "[", "-", "1", "]", "]", "\n", "\n", "presents", "=", "(", ")", "\n", "all_attentions", "=", "[", "]", "\n", "all_hidden_states", "=", "(", ")", "\n", "for", "i", ",", "(", "block", ",", "layer_past", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "h", ",", "past", ")", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "tf", ".", "reshape", "(", "hidden_states", ",", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "block", "(", "[", "hidden_states", ",", "layer_past", ",", "attention_mask", ",", "head_mask", "[", "i", "]", "]", ",", "training", "=", "training", ")", "\n", "\n", "hidden_states", ",", "present", "=", "outputs", "[", ":", "2", "]", "\n", "presents", "=", "presents", "+", "(", "present", ",", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "ln_f", "(", "hidden_states", ")", "\n", "\n", "hidden_states", "=", "tf", ".", "reshape", "(", "hidden_states", ",", "output_shape", ")", "\n", "# Add last hidden state", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", "presents", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# let the number of heads free (-1) so we can extract attention even after head pruning", "\n", "            ", "attention_output_shape", "=", "input_shape", "[", ":", "-", "1", "]", "+", "[", "-", "1", "]", "+", "shape_list", "(", "all_attentions", "[", "0", "]", ")", "[", "-", "2", ":", "]", "\n", "all_attentions", "=", "tuple", "(", "tf", ".", "reshape", "(", "t", ",", "attention_output_shape", ")", "for", "t", "in", "all_attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last hidden state, presents, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFGPT2Model.__init__": [[477, 480], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_gpt2.TFGPT2MainLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFGPT2Model", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFGPT2MainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFGPT2Model.call": [[481, 484], ["modeling_tf_gpt2.TFGPT2Model.transformer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFGPT2LMHeadModel.__init__": [[523, 526], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_gpt2.TFGPT2MainLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFGPT2LMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFGPT2MainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFGPT2LMHeadModel.get_output_embeddings": [[527, 529], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "transformer", ".", "wte", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFGPT2LMHeadModel.call": [[530, 539], ["modeling_tf_gpt2.TFGPT2LMHeadModel.transformer", "modeling_tf_gpt2.TFGPT2LMHeadModel.transformer.wte"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "transformer", ".", "wte", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "# lm_logits, presents, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFGPT2DoubleHeadsModel.__init__": [[600, 606], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_gpt2.TFGPT2MainLayer", "modeling_tf_utils.TFSequenceSummary"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFGPT2DoubleHeadsModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "config", ".", "num_labels", "=", "1", "\n", "self", ".", "transformer", "=", "TFGPT2MainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "self", ".", "multiple_choice_head", "=", "TFSequenceSummary", "(", "\n", "config", ",", "initializer_range", "=", "config", ".", "initializer_range", ",", "name", "=", "\"multiple_choice_head\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFGPT2DoubleHeadsModel.get_output_embeddings": [[608, 610], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "transformer", ".", "wte", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.TFGPT2DoubleHeadsModel.call": [[611, 681], ["isinstance", "modeling_tf_gpt2.TFGPT2DoubleHeadsModel.transformer", "tensorflow.reshape", "modeling_tf_gpt2.TFGPT2DoubleHeadsModel.transformer.wte", "modeling_tf_gpt2.TFGPT2DoubleHeadsModel.multiple_choice_head", "tensorflow.squeeze", "isinstance", "modeling_tf_utils.shape_list", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "modeling_tf_utils.shape_list", "len", "len", "len", "len", "len", "len", "len", "len", "modeling_tf_utils.shape_list"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "\n", "self", ",", "\n", "inputs", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "mc_token_ids", "=", "None", ",", "\n", "training", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "past", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "past", "\n", "attention_mask", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "5", "]", "if", "len", "(", "inputs", ")", ">", "5", "else", "head_mask", "\n", "inputs_embeds", "=", "inputs", "[", "6", "]", "if", "len", "(", "inputs", ")", ">", "6", "else", "inputs_embeds", "\n", "mc_token_ids", "=", "inputs", "[", "7", "]", "if", "len", "(", "inputs", ")", ">", "7", "else", "mc_token_ids", "\n", "assert", "len", "(", "inputs", ")", "<=", "8", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "\"input_ids\"", ")", "\n", "past", "=", "inputs", ".", "get", "(", "\"past\"", ",", "past", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "\"attention_mask\"", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "\"token_type_ids\"", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "\"position_ids\"", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "\"head_mask\"", ",", "head_mask", ")", "\n", "inputs_embeds", "=", "inputs", ".", "get", "(", "\"inputs_embeds\"", ",", "inputs_embeds", ")", "\n", "mc_token_ids", "=", "inputs", ".", "get", "(", "\"mc_token_ids\"", ",", "mc_token_ids", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "8", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shapes", "=", "shape_list", "(", "input_ids", ")", "\n", "", "else", ":", "\n", "            ", "input_shapes", "=", "shape_list", "(", "inputs_embeds", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "seq_length", "=", "input_shapes", "[", "-", "1", "]", "\n", "\n", "flat_input_ids", "=", "tf", ".", "reshape", "(", "input_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "input_ids", "is", "not", "None", "else", "None", "\n", "flat_attention_mask", "=", "tf", ".", "reshape", "(", "attention_mask", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "flat_token_type_ids", "=", "tf", ".", "reshape", "(", "token_type_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_position_ids", "=", "tf", ".", "reshape", "(", "position_ids", ",", "(", "-", "1", ",", "seq_length", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "\n", "flat_inputs", "=", "[", "\n", "flat_input_ids", ",", "\n", "past", ",", "\n", "flat_attention_mask", ",", "\n", "flat_token_type_ids", ",", "\n", "flat_position_ids", ",", "\n", "head_mask", ",", "\n", "inputs_embeds", ",", "\n", "]", "\n", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "flat_inputs", ",", "training", "=", "training", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "hidden_states", "=", "tf", ".", "reshape", "(", "hidden_states", ",", "input_shapes", "+", "shape_list", "(", "hidden_states", ")", "[", "-", "1", ":", "]", ")", "\n", "\n", "lm_logits", "=", "self", ".", "transformer", ".", "wte", "(", "hidden_states", ",", "mode", "=", "\"linear\"", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "[", "hidden_states", ",", "mc_token_ids", "]", ",", "training", "=", "training", ")", "\n", "\n", "mc_logits", "=", "tf", ".", "squeeze", "(", "mc_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", "mc_logits", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "\n", "return", "outputs", "# lm logits, mc logits, presents, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_gpt2.gelu": [[46, 57], ["tensorflow.tanh", "numpy.sqrt", "tensorflow.pow"], "function", ["None"], ["def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"Gaussian Error Linear Unit.\n    This is a smoother version of the RELU.\n    Original paper: https://arxiv.org/abs/1606.08415\n    Args:\n        x: float Tensor to perform activation.\n    Returns:\n        `x` with the GELU activation applied.\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "tf", ".", "tanh", "(", "(", "np", ".", "sqrt", "(", "2", "/", "np", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "tf", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_mmbt.MMBTConfig.__init__": [[34, 39], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "config", ",", "num_labels", "=", "None", ",", "modal_hidden_size", "=", "2048", ")", ":", "\n", "        ", "self", ".", "__dict__", "=", "config", ".", "__dict__", "\n", "self", ".", "modal_hidden_size", "=", "modal_hidden_size", "\n", "if", "num_labels", ":", "\n", "            ", "self", ".", "num_labels", "=", "num_labels", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_roberta.RobertaTokenizer.__init__": [[73, 102], ["tokenization_gpt2.GPT2Tokenizer.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "merges_file", ",", "\n", "errors", "=", "\"replace\"", ",", "\n", "bos_token", "=", "\"<s>\"", ",", "\n", "eos_token", "=", "\"</s>\"", ",", "\n", "sep_token", "=", "\"</s>\"", ",", "\n", "cls_token", "=", "\"<s>\"", ",", "\n", "unk_token", "=", "\"<unk>\"", ",", "\n", "pad_token", "=", "\"<pad>\"", ",", "\n", "mask_token", "=", "\"<mask>\"", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "RobertaTokenizer", ",", "self", ")", ".", "__init__", "(", "\n", "vocab_file", "=", "vocab_file", ",", "\n", "merges_file", "=", "merges_file", ",", "\n", "errors", "=", "errors", ",", "\n", "bos_token", "=", "bos_token", ",", "\n", "eos_token", "=", "eos_token", ",", "\n", "unk_token", "=", "unk_token", ",", "\n", "sep_token", "=", "sep_token", ",", "\n", "cls_token", "=", "cls_token", ",", "\n", "pad_token", "=", "pad_token", ",", "\n", "mask_token", "=", "mask_token", ",", "\n", "**", "kwargs", "\n", ")", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "-", "2", "# take into account special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "-", "4", "# take into account special tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_roberta.RobertaTokenizer.build_inputs_with_special_tokens": [[103, 116], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n        by concatenating and adding special tokens.\n        A RoBERTa sequence has the following format:\n            single sequence: <s> X </s>\n            pair of sequences: <s> A </s></s> B </s>\n        \"\"\"", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "[", "self", ".", "cls_token_id", "]", "+", "token_ids_0", "+", "[", "self", ".", "sep_token_id", "]", "\n", "", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "return", "cls", "+", "token_ids_0", "+", "sep", "+", "sep", "+", "token_ids_1", "+", "sep", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_roberta.RobertaTokenizer.get_special_tokens_mask": [[117, 143], ["list", "ValueError", "map", "len", "len", "len"], "methods", ["None"], ["", "def", "get_special_tokens_mask", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ",", "already_has_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n\n        Args:\n            token_ids_0: list of ids (must not contain special tokens)\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n                for sequence pairs\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n                special tokens for the model\n\n        Returns:\n            A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.\n        \"\"\"", "\n", "if", "already_has_special_tokens", ":", "\n", "            ", "if", "token_ids_1", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"You should not supply a second sequence if the provided sequence of \"", "\n", "\"ids is already formated with special tokens for the model.\"", "\n", ")", "\n", "", "return", "list", "(", "map", "(", "lambda", "x", ":", "1", "if", "x", "in", "[", "self", ".", "sep_token_id", ",", "self", ".", "cls_token_id", "]", "else", "0", ",", "token_ids_0", ")", ")", "\n", "\n", "", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "\n", "", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", ",", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_1", ")", ")", "+", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_roberta.RobertaTokenizer.create_token_type_ids_from_sequences": [[144, 159], ["len", "len", "len"], "methods", ["None"], ["", "def", "create_token_type_ids_from_sequences", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n        A RoBERTa sequence pair mask has the following format:\n        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n        | first sequence    | second sequence\n\n        if token_ids_1 is None, only returns the first portion of the mask (0's).\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "\n", "", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", "+", "sep", ")", "*", "[", "0", "]", "+", "len", "(", "token_ids_1", "+", "sep", ")", "*", "[", "1", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_pytorch_checkpoint_to_tf2.convert_pt_checkpoint_to_tf": [[283, 328], ["config_class.from_json_file", "print", "model_class", "transformers.load_pytorch_checkpoint_in_tf2_model", "print", "transformers.load_pytorch_checkpoint_in_tf2_model.save_weights", "ValueError", "transformers.cached_path", "transformers.cached_path", "transformers.load_pytorch_checkpoint_in_tf2_model.", "torch.load", "pt_model_class.from_pretrained", "pto[].numpy", "tfo[].numpy", "np.amax", "print", "str", "torch.no_grad", "pt_model_class.from_pretrained.", "np.abs", "list", "MODEL_CLASSES.keys"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_pytorch_checkpoint_in_tf2_model", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["def", "convert_pt_checkpoint_to_tf", "(", "\n", "model_type", ",", "pytorch_checkpoint_path", ",", "config_file", ",", "tf_dump_path", ",", "compare_with_pt_model", "=", "False", ",", "use_cached_models", "=", "True", "\n", ")", ":", "\n", "    ", "if", "model_type", "not", "in", "MODEL_CLASSES", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unrecognized model type, should be one of {}.\"", ".", "format", "(", "list", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", ")", "\n", "\n", "", "config_class", ",", "model_class", ",", "pt_model_class", ",", "aws_model_maps", ",", "aws_config_map", "=", "MODEL_CLASSES", "[", "model_type", "]", "\n", "\n", "# Initialise TF model", "\n", "if", "config_file", "in", "aws_config_map", ":", "\n", "        ", "config_file", "=", "cached_path", "(", "aws_config_map", "[", "config_file", "]", ",", "force_download", "=", "not", "use_cached_models", ")", "\n", "", "config", "=", "config_class", ".", "from_json_file", "(", "config_file", ")", "\n", "config", ".", "output_hidden_states", "=", "True", "\n", "config", ".", "output_attentions", "=", "True", "\n", "print", "(", "\"Building TensorFlow model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "tf_model", "=", "model_class", "(", "config", ")", "\n", "\n", "# Load weights from tf checkpoint", "\n", "if", "pytorch_checkpoint_path", "in", "aws_model_maps", ":", "\n", "        ", "pytorch_checkpoint_path", "=", "cached_path", "(", "\n", "aws_model_maps", "[", "pytorch_checkpoint_path", "]", ",", "force_download", "=", "not", "use_cached_models", "\n", ")", "\n", "# Load PyTorch checkpoint in tf2 model:", "\n", "", "tf_model", "=", "load_pytorch_checkpoint_in_tf2_model", "(", "tf_model", ",", "pytorch_checkpoint_path", ")", "\n", "\n", "if", "compare_with_pt_model", ":", "\n", "        ", "tfo", "=", "tf_model", "(", "tf_model", ".", "dummy_inputs", ",", "training", "=", "False", ")", "# build the network", "\n", "\n", "state_dict", "=", "torch", ".", "load", "(", "pytorch_checkpoint_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "pt_model", "=", "pt_model_class", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", "=", "None", ",", "config", "=", "config", ",", "state_dict", "=", "state_dict", "\n", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pto", "=", "pt_model", "(", "**", "pt_model", ".", "dummy_inputs", ")", "\n", "\n", "", "np_pt", "=", "pto", "[", "0", "]", ".", "numpy", "(", ")", "\n", "np_tf", "=", "tfo", "[", "0", "]", ".", "numpy", "(", ")", "\n", "diff", "=", "np", ".", "amax", "(", "np", ".", "abs", "(", "np_pt", "-", "np_tf", ")", ")", "\n", "print", "(", "\"Max absolute difference between models outputs {}\"", ".", "format", "(", "diff", ")", ")", "\n", "assert", "diff", "<=", "2e-2", ",", "\"Error, model absolute difference is >2e-2: {}\"", ".", "format", "(", "diff", ")", "\n", "\n", "# Save pytorch-model", "\n", "", "print", "(", "\"Save TensorFlow model to {}\"", ".", "format", "(", "tf_dump_path", ")", ")", "\n", "tf_model", ".", "save_weights", "(", "tf_dump_path", ",", "save_format", "=", "\"h5\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_pytorch_checkpoint_to_tf2.convert_all_pt_checkpoints_to_tf": [[330, 405], ["os.path.isdir", "enumerate", "list", "print", "print", "print", "enumerate", "MODEL_CLASSES.keys", "ValueError", "list", "zip", "print", "print", "print", "os.path.isfile", "convert_pytorch_checkpoint_to_tf2.convert_pt_checkpoint_to_tf", "len", "aws_model_maps.keys", "transformers.cached_path", "transformers.cached_path", "transformers.cached_path", "transformers.cached_path", "os.remove", "os.remove", "list", "print", "print", "len", "os.path.join", "MODEL_CLASSES.keys"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_pytorch_checkpoint_to_tf2.convert_pt_checkpoint_to_tf", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.cached_path", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.cached_path"], ["", "def", "convert_all_pt_checkpoints_to_tf", "(", "\n", "args_model_type", ",", "\n", "tf_dump_path", ",", "\n", "model_shortcut_names_or_path", "=", "None", ",", "\n", "config_shortcut_names_or_path", "=", "None", ",", "\n", "compare_with_pt_model", "=", "False", ",", "\n", "use_cached_models", "=", "False", ",", "\n", "remove_cached_files", "=", "False", ",", "\n", "only_convert_finetuned_models", "=", "False", ",", "\n", ")", ":", "\n", "    ", "assert", "os", ".", "path", ".", "isdir", "(", "args", ".", "tf_dump_path", ")", ",", "\"--tf_dump_path should be a directory\"", "\n", "\n", "if", "args_model_type", "is", "None", ":", "\n", "        ", "model_types", "=", "list", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_types", "=", "[", "args_model_type", "]", "\n", "\n", "", "for", "j", ",", "model_type", "in", "enumerate", "(", "model_types", ",", "start", "=", "1", ")", ":", "\n", "        ", "print", "(", "\"=\"", "*", "100", ")", "\n", "print", "(", "\" Converting model type {}/{}: {}\"", ".", "format", "(", "j", ",", "len", "(", "model_types", ")", ",", "model_type", ")", ")", "\n", "print", "(", "\"=\"", "*", "100", ")", "\n", "if", "model_type", "not", "in", "MODEL_CLASSES", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Unrecognized model type {}, should be one of {}.\"", ".", "format", "(", "model_type", ",", "list", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", "\n", ")", "\n", "\n", "", "config_class", ",", "model_class", ",", "pt_model_class", ",", "aws_model_maps", ",", "aws_config_map", "=", "MODEL_CLASSES", "[", "model_type", "]", "\n", "\n", "if", "model_shortcut_names_or_path", "is", "None", ":", "\n", "            ", "model_shortcut_names_or_path", "=", "list", "(", "aws_model_maps", ".", "keys", "(", ")", ")", "\n", "", "if", "config_shortcut_names_or_path", "is", "None", ":", "\n", "            ", "config_shortcut_names_or_path", "=", "model_shortcut_names_or_path", "\n", "\n", "", "for", "i", ",", "(", "model_shortcut_name", ",", "config_shortcut_name", ")", "in", "enumerate", "(", "\n", "zip", "(", "model_shortcut_names_or_path", ",", "config_shortcut_names_or_path", ")", ",", "start", "=", "1", "\n", ")", ":", "\n", "            ", "print", "(", "\"-\"", "*", "100", ")", "\n", "if", "\"-squad\"", "in", "model_shortcut_name", "or", "\"-mrpc\"", "in", "model_shortcut_name", "or", "\"-mnli\"", "in", "model_shortcut_name", ":", "\n", "                ", "if", "not", "only_convert_finetuned_models", ":", "\n", "                    ", "print", "(", "\"    Skipping finetuned checkpoint {}\"", ".", "format", "(", "model_shortcut_name", ")", ")", "\n", "continue", "\n", "", "model_type", "=", "model_shortcut_name", "\n", "", "elif", "only_convert_finetuned_models", ":", "\n", "                ", "print", "(", "\"    Skipping not finetuned checkpoint {}\"", ".", "format", "(", "model_shortcut_name", ")", ")", "\n", "continue", "\n", "", "print", "(", "\n", "\"    Converting checkpoint {}/{}: {} - model_type {}\"", ".", "format", "(", "\n", "i", ",", "len", "(", "aws_config_map", ")", ",", "model_shortcut_name", ",", "model_type", "\n", ")", "\n", ")", "\n", "print", "(", "\"-\"", "*", "100", ")", "\n", "\n", "if", "config_shortcut_name", "in", "aws_config_map", ":", "\n", "                ", "config_file", "=", "cached_path", "(", "aws_config_map", "[", "config_shortcut_name", "]", ",", "force_download", "=", "not", "use_cached_models", ")", "\n", "", "else", ":", "\n", "                ", "config_file", "=", "cached_path", "(", "config_shortcut_name", ",", "force_download", "=", "not", "use_cached_models", ")", "\n", "\n", "", "if", "model_shortcut_name", "in", "aws_model_maps", ":", "\n", "                ", "model_file", "=", "cached_path", "(", "aws_model_maps", "[", "model_shortcut_name", "]", ",", "force_download", "=", "not", "use_cached_models", ")", "\n", "", "else", ":", "\n", "                ", "model_file", "=", "cached_path", "(", "model_shortcut_name", ",", "force_download", "=", "not", "use_cached_models", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "model_shortcut_name", ")", ":", "\n", "                ", "model_shortcut_name", "=", "\"converted_model\"", "\n", "\n", "", "convert_pt_checkpoint_to_tf", "(", "\n", "model_type", "=", "model_type", ",", "\n", "pytorch_checkpoint_path", "=", "model_file", ",", "\n", "config_file", "=", "config_file", ",", "\n", "tf_dump_path", "=", "os", ".", "path", ".", "join", "(", "tf_dump_path", ",", "model_shortcut_name", "+", "\"-tf_model.h5\"", ")", ",", "\n", "compare_with_pt_model", "=", "compare_with_pt_model", ",", "\n", ")", "\n", "if", "remove_cached_files", ":", "\n", "                ", "os", ".", "remove", "(", "config_file", ")", "\n", "os", ".", "remove", "(", "model_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_bert_pytorch_checkpoint_to_original_tf.convert_pytorch_checkpoint_to_tf": [[28, 90], ["model.state_dict", "tensorflow.reset_default_graph", "os.path.isdir", "os.makedirs", "iter", "tensorflow.dtypes.as_dtype", "tensorflow.get_variable", "session.run", "session.run", "tensorflow.Session", "tensorflow.train.Saver", "tf.train.Saver.save", "name.replace.replace", "tensorflow.variables_initializer", "convert_bert_pytorch_checkpoint_to_original_tf.convert_pytorch_checkpoint_to_tf.to_tf_var_name"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.__init__.BaseTransformersCLICommand.run", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.__init__.BaseTransformersCLICommand.run", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save"], ["def", "convert_pytorch_checkpoint_to_tf", "(", "model", ":", "BertModel", ",", "ckpt_dir", ":", "str", ",", "model_name", ":", "str", ")", ":", "\n", "\n", "    ", "\"\"\"\n    :param model:BertModel Pytorch model instance to be converted\n    :param ckpt_dir: Tensorflow model directory\n    :param model_name: model name\n    :return:\n\n    Currently supported HF models:\n        Y BertModel\n        N BertForMaskedLM\n        N BertForPreTraining\n        N BertForMultipleChoice\n        N BertForNextSentencePrediction\n        N BertForSequenceClassification\n        N BertForQuestionAnswering\n    \"\"\"", "\n", "\n", "tensors_to_transpose", "=", "(", "\"dense.weight\"", ",", "\"attention.self.query\"", ",", "\"attention.self.key\"", ",", "\"attention.self.value\"", ")", "\n", "\n", "var_map", "=", "(", "\n", "(", "\"layer.\"", ",", "\"layer_\"", ")", ",", "\n", "(", "\"word_embeddings.weight\"", ",", "\"word_embeddings\"", ")", ",", "\n", "(", "\"position_embeddings.weight\"", ",", "\"position_embeddings\"", ")", ",", "\n", "(", "\"token_type_embeddings.weight\"", ",", "\"token_type_embeddings\"", ")", ",", "\n", "(", "\".\"", ",", "\"/\"", ")", ",", "\n", "(", "\"LayerNorm/weight\"", ",", "\"LayerNorm/gamma\"", ")", ",", "\n", "(", "\"LayerNorm/bias\"", ",", "\"LayerNorm/beta\"", ")", ",", "\n", "(", "\"weight\"", ",", "\"kernel\"", ")", ",", "\n", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "ckpt_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "ckpt_dir", ")", "\n", "\n", "", "state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "\n", "def", "to_tf_var_name", "(", "name", ":", "str", ")", ":", "\n", "        ", "for", "patt", ",", "repl", "in", "iter", "(", "var_map", ")", ":", "\n", "            ", "name", "=", "name", ".", "replace", "(", "patt", ",", "repl", ")", "\n", "", "return", "\"bert/{}\"", ".", "format", "(", "name", ")", "\n", "\n", "", "def", "create_tf_var", "(", "tensor", ":", "np", ".", "ndarray", ",", "name", ":", "str", ",", "session", ":", "tf", ".", "Session", ")", ":", "\n", "        ", "tf_dtype", "=", "tf", ".", "dtypes", ".", "as_dtype", "(", "tensor", ".", "dtype", ")", "\n", "tf_var", "=", "tf", ".", "get_variable", "(", "dtype", "=", "tf_dtype", ",", "shape", "=", "tensor", ".", "shape", ",", "name", "=", "name", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "session", ".", "run", "(", "tf", ".", "variables_initializer", "(", "[", "tf_var", "]", ")", ")", "\n", "session", ".", "run", "(", "tf_var", ")", "\n", "return", "tf_var", "\n", "\n", "", "tf", ".", "reset_default_graph", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "session", ":", "\n", "        ", "for", "var_name", "in", "state_dict", ":", "\n", "            ", "tf_name", "=", "to_tf_var_name", "(", "var_name", ")", "\n", "torch_tensor", "=", "state_dict", "[", "var_name", "]", ".", "numpy", "(", ")", "\n", "if", "any", "(", "[", "x", "in", "var_name", "for", "x", "in", "tensors_to_transpose", "]", ")", ":", "\n", "                ", "torch_tensor", "=", "torch_tensor", ".", "T", "\n", "", "tf_var", "=", "create_tf_var", "(", "tensor", "=", "torch_tensor", ",", "name", "=", "tf_name", ",", "session", "=", "session", ")", "\n", "tf", ".", "keras", ".", "backend", ".", "set_value", "(", "tf_var", ",", "torch_tensor", ")", "\n", "tf_weight", "=", "session", ".", "run", "(", "tf_var", ")", "\n", "print", "(", "\"Successfully created {}: {}\"", ".", "format", "(", "tf_name", ",", "np", ".", "allclose", "(", "tf_weight", ",", "torch_tensor", ")", ")", ")", "\n", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "saver", ".", "save", "(", "session", ",", "os", ".", "path", ".", "join", "(", "ckpt_dir", ",", "model_name", ".", "replace", "(", "\"-\"", ",", "\"_\"", ")", "+", "\".ckpt\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_bert_pytorch_checkpoint_to_original_tf.main": [[92, 109], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "transformers.BertModel.from_pretrained", "convert_bert_pytorch_checkpoint_to_original_tf.convert_pytorch_checkpoint_to_tf", "torch.load"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_bert_pytorch_checkpoint_to_original_tf.convert_pytorch_checkpoint_to_tf"], ["", "", "def", "main", "(", "raw_args", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"model name e.g. bert-base-uncased\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "required", "=", "False", ",", "help", "=", "\"Directory containing pytorch model\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--pytorch_model_path\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"/path/to/<pytorch-model-name>.bin\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tf_cache_dir\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"Directory in which to save tensorflow model\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "raw_args", ")", "\n", "\n", "model", "=", "BertModel", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", "=", "args", ".", "model_name", ",", "\n", "state_dict", "=", "torch", ".", "load", "(", "args", ".", "pytorch_model_path", ")", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", ",", "\n", ")", "\n", "\n", "convert_pytorch_checkpoint_to_tf", "(", "model", "=", "model", ",", "ckpt_dir", "=", "args", ".", "tf_cache_dir", ",", "model_name", "=", "args", ".", "model_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.__init__": [[129, 146], ["torch.Module.__init__", "modeling_openai.Attention.register_buffer", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "set", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "register_buffer", "(", "\"bias\"", ",", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "n_ctx", ",", "n_ctx", ")", ")", ".", "view", "(", "1", ",", "1", ",", "n_ctx", ",", "n_ctx", ")", ")", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "c_attn", "=", "Conv1D", "(", "n_state", "*", "3", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "attn_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads": [[147, 165], ["torch.ones", "torch.ones", "torch.ones", "torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_utils.prune_conv1d_layer", "modeling_utils.prune_conv1d_layer", "modeling_openai.Attention.pruned_heads.union", "len", "set", "sum", "len", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "len", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_conv1d_layer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "n_head", ",", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "\n", "for", "head", "in", "heads", ":", "\n", "            ", "head", "-=", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "index_attn", "=", "torch", ".", "cat", "(", "[", "index", ",", "index", "+", "self", ".", "split_size", ",", "index", "+", "(", "2", "*", "self", ".", "split_size", ")", "]", ")", "\n", "# Prune conv1d layers", "\n", "self", ".", "c_attn", "=", "prune_conv1d_layer", "(", "self", ".", "c_attn", ",", "index_attn", ",", "dim", "=", "1", ")", "\n", "self", ".", "c_proj", "=", "prune_conv1d_layer", "(", "self", ".", "c_proj", ",", "index", ",", "dim", "=", "0", ")", "\n", "# Update hyper params", "\n", "self", ".", "split_size", "=", "(", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "*", "(", "self", ".", "n_head", "-", "len", "(", "heads", ")", ")", "\n", "self", ".", "n_head", "=", "self", ".", "n_head", "-", "len", "(", "heads", ")", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention._attn": [[166, 190], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "modeling_openai.Attention.attn_dropout", "torch.Softmax", "torch.Softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "outputs.append", "math.sqrt", "v.size", "modeling_openai.Attention.size", "modeling_openai.Attention.size"], "methods", ["None"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "math", ".", "sqrt", "(", "v", ".", "size", "(", "-", "1", ")", ")", "\n", "# w = w * self.bias + -1e9 * (1 - self.bias)  # TF implem method: mask_attn_weights", "\n", "# XD: self.b may be larger than w, so we need to crop it", "\n", "", "b", "=", "self", ".", "bias", "[", ":", ",", ":", ",", ":", "w", ".", "size", "(", "-", "2", ")", ",", ":", "w", ".", "size", "(", "-", "1", ")", "]", "\n", "w", "=", "w", "*", "b", "+", "-", "1e4", "*", "(", "1", "-", "b", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "            ", "w", "=", "w", "+", "attention_mask", "\n", "\n", "", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "w", "=", "w", "*", "head_mask", "\n", "\n", "", "outputs", "=", "[", "torch", ".", "matmul", "(", "w", ",", "v", ")", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "w", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.merge_heads": [[191, 195], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["None"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.split_heads": [[196, 203], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.forward": [[204, 220], ["modeling_openai.Attention.c_attn", "modeling_openai.Attention.split", "modeling_openai.Attention.split_heads", "modeling_openai.Attention.split_heads", "modeling_openai.Attention.split_heads", "modeling_openai.Attention._attn", "modeling_openai.Attention.merge_heads", "modeling_openai.Attention.c_proj", "modeling_openai.Attention.resid_dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.split_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention._attn", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.merge_heads"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "x", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "\n", "attn_outputs", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ",", "attention_mask", ",", "head_mask", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ")", "\n", "\n", "outputs", "=", "[", "a", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "# a, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.MLP.__init__": [[223, 230], ["torch.Module.__init__", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "nx", ",", "n_state", ")", "\n", "self", ".", "act", "=", "ACT_FNS", "[", "config", ".", "afn", "]", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.MLP.forward": [[231, 235], ["modeling_openai.MLP.act", "modeling_openai.MLP.c_proj", "modeling_openai.MLP.dropout", "modeling_openai.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "return", "self", ".", "dropout", "(", "h2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Block.__init__": [[238, 245], ["torch.Module.__init__", "modeling_openai.Attention", "torch.LayerNorm", "torch.LayerNorm", "modeling_openai.MLP", "torch.LayerNorm", "torch.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", "Block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "attn", "=", "Attention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_1", "=", "nn", ".", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "4", "*", "nx", ",", "config", ")", "\n", "self", ".", "ln_2", "=", "nn", ".", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Block.forward": [[246, 256], ["modeling_openai.Block.attn", "modeling_openai.Block.ln_1", "modeling_openai.Block.mlp", "modeling_openai.Block.ln_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "attn_outputs", "=", "self", ".", "attn", "(", "x", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "n", "=", "self", ".", "ln_1", "(", "x", "+", "a", ")", "\n", "m", "=", "self", ".", "mlp", "(", "n", ")", "\n", "h", "=", "self", ".", "ln_2", "(", "n", "+", "m", ")", "\n", "\n", "outputs", "=", "[", "h", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.OpenAIGPTPreTrainedModel._init_weights": [[268, 280], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "Conv1D", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "Conv1D", ")", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.OpenAIGPTModel.__init__": [[361, 372], ["modeling_utils.PreTrainedModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "modeling_openai.OpenAIGPTModel.init_weights", "modeling_openai.Block", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "\n", "self", ".", "tokens_embed", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "positions_embed", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "Block", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.OpenAIGPTModel.get_input_embeddings": [[373, 375], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "tokens_embed", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.OpenAIGPTModel.set_input_embeddings": [[376, 378], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "tokens_embed", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.OpenAIGPTModel._prune_heads": [[379, 385], ["heads_to_prune.items", "modeling_openai.OpenAIGPTModel.h[].attn.prune_heads"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "h", "[", "layer", "]", ".", "attn", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.OpenAIGPTModel.forward": [[386, 480], ["modeling_openai.OpenAIGPTModel.positions_embed", "modeling_openai.OpenAIGPTModel.drop", "enumerate", "ValueError", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze().view", "attention_mask.to.to.unsqueeze().unsqueeze", "attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "modeling_openai.OpenAIGPTModel.tokens_embed", "token_type_ids.view.view.view", "modeling_openai.OpenAIGPTModel.tokens_embed", "block", "modeling_openai.OpenAIGPTModel.view", "input_ids.view.view.size", "input_ids.view.view.view", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "token_type_ids.view.view.size", "modeling_openai.OpenAIGPTModel.size", "ValueError", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze", "attention_mask.to.to.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_openai.OpenAIGPTModel.view", "modeling_openai.OpenAIGPTModel.size", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "modeling_openai.OpenAIGPTModel.view", "modeling_openai.OpenAIGPTModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_openai.OpenAIGPTModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "# Code is different from when we had a single embedding matrice from position and token embeddings", "\n", "            ", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "position_ids", "=", "torch", ".", "arange", "(", "input_shape", "[", "-", "1", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "# Attention mask.", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "            ", "attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "attention_mask", "=", "attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# head_mask has shape n_layer x batch x n_heads x N x N", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "n_layer", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "tokens_embed", "(", "input_ids", ")", "\n", "", "position_embeds", "=", "self", ".", "positions_embed", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "token_type_embeds", "=", "self", ".", "tokens_embed", "(", "token_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "hidden_states", "=", "self", ".", "drop", "(", "hidden_states", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "\n", "all_attentions", "=", "(", ")", "\n", "all_hidden_states", "=", "(", ")", "\n", "for", "i", ",", "block", "in", "enumerate", "(", "self", ".", "h", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "block", "(", "hidden_states", ",", "attention_mask", ",", "head_mask", "[", "i", "]", ")", "\n", "hidden_states", "=", "outputs", "[", "0", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", "=", "all_attentions", "+", "(", "outputs", "[", "1", "]", ",", ")", "\n", "\n", "# Add last layer", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last hidden state, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.OpenAIGPTLMHeadModel.__init__": [[520, 526], ["modeling_utils.PreTrainedModel.__init__", "modeling_openai.OpenAIGPTModel", "torch.Linear", "torch.Linear", "modeling_openai.OpenAIGPTLMHeadModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "OpenAIGPTModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.OpenAIGPTLMHeadModel.get_output_embeddings": [[527, 529], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.OpenAIGPTLMHeadModel.forward": [[530, 562], ["modeling_openai.OpenAIGPTLMHeadModel.transformer", "modeling_openai.OpenAIGPTLMHeadModel.lm_head", "lm_logits[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous.view", "labels[].contiguous.view", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Shift so that tokens < n predict n", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), lm_logits, (all hidden states), (all attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.__init__": [[625, 634], ["modeling_utils.PreTrainedModel.__init__", "modeling_openai.OpenAIGPTModel", "torch.Linear", "torch.Linear", "modeling_utils.SequenceSummary", "modeling_openai.OpenAIGPTDoubleHeadsModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTDoubleHeadsModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "config", ".", "num_labels", "=", "1", "\n", "self", ".", "transformer", "=", "OpenAIGPTModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "multiple_choice_head", "=", "SequenceSummary", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.get_output_embeddings": [[635, 637], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.OpenAIGPTDoubleHeadsModel.forward": [[638, 676], ["modeling_openai.OpenAIGPTDoubleHeadsModel.transformer", "modeling_openai.OpenAIGPTDoubleHeadsModel.lm_head", "modeling_openai.OpenAIGPTDoubleHeadsModel.multiple_choice_head().squeeze", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous", "lm_labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_openai.OpenAIGPTDoubleHeadsModel.multiple_choice_head", "modeling_openai.OpenAIGPTDoubleHeadsModel.view", "mc_labels.view", "lm_logits[].contiguous.view", "lm_labels[].contiguous.view", "modeling_openai.OpenAIGPTDoubleHeadsModel.size", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "mc_token_ids", "=", "None", ",", "\n", "lm_labels", "=", "None", ",", "\n", "mc_labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "hidden_states", ",", "mc_token_ids", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", "mc_logits", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "mc_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "mc_logits", ".", "view", "(", "-", "1", ",", "mc_logits", ".", "size", "(", "-", "1", ")", ")", ",", "mc_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "lm_labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (lm loss), (mc loss), lm logits, mc logits, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.load_tf_weights_in_openai_gpt": [[40, 115], ["logger.info", "np.cumsum", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "json.load.pop", "init_params.pop", "init_params.pop", "zip", "os.path.dirname", "open", "json.load", "open", "json.load", "np.load", "np.split", "param.reshape", "arr.squeeze", "name.split.split", "logger.info", "torch.from_numpy", "torch.from_numpy", "np.prod", "range", "np.concatenate", "zip", "re.fullmatch", "re.split", "getattr", "len", "int", "getattr", "getattr", "getattr"], "function", ["None"], ["def", "load_tf_weights_in_openai_gpt", "(", "model", ",", "config", ",", "openai_checkpoint_folder_path", ")", ":", "\n", "    ", "\"\"\" Load tf pre-trained weights in a pytorch model (from NumPy arrays here)\n    \"\"\"", "\n", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "\n", "if", "\".ckpt\"", "in", "openai_checkpoint_folder_path", ":", "\n", "        ", "openai_checkpoint_folder_path", "=", "os", ".", "path", ".", "dirname", "(", "openai_checkpoint_folder_path", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Loading weights from {}\"", ".", "format", "(", "openai_checkpoint_folder_path", ")", ")", "\n", "\n", "with", "open", "(", "openai_checkpoint_folder_path", "+", "\"/parameters_names.json\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "names_handle", ":", "\n", "        ", "names", "=", "json", ".", "load", "(", "names_handle", ")", "\n", "", "with", "open", "(", "openai_checkpoint_folder_path", "+", "\"/params_shapes.json\"", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "shapes_handle", ":", "\n", "        ", "shapes", "=", "json", ".", "load", "(", "shapes_handle", ")", "\n", "", "offsets", "=", "np", ".", "cumsum", "(", "[", "np", ".", "prod", "(", "shape", ")", "for", "shape", "in", "shapes", "]", ")", "\n", "init_params", "=", "[", "np", ".", "load", "(", "openai_checkpoint_folder_path", "+", "\"/params_{}.npy\"", ".", "format", "(", "n", ")", ")", "for", "n", "in", "range", "(", "10", ")", "]", "\n", "init_params", "=", "np", ".", "split", "(", "np", ".", "concatenate", "(", "init_params", ",", "0", ")", ",", "offsets", ")", "[", ":", "-", "1", "]", "\n", "init_params", "=", "[", "param", ".", "reshape", "(", "shape", ")", "for", "param", ",", "shape", "in", "zip", "(", "init_params", ",", "shapes", ")", "]", "\n", "\n", "# This was used when we had a single embedding matrix for positions and tokens", "\n", "# init_params[0] = np.concatenate([init_params[1], init_params[0]], 0)", "\n", "# del init_params[1]", "\n", "init_params", "=", "[", "arr", ".", "squeeze", "(", ")", "for", "arr", "in", "init_params", "]", "\n", "\n", "try", ":", "\n", "        ", "assert", "model", ".", "tokens_embed", ".", "weight", ".", "shape", "==", "init_params", "[", "1", "]", ".", "shape", "\n", "assert", "model", ".", "positions_embed", ".", "weight", ".", "shape", "==", "init_params", "[", "0", "]", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "        ", "e", ".", "args", "+=", "(", "model", ".", "tokens_embed", ".", "weight", ".", "shape", ",", "init_params", "[", "1", "]", ".", "shape", ")", "\n", "e", ".", "args", "+=", "(", "model", ".", "positions_embed", ".", "weight", ".", "shape", ",", "init_params", "[", "0", "]", ".", "shape", ")", "\n", "raise", "\n", "\n", "", "model", ".", "tokens_embed", ".", "weight", ".", "data", "=", "torch", ".", "from_numpy", "(", "init_params", "[", "1", "]", ")", "\n", "model", ".", "positions_embed", ".", "weight", ".", "data", "=", "torch", ".", "from_numpy", "(", "init_params", "[", "0", "]", ")", "\n", "names", ".", "pop", "(", "0", ")", "\n", "# Pop position and token embedding arrays", "\n", "init_params", ".", "pop", "(", "0", ")", "\n", "init_params", ".", "pop", "(", "0", ")", "\n", "\n", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "init_params", ")", ":", "# names[1:n_transfer], init_params[1:n_transfer]):", "\n", "        ", "name", "=", "name", "[", "6", ":", "]", "# skip \"model/\"", "\n", "assert", "name", "[", "-", "2", ":", "]", "==", "\":0\"", "\n", "name", "=", "name", "[", ":", "-", "2", "]", "\n", "name", "=", "name", ".", "split", "(", "\"/\"", ")", "\n", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r\"[A-Za-z]+\\d+\"", ",", "m_name", ")", ":", "\n", "                ", "scope_names", "=", "re", ".", "split", "(", "r\"(\\d+)\"", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "scope_names", "=", "[", "m_name", "]", "\n", "", "if", "scope_names", "[", "0", "]", "==", "\"g\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"b\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"bias\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"w\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "", "if", "len", "(", "scope_names", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "scope_names", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.gelu": [[117, 119], ["torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.swish": [[121, 123], ["torch.sigmoid", "torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_albert.AlbertConfig.__init__": [[41, 106], ["configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "30000", ",", "\n", "embedding_size", "=", "128", ",", "\n", "hidden_size", "=", "4096", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_hidden_groups", "=", "1", ",", "\n", "num_attention_heads", "=", "64", ",", "\n", "intermediate_size", "=", "16384", ",", "\n", "inner_group_num", "=", "1", ",", "\n", "hidden_act", "=", "\"gelu_new\"", ",", "\n", "hidden_dropout_prob", "=", "0", ",", "\n", "attention_probs_dropout_prob", "=", "0", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "type_vocab_size", "=", "2", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "layer_norm_eps", "=", "1e-12", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs AlbertConfig.\n\n        Args:\n            vocab_size: Vocabulary size of `inputs_ids` in `AlbertModel`.\n            embedding_size: size of voc embeddings.\n            hidden_size: Size of the encoder layers and the pooler layer.\n            num_hidden_layers: Number of hidden layers in the Transformer encoder.\n            num_hidden_groups: Number of group for the hidden layers, parameters in\n                the same group are shared.\n            num_attention_heads: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n                layer in the Transformer encoder.\n            inner_group_num: int, number of inner repetition of attention and ffn.\n            down_scale_factor: float, the scale to apply\n            hidden_act: The non-linear activation function (function or string) in the\n                encoder and pooler.\n            hidden_dropout_prob: The dropout probability for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            attention_probs_dropout_prob: The dropout ratio for the attention\n                probabilities.\n            max_position_embeddings: The maximum sequence length that this model might\n                ever be used with. Typically set this to something large just in case\n                (e.g., 512 or 1024 or 2048).\n            type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n                `AlbertModel`.\n            initializer_range: The stdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n        \"\"\"", "\n", "super", "(", "AlbertConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "embedding_size", "=", "embedding_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_hidden_groups", "=", "num_hidden_groups", "\n", "self", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "inner_group_num", "=", "inner_group_num", "\n", "self", ".", "hidden_act", "=", "hidden_act", "\n", "self", ".", "intermediate_size", "=", "intermediate_size", "\n", "self", ".", "hidden_dropout_prob", "=", "hidden_dropout_prob", "\n", "self", ".", "attention_probs_dropout_prob", "=", "attention_probs_dropout_prob", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "type_vocab_size", "=", "type_vocab_size", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "layer_norm_eps", "=", "layer_norm_eps", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.convert_tf_weight_name_to_pt_weight_name": [[29, 66], ["tf_name.replace.replace", "re.sub", "tf_name.replace.replace", "re.sub", "tf_name.replace.split", "bool", "tf_name.replace.replace"], "function", ["None"], ["def", "convert_tf_weight_name_to_pt_weight_name", "(", "tf_name", ",", "start_prefix_to_remove", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\" Convert a TF 2.0 model variable name in a pytorch model weight name.\n\n        Conventions for TF2.0 scopes -> PyTorch attribute names conversions:\n            - '$1___$2' is replaced by $2 (can be used to duplicate or remove layers in TF2.0 vs PyTorch)\n            - '_._' is replaced by a new level separation (can be used to convert TF2.0 lists in PyTorch nn.ModulesList)\n\n        return tuple with:\n            - pytorch model weight name\n            - transpose: boolean indicating weither TF2.0 and PyTorch weights matrices are transposed with regards to each other\n    \"\"\"", "\n", "tf_name", "=", "tf_name", ".", "replace", "(", "\":0\"", ",", "\"\"", ")", "# device ids", "\n", "tf_name", "=", "re", ".", "sub", "(", "\n", "r\"/[^/]*___([^/]*)/\"", ",", "r\"/\\1/\"", ",", "tf_name", "\n", ")", "# '$1___$2' is replaced by $2 (can be used to duplicate or remove layers in TF2.0 vs PyTorch)", "\n", "tf_name", "=", "tf_name", ".", "replace", "(", "\n", "\"_._\"", ",", "\"/\"", "\n", ")", "# '_._' is replaced by a level separation (can be used to convert TF2.0 lists in PyTorch nn.ModulesList)", "\n", "tf_name", "=", "re", ".", "sub", "(", "r\"//+\"", ",", "\"/\"", ",", "tf_name", ")", "# Remove empty levels at the end", "\n", "tf_name", "=", "tf_name", ".", "split", "(", "\"/\"", ")", "# Convert from TF2.0 '/' separators to PyTorch '.' separators", "\n", "tf_name", "=", "tf_name", "[", "1", ":", "]", "# Remove level zero", "\n", "\n", "# When should we transpose the weights", "\n", "transpose", "=", "bool", "(", "tf_name", "[", "-", "1", "]", "==", "\"kernel\"", "or", "\"emb_projs\"", "in", "tf_name", "or", "\"out_projs\"", "in", "tf_name", ")", "\n", "\n", "# Convert standard TF2.0 names in PyTorch names", "\n", "if", "tf_name", "[", "-", "1", "]", "==", "\"kernel\"", "or", "tf_name", "[", "-", "1", "]", "==", "\"embeddings\"", "or", "tf_name", "[", "-", "1", "]", "==", "\"gamma\"", ":", "\n", "        ", "tf_name", "[", "-", "1", "]", "=", "\"weight\"", "\n", "", "if", "tf_name", "[", "-", "1", "]", "==", "\"beta\"", ":", "\n", "        ", "tf_name", "[", "-", "1", "]", "=", "\"bias\"", "\n", "\n", "# Remove prefix if needed", "\n", "", "tf_name", "=", "\".\"", ".", "join", "(", "tf_name", ")", "\n", "if", "start_prefix_to_remove", ":", "\n", "        ", "tf_name", "=", "tf_name", ".", "replace", "(", "start_prefix_to_remove", ",", "\"\"", ",", "1", ")", "\n", "\n", "", "return", "tf_name", ",", "transpose", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_pytorch_checkpoint_in_tf2_model": [[73, 94], ["os.path.abspath", "logger.info", "torch.load", "logger.info", "modeling_tf_pytorch_utils.load_pytorch_weights_in_tf2_model", "logger.error", "sum", "t.numel", "torch.load.values"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_pytorch_weights_in_tf2_model"], ["", "def", "load_pytorch_checkpoint_in_tf2_model", "(", "tf_model", ",", "pytorch_checkpoint_path", ",", "tf_inputs", "=", "None", ",", "allow_missing_keys", "=", "False", ")", ":", "\n", "    ", "\"\"\" Load pytorch checkpoints in a TF 2.0 model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "tensorflow", "as", "tf", "# noqa: F401", "\n", "import", "torch", "# noqa: F401", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a PyTorch model in TensorFlow, requires both PyTorch and TensorFlow to be installed. Please see \"", "\n", "\"https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "\n", "", "pt_path", "=", "os", ".", "path", ".", "abspath", "(", "pytorch_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Loading PyTorch weights from {}\"", ".", "format", "(", "pt_path", ")", ")", "\n", "\n", "pt_state_dict", "=", "torch", ".", "load", "(", "pt_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "logger", ".", "info", "(", "\"PyTorch checkpoint contains {:,} parameters\"", ".", "format", "(", "sum", "(", "t", ".", "numel", "(", ")", "for", "t", "in", "pt_state_dict", ".", "values", "(", ")", ")", ")", ")", "\n", "\n", "return", "load_pytorch_weights_in_tf2_model", "(", "\n", "tf_model", ",", "pt_state_dict", ",", "tf_inputs", "=", "tf_inputs", ",", "allow_missing_keys", "=", "allow_missing_keys", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_pytorch_model_in_tf2_model": [[97, 104], ["pt_model.state_dict", "modeling_tf_pytorch_utils.load_pytorch_weights_in_tf2_model"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_pytorch_weights_in_tf2_model"], ["", "def", "load_pytorch_model_in_tf2_model", "(", "tf_model", ",", "pt_model", ",", "tf_inputs", "=", "None", ",", "allow_missing_keys", "=", "False", ")", ":", "\n", "    ", "\"\"\" Load pytorch checkpoints in a TF 2.0 model\n    \"\"\"", "\n", "pt_state_dict", "=", "pt_model", ".", "state_dict", "(", ")", "\n", "\n", "return", "load_pytorch_weights_in_tf2_model", "(", "\n", "tf_model", ",", "pt_state_dict", ",", "tf_inputs", "=", "tf_inputs", ",", "allow_missing_keys", "=", "allow_missing_keys", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_pytorch_weights_in_tf2_model": [[107, 197], ["pt_state_dict.keys", "zip", "set", "K.batch_set_value", "logger.info", "logger.info", "tf_model", "pt_state_dict.pop", "any", "list", "modeling_tf_pytorch_utils.convert_tf_weight_name_to_pt_weight_name", "pt_state_dict[].numpy", "weight_value_tuples.append", "set.discard", "tf_model", "logger.error", "key.replace", "key.replace", "old_keys.append", "new_keys.append", "pt_state_dict.keys", "AttributeError", "numpy.transpose", "len", "len", "numpy.squeeze", "s.startswith", "len", "len", "numpy.expand_dims", "list", "list", "pt_state_dict.keys"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.convert_tf_weight_name_to_pt_weight_name"], ["", "def", "load_pytorch_weights_in_tf2_model", "(", "tf_model", ",", "pt_state_dict", ",", "tf_inputs", "=", "None", ",", "allow_missing_keys", "=", "False", ")", ":", "\n", "    ", "\"\"\" Load pytorch state_dict in a TF 2.0 model.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "torch", "# noqa: F401", "\n", "import", "tensorflow", "as", "tf", "# noqa: F401", "\n", "from", "tensorflow", ".", "python", ".", "keras", "import", "backend", "as", "K", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a PyTorch model in TensorFlow, requires both PyTorch and TensorFlow to be installed. Please see \"", "\n", "\"https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "\n", "", "if", "tf_inputs", "is", "None", ":", "\n", "        ", "tf_inputs", "=", "tf_model", ".", "dummy_inputs", "\n", "\n", "", "if", "tf_inputs", "is", "not", "None", ":", "\n", "        ", "tfo", "=", "tf_model", "(", "tf_inputs", ",", "training", "=", "False", ")", "# Make sure model is built", "\n", "\n", "# Adapt state dict - TODO remove this and update the AWS weights files instead", "\n", "# Convert old format to new format if needed from a PyTorch state_dict", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "pt_state_dict", ".", "keys", "(", ")", ":", "\n", "        ", "new_key", "=", "None", "\n", "if", "\"gamma\"", "in", "key", ":", "\n", "            ", "new_key", "=", "key", ".", "replace", "(", "\"gamma\"", ",", "\"weight\"", ")", "\n", "", "if", "\"beta\"", "in", "key", ":", "\n", "            ", "new_key", "=", "key", ".", "replace", "(", "\"beta\"", ",", "\"bias\"", ")", "\n", "", "if", "new_key", ":", "\n", "            ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "        ", "pt_state_dict", "[", "new_key", "]", "=", "pt_state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "# Make sure we are able to load PyTorch base models as well as derived models (with heads)", "\n", "# TF models always have a prefix, some of PyTorch models (base ones) don't", "\n", "", "start_prefix_to_remove", "=", "\"\"", "\n", "if", "not", "any", "(", "s", ".", "startswith", "(", "tf_model", ".", "base_model_prefix", ")", "for", "s", "in", "pt_state_dict", ".", "keys", "(", ")", ")", ":", "\n", "        ", "start_prefix_to_remove", "=", "tf_model", ".", "base_model_prefix", "+", "\".\"", "\n", "\n", "", "symbolic_weights", "=", "tf_model", ".", "trainable_weights", "+", "tf_model", ".", "non_trainable_weights", "\n", "tf_loaded_numel", "=", "0", "\n", "weight_value_tuples", "=", "[", "]", "\n", "all_pytorch_weights", "=", "set", "(", "list", "(", "pt_state_dict", ".", "keys", "(", ")", ")", ")", "\n", "for", "symbolic_weight", "in", "symbolic_weights", ":", "\n", "        ", "sw_name", "=", "symbolic_weight", ".", "name", "\n", "name", ",", "transpose", "=", "convert_tf_weight_name_to_pt_weight_name", "(", "\n", "sw_name", ",", "start_prefix_to_remove", "=", "start_prefix_to_remove", "\n", ")", "\n", "\n", "# Find associated numpy array in pytorch model state dict", "\n", "if", "name", "not", "in", "pt_state_dict", ":", "\n", "            ", "if", "allow_missing_keys", ":", "\n", "                ", "continue", "\n", "", "raise", "AttributeError", "(", "\"{} not found in PyTorch model\"", ".", "format", "(", "name", ")", ")", "\n", "\n", "", "array", "=", "pt_state_dict", "[", "name", "]", ".", "numpy", "(", ")", "\n", "\n", "if", "transpose", ":", "\n", "            ", "array", "=", "numpy", ".", "transpose", "(", "array", ")", "\n", "\n", "", "if", "len", "(", "symbolic_weight", ".", "shape", ")", "<", "len", "(", "array", ".", "shape", ")", ":", "\n", "            ", "array", "=", "numpy", ".", "squeeze", "(", "array", ")", "\n", "", "elif", "len", "(", "symbolic_weight", ".", "shape", ")", ">", "len", "(", "array", ".", "shape", ")", ":", "\n", "            ", "array", "=", "numpy", ".", "expand_dims", "(", "array", ",", "axis", "=", "0", ")", "\n", "\n", "", "try", ":", "\n", "            ", "assert", "list", "(", "symbolic_weight", ".", "shape", ")", "==", "list", "(", "array", ".", "shape", ")", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "symbolic_weight", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "e", "\n", "\n", "", "tf_loaded_numel", "+=", "array", ".", "size", "\n", "# logger.warning(\"Initialize TF weight {}\".format(symbolic_weight.name))", "\n", "\n", "weight_value_tuples", ".", "append", "(", "(", "symbolic_weight", ",", "array", ")", ")", "\n", "all_pytorch_weights", ".", "discard", "(", "name", ")", "\n", "\n", "", "K", ".", "batch_set_value", "(", "weight_value_tuples", ")", "\n", "\n", "if", "tf_inputs", "is", "not", "None", ":", "\n", "        ", "tfo", "=", "tf_model", "(", "tf_inputs", ",", "training", "=", "False", ")", "# Make sure restore ops are run", "\n", "\n", "", "logger", ".", "info", "(", "\"Loaded {:,} parameters in the TF 2.0 model.\"", ".", "format", "(", "tf_loaded_numel", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\"Weights or buffers not loaded from PyTorch model: {}\"", ".", "format", "(", "all_pytorch_weights", ")", ")", "\n", "\n", "return", "tf_model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_tf2_checkpoint_in_pytorch_model": [[204, 238], ["os.path.abspath", "logger.info", "getattr", "getattr.", "tf_model_class.load_weights", "modeling_tf_pytorch_utils.load_tf2_model_in_pytorch_model", "tf_model_class.", "logger.error"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_tf2_model_in_pytorch_model"], ["", "def", "load_tf2_checkpoint_in_pytorch_model", "(", "pt_model", ",", "tf_checkpoint_path", ",", "tf_inputs", "=", "None", ",", "allow_missing_keys", "=", "False", ")", ":", "\n", "    ", "\"\"\" Load TF 2.0 HDF5 checkpoint in a PyTorch model\n        We use HDF5 to easily do transfer learning\n        (see https://github.com/tensorflow/tensorflow/blob/ee16fcac960ae660e0e4496658a366e2f745e1f0/tensorflow/python/keras/engine/network.py#L1352-L1357).\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "tensorflow", "as", "tf", "# noqa: F401", "\n", "import", "torch", "# noqa: F401", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires both PyTorch and TensorFlow to be installed. Please see \"", "\n", "\"https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "\n", "", "import", "transformers", "\n", "\n", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Loading TensorFlow weights from {}\"", ".", "format", "(", "tf_checkpoint_path", ")", ")", "\n", "\n", "# Instantiate and load the associated TF 2.0 model", "\n", "tf_model_class_name", "=", "\"TF\"", "+", "pt_model", ".", "__class__", ".", "__name__", "# Add \"TF\" at the beggining", "\n", "tf_model_class", "=", "getattr", "(", "transformers", ",", "tf_model_class_name", ")", "\n", "tf_model", "=", "tf_model_class", "(", "pt_model", ".", "config", ")", "\n", "\n", "if", "tf_inputs", "is", "None", ":", "\n", "        ", "tf_inputs", "=", "tf_model", ".", "dummy_inputs", "\n", "\n", "", "if", "tf_inputs", "is", "not", "None", ":", "\n", "        ", "tfo", "=", "tf_model", "(", "tf_inputs", ",", "training", "=", "False", ")", "# Make sure model is built", "\n", "\n", "", "tf_model", ".", "load_weights", "(", "tf_checkpoint_path", ",", "by_name", "=", "True", ")", "\n", "\n", "return", "load_tf2_model_in_pytorch_model", "(", "pt_model", ",", "tf_model", ",", "allow_missing_keys", "=", "allow_missing_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_tf2_model_in_pytorch_model": [[240, 246], ["modeling_tf_pytorch_utils.load_tf2_weights_in_pytorch_model"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_tf2_weights_in_pytorch_model"], ["", "def", "load_tf2_model_in_pytorch_model", "(", "pt_model", ",", "tf_model", ",", "allow_missing_keys", "=", "False", ")", ":", "\n", "    ", "\"\"\" Load TF 2.0 model in a pytorch model\n    \"\"\"", "\n", "weights", "=", "tf_model", ".", "weights", "\n", "\n", "return", "load_tf2_weights_in_pytorch_model", "(", "pt_model", ",", "weights", ",", "allow_missing_keys", "=", "allow_missing_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_tf2_weights_in_pytorch_model": [[248, 331], ["dict", "set", "dict.items", "pt_model.load_state_dict", "logger.info", "pt_model.named_parameters", "any", "modeling_tf_pytorch_utils.convert_tf_weight_name_to_pt_weight_name", "list", "torch.from_numpy", "torch.from_numpy", "set.discard", "len", "logger.info", "len", "logger.info", "logger.error", "tf_weight.numpy", "tf_weights_map.keys", "pt_weight.data_ptr", "AttributeError", "numpy.transpose", "len", "len", "numpy.squeeze", "s.startswith", "missing_keys_pt.append", "len", "len", "numpy.expand_dims", "list", "list", "pt_weight.data_ptr", "dict.keys", "pt_weight.data_ptr"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.convert_tf_weight_name_to_pt_weight_name"], ["", "def", "load_tf2_weights_in_pytorch_model", "(", "pt_model", ",", "tf_weights", ",", "allow_missing_keys", "=", "False", ")", ":", "\n", "    ", "\"\"\" Load TF2.0 symbolic weights in a PyTorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "tensorflow", "as", "tf", "# noqa: F401", "\n", "import", "torch", "# noqa: F401", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires both PyTorch and TensorFlow to be installed. Please see \"", "\n", "\"https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "\n", "", "new_pt_params_dict", "=", "{", "}", "\n", "current_pt_params_dict", "=", "dict", "(", "pt_model", ".", "named_parameters", "(", ")", ")", "\n", "\n", "# Make sure we are able to load PyTorch base models as well as derived models (with heads)", "\n", "# TF models always have a prefix, some of PyTorch models (base ones) don't", "\n", "start_prefix_to_remove", "=", "\"\"", "\n", "if", "not", "any", "(", "s", ".", "startswith", "(", "pt_model", ".", "base_model_prefix", ")", "for", "s", "in", "current_pt_params_dict", ".", "keys", "(", ")", ")", ":", "\n", "        ", "start_prefix_to_remove", "=", "pt_model", ".", "base_model_prefix", "+", "\".\"", "\n", "\n", "# Build a map from potential PyTorch weight names to TF 2.0 Variables", "\n", "", "tf_weights_map", "=", "{", "}", "\n", "for", "tf_weight", "in", "tf_weights", ":", "\n", "        ", "pt_name", ",", "transpose", "=", "convert_tf_weight_name_to_pt_weight_name", "(", "\n", "tf_weight", ".", "name", ",", "start_prefix_to_remove", "=", "start_prefix_to_remove", "\n", ")", "\n", "tf_weights_map", "[", "pt_name", "]", "=", "(", "tf_weight", ".", "numpy", "(", ")", ",", "transpose", ")", "\n", "\n", "", "all_tf_weights", "=", "set", "(", "list", "(", "tf_weights_map", ".", "keys", "(", ")", ")", ")", "\n", "loaded_pt_weights_data_ptr", "=", "{", "}", "\n", "missing_keys_pt", "=", "[", "]", "\n", "for", "pt_weight_name", ",", "pt_weight", "in", "current_pt_params_dict", ".", "items", "(", ")", ":", "\n", "# Handle PyTorch shared weight ()not duplicated in TF 2.0", "\n", "        ", "if", "pt_weight", ".", "data_ptr", "(", ")", "in", "loaded_pt_weights_data_ptr", ":", "\n", "            ", "new_pt_params_dict", "[", "pt_weight_name", "]", "=", "loaded_pt_weights_data_ptr", "[", "pt_weight", ".", "data_ptr", "(", ")", "]", "\n", "continue", "\n", "\n", "# Find associated numpy array in pytorch model state dict", "\n", "", "if", "pt_weight_name", "not", "in", "tf_weights_map", ":", "\n", "            ", "if", "allow_missing_keys", ":", "\n", "                ", "missing_keys_pt", ".", "append", "(", "pt_weight_name", ")", "\n", "continue", "\n", "", "raise", "AttributeError", "(", "\"{} not found in TF 2.0 model\"", ".", "format", "(", "pt_weight_name", ")", ")", "\n", "\n", "", "array", ",", "transpose", "=", "tf_weights_map", "[", "pt_weight_name", "]", "\n", "\n", "if", "transpose", ":", "\n", "            ", "array", "=", "numpy", ".", "transpose", "(", "array", ")", "\n", "\n", "", "if", "len", "(", "pt_weight", ".", "shape", ")", "<", "len", "(", "array", ".", "shape", ")", ":", "\n", "            ", "array", "=", "numpy", ".", "squeeze", "(", "array", ")", "\n", "", "elif", "len", "(", "pt_weight", ".", "shape", ")", ">", "len", "(", "array", ".", "shape", ")", ":", "\n", "            ", "array", "=", "numpy", ".", "expand_dims", "(", "array", ",", "axis", "=", "0", ")", "\n", "\n", "", "try", ":", "\n", "            ", "assert", "list", "(", "pt_weight", ".", "shape", ")", "==", "list", "(", "array", ".", "shape", ")", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pt_weight", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "e", "\n", "\n", "# logger.warning(\"Initialize PyTorch weight {}\".format(pt_weight_name))", "\n", "\n", "", "new_pt_params_dict", "[", "pt_weight_name", "]", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "loaded_pt_weights_data_ptr", "[", "pt_weight", ".", "data_ptr", "(", ")", "]", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "all_tf_weights", ".", "discard", "(", "pt_weight_name", ")", "\n", "\n", "", "missing_keys", ",", "unexpected_keys", "=", "pt_model", ".", "load_state_dict", "(", "new_pt_params_dict", ",", "strict", "=", "False", ")", "\n", "missing_keys", "+=", "missing_keys_pt", "\n", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"Weights of {} not initialized from TF 2.0 model: {}\"", ".", "format", "(", "pt_model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", "\n", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"Weights from TF 2.0 model not used in {}: {}\"", ".", "format", "(", "pt_model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", "\n", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Weights or buffers not loaded from TF 2.0 model: {}\"", ".", "format", "(", "all_tf_weights", ")", ")", "\n", "\n", "return", "pt_model", "\n", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_openai_original_tf_checkpoint_to_pytorch.convert_openai_checkpoint_to_pytorch": [[29, 48], ["transformers.OpenAIGPTModel", "transformers.load_tf_weights_in_openai_gpt", "print", "torch.save", "print", "transformers.OpenAIGPTConfig", "transformers.OpenAIGPTConfig.from_json_file", "transformers.OpenAIGPTModel.state_dict", "open", "f.write", "OpenAIGPTConfig.from_json_file.to_json_string"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.load_tf_weights_in_openai_gpt", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_json_string"], ["def", "convert_openai_checkpoint_to_pytorch", "(", "openai_checkpoint_folder_path", ",", "openai_config_file", ",", "pytorch_dump_folder_path", ")", ":", "\n", "# Construct model", "\n", "    ", "if", "openai_config_file", "==", "\"\"", ":", "\n", "        ", "config", "=", "OpenAIGPTConfig", "(", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "OpenAIGPTConfig", ".", "from_json_file", "(", "openai_config_file", ")", "\n", "", "model", "=", "OpenAIGPTModel", "(", "config", ")", "\n", "\n", "# Load weights from numpy", "\n", "load_tf_weights_in_openai_gpt", "(", "model", ",", "config", ",", "openai_checkpoint_folder_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "pytorch_weights_dump_path", "=", "pytorch_dump_folder_path", "+", "\"/\"", "+", "WEIGHTS_NAME", "\n", "pytorch_config_dump_path", "=", "pytorch_dump_folder_path", "+", "\"/\"", "+", "CONFIG_NAME", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_weights_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_weights_dump_path", ")", "\n", "print", "(", "\"Save configuration file to {}\"", ".", "format", "(", "pytorch_config_dump_path", ")", ")", "\n", "with", "open", "(", "pytorch_config_dump_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_xlm.XLMConfig.__init__": [[82, 154], ["configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "30145", ",", "\n", "emb_dim", "=", "2048", ",", "\n", "n_layers", "=", "12", ",", "\n", "n_heads", "=", "16", ",", "\n", "dropout", "=", "0.1", ",", "\n", "attention_dropout", "=", "0.1", ",", "\n", "gelu_activation", "=", "True", ",", "\n", "sinusoidal_embeddings", "=", "False", ",", "\n", "causal", "=", "False", ",", "\n", "asm", "=", "False", ",", "\n", "n_langs", "=", "1", ",", "\n", "use_lang_emb", "=", "True", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "embed_init_std", "=", "2048", "**", "-", "0.5", ",", "\n", "layer_norm_eps", "=", "1e-12", ",", "\n", "init_std", "=", "0.02", ",", "\n", "bos_index", "=", "0", ",", "\n", "eos_index", "=", "1", ",", "\n", "pad_index", "=", "2", ",", "\n", "unk_index", "=", "3", ",", "\n", "mask_index", "=", "5", ",", "\n", "is_encoder", "=", "True", ",", "\n", "summary_type", "=", "\"first\"", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "start_n_top", "=", "5", ",", "\n", "end_n_top", "=", "5", ",", "\n", "mask_token_id", "=", "0", ",", "\n", "lang_id", "=", "0", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs XLMConfig.\n        \"\"\"", "\n", "super", "(", "XLMConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "emb_dim", "=", "emb_dim", "\n", "self", ".", "n_layers", "=", "n_layers", "\n", "self", ".", "n_heads", "=", "n_heads", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "attention_dropout", "=", "attention_dropout", "\n", "self", ".", "gelu_activation", "=", "gelu_activation", "\n", "self", ".", "sinusoidal_embeddings", "=", "sinusoidal_embeddings", "\n", "self", ".", "causal", "=", "causal", "\n", "self", ".", "asm", "=", "asm", "\n", "self", ".", "n_langs", "=", "n_langs", "\n", "self", ".", "use_lang_emb", "=", "use_lang_emb", "\n", "self", ".", "layer_norm_eps", "=", "layer_norm_eps", "\n", "self", ".", "bos_index", "=", "bos_index", "\n", "self", ".", "eos_index", "=", "eos_index", "\n", "self", ".", "pad_index", "=", "pad_index", "\n", "self", ".", "unk_index", "=", "unk_index", "\n", "self", ".", "mask_index", "=", "mask_index", "\n", "self", ".", "is_encoder", "=", "is_encoder", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "embed_init_std", "=", "embed_init_std", "\n", "self", ".", "init_std", "=", "init_std", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "start_n_top", "=", "start_n_top", "\n", "self", ".", "end_n_top", "=", "end_n_top", "\n", "self", ".", "mask_token_id", "=", "mask_token_id", "\n", "self", ".", "lang_id", "=", "lang_id", "\n", "\n", "if", "\"n_words\"", "in", "kwargs", ":", "\n", "            ", "self", ".", "n_words", "=", "kwargs", "[", "\"n_words\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_xlm.XLMConfig.n_words": [[159, 162], ["None"], "methods", ["None"], ["", "@", "n_words", ".", "setter", "\n", "def", "n_words", "(", "self", ",", "value", ")", ":", "# For backward compatibility", "\n", "        ", "self", ".", "vocab_size", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_xlm.XLMConfig.hidden_size": [[163, 166], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "emb_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_xlm.XLMConfig.num_attention_heads": [[167, 170], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_heads", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_xlm.XLMConfig.num_hidden_layers": [[171, 174], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layers", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert_japanese.BertJapaneseTokenizer.__init__": [[78, 148], ["tokenization_bert.BertTokenizer.__init__", "tokenization_bert.load_vocab", "collections.OrderedDict", "os.path.isfile", "ValueError", "tokenization_bert.BasicTokenizer", "tokenization_bert.WordpieceTokenizer", "tokenization_bert_japanese.BertJapaneseTokenizer.vocab.items", "tokenization_bert_japanese.MecabTokenizer", "ValueError", "tokenization_bert_japanese.CharacterTokenizer", "ValueError"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.load_vocab"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "do_lower_case", "=", "False", ",", "\n", "do_word_tokenize", "=", "True", ",", "\n", "do_subword_tokenize", "=", "True", ",", "\n", "word_tokenizer_type", "=", "\"basic\"", ",", "\n", "subword_tokenizer_type", "=", "\"wordpiece\"", ",", "\n", "never_split", "=", "None", ",", "\n", "unk_token", "=", "\"[UNK]\"", ",", "\n", "sep_token", "=", "\"[SEP]\"", ",", "\n", "pad_token", "=", "\"[PAD]\"", ",", "\n", "cls_token", "=", "\"[CLS]\"", ",", "\n", "mask_token", "=", "\"[MASK]\"", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs a MecabBertTokenizer.\n\n        Args:\n            **vocab_file**: Path to a one-wordpiece-per-line vocabulary file.\n            **do_lower_case**: (`optional`) boolean (default True)\n                Whether to lower case the input.\n                Only has an effect when do_basic_tokenize=True.\n            **do_word_tokenize**: (`optional`) boolean (default True)\n                Whether to do word tokenization.\n            **do_subword_tokenize**: (`optional`) boolean (default True)\n                Whether to do subword tokenization.\n            **word_tokenizer_type**: (`optional`) string (default \"basic\")\n                Type of word tokenizer.\n            **subword_tokenizer_type**: (`optional`) string (default \"wordpiece\")\n                Type of subword tokenizer.\n        \"\"\"", "\n", "super", "(", "BertTokenizer", ",", "self", ")", ".", "__init__", "(", "\n", "unk_token", "=", "unk_token", ",", "\n", "sep_token", "=", "sep_token", ",", "\n", "pad_token", "=", "pad_token", ",", "\n", "cls_token", "=", "cls_token", ",", "\n", "mask_token", "=", "mask_token", ",", "\n", "**", "kwargs", "\n", ")", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "-", "2", "# take into account special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "-", "3", "# take into account special tokens", "\n", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "vocab_file", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Can't find a vocabulary file at path '{}'. To load the vocabulary from a Google pretrained \"", "\n", "\"model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "vocab_file", ")", "\n", ")", "\n", "", "self", ".", "vocab", "=", "load_vocab", "(", "vocab_file", ")", "\n", "self", ".", "ids_to_tokens", "=", "collections", ".", "OrderedDict", "(", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "self", ".", "vocab", ".", "items", "(", ")", "]", ")", "\n", "\n", "self", ".", "do_word_tokenize", "=", "do_word_tokenize", "\n", "if", "do_word_tokenize", ":", "\n", "            ", "if", "word_tokenizer_type", "==", "\"basic\"", ":", "\n", "                ", "self", ".", "word_tokenizer", "=", "BasicTokenizer", "(", "\n", "do_lower_case", "=", "do_lower_case", ",", "never_split", "=", "never_split", ",", "tokenize_chinese_chars", "=", "False", "\n", ")", "\n", "", "elif", "word_tokenizer_type", "==", "\"mecab\"", ":", "\n", "                ", "self", ".", "word_tokenizer", "=", "MecabTokenizer", "(", "do_lower_case", "=", "do_lower_case", ",", "never_split", "=", "never_split", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Invalid word_tokenizer_type '{}' is specified.\"", ".", "format", "(", "word_tokenizer_type", ")", ")", "\n", "\n", "", "", "self", ".", "do_subword_tokenize", "=", "do_subword_tokenize", "\n", "if", "do_subword_tokenize", ":", "\n", "            ", "if", "subword_tokenizer_type", "==", "\"wordpiece\"", ":", "\n", "                ", "self", ".", "subword_tokenizer", "=", "WordpieceTokenizer", "(", "vocab", "=", "self", ".", "vocab", ",", "unk_token", "=", "self", ".", "unk_token", ")", "\n", "", "elif", "subword_tokenizer_type", "==", "\"character\"", ":", "\n", "                ", "self", ".", "subword_tokenizer", "=", "CharacterTokenizer", "(", "vocab", "=", "self", ".", "vocab", ",", "unk_token", "=", "self", ".", "unk_token", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Invalid subword_tokenizer_type '{}' is specified.\"", ".", "format", "(", "subword_tokenizer_type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert_japanese.BertJapaneseTokenizer._tokenize": [[149, 161], ["tokenization_bert_japanese.BertJapaneseTokenizer.word_tokenizer.tokenize", "tokenization_bert_japanese.BertJapaneseTokenizer.subword_tokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "", "", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "if", "self", ".", "do_word_tokenize", ":", "\n", "            ", "tokens", "=", "self", ".", "word_tokenizer", ".", "tokenize", "(", "text", ",", "never_split", "=", "self", ".", "all_special_tokens", ")", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "[", "text", "]", "\n", "\n", "", "if", "self", ".", "do_subword_tokenize", ":", "\n", "            ", "split_tokens", "=", "[", "sub_token", "for", "token", "in", "tokens", "for", "sub_token", "in", "self", ".", "subword_tokenizer", ".", "tokenize", "(", "token", ")", "]", "\n", "", "else", ":", "\n", "            ", "split_tokens", "=", "tokens", "\n", "\n", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert_japanese.MecabTokenizer.__init__": [[166, 186], ["MeCab.Tagger"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "do_lower_case", "=", "False", ",", "never_split", "=", "None", ",", "normalize_text", "=", "True", ")", ":", "\n", "        ", "\"\"\"Constructs a MecabTokenizer.\n\n        Args:\n            **do_lower_case**: (`optional`) boolean (default True)\n                Whether to lower case the input.\n            **never_split**: (`optional`) list of str\n                Kept for backward compatibility purposes.\n                Now implemented directly at the base class level (see :func:`PreTrainedTokenizer.tokenize`)\n                List of token not to split.\n            **normalize_text**: (`optional`) boolean (default True)\n                Whether to apply unicode normalization to text before tokenization.\n        \"\"\"", "\n", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "self", ".", "never_split", "=", "never_split", "if", "never_split", "is", "not", "None", "else", "[", "]", "\n", "self", ".", "normalize_text", "=", "normalize_text", "\n", "\n", "import", "MeCab", "\n", "\n", "self", ".", "mecab", "=", "MeCab", ".", "Tagger", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert_japanese.MecabTokenizer.tokenize": [[187, 212], ["tokenization_bert_japanese.MecabTokenizer.mecab.parse", "tokenization_bert_japanese.MecabTokenizer.split", "unicodedata.normalize", "line.split", "unicodedata.normalize.index", "tokens.append", "len", "token.lower.lower.lower"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "text", ",", "never_split", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text.\"\"\"", "\n", "if", "self", ".", "normalize_text", ":", "\n", "            ", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFKC\"", ",", "text", ")", "\n", "\n", "", "never_split", "=", "self", ".", "never_split", "+", "(", "never_split", "if", "never_split", "is", "not", "None", "else", "[", "]", ")", "\n", "tokens", "=", "[", "]", "\n", "\n", "mecab_output", "=", "self", ".", "mecab", ".", "parse", "(", "text", ")", "\n", "\n", "cursor", "=", "0", "\n", "for", "line", "in", "mecab_output", ".", "split", "(", "\"\\n\"", ")", ":", "\n", "            ", "if", "line", "==", "\"EOS\"", ":", "\n", "                ", "break", "\n", "\n", "", "token", ",", "_", "=", "line", ".", "split", "(", "\"\\t\"", ")", "\n", "token_start", "=", "text", ".", "index", "(", "token", ",", "cursor", ")", "\n", "token_end", "=", "token_start", "+", "len", "(", "token", ")", "\n", "if", "self", ".", "do_lower_case", "and", "token", "not", "in", "never_split", ":", "\n", "                ", "token", "=", "token", ".", "lower", "(", ")", "\n", "\n", "", "tokens", ".", "append", "(", "token", ")", "\n", "cursor", "=", "token_end", "\n", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert_japanese.CharacterTokenizer.__init__": [[217, 231], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab", ",", "unk_token", ",", "normalize_text", "=", "True", ")", ":", "\n", "        ", "\"\"\"Constructs a CharacterTokenizer.\n\n        Args:\n            **vocab**:\n                Vocabulary object.\n            **unk_token**: str\n                A special symbol for out-of-vocabulary token.\n            **normalize_text**: (`optional`) boolean (default True)\n                Whether to apply unicode normalization to text before tokenization.\n        \"\"\"", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "unk_token", "=", "unk_token", "\n", "self", ".", "normalize_text", "=", "normalize_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert_japanese.CharacterTokenizer.tokenize": [[232, 256], ["enumerate", "unicodedata.normalize", "output_tokens.append", "output_tokens.append"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text into characters.\n\n        For example:\n            input = \"apple\"\n            output = [\"a\", \"p\", \"p\", \"l\", \"e\"]\n        Args:\n            text: A single token or whitespace separated tokens.\n                This should have already been passed through `BasicTokenizer`.\n        Returns:\n            A list of characters.\n        \"\"\"", "\n", "if", "self", ".", "normalize_text", ":", "\n", "            ", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFKC\"", ",", "text", ")", "\n", "\n", "", "output_tokens", "=", "[", "]", "\n", "for", "i", ",", "char", "in", "enumerate", "(", "text", ")", ":", "\n", "            ", "if", "char", "not", "in", "self", ".", "vocab", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "continue", "\n", "\n", "", "output_tokens", ".", "append", "(", "char", ")", "\n", "\n", "", "return", "output_tokens", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_auto.AutoTokenizer.__init__": [[67, 70], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\n", "\"AutoTokenizer is designed to be instantiated \"", "\n", "\"using the `AutoTokenizer.from_pretrained(pretrained_model_name_or_path)` method.\"", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_auto.AutoTokenizer.from_pretrained": [[73, 165], ["ValueError", "tokenization_t5.T5Tokenizer.from_pretrained", "tokenization_distilbert.DistilBertTokenizer.from_pretrained", "tokenization_albert.AlbertTokenizer.from_pretrained", "tokenization_camembert.CamembertTokenizer.from_pretrained", "tokenization_xlm_roberta.XLMRobertaTokenizer.from_pretrained", "tokenization_roberta.RobertaTokenizer.from_pretrained", "tokenization_bert_japanese.BertJapaneseTokenizer.from_pretrained", "tokenization_bert.BertTokenizer.from_pretrained", "tokenization_openai.OpenAIGPTTokenizer.from_pretrained", "tokenization_gpt2.GPT2Tokenizer.from_pretrained", "tokenization_transfo_xl.TransfoXLTokenizer.from_pretrained", "tokenization_xlnet.XLNetTokenizer.from_pretrained", "tokenization_xlm.XLMTokenizer.from_pretrained", "tokenization_ctrl.CTRLTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiate a one of the tokenizer classes of the library\n        from a pre-trained model vocabulary.\n\n        The tokenizer class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `t5`: T5Tokenizer (T5 model)\n            - contains `distilbert`: DistilBertTokenizer (DistilBert model)\n            - contains `albert`: AlbertTokenizer (ALBERT model)\n            - contains `camembert`: CamembertTokenizer (CamemBERT model)\n            - contains `xlm-roberta`: XLMRobertaTokenizer (XLM-RoBERTa model)\n            - contains `roberta`: RobertaTokenizer (RoBERTa model)\n            - contains `bert-base-japanese`: BertJapaneseTokenizer (Bert model)\n            - contains `bert`: BertTokenizer (Bert model)\n            - contains `openai-gpt`: OpenAIGPTTokenizer (OpenAI GPT model)\n            - contains `gpt2`: GPT2Tokenizer (OpenAI GPT-2 model)\n            - contains `transfo-xl`: TransfoXLTokenizer (Transformer-XL model)\n            - contains `xlnet`: XLNetTokenizer (XLNet model)\n            - contains `xlm`: XLMTokenizer (XLM model)\n            - contains `ctrl`: CTRLTokenizer (Salesforce CTRL model)\n\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a predefined tokenizer to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a predefined tokenizer that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing vocabulary files required by the tokenizer, for instance saved using the :func:`~transformers.PreTrainedTokenizer.save_pretrained` method, e.g.: ``./my_model_directory/``.\n                - (not applicable to all derived classes) a path or url to a single saved vocabulary file if and only if the tokenizer only requires a single vocabulary file (e.g. Bert, XLNet), e.g.: ``./my_model_directory/vocab.txt``.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded predefined tokenizer vocabulary files should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the vocabulary files and override the cached versions if they exists.\n\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            inputs: (`optional`) positional arguments: will be passed to the Tokenizer ``__init__`` method.\n\n            kwargs: (`optional`) keyword arguments: will be passed to the Tokenizer ``__init__`` method. Can be used to set special tokens like ``bos_token``, ``eos_token``, ``unk_token``, ``sep_token``, ``pad_token``, ``cls_token``, ``mask_token``, ``additional_special_tokens``. See parameters in the doc string of :class:`~transformers.PreTrainedTokenizer` for details.\n\n        Examples::\n\n            # Download vocabulary from S3 and cache.\n            tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n\n            # Download vocabulary from S3 (user-uploaded) and cache.\n            tokenizer = AutoTokenizer.from_pretrained('dbmdz/bert-base-german-cased')\n\n            # If vocabulary files are in a directory (e.g. tokenizer was saved using `save_pretrained('./test/saved_model/')`)\n            tokenizer = AutoTokenizer.from_pretrained('./test/bert_saved_model/')\n\n        \"\"\"", "\n", "if", "\"t5\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "T5Tokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "\"distilbert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "DistilBertTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "\"albert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "AlbertTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "\"camembert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "CamembertTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlm-roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMRobertaTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "\"roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "RobertaTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "\"bert-base-japanese\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertJapaneseTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "\"bert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "\"openai-gpt\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "OpenAIGPTTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "\"gpt2\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "GPT2Tokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "\"transfo-xl\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TransfoXLTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlnet\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlm\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "elif", "\"ctrl\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "CTRLTokenizer", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "", "raise", "ValueError", "(", "\n", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm-roberta', 'xlm', 'roberta', 'distilbert,' 'camembert', 'ctrl', 'albert'\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_xlnet.XLNetConfig.__init__": [[73, 129], ["configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "32000", ",", "\n", "d_model", "=", "1024", ",", "\n", "n_layer", "=", "24", ",", "\n", "n_head", "=", "16", ",", "\n", "d_inner", "=", "4096", ",", "\n", "ff_activation", "=", "\"gelu\"", ",", "\n", "untie_r", "=", "True", ",", "\n", "attn_type", "=", "\"bi\"", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "layer_norm_eps", "=", "1e-12", ",", "\n", "dropout", "=", "0.1", ",", "\n", "mem_len", "=", "None", ",", "\n", "reuse_len", "=", "None", ",", "\n", "bi_data", "=", "False", ",", "\n", "clamp_len", "=", "-", "1", ",", "\n", "same_length", "=", "False", ",", "\n", "summary_type", "=", "\"last\"", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "\"tanh\"", ",", "\n", "summary_last_dropout", "=", "0.1", ",", "\n", "start_n_top", "=", "5", ",", "\n", "end_n_top", "=", "5", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs XLNetConfig.\n        \"\"\"", "\n", "super", "(", "XLNetConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "d_model", "=", "d_model", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "assert", "d_model", "%", "n_head", "==", "0", "\n", "self", ".", "d_head", "=", "d_model", "//", "n_head", "\n", "self", ".", "ff_activation", "=", "ff_activation", "\n", "self", ".", "d_inner", "=", "d_inner", "\n", "self", ".", "untie_r", "=", "untie_r", "\n", "self", ".", "attn_type", "=", "attn_type", "\n", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "layer_norm_eps", "=", "layer_norm_eps", "\n", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "mem_len", "=", "mem_len", "\n", "self", ".", "reuse_len", "=", "reuse_len", "\n", "self", ".", "bi_data", "=", "bi_data", "\n", "self", ".", "clamp_len", "=", "clamp_len", "\n", "self", ".", "same_length", "=", "same_length", "\n", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_last_dropout", "=", "summary_last_dropout", "\n", "self", ".", "start_n_top", "=", "start_n_top", "\n", "self", ".", "end_n_top", "=", "end_n_top", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_xlnet.XLNetConfig.max_position_embeddings": [[130, 133], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_xlnet.XLNetConfig.n_token": [[138, 141], ["None"], "methods", ["None"], ["", "@", "n_token", ".", "setter", "\n", "def", "n_token", "(", "self", ",", "value", ")", ":", "# Backward compatibility", "\n", "        ", "self", ".", "vocab_size", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_xlnet.XLNetConfig.hidden_size": [[142, 145], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "d_model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_xlnet.XLNetConfig.num_attention_heads": [[146, 149], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_xlnet.XLNetConfig.num_hidden_layers": [[150, 153], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.OpenAIGPTTokenizer.__init__": [[84, 114], ["tokenization_utils.PreTrainedTokenizer.__init__", "dict", "English", "English.Defaults.create_tokenizer", "open", "json.load", "open", "tuple", "zip", "logger.warning", "tokenization_bert.BasicTokenizer", "tokenization_openai.OpenAIGPTTokenizer.encoder.items", "merges_handle.read().split", "merge.split", "range", "len", "merges_handle.read"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "unk_token", "=", "\"<unk>\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTTokenizer", ",", "self", ")", ".", "__init__", "(", "unk_token", "=", "unk_token", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "max_len_single_sentence", "=", "(", "\n", "self", ".", "max_len", "\n", ")", "# no default special tokens - you can update this value if you add special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "(", "\n", "self", ".", "max_len", "\n", ")", "# no default special tokens - you can update this value if you add special tokens", "\n", "\n", "try", ":", "\n", "            ", "import", "ftfy", "\n", "from", "spacy", ".", "lang", ".", "en", "import", "English", "\n", "\n", "_nlp", "=", "English", "(", ")", "\n", "self", ".", "nlp", "=", "_nlp", ".", "Defaults", ".", "create_tokenizer", "(", "_nlp", ")", "\n", "self", ".", "fix_text", "=", "ftfy", ".", "fix_text", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\"ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\"", ")", "\n", "self", ".", "nlp", "=", "BasicTokenizer", "(", "do_lower_case", "=", "True", ")", "\n", "self", ".", "fix_text", "=", "None", "\n", "\n", "", "with", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "vocab_handle", ":", "\n", "            ", "self", ".", "encoder", "=", "json", ".", "load", "(", "vocab_handle", ")", "\n", "", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "merges_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "merges_handle", ":", "\n", "            ", "merges", "=", "merges_handle", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "[", "1", ":", "-", "1", "]", "\n", "", "merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "merges", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "merges", ",", "range", "(", "len", "(", "merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.OpenAIGPTTokenizer.vocab_size": [[115, 118], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.OpenAIGPTTokenizer.bpe": [[119, 162], ["tokenization_openai.get_pairs", "tuple", "min", "tuple", "len", "len", "tokenization_openai.get_pairs", "word.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_openai.OpenAIGPTTokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.get_pairs", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "word", "=", "tuple", "(", "token", "[", ":", "-", "1", "]", ")", "+", "(", "token", "[", "-", "1", "]", "+", "\"</w>\"", ",", ")", "\n", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "+", "\"</w>\"", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "\"inf\"", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "\" \"", ".", "join", "(", "word", ")", "\n", "if", "word", "==", "\"\\n  </w>\"", ":", "\n", "            ", "word", "=", "\"\\n</w>\"", "\n", "", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.OpenAIGPTTokenizer._tokenize": [[163, 177], ["tokenization_openai.OpenAIGPTTokenizer.nlp.tokenize", "tokenization_openai.OpenAIGPTTokenizer.nlp", "split_tokens.extend", "tokenization_openai.text_standardize", "split_tokens.extend", "tokenization_openai.OpenAIGPTTokenizer.fix_text", "tokenization_openai.OpenAIGPTTokenizer.bpe().split", "tokenization_openai.OpenAIGPTTokenizer.bpe().split", "tokenization_openai.OpenAIGPTTokenizer.bpe", "tokenization_openai.OpenAIGPTTokenizer.bpe", "token.text.lower"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.text_standardize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.OpenAIGPTTokenizer.bpe", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.OpenAIGPTTokenizer.bpe"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. \"\"\"", "\n", "split_tokens", "=", "[", "]", "\n", "if", "self", ".", "fix_text", "is", "None", ":", "\n", "# Using BERT's BasicTokenizer", "\n", "            ", "text", "=", "self", ".", "nlp", ".", "tokenize", "(", "text", ")", "\n", "for", "token", "in", "text", ":", "\n", "                ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "\" \"", ")", "]", ")", "\n", "", "", "else", ":", "\n", "# Using SpaCy & ftfy (original tokenization process of OpenAI GPT)", "\n", "            ", "text", "=", "self", ".", "nlp", "(", "text_standardize", "(", "self", ".", "fix_text", "(", "text", ")", ")", ")", "\n", "for", "token", "in", "text", ":", "\n", "                ", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ".", "text", ".", "lower", "(", ")", ")", ".", "split", "(", "\" \"", ")", "]", ")", "\n", "", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id": [[178, 181], ["tokenization_openai.OpenAIGPTTokenizer.encoder.get", "tokenization_openai.OpenAIGPTTokenizer.encoder.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "encoder", ".", "get", "(", "token", ",", "self", ".", "encoder", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.OpenAIGPTTokenizer._convert_id_to_token": [[182, 185], ["tokenization_openai.OpenAIGPTTokenizer.decoder.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an id in a token (BPE) using the vocab.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.OpenAIGPTTokenizer.convert_tokens_to_string": [[186, 190], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "\"\"", ".", "join", "(", "tokens", ")", ".", "replace", "(", "\"</w>\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.OpenAIGPTTokenizer.save_vocabulary": [[191, 216], ["os.path.join", "os.path.join", "os.path.isdir", "logger.error", "open", "f.write", "open", "writer.write", "sorted", "json.dumps", "tokenization_openai.OpenAIGPTTokenizer.bpe_ranks.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary and merge files to a directory.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "merge_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"merges_file\"", "]", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "encoder", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "index", "=", "0", "\n", "with", "open", "(", "merge_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "\"#version: 0.2\\n\"", ")", "\n", "for", "bpe_tokens", ",", "token_index", "in", "sorted", "(", "self", ".", "bpe_ranks", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"Saving vocabulary to {}: BPE merge indices are not consecutive.\"", "\n", "\" Please check that the tokenizer is not corrupted!\"", ".", "format", "(", "merge_file", ")", "\n", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "\" \"", ".", "join", "(", "bpe_tokens", ")", "+", "\"\\n\"", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "return", "vocab_file", ",", "merge_file", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.get_pairs": [[44, 55], ["set", "set.add"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.BeamHypotheses.add"], ["def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"\n    Return set of symbol pairs in a word.\n    word is represented as tuple of symbols (symbols being variable-length strings)\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_openai.text_standardize": [[57, 71], ["re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub", "re.sub", "re.sub", "re.sub.strip"], "function", ["None"], ["", "def", "text_standardize", "(", "text", ")", ":", "\n", "    ", "\"\"\"\n    fixes some issues the spacy tokenizer had on books corpus\n    also does some whitespace standardization\n    \"\"\"", "\n", "text", "=", "text", ".", "replace", "(", "\"\u2014\"", ",", "\"-\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u2013\"", ",", "\"-\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u2015\"", ",", "\"-\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u2026\"", ",", "\"...\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u00b4\"", ",", "\"'\"", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"\"\"(-+|~+|!+|\"+|;+|\\?+|\\++|,+|\\)+|\\(+|\\\\+|\\/+|\\*+|\\[+|\\]+|}+|{+|\\|+|_+)\"\"\"", ",", "r\" \\1 \"", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"\\s*\\n\\s*\"", ",", "\" \\n \"", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"[^\\S\\n]+\"", ",", "\" \"", ",", "text", ")", "\n", "return", "text", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_bert_original_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch": [[29, 41], ["transformers.BertConfig.from_json_file", "print", "transformers.BertForPreTraining", "transformers.load_tf_weights_in_bert", "print", "torch.save", "transformers.BertForPreTraining.state_dict", "str"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_bert.load_tf_weights_in_bert", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save"], ["def", "convert_tf_checkpoint_to_pytorch", "(", "tf_checkpoint_path", ",", "bert_config_file", ",", "pytorch_dump_path", ")", ":", "\n", "# Initialise PyTorch model", "\n", "    ", "config", "=", "BertConfig", ".", "from_json_file", "(", "bert_config_file", ")", "\n", "print", "(", "\"Building PyTorch model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "model", "=", "BertForPreTraining", "(", "config", ")", "\n", "\n", "# Load weights from tf checkpoint", "\n", "load_tf_weights_in_bert", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_dump_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.__init__": [[85, 88], ["EnvironmentError"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\n", "\"AutoConfig is designed to be instantiated \"", "\n", "\"using the `AutoConfig.from_pretrained(pretrained_model_name_or_path)` method.\"", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.for_model": [[91, 119], ["ValueError", "configuration_distilbert.DistilBertConfig", "configuration_roberta.RobertaConfig", "configuration_bert.BertConfig", "configuration_openai.OpenAIGPTConfig", "configuration_gpt2.GPT2Config", "configuration_transfo_xl.TransfoXLConfig", "configuration_xlnet.XLNetConfig", "configuration_xlm.XLMConfig", "configuration_ctrl.CTRLConfig", "configuration_albert.AlbertConfig", "configuration_camembert.CamembertConfig"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "for_model", "(", "cls", ",", "model_type", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "\"distilbert\"", "in", "model_type", ":", "\n", "            ", "return", "DistilBertConfig", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"roberta\"", "in", "model_type", ":", "\n", "            ", "return", "RobertaConfig", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"bert\"", "in", "model_type", ":", "\n", "            ", "return", "BertConfig", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"openai-gpt\"", "in", "model_type", ":", "\n", "            ", "return", "OpenAIGPTConfig", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"gpt2\"", "in", "model_type", ":", "\n", "            ", "return", "GPT2Config", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"transfo-xl\"", "in", "model_type", ":", "\n", "            ", "return", "TransfoXLConfig", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlnet\"", "in", "model_type", ":", "\n", "            ", "return", "XLNetConfig", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlm\"", "in", "model_type", ":", "\n", "            ", "return", "XLMConfig", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"ctrl\"", "in", "model_type", ":", "\n", "            ", "return", "CTRLConfig", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"albert\"", "in", "model_type", ":", "\n", "            ", "return", "AlbertConfig", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "elif", "\"camembert\"", "in", "model_type", ":", "\n", "            ", "return", "CamembertConfig", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "raise", "ValueError", "(", "\n", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'distilbert', 'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm', 'roberta', 'ctrl', 'camembert', 'albert'\"", ".", "format", "(", "model_type", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained": [[121, 217], ["ValueError", "configuration_t5.T5Config.from_pretrained", "configuration_distilbert.DistilBertConfig.from_pretrained", "configuration_albert.AlbertConfig.from_pretrained", "configuration_camembert.CamembertConfig.from_pretrained", "configuration_xlm_roberta.XLMRobertaConfig.from_pretrained", "configuration_roberta.RobertaConfig.from_pretrained", "configuration_bert.BertConfig.from_pretrained", "configuration_openai.OpenAIGPTConfig.from_pretrained", "configuration_gpt2.GPT2Config.from_pretrained", "configuration_transfo_xl.TransfoXLConfig.from_pretrained", "configuration_xlnet.XLNetConfig.from_pretrained", "configuration_xlm.XLMConfig.from_pretrained", "configuration_ctrl.CTRLConfig.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiate a one of the configuration classes of the library\n        from a pre-trained model configuration.\n\n        The configuration class to instantiate is selected as the first pattern matching\n        in the `pretrained_model_name_or_path` string (in the following order):\n            - contains `t5`: T5Config (T5 model)\n            - contains `distilbert`: DistilBertConfig (DistilBERT model)\n            - contains `albert`: AlbertConfig (ALBERT model)\n            - contains `camembert`: CamembertConfig (CamemBERT model)\n            - contains `xlm-roberta`: XLMRobertaConfig (XLM-RoBERTa model)\n            - contains `roberta`: RobertaConfig (RoBERTa model)\n            - contains `bert`: BertConfig (Bert model)\n            - contains `openai-gpt`: OpenAIGPTConfig (OpenAI GPT model)\n            - contains `gpt2`: GPT2Config (OpenAI GPT-2 model)\n            - contains `transfo-xl`: TransfoXLConfig (Transformer-XL model)\n            - contains `xlnet`: XLNetConfig (XLNet model)\n            - contains `xlm`: XLMConfig (XLM model)\n            - contains `ctrl` : CTRLConfig (CTRL model)\n        Params:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model configuration to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model configuration that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing a configuration file saved using the :func:`~transformers.PretrainedConfig.save_pretrained` method, e.g.: ``./my_model_directory/``.\n                - a path or url to a saved configuration JSON `file`, e.g.: ``./my_model_directory/configuration.json``.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            kwargs: (`optional`) dict: key/value pairs with which to update the configuration object after loading.\n\n                - The values in kwargs of any keys which are configuration attributes will be used to override the loaded values.\n                - Behavior concerning key/value pairs whose keys are *not* configuration attributes is controlled by the `return_unused_kwargs` keyword parameter.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            return_unused_kwargs: (`optional`) bool:\n\n                - If False, then this function returns just the final configuration object.\n                - If True, then this functions returns a tuple `(config, unused_kwargs)` where `unused_kwargs` is a dictionary consisting of the key/value pairs whose keys are not configuration attributes: ie the part of kwargs which has not been used to update `config` and is otherwise ignored.\n\n        Examples::\n\n            config = AutoConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            config = AutoConfig.from_pretrained('./test/bert_saved_model/')  # E.g. config (or model) was saved using `save_pretrained('./test/saved_model/')`\n            config = AutoConfig.from_pretrained('./test/bert_saved_model/my_configuration.json')\n            config = AutoConfig.from_pretrained('bert-base-uncased', output_attention=True, foo=False)\n            assert config.output_attention == True\n            config, unused_kwargs = AutoConfig.from_pretrained('bert-base-uncased', output_attention=True,\n                                                               foo=False, return_unused_kwargs=True)\n            assert config.output_attention == True\n            assert unused_kwargs == {'foo': False}\n\n        \"\"\"", "\n", "if", "\"t5\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "T5Config", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "\"distilbert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "DistilBertConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "\"albert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "AlbertConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "\"camembert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "CamembertConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlm-roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMRobertaConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "\"roberta\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "RobertaConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "\"bert\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "BertConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "\"openai-gpt\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "OpenAIGPTConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "\"gpt2\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "GPT2Config", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "\"transfo-xl\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "TransfoXLConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlnet\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLNetConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "\"xlm\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "XLMConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "elif", "\"ctrl\"", "in", "pretrained_model_name_or_path", ":", "\n", "            ", "return", "CTRLConfig", ".", "from_pretrained", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "", "raise", "ValueError", "(", "\n", "\"Unrecognized model identifier in {}. Should contains one of \"", "\n", "\"'bert', 'openai-gpt', 'gpt2', 'transfo-xl', 'xlnet', \"", "\n", "\"'xlm-roberta', 'xlm', 'roberta', 'distilbert', 'camembert', 'ctrl', 'albert'\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.xnli.XnliProcessor.__init__": [[32, 35], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "language", ",", "train_language", "=", "None", ")", ":", "\n", "        ", "self", ".", "language", "=", "language", "\n", "self", ".", "train_language", "=", "train_language", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.xnli.XnliProcessor.get_train_examples": [[36, 51], ["xnli.XnliProcessor._read_tsv", "enumerate", "os.path.join", "examples.append", "isinstance", "isinstance", "isinstance", "utils.InputExample"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "lg", "=", "self", ".", "language", "if", "self", ".", "train_language", "is", "None", "else", "self", ".", "train_language", "\n", "lines", "=", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"XNLI-MT-1.0/multinli/multinli.train.{}.tsv\"", ".", "format", "(", "lg", ")", ")", ")", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "\"train\"", ",", "i", ")", "\n", "text_a", "=", "line", "[", "0", "]", "\n", "text_b", "=", "line", "[", "1", "]", "\n", "label", "=", "\"contradiction\"", "if", "line", "[", "2", "]", "==", "\"contradictory\"", "else", "line", "[", "2", "]", "\n", "assert", "isinstance", "(", "text_a", ",", "str", ")", "and", "isinstance", "(", "text_b", ",", "str", ")", "and", "isinstance", "(", "label", ",", "str", ")", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.xnli.XnliProcessor.get_test_examples": [[52, 69], ["xnli.XnliProcessor._read_tsv", "enumerate", "os.path.join", "examples.append", "isinstance", "isinstance", "isinstance", "utils.InputExample"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_test_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "lines", "=", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"XNLI-1.0/xnli.test.tsv\"", ")", ")", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "language", "=", "line", "[", "0", "]", "\n", "if", "language", "!=", "self", ".", "language", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "\"test\"", ",", "i", ")", "\n", "text_a", "=", "line", "[", "6", "]", "\n", "text_b", "=", "line", "[", "7", "]", "\n", "label", "=", "line", "[", "1", "]", "\n", "assert", "isinstance", "(", "text_a", ",", "str", ")", "and", "isinstance", "(", "text_b", ",", "str", ")", "and", "isinstance", "(", "label", ",", "str", ")", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.xnli.XnliProcessor.get_labels": [[70, 73], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"contradiction\"", ",", "\"entailment\"", ",", "\"neutral\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.MrpcProcessor.get_example_from_tensor_dict": [[168, 175], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"sentence1\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "tensor_dict", "[", "\"sentence2\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.MrpcProcessor.get_train_examples": [[177, 181], ["logger.info", "glue.MrpcProcessor._create_examples", "glue.MrpcProcessor._read_tsv", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "logger", ".", "info", "(", "\"LOOKING AT {}\"", ".", "format", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ")", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.MrpcProcessor.get_dev_examples": [[182, 185], ["glue.MrpcProcessor._create_examples", "glue.MrpcProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.MrpcProcessor.get_labels": [[186, 189], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.MrpcProcessor._create_examples": [[190, 202], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text_a", "=", "line", "[", "3", "]", "\n", "text_b", "=", "line", "[", "4", "]", "\n", "label", "=", "line", "[", "0", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.MnliProcessor.get_example_from_tensor_dict": [[207, 214], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"premise\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "tensor_dict", "[", "\"hypothesis\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.MnliProcessor.get_train_examples": [[216, 219], ["glue.MnliProcessor._create_examples", "glue.MnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.MnliProcessor.get_dev_examples": [[220, 223], ["glue.MnliProcessor._create_examples", "glue.MnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev_matched.tsv\"", ")", ")", ",", "\"dev_matched\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.MnliProcessor.get_labels": [[224, 227], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"contradiction\"", ",", "\"entailment\"", ",", "\"neutral\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.MnliProcessor._create_examples": [[228, 240], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "8", "]", "\n", "text_b", "=", "line", "[", "9", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.MnliMismatchedProcessor.get_dev_examples": [[245, 248], ["glue.MnliMismatchedProcessor._create_examples", "glue.MnliMismatchedProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev_mismatched.tsv\"", ")", ")", ",", "\"dev_matched\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.ColaProcessor.get_example_from_tensor_dict": [[253, 260], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"sentence\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "None", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.ColaProcessor.get_train_examples": [[262, 265], ["glue.ColaProcessor._create_examples", "glue.ColaProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.ColaProcessor.get_dev_examples": [[266, 269], ["glue.ColaProcessor._create_examples", "glue.ColaProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.ColaProcessor.get_labels": [[270, 273], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.ColaProcessor._create_examples": [[274, 283], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text_a", "=", "line", "[", "3", "]", "\n", "label", "=", "line", "[", "1", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.Sst2Processor.get_example_from_tensor_dict": [[288, 295], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"sentence\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "None", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.Sst2Processor.get_train_examples": [[297, 300], ["glue.Sst2Processor._create_examples", "glue.Sst2Processor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.Sst2Processor.get_dev_examples": [[301, 304], ["glue.Sst2Processor._create_examples", "glue.Sst2Processor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.Sst2Processor.get_labels": [[305, 308], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.Sst2Processor._create_examples": [[309, 320], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text_a", "=", "line", "[", "0", "]", "\n", "label", "=", "line", "[", "1", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.StsbProcessor.get_example_from_tensor_dict": [[325, 332], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"sentence1\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "tensor_dict", "[", "\"sentence2\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.StsbProcessor.get_train_examples": [[334, 337], ["glue.StsbProcessor._create_examples", "glue.StsbProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.StsbProcessor.get_dev_examples": [[338, 341], ["glue.StsbProcessor._create_examples", "glue.StsbProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.StsbProcessor.get_labels": [[342, 345], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.StsbProcessor._create_examples": [[346, 358], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "7", "]", "\n", "text_b", "=", "line", "[", "8", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.QqpProcessor.get_example_from_tensor_dict": [[363, 370], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"question1\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "tensor_dict", "[", "\"question2\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.QqpProcessor.get_train_examples": [[372, 375], ["glue.QqpProcessor._create_examples", "glue.QqpProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.QqpProcessor.get_dev_examples": [[376, 379], ["glue.QqpProcessor._create_examples", "glue.QqpProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.QqpProcessor.get_labels": [[380, 383], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.QqpProcessor._create_examples": [[384, 399], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "try", ":", "\n", "                ", "text_a", "=", "line", "[", "3", "]", "\n", "text_b", "=", "line", "[", "4", "]", "\n", "label", "=", "line", "[", "5", "]", "\n", "", "except", "IndexError", ":", "\n", "                ", "continue", "\n", "", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.QnliProcessor.get_example_from_tensor_dict": [[404, 411], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"question\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "tensor_dict", "[", "\"sentence\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.QnliProcessor.get_train_examples": [[413, 416], ["glue.QnliProcessor._create_examples", "glue.QnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.QnliProcessor.get_dev_examples": [[417, 420], ["glue.QnliProcessor._create_examples", "glue.QnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev_matched\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.QnliProcessor.get_labels": [[421, 424], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"entailment\"", ",", "\"not_entailment\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.QnliProcessor._create_examples": [[425, 437], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "1", "]", "\n", "text_b", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.RteProcessor.get_example_from_tensor_dict": [[442, 449], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"sentence1\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "tensor_dict", "[", "\"sentence2\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.RteProcessor.get_train_examples": [[451, 454], ["glue.RteProcessor._create_examples", "glue.RteProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.RteProcessor.get_dev_examples": [[455, 458], ["glue.RteProcessor._create_examples", "glue.RteProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.RteProcessor.get_labels": [[459, 462], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"entailment\"", ",", "\"not_entailment\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.RteProcessor._create_examples": [[463, 475], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "1", "]", "\n", "text_b", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.WnliProcessor.get_example_from_tensor_dict": [[480, 487], ["utils.InputExample", "tensor_dict[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "str", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "InputExample", "(", "\n", "tensor_dict", "[", "\"idx\"", "]", ".", "numpy", "(", ")", ",", "\n", "tensor_dict", "[", "\"sentence1\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "tensor_dict", "[", "\"sentence2\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "str", "(", "tensor_dict", "[", "\"label\"", "]", ".", "numpy", "(", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.WnliProcessor.get_train_examples": [[489, 492], ["glue.WnliProcessor._create_examples", "glue.WnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.tsv\"", ")", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.WnliProcessor.get_dev_examples": [[493, 496], ["glue.WnliProcessor._create_examples", "glue.WnliProcessor._read_tsv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.tsv\"", ")", ")", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.WnliProcessor.get_labels": [[497, 500], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "\"0\"", ",", "\"1\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.WnliProcessor._create_examples": [[501, 513], ["enumerate", "examples.append", "utils.InputExample"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "line", "[", "0", "]", ")", "\n", "text_a", "=", "line", "[", "1", "]", "\n", "text_b", "=", "line", "[", "2", "]", "\n", "label", "=", "line", "[", "-", "1", "]", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.glue_convert_examples_to_features": [[31, 163], ["enumerate", "file_utils.is_tf_available", "isinstance", "tokenizer.encode_plus", "features.append", "file_utils.is_tf_available", "tf.data.Dataset.from_generator", "processor.get_labels", "logger.info", "logger.info", "enumerate", "logger.info", "processor.get_example_from_tensor_dict", "processor.tfds_map", "len", "len", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils.InputFeatures", "float", "KeyError", "tf.TensorShape", "tf.TensorShape", "tf.TensorShape", "tf.TensorShape", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_tf_available", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_tf_available", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.get_labels", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.glue.WnliProcessor.get_example_from_tensor_dict"], ["def", "glue_convert_examples_to_features", "(", "\n", "examples", ",", "\n", "tokenizer", ",", "\n", "max_length", "=", "512", ",", "\n", "task", "=", "None", ",", "\n", "label_list", "=", "None", ",", "\n", "output_mode", "=", "None", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Loads a data file into a list of ``InputFeatures``\n\n    Args:\n        examples: List of ``InputExamples`` or ``tf.data.Dataset`` containing the examples.\n        tokenizer: Instance of a tokenizer that will tokenize the examples\n        max_length: Maximum example length\n        task: GLUE task\n        label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method\n        output_mode: String indicating the output mode. Either ``regression`` or ``classification``\n        pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)\n        pad_token: Padding token\n        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)\n        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n            actual values)\n\n    Returns:\n        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n        containing the task-specific features. If the input is a list of ``InputExamples``, will return\n        a list of task-specific ``InputFeatures`` which can be fed to the model.\n\n    \"\"\"", "\n", "is_tf_dataset", "=", "False", "\n", "if", "is_tf_available", "(", ")", "and", "isinstance", "(", "examples", ",", "tf", ".", "data", ".", "Dataset", ")", ":", "\n", "        ", "is_tf_dataset", "=", "True", "\n", "\n", "", "if", "task", "is", "not", "None", ":", "\n", "        ", "processor", "=", "glue_processors", "[", "task", "]", "(", ")", "\n", "if", "label_list", "is", "None", ":", "\n", "            ", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "logger", ".", "info", "(", "\"Using label list %s for task %s\"", "%", "(", "label_list", ",", "task", ")", ")", "\n", "", "if", "output_mode", "is", "None", ":", "\n", "            ", "output_mode", "=", "glue_output_modes", "[", "task", "]", "\n", "logger", ".", "info", "(", "\"Using output mode %s for task %s\"", "%", "(", "output_mode", ",", "task", ")", ")", "\n", "\n", "", "", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d\"", "%", "(", "ex_index", ")", ")", "\n", "", "if", "is_tf_dataset", ":", "\n", "            ", "example", "=", "processor", ".", "get_example_from_tensor_dict", "(", "example", ")", "\n", "example", "=", "processor", ".", "tfds_map", "(", "example", ")", "\n", "\n", "", "inputs", "=", "tokenizer", ".", "encode_plus", "(", "example", ".", "text_a", ",", "example", ".", "text_b", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "max_length", ",", ")", "\n", "input_ids", ",", "token_type_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "attention_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "attention_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "attention_mask", "\n", "token_type_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "token_type_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "attention_mask", "=", "attention_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "token_type_ids", "=", "token_type_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "len", "(", "input_ids", ")", ",", "max_length", ")", "\n", "assert", "len", "(", "attention_mask", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "\n", "len", "(", "attention_mask", ")", ",", "max_length", "\n", ")", "\n", "assert", "len", "(", "token_type_ids", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "\n", "len", "(", "token_type_ids", ")", ",", "max_length", "\n", ")", "\n", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "label", "=", "label_map", "[", "example", ".", "label", "]", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "label", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "            ", "raise", "KeyError", "(", "output_mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"attention_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "attention_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"token_type_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "token_type_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %d)\"", "%", "(", "example", ".", "label", ",", "label", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "\n", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "token_type_ids", "=", "token_type_ids", ",", "label", "=", "label", "\n", ")", "\n", ")", "\n", "\n", "", "if", "is_tf_available", "(", ")", "and", "is_tf_dataset", ":", "\n", "\n", "        ", "def", "gen", "(", ")", ":", "\n", "            ", "for", "ex", "in", "features", ":", "\n", "                ", "yield", "(", "\n", "{", "\n", "\"input_ids\"", ":", "ex", ".", "input_ids", ",", "\n", "\"attention_mask\"", ":", "ex", ".", "attention_mask", ",", "\n", "\"token_type_ids\"", ":", "ex", ".", "token_type_ids", ",", "\n", "}", ",", "\n", "ex", ".", "label", ",", "\n", ")", "\n", "\n", "", "", "return", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "\n", "gen", ",", "\n", "(", "{", "\"input_ids\"", ":", "tf", ".", "int32", ",", "\"attention_mask\"", ":", "tf", ".", "int32", ",", "\"token_type_ids\"", ":", "tf", ".", "int32", "}", ",", "tf", ".", "int64", ")", ",", "\n", "(", "\n", "{", "\n", "\"input_ids\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "\"attention_mask\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "\"token_type_ids\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "}", ",", "\n", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputExample.__init__": [[42, 47], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputExample.__repr__": [[48, 50], ["str", "utils.InputExample.to_json_string"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputExample.to_dict": [[51, 55], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputExample.to_json_string": [[56, 59], ["json.dumps", "utils.InputExample.to_dict"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.__init__": [[74, 79], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "attention_mask", "=", "attention_mask", "\n", "self", ".", "token_type_ids", "=", "token_type_ids", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.__repr__": [[80, 82], ["str", "utils.InputFeatures.to_json_string"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_dict": [[83, 87], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_json_string": [[88, 91], ["json.dumps", "utils.InputFeatures.to_dict"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv": [[96, 101], ["open", "list", "csv.reader"], "methods", ["None"], ["@", "classmethod", "\n", "def", "_read_tsv", "(", "cls", ",", "input_file", ",", "quotechar", "=", "None", ")", ":", "\n", "        ", "\"\"\"Reads a tab separated value file.\"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8-sig\"", ")", "as", "f", ":", "\n", "            ", "return", "list", "(", "csv", ".", "reader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ",", "quotechar", "=", "quotechar", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.SingleSentenceClassificationProcessor.__init__": [[106, 111], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "labels", "=", "None", ",", "examples", "=", "None", ",", "mode", "=", "\"classification\"", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "self", ".", "labels", "=", "[", "]", "if", "labels", "is", "None", "else", "labels", "\n", "self", ".", "examples", "=", "[", "]", "if", "examples", "is", "None", "else", "examples", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "verbose", "=", "verbose", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.SingleSentenceClassificationProcessor.__len__": [[112, 114], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.SingleSentenceClassificationProcessor.__getitem__": [[115, 119], ["isinstance", "utils.SingleSentenceClassificationProcessor"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "isinstance", "(", "idx", ",", "slice", ")", ":", "\n", "            ", "return", "SingleSentenceClassificationProcessor", "(", "labels", "=", "self", ".", "labels", ",", "examples", "=", "self", ".", "examples", "[", "idx", "]", ")", "\n", "", "return", "self", ".", "examples", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.SingleSentenceClassificationProcessor.create_from_csv": [[120, 136], ["cls", "cls.add_examples_from_csv"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.SingleSentenceClassificationProcessor.add_examples_from_csv"], ["", "@", "classmethod", "\n", "def", "create_from_csv", "(", "\n", "cls", ",", "file_name", ",", "split_name", "=", "\"\"", ",", "column_label", "=", "0", ",", "column_text", "=", "1", ",", "column_id", "=", "None", ",", "skip_first_row", "=", "False", ",", "**", "kwargs", "\n", ")", ":", "\n", "        ", "processor", "=", "cls", "(", "**", "kwargs", ")", "\n", "processor", ".", "add_examples_from_csv", "(", "\n", "file_name", ",", "\n", "split_name", "=", "split_name", ",", "\n", "column_label", "=", "column_label", ",", "\n", "column_text", "=", "column_text", ",", "\n", "column_id", "=", "column_id", ",", "\n", "skip_first_row", "=", "skip_first_row", ",", "\n", "overwrite_labels", "=", "True", ",", "\n", "overwrite_examples", "=", "True", ",", "\n", ")", "\n", "return", "processor", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.SingleSentenceClassificationProcessor.create_from_examples": [[137, 142], ["cls", "cls.add_examples"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.SingleSentenceClassificationProcessor.add_examples"], ["", "@", "classmethod", "\n", "def", "create_from_examples", "(", "cls", ",", "texts_or_text_and_labels", ",", "labels", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "processor", "=", "cls", "(", "**", "kwargs", ")", "\n", "processor", ".", "add_examples", "(", "texts_or_text_and_labels", ",", "labels", "=", "labels", ")", "\n", "return", "processor", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.SingleSentenceClassificationProcessor.add_examples_from_csv": [[143, 171], ["utils.SingleSentenceClassificationProcessor._read_tsv", "enumerate", "utils.SingleSentenceClassificationProcessor.add_examples", "texts.append", "labels.append", "ids.append", "ids.append"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.DataProcessor._read_tsv", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.SingleSentenceClassificationProcessor.add_examples"], ["", "def", "add_examples_from_csv", "(", "\n", "self", ",", "\n", "file_name", ",", "\n", "split_name", "=", "\"\"", ",", "\n", "column_label", "=", "0", ",", "\n", "column_text", "=", "1", ",", "\n", "column_id", "=", "None", ",", "\n", "skip_first_row", "=", "False", ",", "\n", "overwrite_labels", "=", "False", ",", "\n", "overwrite_examples", "=", "False", ",", "\n", ")", ":", "\n", "        ", "lines", "=", "self", ".", "_read_tsv", "(", "file_name", ")", "\n", "if", "skip_first_row", ":", "\n", "            ", "lines", "=", "lines", "[", "1", ":", "]", "\n", "", "texts", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "ids", "=", "[", "]", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "texts", ".", "append", "(", "line", "[", "column_text", "]", ")", "\n", "labels", ".", "append", "(", "line", "[", "column_label", "]", ")", "\n", "if", "column_id", "is", "not", "None", ":", "\n", "                ", "ids", ".", "append", "(", "line", "[", "column_id", "]", ")", "\n", "", "else", ":", "\n", "                ", "guid", "=", "\"%s-%s\"", "%", "(", "split_name", ",", "i", ")", "if", "split_name", "else", "\"%s\"", "%", "i", "\n", "ids", ".", "append", "(", "guid", ")", "\n", "\n", "", "", "return", "self", ".", "add_examples", "(", "\n", "texts", ",", "labels", ",", "ids", ",", "overwrite_labels", "=", "overwrite_labels", ",", "overwrite_examples", "=", "overwrite_examples", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.SingleSentenceClassificationProcessor.add_examples": [[173, 205], ["set", "zip", "set.add", "examples.append", "utils.SingleSentenceClassificationProcessor.examples.extend", "list", "list", "len", "len", "len", "len", "len", "len", "isinstance", "utils.InputExample", "set().union", "set"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.BeamHypotheses.add"], ["", "def", "add_examples", "(", "\n", "self", ",", "texts_or_text_and_labels", ",", "labels", "=", "None", ",", "ids", "=", "None", ",", "overwrite_labels", "=", "False", ",", "overwrite_examples", "=", "False", "\n", ")", ":", "\n", "        ", "assert", "labels", "is", "None", "or", "len", "(", "texts_or_text_and_labels", ")", "==", "len", "(", "labels", ")", "\n", "assert", "ids", "is", "None", "or", "len", "(", "texts_or_text_and_labels", ")", "==", "len", "(", "ids", ")", "\n", "if", "ids", "is", "None", ":", "\n", "            ", "ids", "=", "[", "None", "]", "*", "len", "(", "texts_or_text_and_labels", ")", "\n", "", "if", "labels", "is", "None", ":", "\n", "            ", "labels", "=", "[", "None", "]", "*", "len", "(", "texts_or_text_and_labels", ")", "\n", "", "examples", "=", "[", "]", "\n", "added_labels", "=", "set", "(", ")", "\n", "for", "(", "text_or_text_and_label", ",", "label", ",", "guid", ")", "in", "zip", "(", "texts_or_text_and_labels", ",", "labels", ",", "ids", ")", ":", "\n", "            ", "if", "isinstance", "(", "text_or_text_and_label", ",", "(", "tuple", ",", "list", ")", ")", "and", "label", "is", "None", ":", "\n", "                ", "text", ",", "label", "=", "text_or_text_and_label", "\n", "", "else", ":", "\n", "                ", "text", "=", "text_or_text_and_label", "\n", "", "added_labels", ".", "add", "(", "label", ")", "\n", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text", ",", "text_b", "=", "None", ",", "label", "=", "label", ")", ")", "\n", "\n", "# Update examples", "\n", "", "if", "overwrite_examples", ":", "\n", "            ", "self", ".", "examples", "=", "examples", "\n", "", "else", ":", "\n", "            ", "self", ".", "examples", ".", "extend", "(", "examples", ")", "\n", "\n", "# Update labels", "\n", "", "if", "overwrite_labels", ":", "\n", "            ", "self", ".", "labels", "=", "list", "(", "added_labels", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "labels", "=", "list", "(", "set", "(", "self", ".", "labels", ")", ".", "union", "(", "added_labels", ")", ")", "\n", "\n", "", "return", "self", ".", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.SingleSentenceClassificationProcessor.get_features": [[206, 327], ["enumerate", "max", "enumerate", "tokenizer.encode", "torch.tensor.append", "zip", "features.append", "enumerate", "logger.info", "len", "logger.info", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils.InputFeatures", "tf.data.Dataset.from_generator", "min", "float", "ValueError", "file_utils.is_tf_available", "RuntimeError", "torch.tensor", "torch.tensor", "TensorDataset", "ValueError", "tf.TensorShape", "file_utils.is_torch_available", "RuntimeError", "torch.tensor", "tf.TensorShape", "tf.TensorShape", "torch.tensor", "str", "str"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_tf_available", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_torch_available"], ["", "def", "get_features", "(", "\n", "self", ",", "\n", "tokenizer", ",", "\n", "max_length", "=", "None", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", "return_tensors", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Convert examples in a list of ``InputFeatures``\n\n        Args:\n            tokenizer: Instance of a tokenizer that will tokenize the examples\n            max_length: Maximum example length\n            task: GLUE task\n            label_list: List of labels. Can be obtained from the processor using the ``processor.get_labels()`` method\n            output_mode: String indicating the output mode. Either ``regression`` or ``classification``\n            pad_on_left: If set to ``True``, the examples will be padded on the left rather than on the right (default)\n            pad_token: Padding token\n            mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n                and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n                actual values)\n\n        Returns:\n            If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n            containing the task-specific features. If the input is a list of ``InputExamples``, will return\n            a list of task-specific ``InputFeatures`` which can be fed to the model.\n\n        \"\"\"", "\n", "if", "max_length", "is", "None", ":", "\n", "            ", "max_length", "=", "tokenizer", ".", "max_len", "\n", "\n", "", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "self", ".", "labels", ")", "}", "\n", "\n", "all_input_ids", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "self", ".", "examples", ")", ":", "\n", "            ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Tokenizing example %d\"", ",", "ex_index", ")", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "encode", "(", "\n", "example", ".", "text_a", ",", "add_special_tokens", "=", "True", ",", "max_length", "=", "min", "(", "max_length", ",", "tokenizer", ".", "max_len", ")", ",", "\n", ")", "\n", "all_input_ids", ".", "append", "(", "input_ids", ")", "\n", "\n", "", "batch_length", "=", "max", "(", "len", "(", "input_ids", ")", "for", "input_ids", "in", "all_input_ids", ")", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "(", "input_ids", ",", "example", ")", ")", "in", "enumerate", "(", "zip", "(", "all_input_ids", ",", "self", ".", "examples", ")", ")", ":", "\n", "            ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Writing example %d\"", ",", "ex_index", ")", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "", "attention_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "batch_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "                ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "attention_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "attention_mask", "\n", "", "else", ":", "\n", "                ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "attention_mask", "=", "attention_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "batch_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "\n", "len", "(", "input_ids", ")", ",", "batch_length", "\n", ")", "\n", "assert", "len", "(", "attention_mask", ")", "==", "batch_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "\n", "len", "(", "attention_mask", ")", ",", "batch_length", "\n", ")", "\n", "\n", "if", "self", ".", "mode", "==", "\"classification\"", ":", "\n", "                ", "label", "=", "label_map", "[", "example", ".", "label", "]", "\n", "", "elif", "self", ".", "mode", "==", "\"regression\"", ":", "\n", "                ", "label", "=", "float", "(", "example", ".", "label", ")", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "self", ".", "mode", ")", "\n", "\n", "", "if", "ex_index", "<", "5", "and", "self", ".", "verbose", ":", "\n", "                ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"attention_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "attention_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s (id = %d)\"", "%", "(", "example", ".", "label", ",", "label", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "label", "=", "label", ")", ")", "\n", "\n", "", "if", "return_tensors", "is", "None", ":", "\n", "            ", "return", "features", "\n", "", "elif", "return_tensors", "==", "\"tf\"", ":", "\n", "            ", "if", "not", "is_tf_available", "(", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"return_tensors set to 'tf' but TensorFlow 2.0 can't be imported\"", ")", "\n", "", "import", "tensorflow", "as", "tf", "\n", "\n", "def", "gen", "(", ")", ":", "\n", "                ", "for", "ex", "in", "features", ":", "\n", "                    ", "yield", "(", "{", "\"input_ids\"", ":", "ex", ".", "input_ids", ",", "\"attention_mask\"", ":", "ex", ".", "attention_mask", "}", ",", "ex", ".", "label", ")", "\n", "\n", "", "", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "\n", "gen", ",", "\n", "(", "{", "\"input_ids\"", ":", "tf", ".", "int32", ",", "\"attention_mask\"", ":", "tf", ".", "int32", "}", ",", "tf", ".", "int64", ")", ",", "\n", "(", "{", "\"input_ids\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\"attention_mask\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", "}", ",", "tf", ".", "TensorShape", "(", "[", "]", ")", ")", ",", "\n", ")", "\n", "return", "dataset", "\n", "", "elif", "return_tensors", "==", "\"pt\"", ":", "\n", "            ", "if", "not", "is_torch_available", "(", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"return_tensors set to 'pt' but PyTorch can't be imported\"", ")", "\n", "", "import", "torch", "\n", "from", "torch", ".", "utils", ".", "data", "import", "TensorDataset", "\n", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_attention_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "attention_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "self", ".", "mode", "==", "\"classification\"", ":", "\n", "                ", "all_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "elif", "self", ".", "mode", "==", "\"regression\"", ":", "\n", "                ", "all_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_attention_mask", ",", "all_labels", ")", "\n", "return", "dataset", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"return_tensors should be one of 'tf' or 'pt'\"", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._get_example_from_tensor_dict": [[408, 430], ["squad.SquadExample", "[].numpy().decode", "[].numpy", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "tensor_dict[].numpy().decode", "[].numpy", "start.numpy", "text.numpy().decode", "zip", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy", "tensor_dict[].numpy", "text.numpy"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["def", "_get_example_from_tensor_dict", "(", "self", ",", "tensor_dict", ",", "evaluate", "=", "False", ")", ":", "\n", "        ", "if", "not", "evaluate", ":", "\n", "            ", "answer", "=", "tensor_dict", "[", "\"answers\"", "]", "[", "\"text\"", "]", "[", "0", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", "\n", "answer_start", "=", "tensor_dict", "[", "\"answers\"", "]", "[", "\"answer_start\"", "]", "[", "0", "]", ".", "numpy", "(", ")", "\n", "answers", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "answers", "=", "[", "\n", "{", "\"answer_start\"", ":", "start", ".", "numpy", "(", ")", ",", "\"text\"", ":", "text", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", "}", "\n", "for", "start", ",", "text", "in", "zip", "(", "tensor_dict", "[", "\"answers\"", "]", "[", "\"answer_start\"", "]", ",", "tensor_dict", "[", "\"answers\"", "]", "[", "\"text\"", "]", ")", "\n", "]", "\n", "\n", "answer", "=", "None", "\n", "answer_start", "=", "None", "\n", "\n", "", "return", "SquadExample", "(", "\n", "qas_id", "=", "tensor_dict", "[", "\"id\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "question_text", "=", "tensor_dict", "[", "\"question\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "context_text", "=", "tensor_dict", "[", "\"context\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "answer_text", "=", "answer", ",", "\n", "start_position_character", "=", "answer_start", ",", "\n", "title", "=", "tensor_dict", "[", "\"title\"", "]", ".", "numpy", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\n", "answers", "=", "answers", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor.get_examples_from_dataset": [[432, 462], ["tqdm.tqdm.tqdm", "examples.append", "squad.SquadProcessor._get_example_from_tensor_dict"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._get_example_from_tensor_dict"], ["", "def", "get_examples_from_dataset", "(", "self", ",", "dataset", ",", "evaluate", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Creates a list of :class:`~transformers.data.processors.squad.SquadExample` using a TFDS dataset.\n\n        Args:\n            dataset: The tfds dataset loaded from `tensorflow_datasets.load(\"squad\")`\n            evaluate: boolean specifying if in evaluation mode or in training mode\n\n        Returns:\n            List of SquadExample\n\n        Examples::\n\n            import tensorflow_datasets as tfds\n            dataset = tfds.load(\"squad\")\n\n            training_examples = get_examples_from_dataset(dataset, evaluate=False)\n            evaluation_examples = get_examples_from_dataset(dataset, evaluate=True)\n        \"\"\"", "\n", "\n", "if", "evaluate", ":", "\n", "            ", "dataset", "=", "dataset", "[", "\"validation\"", "]", "\n", "", "else", ":", "\n", "            ", "dataset", "=", "dataset", "[", "\"train\"", "]", "\n", "\n", "", "examples", "=", "[", "]", "\n", "for", "tensor_dict", "in", "tqdm", "(", "dataset", ")", ":", "\n", "            ", "examples", ".", "append", "(", "self", ".", "_get_example_from_tensor_dict", "(", "tensor_dict", ",", "evaluate", "=", "evaluate", ")", ")", "\n", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor.get_train_examples": [[463, 484], ["squad.SquadProcessor._create_examples", "ValueError", "open", "os.path.join", "json.load"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples"], ["", "def", "get_train_examples", "(", "self", ",", "data_dir", ",", "filename", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Returns the training examples from the data directory.\n\n        Args:\n            data_dir: Directory containing the data files used for training and evaluating.\n            filename: None by default, specify this if the training file has a different name than the original one\n                which is `train-v1.1.json` and `train-v2.0.json` for squad versions 1.1 and 2.0 respectively.\n\n        \"\"\"", "\n", "if", "data_dir", "is", "None", ":", "\n", "            ", "data_dir", "=", "\"\"", "\n", "\n", "", "if", "self", ".", "train_file", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"SquadProcessor should be instantiated via SquadV1Processor or SquadV2Processor\"", ")", "\n", "\n", "", "with", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "data_dir", ",", "self", ".", "train_file", "if", "filename", "is", "None", "else", "filename", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", "\n", ")", "as", "reader", ":", "\n", "            ", "input_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "", "return", "self", ".", "_create_examples", "(", "input_data", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor.get_dev_examples": [[485, 505], ["squad.SquadProcessor._create_examples", "ValueError", "open", "os.path.join", "json.load"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "data_dir", ",", "filename", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Returns the evaluation example from the data directory.\n\n        Args:\n            data_dir: Directory containing the data files used for training and evaluating.\n            filename: None by default, specify this if the evaluation file has a different name than the original one\n                which is `train-v1.1.json` and `train-v2.0.json` for squad versions 1.1 and 2.0 respectively.\n        \"\"\"", "\n", "if", "data_dir", "is", "None", ":", "\n", "            ", "data_dir", "=", "\"\"", "\n", "\n", "", "if", "self", ".", "dev_file", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"SquadProcessor should be instantiated via SquadV1Processor or SquadV2Processor\"", ")", "\n", "\n", "", "with", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "data_dir", ",", "self", ".", "dev_file", "if", "filename", "is", "None", "else", "filename", ")", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", "\n", ")", "as", "reader", ":", "\n", "            ", "input_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "", "return", "self", ".", "_create_examples", "(", "input_data", ",", "\"dev\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadProcessor._create_examples": [[506, 546], ["tqdm.tqdm.tqdm", "squad.SquadExample", "examples.append"], "methods", ["None"], ["", "def", "_create_examples", "(", "self", ",", "input_data", ",", "set_type", ")", ":", "\n", "        ", "is_training", "=", "set_type", "==", "\"train\"", "\n", "examples", "=", "[", "]", "\n", "for", "entry", "in", "tqdm", "(", "input_data", ")", ":", "\n", "            ", "title", "=", "entry", "[", "\"title\"", "]", "\n", "for", "paragraph", "in", "entry", "[", "\"paragraphs\"", "]", ":", "\n", "                ", "context_text", "=", "paragraph", "[", "\"context\"", "]", "\n", "for", "qa", "in", "paragraph", "[", "\"qas\"", "]", ":", "\n", "                    ", "qas_id", "=", "qa", "[", "\"id\"", "]", "\n", "question_text", "=", "qa", "[", "\"question\"", "]", "\n", "start_position_character", "=", "None", "\n", "answer_text", "=", "None", "\n", "answers", "=", "[", "]", "\n", "\n", "if", "\"is_impossible\"", "in", "qa", ":", "\n", "                        ", "is_impossible", "=", "qa", "[", "\"is_impossible\"", "]", "\n", "", "else", ":", "\n", "                        ", "is_impossible", "=", "False", "\n", "\n", "", "if", "not", "is_impossible", ":", "\n", "                        ", "if", "is_training", ":", "\n", "                            ", "answer", "=", "qa", "[", "\"answers\"", "]", "[", "0", "]", "\n", "answer_text", "=", "answer", "[", "\"text\"", "]", "\n", "start_position_character", "=", "answer", "[", "\"answer_start\"", "]", "\n", "", "else", ":", "\n", "                            ", "answers", "=", "qa", "[", "\"answers\"", "]", "\n", "\n", "", "", "example", "=", "SquadExample", "(", "\n", "qas_id", "=", "qas_id", ",", "\n", "question_text", "=", "question_text", ",", "\n", "context_text", "=", "context_text", ",", "\n", "answer_text", "=", "answer_text", ",", "\n", "start_position_character", "=", "start_position_character", ",", "\n", "title", "=", "title", ",", "\n", "is_impossible", "=", "is_impossible", ",", "\n", "answers", "=", "answers", ",", "\n", ")", "\n", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadExample.__init__": [[573, 618], ["squad._is_whitespace", "char_to_word_offset.append", "doc_tokens.append", "len", "min", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad._is_whitespace"], ["def", "__init__", "(", "\n", "self", ",", "\n", "qas_id", ",", "\n", "question_text", ",", "\n", "context_text", ",", "\n", "answer_text", ",", "\n", "start_position_character", ",", "\n", "title", ",", "\n", "answers", "=", "[", "]", ",", "\n", "is_impossible", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "qas_id", "=", "qas_id", "\n", "self", ".", "question_text", "=", "question_text", "\n", "self", ".", "context_text", "=", "context_text", "\n", "self", ".", "answer_text", "=", "answer_text", "\n", "self", ".", "title", "=", "title", "\n", "self", ".", "is_impossible", "=", "is_impossible", "\n", "self", ".", "answers", "=", "answers", "\n", "\n", "self", ".", "start_position", ",", "self", ".", "end_position", "=", "0", ",", "0", "\n", "\n", "doc_tokens", "=", "[", "]", "\n", "char_to_word_offset", "=", "[", "]", "\n", "prev_is_whitespace", "=", "True", "\n", "\n", "# Split on whitespace so that different tokens may be attributed to their original position.", "\n", "for", "c", "in", "self", ".", "context_text", ":", "\n", "            ", "if", "_is_whitespace", "(", "c", ")", ":", "\n", "                ", "prev_is_whitespace", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "prev_is_whitespace", ":", "\n", "                    ", "doc_tokens", ".", "append", "(", "c", ")", "\n", "", "else", ":", "\n", "                    ", "doc_tokens", "[", "-", "1", "]", "+=", "c", "\n", "", "prev_is_whitespace", "=", "False", "\n", "", "char_to_word_offset", ".", "append", "(", "len", "(", "doc_tokens", ")", "-", "1", ")", "\n", "\n", "", "self", ".", "doc_tokens", "=", "doc_tokens", "\n", "self", ".", "char_to_word_offset", "=", "char_to_word_offset", "\n", "\n", "# Start end end positions only has a value during evaluation.", "\n", "if", "start_position_character", "is", "not", "None", "and", "not", "is_impossible", ":", "\n", "            ", "self", ".", "start_position", "=", "char_to_word_offset", "[", "start_position_character", "]", "\n", "self", ".", "end_position", "=", "char_to_word_offset", "[", "\n", "min", "(", "start_position_character", "+", "len", "(", "answer_text", ")", "-", "1", ",", "len", "(", "char_to_word_offset", ")", "-", "1", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadFeatures.__init__": [[646, 677], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "attention_mask", ",", "\n", "token_type_ids", ",", "\n", "cls_index", ",", "\n", "p_mask", ",", "\n", "example_index", ",", "\n", "unique_id", ",", "\n", "paragraph_len", ",", "\n", "token_is_max_context", ",", "\n", "tokens", ",", "\n", "token_to_orig_map", ",", "\n", "start_position", ",", "\n", "end_position", ",", "\n", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "attention_mask", "=", "attention_mask", "\n", "self", ".", "token_type_ids", "=", "token_type_ids", "\n", "self", ".", "cls_index", "=", "cls_index", "\n", "self", ".", "p_mask", "=", "p_mask", "\n", "\n", "self", ".", "example_index", "=", "example_index", "\n", "self", ".", "unique_id", "=", "unique_id", "\n", "self", ".", "paragraph_len", "=", "paragraph_len", "\n", "self", ".", "token_is_max_context", "=", "token_is_max_context", "\n", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "token_to_orig_map", "=", "token_to_orig_map", "\n", "\n", "self", ".", "start_position", "=", "start_position", "\n", "self", ".", "end_position", "=", "end_position", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.SquadResult.__init__": [[689, 698], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "unique_id", ",", "start_logits", ",", "end_logits", ",", "start_top_index", "=", "None", ",", "end_top_index", "=", "None", ",", "cls_logits", "=", "None", ")", ":", "\n", "        ", "self", ".", "start_logits", "=", "start_logits", "\n", "self", ".", "end_logits", "=", "end_logits", "\n", "self", ".", "unique_id", "=", "unique_id", "\n", "\n", "if", "start_top_index", ":", "\n", "            ", "self", ".", "start_top_index", "=", "start_top_index", "\n", "self", ".", "end_top_index", "=", "end_top_index", "\n", "self", ".", "cls_logits", "=", "cls_logits", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad._improve_answer_span": [[25, 36], ["range", "tokenizer.tokenize", "range"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["def", "_improve_answer_span", "(", "doc_tokens", ",", "input_start", ",", "input_end", ",", "tokenizer", ",", "orig_answer_text", ")", ":", "\n", "    ", "\"\"\"Returns tokenized answer spans that better match the annotated answer.\"\"\"", "\n", "tok_answer_text", "=", "\" \"", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "orig_answer_text", ")", ")", "\n", "\n", "for", "new_start", "in", "range", "(", "input_start", ",", "input_end", "+", "1", ")", ":", "\n", "        ", "for", "new_end", "in", "range", "(", "input_end", ",", "new_start", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "text_span", "=", "\" \"", ".", "join", "(", "doc_tokens", "[", "new_start", ":", "(", "new_end", "+", "1", ")", "]", ")", "\n", "if", "text_span", "==", "tok_answer_text", ":", "\n", "                ", "return", "(", "new_start", ",", "new_end", ")", "\n", "\n", "", "", "", "return", "(", "input_start", ",", "input_end", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad._check_is_max_context": [[38, 56], ["enumerate", "min"], "function", ["None"], ["", "def", "_check_is_max_context", "(", "doc_spans", ",", "cur_span_index", ",", "position", ")", ":", "\n", "    ", "\"\"\"Check if this is the 'max context' doc span for the token.\"\"\"", "\n", "best_score", "=", "None", "\n", "best_span_index", "=", "None", "\n", "for", "(", "span_index", ",", "doc_span", ")", "in", "enumerate", "(", "doc_spans", ")", ":", "\n", "        ", "end", "=", "doc_span", ".", "start", "+", "doc_span", ".", "length", "-", "1", "\n", "if", "position", "<", "doc_span", ".", "start", ":", "\n", "            ", "continue", "\n", "", "if", "position", ">", "end", ":", "\n", "            ", "continue", "\n", "", "num_left_context", "=", "position", "-", "doc_span", ".", "start", "\n", "num_right_context", "=", "end", "-", "position", "\n", "score", "=", "min", "(", "num_left_context", ",", "num_right_context", ")", "+", "0.01", "*", "doc_span", ".", "length", "\n", "if", "best_score", "is", "None", "or", "score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "score", "\n", "best_span_index", "=", "span_index", "\n", "\n", "", "", "return", "cur_span_index", "==", "best_span_index", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad._new_check_is_max_context": [[58, 78], ["enumerate", "min"], "function", ["None"], ["", "def", "_new_check_is_max_context", "(", "doc_spans", ",", "cur_span_index", ",", "position", ")", ":", "\n", "    ", "\"\"\"Check if this is the 'max context' doc span for the token.\"\"\"", "\n", "# if len(doc_spans) == 1:", "\n", "# return True", "\n", "best_score", "=", "None", "\n", "best_span_index", "=", "None", "\n", "for", "(", "span_index", ",", "doc_span", ")", "in", "enumerate", "(", "doc_spans", ")", ":", "\n", "        ", "end", "=", "doc_span", "[", "\"start\"", "]", "+", "doc_span", "[", "\"length\"", "]", "-", "1", "\n", "if", "position", "<", "doc_span", "[", "\"start\"", "]", ":", "\n", "            ", "continue", "\n", "", "if", "position", ">", "end", ":", "\n", "            ", "continue", "\n", "", "num_left_context", "=", "position", "-", "doc_span", "[", "\"start\"", "]", "\n", "num_right_context", "=", "end", "-", "position", "\n", "score", "=", "min", "(", "num_left_context", ",", "num_right_context", ")", "+", "0.01", "*", "doc_span", "[", "\"length\"", "]", "\n", "if", "best_score", "is", "None", "or", "score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "score", "\n", "best_span_index", "=", "span_index", "\n", "\n", "", "", "return", "cur_span_index", "==", "best_span_index", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad._is_whitespace": [[80, 84], ["ord"], "function", ["None"], ["", "def", "_is_whitespace", "(", "c", ")", ":", "\n", "    ", "if", "c", "==", "\" \"", "or", "c", "==", "\"\\t\"", "or", "c", "==", "\"\\r\"", "or", "c", "==", "\"\\n\"", "or", "ord", "(", "c", ")", "==", "0x202F", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.squad_convert_example_to_features": [[86, 248], ["enumerate", "tokenizer.encode", "range", "orig_to_tok_index.append", "tokenizer.tokenize", "squad._improve_answer_span", "len", "tokenizer.encode_plus", "min", "tokenizer.convert_ids_to_tokens", "range", "spans.append", "len", "range", "span[].index", "numpy.array", "numpy.minimum", "features.append", "tokenization_bert.whitespace_tokenize", "actual_text.find", "logger.warning", "len", "tok_to_orig_index.append", "all_doc_tokens.append", "str", "len", "len", "len", "squad._new_check_is_max_context", "squad.SquadFeatures", "len", "len", "type", "len", "np.minimum.tolist", "len", "len", "encoded_dict[].index", "numpy.where", "len", "len", "len", "len", "numpy.array"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx._improve_answer_span", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert.whitespace_tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad._new_check_is_max_context"], ["", "def", "squad_convert_example_to_features", "(", "example", ",", "max_seq_length", ",", "doc_stride", ",", "max_query_length", ",", "is_training", ")", ":", "\n", "    ", "features", "=", "[", "]", "\n", "if", "is_training", "and", "not", "example", ".", "is_impossible", ":", "\n", "# Get start and end position", "\n", "        ", "start_position", "=", "example", ".", "start_position", "\n", "end_position", "=", "example", ".", "end_position", "\n", "\n", "# If the answer cannot be found in the text, then skip this example.", "\n", "actual_text", "=", "\" \"", ".", "join", "(", "example", ".", "doc_tokens", "[", "start_position", ":", "(", "end_position", "+", "1", ")", "]", ")", "\n", "cleaned_answer_text", "=", "\" \"", ".", "join", "(", "whitespace_tokenize", "(", "example", ".", "answer_text", ")", ")", "\n", "if", "actual_text", ".", "find", "(", "cleaned_answer_text", ")", "==", "-", "1", ":", "\n", "            ", "logger", ".", "warning", "(", "\"Could not find answer: '%s' vs. '%s'\"", ",", "actual_text", ",", "cleaned_answer_text", ")", "\n", "return", "[", "]", "\n", "\n", "", "", "tok_to_orig_index", "=", "[", "]", "\n", "orig_to_tok_index", "=", "[", "]", "\n", "all_doc_tokens", "=", "[", "]", "\n", "for", "(", "i", ",", "token", ")", "in", "enumerate", "(", "example", ".", "doc_tokens", ")", ":", "\n", "        ", "orig_to_tok_index", ".", "append", "(", "len", "(", "all_doc_tokens", ")", ")", "\n", "sub_tokens", "=", "tokenizer", ".", "tokenize", "(", "token", ")", "\n", "for", "sub_token", "in", "sub_tokens", ":", "\n", "            ", "tok_to_orig_index", ".", "append", "(", "i", ")", "\n", "all_doc_tokens", ".", "append", "(", "sub_token", ")", "\n", "\n", "", "", "if", "is_training", "and", "not", "example", ".", "is_impossible", ":", "\n", "        ", "tok_start_position", "=", "orig_to_tok_index", "[", "example", ".", "start_position", "]", "\n", "if", "example", ".", "end_position", "<", "len", "(", "example", ".", "doc_tokens", ")", "-", "1", ":", "\n", "            ", "tok_end_position", "=", "orig_to_tok_index", "[", "example", ".", "end_position", "+", "1", "]", "-", "1", "\n", "", "else", ":", "\n", "            ", "tok_end_position", "=", "len", "(", "all_doc_tokens", ")", "-", "1", "\n", "\n", "", "(", "tok_start_position", ",", "tok_end_position", ")", "=", "_improve_answer_span", "(", "\n", "all_doc_tokens", ",", "tok_start_position", ",", "tok_end_position", ",", "tokenizer", ",", "example", ".", "answer_text", "\n", ")", "\n", "\n", "", "spans", "=", "[", "]", "\n", "\n", "truncated_query", "=", "tokenizer", ".", "encode", "(", "example", ".", "question_text", ",", "add_special_tokens", "=", "False", ",", "max_length", "=", "max_query_length", ")", "\n", "sequence_added_tokens", "=", "(", "\n", "tokenizer", ".", "max_len", "-", "tokenizer", ".", "max_len_single_sentence", "+", "1", "\n", "if", "\"roberta\"", "in", "str", "(", "type", "(", "tokenizer", ")", ")", "\n", "else", "tokenizer", ".", "max_len", "-", "tokenizer", ".", "max_len_single_sentence", "\n", ")", "\n", "sequence_pair_added_tokens", "=", "tokenizer", ".", "max_len", "-", "tokenizer", ".", "max_len_sentences_pair", "\n", "\n", "span_doc_tokens", "=", "all_doc_tokens", "\n", "while", "len", "(", "spans", ")", "*", "doc_stride", "<", "len", "(", "all_doc_tokens", ")", ":", "\n", "\n", "        ", "encoded_dict", "=", "tokenizer", ".", "encode_plus", "(", "\n", "truncated_query", "if", "tokenizer", ".", "padding_side", "==", "\"right\"", "else", "span_doc_tokens", ",", "\n", "span_doc_tokens", "if", "tokenizer", ".", "padding_side", "==", "\"right\"", "else", "truncated_query", ",", "\n", "max_length", "=", "max_seq_length", ",", "\n", "return_overflowing_tokens", "=", "True", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "stride", "=", "max_seq_length", "-", "doc_stride", "-", "len", "(", "truncated_query", ")", "-", "sequence_pair_added_tokens", ",", "\n", "truncation_strategy", "=", "\"only_second\"", "if", "tokenizer", ".", "padding_side", "==", "\"right\"", "else", "\"only_first\"", ",", "\n", ")", "\n", "\n", "paragraph_len", "=", "min", "(", "\n", "len", "(", "all_doc_tokens", ")", "-", "len", "(", "spans", ")", "*", "doc_stride", ",", "\n", "max_seq_length", "-", "len", "(", "truncated_query", ")", "-", "sequence_pair_added_tokens", ",", "\n", ")", "\n", "\n", "if", "tokenizer", ".", "pad_token_id", "in", "encoded_dict", "[", "\"input_ids\"", "]", ":", "\n", "            ", "non_padded_ids", "=", "encoded_dict", "[", "\"input_ids\"", "]", "[", ":", "encoded_dict", "[", "\"input_ids\"", "]", ".", "index", "(", "tokenizer", ".", "pad_token_id", ")", "]", "\n", "", "else", ":", "\n", "            ", "non_padded_ids", "=", "encoded_dict", "[", "\"input_ids\"", "]", "\n", "\n", "", "tokens", "=", "tokenizer", ".", "convert_ids_to_tokens", "(", "non_padded_ids", ")", "\n", "\n", "token_to_orig_map", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "paragraph_len", ")", ":", "\n", "            ", "index", "=", "len", "(", "truncated_query", ")", "+", "sequence_added_tokens", "+", "i", "if", "tokenizer", ".", "padding_side", "==", "\"right\"", "else", "i", "\n", "token_to_orig_map", "[", "index", "]", "=", "tok_to_orig_index", "[", "len", "(", "spans", ")", "*", "doc_stride", "+", "i", "]", "\n", "\n", "", "encoded_dict", "[", "\"paragraph_len\"", "]", "=", "paragraph_len", "\n", "encoded_dict", "[", "\"tokens\"", "]", "=", "tokens", "\n", "encoded_dict", "[", "\"token_to_orig_map\"", "]", "=", "token_to_orig_map", "\n", "encoded_dict", "[", "\"truncated_query_with_special_tokens_length\"", "]", "=", "len", "(", "truncated_query", ")", "+", "sequence_added_tokens", "\n", "encoded_dict", "[", "\"token_is_max_context\"", "]", "=", "{", "}", "\n", "encoded_dict", "[", "\"start\"", "]", "=", "len", "(", "spans", ")", "*", "doc_stride", "\n", "encoded_dict", "[", "\"length\"", "]", "=", "paragraph_len", "\n", "\n", "spans", ".", "append", "(", "encoded_dict", ")", "\n", "\n", "if", "\"overflowing_tokens\"", "not", "in", "encoded_dict", ":", "\n", "            ", "break", "\n", "", "span_doc_tokens", "=", "encoded_dict", "[", "\"overflowing_tokens\"", "]", "\n", "\n", "", "for", "doc_span_index", "in", "range", "(", "len", "(", "spans", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "spans", "[", "doc_span_index", "]", "[", "\"paragraph_len\"", "]", ")", ":", "\n", "            ", "is_max_context", "=", "_new_check_is_max_context", "(", "spans", ",", "doc_span_index", ",", "doc_span_index", "*", "doc_stride", "+", "j", ")", "\n", "index", "=", "(", "\n", "j", "\n", "if", "tokenizer", ".", "padding_side", "==", "\"left\"", "\n", "else", "spans", "[", "doc_span_index", "]", "[", "\"truncated_query_with_special_tokens_length\"", "]", "+", "j", "\n", ")", "\n", "spans", "[", "doc_span_index", "]", "[", "\"token_is_max_context\"", "]", "[", "index", "]", "=", "is_max_context", "\n", "\n", "", "", "for", "span", "in", "spans", ":", "\n", "# Identify the position of the CLS token", "\n", "        ", "cls_index", "=", "span", "[", "\"input_ids\"", "]", ".", "index", "(", "tokenizer", ".", "cls_token_id", ")", "\n", "\n", "# p_mask: mask with 1 for token than cannot be in the answer (0 for token which can be in an answer)", "\n", "# Original TF implem also keep the classification token (set to 0) (not sure why...)", "\n", "p_mask", "=", "np", ".", "array", "(", "span", "[", "\"token_type_ids\"", "]", ")", "\n", "\n", "p_mask", "=", "np", ".", "minimum", "(", "p_mask", ",", "1", ")", "\n", "\n", "if", "tokenizer", ".", "padding_side", "==", "\"right\"", ":", "\n", "# Limit positive values to one", "\n", "            ", "p_mask", "=", "1", "-", "p_mask", "\n", "\n", "", "p_mask", "[", "np", ".", "where", "(", "np", ".", "array", "(", "span", "[", "\"input_ids\"", "]", ")", "==", "tokenizer", ".", "sep_token_id", ")", "[", "0", "]", "]", "=", "1", "\n", "\n", "# Set the CLS index to '0'", "\n", "p_mask", "[", "cls_index", "]", "=", "0", "\n", "\n", "span_is_impossible", "=", "example", ".", "is_impossible", "\n", "start_position", "=", "0", "\n", "end_position", "=", "0", "\n", "if", "is_training", "and", "not", "span_is_impossible", ":", "\n", "# For training, if our document chunk does not contain an annotation", "\n", "# we throw it out, since there is nothing to predict.", "\n", "            ", "doc_start", "=", "span", "[", "\"start\"", "]", "\n", "doc_end", "=", "span", "[", "\"start\"", "]", "+", "span", "[", "\"length\"", "]", "-", "1", "\n", "out_of_span", "=", "False", "\n", "\n", "if", "not", "(", "tok_start_position", ">=", "doc_start", "and", "tok_end_position", "<=", "doc_end", ")", ":", "\n", "                ", "out_of_span", "=", "True", "\n", "\n", "", "if", "out_of_span", ":", "\n", "                ", "start_position", "=", "cls_index", "\n", "end_position", "=", "cls_index", "\n", "span_is_impossible", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "tokenizer", ".", "padding_side", "==", "\"left\"", ":", "\n", "                    ", "doc_offset", "=", "0", "\n", "", "else", ":", "\n", "                    ", "doc_offset", "=", "len", "(", "truncated_query", ")", "+", "sequence_added_tokens", "\n", "\n", "", "start_position", "=", "tok_start_position", "-", "doc_start", "+", "doc_offset", "\n", "end_position", "=", "tok_end_position", "-", "doc_start", "+", "doc_offset", "\n", "\n", "", "", "features", ".", "append", "(", "\n", "SquadFeatures", "(", "\n", "span", "[", "\"input_ids\"", "]", ",", "\n", "span", "[", "\"attention_mask\"", "]", ",", "\n", "span", "[", "\"token_type_ids\"", "]", ",", "\n", "cls_index", ",", "\n", "p_mask", ".", "tolist", "(", ")", ",", "\n", "example_index", "=", "0", ",", "# Can not set unique_id and example_index here. They will be set after multiple processing.", "\n", "unique_id", "=", "0", ",", "\n", "paragraph_len", "=", "span", "[", "\"paragraph_len\"", "]", ",", "\n", "token_is_max_context", "=", "span", "[", "\"token_is_max_context\"", "]", ",", "\n", "tokens", "=", "span", "[", "\"tokens\"", "]", ",", "\n", "token_to_orig_map", "=", "span", "[", "\"token_to_orig_map\"", "]", ",", "\n", "start_position", "=", "start_position", ",", "\n", "end_position", "=", "end_position", ",", "\n", ")", "\n", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.squad_convert_example_to_features_init": [[250, 253], ["None"], "function", ["None"], ["", "def", "squad_convert_example_to_features_init", "(", "tokenizer_for_convert", ")", ":", "\n", "    ", "global", "tokenizer", "\n", "tokenizer", "=", "tokenizer_for_convert", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad.squad_convert_examples_to_features": [[255, 397], ["min", "tqdm.tqdm", "multiprocessing.cpu_count", "multiprocessing.Pool", "functools.partial", "list", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "tqdm.tqdm", "len", "new_features.append", "file_utils.is_torch_available", "RuntimeError", "torch.arange", "TensorDataset", "torch.tensor", "torch.tensor", "TensorDataset", "tf.data.Dataset.from_generator", "p.imap", "torch.tensor.size", "file_utils.is_tf_available", "RuntimeError", "len", "tf.TensorShape", "tf.TensorShape", "tf.TensorShape", "tf.TensorShape", "tf.TensorShape", "tf.TensorShape", "tf.TensorShape"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_torch_available", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_tf_available"], ["", "def", "squad_convert_examples_to_features", "(", "\n", "examples", ",", "tokenizer", ",", "max_seq_length", ",", "doc_stride", ",", "max_query_length", ",", "is_training", ",", "return_dataset", "=", "False", ",", "threads", "=", "1", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Converts a list of examples into a list of features that can be directly given as input to a model.\n    It is model-dependant and takes advantage of many of the tokenizer's features to create the model's inputs.\n\n    Args:\n        examples: list of :class:`~transformers.data.processors.squad.SquadExample`\n        tokenizer: an instance of a child of :class:`~transformers.PreTrainedTokenizer`\n        max_seq_length: The maximum sequence length of the inputs.\n        doc_stride: The stride used when the context is too large and is split across several features.\n        max_query_length: The maximum length of the query.\n        is_training: whether to create features for model evaluation or model training.\n        return_dataset: Default False. Either 'pt' or 'tf'.\n            if 'pt': returns a torch.data.TensorDataset,\n            if 'tf': returns a tf.data.Dataset\n        threads: multiple processing threadsa-smi\n\n\n    Returns:\n        list of :class:`~transformers.data.processors.squad.SquadFeatures`\n\n    Example::\n\n        processor = SquadV2Processor()\n        examples = processor.get_dev_examples(data_dir)\n\n        features = squad_convert_examples_to_features(\n            examples=examples,\n            tokenizer=tokenizer,\n            max_seq_length=args.max_seq_length,\n            doc_stride=args.doc_stride,\n            max_query_length=args.max_query_length,\n            is_training=not evaluate,\n        )\n    \"\"\"", "\n", "\n", "# Defining helper methods", "\n", "features", "=", "[", "]", "\n", "threads", "=", "min", "(", "threads", ",", "cpu_count", "(", ")", ")", "\n", "with", "Pool", "(", "threads", ",", "initializer", "=", "squad_convert_example_to_features_init", ",", "initargs", "=", "(", "tokenizer", ",", ")", ")", "as", "p", ":", "\n", "        ", "annotate_", "=", "partial", "(", "\n", "squad_convert_example_to_features", ",", "\n", "max_seq_length", "=", "max_seq_length", ",", "\n", "doc_stride", "=", "doc_stride", ",", "\n", "max_query_length", "=", "max_query_length", ",", "\n", "is_training", "=", "is_training", ",", "\n", ")", "\n", "features", "=", "list", "(", "\n", "tqdm", "(", "\n", "p", ".", "imap", "(", "annotate_", ",", "examples", ",", "chunksize", "=", "32", ")", ",", "\n", "total", "=", "len", "(", "examples", ")", ",", "\n", "desc", "=", "\"convert squad examples to features\"", ",", "\n", ")", "\n", ")", "\n", "", "new_features", "=", "[", "]", "\n", "unique_id", "=", "1000000000", "\n", "example_index", "=", "0", "\n", "for", "example_features", "in", "tqdm", "(", "features", ",", "total", "=", "len", "(", "features", ")", ",", "desc", "=", "\"add example index and unique id\"", ")", ":", "\n", "        ", "if", "not", "example_features", ":", "\n", "            ", "continue", "\n", "", "for", "example_feature", "in", "example_features", ":", "\n", "            ", "example_feature", ".", "example_index", "=", "example_index", "\n", "example_feature", ".", "unique_id", "=", "unique_id", "\n", "new_features", ".", "append", "(", "example_feature", ")", "\n", "unique_id", "+=", "1", "\n", "", "example_index", "+=", "1", "\n", "", "features", "=", "new_features", "\n", "del", "new_features", "\n", "if", "return_dataset", "==", "\"pt\"", ":", "\n", "        ", "if", "not", "is_torch_available", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"PyTorch must be installed to return a PyTorch dataset.\"", ")", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_attention_masks", "=", "torch", ".", "tensor", "(", "[", "f", ".", "attention_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_token_type_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "token_type_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_cls_index", "=", "torch", ".", "tensor", "(", "[", "f", ".", "cls_index", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_p_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "p_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "if", "not", "is_training", ":", "\n", "            ", "all_example_index", "=", "torch", ".", "arange", "(", "all_input_ids", ".", "size", "(", "0", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "dataset", "=", "TensorDataset", "(", "\n", "all_input_ids", ",", "all_attention_masks", ",", "all_token_type_ids", ",", "all_example_index", ",", "all_cls_index", ",", "all_p_mask", "\n", ")", "\n", "", "else", ":", "\n", "            ", "all_start_positions", "=", "torch", ".", "tensor", "(", "[", "f", ".", "start_position", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_end_positions", "=", "torch", ".", "tensor", "(", "[", "f", ".", "end_position", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "dataset", "=", "TensorDataset", "(", "\n", "all_input_ids", ",", "\n", "all_attention_masks", ",", "\n", "all_token_type_ids", ",", "\n", "all_start_positions", ",", "\n", "all_end_positions", ",", "\n", "all_cls_index", ",", "\n", "all_p_mask", ",", "\n", ")", "\n", "\n", "", "return", "features", ",", "dataset", "\n", "", "elif", "return_dataset", "==", "\"tf\"", ":", "\n", "        ", "if", "not", "is_tf_available", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"TensorFlow must be installed to return a TensorFlow dataset.\"", ")", "\n", "\n", "", "def", "gen", "(", ")", ":", "\n", "            ", "for", "ex", "in", "features", ":", "\n", "                ", "yield", "(", "\n", "{", "\n", "\"input_ids\"", ":", "ex", ".", "input_ids", ",", "\n", "\"attention_mask\"", ":", "ex", ".", "attention_mask", ",", "\n", "\"token_type_ids\"", ":", "ex", ".", "token_type_ids", ",", "\n", "}", ",", "\n", "{", "\n", "\"start_position\"", ":", "ex", ".", "start_position", ",", "\n", "\"end_position\"", ":", "ex", ".", "end_position", ",", "\n", "\"cls_index\"", ":", "ex", ".", "cls_index", ",", "\n", "\"p_mask\"", ":", "ex", ".", "p_mask", ",", "\n", "}", ",", "\n", ")", "\n", "\n", "", "", "return", "tf", ".", "data", ".", "Dataset", ".", "from_generator", "(", "\n", "gen", ",", "\n", "(", "\n", "{", "\"input_ids\"", ":", "tf", ".", "int32", ",", "\"attention_mask\"", ":", "tf", ".", "int32", ",", "\"token_type_ids\"", ":", "tf", ".", "int32", "}", ",", "\n", "{", "\"start_position\"", ":", "tf", ".", "int64", ",", "\"end_position\"", ":", "tf", ".", "int64", ",", "\"cls_index\"", ":", "tf", ".", "int64", ",", "\"p_mask\"", ":", "tf", ".", "int32", "}", ",", "\n", ")", ",", "\n", "(", "\n", "{", "\n", "\"input_ids\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "\"attention_mask\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "\"token_type_ids\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "}", ",", "\n", "{", "\n", "\"start_position\"", ":", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "\"end_position\"", ":", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "\"cls_index\"", ":", "tf", ".", "TensorShape", "(", "[", "]", ")", ",", "\n", "\"p_mask\"", ":", "tf", ".", "TensorShape", "(", "[", "None", "]", ")", ",", "\n", "}", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.__init__.is_sklearn_available": [[26, 28], ["None"], "function", ["None"], ["from", ".", "configuration_ctrl", "import", "CTRL_PRETRAINED_CONFIG_ARCHIVE_MAP", ",", "CTRLConfig", "\n", "from", ".", "configuration_distilbert", "import", "DISTILBERT_PRETRAINED_CONFIG_ARCHIVE_MAP", ",", "DistilBertConfig", "\n", "from", ".", "configuration_gpt2", "import", "GPT2_PRETRAINED_CONFIG_ARCHIVE_MAP", ",", "GPT2Config", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.normalize_answer": [[24, 42], ["squad_metrics.normalize_answer.white_space_fix"], "function", ["None"], ["def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "regex", "=", "re", ".", "compile", "(", "r\"\\b(a|an|the)\\b\"", ",", "re", ".", "UNICODE", ")", "\n", "return", "re", ".", "sub", "(", "regex", ",", "\" \"", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "\" \"", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "\"\"", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.get_tokens": [[44, 48], ["normalize_answer().split", "squad_metrics.normalize_answer"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.normalize_answer"], ["", "def", "get_tokens", "(", "s", ")", ":", "\n", "    ", "if", "not", "s", ":", "\n", "        ", "return", "[", "]", "\n", "", "return", "normalize_answer", "(", "s", ")", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.compute_exact": [[50, 52], ["int", "squad_metrics.normalize_answer", "squad_metrics.normalize_answer"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.normalize_answer", "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.normalize_answer"], ["", "def", "compute_exact", "(", "a_gold", ",", "a_pred", ")", ":", "\n", "    ", "return", "int", "(", "normalize_answer", "(", "a_gold", ")", "==", "normalize_answer", "(", "a_pred", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.compute_f1": [[54, 68], ["squad_metrics.get_tokens", "squad_metrics.get_tokens", "sum", "collections.Counter", "collections.Counter", "common.values", "int", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.get_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.get_tokens"], ["", "def", "compute_f1", "(", "a_gold", ",", "a_pred", ")", ":", "\n", "    ", "gold_toks", "=", "get_tokens", "(", "a_gold", ")", "\n", "pred_toks", "=", "get_tokens", "(", "a_pred", ")", "\n", "common", "=", "collections", ".", "Counter", "(", "gold_toks", ")", "&", "collections", ".", "Counter", "(", "pred_toks", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "len", "(", "gold_toks", ")", "==", "0", "or", "len", "(", "pred_toks", ")", "==", "0", ":", "\n", "# If either is no-answer, then F1 is 1 if they agree, 0 otherwise", "\n", "        ", "return", "int", "(", "gold_toks", "==", "pred_toks", ")", "\n", "", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "pred_toks", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "gold_toks", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.get_raw_scores": [[70, 94], ["max", "max", "print", "squad_metrics.normalize_answer", "squad_metrics.compute_exact", "squad_metrics.compute_f1"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.normalize_answer", "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.compute_exact", "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.compute_f1"], ["", "def", "get_raw_scores", "(", "examples", ",", "preds", ")", ":", "\n", "    ", "\"\"\"\n    Computes the exact and f1 scores from the examples and the model predictions\n    \"\"\"", "\n", "exact_scores", "=", "{", "}", "\n", "f1_scores", "=", "{", "}", "\n", "\n", "for", "example", "in", "examples", ":", "\n", "        ", "qas_id", "=", "example", ".", "qas_id", "\n", "gold_answers", "=", "[", "answer", "[", "\"text\"", "]", "for", "answer", "in", "example", ".", "answers", "if", "normalize_answer", "(", "answer", "[", "\"text\"", "]", ")", "]", "\n", "\n", "if", "not", "gold_answers", ":", "\n", "# For unanswerable questions, only correct answer is empty string", "\n", "            ", "gold_answers", "=", "[", "\"\"", "]", "\n", "\n", "", "if", "qas_id", "not", "in", "preds", ":", "\n", "            ", "print", "(", "\"Missing prediction for %s\"", "%", "qas_id", ")", "\n", "continue", "\n", "\n", "", "prediction", "=", "preds", "[", "qas_id", "]", "\n", "exact_scores", "[", "qas_id", "]", "=", "max", "(", "compute_exact", "(", "a", ",", "prediction", ")", "for", "a", "in", "gold_answers", ")", "\n", "f1_scores", "[", "qas_id", "]", "=", "max", "(", "compute_f1", "(", "a", ",", "prediction", ")", "for", "a", "in", "gold_answers", ")", "\n", "\n", "", "return", "exact_scores", ",", "f1_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.apply_no_ans_threshold": [[96, 105], ["scores.items", "float"], "function", ["None"], ["", "def", "apply_no_ans_threshold", "(", "scores", ",", "na_probs", ",", "qid_to_has_ans", ",", "na_prob_thresh", ")", ":", "\n", "    ", "new_scores", "=", "{", "}", "\n", "for", "qid", ",", "s", "in", "scores", ".", "items", "(", ")", ":", "\n", "        ", "pred_na", "=", "na_probs", "[", "qid", "]", ">", "na_prob_thresh", "\n", "if", "pred_na", ":", "\n", "            ", "new_scores", "[", "qid", "]", "=", "float", "(", "not", "qid_to_has_ans", "[", "qid", "]", ")", "\n", "", "else", ":", "\n", "            ", "new_scores", "[", "qid", "]", "=", "s", "\n", "", "", "return", "new_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.make_eval_dict": [[107, 124], ["len", "collections.OrderedDict", "len", "collections.OrderedDict", "sum", "sum", "sum", "sum", "exact_scores.values", "f1_scores.values"], "function", ["None"], ["", "def", "make_eval_dict", "(", "exact_scores", ",", "f1_scores", ",", "qid_list", "=", "None", ")", ":", "\n", "    ", "if", "not", "qid_list", ":", "\n", "        ", "total", "=", "len", "(", "exact_scores", ")", "\n", "return", "collections", ".", "OrderedDict", "(", "\n", "[", "\n", "(", "\"exact\"", ",", "100.0", "*", "sum", "(", "exact_scores", ".", "values", "(", ")", ")", "/", "total", ")", ",", "\n", "(", "\"f1\"", ",", "100.0", "*", "sum", "(", "f1_scores", ".", "values", "(", ")", ")", "/", "total", ")", ",", "\n", "(", "\"total\"", ",", "total", ")", ",", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "        ", "total", "=", "len", "(", "qid_list", ")", "\n", "return", "collections", ".", "OrderedDict", "(", "\n", "[", "\n", "(", "\"exact\"", ",", "100.0", "*", "sum", "(", "exact_scores", "[", "k", "]", "for", "k", "in", "qid_list", ")", "/", "total", ")", ",", "\n", "(", "\"f1\"", ",", "100.0", "*", "sum", "(", "f1_scores", "[", "k", "]", "for", "k", "in", "qid_list", ")", "/", "total", ")", ",", "\n", "(", "\"total\"", ",", "total", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.merge_eval": [[128, 131], ["None"], "function", ["None"], ["", "", "def", "merge_eval", "(", "main_eval", ",", "new_eval", ",", "prefix", ")", ":", "\n", "    ", "for", "k", "in", "new_eval", ":", "\n", "        ", "main_eval", "[", "\"%s_%s\"", "%", "(", "prefix", ",", "k", ")", "]", "=", "new_eval", "[", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.find_best_thresh_v2": [[133, 165], ["sum", "sorted", "enumerate", "len"], "function", ["None"], ["", "", "def", "find_best_thresh_v2", "(", "preds", ",", "scores", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "    ", "num_no_ans", "=", "sum", "(", "1", "for", "k", "in", "qid_to_has_ans", "if", "not", "qid_to_has_ans", "[", "k", "]", ")", "\n", "cur_score", "=", "num_no_ans", "\n", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "0.0", "\n", "qid_list", "=", "sorted", "(", "na_probs", ",", "key", "=", "lambda", "k", ":", "na_probs", "[", "k", "]", ")", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "        ", "if", "qid", "not", "in", "scores", ":", "\n", "            ", "continue", "\n", "", "if", "qid_to_has_ans", "[", "qid", "]", ":", "\n", "            ", "diff", "=", "scores", "[", "qid", "]", "\n", "", "else", ":", "\n", "            ", "if", "preds", "[", "qid", "]", ":", "\n", "                ", "diff", "=", "-", "1", "\n", "", "else", ":", "\n", "                ", "diff", "=", "0", "\n", "", "", "cur_score", "+=", "diff", "\n", "if", "cur_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "na_probs", "[", "qid", "]", "\n", "\n", "", "", "has_ans_score", ",", "has_ans_cnt", "=", "0", ",", "0", "\n", "for", "qid", "in", "qid_list", ":", "\n", "        ", "if", "not", "qid_to_has_ans", "[", "qid", "]", ":", "\n", "            ", "continue", "\n", "", "has_ans_cnt", "+=", "1", "\n", "\n", "if", "qid", "not", "in", "scores", ":", "\n", "            ", "continue", "\n", "", "has_ans_score", "+=", "scores", "[", "qid", "]", "\n", "\n", "", "return", "100.0", "*", "best_score", "/", "len", "(", "scores", ")", ",", "best_thresh", ",", "1.0", "*", "has_ans_score", "/", "has_ans_cnt", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.find_all_best_thresh_v2": [[167, 176], ["squad_metrics.find_best_thresh_v2", "squad_metrics.find_best_thresh_v2"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.find_best_thresh_v2", "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.find_best_thresh_v2"], ["", "def", "find_all_best_thresh_v2", "(", "main_eval", ",", "preds", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "    ", "best_exact", ",", "exact_thresh", ",", "has_ans_exact", "=", "find_best_thresh_v2", "(", "preds", ",", "exact_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "best_f1", ",", "f1_thresh", ",", "has_ans_f1", "=", "find_best_thresh_v2", "(", "preds", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "main_eval", "[", "\"best_exact\"", "]", "=", "best_exact", "\n", "main_eval", "[", "\"best_exact_thresh\"", "]", "=", "exact_thresh", "\n", "main_eval", "[", "\"best_f1\"", "]", "=", "best_f1", "\n", "main_eval", "[", "\"best_f1_thresh\"", "]", "=", "f1_thresh", "\n", "main_eval", "[", "\"has_ans_exact\"", "]", "=", "has_ans_exact", "\n", "main_eval", "[", "\"has_ans_f1\"", "]", "=", "has_ans_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.find_best_thresh": [[178, 199], ["sum", "sorted", "enumerate", "len"], "function", ["None"], ["", "def", "find_best_thresh", "(", "preds", ",", "scores", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "    ", "num_no_ans", "=", "sum", "(", "1", "for", "k", "in", "qid_to_has_ans", "if", "not", "qid_to_has_ans", "[", "k", "]", ")", "\n", "cur_score", "=", "num_no_ans", "\n", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "0.0", "\n", "qid_list", "=", "sorted", "(", "na_probs", ",", "key", "=", "lambda", "k", ":", "na_probs", "[", "k", "]", ")", "\n", "for", "_", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "        ", "if", "qid", "not", "in", "scores", ":", "\n", "            ", "continue", "\n", "", "if", "qid_to_has_ans", "[", "qid", "]", ":", "\n", "            ", "diff", "=", "scores", "[", "qid", "]", "\n", "", "else", ":", "\n", "            ", "if", "preds", "[", "qid", "]", ":", "\n", "                ", "diff", "=", "-", "1", "\n", "", "else", ":", "\n", "                ", "diff", "=", "0", "\n", "", "", "cur_score", "+=", "diff", "\n", "if", "cur_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "na_probs", "[", "qid", "]", "\n", "", "", "return", "100.0", "*", "best_score", "/", "len", "(", "scores", ")", ",", "best_thresh", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.find_all_best_thresh": [[201, 209], ["squad_metrics.find_best_thresh", "squad_metrics.find_best_thresh"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.find_best_thresh", "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.find_best_thresh"], ["", "def", "find_all_best_thresh", "(", "main_eval", ",", "preds", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "    ", "best_exact", ",", "exact_thresh", "=", "find_best_thresh", "(", "preds", ",", "exact_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "best_f1", ",", "f1_thresh", "=", "find_best_thresh", "(", "preds", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "\n", "main_eval", "[", "\"best_exact\"", "]", "=", "best_exact", "\n", "main_eval", "[", "\"best_exact_thresh\"", "]", "=", "exact_thresh", "\n", "main_eval", "[", "\"best_f1\"", "]", "=", "best_f1", "\n", "main_eval", "[", "\"best_f1_thresh\"", "]", "=", "f1_thresh", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.squad_evaluate": [[211, 240], ["squad_metrics.get_raw_scores", "squad_metrics.apply_no_ans_threshold", "squad_metrics.apply_no_ans_threshold", "squad_metrics.make_eval_dict", "bool", "squad_metrics.make_eval_dict", "squad_metrics.merge_eval", "squad_metrics.make_eval_dict", "squad_metrics.merge_eval", "squad_metrics.find_all_best_thresh", "qas_id_to_has_answer.items", "qas_id_to_has_answer.items"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.get_raw_scores", "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.apply_no_ans_threshold", "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.apply_no_ans_threshold", "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.make_eval_dict", "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.make_eval_dict", "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.merge_eval", "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.make_eval_dict", "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.merge_eval", "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.find_all_best_thresh"], ["", "def", "squad_evaluate", "(", "examples", ",", "preds", ",", "no_answer_probs", "=", "None", ",", "no_answer_probability_threshold", "=", "1.0", ")", ":", "\n", "    ", "qas_id_to_has_answer", "=", "{", "example", ".", "qas_id", ":", "bool", "(", "example", ".", "answers", ")", "for", "example", "in", "examples", "}", "\n", "has_answer_qids", "=", "[", "qas_id", "for", "qas_id", ",", "has_answer", "in", "qas_id_to_has_answer", ".", "items", "(", ")", "if", "has_answer", "]", "\n", "no_answer_qids", "=", "[", "qas_id", "for", "qas_id", ",", "has_answer", "in", "qas_id_to_has_answer", ".", "items", "(", ")", "if", "not", "has_answer", "]", "\n", "\n", "if", "no_answer_probs", "is", "None", ":", "\n", "        ", "no_answer_probs", "=", "{", "k", ":", "0.0", "for", "k", "in", "preds", "}", "\n", "\n", "", "exact", ",", "f1", "=", "get_raw_scores", "(", "examples", ",", "preds", ")", "\n", "\n", "exact_threshold", "=", "apply_no_ans_threshold", "(", "\n", "exact", ",", "no_answer_probs", ",", "qas_id_to_has_answer", ",", "no_answer_probability_threshold", "\n", ")", "\n", "f1_threshold", "=", "apply_no_ans_threshold", "(", "f1", ",", "no_answer_probs", ",", "qas_id_to_has_answer", ",", "no_answer_probability_threshold", ")", "\n", "\n", "evaluation", "=", "make_eval_dict", "(", "exact_threshold", ",", "f1_threshold", ")", "\n", "\n", "if", "has_answer_qids", ":", "\n", "        ", "has_ans_eval", "=", "make_eval_dict", "(", "exact_threshold", ",", "f1_threshold", ",", "qid_list", "=", "has_answer_qids", ")", "\n", "merge_eval", "(", "evaluation", ",", "has_ans_eval", ",", "\"HasAns\"", ")", "\n", "\n", "", "if", "no_answer_qids", ":", "\n", "        ", "no_ans_eval", "=", "make_eval_dict", "(", "exact_threshold", ",", "f1_threshold", ",", "qid_list", "=", "no_answer_qids", ")", "\n", "merge_eval", "(", "evaluation", ",", "no_ans_eval", ",", "\"NoAns\"", ")", "\n", "\n", "", "if", "no_answer_probs", ":", "\n", "        ", "find_all_best_thresh", "(", "evaluation", ",", "preds", ",", "exact", ",", "f1", ",", "no_answer_probs", ",", "qas_id_to_has_answer", ")", "\n", "\n", "", "return", "evaluation", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.get_final_text": [[242, 334], ["transformers.tokenization_bert.BasicTokenizer", "tok_text.find", "squad_metrics.get_final_text._strip_spaces"], "function", ["None"], ["", "def", "get_final_text", "(", "pred_text", ",", "orig_text", ",", "do_lower_case", ",", "verbose_logging", "=", "False", ")", ":", "\n", "    ", "\"\"\"Project the tokenized prediction back to the original text.\"\"\"", "\n", "\n", "# When we created the data, we kept track of the alignment between original", "\n", "# (whitespace tokenized) tokens and our WordPiece tokenized tokens. So", "\n", "# now `orig_text` contains the span of our original text corresponding to the", "\n", "# span that we predicted.", "\n", "#", "\n", "# However, `orig_text` may contain extra characters that we don't want in", "\n", "# our prediction.", "\n", "#", "\n", "# For example, let's say:", "\n", "#   pred_text = steve smith", "\n", "#   orig_text = Steve Smith's", "\n", "#", "\n", "# We don't want to return `orig_text` because it contains the extra \"'s\".", "\n", "#", "\n", "# We don't want to return `pred_text` because it's already been normalized", "\n", "# (the SQuAD eval script also does punctuation stripping/lower casing but", "\n", "# our tokenizer does additional normalization like stripping accent", "\n", "# characters).", "\n", "#", "\n", "# What we really want to return is \"Steve Smith\".", "\n", "#", "\n", "# Therefore, we have to apply a semi-complicated alignment heuristic between", "\n", "# `pred_text` and `orig_text` to get a character-to-character alignment. This", "\n", "# can fail in certain cases in which case we just return `orig_text`.", "\n", "\n", "def", "_strip_spaces", "(", "text", ")", ":", "\n", "        ", "ns_chars", "=", "[", "]", "\n", "ns_to_s_map", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "(", "i", ",", "c", ")", "in", "enumerate", "(", "text", ")", ":", "\n", "            ", "if", "c", "==", "\" \"", ":", "\n", "                ", "continue", "\n", "", "ns_to_s_map", "[", "len", "(", "ns_chars", ")", "]", "=", "i", "\n", "ns_chars", ".", "append", "(", "c", ")", "\n", "", "ns_text", "=", "\"\"", ".", "join", "(", "ns_chars", ")", "\n", "return", "(", "ns_text", ",", "ns_to_s_map", ")", "\n", "\n", "# We first tokenize `orig_text`, strip whitespace from the result", "\n", "# and `pred_text`, and check if they are the same length. If they are", "\n", "# NOT the same length, the heuristic has failed. If they are the same", "\n", "# length, we assume the characters are one-to-one aligned.", "\n", "", "tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ")", "\n", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "orig_text", ")", ")", "\n", "\n", "start_position", "=", "tok_text", ".", "find", "(", "pred_text", ")", "\n", "if", "start_position", "==", "-", "1", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Unable to find text: '%s' in '%s'\"", "%", "(", "pred_text", ",", "orig_text", ")", ")", "\n", "", "return", "orig_text", "\n", "", "end_position", "=", "start_position", "+", "len", "(", "pred_text", ")", "-", "1", "\n", "\n", "(", "orig_ns_text", ",", "orig_ns_to_s_map", ")", "=", "_strip_spaces", "(", "orig_text", ")", "\n", "(", "tok_ns_text", ",", "tok_ns_to_s_map", ")", "=", "_strip_spaces", "(", "tok_text", ")", "\n", "\n", "if", "len", "(", "orig_ns_text", ")", "!=", "len", "(", "tok_ns_text", ")", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Length not equal after stripping spaces: '%s' vs '%s'\"", ",", "orig_ns_text", ",", "tok_ns_text", ")", "\n", "", "return", "orig_text", "\n", "\n", "# We then project the characters in `pred_text` back to `orig_text` using", "\n", "# the character-to-character alignment.", "\n", "", "tok_s_to_ns_map", "=", "{", "}", "\n", "for", "(", "i", ",", "tok_index", ")", "in", "tok_ns_to_s_map", ".", "items", "(", ")", ":", "\n", "        ", "tok_s_to_ns_map", "[", "tok_index", "]", "=", "i", "\n", "\n", "", "orig_start_position", "=", "None", "\n", "if", "start_position", "in", "tok_s_to_ns_map", ":", "\n", "        ", "ns_start_position", "=", "tok_s_to_ns_map", "[", "start_position", "]", "\n", "if", "ns_start_position", "in", "orig_ns_to_s_map", ":", "\n", "            ", "orig_start_position", "=", "orig_ns_to_s_map", "[", "ns_start_position", "]", "\n", "\n", "", "", "if", "orig_start_position", "is", "None", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Couldn't map start position\"", ")", "\n", "", "return", "orig_text", "\n", "\n", "", "orig_end_position", "=", "None", "\n", "if", "end_position", "in", "tok_s_to_ns_map", ":", "\n", "        ", "ns_end_position", "=", "tok_s_to_ns_map", "[", "end_position", "]", "\n", "if", "ns_end_position", "in", "orig_ns_to_s_map", ":", "\n", "            ", "orig_end_position", "=", "orig_ns_to_s_map", "[", "ns_end_position", "]", "\n", "\n", "", "", "if", "orig_end_position", "is", "None", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Couldn't map end position\"", ")", "\n", "", "return", "orig_text", "\n", "\n", "", "output_text", "=", "orig_text", "[", "orig_start_position", ":", "(", "orig_end_position", "+", "1", ")", "]", "\n", "return", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics._get_best_indexes": [[336, 346], ["sorted", "range", "enumerate", "len", "best_indexes.append"], "function", ["None"], ["", "def", "_get_best_indexes", "(", "logits", ",", "n_best_size", ")", ":", "\n", "    ", "\"\"\"Get the n-best logits from a list.\"\"\"", "\n", "index_and_score", "=", "sorted", "(", "enumerate", "(", "logits", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "best_indexes", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "index_and_score", ")", ")", ":", "\n", "        ", "if", "i", ">=", "n_best_size", ":", "\n", "            ", "break", "\n", "", "best_indexes", ".", "append", "(", "index_and_score", "[", "i", "]", "[", "0", "]", ")", "\n", "", "return", "best_indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics._compute_softmax": [[348, 369], ["math.exp", "exp_scores.append", "probs.append"], "function", ["None"], ["", "def", "_compute_softmax", "(", "scores", ")", ":", "\n", "    ", "\"\"\"Compute softmax probability over raw logits.\"\"\"", "\n", "if", "not", "scores", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "max_score", "=", "None", "\n", "for", "score", "in", "scores", ":", "\n", "        ", "if", "max_score", "is", "None", "or", "score", ">", "max_score", ":", "\n", "            ", "max_score", "=", "score", "\n", "\n", "", "", "exp_scores", "=", "[", "]", "\n", "total_sum", "=", "0.0", "\n", "for", "score", "in", "scores", ":", "\n", "        ", "x", "=", "math", ".", "exp", "(", "score", "-", "max_score", ")", "\n", "exp_scores", ".", "append", "(", "x", ")", "\n", "total_sum", "+=", "x", "\n", "\n", "", "probs", "=", "[", "]", "\n", "for", "score", "in", "exp_scores", ":", "\n", "        ", "probs", ".", "append", "(", "score", "/", "total_sum", ")", "\n", "", "return", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.compute_predictions_logits": [[371, 568], ["logger.info", "logger.info", "collections.defaultdict", "collections.namedtuple", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "enumerate", "example_index_to_features[].append", "enumerate", "sorted", "collections.namedtuple", "squad_metrics._compute_softmax", "enumerate", "open", "writer.write", "open", "writer.write", "squad_metrics._get_best_indexes", "squad_metrics._get_best_indexes", "sorted.append", "nbest.append", "nbest.append", "len", "total_scores.append", "collections.OrderedDict", "nbest_json.append", "len", "open", "writer.write", "collections.namedtuple.", "len", "tokenizer.convert_tokens_to_string", "tok_text.strip.strip", "squad_metrics.get_final_text", "collections.namedtuple.", "nbest.append", "len", "nbest.insert", "collections.namedtuple.", "json.dumps", "json.dumps", "sorted.append", "tok_text.strip.split", "collections.namedtuple.", "collections.namedtuple.", "json.dumps", "len", "len", "feature.token_is_max_context.get", "collections.namedtuple."], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx._compute_softmax", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx._get_best_indexes", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx._get_best_indexes", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.convert_tokens_to_string", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.get_final_text"], ["", "def", "compute_predictions_logits", "(", "\n", "all_examples", ",", "\n", "all_features", ",", "\n", "all_results", ",", "\n", "n_best_size", ",", "\n", "max_answer_length", ",", "\n", "do_lower_case", ",", "\n", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "\n", "output_null_log_odds_file", ",", "\n", "verbose_logging", ",", "\n", "version_2_with_negative", ",", "\n", "null_score_diff_threshold", ",", "\n", "tokenizer", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Write final predictions to the json file and log-odds of null if needed.\"\"\"", "\n", "logger", ".", "info", "(", "\"Writing predictions to: %s\"", "%", "(", "output_prediction_file", ")", ")", "\n", "logger", ".", "info", "(", "\"Writing nbest to: %s\"", "%", "(", "output_nbest_file", ")", ")", "\n", "\n", "example_index_to_features", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "feature", "in", "all_features", ":", "\n", "        ", "example_index_to_features", "[", "feature", ".", "example_index", "]", ".", "append", "(", "feature", ")", "\n", "\n", "", "unique_id_to_result", "=", "{", "}", "\n", "for", "result", "in", "all_results", ":", "\n", "        ", "unique_id_to_result", "[", "result", ".", "unique_id", "]", "=", "result", "\n", "\n", "", "_PrelimPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"PrelimPrediction\"", ",", "[", "\"feature_index\"", ",", "\"start_index\"", ",", "\"end_index\"", ",", "\"start_logit\"", ",", "\"end_logit\"", "]", "\n", ")", "\n", "\n", "all_predictions", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "all_nbest_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "scores_diff_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "\n", "for", "(", "example_index", ",", "example", ")", "in", "enumerate", "(", "all_examples", ")", ":", "\n", "        ", "features", "=", "example_index_to_features", "[", "example_index", "]", "\n", "\n", "prelim_predictions", "=", "[", "]", "\n", "# keep track of the minimum score of null start+end of position 0", "\n", "score_null", "=", "1000000", "# large and positive", "\n", "min_null_feature_index", "=", "0", "# the paragraph slice with min null score", "\n", "null_start_logit", "=", "0", "# the start logit at the slice with min null score", "\n", "null_end_logit", "=", "0", "# the end logit at the slice with min null score", "\n", "for", "(", "feature_index", ",", "feature", ")", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "result", "=", "unique_id_to_result", "[", "feature", ".", "unique_id", "]", "\n", "start_indexes", "=", "_get_best_indexes", "(", "result", ".", "start_logits", ",", "n_best_size", ")", "\n", "end_indexes", "=", "_get_best_indexes", "(", "result", ".", "end_logits", ",", "n_best_size", ")", "\n", "# if we could have irrelevant answers, get the min score of irrelevant", "\n", "if", "version_2_with_negative", ":", "\n", "                ", "feature_null_score", "=", "result", ".", "start_logits", "[", "0", "]", "+", "result", ".", "end_logits", "[", "0", "]", "\n", "if", "feature_null_score", "<", "score_null", ":", "\n", "                    ", "score_null", "=", "feature_null_score", "\n", "min_null_feature_index", "=", "feature_index", "\n", "null_start_logit", "=", "result", ".", "start_logits", "[", "0", "]", "\n", "null_end_logit", "=", "result", ".", "end_logits", "[", "0", "]", "\n", "", "", "for", "start_index", "in", "start_indexes", ":", "\n", "                ", "for", "end_index", "in", "end_indexes", ":", "\n", "# We could hypothetically create invalid predictions, e.g., predict", "\n", "# that the start of the span is in the question. We throw out all", "\n", "# invalid predictions.", "\n", "                    ", "if", "start_index", ">=", "len", "(", "feature", ".", "tokens", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", ">=", "len", "(", "feature", ".", "tokens", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "start_index", "not", "in", "feature", ".", "token_to_orig_map", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", "not", "in", "feature", ".", "token_to_orig_map", ":", "\n", "                        ", "continue", "\n", "", "if", "not", "feature", ".", "token_is_max_context", ".", "get", "(", "start_index", ",", "False", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", "<", "start_index", ":", "\n", "                        ", "continue", "\n", "", "length", "=", "end_index", "-", "start_index", "+", "1", "\n", "if", "length", ">", "max_answer_length", ":", "\n", "                        ", "continue", "\n", "", "prelim_predictions", ".", "append", "(", "\n", "_PrelimPrediction", "(", "\n", "feature_index", "=", "feature_index", ",", "\n", "start_index", "=", "start_index", ",", "\n", "end_index", "=", "end_index", ",", "\n", "start_logit", "=", "result", ".", "start_logits", "[", "start_index", "]", ",", "\n", "end_logit", "=", "result", ".", "end_logits", "[", "end_index", "]", ",", "\n", ")", "\n", ")", "\n", "", "", "", "if", "version_2_with_negative", ":", "\n", "            ", "prelim_predictions", ".", "append", "(", "\n", "_PrelimPrediction", "(", "\n", "feature_index", "=", "min_null_feature_index", ",", "\n", "start_index", "=", "0", ",", "\n", "end_index", "=", "0", ",", "\n", "start_logit", "=", "null_start_logit", ",", "\n", "end_logit", "=", "null_end_logit", ",", "\n", ")", "\n", ")", "\n", "", "prelim_predictions", "=", "sorted", "(", "prelim_predictions", ",", "key", "=", "lambda", "x", ":", "(", "x", ".", "start_logit", "+", "x", ".", "end_logit", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "_NbestPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"NbestPrediction\"", ",", "[", "\"text\"", ",", "\"start_logit\"", ",", "\"end_logit\"", "]", "\n", ")", "\n", "\n", "seen_predictions", "=", "{", "}", "\n", "nbest", "=", "[", "]", "\n", "for", "pred", "in", "prelim_predictions", ":", "\n", "            ", "if", "len", "(", "nbest", ")", ">=", "n_best_size", ":", "\n", "                ", "break", "\n", "", "feature", "=", "features", "[", "pred", ".", "feature_index", "]", "\n", "if", "pred", ".", "start_index", ">", "0", ":", "# this is a non-null prediction", "\n", "                ", "tok_tokens", "=", "feature", ".", "tokens", "[", "pred", ".", "start_index", ":", "(", "pred", ".", "end_index", "+", "1", ")", "]", "\n", "orig_doc_start", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "start_index", "]", "\n", "orig_doc_end", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "end_index", "]", "\n", "orig_tokens", "=", "example", ".", "doc_tokens", "[", "orig_doc_start", ":", "(", "orig_doc_end", "+", "1", ")", "]", "\n", "\n", "tok_text", "=", "tokenizer", ".", "convert_tokens_to_string", "(", "tok_tokens", ")", "\n", "\n", "# tok_text = \" \".join(tok_tokens)", "\n", "#", "\n", "# # De-tokenize WordPieces that have been split off.", "\n", "# tok_text = tok_text.replace(\" ##\", \"\")", "\n", "# tok_text = tok_text.replace(\"##\", \"\")", "\n", "\n", "# Clean whitespace", "\n", "tok_text", "=", "tok_text", ".", "strip", "(", ")", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tok_text", ".", "split", "(", ")", ")", "\n", "orig_text", "=", "\" \"", ".", "join", "(", "orig_tokens", ")", "\n", "\n", "final_text", "=", "get_final_text", "(", "tok_text", ",", "orig_text", ",", "do_lower_case", ",", "verbose_logging", ")", "\n", "if", "final_text", "in", "seen_predictions", ":", "\n", "                    ", "continue", "\n", "\n", "", "seen_predictions", "[", "final_text", "]", "=", "True", "\n", "", "else", ":", "\n", "                ", "final_text", "=", "\"\"", "\n", "seen_predictions", "[", "final_text", "]", "=", "True", "\n", "\n", "", "nbest", ".", "append", "(", "_NbestPrediction", "(", "text", "=", "final_text", ",", "start_logit", "=", "pred", ".", "start_logit", ",", "end_logit", "=", "pred", ".", "end_logit", ")", ")", "\n", "# if we didn't include the empty option in the n-best, include it", "\n", "", "if", "version_2_with_negative", ":", "\n", "            ", "if", "\"\"", "not", "in", "seen_predictions", ":", "\n", "                ", "nbest", ".", "append", "(", "_NbestPrediction", "(", "text", "=", "\"\"", ",", "start_logit", "=", "null_start_logit", ",", "end_logit", "=", "null_end_logit", ")", ")", "\n", "\n", "# In very rare edge cases we could only have single null prediction.", "\n", "# So we just create a nonce prediction in this case to avoid failure.", "\n", "", "if", "len", "(", "nbest", ")", "==", "1", ":", "\n", "                ", "nbest", ".", "insert", "(", "0", ",", "_NbestPrediction", "(", "text", "=", "\"empty\"", ",", "start_logit", "=", "0.0", ",", "end_logit", "=", "0.0", ")", ")", "\n", "\n", "# In very rare edge cases we could have no valid predictions. So we", "\n", "# just create a nonce prediction in this case to avoid failure.", "\n", "", "", "if", "not", "nbest", ":", "\n", "            ", "nbest", ".", "append", "(", "_NbestPrediction", "(", "text", "=", "\"empty\"", ",", "start_logit", "=", "0.0", ",", "end_logit", "=", "0.0", ")", ")", "\n", "\n", "", "assert", "len", "(", "nbest", ")", ">=", "1", "\n", "\n", "total_scores", "=", "[", "]", "\n", "best_non_null_entry", "=", "None", "\n", "for", "entry", "in", "nbest", ":", "\n", "            ", "total_scores", ".", "append", "(", "entry", ".", "start_logit", "+", "entry", ".", "end_logit", ")", "\n", "if", "not", "best_non_null_entry", ":", "\n", "                ", "if", "entry", ".", "text", ":", "\n", "                    ", "best_non_null_entry", "=", "entry", "\n", "\n", "", "", "", "probs", "=", "_compute_softmax", "(", "total_scores", ")", "\n", "\n", "nbest_json", "=", "[", "]", "\n", "for", "(", "i", ",", "entry", ")", "in", "enumerate", "(", "nbest", ")", ":", "\n", "            ", "output", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "output", "[", "\"text\"", "]", "=", "entry", ".", "text", "\n", "output", "[", "\"probability\"", "]", "=", "probs", "[", "i", "]", "\n", "output", "[", "\"start_logit\"", "]", "=", "entry", ".", "start_logit", "\n", "output", "[", "\"end_logit\"", "]", "=", "entry", ".", "end_logit", "\n", "nbest_json", ".", "append", "(", "output", ")", "\n", "\n", "", "assert", "len", "(", "nbest_json", ")", ">=", "1", "\n", "\n", "if", "not", "version_2_with_negative", ":", "\n", "            ", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "nbest_json", "[", "0", "]", "[", "\"text\"", "]", "\n", "", "else", ":", "\n", "# predict \"\" iff the null score - the score of best non-null > threshold", "\n", "            ", "score_diff", "=", "score_null", "-", "best_non_null_entry", ".", "start_logit", "-", "(", "best_non_null_entry", ".", "end_logit", ")", "\n", "scores_diff_json", "[", "example", ".", "qas_id", "]", "=", "score_diff", "\n", "if", "score_diff", ">", "null_score_diff_threshold", ":", "\n", "                ", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "\"\"", "\n", "", "else", ":", "\n", "                ", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "best_non_null_entry", ".", "text", "\n", "", "", "all_nbest_json", "[", "example", ".", "qas_id", "]", "=", "nbest_json", "\n", "\n", "", "with", "open", "(", "output_prediction_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_predictions", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "with", "open", "(", "output_nbest_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_nbest_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "if", "version_2_with_negative", ":", "\n", "        ", "with", "open", "(", "output_null_log_odds_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "scores_diff_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "return", "all_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.compute_predictions_log_probs": [[570, 758], ["collections.namedtuple", "collections.namedtuple", "logger.info", "collections.defaultdict", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "enumerate", "example_index_to_features[].append", "enumerate", "sorted", "squad_metrics._compute_softmax", "enumerate", "open", "writer.write", "open", "writer.write", "min", "range", "tokenizer.convert_tokens_to_string", "tok_text.strip.strip", "hasattr", "squad_metrics.get_final_text", "nbest.append", "nbest.append", "total_scores.append", "collections.OrderedDict", "nbest_json.append", "len", "open", "writer.write", "range", "len", "tok_text.strip.split", "collections.namedtuple.", "collections.namedtuple.", "json.dumps", "json.dumps", "sorted.append", "json.dumps", "feature.token_is_max_context.get", "collections.namedtuple."], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx._compute_softmax", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.convert_tokens_to_string", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.get_final_text"], ["", "def", "compute_predictions_log_probs", "(", "\n", "all_examples", ",", "\n", "all_features", ",", "\n", "all_results", ",", "\n", "n_best_size", ",", "\n", "max_answer_length", ",", "\n", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "\n", "output_null_log_odds_file", ",", "\n", "start_n_top", ",", "\n", "end_n_top", ",", "\n", "version_2_with_negative", ",", "\n", "tokenizer", ",", "\n", "verbose_logging", ",", "\n", ")", ":", "\n", "    ", "\"\"\" XLNet write prediction logic (more complex than Bert's).\n        Write final predictions to the json file and log-odds of null if needed.\n\n        Requires utils_squad_evaluate.py\n    \"\"\"", "\n", "_PrelimPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"PrelimPrediction\"", ",", "[", "\"feature_index\"", ",", "\"start_index\"", ",", "\"end_index\"", ",", "\"start_log_prob\"", ",", "\"end_log_prob\"", "]", "\n", ")", "\n", "\n", "_NbestPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"NbestPrediction\"", ",", "[", "\"text\"", ",", "\"start_log_prob\"", ",", "\"end_log_prob\"", "]", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\"Writing predictions to: %s\"", ",", "output_prediction_file", ")", "\n", "# logger.info(\"Writing nbest to: %s\" % (output_nbest_file))", "\n", "\n", "example_index_to_features", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "feature", "in", "all_features", ":", "\n", "        ", "example_index_to_features", "[", "feature", ".", "example_index", "]", ".", "append", "(", "feature", ")", "\n", "\n", "", "unique_id_to_result", "=", "{", "}", "\n", "for", "result", "in", "all_results", ":", "\n", "        ", "unique_id_to_result", "[", "result", ".", "unique_id", "]", "=", "result", "\n", "\n", "", "all_predictions", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "all_nbest_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "scores_diff_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "\n", "for", "(", "example_index", ",", "example", ")", "in", "enumerate", "(", "all_examples", ")", ":", "\n", "        ", "features", "=", "example_index_to_features", "[", "example_index", "]", "\n", "\n", "prelim_predictions", "=", "[", "]", "\n", "# keep track of the minimum score of null start+end of position 0", "\n", "score_null", "=", "1000000", "# large and positive", "\n", "\n", "for", "(", "feature_index", ",", "feature", ")", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "result", "=", "unique_id_to_result", "[", "feature", ".", "unique_id", "]", "\n", "\n", "cur_null_score", "=", "result", ".", "cls_logits", "\n", "\n", "# if we could have irrelevant answers, get the min score of irrelevant", "\n", "score_null", "=", "min", "(", "score_null", ",", "cur_null_score", ")", "\n", "\n", "for", "i", "in", "range", "(", "start_n_top", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "end_n_top", ")", ":", "\n", "                    ", "start_log_prob", "=", "result", ".", "start_logits", "[", "i", "]", "\n", "start_index", "=", "result", ".", "start_top_index", "[", "i", "]", "\n", "\n", "j_index", "=", "i", "*", "end_n_top", "+", "j", "\n", "\n", "end_log_prob", "=", "result", ".", "end_logits", "[", "j_index", "]", "\n", "end_index", "=", "result", ".", "end_top_index", "[", "j_index", "]", "\n", "\n", "# We could hypothetically create invalid predictions, e.g., predict", "\n", "# that the start of the span is in the question. We throw out all", "\n", "# invalid predictions.", "\n", "if", "start_index", ">=", "feature", ".", "paragraph_len", "-", "1", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", ">=", "feature", ".", "paragraph_len", "-", "1", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "feature", ".", "token_is_max_context", ".", "get", "(", "start_index", ",", "False", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", "<", "start_index", ":", "\n", "                        ", "continue", "\n", "", "length", "=", "end_index", "-", "start_index", "+", "1", "\n", "if", "length", ">", "max_answer_length", ":", "\n", "                        ", "continue", "\n", "\n", "", "prelim_predictions", ".", "append", "(", "\n", "_PrelimPrediction", "(", "\n", "feature_index", "=", "feature_index", ",", "\n", "start_index", "=", "start_index", ",", "\n", "end_index", "=", "end_index", ",", "\n", "start_log_prob", "=", "start_log_prob", ",", "\n", "end_log_prob", "=", "end_log_prob", ",", "\n", ")", "\n", ")", "\n", "\n", "", "", "", "prelim_predictions", "=", "sorted", "(", "\n", "prelim_predictions", ",", "key", "=", "lambda", "x", ":", "(", "x", ".", "start_log_prob", "+", "x", ".", "end_log_prob", ")", ",", "reverse", "=", "True", "\n", ")", "\n", "\n", "seen_predictions", "=", "{", "}", "\n", "nbest", "=", "[", "]", "\n", "for", "pred", "in", "prelim_predictions", ":", "\n", "            ", "if", "len", "(", "nbest", ")", ">=", "n_best_size", ":", "\n", "                ", "break", "\n", "", "feature", "=", "features", "[", "pred", ".", "feature_index", "]", "\n", "\n", "# XLNet un-tokenizer", "\n", "# Let's keep it simple for now and see if we need all this later.", "\n", "#", "\n", "# tok_start_to_orig_index = feature.tok_start_to_orig_index", "\n", "# tok_end_to_orig_index = feature.tok_end_to_orig_index", "\n", "# start_orig_pos = tok_start_to_orig_index[pred.start_index]", "\n", "# end_orig_pos = tok_end_to_orig_index[pred.end_index]", "\n", "# paragraph_text = example.paragraph_text", "\n", "# final_text = paragraph_text[start_orig_pos: end_orig_pos + 1].strip()", "\n", "\n", "# Previously used Bert untokenizer", "\n", "tok_tokens", "=", "feature", ".", "tokens", "[", "pred", ".", "start_index", ":", "(", "pred", ".", "end_index", "+", "1", ")", "]", "\n", "orig_doc_start", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "start_index", "]", "\n", "orig_doc_end", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "end_index", "]", "\n", "orig_tokens", "=", "example", ".", "doc_tokens", "[", "orig_doc_start", ":", "(", "orig_doc_end", "+", "1", ")", "]", "\n", "tok_text", "=", "tokenizer", ".", "convert_tokens_to_string", "(", "tok_tokens", ")", "\n", "\n", "# Clean whitespace", "\n", "tok_text", "=", "tok_text", ".", "strip", "(", ")", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tok_text", ".", "split", "(", ")", ")", "\n", "orig_text", "=", "\" \"", ".", "join", "(", "orig_tokens", ")", "\n", "\n", "if", "hasattr", "(", "tokenizer", ",", "\"do_lower_case\"", ")", ":", "\n", "                ", "do_lower_case", "=", "tokenizer", ".", "do_lower_case", "\n", "", "else", ":", "\n", "                ", "do_lower_case", "=", "tokenizer", ".", "do_lowercase_and_remove_accent", "\n", "\n", "", "final_text", "=", "get_final_text", "(", "tok_text", ",", "orig_text", ",", "do_lower_case", ",", "verbose_logging", ")", "\n", "\n", "if", "final_text", "in", "seen_predictions", ":", "\n", "                ", "continue", "\n", "\n", "", "seen_predictions", "[", "final_text", "]", "=", "True", "\n", "\n", "nbest", ".", "append", "(", "\n", "_NbestPrediction", "(", "text", "=", "final_text", ",", "start_log_prob", "=", "pred", ".", "start_log_prob", ",", "end_log_prob", "=", "pred", ".", "end_log_prob", ")", "\n", ")", "\n", "\n", "# In very rare edge cases we could have no valid predictions. So we", "\n", "# just create a nonce prediction in this case to avoid failure.", "\n", "", "if", "not", "nbest", ":", "\n", "            ", "nbest", ".", "append", "(", "_NbestPrediction", "(", "text", "=", "\"\"", ",", "start_log_prob", "=", "-", "1e6", ",", "end_log_prob", "=", "-", "1e6", ")", ")", "\n", "\n", "", "total_scores", "=", "[", "]", "\n", "best_non_null_entry", "=", "None", "\n", "for", "entry", "in", "nbest", ":", "\n", "            ", "total_scores", ".", "append", "(", "entry", ".", "start_log_prob", "+", "entry", ".", "end_log_prob", ")", "\n", "if", "not", "best_non_null_entry", ":", "\n", "                ", "best_non_null_entry", "=", "entry", "\n", "\n", "", "", "probs", "=", "_compute_softmax", "(", "total_scores", ")", "\n", "\n", "nbest_json", "=", "[", "]", "\n", "for", "(", "i", ",", "entry", ")", "in", "enumerate", "(", "nbest", ")", ":", "\n", "            ", "output", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "output", "[", "\"text\"", "]", "=", "entry", ".", "text", "\n", "output", "[", "\"probability\"", "]", "=", "probs", "[", "i", "]", "\n", "output", "[", "\"start_log_prob\"", "]", "=", "entry", ".", "start_log_prob", "\n", "output", "[", "\"end_log_prob\"", "]", "=", "entry", ".", "end_log_prob", "\n", "nbest_json", ".", "append", "(", "output", ")", "\n", "\n", "", "assert", "len", "(", "nbest_json", ")", ">=", "1", "\n", "assert", "best_non_null_entry", "is", "not", "None", "\n", "\n", "score_diff", "=", "score_null", "\n", "scores_diff_json", "[", "example", ".", "qas_id", "]", "=", "score_diff", "\n", "# note(zhiliny): always predict best_non_null_entry", "\n", "# and the evaluation script will search for the best threshold", "\n", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "best_non_null_entry", ".", "text", "\n", "\n", "all_nbest_json", "[", "example", ".", "qas_id", "]", "=", "nbest_json", "\n", "\n", "", "with", "open", "(", "output_prediction_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_predictions", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "with", "open", "(", "output_nbest_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_nbest_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "if", "version_2_with_negative", ":", "\n", "        ", "with", "open", "(", "output_null_log_odds_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "scores_diff_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "return", "all_predictions", "\n", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.train.TrainCommand.register_subcommand": [[27, 77], ["parser.add_parser", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.set_defaults"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "register_subcommand", "(", "parser", ":", "ArgumentParser", ")", ":", "\n", "        ", "\"\"\"\n        Register this command to argparse so it's available for the transformer-cli\n        :param parser: Root parser to register command-specific arguments\n        :return:\n        \"\"\"", "\n", "train_parser", "=", "parser", ".", "add_parser", "(", "\"train\"", ",", "help", "=", "\"CLI tool to train a model on a task.\"", ")", "\n", "\n", "train_parser", ".", "add_argument", "(", "\n", "\"--train_data\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"path to train (and optionally evaluation) dataset as a csv with \"", "\n", "\"tab separated labels and sentences.\"", ",", "\n", ")", "\n", "train_parser", ".", "add_argument", "(", "\n", "\"--column_label\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"Column of the dataset csv file with example labels.\"", "\n", ")", "\n", "train_parser", ".", "add_argument", "(", "\n", "\"--column_text\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"Column of the dataset csv file with example texts.\"", "\n", ")", "\n", "train_parser", ".", "add_argument", "(", "\n", "\"--column_id\"", ",", "type", "=", "int", ",", "default", "=", "2", ",", "help", "=", "\"Column of the dataset csv file with example ids.\"", "\n", ")", "\n", "train_parser", ".", "add_argument", "(", "\n", "\"--skip_first_row\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Skip the first row of the csv file (headers).\"", "\n", ")", "\n", "\n", "train_parser", ".", "add_argument", "(", "\"--validation_data\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"path to validation dataset.\"", ")", "\n", "train_parser", ".", "add_argument", "(", "\n", "\"--validation_split\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.1", ",", "\n", "help", "=", "\"if validation dataset is not provided, fraction of train dataset \"", "\"to use as validation dataset.\"", ",", "\n", ")", "\n", "\n", "train_parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "default", "=", "\"./\"", ",", "help", "=", "\"path to saved the trained model.\"", ")", "\n", "\n", "train_parser", ".", "add_argument", "(", "\n", "\"--task\"", ",", "type", "=", "str", ",", "default", "=", "\"text_classification\"", ",", "help", "=", "\"Task to train the model on.\"", "\n", ")", "\n", "train_parser", ".", "add_argument", "(", "\n", "\"--model\"", ",", "type", "=", "str", ",", "default", "=", "\"bert-base-uncased\"", ",", "help", "=", "\"Model's name or path to stored model.\"", "\n", ")", "\n", "train_parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "type", "=", "int", ",", "default", "=", "32", ",", "help", "=", "\"Batch size for training.\"", ")", "\n", "train_parser", ".", "add_argument", "(", "\"--valid_batch_size\"", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "\"Batch size for validation.\"", ")", "\n", "train_parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "type", "=", "float", ",", "default", "=", "3e-5", ",", "help", "=", "\"Learning rate.\"", ")", "\n", "train_parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "type", "=", "float", ",", "default", "=", "1e-08", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "train_parser", ".", "set_defaults", "(", "func", "=", "train_command_factory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.train.TrainCommand.__init__": [[78, 123], ["logging.getLogger", "os.makedirs", "os.path.isdir", "train.TrainCommand.logger.info", "train.TrainCommand.logger.info", "transformers.SingleSentenceClassificationProcessor.create_from_csv", "transformers.is_tf_available", "transformers.TextClassificationPipeline.from_pretrained", "train.TrainCommand.logger.info", "transformers.SingleSentenceClassificationProcessor.create_from_csv"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.SingleSentenceClassificationProcessor.create_from_csv", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_tf_available", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.SingleSentenceClassificationProcessor.create_from_csv"], ["", "def", "__init__", "(", "self", ",", "args", ":", "Namespace", ")", ":", "\n", "        ", "self", ".", "logger", "=", "getLogger", "(", "\"transformers-cli/training\"", ")", "\n", "\n", "self", ".", "framework", "=", "\"tf\"", "if", "is_tf_available", "(", ")", "else", "\"torch\"", "\n", "\n", "os", ".", "makedirs", "(", "args", ".", "output", ",", "exist_ok", "=", "True", ")", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "args", ".", "output", ")", "\n", "self", ".", "output", "=", "args", ".", "output", "\n", "\n", "self", ".", "column_label", "=", "args", ".", "column_label", "\n", "self", ".", "column_text", "=", "args", ".", "column_text", "\n", "self", ".", "column_id", "=", "args", ".", "column_id", "\n", "\n", "self", ".", "logger", ".", "info", "(", "\"Loading {} pipeline for {}\"", ".", "format", "(", "args", ".", "task", ",", "args", ".", "model", ")", ")", "\n", "if", "args", ".", "task", "==", "\"text_classification\"", ":", "\n", "            ", "self", ".", "pipeline", "=", "TextClassificationPipeline", ".", "from_pretrained", "(", "args", ".", "model", ")", "\n", "", "elif", "args", ".", "task", "==", "\"token_classification\"", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "elif", "args", ".", "task", "==", "\"question_answering\"", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "logger", ".", "info", "(", "\"Loading dataset from {}\"", ".", "format", "(", "args", ".", "train_data", ")", ")", "\n", "self", ".", "train_dataset", "=", "Processor", ".", "create_from_csv", "(", "\n", "args", ".", "train_data", ",", "\n", "column_label", "=", "args", ".", "column_label", ",", "\n", "column_text", "=", "args", ".", "column_text", ",", "\n", "column_id", "=", "args", ".", "column_id", ",", "\n", "skip_first_row", "=", "args", ".", "skip_first_row", ",", "\n", ")", "\n", "self", ".", "valid_dataset", "=", "None", "\n", "if", "args", ".", "validation_data", ":", "\n", "            ", "self", ".", "logger", ".", "info", "(", "\"Loading validation dataset from {}\"", ".", "format", "(", "args", ".", "validation_data", ")", ")", "\n", "self", ".", "valid_dataset", "=", "Processor", ".", "create_from_csv", "(", "\n", "args", ".", "validation_data", ",", "\n", "column_label", "=", "args", ".", "column_label", ",", "\n", "column_text", "=", "args", ".", "column_text", ",", "\n", "column_id", "=", "args", ".", "column_id", ",", "\n", "skip_first_row", "=", "args", ".", "skip_first_row", ",", "\n", ")", "\n", "\n", "", "self", ".", "validation_split", "=", "args", ".", "validation_split", "\n", "self", ".", "train_batch_size", "=", "args", ".", "train_batch_size", "\n", "self", ".", "valid_batch_size", "=", "args", ".", "valid_batch_size", "\n", "self", ".", "learning_rate", "=", "args", ".", "learning_rate", "\n", "self", ".", "adam_epsilon", "=", "args", ".", "adam_epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.train.TrainCommand.run": [[124, 128], ["train.TrainCommand.run_torch", "train.TrainCommand.run_tf"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.train.TrainCommand.run_torch", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.train.TrainCommand.run_tf"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "framework", "==", "\"tf\"", ":", "\n", "            ", "return", "self", ".", "run_tf", "(", ")", "\n", "", "return", "self", ".", "run_torch", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.train.TrainCommand.run_torch": [[129, 131], ["None"], "methods", ["None"], ["", "def", "run_torch", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.train.TrainCommand.run_tf": [[132, 145], ["train.TrainCommand.pipeline.fit", "train.TrainCommand.pipeline.save_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained"], ["", "def", "run_tf", "(", "self", ")", ":", "\n", "        ", "self", ".", "pipeline", ".", "fit", "(", "\n", "self", ".", "train_dataset", ",", "\n", "validation_data", "=", "self", ".", "valid_dataset", ",", "\n", "validation_split", "=", "self", ".", "validation_split", ",", "\n", "learning_rate", "=", "self", ".", "learning_rate", ",", "\n", "adam_epsilon", "=", "self", ".", "adam_epsilon", ",", "\n", "train_batch_size", "=", "self", ".", "train_batch_size", ",", "\n", "valid_batch_size", "=", "self", ".", "valid_batch_size", ",", "\n", ")", "\n", "\n", "# Save trained pipeline", "\n", "self", ".", "pipeline", ".", "save_pretrained", "(", "self", ".", "output", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.train.train_command_factory": [[18, 24], ["train.TrainCommand"], "function", ["None"], ["def", "train_command_factory", "(", "args", ":", "Namespace", ")", ":", "\n", "    ", "\"\"\"\n    Factory function used to instantiate serving server from provided command line arguments.\n    :return: ServeCommand\n    \"\"\"", "\n", "return", "TrainCommand", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.UserCommands.register_subcommand": [[13, 30], ["parser.add_parser", "parser.add_parser.set_defaults", "parser.add_parser", "parser.add_parser.set_defaults", "parser.add_parser", "parser.add_parser.set_defaults", "parser.add_parser", "parser.add_parser.set_defaults", "parser.add_parser", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.set_defaults", "user.LoginCommand", "user.WhoamiCommand", "user.LogoutCommand", "user.ListObjsCommand", "user.UploadCommand"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "register_subcommand", "(", "parser", ":", "ArgumentParser", ")", ":", "\n", "        ", "login_parser", "=", "parser", ".", "add_parser", "(", "\"login\"", ")", "\n", "login_parser", ".", "set_defaults", "(", "func", "=", "lambda", "args", ":", "LoginCommand", "(", "args", ")", ")", "\n", "whoami_parser", "=", "parser", ".", "add_parser", "(", "\"whoami\"", ")", "\n", "whoami_parser", ".", "set_defaults", "(", "func", "=", "lambda", "args", ":", "WhoamiCommand", "(", "args", ")", ")", "\n", "logout_parser", "=", "parser", ".", "add_parser", "(", "\"logout\"", ")", "\n", "logout_parser", ".", "set_defaults", "(", "func", "=", "lambda", "args", ":", "LogoutCommand", "(", "args", ")", ")", "\n", "list_parser", "=", "parser", ".", "add_parser", "(", "\"ls\"", ")", "\n", "list_parser", ".", "set_defaults", "(", "func", "=", "lambda", "args", ":", "ListObjsCommand", "(", "args", ")", ")", "\n", "# upload", "\n", "upload_parser", "=", "parser", ".", "add_parser", "(", "\"upload\"", ")", "\n", "upload_parser", ".", "add_argument", "(", "\"path\"", ",", "type", "=", "str", ",", "help", "=", "\"Local path of the folder or individual file to upload.\"", ")", "\n", "upload_parser", ".", "add_argument", "(", "\n", "\"--filename\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Optional: override individual object filename on S3.\"", "\n", ")", "\n", "upload_parser", ".", "set_defaults", "(", "func", "=", "lambda", "args", ":", "UploadCommand", "(", "args", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.ANSI.bold": [[40, 43], ["None"], "methods", ["None"], ["@", "classmethod", "\n", "def", "bold", "(", "cls", ",", "s", ")", ":", "\n", "        ", "return", "\"{}{}{}\"", ".", "format", "(", "cls", ".", "_bold", ",", "s", ",", "cls", ".", "_reset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.BaseUserCommand.__init__": [[46, 49], ["transformers.hf_api.HfApi"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "_api", "=", "HfApi", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.LoginCommand.run": [[52, 75], ["print", "input", "getpass.getpass.getpass", "transformers.hf_api.HfFolder.save_token", "print", "print", "print", "user.LoginCommand._api.login", "print", "exit"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfFolder.save_token", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.login"], ["    ", "def", "run", "(", "self", ")", ":", "\n", "        ", "print", "(", "\n", "\"\"\"\n        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n\n        \"\"\"", "\n", ")", "\n", "username", "=", "input", "(", "\"Username: \"", ")", "\n", "password", "=", "getpass", "(", ")", "\n", "try", ":", "\n", "            ", "token", "=", "self", ".", "_api", ".", "login", "(", "username", ",", "password", ")", "\n", "", "except", "HTTPError", "as", "e", ":", "\n", "# probably invalid credentials, display error message.", "\n", "            ", "print", "(", "e", ")", "\n", "exit", "(", "1", ")", "\n", "", "HfFolder", ".", "save_token", "(", "token", ")", "\n", "print", "(", "\"Login successful\"", ")", "\n", "print", "(", "\"Your token:\"", ",", "token", ",", "\"\\n\"", ")", "\n", "print", "(", "\"Your token has been saved to\"", ",", "HfFolder", ".", "path_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.WhoamiCommand.run": [[78, 88], ["transformers.hf_api.HfFolder.get_token", "print", "exit", "user.WhoamiCommand.WhoamiCommand._api.whoami", "print", "print"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfFolder.get_token", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.whoami"], ["    ", "def", "run", "(", "self", ")", ":", "\n", "        ", "token", "=", "HfFolder", ".", "get_token", "(", ")", "\n", "if", "token", "is", "None", ":", "\n", "            ", "print", "(", "\"Not logged in\"", ")", "\n", "exit", "(", ")", "\n", "", "try", ":", "\n", "            ", "user", "=", "self", ".", "_api", ".", "whoami", "(", "token", ")", "\n", "print", "(", "user", ")", "\n", "", "except", "HTTPError", "as", "e", ":", "\n", "            ", "print", "(", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.LogoutCommand.run": [[91, 99], ["transformers.hf_api.HfFolder.get_token", "transformers.hf_api.HfFolder.delete_token", "user.LogoutCommand._api.logout", "print", "print", "exit"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfFolder.get_token", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfFolder.delete_token", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.logout"], ["    ", "def", "run", "(", "self", ")", ":", "\n", "        ", "token", "=", "HfFolder", ".", "get_token", "(", ")", "\n", "if", "token", "is", "None", ":", "\n", "            ", "print", "(", "\"Not logged in\"", ")", "\n", "exit", "(", ")", "\n", "", "HfFolder", ".", "delete_token", "(", ")", "\n", "self", ".", "_api", ".", "logout", "(", "token", ")", "\n", "print", "(", "\"Successfully logged out.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.ListObjsCommand.tabulate": [[102, 116], ["lines.append", "lines.append", "max", "row_format.format", "row_format.format", "lines.append", "zip", "row_format.format", "len", "len", "str"], "methods", ["None"], ["    ", "def", "tabulate", "(", "self", ",", "rows", ":", "List", "[", "List", "[", "Union", "[", "str", ",", "int", "]", "]", "]", ",", "headers", ":", "List", "[", "str", "]", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Inspired by:\n        stackoverflow.com/a/8356620/593036\n        stackoverflow.com/questions/9535954/printing-lists-as-tabular-data\n        \"\"\"", "\n", "col_widths", "=", "[", "max", "(", "len", "(", "str", "(", "x", ")", ")", "for", "x", "in", "col", ")", "for", "col", "in", "zip", "(", "*", "rows", ",", "headers", ")", "]", "\n", "row_format", "=", "(", "\"{{:{}}} \"", "*", "len", "(", "headers", ")", ")", ".", "format", "(", "*", "col_widths", ")", "\n", "lines", "=", "[", "]", "\n", "lines", ".", "append", "(", "row_format", ".", "format", "(", "*", "headers", ")", ")", "\n", "lines", ".", "append", "(", "row_format", ".", "format", "(", "*", "[", "\"-\"", "*", "w", "for", "w", "in", "col_widths", "]", ")", ")", "\n", "for", "row", "in", "rows", ":", "\n", "            ", "lines", ".", "append", "(", "row_format", ".", "format", "(", "*", "row", ")", ")", "\n", "", "return", "\"\\n\"", ".", "join", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.ListObjsCommand.run": [[117, 132], ["transformers.hf_api.HfFolder.get_token", "print", "print", "exit", "user.ListObjsCommand._api.list_objs", "len", "print", "exit", "user.ListObjsCommand.tabulate", "print", "exit"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfFolder.get_token", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.list_objs", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.ListObjsCommand.tabulate"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "token", "=", "HfFolder", ".", "get_token", "(", ")", "\n", "if", "token", "is", "None", ":", "\n", "            ", "print", "(", "\"Not logged in\"", ")", "\n", "exit", "(", "1", ")", "\n", "", "try", ":", "\n", "            ", "objs", "=", "self", ".", "_api", ".", "list_objs", "(", "token", ")", "\n", "", "except", "HTTPError", "as", "e", ":", "\n", "            ", "print", "(", "e", ")", "\n", "exit", "(", "1", ")", "\n", "", "if", "len", "(", "objs", ")", "==", "0", ":", "\n", "            ", "print", "(", "\"No shared file yet\"", ")", "\n", "exit", "(", ")", "\n", "", "rows", "=", "[", "[", "obj", ".", "filename", ",", "obj", ".", "LastModified", ",", "obj", ".", "ETag", ",", "obj", ".", "Size", "]", "for", "obj", "in", "objs", "]", "\n", "print", "(", "self", ".", "tabulate", "(", "rows", ",", "headers", "=", "[", "\"Filename\"", ",", "\"LastModified\"", ",", "\"ETag\"", ",", "\"Size\"", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.UploadCommand.walk_dir": [[135, 145], ["list", "os.scandir", "f.is_dir", "os.path.join", "f.is_file", "user.UploadCommand.walk_dir", "os.getcwd"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.UploadCommand.walk_dir"], ["    ", "def", "walk_dir", "(", "self", ",", "rel_path", ")", ":", "\n", "        ", "\"\"\"\n        Recursively list all files in a folder.\n        \"\"\"", "\n", "entries", ":", "List", "[", "os", ".", "DirEntry", "]", "=", "list", "(", "os", ".", "scandir", "(", "rel_path", ")", ")", "\n", "files", "=", "[", "(", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "f", ".", "path", ")", ",", "f", ".", "path", ")", "for", "f", "in", "entries", "if", "f", ".", "is_file", "(", ")", "]", "# filepath  # filename", "\n", "for", "f", "in", "entries", ":", "\n", "            ", "if", "f", ".", "is_dir", "(", ")", ":", "\n", "                ", "files", "+=", "self", ".", "walk_dir", "(", "f", ".", "path", ")", "\n", "", "", "return", "files", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.UploadCommand.run": [[146, 175], ["transformers.hf_api.HfFolder.get_token", "os.path.abspath", "os.path.isdir", "input().lower", "print", "print", "exit", "os.path.basename", "user.UploadCommand.walk_dir", "os.path.isfile", "print", "print", "exit", "user.ANSI.bold", "user.UploadCommand._api.presign_and_upload", "print", "print", "ValueError", "ValueError", "input", "os.path.basename", "user.ANSI.bold", "user.ANSI.bold"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfFolder.get_token", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.UploadCommand.walk_dir", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.ANSI.bold", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.presign_and_upload", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.ANSI.bold", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.user.ANSI.bold"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "token", "=", "HfFolder", ".", "get_token", "(", ")", "\n", "if", "token", "is", "None", ":", "\n", "            ", "print", "(", "\"Not logged in\"", ")", "\n", "exit", "(", "1", ")", "\n", "", "local_path", "=", "os", ".", "path", ".", "abspath", "(", "self", ".", "args", ".", "path", ")", "\n", "if", "os", ".", "path", ".", "isdir", "(", "local_path", ")", ":", "\n", "            ", "if", "self", ".", "args", ".", "filename", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"Cannot specify a filename override when uploading a folder.\"", ")", "\n", "", "rel_path", "=", "os", ".", "path", ".", "basename", "(", "local_path", ")", "\n", "files", "=", "self", ".", "walk_dir", "(", "rel_path", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "local_path", ")", ":", "\n", "            ", "filename", "=", "self", ".", "args", ".", "filename", "if", "self", ".", "args", ".", "filename", "is", "not", "None", "else", "os", ".", "path", ".", "basename", "(", "local_path", ")", "\n", "files", "=", "[", "(", "local_path", ",", "filename", ")", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Not a valid file or directory: {}\"", ".", "format", "(", "local_path", ")", ")", "\n", "\n", "", "for", "filepath", ",", "filename", "in", "files", ":", "\n", "            ", "print", "(", "\"About to upload file {} to S3 under filename {}\"", ".", "format", "(", "ANSI", ".", "bold", "(", "filepath", ")", ",", "ANSI", ".", "bold", "(", "filename", ")", ")", ")", "\n", "\n", "", "choice", "=", "input", "(", "\"Proceed? [Y/n] \"", ")", ".", "lower", "(", ")", "\n", "if", "not", "(", "choice", "==", "\"\"", "or", "choice", "==", "\"y\"", "or", "choice", "==", "\"yes\"", ")", ":", "\n", "            ", "print", "(", "\"Abort\"", ")", "\n", "exit", "(", ")", "\n", "", "print", "(", "ANSI", ".", "bold", "(", "\"Uploading... This might take a while if files are large\"", ")", ")", "\n", "for", "filepath", ",", "filename", "in", "files", ":", "\n", "            ", "access_url", "=", "self", ".", "_api", ".", "presign_and_upload", "(", "token", "=", "token", ",", "filename", "=", "filename", ",", "filepath", "=", "filepath", ")", "\n", "print", "(", "\"Your file now lives at:\"", ")", "\n", "print", "(", "access_url", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.download.DownloadCommand.register_subcommand": [[11, 22], ["parser.add_parser", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.set_defaults"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "register_subcommand", "(", "parser", ":", "ArgumentParser", ")", ":", "\n", "        ", "download_parser", "=", "parser", ".", "add_parser", "(", "\"download\"", ")", "\n", "download_parser", ".", "add_argument", "(", "\n", "\"--cache-dir\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Path to location to store the models\"", "\n", ")", "\n", "download_parser", ".", "add_argument", "(", "\n", "\"--force\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Force the model to be download even if already in cache-dir\"", "\n", ")", "\n", "download_parser", ".", "add_argument", "(", "\"model\"", ",", "type", "=", "str", ",", "help", "=", "\"Name of the model to download\"", ")", "\n", "download_parser", ".", "set_defaults", "(", "func", "=", "download_command_factory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.download.DownloadCommand.__init__": [[23, 27], ["None"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "model", ":", "str", ",", "cache", ":", "str", ",", "force", ":", "bool", ")", ":", "\n", "        ", "self", ".", "_model", "=", "model", "\n", "self", ".", "_cache", "=", "cache", "\n", "self", ".", "_force", "=", "force", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.download.DownloadCommand.run": [[28, 33], ["AutoModel.from_pretrained", "AutoTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "from", "transformers", "import", "AutoModel", ",", "AutoTokenizer", "\n", "\n", "AutoModel", ".", "from_pretrained", "(", "self", ".", "_model", ",", "cache_dir", "=", "self", ".", "_cache", ",", "force_download", "=", "self", ".", "_force", ")", "\n", "AutoTokenizer", ".", "from_pretrained", "(", "self", ".", "_model", ",", "cache_dir", "=", "self", ".", "_cache", ",", "force_download", "=", "self", ".", "_force", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.download.download_command_factory": [[6, 8], ["download.DownloadCommand"], "function", ["None"], ["def", "download_command_factory", "(", "args", ")", ":", "\n", "    ", "return", "DownloadCommand", "(", "args", ".", "model", ",", "args", ".", "cache_dir", ",", "args", ".", "force", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.convert.ConvertCommand.register_subcommand": [[18, 45], ["parser.add_parser", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.set_defaults"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "register_subcommand", "(", "parser", ":", "ArgumentParser", ")", ":", "\n", "        ", "\"\"\"\n        Register this command to argparse so it's available for the transformer-cli\n        :param parser: Root parser to register command-specific arguments\n        :return:\n        \"\"\"", "\n", "train_parser", "=", "parser", ".", "add_parser", "(", "\n", "\"convert\"", ",", "\n", "help", "=", "\"CLI tool to run convert model from original \"", "\n", "\"author checkpoints to Transformesr PyTorch checkpoints.\"", ",", "\n", ")", "\n", "train_parser", ".", "add_argument", "(", "\"--model_type\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"Model's type.\"", ")", "\n", "train_parser", ".", "add_argument", "(", "\n", "\"--tf_checkpoint\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"TensorFlow checkpoint path or folder.\"", "\n", ")", "\n", "train_parser", ".", "add_argument", "(", "\n", "\"--pytorch_dump_output\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"Path to the PyTorch savd model output.\"", "\n", ")", "\n", "train_parser", ".", "add_argument", "(", "\"--config\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"Configuration file path or folder.\"", ")", "\n", "train_parser", ".", "add_argument", "(", "\n", "\"--finetuning_task_name\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Optional fine-tuning task name if the TF model was a finetuned model.\"", ",", "\n", ")", "\n", "train_parser", ".", "set_defaults", "(", "func", "=", "convert_command_factory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.convert.ConvertCommand.__init__": [[46, 63], ["logging.getLogger", "convert.ConvertCommand._logger.info"], "methods", ["None"], ["", "def", "__init__", "(", "\n", "self", ",", "\n", "model_type", ":", "str", ",", "\n", "tf_checkpoint", ":", "str", ",", "\n", "pytorch_dump_output", ":", "str", ",", "\n", "config", ":", "str", ",", "\n", "finetuning_task_name", ":", "str", ",", "\n", "*", "args", "\n", ")", ":", "\n", "        ", "self", ".", "_logger", "=", "getLogger", "(", "\"transformers-cli/converting\"", ")", "\n", "\n", "self", ".", "_logger", ".", "info", "(", "\"Loading model {}\"", ".", "format", "(", "model_type", ")", ")", "\n", "self", ".", "_model_type", "=", "model_type", "\n", "self", ".", "_tf_checkpoint", "=", "tf_checkpoint", "\n", "self", ".", "_pytorch_dump_output", "=", "pytorch_dump_output", "\n", "self", ".", "_config", "=", "config", "\n", "self", ".", "_finetuning_task_name", "=", "finetuning_task_name", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.convert.ConvertCommand.run": [[64, 145], ["convert_tf_checkpoint_to_pytorch", "convert_openai_checkpoint_to_pytorch", "ImportError", "convert_transfo_xl_checkpoint_to_pytorch", "convert.ConvertCommand._tf_checkpoint.lower", "convert_gpt2_checkpoint_to_pytorch", "ImportError", "convert_xlnet_checkpoint_to_pytorch", "ImportError", "convert_xlm_checkpoint_to_pytorch", "ValueError", "ImportError"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.convert_xxx_original_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_openai_original_tf_checkpoint_to_pytorch.convert_openai_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_transfo_xl_original_tf_checkpoint_to_pytorch.convert_transfo_xl_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_gpt2_original_tf_checkpoint_to_pytorch.convert_gpt2_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_xlnet_original_tf_checkpoint_to_pytorch.convert_xlnet_checkpoint_to_pytorch", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.convert_xlm_original_pytorch_checkpoint_to_pytorch.convert_xlm_checkpoint_to_pytorch"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_model_type", "==", "\"bert\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", "transformers", ".", "convert_bert_original_tf_checkpoint_to_pytorch", "import", "(", "\n", "convert_tf_checkpoint_to_pytorch", ",", "\n", ")", "\n", "", "except", "ImportError", ":", "\n", "                ", "msg", "=", "(", "\n", "\"transformers can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "ImportError", "(", "msg", ")", "\n", "\n", "", "convert_tf_checkpoint_to_pytorch", "(", "self", ".", "_tf_checkpoint", ",", "self", ".", "_config", ",", "self", ".", "_pytorch_dump_output", ")", "\n", "", "elif", "self", ".", "_model_type", "==", "\"gpt\"", ":", "\n", "            ", "from", "transformers", ".", "convert_openai_original_tf_checkpoint_to_pytorch", "import", "(", "\n", "convert_openai_checkpoint_to_pytorch", ",", "\n", ")", "\n", "\n", "convert_openai_checkpoint_to_pytorch", "(", "self", ".", "_tf_checkpoint", ",", "self", ".", "_config", ",", "self", ".", "_pytorch_dump_output", ")", "\n", "", "elif", "self", ".", "_model_type", "==", "\"transfo_xl\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", "transformers", ".", "convert_transfo_xl_original_tf_checkpoint_to_pytorch", "import", "(", "\n", "convert_transfo_xl_checkpoint_to_pytorch", ",", "\n", ")", "\n", "", "except", "ImportError", ":", "\n", "                ", "msg", "=", "(", "\n", "\"transformers can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "ImportError", "(", "msg", ")", "\n", "\n", "", "if", "\"ckpt\"", "in", "self", ".", "_tf_checkpoint", ".", "lower", "(", ")", ":", "\n", "                ", "TF_CHECKPOINT", "=", "self", ".", "_tf_checkpoint", "\n", "TF_DATASET_FILE", "=", "\"\"", "\n", "", "else", ":", "\n", "                ", "TF_DATASET_FILE", "=", "self", ".", "_tf_checkpoint", "\n", "TF_CHECKPOINT", "=", "\"\"", "\n", "", "convert_transfo_xl_checkpoint_to_pytorch", "(", "\n", "TF_CHECKPOINT", ",", "self", ".", "_config", ",", "self", ".", "_pytorch_dump_output", ",", "TF_DATASET_FILE", "\n", ")", "\n", "", "elif", "self", ".", "_model_type", "==", "\"gpt2\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", "transformers", ".", "convert_gpt2_original_tf_checkpoint_to_pytorch", "import", "(", "\n", "convert_gpt2_checkpoint_to_pytorch", ",", "\n", ")", "\n", "", "except", "ImportError", ":", "\n", "                ", "msg", "=", "(", "\n", "\"transformers can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "ImportError", "(", "msg", ")", "\n", "\n", "", "convert_gpt2_checkpoint_to_pytorch", "(", "self", ".", "_tf_checkpoint", ",", "self", ".", "_config", ",", "self", ".", "_pytorch_dump_output", ")", "\n", "", "elif", "self", ".", "_model_type", "==", "\"xlnet\"", ":", "\n", "            ", "try", ":", "\n", "                ", "from", "transformers", ".", "convert_xlnet_original_tf_checkpoint_to_pytorch", "import", "(", "\n", "convert_xlnet_checkpoint_to_pytorch", ",", "\n", ")", "\n", "", "except", "ImportError", ":", "\n", "                ", "msg", "=", "(", "\n", "\"transformers can only be used from the commandline to convert TensorFlow models in PyTorch, \"", "\n", "\"In that case, it requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "ImportError", "(", "msg", ")", "\n", "\n", "", "convert_xlnet_checkpoint_to_pytorch", "(", "\n", "self", ".", "_tf_checkpoint", ",", "self", ".", "_config", ",", "self", ".", "_pytorch_dump_output", ",", "self", ".", "_finetuning_task_name", "\n", ")", "\n", "", "elif", "self", ".", "_model_type", "==", "\"xlm\"", ":", "\n", "            ", "from", "transformers", ".", "convert_xlm_original_pytorch_checkpoint_to_pytorch", "import", "(", "\n", "convert_xlm_checkpoint_to_pytorch", ",", "\n", ")", "\n", "\n", "convert_xlm_checkpoint_to_pytorch", "(", "self", ".", "_tf_checkpoint", ",", "self", ".", "_pytorch_dump_output", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"--model_type should be selected in the list [bert, gpt, gpt2, transfo_xl, xlnet, xlm]\"", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.convert.convert_command_factory": [[7, 14], ["convert.ConvertCommand"], "function", ["None"], ["def", "convert_command_factory", "(", "args", ":", "Namespace", ")", ":", "\n", "    ", "\"\"\"\n    Factory function used to convert a model TF 1.0 checkpoint in a PyTorch checkpoint.\n    :return: ServeCommand\n    \"\"\"", "\n", "return", "ConvertCommand", "(", "\n", "args", ".", "model_type", ",", "args", ".", "tf_checkpoint", ",", "args", ".", "pytorch_dump_output", ",", "args", ".", "config", ",", "args", ".", "finetuning_task_name", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.run.RunCommand.__init__": [[45, 48], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "nlp", ":", "Pipeline", ",", "reader", ":", "PipelineDataFormat", ")", ":", "\n", "        ", "self", ".", "_nlp", "=", "nlp", "\n", "self", ".", "_reader", "=", "reader", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.run.RunCommand.register_subcommand": [[49, 80], ["parser.add_parser", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.set_defaults", "transformers.pipelines.SUPPORTED_TASKS.keys"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "register_subcommand", "(", "parser", ":", "ArgumentParser", ")", ":", "\n", "        ", "run_parser", "=", "parser", ".", "add_parser", "(", "\"run\"", ",", "help", "=", "\"Run a pipeline through the CLI\"", ")", "\n", "run_parser", ".", "add_argument", "(", "\"--task\"", ",", "choices", "=", "SUPPORTED_TASKS", ".", "keys", "(", ")", ",", "help", "=", "\"Task to run\"", ")", "\n", "run_parser", ".", "add_argument", "(", "\"--input\"", ",", "type", "=", "str", ",", "help", "=", "\"Path to the file to use for inference\"", ")", "\n", "run_parser", ".", "add_argument", "(", "\"--output\"", ",", "type", "=", "str", ",", "help", "=", "\"Path to the file that will be used post to write results.\"", ")", "\n", "run_parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "help", "=", "\"Name or path to the model to instantiate.\"", ")", "\n", "run_parser", ".", "add_argument", "(", "\"--config\"", ",", "type", "=", "str", ",", "help", "=", "\"Name or path to the model's config to instantiate.\"", ")", "\n", "run_parser", ".", "add_argument", "(", "\n", "\"--tokenizer\"", ",", "type", "=", "str", ",", "help", "=", "\"Name of the tokenizer to use. (default: same as the model name)\"", "\n", ")", "\n", "run_parser", ".", "add_argument", "(", "\n", "\"--column\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Name of the column to use as input. (For multi columns input as QA use column1,columns2)\"", ",", "\n", ")", "\n", "run_parser", ".", "add_argument", "(", "\n", "\"--format\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"infer\"", ",", "\n", "choices", "=", "PipelineDataFormat", ".", "SUPPORTED_FORMATS", ",", "\n", "help", "=", "\"Input format to read from\"", ",", "\n", ")", "\n", "run_parser", ".", "add_argument", "(", "\n", "\"--device\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Indicate the device to run onto, -1 indicates CPU, >= 0 indicates GPU (default: -1)\"", ",", "\n", ")", "\n", "run_parser", ".", "add_argument", "(", "\"--overwrite\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Allow overwriting the output file.\"", ")", "\n", "run_parser", ".", "set_defaults", "(", "func", "=", "run_command_factory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.run.RunCommand.run": [[81, 97], ["isinstance", "run.RunCommand._reader.save_binary", "logger.warning", "run.RunCommand._reader.save", "nlp", "nlp", "outputs.append"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save_binary", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "nlp", ",", "outputs", "=", "self", ".", "_nlp", ",", "[", "]", "\n", "\n", "for", "entry", "in", "self", ".", "_reader", ":", "\n", "            ", "output", "=", "nlp", "(", "**", "entry", ")", "if", "self", ".", "_reader", ".", "is_multi_columns", "else", "nlp", "(", "entry", ")", "\n", "if", "isinstance", "(", "output", ",", "dict", ")", ":", "\n", "                ", "outputs", ".", "append", "(", "output", ")", "\n", "", "else", ":", "\n", "                ", "outputs", "+=", "output", "\n", "\n", "# Saving data", "\n", "", "", "if", "self", ".", "_nlp", ".", "binary_output", ":", "\n", "            ", "binary_path", "=", "self", ".", "_reader", ".", "save_binary", "(", "outputs", ")", "\n", "logger", ".", "warning", "(", "\"Current pipeline requires output to be in binary format, saving at {}\"", ".", "format", "(", "binary_path", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_reader", ".", "save", "(", "outputs", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.run.try_infer_format_from_ext": [[11, 22], ["Exception", "path.endswith"], "function", ["None"], ["def", "try_infer_format_from_ext", "(", "path", ":", "str", ")", ":", "\n", "    ", "if", "not", "path", ":", "\n", "        ", "return", "\"pipe\"", "\n", "\n", "", "for", "ext", "in", "PipelineDataFormat", ".", "SUPPORTED_FORMATS", ":", "\n", "        ", "if", "path", ".", "endswith", "(", "ext", ")", ":", "\n", "            ", "return", "ext", "\n", "\n", "", "", "raise", "Exception", "(", "\n", "\"Unable to determine file format from file extension {}. \"", "\n", "\"Please provide the format through --format {}\"", ".", "format", "(", "path", ",", "PipelineDataFormat", ".", "SUPPORTED_FORMATS", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.run.run_command_factory": [[25, 42], ["transformers.pipelines.pipeline", "transformers.pipelines.PipelineDataFormat.from_str", "run.RunCommand", "run.try_infer_format_from_ext"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.pipeline", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipelineDataFormat.from_str", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.run.try_infer_format_from_ext"], ["", "def", "run_command_factory", "(", "args", ")", ":", "\n", "    ", "nlp", "=", "pipeline", "(", "\n", "task", "=", "args", ".", "task", ",", "\n", "model", "=", "args", ".", "model", "if", "args", ".", "model", "else", "None", ",", "\n", "config", "=", "args", ".", "config", ",", "\n", "tokenizer", "=", "args", ".", "tokenizer", ",", "\n", "device", "=", "args", ".", "device", ",", "\n", ")", "\n", "format", "=", "try_infer_format_from_ext", "(", "args", ".", "input", ")", "if", "args", ".", "format", "==", "\"infer\"", "else", "args", ".", "format", "\n", "reader", "=", "PipelineDataFormat", ".", "from_str", "(", "\n", "format", "=", "format", ",", "\n", "output_path", "=", "args", ".", "output", ",", "\n", "input_path", "=", "args", ".", "input", ",", "\n", "column", "=", "args", ".", "column", "if", "args", ".", "column", "else", "nlp", ".", "default_input_names", ",", "\n", "overwrite", "=", "args", ".", "overwrite", ",", "\n", ")", "\n", "return", "RunCommand", "(", "nlp", ",", "reader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.register_subcommand": [[77, 102], ["parser.add_parser", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.add_argument", "parser.add_parser.set_defaults", "transformers.pipelines.SUPPORTED_TASKS.keys"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "register_subcommand", "(", "parser", ":", "ArgumentParser", ")", ":", "\n", "        ", "\"\"\"\n        Register this command to argparse so it's available for the transformer-cli\n        :param parser: Root parser to register command-specific arguments\n        :return:\n        \"\"\"", "\n", "serve_parser", "=", "parser", ".", "add_parser", "(", "\n", "\"serve\"", ",", "help", "=", "\"CLI tool to run inference requests through REST and GraphQL endpoints.\"", "\n", ")", "\n", "serve_parser", ".", "add_argument", "(", "\n", "\"--task\"", ",", "type", "=", "str", ",", "choices", "=", "SUPPORTED_TASKS", ".", "keys", "(", ")", ",", "help", "=", "\"The task to run the pipeline on\"", "\n", ")", "\n", "serve_parser", ".", "add_argument", "(", "\"--host\"", ",", "type", "=", "str", ",", "default", "=", "\"localhost\"", ",", "help", "=", "\"Interface the server will listen on.\"", ")", "\n", "serve_parser", ".", "add_argument", "(", "\"--port\"", ",", "type", "=", "int", ",", "default", "=", "8888", ",", "help", "=", "\"Port the serving will listen to.\"", ")", "\n", "serve_parser", ".", "add_argument", "(", "\"--model\"", ",", "type", "=", "str", ",", "help", "=", "\"Model's name or path to stored model.\"", ")", "\n", "serve_parser", ".", "add_argument", "(", "\"--config\"", ",", "type", "=", "str", ",", "help", "=", "\"Model's config name or path to stored model.\"", ")", "\n", "serve_parser", ".", "add_argument", "(", "\"--tokenizer\"", ",", "type", "=", "str", ",", "help", "=", "\"Tokenizer name to use.\"", ")", "\n", "serve_parser", ".", "add_argument", "(", "\n", "\"--device\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "-", "1", ",", "\n", "help", "=", "\"Indicate the device to run onto, -1 indicates CPU, >= 0 indicates GPU (default: -1)\"", ",", "\n", ")", "\n", "serve_parser", ".", "set_defaults", "(", "func", "=", "serve_command_factory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.__init__": [[103, 126], ["RuntimeError", "logger.info", "FastAPI", "serving.ServeCommand._app.add_api_route", "serving.ServeCommand._app.add_api_route", "serving.ServeCommand._app.add_api_route", "serving.ServeCommand._app.add_api_route"], "methods", ["None"], ["", "def", "__init__", "(", "self", ",", "pipeline", ":", "Pipeline", ",", "host", ":", "str", ",", "port", ":", "int", ")", ":", "\n", "\n", "        ", "self", ".", "_pipeline", "=", "pipeline", "\n", "\n", "self", ".", "_host", "=", "host", "\n", "self", ".", "_port", "=", "port", "\n", "if", "not", "_serve_dependancies_installed", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Using serve command requires FastAPI and unicorn. \"", "\n", "\"Please install transformers with [serving]: pip install transformers[serving].\"", "\n", "\"Or install FastAPI and unicorn separatly.\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"Serving model over {}:{}\"", ".", "format", "(", "host", ",", "port", ")", ")", "\n", "self", ".", "_app", "=", "FastAPI", "(", ")", "\n", "\n", "# Register routes", "\n", "self", ".", "_app", ".", "add_api_route", "(", "\"/\"", ",", "self", ".", "model_info", ",", "response_model", "=", "ServeModelInfoResult", ",", "methods", "=", "[", "\"GET\"", "]", ")", "\n", "self", ".", "_app", ".", "add_api_route", "(", "\"/tokenize\"", ",", "self", ".", "tokenize", ",", "response_model", "=", "ServeTokenizeResult", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "self", ".", "_app", ".", "add_api_route", "(", "\n", "\"/detokenize\"", ",", "self", ".", "detokenize", ",", "response_model", "=", "ServeDeTokenizeResult", ",", "methods", "=", "[", "\"POST\"", "]", "\n", ")", "\n", "self", ".", "_app", ".", "add_api_route", "(", "\"/forward\"", ",", "self", ".", "forward", ",", "response_model", "=", "ServeForwardResult", ",", "methods", "=", "[", "\"POST\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.run": [[127, 129], ["serving.ServeCommand.run"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.__init__.BaseTransformersCLICommand.run"], ["", "", "def", "run", "(", "self", ")", ":", "\n", "        ", "run", "(", "self", ".", "_app", ",", "host", "=", "self", ".", "_host", ",", "port", "=", "self", ".", "_port", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.model_info": [[130, 132], ["serving.ServeModelInfoResult", "vars"], "methods", ["None"], ["", "def", "model_info", "(", "self", ")", ":", "\n", "        ", "return", "ServeModelInfoResult", "(", "infos", "=", "vars", "(", "self", ".", "_pipeline", ".", "model", ".", "config", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize": [[133, 150], ["Body", "Body", "serving.ServeCommand._pipeline.tokenizer.tokenize", "serving.ServeCommand._pipeline.tokenizer.convert_tokens_to_ids", "serving.ServeTokenizeResult", "serving.ServeTokenizeResult", "HTTPException", "str"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "tokenize", "(", "self", ",", "text_input", ":", "str", "=", "Body", "(", "None", ",", "embed", "=", "True", ")", ",", "return_ids", ":", "bool", "=", "Body", "(", "False", ",", "embed", "=", "True", ")", ")", ":", "\n", "        ", "\"\"\"\n        Tokenize the provided input and eventually returns corresponding tokens id:\n        - **text_input**: String to tokenize\n        - **return_ids**: Boolean flags indicating if the tokens have to be converted to their integer mapping.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "tokens_txt", "=", "self", ".", "_pipeline", ".", "tokenizer", ".", "tokenize", "(", "text_input", ")", "\n", "\n", "if", "return_ids", ":", "\n", "                ", "tokens_ids", "=", "self", ".", "_pipeline", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens_txt", ")", "\n", "return", "ServeTokenizeResult", "(", "tokens", "=", "tokens_txt", ",", "tokens_ids", "=", "tokens_ids", ")", "\n", "", "else", ":", "\n", "                ", "return", "ServeTokenizeResult", "(", "tokens", "=", "tokens_txt", ")", "\n", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "HTTPException", "(", "status_code", "=", "500", ",", "detail", "=", "{", "\"model\"", ":", "\"\"", ",", "\"error\"", ":", "str", "(", "e", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.detokenize": [[151, 168], ["Body", "Body", "Body", "serving.ServeCommand._pipeline.tokenizer.decode", "serving.ServeDeTokenizeResult", "HTTPException", "str"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "", "def", "detokenize", "(", "\n", "self", ",", "\n", "tokens_ids", ":", "List", "[", "int", "]", "=", "Body", "(", "None", ",", "embed", "=", "True", ")", ",", "\n", "skip_special_tokens", ":", "bool", "=", "Body", "(", "False", ",", "embed", "=", "True", ")", ",", "\n", "cleanup_tokenization_spaces", ":", "bool", "=", "Body", "(", "True", ",", "embed", "=", "True", ")", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Detokenize the provided tokens ids to readable text:\n        - **tokens_ids**: List of tokens ids\n        - **skip_special_tokens**: Flag indicating to not try to decode special tokens\n        - **cleanup_tokenization_spaces**: Flag indicating to remove all leading/trailing spaces and intermediate ones.\n        \"\"\"", "\n", "try", ":", "\n", "            ", "decoded_str", "=", "self", ".", "_pipeline", ".", "tokenizer", ".", "decode", "(", "tokens_ids", ",", "skip_special_tokens", ",", "cleanup_tokenization_spaces", ")", "\n", "return", "ServeDeTokenizeResult", "(", "model", "=", "\"\"", ",", "text", "=", "decoded_str", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "HTTPException", "(", "status_code", "=", "500", ",", "detail", "=", "{", "\"model\"", ":", "\"\"", ",", "\"error\"", ":", "str", "(", "e", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.forward": [[169, 186], ["Body", "len", "serving.ServeForwardResult", "serving.ServeCommand._pipeline", "serving.ServeForwardResult", "HTTPException", "str"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inputs", ":", "Union", "[", "str", ",", "dict", ",", "List", "[", "str", "]", ",", "List", "[", "int", "]", ",", "List", "[", "dict", "]", "]", "=", "Body", "(", "None", ",", "embed", "=", "True", ")", ")", ":", "\n", "        ", "\"\"\"\n        **inputs**:\n        **attention_mask**:\n        **tokens_type_ids**:\n        \"\"\"", "\n", "\n", "# Check we don't have empty string", "\n", "if", "len", "(", "inputs", ")", "==", "0", ":", "\n", "            ", "return", "ServeForwardResult", "(", "output", "=", "[", "]", ",", "attention", "=", "[", "]", ")", "\n", "\n", "", "try", ":", "\n", "# Forward through the model", "\n", "            ", "output", "=", "self", ".", "_pipeline", "(", "inputs", ")", "\n", "return", "ServeForwardResult", "(", "output", "=", "output", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "HTTPException", "(", "500", ",", "{", "\"error\"", ":", "str", "(", "e", ")", "}", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.serve_command_factory": [[28, 41], ["transformers.pipelines.pipeline", "serving.ServeCommand"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.pipeline"], ["def", "serve_command_factory", "(", "args", ":", "Namespace", ")", ":", "\n", "    ", "\"\"\"\n    Factory function used to instantiate serving server from provided command line arguments.\n    :return: ServeCommand\n    \"\"\"", "\n", "nlp", "=", "pipeline", "(", "\n", "task", "=", "args", ".", "task", ",", "\n", "model", "=", "args", ".", "model", "if", "args", ".", "model", "else", "None", ",", "\n", "config", "=", "args", ".", "config", ",", "\n", "tokenizer", "=", "args", ".", "tokenizer", ",", "\n", "device", "=", "args", ".", "device", ",", "\n", ")", "\n", "return", "ServeCommand", "(", "nlp", ",", "args", ".", "host", ",", "args", ".", "port", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.__init__.BaseTransformersCLICommand.register_subcommand": [[6, 10], ["NotImplementedError"], "methods", ["None"], ["\n", "# Work around to update TensorFlow's absl.logging threshold which alters the", "\n", "# default Python logging output behavior when present.", "\n", "# see: https://github.com/abseil/abseil-py/issues/99", "\n", "# and: https://github.com/tensorflow/tensorflow/issues/26691#issuecomment-500369493", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.__init__.BaseTransformersCLICommand.run": [[11, 14], ["NotImplementedError"], "methods", ["None"], ["try", ":", "\n", "    ", "import", "absl", ".", "logging", "\n", "", "except", "ImportError", ":", "\n", "    ", "pass", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.utils.download_glue_data.download_and_extract": [[47, 55], ["print", "urllib.request.urlretrieve", "os.remove", "print", "zipfile.ZipFile", "zip_ref.extractall"], "function", ["None"], ["def", "download_and_extract", "(", "task", ",", "data_dir", ")", ":", "\n", "    ", "print", "(", "\"Downloading and extracting %s...\"", "%", "task", ")", "\n", "data_file", "=", "\"%s.zip\"", "%", "task", "\n", "urllib", ".", "request", ".", "urlretrieve", "(", "TASK2PATH", "[", "task", "]", ",", "data_file", ")", "\n", "with", "zipfile", ".", "ZipFile", "(", "data_file", ")", "as", "zip_ref", ":", "\n", "        ", "zip_ref", ".", "extractall", "(", "data_dir", ")", "\n", "", "os", ".", "remove", "(", "data_file", ")", "\n", "print", "(", "\"\\tCompleted!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.utils.download_glue_data.format_mrpc": [[57, 102], ["print", "os.path.join", "os.path.isfile", "os.path.isfile", "urllib.request.urlretrieve", "print", "os.path.isdir", "os.mkdir", "os.path.join", "os.path.join", "print", "os.path.join", "os.path.join", "urllib.request.urlretrieve", "urllib.request.urlretrieve", "os.path.join", "open", "open", "open", "open", "data_fh.readline", "train_fh.write", "dev_fh.write", "open", "open", "data_fh.readline", "test_fh.write", "enumerate", "os.path.join", "dev_ids.append", "os.path.join", "os.path.join", "row.strip().split", "os.path.join", "row.strip().split", "test_fh.write", "row.strip().split", "dev_fh.write", "train_fh.write", "row.strip", "row.strip", "row.strip"], "function", ["None"], ["", "def", "format_mrpc", "(", "data_dir", ",", "path_to_data", ")", ":", "\n", "    ", "print", "(", "\"Processing MRPC...\"", ")", "\n", "mrpc_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"MRPC\"", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "mrpc_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "mrpc_dir", ")", "\n", "", "if", "path_to_data", ":", "\n", "        ", "mrpc_train_file", "=", "os", ".", "path", ".", "join", "(", "path_to_data", ",", "\"msr_paraphrase_train.txt\"", ")", "\n", "mrpc_test_file", "=", "os", ".", "path", ".", "join", "(", "path_to_data", ",", "\"msr_paraphrase_test.txt\"", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Local MRPC data not specified, downloading data from %s\"", "%", "MRPC_TRAIN", ")", "\n", "mrpc_train_file", "=", "os", ".", "path", ".", "join", "(", "mrpc_dir", ",", "\"msr_paraphrase_train.txt\"", ")", "\n", "mrpc_test_file", "=", "os", ".", "path", ".", "join", "(", "mrpc_dir", ",", "\"msr_paraphrase_test.txt\"", ")", "\n", "urllib", ".", "request", ".", "urlretrieve", "(", "MRPC_TRAIN", ",", "mrpc_train_file", ")", "\n", "urllib", ".", "request", ".", "urlretrieve", "(", "MRPC_TEST", ",", "mrpc_test_file", ")", "\n", "", "assert", "os", ".", "path", ".", "isfile", "(", "mrpc_train_file", ")", ",", "\"Train data not found at %s\"", "%", "mrpc_train_file", "\n", "assert", "os", ".", "path", ".", "isfile", "(", "mrpc_test_file", ")", ",", "\"Test data not found at %s\"", "%", "mrpc_test_file", "\n", "urllib", ".", "request", ".", "urlretrieve", "(", "TASK2PATH", "[", "\"MRPC\"", "]", ",", "os", ".", "path", ".", "join", "(", "mrpc_dir", ",", "\"dev_ids.tsv\"", ")", ")", "\n", "\n", "dev_ids", "=", "[", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "mrpc_dir", ",", "\"dev_ids.tsv\"", ")", ",", "encoding", "=", "\"utf8\"", ")", "as", "ids_fh", ":", "\n", "        ", "for", "row", "in", "ids_fh", ":", "\n", "            ", "dev_ids", ".", "append", "(", "row", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", ")", "\n", "\n", "", "", "with", "open", "(", "mrpc_train_file", ",", "encoding", "=", "\"utf8\"", ")", "as", "data_fh", ",", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "mrpc_dir", ",", "\"train.tsv\"", ")", ",", "\"w\"", ",", "encoding", "=", "\"utf8\"", "\n", ")", "as", "train_fh", ",", "open", "(", "os", ".", "path", ".", "join", "(", "mrpc_dir", ",", "\"dev.tsv\"", ")", ",", "\"w\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "dev_fh", ":", "\n", "        ", "header", "=", "data_fh", ".", "readline", "(", ")", "\n", "train_fh", ".", "write", "(", "header", ")", "\n", "dev_fh", ".", "write", "(", "header", ")", "\n", "for", "row", "in", "data_fh", ":", "\n", "            ", "label", ",", "id1", ",", "id2", ",", "s1", ",", "s2", "=", "row", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "if", "[", "id1", ",", "id2", "]", "in", "dev_ids", ":", "\n", "                ", "dev_fh", ".", "write", "(", "\"%s\\t%s\\t%s\\t%s\\t%s\\n\"", "%", "(", "label", ",", "id1", ",", "id2", ",", "s1", ",", "s2", ")", ")", "\n", "", "else", ":", "\n", "                ", "train_fh", ".", "write", "(", "\"%s\\t%s\\t%s\\t%s\\t%s\\n\"", "%", "(", "label", ",", "id1", ",", "id2", ",", "s1", ",", "s2", ")", ")", "\n", "\n", "", "", "", "with", "open", "(", "mrpc_test_file", ",", "encoding", "=", "\"utf8\"", ")", "as", "data_fh", ",", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "mrpc_dir", ",", "\"test.tsv\"", ")", ",", "\"w\"", ",", "encoding", "=", "\"utf8\"", "\n", ")", "as", "test_fh", ":", "\n", "        ", "header", "=", "data_fh", ".", "readline", "(", ")", "\n", "test_fh", ".", "write", "(", "\"index\\t#1 ID\\t#2 ID\\t#1 String\\t#2 String\\n\"", ")", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "data_fh", ")", ":", "\n", "            ", "label", ",", "id1", ",", "id2", ",", "s1", ",", "s2", "=", "row", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "test_fh", ".", "write", "(", "\"%d\\t%s\\t%s\\t%s\\t%s\\n\"", "%", "(", "idx", ",", "id1", ",", "id2", ",", "s1", ",", "s2", ")", ")", "\n", "", "", "print", "(", "\"\\tCompleted!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.utils.download_glue_data.download_diagnostic": [[104, 112], ["print", "os.path.join", "urllib.request.urlretrieve", "print", "os.path.isdir", "os.mkdir", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "download_diagnostic", "(", "data_dir", ")", ":", "\n", "    ", "print", "(", "\"Downloading and extracting diagnostic...\"", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"diagnostic\"", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"diagnostic\"", ")", ")", "\n", "", "data_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"diagnostic\"", ",", "\"diagnostic.tsv\"", ")", "\n", "urllib", ".", "request", ".", "urlretrieve", "(", "TASK2PATH", "[", "\"diagnostic\"", "]", ",", "data_file", ")", "\n", "print", "(", "\"\\tCompleted!\"", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.utils.download_glue_data.get_tasks": [[114, 124], ["task_names.split.split", "tasks.append"], "function", ["None"], ["", "def", "get_tasks", "(", "task_names", ")", ":", "\n", "    ", "task_names", "=", "task_names", ".", "split", "(", "\",\"", ")", "\n", "if", "\"all\"", "in", "task_names", ":", "\n", "        ", "tasks", "=", "TASKS", "\n", "", "else", ":", "\n", "        ", "tasks", "=", "[", "]", "\n", "for", "task_name", "in", "task_names", ":", "\n", "            ", "assert", "task_name", "in", "TASKS", ",", "\"Task %s not found!\"", "%", "task_name", "\n", "tasks", ".", "append", "(", "task_name", ")", "\n", "", "", "return", "tasks", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.utils.download_glue_data.main": [[126, 151], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "download_glue_data.get_tasks", "os.path.isdir", "os.mkdir", "download_glue_data.format_mrpc", "download_glue_data.download_diagnostic", "download_glue_data.download_and_extract"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.utils.download_glue_data.get_tasks", "home.repos.pwc.inspect_result.bcmi220_ggdp.utils.download_glue_data.format_mrpc", "home.repos.pwc.inspect_result.bcmi220_ggdp.utils.download_glue_data.download_diagnostic", "home.repos.pwc.inspect_result.bcmi220_ggdp.utils.download_glue_data.download_and_extract"], ["", "def", "main", "(", "arguments", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "help", "=", "\"directory to save data to\"", ",", "type", "=", "str", ",", "default", "=", "\"glue_data\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tasks\"", ",", "help", "=", "\"tasks to download data for as a comma separated string\"", ",", "type", "=", "str", ",", "default", "=", "\"all\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--path_to_mrpc\"", ",", "\n", "help", "=", "\"path to directory containing extracted MRPC data, msr_paraphrase_train.txt and msr_paraphrase_text.txt\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"\"", ",", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", "arguments", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "data_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "args", ".", "data_dir", ")", "\n", "", "tasks", "=", "get_tasks", "(", "args", ".", "tasks", ")", "\n", "\n", "for", "task", "in", "tasks", ":", "\n", "        ", "if", "task", "==", "\"MRPC\"", ":", "\n", "            ", "format_mrpc", "(", "args", ".", "data_dir", ",", "args", ".", "path_to_mrpc", ")", "\n", "", "elif", "task", "==", "\"diagnostic\"", ":", "\n", "            ", "download_diagnostic", "(", "args", ".", "data_dir", ")", "\n", "", "else", ":", "\n", "            ", "download_and_extract", "(", "task", ",", "args", ".", "data_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.utils.link_tester.list_python_files_in_repository": [[17, 32], ["os.walk", "os.path.join", "source_code_files.append"], "function", ["None"], ["def", "list_python_files_in_repository", "(", ")", ":", "\n", "    ", "\"\"\" List all python files in the repository.\n\n    This function assumes that the script is executed in the root folder.\n    \"\"\"", "\n", "source_code_files", "=", "[", "]", "\n", "for", "path", ",", "subdirs", ",", "files", "in", "os", ".", "walk", "(", "\".\"", ")", ":", "\n", "        ", "if", "\"templates\"", "in", "path", ":", "\n", "            ", "continue", "\n", "", "for", "name", "in", "files", ":", "\n", "            ", "if", "\".py\"", "in", "name", "and", "\".pyc\"", "not", "in", "name", ":", "\n", "                ", "path_to_files", "=", "os", ".", "path", ".", "join", "(", "path", ",", "name", ")", "\n", "source_code_files", ".", "append", "(", "path_to_files", ")", "\n", "\n", "", "", "", "return", "source_code_files", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.utils.link_tester.find_all_links": [[34, 40], ["link_tester.scan_code_for_links"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.utils.link_tester.scan_code_for_links"], ["", "def", "find_all_links", "(", "file_paths", ")", ":", "\n", "    ", "links", "=", "[", "]", "\n", "for", "path", "in", "file_paths", ":", "\n", "        ", "links", "+=", "scan_code_for_links", "(", "path", ")", "\n", "\n", "", "return", "links", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.utils.link_tester.scan_code_for_links": [[42, 52], ["open", "content.read.read", "re.findall"], "function", ["None"], ["", "def", "scan_code_for_links", "(", "source", ")", ":", "\n", "    ", "\"\"\" Scans the file to find links using a regular expression.\n    Returns a list of links.\n    \"\"\"", "\n", "with", "open", "(", "source", ",", "\"r\"", ")", "as", "content", ":", "\n", "        ", "content", "=", "content", ".", "read", "(", ")", "\n", "raw_links", "=", "re", ".", "findall", "(", "REGEXP_FIND_S3_LINKS", ",", "content", ")", "\n", "links", "=", "[", "prefix", "+", "suffix", "for", "_", ",", "prefix", ",", "suffix", "in", "raw_links", "]", "\n", "\n", "", "return", "links", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.utils.link_tester.check_all_links": [[54, 67], ["requests.head", "broken_links.append"], "function", ["None"], ["", "def", "check_all_links", "(", "links", ")", ":", "\n", "    ", "\"\"\" Check that the provided links are valid.\n\n    Links are considered valid if a HEAD request to the server\n    returns a 200 status code.\n    \"\"\"", "\n", "broken_links", "=", "[", "]", "\n", "for", "link", "in", "links", ":", "\n", "        ", "head", "=", "requests", ".", "head", "(", "link", ")", "\n", "if", "head", ".", "status_code", "!=", "200", ":", "\n", "            ", "broken_links", ".", "append", "(", "link", ")", "\n", "\n", "", "", "return", "broken_links", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.run_xxx.set_seed": [[83, 89], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.run_xxx.to_list": [[91, 93], ["tensor.detach().cpu().tolist", "tensor.detach().cpu", "tensor.detach"], "function", ["None"], ["", "", "def", "to_list", "(", "tensor", ")", ":", "\n", "    ", "return", "tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.run_xxx.train": [[95, 235], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_xxx.set_seed", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "tqdm.tqdm", "enumerate", "SummaryWriter.close", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "ImportError", "torch.distributed.get_world_size", "inputs.update", "loss.mean.mean", "loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "os.path.join", "model_to_save.save_pretrained", "torch.save", "logger.info", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_xxx.evaluate", "evaluate.items", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_linear_schedule_with_warmup", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.TqdmProgressFileReader.close", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.train", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.TqdmProgressFileReader.close", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator.step", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator.step", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.TqdmProgressFileReader.close", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"start_positions\"", ":", "batch", "[", "3", "]", ",", "\n", "\"end_positions\"", ":", "batch", "[", "4", "]", ",", "\n", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "None", "if", "args", ".", "model_type", "==", "\"xlm\"", "else", "batch", "[", "2", "]", "\n", "", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", ",", "\"xlm\"", "]", ":", "\n", "                ", "inputs", ".", "update", "(", "{", "\"cls_index\"", ":", "batch", "[", "5", "]", ",", "\"p_mask\"", ":", "batch", "[", "6", "]", "}", ")", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel (not distributed) training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "(", "\n", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", "\n", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.run_xxx.evaluate": [[237, 332], ["run_xxx.load_and_cache_examples", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "tqdm.tqdm", "os.path.join", "os.path.join", "utils_squad_evaluate.EVAL_OPTS", "utils_squad_evaluate.main", "os.makedirs", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "model.eval", "tuple", "enumerate", "os.path.join", "utils_squad.write_predictions_extended", "utils_squad.write_predictions", "os.path.exists", "torch.no_grad", "model", "int", "all_results.append", "t.to", "inputs.update", "utils_squad.RawResultExtended", "utils_squad.RawResult", "example_index.item", "run_xxx.to_list", "run_xxx.to_list", "run_xxx.to_list", "run_xxx.to_list", "run_xxx.to_list", "run_xxx.to_list", "run_xxx.to_list"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.run_xxx.load_and_cache_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.main", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.write_predictions_extended", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.write_predictions", "home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.model", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.run_xxx.to_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.run_xxx.to_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.run_xxx.to_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.run_xxx.to_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.run_xxx.to_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.run_xxx.to_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.run_xxx.to_list"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "dataset", ",", "examples", ",", "features", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "True", ",", "output_examples", "=", "True", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "all_results", "=", "[", "]", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\"attention_mask\"", ":", "batch", "[", "1", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "None", "if", "args", ".", "model_type", "==", "\"xlm\"", "else", "batch", "[", "2", "]", "# XLM don't use segment_ids", "\n", "", "example_indices", "=", "batch", "[", "3", "]", "\n", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", ",", "\"xlm\"", "]", ":", "\n", "                ", "inputs", ".", "update", "(", "{", "\"cls_index\"", ":", "batch", "[", "4", "]", ",", "\"p_mask\"", ":", "batch", "[", "5", "]", "}", ")", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "", "for", "i", ",", "example_index", "in", "enumerate", "(", "example_indices", ")", ":", "\n", "            ", "eval_feature", "=", "features", "[", "example_index", ".", "item", "(", ")", "]", "\n", "unique_id", "=", "int", "(", "eval_feature", ".", "unique_id", ")", "\n", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", ",", "\"xlm\"", "]", ":", "\n", "# XLNet uses a more complex post-processing procedure", "\n", "                ", "result", "=", "RawResultExtended", "(", "\n", "unique_id", "=", "unique_id", ",", "\n", "start_top_log_probs", "=", "to_list", "(", "outputs", "[", "0", "]", "[", "i", "]", ")", ",", "\n", "start_top_index", "=", "to_list", "(", "outputs", "[", "1", "]", "[", "i", "]", ")", ",", "\n", "end_top_log_probs", "=", "to_list", "(", "outputs", "[", "2", "]", "[", "i", "]", ")", ",", "\n", "end_top_index", "=", "to_list", "(", "outputs", "[", "3", "]", "[", "i", "]", ")", ",", "\n", "cls_logits", "=", "to_list", "(", "outputs", "[", "4", "]", "[", "i", "]", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "result", "=", "RawResult", "(", "\n", "unique_id", "=", "unique_id", ",", "start_logits", "=", "to_list", "(", "outputs", "[", "0", "]", "[", "i", "]", ")", ",", "end_logits", "=", "to_list", "(", "outputs", "[", "1", "]", "[", "i", "]", ")", "\n", ")", "\n", "", "all_results", ".", "append", "(", "result", ")", "\n", "\n", "# Compute predictions", "\n", "", "", "output_prediction_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"predictions_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "output_nbest_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"nbest_predictions_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "if", "args", ".", "version_2_with_negative", ":", "\n", "        ", "output_null_log_odds_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"null_odds_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "", "else", ":", "\n", "        ", "output_null_log_odds_file", "=", "None", "\n", "\n", "", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", ",", "\"xlm\"", "]", ":", "\n", "# XLNet uses a more complex post-processing procedure", "\n", "        ", "write_predictions_extended", "(", "\n", "examples", ",", "\n", "features", ",", "\n", "all_results", ",", "\n", "args", ".", "n_best_size", ",", "\n", "args", ".", "max_answer_length", ",", "\n", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "\n", "output_null_log_odds_file", ",", "\n", "args", ".", "predict_file", ",", "\n", "model", ".", "config", ".", "start_n_top", ",", "\n", "model", ".", "config", ".", "end_n_top", ",", "\n", "args", ".", "version_2_with_negative", ",", "\n", "tokenizer", ",", "\n", "args", ".", "verbose_logging", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "write_predictions", "(", "\n", "examples", ",", "\n", "features", ",", "\n", "all_results", ",", "\n", "args", ".", "n_best_size", ",", "\n", "args", ".", "max_answer_length", ",", "\n", "args", ".", "do_lower_case", ",", "\n", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "\n", "output_null_log_odds_file", ",", "\n", "args", ".", "verbose_logging", ",", "\n", "args", ".", "version_2_with_negative", ",", "\n", "args", ".", "null_score_diff_threshold", ",", "\n", ")", "\n", "\n", "# Evaluate with the official SQuAD script", "\n", "", "evaluate_options", "=", "EVAL_OPTS", "(", "\n", "data_file", "=", "args", ".", "predict_file", ",", "pred_file", "=", "output_prediction_file", ",", "na_prob_file", "=", "output_null_log_odds_file", "\n", ")", "\n", "results", "=", "evaluate_on_squad", "(", "evaluate_options", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.run_xxx.load_and_cache_examples": [[334, 398], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.distributed.barrier", "os.path.dirname", "os.path.exists", "logger.info", "torch.load", "logger.info", "utils_squad.read_squad_examples", "utils_squad.convert_examples_to_features", "torch.distributed.barrier", "torch.arange", "torch.utils.data.TensorDataset", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "list().pop", "str", "logger.info", "torch.save", "torch.tensor.size", "list", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.read_squad_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.convert_examples_to_features", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save"], ["", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "output_examples", "=", "False", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Load data features from cache or dataset file", "\n", "", "input_file", "=", "args", ".", "predict_file", "if", "evaluate", "else", "args", ".", "train_file", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "dirname", "(", "input_file", ")", ",", "\n", "\"cached_{}_{}_{}\"", ".", "format", "(", "\n", "\"dev\"", "if", "evaluate", "else", "\"train\"", ",", "\n", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", ")", ",", "\n", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", "and", "not", "output_examples", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "input_file", ")", "\n", "examples", "=", "read_squad_examples", "(", "\n", "input_file", "=", "input_file", ",", "is_training", "=", "not", "evaluate", ",", "version_2_with_negative", "=", "args", ".", "version_2_with_negative", "\n", ")", "\n", "features", "=", "convert_examples_to_features", "(", "\n", "examples", "=", "examples", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "max_seq_length", "=", "args", ".", "max_seq_length", ",", "\n", "doc_stride", "=", "args", ".", "doc_stride", ",", "\n", "max_query_length", "=", "args", ".", "max_query_length", ",", "\n", "is_training", "=", "not", "evaluate", ",", "\n", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_cls_index", "=", "torch", ".", "tensor", "(", "[", "f", ".", "cls_index", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_p_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "p_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "if", "evaluate", ":", "\n", "        ", "all_example_index", "=", "torch", ".", "arange", "(", "all_input_ids", ".", "size", "(", "0", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "dataset", "=", "TensorDataset", "(", "\n", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_example_index", ",", "all_cls_index", ",", "all_p_mask", "\n", ")", "\n", "", "else", ":", "\n", "        ", "all_start_positions", "=", "torch", ".", "tensor", "(", "[", "f", ".", "start_position", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_end_positions", "=", "torch", ".", "tensor", "(", "[", "f", ".", "end_position", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "dataset", "=", "TensorDataset", "(", "\n", "all_input_ids", ",", "\n", "all_input_mask", ",", "\n", "all_segment_ids", ",", "\n", "all_start_positions", ",", "\n", "all_end_positions", ",", "\n", "all_cls_index", ",", "\n", "all_p_mask", ",", "\n", ")", "\n", "\n", "", "if", "output_examples", ":", "\n", "        ", "return", "dataset", ",", "examples", ",", "features", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.run_xxx.main": [[400, 717], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_xxx.set_seed", "parser.parse_args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "logger.info", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "torch.distributed.barrier", "run_xxx.load_and_cache_examples", "run_xxx.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "model_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "bool", "apex.amp.register_half_function", "os.makedirs", "hasattr", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_xxx.evaluate", "dict", "results.update", "ImportError", "torch.distributed.get_rank", "os.path.exists", "MODEL_CLASSES.keys", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "sorted", "dict.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.run_xxx.load_and_cache_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.train", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"SQuAD json for training. E.g., train-v1.1.json\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--predict_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"SQuAD json for predictions. E.g., dev-v1.1.json or test-v1.1.json\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name selected in the list: \"", "+", "\", \"", ".", "join", "(", "ALL_MODELS", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model checkpoints and predictions will be written.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--version_2_with_negative\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, the SQuAD examples contain some that do not have an answer.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--null_score_diff_threshold\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.0", ",", "\n", "help", "=", "\"If null_score - best_non_null is greater than the threshold predict null.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "384", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after WordPiece tokenization. Sequences \"", "\n", "\"longer than this will be truncated, and sequences shorter than this will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--doc_stride\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"When splitting up a long document into chunks, how much stride to take between chunks.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_query_length\"", ",", "\n", "default", "=", "64", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum number of tokens for the question. Questions longer than this will \"", "\n", "\"be truncated to this length.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Rul evaluation during training at each logging step.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--n_best_size\"", ",", "\n", "default", "=", "20", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The total number of n-best predictions to generate in the nbest_predictions.json output file.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_answer_length\"", ",", "\n", "default", "=", "30", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum length of an answer that can be generated. This is needed because the start \"", "\n", "\"and end predictions are not conditioned on one another.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--verbose_logging\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, all of the warnings related to data processing will be printed. \"", "\n", "\"A number of warnings are expected for a normal SQuAD evaluation.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether not to use CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"local_rank for distributed training on gpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"Can be used for distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"Can be used for distant debugging.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Before we do anything with models, we want to ensure that we get fp16 execution of torch.einsum if args.fp16 is set.", "\n", "# Otherwise it'll default to \"promote\" mode, and we'll get fp32 operations. Note that running `--fp16_opt_level=\"O2\"` will", "\n", "# remove the need for this code, but it is still valid.", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "apex", "\n", "\n", "apex", ".", "amp", ".", "register_half_function", "(", "torch", ",", "\"einsum\"", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "\n", "# Training", "\n", "", "", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "output_examples", "=", "False", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Save the trained model and the tokenizer", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Evaluation - we can ask to evaluate all the checkpoints (sub-directories) in a directory", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", "\n", ")", "\n", "logging", ".", "getLogger", "(", "\"transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce model loading logs", "\n", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "# Reload the model", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Evaluate", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "global_step", ")", "\n", "\n", "result", "=", "dict", "(", "(", "k", "+", "(", "\"_{}\"", ".", "format", "(", "global_step", ")", "if", "global_step", "else", "\"\"", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"Results: {}\"", ".", "format", "(", "results", ")", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.SquadExample.__init__": [[38, 55], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "qas_id", ",", "\n", "question_text", ",", "\n", "doc_tokens", ",", "\n", "orig_answer_text", "=", "None", ",", "\n", "start_position", "=", "None", ",", "\n", "end_position", "=", "None", ",", "\n", "is_impossible", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "qas_id", "=", "qas_id", "\n", "self", ".", "question_text", "=", "question_text", "\n", "self", ".", "doc_tokens", "=", "doc_tokens", "\n", "self", ".", "orig_answer_text", "=", "orig_answer_text", "\n", "self", ".", "start_position", "=", "start_position", "\n", "self", ".", "end_position", "=", "end_position", "\n", "self", ".", "is_impossible", "=", "is_impossible", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.SquadExample.__str__": [[56, 58], ["utils_xxx.SquadExample.__repr__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.modeling.utils_modeling.BiLinear.__repr__"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__repr__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.SquadExample.__repr__": [[59, 71], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "\"\"", "\n", "s", "+=", "\"qas_id: %s\"", "%", "(", "self", ".", "qas_id", ")", "\n", "s", "+=", "\", question_text: %s\"", "%", "(", "self", ".", "question_text", ")", "\n", "s", "+=", "\", doc_tokens: [%s]\"", "%", "(", "\" \"", ".", "join", "(", "self", ".", "doc_tokens", ")", ")", "\n", "if", "self", ".", "start_position", ":", "\n", "            ", "s", "+=", "\", start_position: %d\"", "%", "(", "self", ".", "start_position", ")", "\n", "", "if", "self", ".", "end_position", ":", "\n", "            ", "s", "+=", "\", end_position: %d\"", "%", "(", "self", ".", "end_position", ")", "\n", "", "if", "self", ".", "is_impossible", ":", "\n", "            ", "s", "+=", "\", is_impossible: %r\"", "%", "(", "self", ".", "is_impossible", ")", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.InputFeatures.__init__": [[76, 109], ["None"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "unique_id", ",", "\n", "example_index", ",", "\n", "doc_span_index", ",", "\n", "tokens", ",", "\n", "token_to_orig_map", ",", "\n", "token_is_max_context", ",", "\n", "input_ids", ",", "\n", "input_mask", ",", "\n", "segment_ids", ",", "\n", "cls_index", ",", "\n", "p_mask", ",", "\n", "paragraph_len", ",", "\n", "start_position", "=", "None", ",", "\n", "end_position", "=", "None", ",", "\n", "is_impossible", "=", "None", ",", "\n", ")", ":", "\n", "        ", "self", ".", "unique_id", "=", "unique_id", "\n", "self", ".", "example_index", "=", "example_index", "\n", "self", ".", "doc_span_index", "=", "doc_span_index", "\n", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "token_to_orig_map", "=", "token_to_orig_map", "\n", "self", ".", "token_is_max_context", "=", "token_is_max_context", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "cls_index", "=", "cls_index", "\n", "self", ".", "p_mask", "=", "p_mask", "\n", "self", ".", "paragraph_len", "=", "paragraph_len", "\n", "self", ".", "start_position", "=", "start_position", "\n", "self", ".", "end_position", "=", "end_position", "\n", "self", ".", "is_impossible", "=", "is_impossible", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.read_squad_examples": [[111, 185], ["open", "json.load", "ord", "utils_xxx.read_squad_examples.is_whitespace"], "function", ["None"], ["", "", "def", "read_squad_examples", "(", "input_file", ",", "is_training", ",", "version_2_with_negative", ")", ":", "\n", "    ", "\"\"\"Read a SQuAD json file into a list of SquadExample.\"\"\"", "\n", "with", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "        ", "input_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "\n", "", "def", "is_whitespace", "(", "c", ")", ":", "\n", "        ", "if", "c", "==", "\" \"", "or", "c", "==", "\"\\t\"", "or", "c", "==", "\"\\r\"", "or", "c", "==", "\"\\n\"", "or", "ord", "(", "c", ")", "==", "0x202F", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n", "", "examples", "=", "[", "]", "\n", "for", "entry", "in", "input_data", ":", "\n", "        ", "for", "paragraph", "in", "entry", "[", "\"paragraphs\"", "]", ":", "\n", "            ", "paragraph_text", "=", "paragraph", "[", "\"context\"", "]", "\n", "doc_tokens", "=", "[", "]", "\n", "char_to_word_offset", "=", "[", "]", "\n", "prev_is_whitespace", "=", "True", "\n", "for", "c", "in", "paragraph_text", ":", "\n", "                ", "if", "is_whitespace", "(", "c", ")", ":", "\n", "                    ", "prev_is_whitespace", "=", "True", "\n", "", "else", ":", "\n", "                    ", "if", "prev_is_whitespace", ":", "\n", "                        ", "doc_tokens", ".", "append", "(", "c", ")", "\n", "", "else", ":", "\n", "                        ", "doc_tokens", "[", "-", "1", "]", "+=", "c", "\n", "", "prev_is_whitespace", "=", "False", "\n", "", "char_to_word_offset", ".", "append", "(", "len", "(", "doc_tokens", ")", "-", "1", ")", "\n", "\n", "", "for", "qa", "in", "paragraph", "[", "\"qas\"", "]", ":", "\n", "                ", "qas_id", "=", "qa", "[", "\"id\"", "]", "\n", "question_text", "=", "qa", "[", "\"question\"", "]", "\n", "start_position", "=", "None", "\n", "end_position", "=", "None", "\n", "orig_answer_text", "=", "None", "\n", "is_impossible", "=", "False", "\n", "if", "is_training", ":", "\n", "                    ", "if", "version_2_with_negative", ":", "\n", "                        ", "is_impossible", "=", "qa", "[", "\"is_impossible\"", "]", "\n", "", "if", "(", "len", "(", "qa", "[", "\"answers\"", "]", ")", "!=", "1", ")", "and", "(", "not", "is_impossible", ")", ":", "\n", "                        ", "raise", "ValueError", "(", "\"For training, each question should have exactly 1 answer.\"", ")", "\n", "", "if", "not", "is_impossible", ":", "\n", "                        ", "answer", "=", "qa", "[", "\"answers\"", "]", "[", "0", "]", "\n", "orig_answer_text", "=", "answer", "[", "\"text\"", "]", "\n", "answer_offset", "=", "answer", "[", "\"answer_start\"", "]", "\n", "answer_length", "=", "len", "(", "orig_answer_text", ")", "\n", "start_position", "=", "char_to_word_offset", "[", "answer_offset", "]", "\n", "end_position", "=", "char_to_word_offset", "[", "answer_offset", "+", "answer_length", "-", "1", "]", "\n", "# Only add answers where the text can be exactly recovered from the", "\n", "# document. If this CAN'T happen it's likely due to weird Unicode", "\n", "# stuff so we will just skip the example.", "\n", "#", "\n", "# Note that this means for training mode, every example is NOT", "\n", "# guaranteed to be preserved.", "\n", "actual_text", "=", "\" \"", ".", "join", "(", "doc_tokens", "[", "start_position", ":", "(", "end_position", "+", "1", ")", "]", ")", "\n", "cleaned_answer_text", "=", "\" \"", ".", "join", "(", "whitespace_tokenize", "(", "orig_answer_text", ")", ")", "\n", "if", "actual_text", ".", "find", "(", "cleaned_answer_text", ")", "==", "-", "1", ":", "\n", "                            ", "logger", ".", "warning", "(", "\"Could not find answer: '%s' vs. '%s'\"", ",", "actual_text", ",", "cleaned_answer_text", ")", "\n", "continue", "\n", "", "", "else", ":", "\n", "                        ", "start_position", "=", "-", "1", "\n", "end_position", "=", "-", "1", "\n", "orig_answer_text", "=", "\"\"", "\n", "\n", "", "", "example", "=", "SquadExample", "(", "\n", "qas_id", "=", "qas_id", ",", "\n", "question_text", "=", "question_text", ",", "\n", "doc_tokens", "=", "doc_tokens", ",", "\n", "orig_answer_text", "=", "orig_answer_text", ",", "\n", "start_position", "=", "start_position", ",", "\n", "end_position", "=", "end_position", ",", "\n", "is_impossible", "=", "is_impossible", ",", "\n", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.convert_examples_to_features": [[187, 404], ["enumerate", "tokenizer.tokenize", "enumerate", "collections.namedtuple", "enumerate", "len", "orig_to_tok_index.append", "tokenizer.tokenize", "utils_xxx._improve_answer_span", "len", "doc_spans.append", "min", "tokens.append", "segment_ids.append", "p_mask.append", "range", "tokens.append", "segment_ids.append", "p_mask.append", "tokenizer.convert_tokens_to_ids", "features.append", "len", "tok_to_orig_index.append", "all_doc_tokens.append", "len", "len", "collections.namedtuple.", "len", "tokens.append", "segment_ids.append", "p_mask.append", "tokens.append", "segment_ids.append", "p_mask.append", "utils_xxx._check_is_max_context", "tokens.append", "segment_ids.append", "p_mask.append", "tokens.append", "segment_ids.append", "p_mask.append", "len", "len", "tokenizer.convert_tokens_to_ids.append", "input_mask.append", "segment_ids.append", "p_mask.append", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils_xxx.InputFeatures", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "len", "len", "len", "str", "str", "str", "token_to_orig_map.items", "token_is_max_context.items"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx._improve_answer_span", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx._check_is_max_context"], ["", "def", "convert_examples_to_features", "(", "\n", "examples", ",", "\n", "tokenizer", ",", "\n", "max_seq_length", ",", "\n", "doc_stride", ",", "\n", "max_query_length", ",", "\n", "is_training", ",", "\n", "cls_token_at_end", "=", "False", ",", "\n", "cls_token", "=", "\"[CLS]\"", ",", "\n", "sep_token", "=", "\"[SEP]\"", ",", "\n", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "\n", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "0", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"", "\n", "\n", "unique_id", "=", "1000000000", "\n", "# cnt_pos, cnt_neg = 0, 0", "\n", "# max_N, max_M = 1024, 1024", "\n", "# f = np.zeros((max_N, max_M), dtype=np.float32)", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "example_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "\n", "# if example_index % 100 == 0:", "\n", "#     logger.info('Converting %s/%s pos %s neg %s', example_index, len(examples), cnt_pos, cnt_neg)", "\n", "\n", "        ", "query_tokens", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "question_text", ")", "\n", "\n", "if", "len", "(", "query_tokens", ")", ">", "max_query_length", ":", "\n", "            ", "query_tokens", "=", "query_tokens", "[", "0", ":", "max_query_length", "]", "\n", "\n", "", "tok_to_orig_index", "=", "[", "]", "\n", "orig_to_tok_index", "=", "[", "]", "\n", "all_doc_tokens", "=", "[", "]", "\n", "for", "(", "i", ",", "token", ")", "in", "enumerate", "(", "example", ".", "doc_tokens", ")", ":", "\n", "            ", "orig_to_tok_index", ".", "append", "(", "len", "(", "all_doc_tokens", ")", ")", "\n", "sub_tokens", "=", "tokenizer", ".", "tokenize", "(", "token", ")", "\n", "for", "sub_token", "in", "sub_tokens", ":", "\n", "                ", "tok_to_orig_index", ".", "append", "(", "i", ")", "\n", "all_doc_tokens", ".", "append", "(", "sub_token", ")", "\n", "\n", "", "", "tok_start_position", "=", "None", "\n", "tok_end_position", "=", "None", "\n", "if", "is_training", "and", "example", ".", "is_impossible", ":", "\n", "            ", "tok_start_position", "=", "-", "1", "\n", "tok_end_position", "=", "-", "1", "\n", "", "if", "is_training", "and", "not", "example", ".", "is_impossible", ":", "\n", "            ", "tok_start_position", "=", "orig_to_tok_index", "[", "example", ".", "start_position", "]", "\n", "if", "example", ".", "end_position", "<", "len", "(", "example", ".", "doc_tokens", ")", "-", "1", ":", "\n", "                ", "tok_end_position", "=", "orig_to_tok_index", "[", "example", ".", "end_position", "+", "1", "]", "-", "1", "\n", "", "else", ":", "\n", "                ", "tok_end_position", "=", "len", "(", "all_doc_tokens", ")", "-", "1", "\n", "", "(", "tok_start_position", ",", "tok_end_position", ")", "=", "_improve_answer_span", "(", "\n", "all_doc_tokens", ",", "tok_start_position", ",", "tok_end_position", ",", "tokenizer", ",", "example", ".", "orig_answer_text", "\n", ")", "\n", "\n", "# The -3 accounts for [CLS], [SEP] and [SEP]", "\n", "", "max_tokens_for_doc", "=", "max_seq_length", "-", "len", "(", "query_tokens", ")", "-", "3", "\n", "\n", "# We can have documents that are longer than the maximum sequence length.", "\n", "# To deal with this we do a sliding window approach, where we take chunks", "\n", "# of the up to our max length with a stride of `doc_stride`.", "\n", "_DocSpan", "=", "collections", ".", "namedtuple", "(", "\"DocSpan\"", ",", "[", "\"start\"", ",", "\"length\"", "]", ")", "# pylint: disable=invalid-name", "\n", "doc_spans", "=", "[", "]", "\n", "start_offset", "=", "0", "\n", "while", "start_offset", "<", "len", "(", "all_doc_tokens", ")", ":", "\n", "            ", "length", "=", "len", "(", "all_doc_tokens", ")", "-", "start_offset", "\n", "if", "length", ">", "max_tokens_for_doc", ":", "\n", "                ", "length", "=", "max_tokens_for_doc", "\n", "", "doc_spans", ".", "append", "(", "_DocSpan", "(", "start", "=", "start_offset", ",", "length", "=", "length", ")", ")", "\n", "if", "start_offset", "+", "length", "==", "len", "(", "all_doc_tokens", ")", ":", "\n", "                ", "break", "\n", "", "start_offset", "+=", "min", "(", "length", ",", "doc_stride", ")", "\n", "\n", "", "for", "(", "doc_span_index", ",", "doc_span", ")", "in", "enumerate", "(", "doc_spans", ")", ":", "\n", "            ", "tokens", "=", "[", "]", "\n", "token_to_orig_map", "=", "{", "}", "\n", "token_is_max_context", "=", "{", "}", "\n", "segment_ids", "=", "[", "]", "\n", "\n", "# p_mask: mask with 1 for token than cannot be in the answer (0 for token which can be in an answer)", "\n", "# Original TF implem also keep the classification token (set to 0) (not sure why...)", "\n", "p_mask", "=", "[", "]", "\n", "\n", "# CLS token at the beginning", "\n", "if", "not", "cls_token_at_end", ":", "\n", "                ", "tokens", ".", "append", "(", "cls_token", ")", "\n", "segment_ids", ".", "append", "(", "cls_token_segment_id", ")", "\n", "p_mask", ".", "append", "(", "0", ")", "\n", "cls_index", "=", "0", "\n", "\n", "# Query", "\n", "", "for", "token", "in", "query_tokens", ":", "\n", "                ", "tokens", ".", "append", "(", "token", ")", "\n", "segment_ids", ".", "append", "(", "sequence_a_segment_id", ")", "\n", "p_mask", ".", "append", "(", "1", ")", "\n", "\n", "# SEP token", "\n", "", "tokens", ".", "append", "(", "sep_token", ")", "\n", "segment_ids", ".", "append", "(", "sequence_a_segment_id", ")", "\n", "p_mask", ".", "append", "(", "1", ")", "\n", "\n", "# Paragraph", "\n", "for", "i", "in", "range", "(", "doc_span", ".", "length", ")", ":", "\n", "                ", "split_token_index", "=", "doc_span", ".", "start", "+", "i", "\n", "token_to_orig_map", "[", "len", "(", "tokens", ")", "]", "=", "tok_to_orig_index", "[", "split_token_index", "]", "\n", "\n", "is_max_context", "=", "_check_is_max_context", "(", "doc_spans", ",", "doc_span_index", ",", "split_token_index", ")", "\n", "token_is_max_context", "[", "len", "(", "tokens", ")", "]", "=", "is_max_context", "\n", "tokens", ".", "append", "(", "all_doc_tokens", "[", "split_token_index", "]", ")", "\n", "segment_ids", ".", "append", "(", "sequence_b_segment_id", ")", "\n", "p_mask", ".", "append", "(", "0", ")", "\n", "", "paragraph_len", "=", "doc_span", ".", "length", "\n", "\n", "# SEP token", "\n", "tokens", ".", "append", "(", "sep_token", ")", "\n", "segment_ids", ".", "append", "(", "sequence_b_segment_id", ")", "\n", "p_mask", ".", "append", "(", "1", ")", "\n", "\n", "# CLS token at the end", "\n", "if", "cls_token_at_end", ":", "\n", "                ", "tokens", ".", "append", "(", "cls_token", ")", "\n", "segment_ids", ".", "append", "(", "cls_token_segment_id", ")", "\n", "p_mask", ".", "append", "(", "0", ")", "\n", "cls_index", "=", "len", "(", "tokens", ")", "-", "1", "# Index of classification token", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "while", "len", "(", "input_ids", ")", "<", "max_seq_length", ":", "\n", "                ", "input_ids", ".", "append", "(", "pad_token", ")", "\n", "input_mask", ".", "append", "(", "0", "if", "mask_padding_with_zero", "else", "1", ")", "\n", "segment_ids", ".", "append", "(", "pad_token_segment_id", ")", "\n", "p_mask", ".", "append", "(", "1", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "\n", "span_is_impossible", "=", "example", ".", "is_impossible", "\n", "start_position", "=", "None", "\n", "end_position", "=", "None", "\n", "if", "is_training", "and", "not", "span_is_impossible", ":", "\n", "# For training, if our document chunk does not contain an annotation", "\n", "# we throw it out, since there is nothing to predict.", "\n", "                ", "doc_start", "=", "doc_span", ".", "start", "\n", "doc_end", "=", "doc_span", ".", "start", "+", "doc_span", ".", "length", "-", "1", "\n", "out_of_span", "=", "False", "\n", "if", "not", "(", "tok_start_position", ">=", "doc_start", "and", "tok_end_position", "<=", "doc_end", ")", ":", "\n", "                    ", "out_of_span", "=", "True", "\n", "", "if", "out_of_span", ":", "\n", "                    ", "start_position", "=", "0", "\n", "end_position", "=", "0", "\n", "span_is_impossible", "=", "True", "\n", "", "else", ":", "\n", "                    ", "doc_offset", "=", "len", "(", "query_tokens", ")", "+", "2", "\n", "start_position", "=", "tok_start_position", "-", "doc_start", "+", "doc_offset", "\n", "end_position", "=", "tok_end_position", "-", "doc_start", "+", "doc_offset", "\n", "\n", "", "", "if", "is_training", "and", "span_is_impossible", ":", "\n", "                ", "start_position", "=", "cls_index", "\n", "end_position", "=", "cls_index", "\n", "\n", "", "if", "example_index", "<", "20", ":", "\n", "                ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"unique_id: %s\"", "%", "(", "unique_id", ")", ")", "\n", "logger", ".", "info", "(", "\"example_index: %s\"", "%", "(", "example_index", ")", ")", "\n", "logger", ".", "info", "(", "\"doc_span_index: %s\"", "%", "(", "doc_span_index", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "tokens", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"token_to_orig_map: %s\"", "%", "\" \"", ".", "join", "(", "[", "\"%d:%d\"", "%", "(", "x", ",", "y", ")", "for", "(", "x", ",", "y", ")", "in", "token_to_orig_map", ".", "items", "(", ")", "]", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\"token_is_max_context: %s\"", "\n", "%", "\" \"", ".", "join", "(", "[", "\"%d:%s\"", "%", "(", "x", ",", "y", ")", "for", "(", "x", ",", "y", ")", "in", "token_is_max_context", ".", "items", "(", ")", "]", ")", "\n", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "if", "is_training", "and", "span_is_impossible", ":", "\n", "                    ", "logger", ".", "info", "(", "\"impossible example\"", ")", "\n", "", "if", "is_training", "and", "not", "span_is_impossible", ":", "\n", "                    ", "answer_text", "=", "\" \"", ".", "join", "(", "tokens", "[", "start_position", ":", "(", "end_position", "+", "1", ")", "]", ")", "\n", "logger", ".", "info", "(", "\"start_position: %d\"", "%", "(", "start_position", ")", ")", "\n", "logger", ".", "info", "(", "\"end_position: %d\"", "%", "(", "end_position", ")", ")", "\n", "logger", ".", "info", "(", "\"answer: %s\"", "%", "(", "answer_text", ")", ")", "\n", "\n", "", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "\n", "unique_id", "=", "unique_id", ",", "\n", "example_index", "=", "example_index", ",", "\n", "doc_span_index", "=", "doc_span_index", ",", "\n", "tokens", "=", "tokens", ",", "\n", "token_to_orig_map", "=", "token_to_orig_map", ",", "\n", "token_is_max_context", "=", "token_is_max_context", ",", "\n", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "cls_index", "=", "cls_index", ",", "\n", "p_mask", "=", "p_mask", ",", "\n", "paragraph_len", "=", "paragraph_len", ",", "\n", "start_position", "=", "start_position", ",", "\n", "end_position", "=", "end_position", ",", "\n", "is_impossible", "=", "span_is_impossible", ",", "\n", ")", "\n", ")", "\n", "unique_id", "+=", "1", "\n", "\n", "", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx._improve_answer_span": [[406, 440], ["range", "tokenizer.tokenize", "range"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "_improve_answer_span", "(", "doc_tokens", ",", "input_start", ",", "input_end", ",", "tokenizer", ",", "orig_answer_text", ")", ":", "\n", "    ", "\"\"\"Returns tokenized answer spans that better match the annotated answer.\"\"\"", "\n", "\n", "# The SQuAD annotations are character based. We first project them to", "\n", "# whitespace-tokenized words. But then after WordPiece tokenization, we can", "\n", "# often find a \"better match\". For example:", "\n", "#", "\n", "#   Question: What year was John Smith born?", "\n", "#   Context: The leader was John Smith (1895-1943).", "\n", "#   Answer: 1895", "\n", "#", "\n", "# The original whitespace-tokenized answer will be \"(1895-1943).\". However", "\n", "# after tokenization, our tokens will be \"( 1895 - 1943 ) .\". So we can match", "\n", "# the exact answer, 1895.", "\n", "#", "\n", "# However, this is not always possible. Consider the following:", "\n", "#", "\n", "#   Question: What country is the top exporter of electornics?", "\n", "#   Context: The Japanese electronics industry is the lagest in the world.", "\n", "#   Answer: Japan", "\n", "#", "\n", "# In this case, the annotator chose \"Japan\" as a character sub-span of", "\n", "# the word \"Japanese\". Since our WordPiece tokenizer does not split", "\n", "# \"Japanese\", we just use \"Japanese\" as the annotation. This is fairly rare", "\n", "# in SQuAD, but does happen.", "\n", "tok_answer_text", "=", "\" \"", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "orig_answer_text", ")", ")", "\n", "\n", "for", "new_start", "in", "range", "(", "input_start", ",", "input_end", "+", "1", ")", ":", "\n", "        ", "for", "new_end", "in", "range", "(", "input_end", ",", "new_start", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "text_span", "=", "\" \"", ".", "join", "(", "doc_tokens", "[", "new_start", ":", "(", "new_end", "+", "1", ")", "]", ")", "\n", "if", "text_span", "==", "tok_answer_text", ":", "\n", "                ", "return", "(", "new_start", ",", "new_end", ")", "\n", "\n", "", "", "", "return", "(", "input_start", ",", "input_end", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx._check_is_max_context": [[442, 477], ["enumerate", "min"], "function", ["None"], ["", "def", "_check_is_max_context", "(", "doc_spans", ",", "cur_span_index", ",", "position", ")", ":", "\n", "    ", "\"\"\"Check if this is the 'max context' doc span for the token.\"\"\"", "\n", "\n", "# Because of the sliding window approach taken to scoring documents, a single", "\n", "# token can appear in multiple documents. E.g.", "\n", "#  Doc: the man went to the store and bought a gallon of milk", "\n", "#  Span A: the man went to the", "\n", "#  Span B: to the store and bought", "\n", "#  Span C: and bought a gallon of", "\n", "#  ...", "\n", "#", "\n", "# Now the word 'bought' will have two scores from spans B and C. We only", "\n", "# want to consider the score with \"maximum context\", which we define as", "\n", "# the *minimum* of its left and right context (the *sum* of left and", "\n", "# right context will always be the same, of course).", "\n", "#", "\n", "# In the example the maximum context for 'bought' would be span C since", "\n", "# it has 1 left context and 3 right context, while span B has 4 left context", "\n", "# and 0 right context.", "\n", "best_score", "=", "None", "\n", "best_span_index", "=", "None", "\n", "for", "(", "span_index", ",", "doc_span", ")", "in", "enumerate", "(", "doc_spans", ")", ":", "\n", "        ", "end", "=", "doc_span", ".", "start", "+", "doc_span", ".", "length", "-", "1", "\n", "if", "position", "<", "doc_span", ".", "start", ":", "\n", "            ", "continue", "\n", "", "if", "position", ">", "end", ":", "\n", "            ", "continue", "\n", "", "num_left_context", "=", "position", "-", "doc_span", ".", "start", "\n", "num_right_context", "=", "end", "-", "position", "\n", "score", "=", "min", "(", "num_left_context", ",", "num_right_context", ")", "+", "0.01", "*", "doc_span", ".", "length", "\n", "if", "best_score", "is", "None", "or", "score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "score", "\n", "best_span_index", "=", "span_index", "\n", "\n", "", "", "return", "cur_span_index", "==", "best_span_index", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.write_predictions": [[482, 675], ["logger.info", "logger.info", "collections.defaultdict", "collections.namedtuple", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "enumerate", "example_index_to_features[].append", "enumerate", "sorted", "collections.namedtuple", "utils_xxx._compute_softmax", "enumerate", "open", "writer.write", "open", "writer.write", "utils_xxx._get_best_indexes", "utils_xxx._get_best_indexes", "sorted.append", "nbest.append", "nbest.append", "len", "total_scores.append", "collections.OrderedDict", "nbest_json.append", "len", "open", "writer.write", "collections.namedtuple.", "len", "tok_text.strip.replace", "tok_text.strip.replace", "tok_text.strip.strip", "utils_xxx.get_final_text", "collections.namedtuple.", "nbest.append", "len", "nbest.insert", "collections.namedtuple.", "json.dumps", "json.dumps", "sorted.append", "tok_text.strip.split", "collections.namedtuple.", "collections.namedtuple.", "json.dumps", "len", "len", "feature.token_is_max_context.get", "collections.namedtuple."], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx._compute_softmax", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx._get_best_indexes", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx._get_best_indexes", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.get_final_text"], ["def", "write_predictions", "(", "\n", "all_examples", ",", "\n", "all_features", ",", "\n", "all_results", ",", "\n", "n_best_size", ",", "\n", "max_answer_length", ",", "\n", "do_lower_case", ",", "\n", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "\n", "output_null_log_odds_file", ",", "\n", "verbose_logging", ",", "\n", "version_2_with_negative", ",", "\n", "null_score_diff_threshold", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Write final predictions to the json file and log-odds of null if needed.\"\"\"", "\n", "logger", ".", "info", "(", "\"Writing predictions to: %s\"", "%", "(", "output_prediction_file", ")", ")", "\n", "logger", ".", "info", "(", "\"Writing nbest to: %s\"", "%", "(", "output_nbest_file", ")", ")", "\n", "\n", "example_index_to_features", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "feature", "in", "all_features", ":", "\n", "        ", "example_index_to_features", "[", "feature", ".", "example_index", "]", ".", "append", "(", "feature", ")", "\n", "\n", "", "unique_id_to_result", "=", "{", "}", "\n", "for", "result", "in", "all_results", ":", "\n", "        ", "unique_id_to_result", "[", "result", ".", "unique_id", "]", "=", "result", "\n", "\n", "", "_PrelimPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"PrelimPrediction\"", ",", "[", "\"feature_index\"", ",", "\"start_index\"", ",", "\"end_index\"", ",", "\"start_logit\"", ",", "\"end_logit\"", "]", "\n", ")", "\n", "\n", "all_predictions", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "all_nbest_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "scores_diff_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "\n", "for", "(", "example_index", ",", "example", ")", "in", "enumerate", "(", "all_examples", ")", ":", "\n", "        ", "features", "=", "example_index_to_features", "[", "example_index", "]", "\n", "\n", "prelim_predictions", "=", "[", "]", "\n", "# keep track of the minimum score of null start+end of position 0", "\n", "score_null", "=", "1000000", "# large and positive", "\n", "min_null_feature_index", "=", "0", "# the paragraph slice with min null score", "\n", "null_start_logit", "=", "0", "# the start logit at the slice with min null score", "\n", "null_end_logit", "=", "0", "# the end logit at the slice with min null score", "\n", "for", "(", "feature_index", ",", "feature", ")", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "result", "=", "unique_id_to_result", "[", "feature", ".", "unique_id", "]", "\n", "start_indexes", "=", "_get_best_indexes", "(", "result", ".", "start_logits", ",", "n_best_size", ")", "\n", "end_indexes", "=", "_get_best_indexes", "(", "result", ".", "end_logits", ",", "n_best_size", ")", "\n", "# if we could have irrelevant answers, get the min score of irrelevant", "\n", "if", "version_2_with_negative", ":", "\n", "                ", "feature_null_score", "=", "result", ".", "start_logits", "[", "0", "]", "+", "result", ".", "end_logits", "[", "0", "]", "\n", "if", "feature_null_score", "<", "score_null", ":", "\n", "                    ", "score_null", "=", "feature_null_score", "\n", "min_null_feature_index", "=", "feature_index", "\n", "null_start_logit", "=", "result", ".", "start_logits", "[", "0", "]", "\n", "null_end_logit", "=", "result", ".", "end_logits", "[", "0", "]", "\n", "", "", "for", "start_index", "in", "start_indexes", ":", "\n", "                ", "for", "end_index", "in", "end_indexes", ":", "\n", "# We could hypothetically create invalid predictions, e.g., predict", "\n", "# that the start of the span is in the question. We throw out all", "\n", "# invalid predictions.", "\n", "                    ", "if", "start_index", ">=", "len", "(", "feature", ".", "tokens", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", ">=", "len", "(", "feature", ".", "tokens", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "start_index", "not", "in", "feature", ".", "token_to_orig_map", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", "not", "in", "feature", ".", "token_to_orig_map", ":", "\n", "                        ", "continue", "\n", "", "if", "not", "feature", ".", "token_is_max_context", ".", "get", "(", "start_index", ",", "False", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", "<", "start_index", ":", "\n", "                        ", "continue", "\n", "", "length", "=", "end_index", "-", "start_index", "+", "1", "\n", "if", "length", ">", "max_answer_length", ":", "\n", "                        ", "continue", "\n", "", "prelim_predictions", ".", "append", "(", "\n", "_PrelimPrediction", "(", "\n", "feature_index", "=", "feature_index", ",", "\n", "start_index", "=", "start_index", ",", "\n", "end_index", "=", "end_index", ",", "\n", "start_logit", "=", "result", ".", "start_logits", "[", "start_index", "]", ",", "\n", "end_logit", "=", "result", ".", "end_logits", "[", "end_index", "]", ",", "\n", ")", "\n", ")", "\n", "", "", "", "if", "version_2_with_negative", ":", "\n", "            ", "prelim_predictions", ".", "append", "(", "\n", "_PrelimPrediction", "(", "\n", "feature_index", "=", "min_null_feature_index", ",", "\n", "start_index", "=", "0", ",", "\n", "end_index", "=", "0", ",", "\n", "start_logit", "=", "null_start_logit", ",", "\n", "end_logit", "=", "null_end_logit", ",", "\n", ")", "\n", ")", "\n", "", "prelim_predictions", "=", "sorted", "(", "prelim_predictions", ",", "key", "=", "lambda", "x", ":", "(", "x", ".", "start_logit", "+", "x", ".", "end_logit", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "_NbestPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"NbestPrediction\"", ",", "[", "\"text\"", ",", "\"start_logit\"", ",", "\"end_logit\"", "]", "\n", ")", "\n", "\n", "seen_predictions", "=", "{", "}", "\n", "nbest", "=", "[", "]", "\n", "for", "pred", "in", "prelim_predictions", ":", "\n", "            ", "if", "len", "(", "nbest", ")", ">=", "n_best_size", ":", "\n", "                ", "break", "\n", "", "feature", "=", "features", "[", "pred", ".", "feature_index", "]", "\n", "if", "pred", ".", "start_index", ">", "0", ":", "# this is a non-null prediction", "\n", "                ", "tok_tokens", "=", "feature", ".", "tokens", "[", "pred", ".", "start_index", ":", "(", "pred", ".", "end_index", "+", "1", ")", "]", "\n", "orig_doc_start", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "start_index", "]", "\n", "orig_doc_end", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "end_index", "]", "\n", "orig_tokens", "=", "example", ".", "doc_tokens", "[", "orig_doc_start", ":", "(", "orig_doc_end", "+", "1", ")", "]", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tok_tokens", ")", "\n", "\n", "# De-tokenize WordPieces that have been split off.", "\n", "tok_text", "=", "tok_text", ".", "replace", "(", "\" ##\"", ",", "\"\"", ")", "\n", "tok_text", "=", "tok_text", ".", "replace", "(", "\"##\"", ",", "\"\"", ")", "\n", "\n", "# Clean whitespace", "\n", "tok_text", "=", "tok_text", ".", "strip", "(", ")", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tok_text", ".", "split", "(", ")", ")", "\n", "orig_text", "=", "\" \"", ".", "join", "(", "orig_tokens", ")", "\n", "\n", "final_text", "=", "get_final_text", "(", "tok_text", ",", "orig_text", ",", "do_lower_case", ",", "verbose_logging", ")", "\n", "if", "final_text", "in", "seen_predictions", ":", "\n", "                    ", "continue", "\n", "\n", "", "seen_predictions", "[", "final_text", "]", "=", "True", "\n", "", "else", ":", "\n", "                ", "final_text", "=", "\"\"", "\n", "seen_predictions", "[", "final_text", "]", "=", "True", "\n", "\n", "", "nbest", ".", "append", "(", "_NbestPrediction", "(", "text", "=", "final_text", ",", "start_logit", "=", "pred", ".", "start_logit", ",", "end_logit", "=", "pred", ".", "end_logit", ")", ")", "\n", "# if we didn't include the empty option in the n-best, include it", "\n", "", "if", "version_2_with_negative", ":", "\n", "            ", "if", "\"\"", "not", "in", "seen_predictions", ":", "\n", "                ", "nbest", ".", "append", "(", "_NbestPrediction", "(", "text", "=", "\"\"", ",", "start_logit", "=", "null_start_logit", ",", "end_logit", "=", "null_end_logit", ")", ")", "\n", "\n", "# In very rare edge cases we could only have single null prediction.", "\n", "# So we just create a nonce prediction in this case to avoid failure.", "\n", "", "if", "len", "(", "nbest", ")", "==", "1", ":", "\n", "                ", "nbest", ".", "insert", "(", "0", ",", "_NbestPrediction", "(", "text", "=", "\"empty\"", ",", "start_logit", "=", "0.0", ",", "end_logit", "=", "0.0", ")", ")", "\n", "\n", "# In very rare edge cases we could have no valid predictions. So we", "\n", "# just create a nonce prediction in this case to avoid failure.", "\n", "", "", "if", "not", "nbest", ":", "\n", "            ", "nbest", ".", "append", "(", "_NbestPrediction", "(", "text", "=", "\"empty\"", ",", "start_logit", "=", "0.0", ",", "end_logit", "=", "0.0", ")", ")", "\n", "\n", "", "assert", "len", "(", "nbest", ")", ">=", "1", "\n", "\n", "total_scores", "=", "[", "]", "\n", "best_non_null_entry", "=", "None", "\n", "for", "entry", "in", "nbest", ":", "\n", "            ", "total_scores", ".", "append", "(", "entry", ".", "start_logit", "+", "entry", ".", "end_logit", ")", "\n", "if", "not", "best_non_null_entry", ":", "\n", "                ", "if", "entry", ".", "text", ":", "\n", "                    ", "best_non_null_entry", "=", "entry", "\n", "\n", "", "", "", "probs", "=", "_compute_softmax", "(", "total_scores", ")", "\n", "\n", "nbest_json", "=", "[", "]", "\n", "for", "(", "i", ",", "entry", ")", "in", "enumerate", "(", "nbest", ")", ":", "\n", "            ", "output", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "output", "[", "\"text\"", "]", "=", "entry", ".", "text", "\n", "output", "[", "\"probability\"", "]", "=", "probs", "[", "i", "]", "\n", "output", "[", "\"start_logit\"", "]", "=", "entry", ".", "start_logit", "\n", "output", "[", "\"end_logit\"", "]", "=", "entry", ".", "end_logit", "\n", "nbest_json", ".", "append", "(", "output", ")", "\n", "\n", "", "assert", "len", "(", "nbest_json", ")", ">=", "1", "\n", "\n", "if", "not", "version_2_with_negative", ":", "\n", "            ", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "nbest_json", "[", "0", "]", "[", "\"text\"", "]", "\n", "", "else", ":", "\n", "# predict \"\" iff the null score - the score of best non-null > threshold", "\n", "            ", "score_diff", "=", "score_null", "-", "best_non_null_entry", ".", "start_logit", "-", "(", "best_non_null_entry", ".", "end_logit", ")", "\n", "scores_diff_json", "[", "example", ".", "qas_id", "]", "=", "score_diff", "\n", "if", "score_diff", ">", "null_score_diff_threshold", ":", "\n", "                ", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "\"\"", "\n", "", "else", ":", "\n", "                ", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "best_non_null_entry", ".", "text", "\n", "", "", "all_nbest_json", "[", "example", ".", "qas_id", "]", "=", "nbest_json", "\n", "\n", "", "with", "open", "(", "output_prediction_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_predictions", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "with", "open", "(", "output_nbest_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_nbest_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "if", "version_2_with_negative", ":", "\n", "        ", "with", "open", "(", "output_null_log_odds_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "scores_diff_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "return", "all_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.write_predictions_extended": [[684, 879], ["collections.namedtuple", "collections.namedtuple", "logger.info", "collections.defaultdict", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "enumerate", "utils_squad_evaluate.make_qid_to_has_ans", "utils_squad_evaluate.get_raw_scores", "utils_squad_evaluate.find_all_best_thresh_v2", "example_index_to_features[].append", "enumerate", "sorted", "utils_xxx._compute_softmax", "enumerate", "open", "writer.write", "open", "writer.write", "open", "min", "range", "tokenizer.convert_tokens_to_string", "tok_text.strip.strip", "utils_xxx.get_final_text", "nbest.append", "nbest.append", "total_scores.append", "collections.OrderedDict", "nbest_json.append", "len", "open", "writer.write", "json.load", "utils_squad_evaluate.make_qid_to_has_ans.items", "utils_squad_evaluate.make_qid_to_has_ans.items", "range", "len", "tok_text.strip.split", "collections.namedtuple.", "collections.namedtuple.", "json.dumps", "json.dumps", "sorted.append", "json.dumps", "feature.token_is_max_context.get", "collections.namedtuple."], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.get_raw_scores", "home.repos.pwc.inspect_result.bcmi220_ggdp.metrics.squad_metrics.find_all_best_thresh_v2", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx._compute_softmax", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.convert_tokens_to_string", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.get_final_text"], ["def", "write_predictions_extended", "(", "\n", "all_examples", ",", "\n", "all_features", ",", "\n", "all_results", ",", "\n", "n_best_size", ",", "\n", "max_answer_length", ",", "\n", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "\n", "output_null_log_odds_file", ",", "\n", "orig_data_file", ",", "\n", "start_n_top", ",", "\n", "end_n_top", ",", "\n", "version_2_with_negative", ",", "\n", "tokenizer", ",", "\n", "verbose_logging", ",", "\n", ")", ":", "\n", "    ", "\"\"\" XLNet write prediction logic (more complex than Bert's).\n        Write final predictions to the json file and log-odds of null if needed.\n\n        Requires utils_squad_evaluate.py\n    \"\"\"", "\n", "_PrelimPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"PrelimPrediction\"", ",", "[", "\"feature_index\"", ",", "\"start_index\"", ",", "\"end_index\"", ",", "\"start_log_prob\"", ",", "\"end_log_prob\"", "]", "\n", ")", "\n", "\n", "_NbestPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"NbestPrediction\"", ",", "[", "\"text\"", ",", "\"start_log_prob\"", ",", "\"end_log_prob\"", "]", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\"Writing predictions to: %s\"", ",", "output_prediction_file", ")", "\n", "# logger.info(\"Writing nbest to: %s\" % (output_nbest_file))", "\n", "\n", "example_index_to_features", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "feature", "in", "all_features", ":", "\n", "        ", "example_index_to_features", "[", "feature", ".", "example_index", "]", ".", "append", "(", "feature", ")", "\n", "\n", "", "unique_id_to_result", "=", "{", "}", "\n", "for", "result", "in", "all_results", ":", "\n", "        ", "unique_id_to_result", "[", "result", ".", "unique_id", "]", "=", "result", "\n", "\n", "", "all_predictions", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "all_nbest_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "scores_diff_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "\n", "for", "(", "example_index", ",", "example", ")", "in", "enumerate", "(", "all_examples", ")", ":", "\n", "        ", "features", "=", "example_index_to_features", "[", "example_index", "]", "\n", "\n", "prelim_predictions", "=", "[", "]", "\n", "# keep track of the minimum score of null start+end of position 0", "\n", "score_null", "=", "1000000", "# large and positive", "\n", "\n", "for", "(", "feature_index", ",", "feature", ")", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "result", "=", "unique_id_to_result", "[", "feature", ".", "unique_id", "]", "\n", "\n", "cur_null_score", "=", "result", ".", "cls_logits", "\n", "\n", "# if we could have irrelevant answers, get the min score of irrelevant", "\n", "score_null", "=", "min", "(", "score_null", ",", "cur_null_score", ")", "\n", "\n", "for", "i", "in", "range", "(", "start_n_top", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "end_n_top", ")", ":", "\n", "                    ", "start_log_prob", "=", "result", ".", "start_top_log_probs", "[", "i", "]", "\n", "start_index", "=", "result", ".", "start_top_index", "[", "i", "]", "\n", "\n", "j_index", "=", "i", "*", "end_n_top", "+", "j", "\n", "\n", "end_log_prob", "=", "result", ".", "end_top_log_probs", "[", "j_index", "]", "\n", "end_index", "=", "result", ".", "end_top_index", "[", "j_index", "]", "\n", "\n", "# We could hypothetically create invalid predictions, e.g., predict", "\n", "# that the start of the span is in the question. We throw out all", "\n", "# invalid predictions.", "\n", "if", "start_index", ">=", "feature", ".", "paragraph_len", "-", "1", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", ">=", "feature", ".", "paragraph_len", "-", "1", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "feature", ".", "token_is_max_context", ".", "get", "(", "start_index", ",", "False", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", "<", "start_index", ":", "\n", "                        ", "continue", "\n", "", "length", "=", "end_index", "-", "start_index", "+", "1", "\n", "if", "length", ">", "max_answer_length", ":", "\n", "                        ", "continue", "\n", "\n", "", "prelim_predictions", ".", "append", "(", "\n", "_PrelimPrediction", "(", "\n", "feature_index", "=", "feature_index", ",", "\n", "start_index", "=", "start_index", ",", "\n", "end_index", "=", "end_index", ",", "\n", "start_log_prob", "=", "start_log_prob", ",", "\n", "end_log_prob", "=", "end_log_prob", ",", "\n", ")", "\n", ")", "\n", "\n", "", "", "", "prelim_predictions", "=", "sorted", "(", "\n", "prelim_predictions", ",", "key", "=", "lambda", "x", ":", "(", "x", ".", "start_log_prob", "+", "x", ".", "end_log_prob", ")", ",", "reverse", "=", "True", "\n", ")", "\n", "\n", "seen_predictions", "=", "{", "}", "\n", "nbest", "=", "[", "]", "\n", "for", "pred", "in", "prelim_predictions", ":", "\n", "            ", "if", "len", "(", "nbest", ")", ">=", "n_best_size", ":", "\n", "                ", "break", "\n", "", "feature", "=", "features", "[", "pred", ".", "feature_index", "]", "\n", "\n", "# XLNet un-tokenizer", "\n", "# Let's keep it simple for now and see if we need all this later.", "\n", "#", "\n", "# tok_start_to_orig_index = feature.tok_start_to_orig_index", "\n", "# tok_end_to_orig_index = feature.tok_end_to_orig_index", "\n", "# start_orig_pos = tok_start_to_orig_index[pred.start_index]", "\n", "# end_orig_pos = tok_end_to_orig_index[pred.end_index]", "\n", "# paragraph_text = example.paragraph_text", "\n", "# final_text = paragraph_text[start_orig_pos: end_orig_pos + 1].strip()", "\n", "\n", "# Previously used Bert untokenizer", "\n", "tok_tokens", "=", "feature", ".", "tokens", "[", "pred", ".", "start_index", ":", "(", "pred", ".", "end_index", "+", "1", ")", "]", "\n", "orig_doc_start", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "start_index", "]", "\n", "orig_doc_end", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "end_index", "]", "\n", "orig_tokens", "=", "example", ".", "doc_tokens", "[", "orig_doc_start", ":", "(", "orig_doc_end", "+", "1", ")", "]", "\n", "tok_text", "=", "tokenizer", ".", "convert_tokens_to_string", "(", "tok_tokens", ")", "\n", "\n", "# Clean whitespace", "\n", "tok_text", "=", "tok_text", ".", "strip", "(", ")", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tok_text", ".", "split", "(", ")", ")", "\n", "orig_text", "=", "\" \"", ".", "join", "(", "orig_tokens", ")", "\n", "\n", "final_text", "=", "get_final_text", "(", "tok_text", ",", "orig_text", ",", "tokenizer", ".", "do_lower_case", ",", "verbose_logging", ")", "\n", "\n", "if", "final_text", "in", "seen_predictions", ":", "\n", "                ", "continue", "\n", "\n", "", "seen_predictions", "[", "final_text", "]", "=", "True", "\n", "\n", "nbest", ".", "append", "(", "\n", "_NbestPrediction", "(", "text", "=", "final_text", ",", "start_log_prob", "=", "pred", ".", "start_log_prob", ",", "end_log_prob", "=", "pred", ".", "end_log_prob", ")", "\n", ")", "\n", "\n", "# In very rare edge cases we could have no valid predictions. So we", "\n", "# just create a nonce prediction in this case to avoid failure.", "\n", "", "if", "not", "nbest", ":", "\n", "            ", "nbest", ".", "append", "(", "_NbestPrediction", "(", "text", "=", "\"\"", ",", "start_log_prob", "=", "-", "1e6", ",", "end_log_prob", "=", "-", "1e6", ")", ")", "\n", "\n", "", "total_scores", "=", "[", "]", "\n", "best_non_null_entry", "=", "None", "\n", "for", "entry", "in", "nbest", ":", "\n", "            ", "total_scores", ".", "append", "(", "entry", ".", "start_log_prob", "+", "entry", ".", "end_log_prob", ")", "\n", "if", "not", "best_non_null_entry", ":", "\n", "                ", "best_non_null_entry", "=", "entry", "\n", "\n", "", "", "probs", "=", "_compute_softmax", "(", "total_scores", ")", "\n", "\n", "nbest_json", "=", "[", "]", "\n", "for", "(", "i", ",", "entry", ")", "in", "enumerate", "(", "nbest", ")", ":", "\n", "            ", "output", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "output", "[", "\"text\"", "]", "=", "entry", ".", "text", "\n", "output", "[", "\"probability\"", "]", "=", "probs", "[", "i", "]", "\n", "output", "[", "\"start_log_prob\"", "]", "=", "entry", ".", "start_log_prob", "\n", "output", "[", "\"end_log_prob\"", "]", "=", "entry", ".", "end_log_prob", "\n", "nbest_json", ".", "append", "(", "output", ")", "\n", "\n", "", "assert", "len", "(", "nbest_json", ")", ">=", "1", "\n", "assert", "best_non_null_entry", "is", "not", "None", "\n", "\n", "score_diff", "=", "score_null", "\n", "scores_diff_json", "[", "example", ".", "qas_id", "]", "=", "score_diff", "\n", "# note(zhiliny): always predict best_non_null_entry", "\n", "# and the evaluation script will search for the best threshold", "\n", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "best_non_null_entry", ".", "text", "\n", "\n", "all_nbest_json", "[", "example", ".", "qas_id", "]", "=", "nbest_json", "\n", "\n", "", "with", "open", "(", "output_prediction_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_predictions", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "with", "open", "(", "output_nbest_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_nbest_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "if", "version_2_with_negative", ":", "\n", "        ", "with", "open", "(", "output_null_log_odds_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "scores_diff_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "with", "open", "(", "orig_data_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "        ", "orig_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "\n", "", "qid_to_has_ans", "=", "make_qid_to_has_ans", "(", "orig_data", ")", "\n", "has_ans_qids", "=", "[", "k", "for", "k", ",", "v", "in", "qid_to_has_ans", ".", "items", "(", ")", "if", "v", "]", "\n", "no_ans_qids", "=", "[", "k", "for", "k", ",", "v", "in", "qid_to_has_ans", ".", "items", "(", ")", "if", "not", "v", "]", "\n", "exact_raw", ",", "f1_raw", "=", "get_raw_scores", "(", "orig_data", ",", "all_predictions", ")", "\n", "out_eval", "=", "{", "}", "\n", "\n", "find_all_best_thresh_v2", "(", "out_eval", ",", "all_predictions", ",", "exact_raw", ",", "f1_raw", ",", "scores_diff_json", ",", "qid_to_has_ans", ")", "\n", "\n", "return", "out_eval", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx.get_final_text": [[881, 973], ["transformers.tokenization_bert.BasicTokenizer", "tok_text.find", "utils_xxx.get_final_text._strip_spaces"], "function", ["None"], ["", "def", "get_final_text", "(", "pred_text", ",", "orig_text", ",", "do_lower_case", ",", "verbose_logging", "=", "False", ")", ":", "\n", "    ", "\"\"\"Project the tokenized prediction back to the original text.\"\"\"", "\n", "\n", "# When we created the data, we kept track of the alignment between original", "\n", "# (whitespace tokenized) tokens and our WordPiece tokenized tokens. So", "\n", "# now `orig_text` contains the span of our original text corresponding to the", "\n", "# span that we predicted.", "\n", "#", "\n", "# However, `orig_text` may contain extra characters that we don't want in", "\n", "# our prediction.", "\n", "#", "\n", "# For example, let's say:", "\n", "#   pred_text = steve smith", "\n", "#   orig_text = Steve Smith's", "\n", "#", "\n", "# We don't want to return `orig_text` because it contains the extra \"'s\".", "\n", "#", "\n", "# We don't want to return `pred_text` because it's already been normalized", "\n", "# (the SQuAD eval script also does punctuation stripping/lower casing but", "\n", "# our tokenizer does additional normalization like stripping accent", "\n", "# characters).", "\n", "#", "\n", "# What we really want to return is \"Steve Smith\".", "\n", "#", "\n", "# Therefore, we have to apply a semi-complicated alignment heuristic between", "\n", "# `pred_text` and `orig_text` to get a character-to-character alignment. This", "\n", "# can fail in certain cases in which case we just return `orig_text`.", "\n", "\n", "def", "_strip_spaces", "(", "text", ")", ":", "\n", "        ", "ns_chars", "=", "[", "]", "\n", "ns_to_s_map", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "(", "i", ",", "c", ")", "in", "enumerate", "(", "text", ")", ":", "\n", "            ", "if", "c", "==", "\" \"", ":", "\n", "                ", "continue", "\n", "", "ns_to_s_map", "[", "len", "(", "ns_chars", ")", "]", "=", "i", "\n", "ns_chars", ".", "append", "(", "c", ")", "\n", "", "ns_text", "=", "\"\"", ".", "join", "(", "ns_chars", ")", "\n", "return", "(", "ns_text", ",", "ns_to_s_map", ")", "\n", "\n", "# We first tokenize `orig_text`, strip whitespace from the result", "\n", "# and `pred_text`, and check if they are the same length. If they are", "\n", "# NOT the same length, the heuristic has failed. If they are the same", "\n", "# length, we assume the characters are one-to-one aligned.", "\n", "", "tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ")", "\n", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "orig_text", ")", ")", "\n", "\n", "start_position", "=", "tok_text", ".", "find", "(", "pred_text", ")", "\n", "if", "start_position", "==", "-", "1", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Unable to find text: '%s' in '%s'\"", "%", "(", "pred_text", ",", "orig_text", ")", ")", "\n", "", "return", "orig_text", "\n", "", "end_position", "=", "start_position", "+", "len", "(", "pred_text", ")", "-", "1", "\n", "\n", "(", "orig_ns_text", ",", "orig_ns_to_s_map", ")", "=", "_strip_spaces", "(", "orig_text", ")", "\n", "(", "tok_ns_text", ",", "tok_ns_to_s_map", ")", "=", "_strip_spaces", "(", "tok_text", ")", "\n", "\n", "if", "len", "(", "orig_ns_text", ")", "!=", "len", "(", "tok_ns_text", ")", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Length not equal after stripping spaces: '%s' vs '%s'\"", ",", "orig_ns_text", ",", "tok_ns_text", ")", "\n", "", "return", "orig_text", "\n", "\n", "# We then project the characters in `pred_text` back to `orig_text` using", "\n", "# the character-to-character alignment.", "\n", "", "tok_s_to_ns_map", "=", "{", "}", "\n", "for", "(", "i", ",", "tok_index", ")", "in", "tok_ns_to_s_map", ".", "items", "(", ")", ":", "\n", "        ", "tok_s_to_ns_map", "[", "tok_index", "]", "=", "i", "\n", "\n", "", "orig_start_position", "=", "None", "\n", "if", "start_position", "in", "tok_s_to_ns_map", ":", "\n", "        ", "ns_start_position", "=", "tok_s_to_ns_map", "[", "start_position", "]", "\n", "if", "ns_start_position", "in", "orig_ns_to_s_map", ":", "\n", "            ", "orig_start_position", "=", "orig_ns_to_s_map", "[", "ns_start_position", "]", "\n", "\n", "", "", "if", "orig_start_position", "is", "None", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Couldn't map start position\"", ")", "\n", "", "return", "orig_text", "\n", "\n", "", "orig_end_position", "=", "None", "\n", "if", "end_position", "in", "tok_s_to_ns_map", ":", "\n", "        ", "ns_end_position", "=", "tok_s_to_ns_map", "[", "end_position", "]", "\n", "if", "ns_end_position", "in", "orig_ns_to_s_map", ":", "\n", "            ", "orig_end_position", "=", "orig_ns_to_s_map", "[", "ns_end_position", "]", "\n", "\n", "", "", "if", "orig_end_position", "is", "None", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Couldn't map end position\"", ")", "\n", "", "return", "orig_text", "\n", "\n", "", "output_text", "=", "orig_text", "[", "orig_start_position", ":", "(", "orig_end_position", "+", "1", ")", "]", "\n", "return", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx._get_best_indexes": [[975, 985], ["sorted", "range", "enumerate", "len", "best_indexes.append"], "function", ["None"], ["", "def", "_get_best_indexes", "(", "logits", ",", "n_best_size", ")", ":", "\n", "    ", "\"\"\"Get the n-best logits from a list.\"\"\"", "\n", "index_and_score", "=", "sorted", "(", "enumerate", "(", "logits", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "best_indexes", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "index_and_score", ")", ")", ":", "\n", "        ", "if", "i", ">=", "n_best_size", ":", "\n", "            ", "break", "\n", "", "best_indexes", ".", "append", "(", "index_and_score", "[", "i", "]", "[", "0", "]", ")", "\n", "", "return", "best_indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_example_script.utils_xxx._compute_softmax": [[987, 1008], ["math.exp", "exp_scores.append", "probs.append"], "function", ["None"], ["", "def", "_compute_softmax", "(", "scores", ")", ":", "\n", "    ", "\"\"\"Compute softmax probability over raw logits.\"\"\"", "\n", "if", "not", "scores", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "max_score", "=", "None", "\n", "for", "score", "in", "scores", ":", "\n", "        ", "if", "max_score", "is", "None", "or", "score", ">", "max_score", ":", "\n", "            ", "max_score", "=", "score", "\n", "\n", "", "", "exp_scores", "=", "[", "]", "\n", "total_sum", "=", "0.0", "\n", "for", "score", "in", "scores", ":", "\n", "        ", "x", "=", "math", ".", "exp", "(", "score", "-", "max_score", ")", "\n", "exp_scores", ".", "append", "(", "x", ")", "\n", "total_sum", "+=", "x", "\n", "\n", "", "probs", "=", "[", "]", "\n", "for", "score", "in", "exp_scores", ":", "\n", "        ", "probs", ".", "append", "(", "score", "/", "total_sum", ")", "\n", "", "return", "probs", "\n", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.convert_xxx_original_tf_checkpoint_to_pytorch.convert_tf_checkpoint_to_pytorch": [[29, 41], ["transformers.XxxConfig.from_json_file", "print", "transformers.XxxForPreTraining", "transformers.load_tf_weights_in_xxx", "print", "torch.save", "transformers.XxxForPreTraining.state_dict", "str"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.load_tf_weights_in_xxx", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save"], ["def", "convert_tf_checkpoint_to_pytorch", "(", "tf_checkpoint_path", ",", "config_file", ",", "pytorch_dump_path", ")", ":", "\n", "# Initialise PyTorch model", "\n", "    ", "config", "=", "XxxConfig", ".", "from_json_file", "(", "config_file", ")", "\n", "print", "(", "\"Building PyTorch model from configuration: {}\"", ".", "format", "(", "str", "(", "config", ")", ")", ")", "\n", "model", "=", "XxxForPreTraining", "(", "config", ")", "\n", "\n", "# Load weights from tf checkpoint", "\n", "load_tf_weights_in_xxx", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", "\n", "\n", "# Save pytorch-model", "\n", "print", "(", "\"Save PyTorch model to {}\"", ".", "format", "(", "pytorch_dump_path", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pytorch_dump_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.__init__": [[93, 129], ["tokenization_utils.PreTrainedTokenizer.__init__", "tokenization_xxx.load_vocab", "os.path.isfile", "ValueError"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.load_vocab"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "do_lower_case", "=", "True", ",", "\n", "unk_token", "=", "\"[UNK]\"", ",", "\n", "sep_token", "=", "\"[SEP]\"", ",", "\n", "pad_token", "=", "\"[PAD]\"", ",", "\n", "cls_token", "=", "\"[CLS]\"", ",", "\n", "mask_token", "=", "\"[MASK]\"", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Constructs a XxxTokenizer.\n\n        Args:\n            **vocab_file**: Path to a one-wordpiece-per-line vocabulary file\n            **do_lower_case**: (`optional`) boolean (default True)\n                Whether to lower case the input\n                Only has an effect when do_basic_tokenize=True\n        \"\"\"", "\n", "super", "(", "XxxTokenizer", ",", "self", ")", ".", "__init__", "(", "\n", "unk_token", "=", "unk_token", ",", "\n", "sep_token", "=", "sep_token", ",", "\n", "pad_token", "=", "pad_token", ",", "\n", "cls_token", "=", "cls_token", ",", "\n", "mask_token", "=", "mask_token", ",", "\n", "**", "kwargs", "\n", ")", "\n", "self", ".", "max_len_single_sentence", "=", "self", ".", "max_len", "-", "2", "# take into account special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "self", ".", "max_len", "-", "3", "# take into account special tokens", "\n", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "vocab_file", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Can't find a vocabulary file at path '{}'. To load the vocabulary from a Google pretrained \"", "\n", "\"model use `tokenizer = XxxTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "vocab_file", ")", "\n", ")", "\n", "", "self", ".", "vocab", "=", "load_vocab", "(", "vocab_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.vocab_size": [[130, 133], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer._tokenize": [[134, 145], ["tokenization_xxx.XxxTokenizer.basic_tokenizer.tokenize", "tokenization_xxx.XxxTokenizer.wordpiece_tokenizer.tokenize", "tokenization_xxx.XxxTokenizer.wordpiece_tokenizer.tokenize", "tokenization_xxx.XxxTokenizer.append"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Take as input a string and return a list of strings (tokens) for words/sub-words\n        \"\"\"", "\n", "split_tokens", "=", "[", "]", "\n", "if", "self", ".", "do_basic_tokenize", ":", "\n", "            ", "for", "token", "in", "self", ".", "basic_tokenizer", ".", "tokenize", "(", "text", ",", "never_split", "=", "self", ".", "all_special_tokens", ")", ":", "\n", "                ", "for", "sub_token", "in", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", ":", "\n", "                    ", "split_tokens", ".", "append", "(", "sub_token", ")", "\n", "", "", "", "else", ":", "\n", "            ", "split_tokens", "=", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "text", ")", "\n", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer._convert_token_to_id": [[146, 149], ["tokenization_xxx.XxxTokenizer.vocab.get", "tokenization_xxx.XxxTokenizer.vocab.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "vocab", ".", "get", "(", "token", ",", "self", ".", "vocab", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer._convert_id_to_token": [[150, 153], ["tokenization_xxx.XxxTokenizer.ids_to_tokens.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"", "\n", "return", "self", ".", "ids_to_tokens", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.convert_tokens_to_string": [[154, 158], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "\" \"", ".", "join", "(", "tokens", ")", ".", "replace", "(", "\" ##\"", ",", "\"\"", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens": [[159, 172], ["None"], "methods", ["None"], ["", "def", "build_inputs_with_special_tokens", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n        by concatenating and adding special tokens.\n        A BERT sequence has the following format:\n            single sequence: [CLS] X [SEP]\n            pair of sequences: [CLS] A [SEP] B [SEP]\n        \"\"\"", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "[", "self", ".", "cls_token_id", "]", "+", "token_ids_0", "+", "[", "self", ".", "sep_token_id", "]", "\n", "", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "return", "cls", "+", "token_ids_0", "+", "sep", "+", "token_ids_1", "+", "sep", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.get_special_tokens_mask": [[173, 200], ["list", "ValueError", "map", "len", "len", "len"], "methods", ["None"], ["", "def", "get_special_tokens_mask", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ",", "already_has_special_tokens", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n\n        Args:\n            token_ids_0: list of ids (must not contain special tokens)\n            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n                for sequence pairs\n            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n                special tokens for the model\n\n        Returns:\n            A list of integers in the range [0, 1]: 1 for a special token, 0 for a sequence token.\n        \"\"\"", "\n", "\n", "if", "already_has_special_tokens", ":", "\n", "            ", "if", "token_ids_1", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"You should not supply a second sequence if the provided sequence of \"", "\n", "\"ids is already formated with special tokens for the model.\"", "\n", ")", "\n", "", "return", "list", "(", "map", "(", "lambda", "x", ":", "1", "if", "x", "in", "[", "self", ".", "sep_token_id", ",", "self", ".", "cls_token_id", "]", "else", "0", ",", "token_ids_0", ")", ")", "\n", "\n", "", "if", "token_ids_1", "is", "not", "None", ":", "\n", "            ", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_1", ")", ")", "+", "[", "1", "]", "\n", "", "return", "[", "1", "]", "+", "(", "[", "0", "]", "*", "len", "(", "token_ids_0", ")", ")", "+", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.create_token_type_ids_from_sequences": [[201, 215], ["len", "len", "len"], "methods", ["None"], ["", "def", "create_token_type_ids_from_sequences", "(", "self", ",", "token_ids_0", ",", "token_ids_1", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n        A BERT sequence pair mask has the following format:\n        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n        | first sequence    | second sequence\n\n        if token_ids_1 is None, only returns the first portion of the mask (0's).\n        \"\"\"", "\n", "sep", "=", "[", "self", ".", "sep_token_id", "]", "\n", "cls", "=", "[", "self", ".", "cls_token_id", "]", "\n", "if", "token_ids_1", "is", "None", ":", "\n", "            ", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "\n", "", "return", "len", "(", "cls", "+", "token_ids_0", "+", "sep", ")", "*", "[", "0", "]", "+", "len", "(", "token_ids_1", "+", "sep", ")", "*", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.save_vocabulary": [[216, 234], ["os.path.isdir", "os.path.join", "open", "sorted", "tokenization_xxx.XxxTokenizer.vocab.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "vocab_path", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary to a directory or file.\"\"\"", "\n", "index", "=", "0", "\n", "if", "os", ".", "path", ".", "isdir", "(", "vocab_path", ")", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "vocab_path", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "vocab_file", "=", "vocab_path", "\n", "", "with", "open", "(", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "for", "token", ",", "token_index", "in", "sorted", "(", "self", ".", "vocab", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"Saving vocabulary to {}: vocabulary indices are not consecutive.\"", "\n", "\" Please check that the vocabulary is not corrupted!\"", ".", "format", "(", "vocab_file", ")", "\n", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "token", "+", "\"\\n\"", ")", "\n", "index", "+=", "1", "\n", "", "", "return", "(", "vocab_file", ",", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.load_vocab": [[67, 76], ["collections.OrderedDict", "enumerate", "open", "reader.readlines", "token.rstrip.rstrip"], "function", ["None"], ["def", "load_vocab", "(", "vocab_file", ")", ":", "\n", "    ", "\"\"\"Loads a vocabulary file into a dictionary.\"\"\"", "\n", "vocab", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "with", "open", "(", "vocab_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "        ", "tokens", "=", "reader", ".", "readlines", "(", ")", "\n", "", "for", "index", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "        ", "token", "=", "token", ".", "rstrip", "(", "\"\\n\"", ")", "\n", "vocab", "[", "token", "]", "=", "index", "\n", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.configuration_xxx.XxxConfig.__init__": [[62, 99], ["configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "50257", ",", "\n", "n_positions", "=", "1024", ",", "\n", "n_ctx", "=", "1024", ",", "\n", "n_embd", "=", "768", ",", "\n", "n_layer", "=", "12", ",", "\n", "n_head", "=", "12", ",", "\n", "resid_pdrop", "=", "0.1", ",", "\n", "embd_pdrop", "=", "0.1", ",", "\n", "attn_pdrop", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "summary_type", "=", "\"cls_index\"", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", "XxxConfig", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "resid_pdrop", "=", "resid_pdrop", "\n", "self", ".", "embd_pdrop", "=", "embd_pdrop", "\n", "self", ".", "attn_pdrop", "=", "attn_pdrop", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.configuration_xxx.XxxConfig.max_position_embeddings": [[100, 103], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.configuration_xxx.XxxConfig.hidden_size": [[104, 107], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_embd", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.configuration_xxx.XxxConfig.num_attention_heads": [[108, 111], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.configuration_xxx.XxxConfig.num_hidden_layers": [[112, 115], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxLayer.__init__": [[71, 76], ["super().__init__", "TFXxxAttention", "TFXxxIntermediate", "TFXxxOutput"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXxxLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "self", ".", "attention", "=", "TFXxxAttention", "(", "config", ",", "name", "=", "\"attention\"", ")", "\n", "self", ".", "intermediate", "=", "TFXxxIntermediate", "(", "config", ",", "name", "=", "\"intermediate\"", ")", "\n", "self", ".", "transformer_output", "=", "TFXxxOutput", "(", "config", ",", "name", "=", "\"output\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxLayer.call": [[77, 86], ["modeling_tf_xxx.TFXxxLayer.attention", "modeling_tf_xxx.TFXxxLayer.intermediate", "modeling_tf_xxx.TFXxxLayer.transformer_output"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "training", "=", "False", ")", ":", "\n", "        ", "hidden_states", ",", "attention_mask", ",", "head_mask", "=", "inputs", "\n", "\n", "attention_outputs", "=", "self", ".", "attention", "(", "[", "hidden_states", ",", "attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "attention_output", "=", "attention_outputs", "[", "0", "]", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "transformer_output", "(", "[", "intermediate_output", ",", "attention_output", "]", ",", "training", "=", "training", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "attention_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxMainLayer.__init__": [[93, 95], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXxxMainLayer", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxMainLayer._resize_token_embeddings": [[96, 98], ["None"], "methods", ["None"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "raise", "NotImplementedError", "# Not implemented yet in the library fr TF 2.0 models", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxMainLayer._prune_heads": [[99, 101], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "raise", "NotImplementedError", "# Not implemented yet in the library fr TF 2.0 models", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxMainLayer.call": [[102, 168], ["isinstance", "tensorflow.cast", "modeling_tf_xxx.TFXxxMainLayer.embeddings", "modeling_tf_xxx.TFXxxMainLayer.encoder", "isinstance", "tensorflow.fill", "tensorflow.fill", "len", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "inputs.get", "modeling_tf_utils.shape_list", "modeling_tf_utils.shape_list", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.shape_list"], ["", "def", "call", "(", "\n", "self", ",", "inputs", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "training", "=", "False", "\n", ")", ":", "\n", "# We allow three types of multi-inputs:", "\n", "# - traditional keyword arguments in the call method", "\n", "# - all the arguments provided as a dict in the first positional argument of call", "\n", "# - all the arguments provided as a list/tuple (ordered) in the first positional argument of call", "\n", "# The last two options are useful to use the tf.keras fit() method.", "\n", "\n", "        ", "if", "isinstance", "(", "inputs", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "            ", "input_ids", "=", "inputs", "[", "0", "]", "\n", "attention_mask", "=", "inputs", "[", "1", "]", "if", "len", "(", "inputs", ")", ">", "1", "else", "attention_mask", "\n", "token_type_ids", "=", "inputs", "[", "2", "]", "if", "len", "(", "inputs", ")", ">", "2", "else", "token_type_ids", "\n", "position_ids", "=", "inputs", "[", "3", "]", "if", "len", "(", "inputs", ")", ">", "3", "else", "position_ids", "\n", "head_mask", "=", "inputs", "[", "4", "]", "if", "len", "(", "inputs", ")", ">", "4", "else", "head_mask", "\n", "assert", "len", "(", "inputs", ")", "<=", "5", ",", "\"Too many inputs.\"", "\n", "", "elif", "isinstance", "(", "inputs", ",", "dict", ")", ":", "\n", "            ", "input_ids", "=", "inputs", ".", "get", "(", "\"input_ids\"", ")", "\n", "attention_mask", "=", "inputs", ".", "get", "(", "\"attention_mask\"", ",", "attention_mask", ")", "\n", "token_type_ids", "=", "inputs", ".", "get", "(", "\"token_type_ids\"", ",", "token_type_ids", ")", "\n", "position_ids", "=", "inputs", ".", "get", "(", "\"position_ids\"", ",", "position_ids", ")", "\n", "head_mask", "=", "inputs", ".", "get", "(", "\"head_mask\"", ",", "head_mask", ")", "\n", "assert", "len", "(", "inputs", ")", "<=", "5", ",", "\"Too many inputs.\"", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "inputs", "\n", "\n", "", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "tf", ".", "fill", "(", "shape_list", "(", "input_ids", ")", ",", "1", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "tf", ".", "fill", "(", "shape_list", "(", "input_ids", ")", ",", "0", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "extended_attention_mask", "=", "attention_mask", "[", ":", ",", "tf", ".", "newaxis", ",", "tf", ".", "newaxis", ",", ":", "]", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "\n", "extended_attention_mask", "=", "tf", ".", "cast", "(", "extended_attention_mask", ",", "tf", ".", "float32", ")", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "num_hidden_layers", "\n", "# head_mask = tf.constant([0] * self.num_hidden_layers)", "\n", "\n", "##################################", "\n", "# Replace this with your model code", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "[", "embedding_output", ",", "extended_attention_mask", ",", "head_mask", "]", ",", "training", "=", "training", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "outputs", "=", "(", "sequence_output", ",", ")", "+", "encoder_outputs", "[", "1", ":", "]", "# add hidden_states and attentions if they are here", "\n", "\n", "return", "outputs", "# sequence_output, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxModel.__init__": [[309, 312], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xxx.TFXxxMainLayer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXxxModel", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "transformer", "=", "TFXxxMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxModel.call": [[313, 316], ["modeling_tf_xxx.TFXxxModel.transformer"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxForMaskedLM.__init__": [[350, 355], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xxx.TFXxxMainLayer", "TFXxxMLMHead"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXxxForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "transformer", "=", "TFXxxMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "self", ".", "mlm", "=", "TFXxxMLMHead", "(", "config", ",", "self", ".", "transformer", ".", "embeddings", ",", "name", "=", "\"mlm\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxForMaskedLM.call": [[356, 365], ["modeling_tf_xxx.TFXxxForMaskedLM.transformer", "modeling_tf_xxx.TFXxxForMaskedLM.mlm", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "mlm", "(", "sequence_output", ",", "training", "=", "kwargs", ".", "get", "(", "\"training\"", ",", "False", ")", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxForSequenceClassification.__init__": [[399, 407], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xxx.TFXxxMainLayer", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXxxForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "TFXxxMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"classifier\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxForSequenceClassification.call": [[409, 420], ["modeling_tf_xxx.TFXxxForSequenceClassification.transformer", "modeling_tf_xxx.TFXxxForSequenceClassification.dropout", "modeling_tf_xxx.TFXxxForSequenceClassification.classifier", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ",", "training", "=", "kwargs", ".", "get", "(", "\"training\"", ",", "False", ")", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxForTokenClassification.__init__": [[454, 462], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xxx.TFXxxMainLayer", "tensorflow.keras.layers.Dropout", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXxxForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "TFXxxMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "self", ".", "dropout", "=", "tf", ".", "keras", ".", "layers", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"classifier\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxForTokenClassification.call": [[464, 475], ["modeling_tf_xxx.TFXxxForTokenClassification.transformer", "modeling_tf_xxx.TFXxxForTokenClassification.dropout", "modeling_tf_xxx.TFXxxForTokenClassification.classifier", "kwargs.get"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ",", "training", "=", "kwargs", ".", "get", "(", "\"training\"", ",", "False", ")", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "return", "outputs", "# scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxForQuestionAnswering.__init__": [[511, 518], ["modeling_tf_utils.TFPreTrainedModel.__init__", "modeling_tf_xxx.TFXxxMainLayer", "tensorflow.keras.layers.Dense", "modeling_tf_utils.get_initializer"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_utils.get_initializer"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "TFXxxForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "TFXxxMainLayer", "(", "config", ",", "name", "=", "\"transformer\"", ")", "\n", "self", ".", "qa_outputs", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "\n", "config", ".", "num_labels", ",", "kernel_initializer", "=", "get_initializer", "(", "config", ".", "initializer_range", ")", ",", "name", "=", "\"qa_outputs\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_tf_xxx.TFXxxForQuestionAnswering.call": [[520, 533], ["modeling_tf_xxx.TFXxxForQuestionAnswering.transformer", "modeling_tf_xxx.TFXxxForQuestionAnswering.qa_outputs", "tensorflow.split", "tensorflow.squeeze", "tensorflow.squeeze"], "methods", ["None"], ["", "def", "call", "(", "self", ",", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "inputs", ",", "**", "kwargs", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "tf", ".", "split", "(", "logits", ",", "2", ",", "axis", "=", "-", "1", ")", "\n", "start_logits", "=", "tf", ".", "squeeze", "(", "start_logits", ",", "axis", "=", "-", "1", ")", "\n", "end_logits", "=", "tf", ".", "squeeze", "(", "end_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "\n", "return", "outputs", "# start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxLayer.__init__": [[140, 145], ["torch.nn.Module.__init__", "XxxAttention", "XxxIntermediate", "XxxOutput"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XxxLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "XxxAttention", "(", "config", ")", "\n", "self", ".", "intermediate", "=", "XxxIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "XxxOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxLayer.forward": [[146, 153], ["modeling_xxx.XxxLayer.attention", "modeling_xxx.XxxLayer.intermediate", "modeling_xxx.XxxLayer.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "attention_outputs", "=", "self", ".", "attention", "(", "hidden_states", ",", "attention_mask", ",", "head_mask", ")", "\n", "attention_output", "=", "attention_outputs", "[", "0", "]", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "outputs", "=", "(", "layer_output", ",", ")", "+", "attention_outputs", "[", "1", ":", "]", "# add attentions if we output them", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxPreTrainedModel._init_weights": [[184, 195], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "XxxLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.__init__": [[300, 308], ["modeling_utils.PreTrainedModel.__init__", "XxxEmbeddings", "XxxEncoder", "XxxPooler", "modeling_xxx.XxxModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XxxModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embeddings", "=", "XxxEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "XxxEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "XxxPooler", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.get_input_embeddings": [[309, 311], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.set_input_embeddings": [[312, 314], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "embeddings", ".", "word_embeddings", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel._prune_heads": [[315, 322], ["heads_to_prune.items", "modeling_xxx.XxxModel.encoder.layer[].attention.prune_heads"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n            See base class PreTrainedModel\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "encoder", ".", "layer", "[", "layer", "]", ".", "attention", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.forward": [[323, 392], ["torch.ones.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "modeling_xxx.XxxModel.embeddings", "modeling_xxx.XxxModel.encoder", "ValueError", "torch.ones", "torch.zeros", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "input_ids.size", "torch.ones.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "ValueError", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "inputs_embeds.size", "modeling_xxx.XxxModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_xxx.XxxModel.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", ")", ":", "\n", "        ", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones", "(", "input_shape", ",", "device", "=", "device", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]", "\n", "# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "num_hidden_layers", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "num_hidden_layers", "\n", "\n", "##################################", "\n", "# Replace this with your model code", "\n", "", "embedding_output", "=", "self", ".", "embeddings", "(", "\n", "input_ids", "=", "input_ids", ",", "position_ids", "=", "position_ids", ",", "token_type_ids", "=", "token_type_ids", ",", "inputs_embeds", "=", "inputs_embeds", "\n", ")", "\n", "encoder_outputs", "=", "self", ".", "encoder", "(", "embedding_output", ",", "extended_attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "sequence_output", "=", "encoder_outputs", "[", "0", "]", "\n", "outputs", "=", "(", "sequence_output", ",", ")", "+", "encoder_outputs", "[", "1", ":", "]", "# add hidden_states and attentions if they are here", "\n", "\n", "return", "outputs", "# sequence_output, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxForMaskedLM.__init__": [[428, 435], ["modeling_utils.PreTrainedModel.__init__", "modeling_xxx.XxxModel", "torch.nn.Linear", "modeling_xxx.XxxForMaskedLM.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XxxForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "transformer", "=", "XxxModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxForMaskedLM.get_output_embeddings": [[436, 438], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxForMaskedLM.forward": [[439, 469], ["modeling_xxx.XxxForMaskedLM.transformer", "modeling_xxx.XxxForMaskedLM.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_xxx.XxxForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "masked_lm_labels", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "cls", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (masked_lm_loss), prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxForSequenceClassification.__init__": [[509, 518], ["modeling_utils.PreTrainedModel.__init__", "modeling_xxx.XxxModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling_xxx.XxxForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XxxForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "XxxModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxForSequenceClassification.forward": [[519, 557], ["modeling_xxx.XxxForSequenceClassification.transformer", "modeling_xxx.XxxForSequenceClassification.dropout", "modeling_xxx.XxxForSequenceClassification.classifier", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_xxx.XxxForSequenceClassification.view", "labels.view", "modeling_xxx.XxxForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxForTokenClassification.__init__": [[595, 604], ["modeling_utils.PreTrainedModel.__init__", "modeling_xxx.XxxModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling_xxx.XxxForTokenClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XxxForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "XxxModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxForTokenClassification.forward": [[605, 644], ["modeling_xxx.XxxForTokenClassification.transformer", "modeling_xxx.XxxForTokenClassification.dropout", "modeling_xxx.XxxForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "modeling_xxx.XxxForTokenClassification.view", "labels.view", "modeling_xxx.XxxForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxForQuestionAnswering.__init__": [[694, 702], ["modeling_utils.PreTrainedModel.__init__", "modeling_xxx.XxxModel", "torch.nn.Linear", "modeling_xxx.XxxForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XxxForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "XxxModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxForQuestionAnswering.forward": [[703, 750], ["modeling_xxx.XxxForQuestionAnswering.transformer", "modeling_xxx.XxxForQuestionAnswering.qa_outputs", "modeling_xxx.XxxForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "\n", "end_positions", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.load_tf_weights_in_xxx": [[50, 117], ["os.path.abspath", "logger.info", "tf.train.list_variables", "zip", "logger.info", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "any", "logger.info", "torch.from_numpy", "logger.error", "logger.info", "re.fullmatch", "getattr", "re.split", "getattr", "len", "int", "np.transpose", "getattr", "getattr", "getattr", "getattr", "logger.info"], "function", ["None"], ["def", "load_tf_weights_in_xxx", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", ".", "split", "(", "\"/\"", ")", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "any", "(", "n", "in", "[", "\"adam_v\"", ",", "\"adam_m\"", ",", "\"global_step\"", "]", "for", "n", "in", "name", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r\"[A-Za-z]+_\\d+\"", ",", "m_name", ")", ":", "\n", "                ", "scope_names", "=", "re", ".", "split", "(", "r\"_(\\d+)\"", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "scope_names", "=", "[", "m_name", "]", "\n", "", "if", "scope_names", "[", "0", "]", "==", "\"kernel\"", "or", "scope_names", "[", "0", "]", "==", "\"gamma\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"output_bias\"", "or", "scope_names", "[", "0", "]", "==", "\"beta\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"bias\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"output_weights\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"squad\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"classifier\"", ")", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "", "if", "len", "(", "scope_names", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "scope_names", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "if", "m_name", "[", "-", "11", ":", "]", "==", "\"_embeddings\"", ":", "\n", "            ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "m_name", "==", "\"kernel\"", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xxx.XxxTokenizationTest.setUp": [[29, 50], ["super().setUp", "os.path.join", "open", "vocab_writer.write"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "XxxTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "vocab_tokens", "=", "[", "\n", "\"[UNK]\"", ",", "\n", "\"[CLS]\"", ",", "\n", "\"[SEP]\"", ",", "\n", "\"want\"", ",", "\n", "\"##want\"", ",", "\n", "\"##ed\"", ",", "\n", "\"wa\"", ",", "\n", "\"un\"", ",", "\n", "\"runn\"", ",", "\n", "\"##ing\"", ",", "\n", "\",\"", ",", "\n", "\"low\"", ",", "\n", "\"lowest\"", ",", "\n", "]", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "vocab_writer", ":", "\n", "            ", "vocab_writer", ".", "write", "(", "\"\"", ".", "join", "(", "[", "x", "+", "\"\\n\"", "for", "x", "in", "vocab_tokens", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xxx.XxxTokenizationTest.get_tokenizer": [[51, 53], ["transformers.tokenization_bert.XxxTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "XxxTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xxx.XxxTokenizationTest.get_input_output_texts": [[54, 58], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "\"UNwant\\u00E9d,running\"", "\n", "output_text", "=", "\"unwanted, running\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xxx.XxxTokenizationTest.test_full_tokenizer": [[59, 65], ["test_tokenization_xxx.XxxTokenizationTest.tokenizer_class", "test_tokenization_xxx.XxxTokenizationTest.tokenize", "test_tokenization_xxx.XxxTokenizationTest.assertListEqual", "test_tokenization_xxx.XxxTokenizationTest.assertListEqual", "test_tokenization_xxx.XxxTokenizationTest.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "tokenizer_class", "(", "self", ".", "vocab_file", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "\"UNwant\\u00E9d,running\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "\"un\"", ",", "\"##want\"", ",", "\"##ed\"", ",", "\",\"", ",", "\"runn\"", ",", "\"##ing\"", "]", ")", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ",", "[", "7", ",", "4", ",", "5", ",", "10", ",", "8", ",", "9", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xxx.XxxModelTest.setUp": [[243, 246], ["XxxModelTest.XxxModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "XxxModelTest", ".", "XxxModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "XxxConfig", ",", "hidden_size", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xxx.XxxModelTest.test_config": [[247, 249], ["test_modeling_xxx.XxxModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xxx.XxxModelTest.test_xxx_model": [[250, 253], ["test_modeling_xxx.XxxModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xxx.XxxModelTest.model_tester.create_and_check_xxx_model"], "methods", ["None"], ["", "def", "test_xxx_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xxx_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xxx.XxxModelTest.test_for_masked_lm": [[254, 257], ["test_modeling_xxx.XxxModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xxx.XxxModelTest.model_tester.create_and_check_xxx_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xxx_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xxx.XxxModelTest.test_for_question_answering": [[258, 261], ["test_modeling_xxx.XxxModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xxx.XxxModelTest.model_tester.create_and_check_xxx_for_question_answering"], "methods", ["None"], ["", "def", "test_for_question_answering", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xxx_for_question_answering", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xxx.XxxModelTest.test_for_sequence_classification": [[262, 265], ["test_modeling_xxx.XxxModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xxx.XxxModelTest.model_tester.create_and_check_xxx_for_sequence_classification"], "methods", ["None"], ["", "def", "test_for_sequence_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xxx_for_sequence_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xxx.XxxModelTest.test_for_token_classification": [[266, 269], ["test_modeling_xxx.XxxModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xxx.XxxModelTest.model_tester.create_and_check_xxx_for_token_classification"], "methods", ["None"], ["", "def", "test_for_token_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xxx_for_token_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xxx.XxxModelTest.test_model_from_pretrained": [[270, 275], ["list", "XxxModel.from_pretrained", "test_modeling_xxx.XxxModelTest.assertIsNotNone", "XXX_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "XXX_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "XxxModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xxx.TFXxxModelTest.setUp": [[222, 225], ["TFXxxModelTest.TFXxxModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFXxxModelTest", ".", "TFXxxModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "XxxConfig", ",", "hidden_size", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xxx.TFXxxModelTest.test_config": [[226, 228], ["test_modeling_tf_xxx.TFXxxModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xxx.TFXxxModelTest.test_xxx_model": [[229, 232], ["test_modeling_tf_xxx.TFXxxModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_xxx.TFXxxModelTest.model_tester.create_and_check_xxx_model"], "methods", ["None"], ["", "def", "test_xxx_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xxx_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xxx.TFXxxModelTest.test_for_masked_lm": [[233, 236], ["test_modeling_tf_xxx.TFXxxModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_xxx.TFXxxModelTest.model_tester.create_and_check_xxx_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xxx_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xxx.TFXxxModelTest.test_for_question_answering": [[237, 240], ["test_modeling_tf_xxx.TFXxxModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_xxx.TFXxxModelTest.model_tester.create_and_check_xxx_for_question_answering"], "methods", ["None"], ["", "def", "test_for_question_answering", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xxx_for_question_answering", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xxx.TFXxxModelTest.test_for_sequence_classification": [[241, 244], ["test_modeling_tf_xxx.TFXxxModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_xxx.TFXxxModelTest.model_tester.create_and_check_xxx_for_sequence_classification"], "methods", ["None"], ["", "def", "test_for_sequence_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xxx_for_sequence_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xxx.TFXxxModelTest.test_for_token_classification": [[245, 248], ["test_modeling_tf_xxx.TFXxxModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_xxx.TFXxxModelTest.model_tester.create_and_check_xxx_for_token_classification"], "methods", ["None"], ["", "def", "test_for_token_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xxx_for_token_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xxx.TFXxxModelTest.test_model_from_pretrained": [[249, 254], ["TFXxxModel.from_pretrained", "test_modeling_tf_xxx.TFXxxModelTest.assertIsNotNone"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "[", "\"xxx-base-uncased\"", "]", ":", "\n", "            ", "model", "=", "TFXxxModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_t5.T5TokenizationTest.setUp": [[33, 39], ["super().setUp", "transformers.tokenization_t5.T5Tokenizer", "transformers.tokenization_t5.T5Tokenizer.save_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.setUp", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "T5TokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# We have a SentencePiece fixture for testing", "\n", "tokenizer", "=", "T5Tokenizer", "(", "SAMPLE_VOCAB", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "self", ".", "tmpdirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_t5.T5TokenizationTest.get_tokenizer": [[40, 42], ["transformers.tokenization_t5.T5Tokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "T5Tokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_t5.T5TokenizationTest.get_input_output_texts": [[43, 47], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "\"This is a test\"", "\n", "output_text", "=", "\"This is a test\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_t5.T5TokenizationTest.test_full_tokenizer": [[48, 111], ["transformers.tokenization_t5.T5Tokenizer", "transformers.tokenization_t5.T5Tokenizer.tokenize", "test_tokenization_t5.T5TokenizationTest.assertListEqual", "test_tokenization_t5.T5TokenizationTest.assertListEqual", "transformers.tokenization_t5.T5Tokenizer.tokenize", "test_tokenization_t5.T5TokenizationTest.assertListEqual", "transformers.tokenization_t5.T5Tokenizer.convert_tokens_to_ids", "test_tokenization_t5.T5TokenizationTest.assertListEqual", "transformers.tokenization_t5.T5Tokenizer.convert_ids_to_tokens", "test_tokenization_t5.T5TokenizationTest.assertListEqual", "transformers.tokenization_t5.T5Tokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "T5Tokenizer", "(", "SAMPLE_VOCAB", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "\"This is a test\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "\"\u2581This\"", ",", "\"\u2581is\"", ",", "\"\u2581a\"", ",", "\"\u2581t\"", ",", "\"est\"", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ",", "[", "285", ",", "46", ",", "10", ",", "170", ",", "382", "]", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "\"I was born in 92000, and this is fals\u00e9.\"", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "tokens", ",", "\n", "[", "\n", "SPIECE_UNDERLINE", "+", "\"I\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"was\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"b\"", ",", "\n", "\"or\"", ",", "\n", "\"n\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"in\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"\"", ",", "\n", "\"9\"", ",", "\n", "\"2\"", ",", "\n", "\"0\"", ",", "\n", "\"0\"", ",", "\n", "\"0\"", ",", "\n", "\",\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"and\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"this\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"is\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"f\"", ",", "\n", "\"al\"", ",", "\n", "\"s\"", ",", "\n", "\"\u00e9\"", ",", "\n", "\".\"", ",", "\n", "]", ",", "\n", ")", "\n", "ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "self", ".", "assertListEqual", "(", "ids", ",", "[", "8", ",", "21", ",", "84", ",", "55", ",", "24", ",", "19", ",", "7", ",", "0", ",", "602", ",", "347", ",", "347", ",", "347", ",", "3", ",", "12", ",", "66", ",", "46", ",", "72", ",", "80", ",", "6", ",", "0", ",", "4", "]", ")", "\n", "\n", "back_tokens", "=", "tokenizer", ".", "convert_ids_to_tokens", "(", "ids", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "back_tokens", ",", "\n", "[", "\n", "SPIECE_UNDERLINE", "+", "\"I\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"was\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"b\"", ",", "\n", "\"or\"", ",", "\n", "\"n\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"in\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"\"", ",", "\n", "\"<unk>\"", ",", "\n", "\"2\"", ",", "\n", "\"0\"", ",", "\n", "\"0\"", ",", "\n", "\"0\"", ",", "\n", "\",\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"and\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"this\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"is\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"f\"", ",", "\n", "\"al\"", ",", "\n", "\"s\"", ",", "\n", "\"<unk>\"", ",", "\n", "\".\"", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.OptimizationTest.assertListAlmostEqual": [[64, 68], ["test_optimization.OptimizationTest.assertEqual", "zip", "len", "len", "test_optimization.OptimizationTest.assertAlmostEqual"], "methods", ["None"], ["    ", "def", "assertListAlmostEqual", "(", "self", ",", "list1", ",", "list2", ",", "tol", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "len", "(", "list1", ")", ",", "len", "(", "list2", ")", ")", "\n", "for", "a", ",", "b", "in", "zip", "(", "list1", ",", "list2", ")", ":", "\n", "            ", "self", ".", "assertAlmostEqual", "(", "a", ",", "b", ",", "delta", "=", "tol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.OptimizationTest.test_adam_w": [[69, 82], ["torch.tensor", "torch.tensor", "torch.nn.MSELoss", "AdamW", "range", "test_optimization.OptimizationTest.assertListAlmostEqual", "torch.nn.MSELoss.", "torch.nn.MSELoss.backward", "AdamW.step", "torch.tensor.grad.detach_", "torch.tensor.grad.zero_", "torch.tensor.tolist"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization_tf.OptimizationFTest.assertListAlmostEqual", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator.step"], ["", "", "def", "test_adam_w", "(", "self", ")", ":", "\n", "        ", "w", "=", "torch", ".", "tensor", "(", "[", "0.1", ",", "-", "0.2", ",", "-", "0.1", "]", ",", "requires_grad", "=", "True", ")", "\n", "target", "=", "torch", ".", "tensor", "(", "[", "0.4", ",", "0.2", ",", "-", "0.5", "]", ")", "\n", "criterion", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "\n", "# No warmup, constant schedule, no gradient clipping", "\n", "optimizer", "=", "AdamW", "(", "params", "=", "[", "w", "]", ",", "lr", "=", "2e-1", ",", "weight_decay", "=", "0.0", ")", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "            ", "loss", "=", "criterion", "(", "w", ",", "target", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "w", ".", "grad", ".", "detach_", "(", ")", "# No zero_grad() function on simple tensors. we do it ourselves.", "\n", "w", ".", "grad", ".", "zero_", "(", ")", "\n", "", "self", ".", "assertListAlmostEqual", "(", "w", ".", "tolist", "(", ")", ",", "[", "0.4", ",", "0.2", ",", "-", "0.5", "]", ",", "tol", "=", "1e-2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.ScheduleInitTest.assertListAlmostEqual": [[90, 94], ["test_optimization.ScheduleInitTest.assertEqual", "zip", "len", "len", "test_optimization.ScheduleInitTest.assertAlmostEqual"], "methods", ["None"], ["def", "assertListAlmostEqual", "(", "self", ",", "list1", ",", "list2", ",", "tol", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "len", "(", "list1", ")", ",", "len", "(", "list2", ")", ")", "\n", "for", "a", ",", "b", "in", "zip", "(", "list1", ",", "list2", ")", ":", "\n", "            ", "self", ".", "assertAlmostEqual", "(", "a", ",", "b", ",", "delta", "=", "tol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.ScheduleInitTest.test_constant_scheduler": [[95, 105], ["get_constant_schedule", "test_optimization.unwrap_schedule", "test_optimization.ScheduleInitTest.assertEqual", "test_optimization.ScheduleInitTest.assertListEqual", "get_constant_schedule", "test_optimization.unwrap_and_save_reload_schedule", "test_optimization.ScheduleInitTest.assertListEqual", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_constant_schedule", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.unwrap_schedule", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_constant_schedule", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.unwrap_and_save_reload_schedule"], ["", "", "def", "test_constant_scheduler", "(", "self", ")", ":", "\n", "        ", "scheduler", "=", "get_constant_schedule", "(", "self", ".", "optimizer", ")", "\n", "lrs", "=", "unwrap_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "expected_learning_rates", "=", "[", "10.0", "]", "*", "self", ".", "num_steps", "\n", "self", ".", "assertEqual", "(", "len", "(", "lrs", "[", "0", "]", ")", ",", "1", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "expected_learning_rates", ")", "\n", "\n", "scheduler", "=", "get_constant_schedule", "(", "self", ".", "optimizer", ")", "\n", "lrs_2", "=", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "[", "l", "[", "0", "]", "for", "l", "in", "lrs_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.ScheduleInitTest.test_warmup_constant_scheduler": [[106, 116], ["get_constant_schedule_with_warmup", "test_optimization.unwrap_schedule", "test_optimization.ScheduleInitTest.assertEqual", "test_optimization.ScheduleInitTest.assertListEqual", "get_constant_schedule_with_warmup", "test_optimization.unwrap_and_save_reload_schedule", "test_optimization.ScheduleInitTest.assertListEqual", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_constant_schedule_with_warmup", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.unwrap_schedule", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_constant_schedule_with_warmup", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.unwrap_and_save_reload_schedule"], ["", "def", "test_warmup_constant_scheduler", "(", "self", ")", ":", "\n", "        ", "scheduler", "=", "get_constant_schedule_with_warmup", "(", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "4", ")", "\n", "lrs", "=", "unwrap_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "expected_learning_rates", "=", "[", "2.5", ",", "5.0", ",", "7.5", ",", "10.0", ",", "10.0", ",", "10.0", ",", "10.0", ",", "10.0", ",", "10.0", ",", "10.0", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "lrs", "[", "0", "]", ")", ",", "1", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "expected_learning_rates", ")", "\n", "\n", "scheduler", "=", "get_constant_schedule_with_warmup", "(", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "4", ")", "\n", "lrs_2", "=", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "[", "l", "[", "0", "]", "for", "l", "in", "lrs_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.ScheduleInitTest.test_warmup_linear_scheduler": [[117, 127], ["get_linear_schedule_with_warmup", "test_optimization.unwrap_schedule", "test_optimization.ScheduleInitTest.assertEqual", "test_optimization.ScheduleInitTest.assertListEqual", "get_linear_schedule_with_warmup", "test_optimization.unwrap_and_save_reload_schedule", "test_optimization.ScheduleInitTest.assertListEqual", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_linear_schedule_with_warmup", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.unwrap_schedule", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_linear_schedule_with_warmup", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.unwrap_and_save_reload_schedule"], ["", "def", "test_warmup_linear_scheduler", "(", "self", ")", ":", "\n", "        ", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "2", ",", "num_training_steps", "=", "10", ")", "\n", "lrs", "=", "unwrap_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "expected_learning_rates", "=", "[", "5.0", ",", "10.0", ",", "8.75", ",", "7.5", ",", "6.25", ",", "5.0", ",", "3.75", ",", "2.5", ",", "1.25", ",", "0.0", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "lrs", "[", "0", "]", ")", ",", "1", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "expected_learning_rates", ")", "\n", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "2", ",", "num_training_steps", "=", "10", ")", "\n", "lrs_2", "=", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "[", "l", "[", "0", "]", "for", "l", "in", "lrs_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.ScheduleInitTest.test_warmup_cosine_scheduler": [[128, 138], ["get_cosine_schedule_with_warmup", "test_optimization.unwrap_schedule", "test_optimization.ScheduleInitTest.assertEqual", "test_optimization.ScheduleInitTest.assertListAlmostEqual", "get_cosine_schedule_with_warmup", "test_optimization.unwrap_and_save_reload_schedule", "test_optimization.ScheduleInitTest.assertListEqual", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_cosine_schedule_with_warmup", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.unwrap_schedule", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization_tf.OptimizationFTest.assertListAlmostEqual", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_cosine_schedule_with_warmup", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.unwrap_and_save_reload_schedule"], ["", "def", "test_warmup_cosine_scheduler", "(", "self", ")", ":", "\n", "        ", "scheduler", "=", "get_cosine_schedule_with_warmup", "(", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "2", ",", "num_training_steps", "=", "10", ")", "\n", "lrs", "=", "unwrap_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "expected_learning_rates", "=", "[", "5.0", ",", "10.0", ",", "9.61", ",", "8.53", ",", "6.91", ",", "5.0", ",", "3.08", ",", "1.46", ",", "0.38", ",", "0.0", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "lrs", "[", "0", "]", ")", ",", "1", ")", "\n", "self", ".", "assertListAlmostEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "expected_learning_rates", ",", "tol", "=", "1e-2", ")", "\n", "\n", "scheduler", "=", "get_cosine_schedule_with_warmup", "(", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "2", ",", "num_training_steps", "=", "10", ")", "\n", "lrs_2", "=", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "[", "l", "[", "0", "]", "for", "l", "in", "lrs_2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.ScheduleInitTest.test_warmup_cosine_hard_restart_scheduler": [[139, 153], ["get_cosine_with_hard_restarts_schedule_with_warmup", "test_optimization.unwrap_schedule", "test_optimization.ScheduleInitTest.assertEqual", "test_optimization.ScheduleInitTest.assertListAlmostEqual", "get_cosine_with_hard_restarts_schedule_with_warmup", "test_optimization.unwrap_and_save_reload_schedule", "test_optimization.ScheduleInitTest.assertListEqual", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_cosine_with_hard_restarts_schedule_with_warmup", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.unwrap_schedule", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization_tf.OptimizationFTest.assertListAlmostEqual", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_cosine_with_hard_restarts_schedule_with_warmup", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.unwrap_and_save_reload_schedule"], ["", "def", "test_warmup_cosine_hard_restart_scheduler", "(", "self", ")", ":", "\n", "        ", "scheduler", "=", "get_cosine_with_hard_restarts_schedule_with_warmup", "(", "\n", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "2", ",", "num_cycles", "=", "2", ",", "num_training_steps", "=", "10", "\n", ")", "\n", "lrs", "=", "unwrap_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "expected_learning_rates", "=", "[", "5.0", ",", "10.0", ",", "8.53", ",", "5.0", ",", "1.46", ",", "10.0", ",", "8.53", ",", "5.0", ",", "1.46", ",", "0.0", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "lrs", "[", "0", "]", ")", ",", "1", ")", "\n", "self", ".", "assertListAlmostEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "expected_learning_rates", ",", "tol", "=", "1e-2", ")", "\n", "\n", "scheduler", "=", "get_cosine_with_hard_restarts_schedule_with_warmup", "(", "\n", "self", ".", "optimizer", ",", "num_warmup_steps", "=", "2", ",", "num_cycles", "=", "2", ",", "num_training_steps", "=", "10", "\n", ")", "\n", "lrs_2", "=", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "self", ".", "num_steps", ")", "\n", "self", ".", "assertListEqual", "(", "[", "l", "[", "0", "]", "for", "l", "in", "lrs", "]", ",", "[", "l", "[", "0", "]", "for", "l", "in", "lrs_2", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.unwrap_schedule": [[39, 45], ["range", "scheduler.step", "lrs.append", "scheduler.get_lr"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator.step"], ["", "def", "unwrap_schedule", "(", "scheduler", ",", "num_steps", "=", "10", ")", ":", "\n", "    ", "lrs", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_steps", ")", ":", "\n", "        ", "scheduler", ".", "step", "(", ")", "\n", "lrs", ".", "append", "(", "scheduler", ".", "get_lr", "(", ")", ")", "\n", "", "return", "lrs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization.unwrap_and_save_reload_schedule": [[47, 60], ["range", "scheduler.step", "lrs.append", "scheduler.get_lr", "tempfile.TemporaryDirectory", "os.path.join", "torch.save", "torch.load", "scheduler.load_state_dict", "scheduler.state_dict"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator.step", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save"], ["", "def", "unwrap_and_save_reload_schedule", "(", "scheduler", ",", "num_steps", "=", "10", ")", ":", "\n", "    ", "lrs", "=", "[", "]", "\n", "for", "step", "in", "range", "(", "num_steps", ")", ":", "\n", "        ", "scheduler", ".", "step", "(", ")", "\n", "lrs", ".", "append", "(", "scheduler", ".", "get_lr", "(", ")", ")", "\n", "if", "step", "==", "num_steps", "//", "2", ":", "\n", "            ", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdirname", ":", "\n", "                ", "file_name", "=", "os", ".", "path", ".", "join", "(", "tmpdirname", ",", "\"schedule.bin\"", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "file_name", ")", "\n", "\n", "state_dict", "=", "torch", ".", "load", "(", "file_name", ")", "\n", "scheduler", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "", "", "return", "lrs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_hf_api.HfApiLoginTest.test_login_invalid": [[46, 49], ["test_hf_api.HfApiLoginTest.assertRaises", "test_hf_api.HfApiLoginTest._api.login"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.login"], ["    ", "def", "test_login_invalid", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "assertRaises", "(", "HTTPError", ")", ":", "\n", "            ", "self", ".", "_api", ".", "login", "(", "username", "=", "USER", ",", "password", "=", "\"fake\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_hf_api.HfApiLoginTest.test_login_valid": [[50, 53], ["test_hf_api.HfApiLoginTest._api.login", "test_hf_api.HfApiLoginTest.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.login"], ["", "", "def", "test_login_valid", "(", "self", ")", ":", "\n", "        ", "token", "=", "self", ".", "_api", ".", "login", "(", "username", "=", "USER", ",", "password", "=", "PASS", ")", "\n", "self", ".", "assertIsInstance", "(", "token", ",", "str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_hf_api.HfApiEndpointsTest.setUpClass": [[56, 62], ["cls._api.login"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.login"], ["    ", "@", "classmethod", "\n", "def", "setUpClass", "(", "cls", ")", ":", "\n", "        ", "\"\"\"\n        Share this valid token in all tests below.\n        \"\"\"", "\n", "cls", ".", "_token", "=", "cls", ".", "_api", ".", "login", "(", "username", "=", "USER", ",", "password", "=", "PASS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_hf_api.HfApiEndpointsTest.test_whoami": [[63, 66], ["test_hf_api.HfApiEndpointsTest._api.whoami", "test_hf_api.HfApiEndpointsTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.whoami"], ["", "def", "test_whoami", "(", "self", ")", ":", "\n", "        ", "user", "=", "self", ".", "_api", ".", "whoami", "(", "token", "=", "self", ".", "_token", ")", "\n", "self", ".", "assertEqual", "(", "user", ",", "USER", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_hf_api.HfApiEndpointsTest.test_presign": [[67, 72], ["test_hf_api.HfApiEndpointsTest._api.presign", "test_hf_api.HfApiEndpointsTest.assertIsInstance", "test_hf_api.HfApiEndpointsTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.presign"], ["", "def", "test_presign", "(", "self", ")", ":", "\n", "        ", "for", "FILE_KEY", ",", "FILE_PATH", "in", "FILES", ":", "\n", "            ", "urls", "=", "self", ".", "_api", ".", "presign", "(", "token", "=", "self", ".", "_token", ",", "filename", "=", "FILE_KEY", ")", "\n", "self", ".", "assertIsInstance", "(", "urls", ",", "PresignedUrl", ")", "\n", "self", ".", "assertEqual", "(", "urls", ".", "type", ",", "\"text/plain\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_hf_api.HfApiEndpointsTest.test_presign_and_upload": [[73, 81], ["test_hf_api.HfApiEndpointsTest._api.presign_and_upload", "test_hf_api.HfApiEndpointsTest.assertIsInstance", "requests.get", "test_hf_api.HfApiEndpointsTest.assertEqual", "open", "f.read"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.presign_and_upload"], ["", "", "def", "test_presign_and_upload", "(", "self", ")", ":", "\n", "        ", "for", "FILE_KEY", ",", "FILE_PATH", "in", "FILES", ":", "\n", "            ", "access_url", "=", "self", ".", "_api", ".", "presign_and_upload", "(", "token", "=", "self", ".", "_token", ",", "filename", "=", "FILE_KEY", ",", "filepath", "=", "FILE_PATH", ")", "\n", "self", ".", "assertIsInstance", "(", "access_url", ",", "str", ")", "\n", "with", "open", "(", "FILE_PATH", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "body", "=", "f", ".", "read", "(", ")", "\n", "", "r", "=", "requests", ".", "get", "(", "access_url", ")", "\n", "self", ".", "assertEqual", "(", "r", ".", "text", ",", "body", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_hf_api.HfApiEndpointsTest.test_list_objs": [[82, 88], ["test_hf_api.HfApiEndpointsTest._api.list_objs", "test_hf_api.HfApiEndpointsTest.assertIsInstance", "len", "test_hf_api.HfApiEndpointsTest.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfApi.list_objs"], ["", "", "def", "test_list_objs", "(", "self", ")", ":", "\n", "        ", "objs", "=", "self", ".", "_api", ".", "list_objs", "(", "token", "=", "self", ".", "_token", ")", "\n", "self", ".", "assertIsInstance", "(", "objs", ",", "list", ")", "\n", "if", "len", "(", "objs", ")", ">", "0", ":", "\n", "            ", "o", "=", "objs", "[", "-", "1", "]", "\n", "self", ".", "assertIsInstance", "(", "o", ",", "S3Obj", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_hf_api.HfFolderTest.test_token_workflow": [[91, 104], ["transformers.hf_api.HfFolder.save_token", "test_hf_api.HfFolderTest.assertEqual", "transformers.hf_api.HfFolder.delete_token", "transformers.hf_api.HfFolder.delete_token", "test_hf_api.HfFolderTest.assertEqual", "int", "transformers.hf_api.HfFolder.get_token", "transformers.hf_api.HfFolder.get_token", "time.time"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfFolder.save_token", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfFolder.delete_token", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfFolder.delete_token", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfFolder.get_token", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.HfFolder.get_token"], ["    ", "def", "test_token_workflow", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Test the whole token save/get/delete workflow,\n        with the desired behavior with respect to non-existent tokens.\n        \"\"\"", "\n", "token", "=", "\"token-{}\"", ".", "format", "(", "int", "(", "time", ".", "time", "(", ")", ")", ")", "\n", "HfFolder", ".", "save_token", "(", "token", ")", "\n", "self", ".", "assertEqual", "(", "HfFolder", ".", "get_token", "(", ")", ",", "token", ")", "\n", "HfFolder", ".", "delete_token", "(", ")", "\n", "HfFolder", ".", "delete_token", "(", ")", "\n", "# ^^ not an error, we test that the", "\n", "# second call does not fail.", "\n", "self", ".", "assertEqual", "(", "HfFolder", ".", "get_token", "(", ")", ",", "None", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_utils.TokenizerUtilsTest.check_tokenizer_from_pretrained": [[26, 38], ["list", "tokenizer_class.max_model_input_sizes.keys", "tokenizer_class.from_pretrained", "test_tokenization_utils.TokenizerUtilsTest.assertIsNotNone", "test_tokenization_utils.TokenizerUtilsTest.assertIsInstance", "test_tokenization_utils.TokenizerUtilsTest.assertIsInstance", "test_tokenization_utils.TokenizerUtilsTest.assertIsInstance", "tokenizer_class.from_pretrained.convert_tokens_to_ids", "test_tokenization_utils.TokenizerUtilsTest.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["    ", "def", "check_tokenizer_from_pretrained", "(", "self", ",", "tokenizer_class", ")", ":", "\n", "        ", "s3_models", "=", "list", "(", "tokenizer_class", ".", "max_model_input_sizes", ".", "keys", "(", ")", ")", "\n", "for", "model_name", "in", "s3_models", "[", ":", "1", "]", ":", "\n", "            ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "tokenizer", ")", "\n", "self", ".", "assertIsInstance", "(", "tokenizer", ",", "tokenizer_class", ")", "\n", "self", ".", "assertIsInstance", "(", "tokenizer", ",", "PreTrainedTokenizer", ")", "\n", "\n", "for", "special_tok", "in", "tokenizer", ".", "all_special_tokens", ":", "\n", "                ", "self", ".", "assertIsInstance", "(", "special_tok", ",", "str", ")", "\n", "special_tok_id", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "special_tok", ")", "\n", "self", ".", "assertIsInstance", "(", "special_tok_id", ",", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_utils.TokenizerUtilsTest.test_pretrained_tokenizers": [[39, 42], ["test_tokenization_utils.TokenizerUtilsTest.check_tokenizer_from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_utils.TokenizerUtilsTest.check_tokenizer_from_pretrained"], ["", "", "", "@", "slow", "\n", "def", "test_pretrained_tokenizers", "(", "self", ")", ":", "\n", "        ", "self", ".", "check_tokenizer_from_pretrained", "(", "GPT2Tokenizer", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MonoColumnInputTestCase._test_mono_column_pipeline": [[67, 92], ["test_pipelines.MonoColumnInputTestCase.assertIsNotNone", "nlp", "test_pipelines.MonoColumnInputTestCase.assertIsInstance", "test_pipelines.MonoColumnInputTestCase.assertIsInstance", "isinstance", "nlp", "test_pipelines.MonoColumnInputTestCase.assertIsInstance", "test_pipelines.MonoColumnInputTestCase.assertIsInstance", "isinstance", "test_pipelines.MonoColumnInputTestCase.assertRaises", "test_pipelines.MonoColumnInputTestCase.assertIn", "test_pipelines.MonoColumnInputTestCase.assertIn"], "methods", ["None"], ["    ", "def", "_test_mono_column_pipeline", "(", "self", ",", "nlp", ",", "valid_inputs", ":", "list", ",", "invalid_inputs", ":", "list", ",", "output_keys", ":", "Iterable", "[", "str", "]", ")", ":", "\n", "        ", "self", ".", "assertIsNotNone", "(", "nlp", ")", "\n", "\n", "mono_result", "=", "nlp", "(", "valid_inputs", "[", "0", "]", ")", "\n", "self", ".", "assertIsInstance", "(", "mono_result", ",", "list", ")", "\n", "self", ".", "assertIsInstance", "(", "mono_result", "[", "0", "]", ",", "(", "dict", ",", "list", ")", ")", "\n", "\n", "if", "isinstance", "(", "mono_result", "[", "0", "]", ",", "list", ")", ":", "\n", "            ", "mono_result", "=", "mono_result", "[", "0", "]", "\n", "\n", "", "for", "key", "in", "output_keys", ":", "\n", "            ", "self", ".", "assertIn", "(", "key", ",", "mono_result", "[", "0", "]", ")", "\n", "\n", "", "multi_result", "=", "nlp", "(", "valid_inputs", ")", "\n", "self", ".", "assertIsInstance", "(", "multi_result", ",", "list", ")", "\n", "self", ".", "assertIsInstance", "(", "multi_result", "[", "0", "]", ",", "(", "dict", ",", "list", ")", ")", "\n", "\n", "if", "isinstance", "(", "multi_result", "[", "0", "]", ",", "list", ")", ":", "\n", "            ", "multi_result", "=", "multi_result", "[", "0", "]", "\n", "\n", "", "for", "result", "in", "multi_result", ":", "\n", "            ", "for", "key", "in", "output_keys", ":", "\n", "                ", "self", ".", "assertIn", "(", "key", ",", "result", ")", "\n", "\n", "", "", "self", ".", "assertRaises", "(", "Exception", ",", "nlp", ",", "invalid_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MonoColumnInputTestCase.test_ner": [[93, 101], ["transformers.pipeline", "test_pipelines.MonoColumnInputTestCase._test_mono_column_pipeline"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.pipeline", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MonoColumnInputTestCase._test_mono_column_pipeline"], ["", "@", "require_torch", "\n", "def", "test_ner", "(", "self", ")", ":", "\n", "        ", "mandatory_keys", "=", "{", "\"entity\"", ",", "\"word\"", ",", "\"score\"", "}", "\n", "valid_inputs", "=", "[", "\"HuggingFace is solving NLP one commit at a time.\"", ",", "\"HuggingFace is based in New-York & Paris\"", "]", "\n", "invalid_inputs", "=", "[", "None", "]", "\n", "for", "tokenizer", ",", "model", ",", "config", "in", "NER_FINETUNED_MODELS", ":", "\n", "            ", "nlp", "=", "pipeline", "(", "task", "=", "\"ner\"", ",", "model", "=", "model", ",", "config", "=", "config", ",", "tokenizer", "=", "tokenizer", ")", "\n", "self", ".", "_test_mono_column_pipeline", "(", "nlp", ",", "valid_inputs", ",", "invalid_inputs", ",", "mandatory_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MonoColumnInputTestCase.test_tf_ner": [[102, 110], ["transformers.pipeline", "test_pipelines.MonoColumnInputTestCase._test_mono_column_pipeline"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.pipeline", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MonoColumnInputTestCase._test_mono_column_pipeline"], ["", "", "@", "require_tf", "\n", "def", "test_tf_ner", "(", "self", ")", ":", "\n", "        ", "mandatory_keys", "=", "{", "\"entity\"", ",", "\"word\"", ",", "\"score\"", "}", "\n", "valid_inputs", "=", "[", "\"HuggingFace is solving NLP one commit at a time.\"", ",", "\"HuggingFace is based in New-York & Paris\"", "]", "\n", "invalid_inputs", "=", "[", "None", "]", "\n", "for", "tokenizer", ",", "model", ",", "config", "in", "TF_NER_FINETUNED_MODELS", ":", "\n", "            ", "nlp", "=", "pipeline", "(", "task", "=", "\"ner\"", ",", "model", "=", "model", ",", "config", "=", "config", ",", "tokenizer", "=", "tokenizer", ")", "\n", "self", ".", "_test_mono_column_pipeline", "(", "nlp", ",", "valid_inputs", ",", "invalid_inputs", ",", "mandatory_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MonoColumnInputTestCase.test_sentiment_analysis": [[111, 119], ["transformers.pipeline", "test_pipelines.MonoColumnInputTestCase._test_mono_column_pipeline"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.pipeline", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MonoColumnInputTestCase._test_mono_column_pipeline"], ["", "", "@", "require_torch", "\n", "def", "test_sentiment_analysis", "(", "self", ")", ":", "\n", "        ", "mandatory_keys", "=", "{", "\"label\"", "}", "\n", "valid_inputs", "=", "[", "\"HuggingFace is solving NLP one commit at a time.\"", ",", "\"HuggingFace is based in New-York & Paris\"", "]", "\n", "invalid_inputs", "=", "[", "None", "]", "\n", "for", "tokenizer", ",", "model", ",", "config", "in", "TEXT_CLASSIF_FINETUNED_MODELS", ":", "\n", "            ", "nlp", "=", "pipeline", "(", "task", "=", "\"sentiment-analysis\"", ",", "model", "=", "model", ",", "config", "=", "config", ",", "tokenizer", "=", "tokenizer", ")", "\n", "self", ".", "_test_mono_column_pipeline", "(", "nlp", ",", "valid_inputs", ",", "invalid_inputs", ",", "mandatory_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MonoColumnInputTestCase.test_tf_sentiment_analysis": [[120, 128], ["transformers.pipeline", "test_pipelines.MonoColumnInputTestCase._test_mono_column_pipeline"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.pipeline", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MonoColumnInputTestCase._test_mono_column_pipeline"], ["", "", "@", "require_tf", "\n", "def", "test_tf_sentiment_analysis", "(", "self", ")", ":", "\n", "        ", "mandatory_keys", "=", "{", "\"label\"", "}", "\n", "valid_inputs", "=", "[", "\"HuggingFace is solving NLP one commit at a time.\"", ",", "\"HuggingFace is based in New-York & Paris\"", "]", "\n", "invalid_inputs", "=", "[", "None", "]", "\n", "for", "tokenizer", ",", "model", ",", "config", "in", "TF_TEXT_CLASSIF_FINETUNED_MODELS", ":", "\n", "            ", "nlp", "=", "pipeline", "(", "task", "=", "\"sentiment-analysis\"", ",", "model", "=", "model", ",", "config", "=", "config", ",", "tokenizer", "=", "tokenizer", ")", "\n", "self", ".", "_test_mono_column_pipeline", "(", "nlp", ",", "valid_inputs", ",", "invalid_inputs", ",", "mandatory_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MonoColumnInputTestCase.test_features_extraction": [[129, 136], ["transformers.pipeline", "test_pipelines.MonoColumnInputTestCase._test_mono_column_pipeline"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.pipeline", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MonoColumnInputTestCase._test_mono_column_pipeline"], ["", "", "@", "require_torch", "\n", "def", "test_features_extraction", "(", "self", ")", ":", "\n", "        ", "valid_inputs", "=", "[", "\"HuggingFace is solving NLP one commit at a time.\"", ",", "\"HuggingFace is based in New-York & Paris\"", "]", "\n", "invalid_inputs", "=", "[", "None", "]", "\n", "for", "tokenizer", ",", "model", ",", "config", "in", "FEATURE_EXTRACT_FINETUNED_MODELS", ":", "\n", "            ", "nlp", "=", "pipeline", "(", "task", "=", "\"sentiment-analysis\"", ",", "model", "=", "model", ",", "config", "=", "config", ",", "tokenizer", "=", "tokenizer", ")", "\n", "self", ".", "_test_mono_column_pipeline", "(", "nlp", ",", "valid_inputs", ",", "invalid_inputs", ",", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MonoColumnInputTestCase.test_tf_features_extraction": [[137, 144], ["transformers.pipeline", "test_pipelines.MonoColumnInputTestCase._test_mono_column_pipeline"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.pipeline", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MonoColumnInputTestCase._test_mono_column_pipeline"], ["", "", "@", "require_tf", "\n", "def", "test_tf_features_extraction", "(", "self", ")", ":", "\n", "        ", "valid_inputs", "=", "[", "\"HuggingFace is solving NLP one commit at a time.\"", ",", "\"HuggingFace is based in New-York & Paris\"", "]", "\n", "invalid_inputs", "=", "[", "None", "]", "\n", "for", "tokenizer", ",", "model", ",", "config", "in", "TF_FEATURE_EXTRACT_FINETUNED_MODELS", ":", "\n", "            ", "nlp", "=", "pipeline", "(", "task", "=", "\"sentiment-analysis\"", ",", "model", "=", "model", ",", "config", "=", "config", ",", "tokenizer", "=", "tokenizer", ")", "\n", "self", ".", "_test_mono_column_pipeline", "(", "nlp", ",", "valid_inputs", ",", "invalid_inputs", ",", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MultiColumnInputTestCase._test_multicolumn_pipeline": [[147, 166], ["test_pipelines.MultiColumnInputTestCase.assertIsNotNone", "nlp", "test_pipelines.MultiColumnInputTestCase.assertIsInstance", "nlp", "test_pipelines.MultiColumnInputTestCase.assertIsInstance", "test_pipelines.MultiColumnInputTestCase.assertIsInstance", "test_pipelines.MultiColumnInputTestCase.assertRaises", "test_pipelines.MultiColumnInputTestCase.assertRaises", "test_pipelines.MultiColumnInputTestCase.assertIn", "test_pipelines.MultiColumnInputTestCase.assertIn"], "methods", ["None"], ["    ", "def", "_test_multicolumn_pipeline", "(", "self", ",", "nlp", ",", "valid_inputs", ":", "list", ",", "invalid_inputs", ":", "list", ",", "output_keys", ":", "Iterable", "[", "str", "]", ")", ":", "\n", "        ", "self", ".", "assertIsNotNone", "(", "nlp", ")", "\n", "\n", "mono_result", "=", "nlp", "(", "valid_inputs", "[", "0", "]", ")", "\n", "self", ".", "assertIsInstance", "(", "mono_result", ",", "dict", ")", "\n", "\n", "for", "key", "in", "output_keys", ":", "\n", "            ", "self", ".", "assertIn", "(", "key", ",", "mono_result", ")", "\n", "\n", "", "multi_result", "=", "nlp", "(", "valid_inputs", ")", "\n", "self", ".", "assertIsInstance", "(", "multi_result", ",", "list", ")", "\n", "self", ".", "assertIsInstance", "(", "multi_result", "[", "0", "]", ",", "dict", ")", "\n", "\n", "for", "result", "in", "multi_result", ":", "\n", "            ", "for", "key", "in", "output_keys", ":", "\n", "                ", "self", ".", "assertIn", "(", "key", ",", "result", ")", "\n", "\n", "", "", "self", ".", "assertRaises", "(", "Exception", ",", "nlp", ",", "invalid_inputs", "[", "0", "]", ")", "\n", "self", ".", "assertRaises", "(", "Exception", ",", "nlp", ",", "invalid_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MultiColumnInputTestCase.test_question_answering": [[167, 187], ["transformers.pipeline", "test_pipelines.MultiColumnInputTestCase._test_multicolumn_pipeline"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.pipeline", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MultiColumnInputTestCase._test_multicolumn_pipeline"], ["", "@", "require_torch", "\n", "def", "test_question_answering", "(", "self", ")", ":", "\n", "        ", "mandatory_output_keys", "=", "{", "\"score\"", ",", "\"answer\"", ",", "\"start\"", ",", "\"end\"", "}", "\n", "valid_samples", "=", "[", "\n", "{", "\"question\"", ":", "\"Where was HuggingFace founded ?\"", ",", "\"context\"", ":", "\"HuggingFace was founded in Paris.\"", "}", ",", "\n", "{", "\n", "\"question\"", ":", "\"In what field is HuggingFace working ?\"", ",", "\n", "\"context\"", ":", "\"HuggingFace is a startup based in New-York founded in Paris which is trying to solve NLP.\"", ",", "\n", "}", ",", "\n", "]", "\n", "invalid_samples", "=", "[", "\n", "{", "\"question\"", ":", "\"\"", ",", "\"context\"", ":", "\"This is a test to try empty question edge case\"", "}", ",", "\n", "{", "\"question\"", ":", "None", ",", "\"context\"", ":", "\"This is a test to try empty question edge case\"", "}", ",", "\n", "{", "\"question\"", ":", "\"What is does with empty context ?\"", ",", "\"context\"", ":", "\"\"", "}", ",", "\n", "{", "\"question\"", ":", "\"What is does with empty context ?\"", ",", "\"context\"", ":", "None", "}", ",", "\n", "]", "\n", "\n", "for", "tokenizer", ",", "model", ",", "config", "in", "QA_FINETUNED_MODELS", ":", "\n", "            ", "nlp", "=", "pipeline", "(", "task", "=", "\"question-answering\"", ",", "model", "=", "model", ",", "config", "=", "config", ",", "tokenizer", "=", "tokenizer", ")", "\n", "self", ".", "_test_multicolumn_pipeline", "(", "nlp", ",", "valid_samples", ",", "invalid_samples", ",", "mandatory_output_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MultiColumnInputTestCase.test_tf_question_answering": [[188, 208], ["transformers.pipeline", "test_pipelines.MultiColumnInputTestCase._test_multicolumn_pipeline"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.pipeline", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_pipelines.MultiColumnInputTestCase._test_multicolumn_pipeline"], ["", "", "@", "require_tf", "\n", "def", "test_tf_question_answering", "(", "self", ")", ":", "\n", "        ", "mandatory_output_keys", "=", "{", "\"score\"", ",", "\"answer\"", ",", "\"start\"", ",", "\"end\"", "}", "\n", "valid_samples", "=", "[", "\n", "{", "\"question\"", ":", "\"Where was HuggingFace founded ?\"", ",", "\"context\"", ":", "\"HuggingFace was founded in Paris.\"", "}", ",", "\n", "{", "\n", "\"question\"", ":", "\"In what field is HuggingFace working ?\"", ",", "\n", "\"context\"", ":", "\"HuggingFace is a startup based in New-York founded in Paris which is trying to solve NLP.\"", ",", "\n", "}", ",", "\n", "]", "\n", "invalid_samples", "=", "[", "\n", "{", "\"question\"", ":", "\"\"", ",", "\"context\"", ":", "\"This is a test to try empty question edge case\"", "}", ",", "\n", "{", "\"question\"", ":", "None", ",", "\"context\"", ":", "\"This is a test to try empty question edge case\"", "}", ",", "\n", "{", "\"question\"", ":", "\"What is does with empty context ?\"", ",", "\"context\"", ":", "\"\"", "}", ",", "\n", "{", "\"question\"", ":", "\"What is does with empty context ?\"", ",", "\"context\"", ":", "None", "}", ",", "\n", "]", "\n", "\n", "for", "tokenizer", ",", "model", ",", "config", "in", "TF_QA_FINETUNED_MODELS", ":", "\n", "            ", "nlp", "=", "pipeline", "(", "task", "=", "\"question-answering\"", ",", "model", "=", "model", ",", "config", "=", "config", ",", "tokenizer", "=", "tokenizer", ")", "\n", "self", ".", "_test_multicolumn_pipeline", "(", "nlp", ",", "valid_samples", ",", "invalid_samples", ",", "mandatory_output_keys", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_openai.OpenAIGPTTokenizationTest.setUp": [[30, 66], ["super().setUp", "dict", "os.path.join", "os.path.join", "zip", "open", "fp.write", "open", "fp.write", "range", "json.dumps", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "OpenAIGPTTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt", "\n", "vocab", "=", "[", "\n", "\"l\"", ",", "\n", "\"o\"", ",", "\n", "\"w\"", ",", "\n", "\"e\"", ",", "\n", "\"r\"", ",", "\n", "\"s\"", ",", "\n", "\"t\"", ",", "\n", "\"i\"", ",", "\n", "\"d\"", ",", "\n", "\"n\"", ",", "\n", "\"w</w>\"", ",", "\n", "\"r</w>\"", ",", "\n", "\"t</w>\"", ",", "\n", "\"lo\"", ",", "\n", "\"low\"", ",", "\n", "\"er</w>\"", ",", "\n", "\"low</w>\"", ",", "\n", "\"lowest</w>\"", ",", "\n", "\"newer</w>\"", ",", "\n", "\"wider</w>\"", ",", "\n", "\"<unk>\"", ",", "\n", "]", "\n", "vocab_tokens", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "merges", "=", "[", "\"#version: 0.2\"", ",", "\"l o\"", ",", "\"lo w\"", ",", "\"e r</w>\"", ",", "\"\"", "]", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "self", ".", "merges_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "\"merges_file\"", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "json", ".", "dumps", "(", "vocab_tokens", ")", ")", "\n", "", "with", "open", "(", "self", ".", "merges_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "\"\\n\"", ".", "join", "(", "merges", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_openai.OpenAIGPTTokenizationTest.get_tokenizer": [[67, 69], ["transformers.tokenization_openai.OpenAIGPTTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "OpenAIGPTTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_openai.OpenAIGPTTokenizationTest.get_input_output_texts": [[70, 74], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "\"lower newer\"", "\n", "output_text", "=", "\"lower newer\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_openai.OpenAIGPTTokenizationTest.test_full_tokenizer": [[75, 86], ["transformers.tokenization_openai.OpenAIGPTTokenizer", "transformers.tokenization_openai.OpenAIGPTTokenizer.tokenize", "test_tokenization_openai.OpenAIGPTTokenizationTest.assertListEqual", "test_tokenization_openai.OpenAIGPTTokenizationTest.assertListEqual", "transformers.tokenization_openai.OpenAIGPTTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "OpenAIGPTTokenizer", "(", "self", ".", "vocab_file", ",", "self", ".", "merges_file", ")", "\n", "\n", "text", "=", "\"lower\"", "\n", "bpe_tokens", "=", "[", "\"low\"", ",", "\"er</w>\"", "]", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "bpe_tokens", ")", "\n", "\n", "input_tokens", "=", "tokens", "+", "[", "\"<unk>\"", "]", "\n", "input_bpe_tokens", "=", "[", "14", ",", "15", ",", "20", "]", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "input_tokens", ")", ",", "input_bpe_tokens", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_transfo_xl.TransfoXLModelTest.setUp": [[187, 190], ["TransfoXLModelTest.TransfoXLModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TransfoXLModelTest", ".", "TransfoXLModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "TransfoXLConfig", ",", "d_embed", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_transfo_xl.TransfoXLModelTest.test_config": [[191, 193], ["test_modeling_transfo_xl.TransfoXLModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_transfo_xl.TransfoXLModelTest.test_transfo_xl_model": [[194, 199], ["test_modeling_transfo_xl.TransfoXLModelTest.model_tester.set_seed", "test_modeling_transfo_xl.TransfoXLModelTest.model_tester.prepare_config_and_inputs", "test_modeling_transfo_xl.TransfoXLModelTest.model_tester.create_transfo_xl_model", "test_modeling_transfo_xl.TransfoXLModelTest.model_tester.check_transfo_xl_model_output"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed"], ["", "def", "test_transfo_xl_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "output_result", "=", "self", ".", "model_tester", ".", "create_transfo_xl_model", "(", "*", "config_and_inputs", ")", "\n", "self", ".", "model_tester", ".", "check_transfo_xl_model_output", "(", "output_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_transfo_xl.TransfoXLModelTest.test_transfo_xl_lm_head": [[200, 205], ["test_modeling_transfo_xl.TransfoXLModelTest.model_tester.set_seed", "test_modeling_transfo_xl.TransfoXLModelTest.model_tester.prepare_config_and_inputs", "test_modeling_transfo_xl.TransfoXLModelTest.model_tester.create_transfo_xl_lm_head", "test_modeling_transfo_xl.TransfoXLModelTest.model_tester.check_transfo_xl_lm_head_output"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed"], ["", "def", "test_transfo_xl_lm_head", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "output_result", "=", "self", ".", "model_tester", ".", "create_transfo_xl_lm_head", "(", "*", "config_and_inputs", ")", "\n", "self", ".", "model_tester", ".", "check_transfo_xl_lm_head_output", "(", "output_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_transfo_xl.TransfoXLModelTest.test_model_from_pretrained": [[206, 211], ["list", "TransfoXLModel.from_pretrained", "test_modeling_transfo_xl.TransfoXLModelTest.assertIsNotNone", "TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TransfoXLModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlnet.XLNetModelTest.setUp": [[459, 462], ["XLNetModelTest.XLNetModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "XLNetModelTest", ".", "XLNetModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "XLNetConfig", ",", "d_inner", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlnet.XLNetModelTest.test_config": [[463, 465], ["test_modeling_xlnet.XLNetModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlnet.XLNetModelTest.test_xlnet_base_model": [[466, 470], ["test_modeling_xlnet.XLNetModelTest.model_tester.set_seed", "test_modeling_xlnet.XLNetModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xlnet.XLNetModelTest.model_tester.create_and_check_xlnet_base_model"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed"], ["", "def", "test_xlnet_base_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_base_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlnet.XLNetModelTest.test_xlnet_base_model_with_att_output": [[471, 476], ["test_modeling_xlnet.XLNetModelTest.model_tester.set_seed", "test_modeling_xlnet.XLNetModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xlnet.XLNetModelTest.model_tester.create_and_check_xlnet_base_model_with_att_output"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed"], ["", "def", "test_xlnet_base_model_with_att_output", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "config_and_inputs", "[", "0", "]", ".", "output_attentions", "=", "True", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_base_model_with_att_output", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlnet.XLNetModelTest.test_xlnet_lm_head": [[477, 481], ["test_modeling_xlnet.XLNetModelTest.model_tester.set_seed", "test_modeling_xlnet.XLNetModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xlnet.XLNetModelTest.model_tester.create_and_check_xlnet_lm_head"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed"], ["", "def", "test_xlnet_lm_head", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlnet.XLNetModelTest.test_xlnet_sequence_classif": [[482, 486], ["test_modeling_xlnet.XLNetModelTest.model_tester.set_seed", "test_modeling_xlnet.XLNetModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xlnet.XLNetModelTest.model_tester.create_and_check_xlnet_sequence_classif"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed"], ["", "def", "test_xlnet_sequence_classif", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_sequence_classif", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlnet.XLNetModelTest.test_xlnet_token_classif": [[487, 491], ["test_modeling_xlnet.XLNetModelTest.model_tester.set_seed", "test_modeling_xlnet.XLNetModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xlnet.XLNetModelTest.model_tester.create_and_check_xlnet_token_classif"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed"], ["", "def", "test_xlnet_token_classif", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_token_classif", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlnet.XLNetModelTest.test_xlnet_qa": [[492, 496], ["test_modeling_xlnet.XLNetModelTest.model_tester.set_seed", "test_modeling_xlnet.XLNetModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xlnet.XLNetModelTest.model_tester.create_and_check_xlnet_qa"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed"], ["", "def", "test_xlnet_qa", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_qa", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlnet.XLNetModelTest.test_model_from_pretrained": [[497, 502], ["list", "XLNetModel.from_pretrained", "test_modeling_xlnet.XLNetModelTest.assertIsNotNone", "XLNET_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "XLNET_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "XLNetModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert_japanese.BertJapaneseTokenizationTest.setUp": [[37, 62], ["super().setUp", "os.path.join", "open", "vocab_writer.write"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "BertJapaneseTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "vocab_tokens", "=", "[", "\n", "\"[UNK]\"", ",", "\n", "\"[CLS]\"", ",", "\n", "\"[SEP]\"", ",", "\n", "\"\u3053\u3093\u306b\u3061\u306f\"", ",", "\n", "\"\u3053\u3093\"", ",", "\n", "\"\u306b\u3061\u306f\"", ",", "\n", "\"\u3070\u3093\u306f\"", ",", "\n", "\"##\u3053\u3093\"", ",", "\n", "\"##\u306b\u3061\u306f\"", ",", "\n", "\"##\u3070\u3093\u306f\"", ",", "\n", "\"\u4e16\u754c\"", ",", "\n", "\"##\u4e16\u754c\"", ",", "\n", "\"\u3001\"", ",", "\n", "\"##\u3001\"", ",", "\n", "\"\u3002\"", ",", "\n", "\"##\u3002\"", ",", "\n", "]", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "vocab_writer", ":", "\n", "            ", "vocab_writer", ".", "write", "(", "\"\"", ".", "join", "(", "[", "x", "+", "\"\\n\"", "for", "x", "in", "vocab_tokens", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert_japanese.BertJapaneseTokenizationTest.get_tokenizer": [[63, 65], ["transformers.tokenization_bert_japanese.BertJapaneseTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "BertJapaneseTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert_japanese.BertJapaneseTokenizationTest.get_input_output_texts": [[66, 70], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "\"\u3053\u3093\u306b\u3061\u306f\u3001\u4e16\u754c\u3002 \\n\u3053\u3093\u3070\u3093\u306f\u3001\u4e16\u754c\u3002\"", "\n", "output_text", "=", "\"\u3053\u3093\u306b\u3061\u306f \u3001 \u4e16\u754c \u3002 \u3053\u3093\u3070\u3093\u306f \u3001 \u4e16\u754c \u3002\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert_japanese.BertJapaneseTokenizationTest.test_full_tokenizer": [[71, 77], ["test_tokenization_bert_japanese.BertJapaneseTokenizationTest.tokenizer_class", "test_tokenization_bert_japanese.BertJapaneseTokenizationTest.tokenize", "test_tokenization_bert_japanese.BertJapaneseTokenizationTest.assertListEqual", "test_tokenization_bert_japanese.BertJapaneseTokenizationTest.assertListEqual", "test_tokenization_bert_japanese.BertJapaneseTokenizationTest.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "tokenizer_class", "(", "self", ".", "vocab_file", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "\"\u3053\u3093\u306b\u3061\u306f\u3001\u4e16\u754c\u3002\\n\u3053\u3093\u3070\u3093\u306f\u3001\u4e16\u754c\u3002\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "\"\u3053\u3093\u306b\u3061\u306f\"", ",", "\"\u3001\"", ",", "\"\u4e16\u754c\"", ",", "\"\u3002\"", ",", "\"\u3053\u3093\"", ",", "\"##\u3070\u3093\u306f\"", ",", "\"\u3001\"", ",", "\"\u4e16\u754c\"", ",", "\"\u3002\"", "]", ")", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ",", "[", "3", ",", "12", ",", "10", ",", "14", ",", "4", ",", "9", ",", "12", ",", "10", ",", "14", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert_japanese.BertJapaneseTokenizationTest.test_mecab_tokenizer": [[78, 84], ["transformers.tokenization_bert_japanese.MecabTokenizer", "test_tokenization_bert_japanese.BertJapaneseTokenizationTest.assertListEqual", "transformers.tokenization_bert_japanese.MecabTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "test_mecab_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "MecabTokenizer", "(", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "\" \\t\uff71\uff6f\uff8c\uff9f\uff99\u30b9\u30c8\u30a2\u3067iPhone\uff18 \u304c  \\n \u767a\u58f2\u3055\u308c\u305f\u3000\u3002  \"", ")", ",", "\n", "[", "\"\u30a2\u30c3\u30d7\u30eb\u30b9\u30c8\u30a2\"", ",", "\"\u3067\"", ",", "\"iPhone\"", ",", "\"8\"", ",", "\"\u304c\"", ",", "\"\u767a\u58f2\"", ",", "\"\u3055\"", ",", "\"\u308c\"", ",", "\"\u305f\"", ",", "\"\u3002\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert_japanese.BertJapaneseTokenizationTest.test_mecab_tokenizer_lower": [[86, 92], ["transformers.tokenization_bert_japanese.MecabTokenizer", "test_tokenization_bert_japanese.BertJapaneseTokenizationTest.assertListEqual", "transformers.tokenization_bert_japanese.MecabTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "test_mecab_tokenizer_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "MecabTokenizer", "(", "do_lower_case", "=", "True", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "\" \\t\uff71\uff6f\uff8c\uff9f\uff99\u30b9\u30c8\u30a2\u3067iPhone\uff18 \u304c  \\n \u767a\u58f2\u3055\u308c\u305f\u3000\u3002  \"", ")", ",", "\n", "[", "\"\u30a2\u30c3\u30d7\u30eb\u30b9\u30c8\u30a2\"", ",", "\"\u3067\"", ",", "\"iphone\"", ",", "\"8\"", ",", "\"\u304c\"", ",", "\"\u767a\u58f2\"", ",", "\"\u3055\"", ",", "\"\u308c\"", ",", "\"\u305f\"", ",", "\"\u3002\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert_japanese.BertJapaneseTokenizationTest.test_mecab_tokenizer_no_normalize": [[94, 100], ["transformers.tokenization_bert_japanese.MecabTokenizer", "test_tokenization_bert_japanese.BertJapaneseTokenizationTest.assertListEqual", "transformers.tokenization_bert_japanese.MecabTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "test_mecab_tokenizer_no_normalize", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "MecabTokenizer", "(", "normalize_text", "=", "False", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "\" \\t\uff71\uff6f\uff8c\uff9f\uff99\u30b9\u30c8\u30a2\u3067iPhone\uff18 \u304c  \\n \u767a\u58f2\u3055\u308c\u305f\u3000\u3002  \"", ")", ",", "\n", "[", "\"\uff71\uff6f\uff8c\uff9f\uff99\u30b9\u30c8\u30a2\"", ",", "\"\u3067\"", ",", "\"iPhone\"", ",", "\"\uff18\"", ",", "\"\u304c\"", ",", "\"\u767a\u58f2\"", ",", "\"\u3055\"", ",", "\"\u308c\"", ",", "\"\u305f\"", ",", "\"\u3000\"", ",", "\"\u3002\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert_japanese.BertJapaneseTokenizationTest.test_wordpiece_tokenizer": [[102, 117], ["enumerate", "transformers.tokenization_bert.WordpieceTokenizer", "test_tokenization_bert_japanese.BertJapaneseTokenizationTest.assertListEqual", "test_tokenization_bert_japanese.BertJapaneseTokenizationTest.assertListEqual", "test_tokenization_bert_japanese.BertJapaneseTokenizationTest.assertListEqual", "test_tokenization_bert_japanese.BertJapaneseTokenizationTest.assertListEqual", "transformers.tokenization_bert.WordpieceTokenizer.tokenize", "transformers.tokenization_bert.WordpieceTokenizer.tokenize", "transformers.tokenization_bert.WordpieceTokenizer.tokenize", "transformers.tokenization_bert.WordpieceTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "test_wordpiece_tokenizer", "(", "self", ")", ":", "\n", "        ", "vocab_tokens", "=", "[", "\"[UNK]\"", ",", "\"[CLS]\"", ",", "\"[SEP]\"", ",", "\"\u3053\u3093\u306b\u3061\u306f\"", ",", "\"\u3053\u3093\"", ",", "\"\u306b\u3061\u306f\"", "\"\u3070\u3093\u306f\"", ",", "\"##\u3053\u3093\"", ",", "\"##\u306b\u3061\u306f\"", ",", "\"##\u3070\u3093\u306f\"", "]", "\n", "\n", "vocab", "=", "{", "}", "\n", "for", "(", "i", ",", "token", ")", "in", "enumerate", "(", "vocab_tokens", ")", ":", "\n", "            ", "vocab", "[", "token", "]", "=", "i", "\n", "", "tokenizer", "=", "WordpieceTokenizer", "(", "vocab", "=", "vocab", ",", "unk_token", "=", "\"[UNK]\"", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "\"\"", ")", ",", "[", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "\"\u3053\u3093\u306b\u3061\u306f\"", ")", ",", "[", "\"\u3053\u3093\u306b\u3061\u306f\"", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "\"\u3053\u3093\u3070\u3093\u306f\"", ")", ",", "[", "\"\u3053\u3093\"", ",", "\"##\u3070\u3093\u306f\"", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "\"\u3053\u3093\u3070\u3093\u306f \u3053\u3093\u3070\u3093\u306b\u3061\u306f \u3053\u3093\u306b\u3061\u306f\"", ")", ",", "[", "\"\u3053\u3093\"", ",", "\"##\u3070\u3093\u306f\"", ",", "\"[UNK]\"", ",", "\"\u3053\u3093\u306b\u3061\u306f\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert_japanese.BertJapaneseTokenizationTest.test_sequence_builders": [[118, 131], ["test_tokenization_bert_japanese.BertJapaneseTokenizationTest.tokenizer_class.from_pretrained", "test_tokenization_bert_japanese.BertJapaneseTokenizationTest.encode", "test_tokenization_bert_japanese.BertJapaneseTokenizationTest.encode", "test_tokenization_bert_japanese.BertJapaneseTokenizationTest.build_inputs_with_special_tokens", "test_tokenization_bert_japanese.BertJapaneseTokenizationTest.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens"], ["", "@", "slow", "\n", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "tokenizer_class", ".", "from_pretrained", "(", "\"bert-base-japanese\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"\u3042\u308a\u304c\u3068\u3046\u3002\"", ",", "add_special_tokens", "=", "False", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"\u3069\u3046\u3044\u305f\u3057\u307e\u3057\u3066\u3002\"", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ",", "text_2", ")", "\n", "\n", "# 2 is for \"[CLS]\", 3 is for \"[SEP]\"", "\n", "assert", "encoded_sentence", "==", "[", "2", "]", "+", "text", "+", "[", "3", "]", "\n", "assert", "encoded_pair", "==", "[", "2", "]", "+", "text", "+", "[", "3", "]", "+", "text_2", "+", "[", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.setUp": [[137, 145], ["super().setUp", "os.path.join", "open", "vocab_writer.write"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "BertJapaneseCharacterTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "vocab_tokens", "=", "[", "\"[UNK]\"", ",", "\"[CLS]\"", ",", "\"[SEP]\"", ",", "\"\u3053\"", ",", "\"\u3093\"", ",", "\"\u306b\"", ",", "\"\u3061\"", ",", "\"\u306f\"", ",", "\"\u3070\"", ",", "\"\u4e16\"", ",", "\"\u754c\"", ",", "\"\u3001\"", ",", "\"\u3002\"", "]", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "vocab_writer", ":", "\n", "            ", "vocab_writer", ".", "write", "(", "\"\"", ".", "join", "(", "[", "x", "+", "\"\\n\"", "for", "x", "in", "vocab_tokens", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.get_tokenizer": [[146, 148], ["transformers.tokenization_bert_japanese.BertJapaneseTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "BertJapaneseTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "subword_tokenizer_type", "=", "\"character\"", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.get_input_output_texts": [[149, 153], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "\"\u3053\u3093\u306b\u3061\u306f\u3001\u4e16\u754c\u3002 \\n\u3053\u3093\u3070\u3093\u306f\u3001\u4e16\u754c\u3002\"", "\n", "output_text", "=", "\"\u3053 \u3093 \u306b \u3061 \u306f \u3001 \u4e16 \u754c \u3002 \u3053 \u3093 \u3070 \u3093 \u306f \u3001 \u4e16 \u754c \u3002\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.test_full_tokenizer": [[154, 163], ["test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.tokenizer_class", "test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.tokenize", "test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.assertListEqual", "test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.assertListEqual", "test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "tokenizer_class", "(", "self", ".", "vocab_file", ",", "subword_tokenizer_type", "=", "\"character\"", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "\"\u3053\u3093\u306b\u3061\u306f\u3001\u4e16\u754c\u3002 \\n\u3053\u3093\u3070\u3093\u306f\u3001\u4e16\u754c\u3002\"", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "tokens", ",", "[", "\"\u3053\"", ",", "\"\u3093\"", ",", "\"\u306b\"", ",", "\"\u3061\"", ",", "\"\u306f\"", ",", "\"\u3001\"", ",", "\"\u4e16\"", ",", "\"\u754c\"", ",", "\"\u3002\"", ",", "\"\u3053\"", ",", "\"\u3093\"", ",", "\"\u3070\"", ",", "\"\u3093\"", ",", "\"\u306f\"", ",", "\"\u3001\"", ",", "\"\u4e16\"", ",", "\"\u754c\"", ",", "\"\u3002\"", "]", "\n", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ",", "[", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "11", ",", "9", ",", "10", ",", "12", ",", "3", ",", "4", ",", "8", ",", "4", ",", "7", ",", "11", ",", "9", ",", "10", ",", "12", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.test_character_tokenizer": [[165, 178], ["enumerate", "transformers.tokenization_bert_japanese.CharacterTokenizer", "test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.assertListEqual", "test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.assertListEqual", "test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.assertListEqual", "transformers.tokenization_bert_japanese.CharacterTokenizer.tokenize", "transformers.tokenization_bert_japanese.CharacterTokenizer.tokenize", "transformers.tokenization_bert_japanese.CharacterTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "test_character_tokenizer", "(", "self", ")", ":", "\n", "        ", "vocab_tokens", "=", "[", "\"[UNK]\"", ",", "\"[CLS]\"", ",", "\"[SEP]\"", ",", "\"\u3053\"", ",", "\"\u3093\"", ",", "\"\u306b\"", ",", "\"\u3061\"", ",", "\"\u306f\"", ",", "\"\u3070\"", ",", "\"\u4e16\"", ",", "\"\u754c\"", "\"\u3001\"", ",", "\"\u3002\"", "]", "\n", "\n", "vocab", "=", "{", "}", "\n", "for", "(", "i", ",", "token", ")", "in", "enumerate", "(", "vocab_tokens", ")", ":", "\n", "            ", "vocab", "[", "token", "]", "=", "i", "\n", "", "tokenizer", "=", "CharacterTokenizer", "(", "vocab", "=", "vocab", ",", "unk_token", "=", "\"[UNK]\"", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "\"\"", ")", ",", "[", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "\"\u3053\u3093\u306b\u3061\u306f\"", ")", ",", "[", "\"\u3053\"", ",", "\"\u3093\"", ",", "\"\u306b\"", ",", "\"\u3061\"", ",", "\"\u306f\"", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "\"\u3053\u3093\u306b\u3061\u307b\"", ")", ",", "[", "\"\u3053\"", ",", "\"\u3093\"", ",", "\"\u306b\"", ",", "\"\u3061\"", ",", "\"[UNK]\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.test_sequence_builders": [[179, 192], ["test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.tokenizer_class.from_pretrained", "test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.encode", "test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.encode", "test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.build_inputs_with_special_tokens", "test_tokenization_bert_japanese.BertJapaneseCharacterTokenizationTest.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens"], ["", "@", "slow", "\n", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "tokenizer_class", ".", "from_pretrained", "(", "\"bert-base-japanese-char\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"\u3042\u308a\u304c\u3068\u3046\u3002\"", ",", "add_special_tokens", "=", "False", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"\u3069\u3046\u3044\u305f\u3057\u307e\u3057\u3066\u3002\"", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ",", "text_2", ")", "\n", "\n", "# 2 is for \"[CLS]\", 3 is for \"[SEP]\"", "\n", "assert", "encoded_sentence", "==", "[", "2", "]", "+", "text", "+", "[", "3", "]", "\n", "assert", "encoded_pair", "==", "[", "2", "]", "+", "text", "+", "[", "3", "]", "+", "text_2", "+", "[", "3", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlm.XLMModelTest.setUp": [[361, 364], ["XLMModelTest.XLMModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "XLMModelTest", ".", "XLMModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "XLMConfig", ",", "emb_dim", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlm.XLMModelTest.test_config": [[365, 367], ["test_modeling_xlm.XLMModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlm.XLMModelTest.test_xlm_model": [[368, 371], ["test_modeling_xlm.XLMModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xlm.XLMModelTest.model_tester.create_and_check_xlm_model"], "methods", ["None"], ["", "def", "test_xlm_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlm.XLMModelTest.test_xlm_lm_head": [[372, 375], ["test_modeling_xlm.XLMModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xlm.XLMModelTest.model_tester.create_and_check_xlm_lm_head"], "methods", ["None"], ["", "def", "test_xlm_lm_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlm.XLMModelTest.test_xlm_simple_qa": [[376, 379], ["test_modeling_xlm.XLMModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xlm.XLMModelTest.model_tester.create_and_check_xlm_simple_qa"], "methods", ["None"], ["", "def", "test_xlm_simple_qa", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_simple_qa", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlm.XLMModelTest.test_xlm_qa": [[380, 383], ["test_modeling_xlm.XLMModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xlm.XLMModelTest.model_tester.create_and_check_xlm_qa"], "methods", ["None"], ["", "def", "test_xlm_qa", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_qa", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlm.XLMModelTest.test_xlm_sequence_classif": [[384, 387], ["test_modeling_xlm.XLMModelTest.model_tester.prepare_config_and_inputs", "test_modeling_xlm.XLMModelTest.model_tester.create_and_check_xlm_sequence_classif"], "methods", ["None"], ["", "def", "test_xlm_sequence_classif", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_sequence_classif", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_xlm.XLMModelTest.test_model_from_pretrained": [[388, 393], ["list", "XLMModel.from_pretrained", "test_modeling_xlm.XLMModelTest.assertIsNotNone", "XLM_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "XLM_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "XLMModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_ctrl.CTRLTokenizationTest.setUp": [[29, 44], ["super().setUp", "dict", "os.path.join", "os.path.join", "zip", "open", "fp.write", "open", "fp.write", "range", "len", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "CTRLTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt", "\n", "vocab", "=", "[", "\"adapt\"", ",", "\"re@@\"", ",", "\"a@@\"", ",", "\"apt\"", ",", "\"c@@\"", ",", "\"t\"", ",", "\"<unk>\"", "]", "\n", "vocab_tokens", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "merges", "=", "[", "\"#version: 0.2\"", ",", "\"a p\"", ",", "\"ap t</w>\"", ",", "\"r e\"", ",", "\"a d\"", ",", "\"ad apt</w>\"", ",", "\"\"", "]", "\n", "self", ".", "special_tokens_map", "=", "{", "\"unk_token\"", ":", "\"<unk>\"", "}", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "self", ".", "merges_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "\"merges_file\"", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "json", ".", "dumps", "(", "vocab_tokens", ")", "+", "\"\\n\"", ")", "\n", "", "with", "open", "(", "self", ".", "merges_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "\"\\n\"", ".", "join", "(", "merges", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_ctrl.CTRLTokenizationTest.get_tokenizer": [[45, 48], ["kwargs.update", "transformers.tokenization_ctrl.CTRLTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "kwargs", ".", "update", "(", "self", ".", "special_tokens_map", ")", "\n", "return", "CTRLTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_ctrl.CTRLTokenizationTest.get_input_output_texts": [[49, 53], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "\"adapt react readapt apt\"", "\n", "output_text", "=", "\"adapt react readapt apt\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_ctrl.CTRLTokenizationTest.test_full_tokenizer": [[54, 65], ["transformers.tokenization_ctrl.CTRLTokenizer", "transformers.tokenization_ctrl.CTRLTokenizer.tokenize", "test_tokenization_ctrl.CTRLTokenizationTest.assertListEqual", "test_tokenization_ctrl.CTRLTokenizationTest.assertListEqual", "transformers.tokenization_ctrl.CTRLTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "CTRLTokenizer", "(", "self", ".", "vocab_file", ",", "self", ".", "merges_file", ",", "**", "self", ".", "special_tokens_map", ")", "\n", "text", "=", "\"adapt react readapt apt\"", "\n", "bpe_tokens", "=", "\"adapt re@@ a@@ c@@ t re@@ adapt apt\"", ".", "split", "(", ")", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "bpe_tokens", ")", "\n", "\n", "input_tokens", "=", "tokens", "+", "[", "tokenizer", ".", "unk_token", "]", "\n", "\n", "input_bpe_tokens", "=", "[", "0", ",", "1", ",", "2", ",", "4", ",", "5", ",", "1", ",", "0", ",", "3", ",", "6", "]", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "input_tokens", ")", ",", "input_bpe_tokens", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_auto.AutoModelTest.test_model_from_pretrained": [[43, 57], ["logging.basicConfig", "list", "AutoConfig.from_pretrained", "test_modeling_auto.AutoModelTest.assertIsNotNone", "test_modeling_auto.AutoModelTest.assertIsInstance", "AutoModel.from_pretrained", "AutoModel.from_pretrained", "test_modeling_auto.AutoModelTest.assertIsNotNone", "test_modeling_auto.AutoModelTest.assertIsInstance", "loading_info.values", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys", "test_modeling_auto.AutoModelTest.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["    ", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "AutoModel", ".", "from_pretrained", "(", "model_name", ")", "\n", "model", ",", "loading_info", "=", "AutoModel", ".", "from_pretrained", "(", "model_name", ",", "output_loading_info", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "BertModel", ")", "\n", "for", "value", "in", "loading_info", ".", "values", "(", ")", ":", "\n", "                ", "self", ".", "assertEqual", "(", "len", "(", "value", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_auto.AutoModelTest.test_lmhead_model_from_pretrained": [[58, 70], ["logging.basicConfig", "list", "AutoConfig.from_pretrained", "test_modeling_auto.AutoModelTest.assertIsNotNone", "test_modeling_auto.AutoModelTest.assertIsInstance", "AutoModelWithLMHead.from_pretrained", "AutoModelWithLMHead.from_pretrained", "test_modeling_auto.AutoModelTest.assertIsNotNone", "test_modeling_auto.AutoModelTest.assertIsInstance", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "", "@", "slow", "\n", "def", "test_lmhead_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "AutoModelWithLMHead", ".", "from_pretrained", "(", "model_name", ")", "\n", "model", ",", "loading_info", "=", "AutoModelWithLMHead", ".", "from_pretrained", "(", "model_name", ",", "output_loading_info", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "BertForMaskedLM", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_auto.AutoModelTest.test_sequence_classification_model_from_pretrained": [[71, 85], ["logging.basicConfig", "list", "AutoConfig.from_pretrained", "test_modeling_auto.AutoModelTest.assertIsNotNone", "test_modeling_auto.AutoModelTest.assertIsInstance", "AutoModelForSequenceClassification.from_pretrained", "AutoModelForSequenceClassification.from_pretrained", "test_modeling_auto.AutoModelTest.assertIsNotNone", "test_modeling_auto.AutoModelTest.assertIsInstance", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "@", "slow", "\n", "def", "test_sequence_classification_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "model_name", ")", "\n", "model", ",", "loading_info", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "\n", "model_name", ",", "output_loading_info", "=", "True", "\n", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "BertForSequenceClassification", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_auto.AutoModelTest.test_question_answering_model_from_pretrained": [[86, 98], ["logging.basicConfig", "list", "AutoConfig.from_pretrained", "test_modeling_auto.AutoModelTest.assertIsNotNone", "test_modeling_auto.AutoModelTest.assertIsInstance", "AutoModelForQuestionAnswering.from_pretrained", "AutoModelForQuestionAnswering.from_pretrained", "test_modeling_auto.AutoModelTest.assertIsNotNone", "test_modeling_auto.AutoModelTest.assertIsInstance", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "@", "slow", "\n", "def", "test_question_answering_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "AutoModelForQuestionAnswering", ".", "from_pretrained", "(", "model_name", ")", "\n", "model", ",", "loading_info", "=", "AutoModelForQuestionAnswering", ".", "from_pretrained", "(", "model_name", ",", "output_loading_info", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "BertForQuestionAnswering", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_auto.AutoModelTest.test_from_pretrained_identifier": [[99, 103], ["logging.basicConfig", "AutoModelWithLMHead.from_pretrained", "test_modeling_auto.AutoModelTest.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "test_from_pretrained_identifier", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "model", "=", "AutoModelWithLMHead", ".", "from_pretrained", "(", "SMALL_MODEL_IDENTIFIER", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "BertForMaskedLM", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_transfo_xl.TFTransfoXLModelTest.setUp": [[188, 191], ["TFTransfoXLModelTest.TFTransfoXLModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFTransfoXLModelTest", ".", "TFTransfoXLModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "TransfoXLConfig", ",", "d_embed", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_transfo_xl.TFTransfoXLModelTest.test_config": [[192, 194], ["test_modeling_tf_transfo_xl.TFTransfoXLModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_transfo_xl.TFTransfoXLModelTest.test_transfo_xl_model": [[195, 199], ["test_modeling_tf_transfo_xl.TFTransfoXLModelTest.model_tester.set_seed", "test_modeling_tf_transfo_xl.TFTransfoXLModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_transfo_xl.TFTransfoXLModelTest.model_tester.create_and_check_transfo_xl_model"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed"], ["", "def", "test_transfo_xl_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_transfo_xl_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_transfo_xl.TFTransfoXLModelTest.test_transfo_xl_lm_head": [[200, 204], ["test_modeling_tf_transfo_xl.TFTransfoXLModelTest.model_tester.set_seed", "test_modeling_tf_transfo_xl.TFTransfoXLModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_transfo_xl.TFTransfoXLModelTest.model_tester.create_and_check_transfo_xl_lm_head"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed"], ["", "def", "test_transfo_xl_lm_head", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_transfo_xl_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_transfo_xl.TFTransfoXLModelTest.test_model_from_pretrained": [[205, 210], ["list", "TFTransfoXLModel.from_pretrained", "test_modeling_tf_transfo_xl.TFTransfoXLModelTest.assertIsNotNone", "TF_TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "TF_TRANSFO_XL_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TFTransfoXLModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_ctrl.TFCTRLModelTest.setUp": [[184, 187], ["TFCTRLModelTest.TFCTRLModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFCTRLModelTest", ".", "TFCTRLModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "CTRLConfig", ",", "n_embd", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_ctrl.TFCTRLModelTest.test_config": [[188, 190], ["test_modeling_tf_ctrl.TFCTRLModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_ctrl.TFCTRLModelTest.test_ctrl_model": [[191, 194], ["test_modeling_tf_ctrl.TFCTRLModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_ctrl.TFCTRLModelTest.model_tester.create_and_check_ctrl_model"], "methods", ["None"], ["", "def", "test_ctrl_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_ctrl_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_ctrl.TFCTRLModelTest.test_ctrl_lm_head": [[195, 198], ["test_modeling_tf_ctrl.TFCTRLModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_ctrl.TFCTRLModelTest.model_tester.create_and_check_ctrl_lm_head"], "methods", ["None"], ["", "def", "test_ctrl_lm_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_ctrl_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_ctrl.TFCTRLModelTest.test_model_from_pretrained": [[199, 204], ["list", "TFCTRLModel.from_pretrained", "test_modeling_tf_ctrl.TFCTRLModelTest.assertIsNotNone", "TF_CTRL_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "TF_CTRL_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TFCTRLModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_bert.BertModelTest.setUp": [[426, 429], ["BertModelTest.BertModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "BertModelTest", ".", "BertModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "BertConfig", ",", "hidden_size", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_bert.BertModelTest.test_config": [[430, 432], ["test_modeling_bert.BertModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_bert.BertModelTest.test_bert_model": [[433, 436], ["test_modeling_bert.BertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_bert.BertModelTest.model_tester.create_and_check_bert_model"], "methods", ["None"], ["", "def", "test_bert_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_bert.BertModelTest.test_bert_model_as_decoder": [[437, 440], ["test_modeling_bert.BertModelTest.model_tester.prepare_config_and_inputs_for_decoder", "test_modeling_bert.BertModelTest.model_tester.create_and_check_bert_model_as_decoder"], "methods", ["None"], ["", "def", "test_bert_model_as_decoder", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_decoder", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_model_as_decoder", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_bert.BertModelTest.test_for_masked_lm": [[441, 444], ["test_modeling_bert.BertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_bert.BertModelTest.model_tester.create_and_check_bert_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_bert.BertModelTest.test_for_masked_lm_decoder": [[445, 448], ["test_modeling_bert.BertModelTest.model_tester.prepare_config_and_inputs_for_decoder", "test_modeling_bert.BertModelTest.model_tester.create_and_check_bert_model_for_masked_lm_as_decoder"], "methods", ["None"], ["", "def", "test_for_masked_lm_decoder", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_decoder", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_model_for_masked_lm_as_decoder", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_bert.BertModelTest.test_for_multiple_choice": [[449, 452], ["test_modeling_bert.BertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_bert.BertModelTest.model_tester.create_and_check_bert_for_multiple_choice"], "methods", ["None"], ["", "def", "test_for_multiple_choice", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_multiple_choice", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_bert.BertModelTest.test_for_next_sequence_prediction": [[453, 456], ["test_modeling_bert.BertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_bert.BertModelTest.model_tester.create_and_check_bert_for_next_sequence_prediction"], "methods", ["None"], ["", "def", "test_for_next_sequence_prediction", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_next_sequence_prediction", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_bert.BertModelTest.test_for_pretraining": [[457, 460], ["test_modeling_bert.BertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_bert.BertModelTest.model_tester.create_and_check_bert_for_pretraining"], "methods", ["None"], ["", "def", "test_for_pretraining", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_pretraining", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_bert.BertModelTest.test_for_question_answering": [[461, 464], ["test_modeling_bert.BertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_bert.BertModelTest.model_tester.create_and_check_bert_for_question_answering"], "methods", ["None"], ["", "def", "test_for_question_answering", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_question_answering", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_bert.BertModelTest.test_for_sequence_classification": [[465, 468], ["test_modeling_bert.BertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_bert.BertModelTest.model_tester.create_and_check_bert_for_sequence_classification"], "methods", ["None"], ["", "def", "test_for_sequence_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_sequence_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_bert.BertModelTest.test_for_token_classification": [[469, 472], ["test_modeling_bert.BertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_bert.BertModelTest.model_tester.create_and_check_bert_for_token_classification"], "methods", ["None"], ["", "def", "test_for_token_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_token_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_bert.BertModelTest.test_model_from_pretrained": [[473, 478], ["list", "BertModel.from_pretrained", "test_modeling_bert.BertModelTest.assertIsNotNone", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "BertModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_save_load": [[64, 88], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "model_class", "model_class.from_pretrained.to", "model_class.from_pretrained.eval", "outputs[].numpy", "torch.no_grad", "model_class.from_pretrained.", "tempfile.TemporaryDirectory", "model_class.from_pretrained.save_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "after_outputs[].cpu().numpy", "np.amax", "test_modeling_common.ModelTesterMixin.assertLessEqual", "np.isnan", "torch.no_grad", "model_class.from_pretrained.", "np.abs", "after_outputs[].cpu", "np.isnan"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["def", "test_save_load", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "model", "=", "model_class", "(", "config", ")", "\n", "model", ".", "to", "(", "torch_device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs_dict", ")", "\n", "", "out_2", "=", "outputs", "[", "0", "]", ".", "numpy", "(", ")", "\n", "out_2", "[", "np", ".", "isnan", "(", "out_2", ")", "]", "=", "0", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdirname", ":", "\n", "                ", "model", ".", "save_pretrained", "(", "tmpdirname", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "tmpdirname", ")", "\n", "model", ".", "to", "(", "torch_device", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "after_outputs", "=", "model", "(", "**", "inputs_dict", ")", "\n", "\n", "# Make sure we don't have nans", "\n", "", "out_1", "=", "after_outputs", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_1", "[", "np", ".", "isnan", "(", "out_1", ")", "]", "=", "0", "\n", "max_diff", "=", "np", ".", "amax", "(", "np", ".", "abs", "(", "out_1", "-", "out_2", ")", ")", "\n", "self", ".", "assertLessEqual", "(", "max_diff", ",", "1e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_initialization": [[89, 101], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "test_modeling_common._config_zero_init", "model_class", "model_class.named_parameters", "test_modeling_common.ModelTesterMixin.assertIn", "param.data.mean().item", "param.data.mean"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common._config_zero_init"], ["", "", "", "def", "test_initialization", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "configs_no_init", "=", "_config_zero_init", "(", "config", ")", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "model", "=", "model_class", "(", "config", "=", "configs_no_init", ")", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "param", ".", "requires_grad", ":", "\n", "                    ", "self", ".", "assertIn", "(", "\n", "param", ".", "data", ".", "mean", "(", ")", ".", "item", "(", ")", ",", "\n", "[", "0.0", ",", "1.0", "]", ",", "\n", "msg", "=", "\"Parameter {} of model {} seems not properly initialized\"", ".", "format", "(", "name", ",", "model_class", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_determinism": [[103, 119], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "model_class", "model_class.to", "model_class.eval", "first.cpu().numpy", "second.cpu().numpy", "np.amax", "test_modeling_common.ModelTesterMixin.assertLessEqual", "torch.no_grad", "np.abs", "model_class.", "model_class.", "first.cpu", "second.cpu", "np.isnan", "np.isnan"], "methods", ["None"], ["", "", "", "", "def", "test_determinism", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "model", "=", "model_class", "(", "config", ")", "\n", "model", ".", "to", "(", "torch_device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "first", "=", "model", "(", "**", "inputs_dict", ")", "[", "0", "]", "\n", "second", "=", "model", "(", "**", "inputs_dict", ")", "[", "0", "]", "\n", "", "out_1", "=", "first", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_2", "=", "second", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_1", "=", "out_1", "[", "~", "np", ".", "isnan", "(", "out_1", ")", "]", "\n", "out_2", "=", "out_2", "[", "~", "np", ".", "isnan", "(", "out_2", ")", "]", "\n", "max_diff", "=", "np", ".", "amax", "(", "np", ".", "abs", "(", "out_1", "-", "out_2", ")", ")", "\n", "self", ".", "assertLessEqual", "(", "max_diff", ",", "1e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_attention_outputs": [[120, 186], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "hasattr", "hasattr", "hasattr", "hasattr", "model_class", "model_class.to", "model_class.eval", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertListEqual", "len", "model_class", "model_class.to", "model_class.eval", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertListEqual", "torch.no_grad", "model_class.", "len", "list", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertListEqual", "torch.no_grad", "model_class.", "len", "len", "list", "len", "list"], "methods", ["None"], ["", "", "def", "test_attention_outputs", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "decoder_seq_length", "=", "(", "\n", "self", ".", "model_tester", ".", "decoder_seq_length", "\n", "if", "hasattr", "(", "self", ".", "model_tester", ",", "\"decoder_seq_length\"", ")", "\n", "else", "self", ".", "model_tester", ".", "seq_length", "\n", ")", "\n", "encoder_seq_length", "=", "(", "\n", "self", ".", "model_tester", ".", "encoder_seq_length", "\n", "if", "hasattr", "(", "self", ".", "model_tester", ",", "\"encoder_seq_length\"", ")", "\n", "else", "self", ".", "model_tester", ".", "seq_length", "\n", ")", "\n", "decoder_key_length", "=", "(", "\n", "self", ".", "model_tester", ".", "key_length", "if", "hasattr", "(", "self", ".", "model_tester", ",", "\"key_length\"", ")", "else", "decoder_seq_length", "\n", ")", "\n", "encoder_key_length", "=", "(", "\n", "self", ".", "model_tester", ".", "key_length", "if", "hasattr", "(", "self", ".", "model_tester", ",", "\"key_length\"", ")", "else", "encoder_seq_length", "\n", ")", "\n", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "config", ".", "output_attentions", "=", "True", "\n", "config", ".", "output_hidden_states", "=", "False", "\n", "model", "=", "model_class", "(", "config", ")", "\n", "model", ".", "to", "(", "torch_device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs_dict", ")", "\n", "", "attentions", "=", "outputs", "[", "-", "1", "]", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_attentions", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_hidden_states", ",", "False", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "attentions", ")", ",", "self", ".", "model_tester", ".", "num_hidden_layers", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "list", "(", "attentions", "[", "0", "]", ".", "shape", "[", "-", "3", ":", "]", ")", ",", "\n", "[", "self", ".", "model_tester", ".", "num_attention_heads", ",", "encoder_seq_length", ",", "encoder_key_length", "]", ",", "\n", ")", "\n", "out_len", "=", "len", "(", "outputs", ")", "\n", "\n", "if", "self", ".", "is_encoder_decoder", ":", "\n", "                ", "self", ".", "assertEqual", "(", "out_len", "%", "2", ",", "0", ")", "\n", "decoder_attentions", "=", "outputs", "[", "(", "out_len", "//", "2", ")", "-", "1", "]", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_attentions", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_hidden_states", ",", "False", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "decoder_attentions", ")", ",", "self", ".", "model_tester", ".", "num_hidden_layers", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "list", "(", "decoder_attentions", "[", "0", "]", ".", "shape", "[", "-", "3", ":", "]", ")", ",", "\n", "[", "self", ".", "model_tester", ".", "num_attention_heads", ",", "decoder_seq_length", ",", "decoder_key_length", "]", ",", "\n", ")", "\n", "\n", "# Check attention is always last and order is fine", "\n", "", "config", ".", "output_attentions", "=", "True", "\n", "config", ".", "output_hidden_states", "=", "True", "\n", "model", "=", "model_class", "(", "config", ")", "\n", "model", ".", "to", "(", "torch_device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs_dict", ")", "\n", "", "self", ".", "assertEqual", "(", "out_len", "+", "(", "2", "if", "self", ".", "is_encoder_decoder", "else", "1", ")", ",", "len", "(", "outputs", ")", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_attentions", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_hidden_states", ",", "True", ")", "\n", "\n", "self_attentions", "=", "outputs", "[", "-", "1", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "self_attentions", ")", ",", "self", ".", "model_tester", ".", "num_hidden_layers", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "list", "(", "self_attentions", "[", "0", "]", ".", "shape", "[", "-", "3", ":", "]", ")", ",", "\n", "[", "self", ".", "model_tester", ".", "num_attention_heads", ",", "encoder_seq_length", ",", "encoder_key_length", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_torchscript": [[188, 192], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "test_modeling_common.ModelTesterMixin._create_and_check_torchscript"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin._create_and_check_torchscript"], ["", "", "def", "test_torchscript", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "self", ".", "_create_and_check_torchscript", "(", "config", ",", "inputs_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_torchscript_output_attentions": [[193, 198], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "test_modeling_common.ModelTesterMixin._create_and_check_torchscript"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin._create_and_check_torchscript"], ["", "def", "test_torchscript_output_attentions", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "config", ".", "output_attentions", "=", "True", "\n", "self", ".", "_create_and_check_torchscript", "(", "config", ",", "inputs_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_torchscript_output_hidden_state": [[199, 204], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "test_modeling_common.ModelTesterMixin._create_and_check_torchscript"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin._create_and_check_torchscript"], ["", "def", "test_torchscript_output_hidden_state", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "config", ".", "output_hidden_states", "=", "True", "\n", "self", ".", "_create_and_check_torchscript", "(", "config", ",", "inputs_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin._create_and_check_torchscript": [[205, 250], ["test_modeling_common._config_zero_init", "model_class", "model_class.to", "model_class.eval", "model_class.to", "model_class.eval", "torch.jit.load.to", "torch.jit.load.eval", "model_class.parameters", "torch.jit.load.parameters", "zip", "test_modeling_common.ModelTesterMixin.assertTrue", "torch.jit.trace", "tempfile.TemporaryDirectory", "os.path.join", "test_modeling_common.ModelTesterMixin.fail", "torch.jit.save", "torch.jit.load", "p1.data.ne().sum", "test_modeling_common.ModelTesterMixin.fail", "test_modeling_common.ModelTesterMixin.fail", "p1.data.ne"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common._config_zero_init", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save"], ["", "def", "_create_and_check_torchscript", "(", "self", ",", "config", ",", "inputs_dict", ")", ":", "\n", "        ", "if", "not", "self", ".", "test_torchscript", ":", "\n", "            ", "return", "\n", "\n", "", "configs_no_init", "=", "_config_zero_init", "(", "config", ")", "# To be sure we have no Nan", "\n", "configs_no_init", ".", "torchscript", "=", "True", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "model", "=", "model_class", "(", "config", "=", "configs_no_init", ")", "\n", "model", ".", "to", "(", "torch_device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "inputs", "=", "inputs_dict", "[", "\"input_ids\"", "]", "# Let's keep only input_ids", "\n", "\n", "try", ":", "\n", "                ", "traced_gpt2", "=", "torch", ".", "jit", ".", "trace", "(", "model", ",", "inputs", ")", "\n", "", "except", "RuntimeError", ":", "\n", "                ", "self", ".", "fail", "(", "\"Couldn't trace module.\"", ")", "\n", "\n", "", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmp_dir_name", ":", "\n", "                ", "pt_file_name", "=", "os", ".", "path", ".", "join", "(", "tmp_dir_name", ",", "\"traced_model.pt\"", ")", "\n", "\n", "try", ":", "\n", "                    ", "torch", ".", "jit", ".", "save", "(", "traced_gpt2", ",", "pt_file_name", ")", "\n", "", "except", "Exception", ":", "\n", "                    ", "self", ".", "fail", "(", "\"Couldn't save module.\"", ")", "\n", "\n", "", "try", ":", "\n", "                    ", "loaded_model", "=", "torch", ".", "jit", ".", "load", "(", "pt_file_name", ")", "\n", "", "except", "Exception", ":", "\n", "                    ", "self", ".", "fail", "(", "\"Couldn't load module.\"", ")", "\n", "\n", "", "", "model", ".", "to", "(", "torch_device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "loaded_model", ".", "to", "(", "torch_device", ")", "\n", "loaded_model", ".", "eval", "(", ")", "\n", "\n", "model_params", "=", "model", ".", "parameters", "(", ")", "\n", "loaded_model_params", "=", "loaded_model", ".", "parameters", "(", ")", "\n", "\n", "models_equal", "=", "True", "\n", "for", "p1", ",", "p2", "in", "zip", "(", "model_params", ",", "loaded_model_params", ")", ":", "\n", "                ", "if", "p1", ".", "data", ".", "ne", "(", "p2", ".", "data", ")", ".", "sum", "(", ")", ">", "0", ":", "\n", "                    ", "models_equal", "=", "False", "\n", "\n", "", "", "self", ".", "assertTrue", "(", "models_equal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_headmasking": [[251, 305], ["global_rng.seed", "test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "global_rng.seed", "test_modeling_common._config_zero_init", "model_class", "model_class.to", "model_class.eval", "torch.ones", "torch.ones.requires_grad_", "inputs_dict.copy", "model_class.", "sum", "output.sum.sum.sum", "output.sum.sum.backward", "test_modeling_common.ModelTesterMixin.assertIsNotNone", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertAlmostEqual", "test_modeling_common.ModelTesterMixin.assertNotEqual", "test_modeling_common.ModelTesterMixin.assertNotEqual", "test_modeling_common.ModelTesterMixin.assertAlmostEqual", "test_modeling_common.ModelTesterMixin.assertNotEqual", "test_modeling_common.ModelTesterMixin.assertLess", "t.masked_fill", "len", "[].flatten().sum().item", "[].flatten().sum().item", "[].flatten().sum().item", "[].flatten().sum().item", "[].flatten().sum().item", "t.sum", "torch.sum", "torch.isnan", "torch.isnan", "t.numel", "[].flatten().sum", "[].flatten().sum", "[].flatten().sum", "[].flatten().sum", "[].flatten().sum", "[].flatten", "[].flatten", "[].flatten", "[].flatten", "[].flatten"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common._config_zero_init"], ["", "", "def", "test_headmasking", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "test_head_masking", ":", "\n", "            ", "return", "\n", "\n", "", "global_rng", ".", "seed", "(", "42", ")", "\n", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "global_rng", ".", "seed", "(", ")", "\n", "\n", "config", ".", "output_attentions", "=", "True", "\n", "config", ".", "output_hidden_states", "=", "True", "\n", "configs_no_init", "=", "_config_zero_init", "(", "config", ")", "# To be sure we have no Nan", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "model", "=", "model_class", "(", "config", "=", "configs_no_init", ")", "\n", "model", ".", "to", "(", "torch_device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Prepare head_mask", "\n", "# Set require_grad after having prepared the tensor to avoid error (leaf variable has been moved into the graph interior)", "\n", "head_mask", "=", "torch", ".", "ones", "(", "\n", "self", ".", "model_tester", ".", "num_hidden_layers", ",", "self", ".", "model_tester", ".", "num_attention_heads", ",", "device", "=", "torch_device", "\n", ")", "\n", "head_mask", "[", "0", ",", "0", "]", "=", "0", "\n", "head_mask", "[", "-", "1", ",", ":", "-", "1", "]", "=", "0", "\n", "head_mask", ".", "requires_grad_", "(", "requires_grad", "=", "True", ")", "\n", "inputs", "=", "inputs_dict", ".", "copy", "(", ")", "\n", "inputs", "[", "\"head_mask\"", "]", "=", "head_mask", "\n", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "# Test that we can get a gradient back for importance score computation", "\n", "output", "=", "sum", "(", "t", ".", "sum", "(", ")", "for", "t", "in", "outputs", "[", "0", "]", ")", "\n", "output", "=", "output", ".", "sum", "(", ")", "\n", "output", ".", "backward", "(", ")", "\n", "multihead_outputs", "=", "head_mask", ".", "grad", "\n", "\n", "attentions", "=", "outputs", "[", "-", "1", "]", "\n", "hidden_states", "=", "outputs", "[", "-", "2", "]", "\n", "\n", "# Remove Nan", "\n", "for", "t", "in", "attentions", ":", "\n", "                ", "self", ".", "assertLess", "(", "\n", "torch", ".", "sum", "(", "torch", ".", "isnan", "(", "t", ")", ")", ",", "t", ".", "numel", "(", ")", "/", "4", "\n", ")", "# Check we don't have more than 25% nans (arbitrary)", "\n", "", "attentions", "=", "[", "\n", "t", ".", "masked_fill", "(", "torch", ".", "isnan", "(", "t", ")", ",", "0.0", ")", "for", "t", "in", "attentions", "\n", "]", "# remove them (the test is less complete)", "\n", "\n", "self", ".", "assertIsNotNone", "(", "multihead_outputs", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "multihead_outputs", ")", ",", "self", ".", "model_tester", ".", "num_hidden_layers", ")", "\n", "self", ".", "assertAlmostEqual", "(", "attentions", "[", "0", "]", "[", "...", ",", "0", ",", ":", ",", ":", "]", ".", "flatten", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "0.0", ")", "\n", "self", ".", "assertNotEqual", "(", "attentions", "[", "0", "]", "[", "...", ",", "-", "1", ",", ":", ",", ":", "]", ".", "flatten", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "0.0", ")", "\n", "self", ".", "assertNotEqual", "(", "attentions", "[", "1", "]", "[", "...", ",", "0", ",", ":", ",", ":", "]", ".", "flatten", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "0.0", ")", "\n", "self", ".", "assertAlmostEqual", "(", "attentions", "[", "-", "1", "]", "[", "...", ",", "-", "2", ",", ":", ",", ":", "]", ".", "flatten", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "0.0", ")", "\n", "self", ".", "assertNotEqual", "(", "attentions", "[", "-", "1", "]", "[", "...", ",", "-", "1", ",", ":", ",", ":", "]", ".", "flatten", "(", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_head_pruning": [[306, 331], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "model_class", "model_class.to", "model_class.eval", "model_class.prune_heads", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "list", "torch.no_grad", "model_class.", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads"], ["", "", "def", "test_head_pruning", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "test_pruning", ":", "\n", "            ", "return", "\n", "\n", "", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "if", "\"head_mask\"", "in", "inputs_dict", ":", "\n", "                ", "del", "inputs_dict", "[", "\"head_mask\"", "]", "\n", "\n", "", "config", ".", "output_attentions", "=", "True", "\n", "config", ".", "output_hidden_states", "=", "False", "\n", "model", "=", "model_class", "(", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "torch_device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "heads_to_prune", "=", "{", "0", ":", "list", "(", "range", "(", "1", ",", "self", ".", "model_tester", ".", "num_attention_heads", ")", ")", ",", "-", "1", ":", "[", "0", "]", "}", "\n", "model", ".", "prune_heads", "(", "heads_to_prune", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs_dict", ")", "\n", "\n", "", "attentions", "=", "outputs", "[", "-", "1", "]", "\n", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "0", "]", ".", "shape", "[", "-", "3", "]", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "1", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", ")", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "-", "1", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_head_pruning_save_load_from_pretrained": [[332, 361], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "model_class", "model_class.from_pretrained.to", "model_class.from_pretrained.eval", "model_class.from_pretrained.prune_heads", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "list", "tempfile.TemporaryDirectory", "model_class.from_pretrained.save_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "torch.no_grad", "model_class.from_pretrained.", "range"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "test_head_pruning_save_load_from_pretrained", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "test_pruning", ":", "\n", "            ", "return", "\n", "\n", "", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "if", "\"head_mask\"", "in", "inputs_dict", ":", "\n", "                ", "del", "inputs_dict", "[", "\"head_mask\"", "]", "\n", "\n", "", "config", ".", "output_attentions", "=", "True", "\n", "config", ".", "output_hidden_states", "=", "False", "\n", "model", "=", "model_class", "(", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "torch_device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "heads_to_prune", "=", "{", "0", ":", "list", "(", "range", "(", "1", ",", "self", ".", "model_tester", ".", "num_attention_heads", ")", ")", ",", "-", "1", ":", "[", "0", "]", "}", "\n", "model", ".", "prune_heads", "(", "heads_to_prune", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "temp_dir_name", ":", "\n", "                ", "model", ".", "save_pretrained", "(", "temp_dir_name", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "temp_dir_name", ")", "\n", "model", ".", "to", "(", "torch_device", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs_dict", ")", "\n", "", "attentions", "=", "outputs", "[", "-", "1", "]", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "0", "]", ".", "shape", "[", "-", "3", "]", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "1", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", ")", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "-", "1", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_head_pruning_save_load_from_config_init": [[362, 389], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "model_class", "model_class.to", "model_class.eval", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "list", "torch.no_grad", "model_class.", "range"], "methods", ["None"], ["", "", "def", "test_head_pruning_save_load_from_config_init", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "test_pruning", ":", "\n", "            ", "return", "\n", "\n", "", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "if", "\"head_mask\"", "in", "inputs_dict", ":", "\n", "                ", "del", "inputs_dict", "[", "\"head_mask\"", "]", "\n", "\n", "", "config", ".", "output_attentions", "=", "True", "\n", "config", ".", "output_hidden_states", "=", "False", "\n", "\n", "heads_to_prune", "=", "{", "0", ":", "list", "(", "range", "(", "1", ",", "self", ".", "model_tester", ".", "num_attention_heads", ")", ")", ",", "-", "1", ":", "[", "0", "]", "}", "\n", "config", ".", "pruned_heads", "=", "heads_to_prune", "\n", "\n", "model", "=", "model_class", "(", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "torch_device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs_dict", ")", "\n", "", "attentions", "=", "outputs", "[", "-", "1", "]", "\n", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "0", "]", ".", "shape", "[", "-", "3", "]", ",", "1", ")", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "1", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", ")", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "-", "1", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_head_pruning_integration": [[390, 446], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "model_class", "model_class.from_pretrained.to", "model_class.from_pretrained.eval", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "model_class.from_pretrained.prune_heads", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertDictEqual", "torch.no_grad", "model_class.from_pretrained.", "tempfile.TemporaryDirectory", "model_class.from_pretrained.save_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "torch.no_grad", "model_class.from_pretrained.", "torch.no_grad", "model_class.from_pretrained."], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_openai.Attention.prune_heads", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "test_head_pruning_integration", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "test_pruning", ":", "\n", "            ", "return", "\n", "\n", "", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "if", "\"head_mask\"", "in", "inputs_dict", ":", "\n", "                ", "del", "inputs_dict", "[", "\"head_mask\"", "]", "\n", "\n", "", "config", ".", "output_attentions", "=", "True", "\n", "config", ".", "output_hidden_states", "=", "False", "\n", "\n", "heads_to_prune", "=", "{", "0", ":", "[", "0", "]", ",", "1", ":", "[", "1", ",", "2", "]", "}", "\n", "config", ".", "pruned_heads", "=", "heads_to_prune", "\n", "\n", "model", "=", "model_class", "(", "config", "=", "config", ")", "\n", "model", ".", "to", "(", "torch_device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs_dict", ")", "\n", "", "attentions", "=", "outputs", "[", "-", "1", "]", "\n", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "0", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", "-", "1", ")", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "1", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", "-", "2", ")", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "2", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", ")", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "3", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "temp_dir_name", ":", "\n", "                ", "model", ".", "save_pretrained", "(", "temp_dir_name", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "temp_dir_name", ")", "\n", "model", ".", "to", "(", "torch_device", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs_dict", ")", "\n", "", "attentions", "=", "outputs", "[", "-", "1", "]", "\n", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "0", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", "-", "1", ")", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "1", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", "-", "2", ")", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "2", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", ")", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "3", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", ")", "\n", "\n", "heads_to_prune", "=", "{", "0", ":", "[", "0", "]", ",", "2", ":", "[", "1", ",", "2", "]", "}", "\n", "model", ".", "prune_heads", "(", "heads_to_prune", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs_dict", ")", "\n", "", "attentions", "=", "outputs", "[", "-", "1", "]", "\n", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "0", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", "-", "1", ")", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "1", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", "-", "2", ")", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "2", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", "-", "2", ")", "\n", "self", ".", "assertEqual", "(", "attentions", "[", "3", "]", ".", "shape", "[", "-", "3", "]", ",", "self", ".", "model_tester", ".", "num_attention_heads", ")", "\n", "\n", "self", ".", "assertDictEqual", "(", "model", ".", "config", ".", "pruned_heads", ",", "{", "0", ":", "[", "0", "]", ",", "1", ":", "[", "1", ",", "2", "]", ",", "2", ":", "[", "1", ",", "2", "]", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_hidden_states_output": [[447, 469], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "model_class", "model_class.to", "model_class.eval", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertListEqual", "torch.no_grad", "model_class.", "len", "list", "hasattr"], "methods", ["None"], ["", "", "def", "test_hidden_states_output", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "config", ".", "output_hidden_states", "=", "True", "\n", "config", ".", "output_attentions", "=", "False", "\n", "model", "=", "model_class", "(", "config", ")", "\n", "model", ".", "to", "(", "torch_device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs_dict", ")", "\n", "", "hidden_states", "=", "outputs", "[", "-", "1", "]", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_attentions", ",", "False", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_hidden_states", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "hidden_states", ")", ",", "self", ".", "model_tester", ".", "num_hidden_layers", "+", "1", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "list", "(", "hidden_states", "[", "0", "]", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "\n", "[", "\n", "self", ".", "model_tester", ".", "encoder_seq_length", "\n", "if", "hasattr", "(", "self", ".", "model_tester", ",", "\"encoder_seq_length\"", ")", "\n", "else", "self", ".", "model_tester", ".", "seq_length", ",", "\n", "self", ".", "model_tester", ".", "hidden_size", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_resize_tokens_embeddings": [[472, 505], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "copy.deepcopy", "model_class", "model_class.resize_token_embeddings", "model_class.resize_token_embeddings.weight.clone", "model_class.resize_token_embeddings", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "model_class.resize_token_embeddings", "test_modeling_common.ModelTesterMixin.assertEqual", "test_modeling_common.ModelTesterMixin.assertEqual", "zip", "test_modeling_common.ModelTesterMixin.assertTrue", "p1.data.ne().sum", "p1.data.ne"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.resize_token_embeddings", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.resize_token_embeddings", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.resize_token_embeddings"], ["", "", "def", "test_resize_tokens_embeddings", "(", "self", ")", ":", "\n", "        ", "original_config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "if", "not", "self", ".", "test_resize_embeddings", ":", "\n", "            ", "return", "\n", "\n", "", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "config", "=", "copy", ".", "deepcopy", "(", "original_config", ")", "\n", "model", "=", "model_class", "(", "config", ")", "\n", "\n", "model_vocab_size", "=", "config", ".", "vocab_size", "\n", "# Retrieve the embeddings and clone theme", "\n", "model_embed", "=", "model", ".", "resize_token_embeddings", "(", "model_vocab_size", ")", "\n", "cloned_embeddings", "=", "model_embed", ".", "weight", ".", "clone", "(", ")", "\n", "\n", "# Check that resizing the token embeddings with a larger vocab size increases the model's vocab size", "\n", "model_embed", "=", "model", ".", "resize_token_embeddings", "(", "model_vocab_size", "+", "10", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "vocab_size", ",", "model_vocab_size", "+", "10", ")", "\n", "# Check that it actually resizes the embeddings matrix", "\n", "self", ".", "assertEqual", "(", "model_embed", ".", "weight", ".", "shape", "[", "0", "]", ",", "cloned_embeddings", ".", "shape", "[", "0", "]", "+", "10", ")", "\n", "\n", "# Check that resizing the token embeddings with a smaller vocab size decreases the model's vocab size", "\n", "model_embed", "=", "model", ".", "resize_token_embeddings", "(", "model_vocab_size", "-", "15", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "vocab_size", ",", "model_vocab_size", "-", "15", ")", "\n", "# Check that it actually resizes the embeddings matrix", "\n", "self", ".", "assertEqual", "(", "model_embed", ".", "weight", ".", "shape", "[", "0", "]", ",", "cloned_embeddings", ".", "shape", "[", "0", "]", "-", "15", ")", "\n", "\n", "# Check that adding and removing tokens has not modified the first part of the embedding matrix.", "\n", "models_equal", "=", "True", "\n", "for", "p1", ",", "p2", "in", "zip", "(", "cloned_embeddings", ",", "model_embed", ".", "weight", ")", ":", "\n", "                ", "if", "p1", ".", "data", ".", "ne", "(", "p2", ".", "data", ")", ".", "sum", "(", ")", ">", "0", ":", "\n", "                    ", "models_equal", "=", "False", "\n", "\n", "", "", "self", ".", "assertTrue", "(", "models_equal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_model_common_attributes": [[506, 515], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "model_class", "test_modeling_common.ModelTesterMixin.assertIsInstance", "model_class.set_input_embeddings", "model_class.get_output_embeddings", "test_modeling_common.ModelTesterMixin.assertTrue", "model_class.get_input_embeddings", "torch.nn.Embedding", "isinstance"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.set_input_embeddings", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxForMaskedLM.get_output_embeddings", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.get_input_embeddings"], ["", "", "def", "test_model_common_attributes", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "model", "=", "model_class", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ".", "get_input_embeddings", "(", ")", ",", "(", "torch", ".", "nn", ".", "Embedding", ",", "AdaptiveEmbedding", ")", ")", "\n", "model", ".", "set_input_embeddings", "(", "torch", ".", "nn", ".", "Embedding", "(", "10", ",", "10", ")", ")", "\n", "x", "=", "model", ".", "get_output_embeddings", "(", ")", "\n", "self", ".", "assertTrue", "(", "x", "is", "None", "or", "isinstance", "(", "x", ",", "torch", ".", "nn", ".", "Linear", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_tie_model_weights": [[516, 563], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "zip", "model_class", "list", "copy.deepcopy", "model_class", "list", "test_modeling_common.ModelTesterMixin.assertGreater", "model_class.resize_token_embeddings", "list", "test_modeling_common.ModelTesterMixin.assertGreater", "test_modeling_common.ModelTesterMixin.assertEqual", "model_class.get_output_embeddings", "model_class.parameters", "model_class.parameters", "len", "len", "model_class.parameters", "len", "len", "len", "len", "p1.data.ne().sum", "p1.data.ne"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.resize_token_embeddings", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxForMaskedLM.get_output_embeddings"], ["", "", "def", "test_tie_model_weights", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "test_torchscript", ":", "\n", "            ", "return", "\n", "\n", "", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "def", "check_same_values", "(", "layer_1", ",", "layer_2", ")", ":", "\n", "            ", "equal", "=", "True", "\n", "for", "p1", ",", "p2", "in", "zip", "(", "layer_1", ".", "weight", ",", "layer_2", ".", "weight", ")", ":", "\n", "                ", "if", "p1", ".", "data", ".", "ne", "(", "p2", ".", "data", ")", ".", "sum", "(", ")", ">", "0", ":", "\n", "                    ", "equal", "=", "False", "\n", "", "", "return", "equal", "\n", "\n", "", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "config", ".", "torchscript", "=", "True", "\n", "model_not_tied", "=", "model_class", "(", "config", ")", "\n", "if", "model_not_tied", ".", "get_output_embeddings", "(", ")", "is", "None", ":", "\n", "                ", "continue", "\n", "\n", "", "params_not_tied", "=", "list", "(", "model_not_tied", ".", "parameters", "(", ")", ")", "\n", "\n", "config_tied", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "config_tied", ".", "torchscript", "=", "False", "\n", "model_tied", "=", "model_class", "(", "config_tied", ")", "\n", "params_tied", "=", "list", "(", "model_tied", ".", "parameters", "(", ")", ")", "\n", "\n", "# Check that the embedding layer and decoding layer are the same in size and in value", "\n", "self", ".", "assertGreater", "(", "len", "(", "params_not_tied", ")", ",", "len", "(", "params_tied", ")", ")", "\n", "# self.assertTrue(check_same_values(embeddings, decoding))", "\n", "\n", "# # Check that after modification, they remain the same.", "\n", "# embeddings.weight.data.div_(2)", "\n", "# # Check that the embedding layer and decoding layer are the same in size and in value", "\n", "# self.assertTrue(embeddings.weight.shape, decoding.weight.shape)", "\n", "# self.assertTrue(check_same_values(embeddings, decoding))", "\n", "\n", "# # Check that after modification, they remain the same.", "\n", "# decoding.weight.data.div_(4)", "\n", "# # Check that the embedding layer and decoding layer are the same in size and in value", "\n", "# self.assertTrue(embeddings.weight.shape, decoding.weight.shape)", "\n", "# self.assertTrue(check_same_values(embeddings, decoding))", "\n", "\n", "# Check that after resize they remain tied.", "\n", "model_tied", ".", "resize_token_embeddings", "(", "config", ".", "vocab_size", "+", "10", ")", "\n", "params_tied_2", "=", "list", "(", "model_tied", ".", "parameters", "(", ")", ")", "\n", "self", ".", "assertGreater", "(", "len", "(", "params_not_tied", ")", ",", "len", "(", "params_tied", ")", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "params_tied_2", ")", ",", "len", "(", "params_tied", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelTesterMixin.test_inputs_embeds": [[569, 594], ["test_modeling_common.ModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "model_class", "model_class.to", "model_class.eval", "model_class.get_input_embeddings", "model_class.get_input_embeddings.", "model_class.get_input_embeddings.", "model_class.get_input_embeddings.", "torch.no_grad", "model_class."], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.get_input_embeddings"], ["", "", "def", "test_inputs_embeds", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "if", "not", "self", ".", "is_encoder_decoder", ":", "\n", "            ", "input_ids", "=", "inputs_dict", "[", "\"input_ids\"", "]", "\n", "del", "inputs_dict", "[", "\"input_ids\"", "]", "\n", "", "else", ":", "\n", "            ", "encoder_input_ids", "=", "inputs_dict", "[", "\"encoder_input_ids\"", "]", "\n", "decoder_input_ids", "=", "inputs_dict", "[", "\"decoder_input_ids\"", "]", "\n", "del", "inputs_dict", "[", "\"encoder_input_ids\"", "]", "\n", "del", "inputs_dict", "[", "\"decoder_input_ids\"", "]", "\n", "\n", "", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "model", "=", "model_class", "(", "config", ")", "\n", "model", ".", "to", "(", "torch_device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "wte", "=", "model", ".", "get_input_embeddings", "(", ")", "\n", "if", "not", "self", ".", "is_encoder_decoder", ":", "\n", "                ", "inputs_dict", "[", "\"inputs_embeds\"", "]", "=", "wte", "(", "input_ids", ")", "\n", "", "else", ":", "\n", "                ", "inputs_dict", "[", "\"encoder_inputs_embeds\"", "]", "=", "wte", "(", "encoder_input_ids", ")", "\n", "inputs_dict", "[", "\"decoder_inputs_embeds\"", "]", "=", "wte", "(", "decoder_input_ids", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "model", "(", "**", "inputs_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ConfigTester.__init__": [[597, 601], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "parent", ",", "config_class", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "parent", "=", "parent", "\n", "self", ".", "config_class", "=", "config_class", "\n", "self", ".", "inputs_dict", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ConfigTester.create_and_test_config_common_properties": [[602, 608], ["test_modeling_common.ConfigTester.config_class", "test_modeling_common.ConfigTester.parent.assertTrue", "test_modeling_common.ConfigTester.parent.assertTrue", "test_modeling_common.ConfigTester.parent.assertTrue", "test_modeling_common.ConfigTester.parent.assertTrue", "hasattr", "hasattr", "hasattr", "hasattr"], "methods", ["None"], ["", "def", "create_and_test_config_common_properties", "(", "self", ")", ":", "\n", "        ", "config", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "\"vocab_size\"", ")", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "\"hidden_size\"", ")", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "\"num_attention_heads\"", ")", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "\"num_hidden_layers\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ConfigTester.create_and_test_config_to_json_string": [[609, 614], ["test_modeling_common.ConfigTester.config_class", "json.loads", "test_modeling_common.ConfigTester.inputs_dict.items", "test_modeling_common.ConfigTester.to_json_string", "test_modeling_common.ConfigTester.parent.assertEqual"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_json_string"], ["", "def", "create_and_test_config_to_json_string", "(", "self", ")", ":", "\n", "        ", "config", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "obj", "=", "json", ".", "loads", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "inputs_dict", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "parent", ".", "assertEqual", "(", "obj", "[", "key", "]", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ConfigTester.create_and_test_config_to_json_file": [[615, 622], ["test_modeling_common.ConfigTester.config_class", "os.path.join", "test_modeling_common.ConfigTester.to_json_file", "test_modeling_common.ConfigTester.config_class.from_json_file", "os.remove", "test_modeling_common.ConfigTester.parent.assertEqual", "os.getcwd", "test_modeling_common.ConfigTester.to_dict", "test_modeling_common.ConfigTester.to_dict", "str", "uuid.uuid4"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.to_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_dict", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_dict"], ["", "", "def", "create_and_test_config_to_json_file", "(", "self", ")", ":", "\n", "        ", "config_first", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "json_file_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "\"config_\"", "+", "str", "(", "uuid", ".", "uuid4", "(", ")", ")", "+", "\".json\"", ")", "\n", "config_first", ".", "to_json_file", "(", "json_file_path", ")", "\n", "config_second", "=", "self", ".", "config_class", ".", "from_json_file", "(", "json_file_path", ")", "\n", "os", ".", "remove", "(", "json_file_path", ")", "\n", "self", ".", "parent", ".", "assertEqual", "(", "config_second", ".", "to_dict", "(", ")", ",", "config_first", ".", "to_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ConfigTester.run_common_tests": [[623, 627], ["test_modeling_common.ConfigTester.create_and_test_config_common_properties", "test_modeling_common.ConfigTester.create_and_test_config_to_json_string", "test_modeling_common.ConfigTester.create_and_test_config_to_json_file"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.create_and_test_config_common_properties", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.create_and_test_config_to_json_string", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.create_and_test_config_to_json_file"], ["", "def", "run_common_tests", "(", "self", ")", ":", "\n", "        ", "self", ".", "create_and_test_config_common_properties", "(", ")", "\n", "self", ".", "create_and_test_config_to_json_string", "(", ")", "\n", "self", ".", "create_and_test_config_to_json_file", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ModelUtilsTest.test_model_from_pretrained": [[666, 686], ["logging.basicConfig", "list", "BertConfig.from_pretrained", "test_modeling_common.ModelUtilsTest.assertIsNotNone", "test_modeling_common.ModelUtilsTest.assertIsInstance", "BertModel.from_pretrained", "BertModel.from_pretrained", "test_modeling_common.ModelUtilsTest.assertIsNotNone", "test_modeling_common.ModelUtilsTest.assertIsInstance", "loading_info.values", "BertConfig.from_pretrained", "BertModel.from_pretrained", "test_modeling_common.ModelUtilsTest.assertEqual", "test_modeling_common.ModelUtilsTest.assertEqual", "test_modeling_common.ModelUtilsTest.assertEqual", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys", "test_modeling_common.ModelUtilsTest.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["    ", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "config", "=", "BertConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "PretrainedConfig", ")", "\n", "\n", "model", "=", "BertModel", ".", "from_pretrained", "(", "model_name", ")", "\n", "model", ",", "loading_info", "=", "BertModel", ".", "from_pretrained", "(", "model_name", ",", "output_loading_info", "=", "True", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "PreTrainedModel", ")", "\n", "for", "value", "in", "loading_info", ".", "values", "(", ")", ":", "\n", "                ", "self", ".", "assertEqual", "(", "len", "(", "value", ")", ",", "0", ")", "\n", "\n", "", "config", "=", "BertConfig", ".", "from_pretrained", "(", "model_name", ",", "output_attentions", "=", "True", ",", "output_hidden_states", "=", "True", ")", "\n", "model", "=", "BertModel", ".", "from_pretrained", "(", "model_name", ",", "output_attentions", "=", "True", ",", "output_hidden_states", "=", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_attentions", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_hidden_states", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ",", "config", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common._config_zero_init": [[45, 51], ["copy.deepcopy", "copy.deepcopy.__dict__.keys", "setattr"], "function", ["None"], ["", "def", "_config_zero_init", "(", "config", ")", ":", "\n", "    ", "configs_no_init", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "for", "key", "in", "configs_no_init", ".", "__dict__", ".", "keys", "(", ")", ":", "\n", "        ", "if", "\"_range\"", "in", "key", "or", "\"_std\"", "in", "key", "or", "\"initializer_factor\"", "in", "key", ":", "\n", "            ", "setattr", "(", "configs_no_init", ",", "key", ",", "0.0", ")", "\n", "", "", "return", "configs_no_init", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.ids_tensor": [[632, 646], ["range", "torch.tensor().view().contiguous", "values.append", "rng.randint", "torch.tensor().view", "torch.tensor"], "function", ["None"], ["def", "ids_tensor", "(", "shape", ",", "vocab_size", ",", "rng", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates a random int32 tensor of the shape within the vocab size.\"\"\"", "\n", "if", "rng", "is", "None", ":", "\n", "        ", "rng", "=", "global_rng", "\n", "\n", "", "total_dims", "=", "1", "\n", "for", "dim", "in", "shape", ":", "\n", "        ", "total_dims", "*=", "dim", "\n", "\n", "", "values", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "total_dims", ")", ":", "\n", "        ", "values", ".", "append", "(", "rng", ".", "randint", "(", "0", ",", "vocab_size", "-", "1", ")", ")", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "data", "=", "values", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "torch_device", ")", ".", "view", "(", "shape", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_common.floats_tensor": [[648, 662], ["range", "torch.tensor().view().contiguous", "values.append", "torch.tensor().view", "rng.random", "torch.tensor"], "function", ["None"], ["", "def", "floats_tensor", "(", "shape", ",", "scale", "=", "1.0", ",", "rng", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates a random float32 tensor of the shape within the vocab size.\"\"\"", "\n", "if", "rng", "is", "None", ":", "\n", "        ", "rng", "=", "global_rng", "\n", "\n", "", "total_dims", "=", "1", "\n", "for", "dim", "in", "shape", ":", "\n", "        ", "total_dims", "*=", "dim", "\n", "\n", "", "values", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "total_dims", ")", ":", "\n", "        ", "values", ".", "append", "(", "rng", ".", "random", "(", ")", "*", "scale", ")", "\n", "\n", "", "return", "torch", ".", "tensor", "(", "data", "=", "values", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "torch_device", ")", ".", "view", "(", "shape", ")", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_auto.TFAutoModelTest.test_model_from_pretrained": [[42, 58], ["test_modeling_tf_auto.TFAutoModelTest.assertTrue", "logging.basicConfig", "h5py.version.hdf5_version.startswith", "AutoConfig.from_pretrained", "test_modeling_tf_auto.TFAutoModelTest.assertIsNotNone", "test_modeling_tf_auto.TFAutoModelTest.assertIsInstance", "TFAutoModel.from_pretrained", "test_modeling_tf_auto.TFAutoModelTest.assertIsNotNone", "test_modeling_tf_auto.TFAutoModelTest.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["    ", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "import", "h5py", "\n", "\n", "self", ".", "assertTrue", "(", "h5py", ".", "version", ".", "hdf5_version", ".", "startswith", "(", "\"1.10\"", ")", ")", "\n", "\n", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "# for model_name in list(TF_BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys())[:1]:", "\n", "for", "model_name", "in", "[", "\"bert-base-uncased\"", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "TFAutoModel", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "TFBertModel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_auto.TFAutoModelTest.test_lmhead_model_from_pretrained": [[59, 71], ["logging.basicConfig", "AutoConfig.from_pretrained", "test_modeling_tf_auto.TFAutoModelTest.assertIsNotNone", "test_modeling_tf_auto.TFAutoModelTest.assertIsInstance", "TFAutoModelWithLMHead.from_pretrained", "test_modeling_tf_auto.TFAutoModelTest.assertIsNotNone", "test_modeling_tf_auto.TFAutoModelTest.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "@", "slow", "\n", "def", "test_lmhead_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "# for model_name in list(TF_BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys())[:1]:", "\n", "for", "model_name", "in", "[", "\"bert-base-uncased\"", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "TFAutoModelWithLMHead", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "TFBertForMaskedLM", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_auto.TFAutoModelTest.test_sequence_classification_model_from_pretrained": [[72, 84], ["logging.basicConfig", "AutoConfig.from_pretrained", "test_modeling_tf_auto.TFAutoModelTest.assertIsNotNone", "test_modeling_tf_auto.TFAutoModelTest.assertIsInstance", "TFAutoModelForSequenceClassification.from_pretrained", "test_modeling_tf_auto.TFAutoModelTest.assertIsNotNone", "test_modeling_tf_auto.TFAutoModelTest.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "@", "slow", "\n", "def", "test_sequence_classification_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "# for model_name in list(TF_BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys())[:1]:", "\n", "for", "model_name", "in", "[", "\"bert-base-uncased\"", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "TFAutoModelForSequenceClassification", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "TFBertForSequenceClassification", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_auto.TFAutoModelTest.test_question_answering_model_from_pretrained": [[85, 97], ["logging.basicConfig", "AutoConfig.from_pretrained", "test_modeling_tf_auto.TFAutoModelTest.assertIsNotNone", "test_modeling_tf_auto.TFAutoModelTest.assertIsInstance", "TFAutoModelForQuestionAnswering.from_pretrained", "test_modeling_tf_auto.TFAutoModelTest.assertIsNotNone", "test_modeling_tf_auto.TFAutoModelTest.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "@", "slow", "\n", "def", "test_question_answering_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "# for model_name in list(TF_BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys())[:1]:", "\n", "for", "model_name", "in", "[", "\"bert-base-uncased\"", "]", ":", "\n", "            ", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "config", ")", "\n", "self", ".", "assertIsInstance", "(", "config", ",", "BertConfig", ")", "\n", "\n", "model", "=", "TFAutoModelForQuestionAnswering", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "TFBertForQuestionAnswering", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_auto.TFAutoModelTest.test_from_pretrained_identifier": [[98, 102], ["logging.basicConfig", "TFAutoModelWithLMHead.from_pretrained", "test_modeling_tf_auto.TFAutoModelTest.assertIsInstance"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "test_from_pretrained_identifier", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "model", "=", "TFAutoModelWithLMHead", ".", "from_pretrained", "(", "SMALL_MODEL_IDENTIFIER", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ",", "TFBertForMaskedLM", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.__init__": [[23, 27], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "parent", ",", "config_class", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "parent", "=", "parent", "\n", "self", ".", "config_class", "=", "config_class", "\n", "self", ".", "inputs_dict", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.create_and_test_config_common_properties": [[28, 34], ["test_configuration_common.ConfigTester.config_class", "test_configuration_common.ConfigTester.parent.assertTrue", "test_configuration_common.ConfigTester.parent.assertTrue", "test_configuration_common.ConfigTester.parent.assertTrue", "test_configuration_common.ConfigTester.parent.assertTrue", "hasattr", "hasattr", "hasattr", "hasattr"], "methods", ["None"], ["", "def", "create_and_test_config_common_properties", "(", "self", ")", ":", "\n", "        ", "config", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "\"vocab_size\"", ")", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "\"hidden_size\"", ")", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "\"num_attention_heads\"", ")", ")", "\n", "self", ".", "parent", ".", "assertTrue", "(", "hasattr", "(", "config", ",", "\"num_hidden_layers\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.create_and_test_config_to_json_string": [[35, 40], ["test_configuration_common.ConfigTester.config_class", "json.loads", "test_configuration_common.ConfigTester.inputs_dict.items", "test_configuration_common.ConfigTester.to_json_string", "test_configuration_common.ConfigTester.parent.assertEqual"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_json_string"], ["", "def", "create_and_test_config_to_json_string", "(", "self", ")", ":", "\n", "        ", "config", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "obj", "=", "json", ".", "loads", "(", "config", ".", "to_json_string", "(", ")", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "inputs_dict", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "parent", ".", "assertEqual", "(", "obj", "[", "key", "]", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.create_and_test_config_to_json_file": [[41, 50], ["test_configuration_common.ConfigTester.config_class", "test_configuration_common.ConfigTester.parent.assertEqual", "tempfile.TemporaryDirectory", "os.path.join", "test_configuration_common.ConfigTester.to_json_file", "test_configuration_common.ConfigTester.config_class.from_json_file", "test_configuration_common.ConfigTester.to_dict", "test_configuration_common.ConfigTester.to_dict"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.to_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_dict", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_dict"], ["", "", "def", "create_and_test_config_to_json_file", "(", "self", ")", ":", "\n", "        ", "config_first", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdirname", ":", "\n", "            ", "json_file_path", "=", "os", ".", "path", ".", "join", "(", "tmpdirname", ",", "\"config.json\"", ")", "\n", "config_first", ".", "to_json_file", "(", "json_file_path", ")", "\n", "config_second", "=", "self", ".", "config_class", ".", "from_json_file", "(", "json_file_path", ")", "\n", "\n", "", "self", ".", "parent", ".", "assertEqual", "(", "config_second", ".", "to_dict", "(", ")", ",", "config_first", ".", "to_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.create_and_test_config_from_and_save_pretrained": [[51, 59], ["test_configuration_common.ConfigTester.config_class", "test_configuration_common.ConfigTester.parent.assertEqual", "tempfile.TemporaryDirectory", "test_configuration_common.ConfigTester.save_pretrained", "test_configuration_common.ConfigTester.config_class.from_pretrained", "test_configuration_common.ConfigTester.to_dict", "test_configuration_common.ConfigTester.to_dict"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_dict", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_dict"], ["", "def", "create_and_test_config_from_and_save_pretrained", "(", "self", ")", ":", "\n", "        ", "config_first", "=", "self", ".", "config_class", "(", "**", "self", ".", "inputs_dict", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdirname", ":", "\n", "            ", "config_first", ".", "save_pretrained", "(", "tmpdirname", ")", "\n", "config_second", "=", "self", ".", "config_class", ".", "from_pretrained", "(", "tmpdirname", ")", "\n", "\n", "", "self", ".", "parent", ".", "assertEqual", "(", "config_second", ".", "to_dict", "(", ")", ",", "config_first", ".", "to_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests": [[60, 65], ["test_configuration_common.ConfigTester.create_and_test_config_common_properties", "test_configuration_common.ConfigTester.create_and_test_config_to_json_string", "test_configuration_common.ConfigTester.create_and_test_config_to_json_file", "test_configuration_common.ConfigTester.create_and_test_config_from_and_save_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.create_and_test_config_common_properties", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.create_and_test_config_to_json_string", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.create_and_test_config_to_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.create_and_test_config_from_and_save_pretrained"], ["", "def", "run_common_tests", "(", "self", ")", ":", "\n", "        ", "self", ".", "create_and_test_config_common_properties", "(", ")", "\n", "self", ".", "create_and_test_config_to_json_string", "(", ")", "\n", "self", ".", "create_and_test_config_to_json_file", "(", ")", "\n", "self", ".", "create_and_test_config_from_and_save_pretrained", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_ctrl.CTRLModelTest.setUp": [[194, 197], ["CTRLModelTest.CTRLModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "CTRLModelTest", ".", "CTRLModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "CTRLConfig", ",", "n_embd", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_ctrl.CTRLModelTest.test_config": [[198, 200], ["test_modeling_ctrl.CTRLModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_ctrl.CTRLModelTest.test_ctrl_model": [[201, 204], ["test_modeling_ctrl.CTRLModelTest.model_tester.prepare_config_and_inputs", "test_modeling_ctrl.CTRLModelTest.model_tester.create_and_check_ctrl_model"], "methods", ["None"], ["", "def", "test_ctrl_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_ctrl_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_ctrl.CTRLModelTest.test_ctrl_lm_head_model": [[205, 208], ["test_modeling_ctrl.CTRLModelTest.model_tester.prepare_config_and_inputs", "test_modeling_ctrl.CTRLModelTest.model_tester.create_and_check_lm_head_model"], "methods", ["None"], ["", "def", "test_ctrl_lm_head_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_lm_head_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_ctrl.CTRLModelTest.test_model_from_pretrained": [[209, 214], ["list", "CTRLModel.from_pretrained", "test_modeling_ctrl.CTRLModelTest.assertIsNotNone", "CTRL_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "CTRL_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "CTRLModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_openai.OpenAIGPTModelTest.setUp": [[184, 187], ["OpenAIGPTModelTest.OpenAIGPTModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "OpenAIGPTModelTest", ".", "OpenAIGPTModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "OpenAIGPTConfig", ",", "n_embd", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_openai.OpenAIGPTModelTest.test_config": [[188, 190], ["test_modeling_openai.OpenAIGPTModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_openai.OpenAIGPTModelTest.test_openai_gpt_model": [[191, 194], ["test_modeling_openai.OpenAIGPTModelTest.model_tester.prepare_config_and_inputs", "test_modeling_openai.OpenAIGPTModelTest.model_tester.create_and_check_openai_gpt_model"], "methods", ["None"], ["", "def", "test_openai_gpt_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_openai_gpt_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_openai.OpenAIGPTModelTest.test_openai_gpt_lm_head_model": [[195, 198], ["test_modeling_openai.OpenAIGPTModelTest.model_tester.prepare_config_and_inputs", "test_modeling_openai.OpenAIGPTModelTest.model_tester.create_and_check_lm_head_model"], "methods", ["None"], ["", "def", "test_openai_gpt_lm_head_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_lm_head_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_openai.OpenAIGPTModelTest.test_openai_gpt_double_lm_head_model": [[199, 202], ["test_modeling_openai.OpenAIGPTModelTest.model_tester.prepare_config_and_inputs", "test_modeling_openai.OpenAIGPTModelTest.model_tester.create_and_check_double_lm_head_model"], "methods", ["None"], ["", "def", "test_openai_gpt_double_lm_head_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_double_lm_head_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_openai.OpenAIGPTModelTest.test_model_from_pretrained": [[203, 208], ["list", "OpenAIGPTModel.from_pretrained", "test_modeling_openai.OpenAIGPTModelTest.assertIsNotNone", "OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "OpenAIGPTModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_transfo_xl.TransfoXLTokenizationTest.setUp": [[35, 54], ["super().setUp", "os.path.join", "open", "vocab_writer.write"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "TransfoXLTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "vocab_tokens", "=", "[", "\n", "\"<unk>\"", ",", "\n", "\"[CLS]\"", ",", "\n", "\"[SEP]\"", ",", "\n", "\"want\"", ",", "\n", "\"unwanted\"", ",", "\n", "\"wa\"", ",", "\n", "\"un\"", ",", "\n", "\"running\"", ",", "\n", "\",\"", ",", "\n", "\"low\"", ",", "\n", "\"l\"", ",", "\n", "]", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "vocab_writer", ":", "\n", "            ", "vocab_writer", ".", "write", "(", "\"\"", ".", "join", "(", "[", "x", "+", "\"\\n\"", "for", "x", "in", "vocab_tokens", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_transfo_xl.TransfoXLTokenizationTest.get_tokenizer": [[55, 58], ["TransfoXLTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "kwargs", "[", "\"lower_case\"", "]", "=", "True", "\n", "return", "TransfoXLTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_transfo_xl.TransfoXLTokenizationTest.get_input_output_texts": [[59, 63], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "\"<unk> UNwanted , running\"", "\n", "output_text", "=", "\"<unk> unwanted, running\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_transfo_xl.TransfoXLTokenizationTest.test_full_tokenizer": [[64, 71], ["TransfoXLTokenizer", "TransfoXLTokenizer.tokenize", "test_tokenization_transfo_xl.TransfoXLTokenizationTest.assertListEqual", "test_tokenization_transfo_xl.TransfoXLTokenizationTest.assertListEqual", "TransfoXLTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "TransfoXLTokenizer", "(", "vocab_file", "=", "self", ".", "vocab_file", ",", "lower_case", "=", "True", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "\"<unk> UNwanted , running\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "\"<unk>\"", ",", "\"unwanted\"", ",", "\",\"", ",", "\"running\"", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ",", "[", "0", ",", "4", ",", "8", ",", "7", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_transfo_xl.TransfoXLTokenizationTest.test_full_tokenizer_lower": [[72, 77], ["TransfoXLTokenizer", "test_tokenization_transfo_xl.TransfoXLTokenizationTest.assertListEqual", "TransfoXLTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "test_full_tokenizer_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "TransfoXLTokenizer", "(", "lower_case", "=", "True", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "\" \\tHeLLo ! how  \\n Are yoU ?  \"", ")", ",", "[", "\"hello\"", ",", "\"!\"", ",", "\"how\"", ",", "\"are\"", ",", "\"you\"", ",", "\"?\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_transfo_xl.TransfoXLTokenizationTest.test_full_tokenizer_no_lower": [[79, 84], ["TransfoXLTokenizer", "test_tokenization_transfo_xl.TransfoXLTokenizationTest.assertListEqual", "TransfoXLTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "test_full_tokenizer_no_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "TransfoXLTokenizer", "(", "lower_case", "=", "False", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "\" \\tHeLLo ! how  \\n Are yoU ?  \"", ")", ",", "[", "\"HeLLo\"", ",", "\"!\"", ",", "\"how\"", ",", "\"Are\"", ",", "\"yoU\"", ",", "\"?\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_distilbert.TFDistilBertModelTest.setUp": [[196, 199], ["TFDistilBertModelTest.TFDistilBertModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFDistilBertModelTest", ".", "TFDistilBertModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "DistilBertConfig", ",", "dim", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_distilbert.TFDistilBertModelTest.test_config": [[200, 202], ["test_modeling_tf_distilbert.TFDistilBertModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_distilbert.TFDistilBertModelTest.test_distilbert_model": [[203, 206], ["test_modeling_tf_distilbert.TFDistilBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_distilbert.TFDistilBertModelTest.model_tester.create_and_check_distilbert_model"], "methods", ["None"], ["", "def", "test_distilbert_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_distilbert.TFDistilBertModelTest.test_for_masked_lm": [[207, 210], ["test_modeling_tf_distilbert.TFDistilBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_distilbert.TFDistilBertModelTest.model_tester.create_and_check_distilbert_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_distilbert.TFDistilBertModelTest.test_for_question_answering": [[211, 214], ["test_modeling_tf_distilbert.TFDistilBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_distilbert.TFDistilBertModelTest.model_tester.create_and_check_distilbert_for_question_answering"], "methods", ["None"], ["", "def", "test_for_question_answering", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_for_question_answering", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_distilbert.TFDistilBertModelTest.test_for_sequence_classification": [[215, 218], ["test_modeling_tf_distilbert.TFDistilBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_distilbert.TFDistilBertModelTest.model_tester.create_and_check_distilbert_for_sequence_classification"], "methods", ["None"], ["", "def", "test_for_sequence_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_for_sequence_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_model_card.ModelCardTester.setUp": [[26, 44], ["None"], "methods", ["None"], ["    ", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "inputs_dict", "=", "{", "\n", "\"model_details\"", ":", "{", "\n", "\"Organization\"", ":", "\"testing\"", ",", "\n", "\"Model date\"", ":", "\"today\"", ",", "\n", "\"Model version\"", ":", "\"v2.1, Developed by Test Corp in 2019.\"", ",", "\n", "\"Architecture\"", ":", "\"Convolutional Neural Network.\"", ",", "\n", "}", ",", "\n", "\"metrics\"", ":", "\"BLEU and ROUGE-1\"", ",", "\n", "\"evaluation_data\"", ":", "{", "\n", "\"Datasets\"", ":", "{", "\"BLEU\"", ":", "\"My-great-dataset-v1\"", ",", "\"ROUGE-1\"", ":", "\"My-short-dataset-v2.1\"", "}", ",", "\n", "\"Preprocessing\"", ":", "\"See details on https://arxiv.org/pdf/1810.03993.pdf\"", ",", "\n", "}", ",", "\n", "\"training_data\"", ":", "{", "\n", "\"Dataset\"", ":", "\"English Wikipedia dump dated 2018-12-01\"", ",", "\n", "\"Preprocessing\"", ":", "\"Using SentencePiece vocabulary of size 52k tokens. See details on https://arxiv.org/pdf/1810.03993.pdf\"", ",", "\n", "}", ",", "\n", "\"quantitative_analyses\"", ":", "{", "\"BLEU\"", ":", "55.1", ",", "\"ROUGE-1\"", ":", "76", "}", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_model_card.ModelCardTester.test_model_card_common_properties": [[46, 57], ["transformers.modelcard.ModelCard.from_dict", "test_model_card.ModelCardTester.assertTrue", "test_model_card.ModelCardTester.assertTrue", "test_model_card.ModelCardTester.assertTrue", "test_model_card.ModelCardTester.assertTrue", "test_model_card.ModelCardTester.assertTrue", "test_model_card.ModelCardTester.assertTrue", "test_model_card.ModelCardTester.assertTrue", "test_model_card.ModelCardTester.assertTrue", "test_model_card.ModelCardTester.assertTrue", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr", "hasattr"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_dict"], ["", "def", "test_model_card_common_properties", "(", "self", ")", ":", "\n", "        ", "modelcard", "=", "ModelCard", ".", "from_dict", "(", "self", ".", "inputs_dict", ")", "\n", "self", ".", "assertTrue", "(", "hasattr", "(", "modelcard", ",", "\"model_details\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "hasattr", "(", "modelcard", ",", "\"intended_use\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "hasattr", "(", "modelcard", ",", "\"factors\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "hasattr", "(", "modelcard", ",", "\"metrics\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "hasattr", "(", "modelcard", ",", "\"evaluation_data\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "hasattr", "(", "modelcard", ",", "\"training_data\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "hasattr", "(", "modelcard", ",", "\"quantitative_analyses\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "hasattr", "(", "modelcard", ",", "\"ethical_considerations\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "hasattr", "(", "modelcard", ",", "\"caveats_and_recommendations\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_model_card.ModelCardTester.test_model_card_to_json_string": [[58, 63], ["transformers.modelcard.ModelCard.from_dict", "json.loads", "test_model_card.ModelCardTester.inputs_dict.items", "transformers.modelcard.ModelCard.from_dict.to_json_string", "test_model_card.ModelCardTester.assertEqual"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_dict", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_json_string"], ["", "def", "test_model_card_to_json_string", "(", "self", ")", ":", "\n", "        ", "modelcard", "=", "ModelCard", ".", "from_dict", "(", "self", ".", "inputs_dict", ")", "\n", "obj", "=", "json", ".", "loads", "(", "modelcard", ".", "to_json_string", "(", ")", ")", "\n", "for", "key", ",", "value", "in", "self", ".", "inputs_dict", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "assertEqual", "(", "obj", "[", "key", "]", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_model_card.ModelCardTester.test_model_card_to_json_file": [[64, 73], ["transformers.modelcard.ModelCard.from_dict", "test_model_card.ModelCardTester.assertEqual", "tempfile.TemporaryDirectory", "os.path.join", "transformers.modelcard.ModelCard.from_dict.to_json_file", "transformers.modelcard.ModelCard.from_json_file", "transformers.modelcard.ModelCard.from_json_file.to_dict", "transformers.modelcard.ModelCard.from_dict.to_dict"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_dict", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.to_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_json_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_dict", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_dict"], ["", "", "def", "test_model_card_to_json_file", "(", "self", ")", ":", "\n", "        ", "model_card_first", "=", "ModelCard", ".", "from_dict", "(", "self", ".", "inputs_dict", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdirname", ":", "\n", "            ", "filename", "=", "os", ".", "path", ".", "join", "(", "tmpdirname", ",", "\"modelcard.json\"", ")", "\n", "model_card_first", ".", "to_json_file", "(", "filename", ")", "\n", "model_card_second", "=", "ModelCard", ".", "from_json_file", "(", "filename", ")", "\n", "\n", "", "self", ".", "assertEqual", "(", "model_card_second", ".", "to_dict", "(", ")", ",", "model_card_first", ".", "to_dict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_model_card.ModelCardTester.test_model_card_from_and_save_pretrained": [[74, 82], ["transformers.modelcard.ModelCard.from_dict", "test_model_card.ModelCardTester.assertEqual", "tempfile.TemporaryDirectory", "transformers.modelcard.ModelCard.from_dict.save_pretrained", "transformers.modelcard.ModelCard.from_pretrained", "transformers.modelcard.ModelCard.from_pretrained.to_dict", "transformers.modelcard.ModelCard.from_dict.to_dict"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.from_dict", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_dict", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.utils.InputFeatures.to_dict"], ["", "def", "test_model_card_from_and_save_pretrained", "(", "self", ")", ":", "\n", "        ", "model_card_first", "=", "ModelCard", ".", "from_dict", "(", "self", ".", "inputs_dict", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdirname", ":", "\n", "            ", "model_card_first", ".", "save_pretrained", "(", "tmpdirname", ")", "\n", "model_card_second", "=", "ModelCard", ".", "from_pretrained", "(", "tmpdirname", ")", "\n", "\n", "", "self", ".", "assertEqual", "(", "model_card_second", ".", "to_dict", "(", ")", ",", "model_card_first", ".", "to_dict", "(", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xlnet.XLNetTokenizationTest.setUp": [[33, 39], ["super().setUp", "transformers.tokenization_xlnet.XLNetTokenizer", "transformers.tokenization_xlnet.XLNetTokenizer.save_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.setUp", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "XLNetTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# We have a SentencePiece fixture for testing", "\n", "tokenizer", "=", "XLNetTokenizer", "(", "SAMPLE_VOCAB", ",", "keep_accents", "=", "True", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "self", ".", "tmpdirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xlnet.XLNetTokenizationTest.get_tokenizer": [[40, 42], ["transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "XLNetTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xlnet.XLNetTokenizationTest.get_input_output_texts": [[43, 47], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "\"This is a test\"", "\n", "output_text", "=", "\"This is a test\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xlnet.XLNetTokenizationTest.test_full_tokenizer": [[48, 111], ["transformers.tokenization_xlnet.XLNetTokenizer", "transformers.tokenization_xlnet.XLNetTokenizer.tokenize", "test_tokenization_xlnet.XLNetTokenizationTest.assertListEqual", "test_tokenization_xlnet.XLNetTokenizationTest.assertListEqual", "transformers.tokenization_xlnet.XLNetTokenizer.tokenize", "test_tokenization_xlnet.XLNetTokenizationTest.assertListEqual", "transformers.tokenization_xlnet.XLNetTokenizer.convert_tokens_to_ids", "test_tokenization_xlnet.XLNetTokenizationTest.assertListEqual", "transformers.tokenization_xlnet.XLNetTokenizer.convert_ids_to_tokens", "test_tokenization_xlnet.XLNetTokenizationTest.assertListEqual", "transformers.tokenization_xlnet.XLNetTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "XLNetTokenizer", "(", "SAMPLE_VOCAB", ",", "keep_accents", "=", "True", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "\"This is a test\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "\"\u2581This\"", ",", "\"\u2581is\"", ",", "\"\u2581a\"", ",", "\"\u2581t\"", ",", "\"est\"", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ",", "[", "285", ",", "46", ",", "10", ",", "170", ",", "382", "]", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "\"I was born in 92000, and this is fals\u00e9.\"", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "tokens", ",", "\n", "[", "\n", "SPIECE_UNDERLINE", "+", "\"I\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"was\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"b\"", ",", "\n", "\"or\"", ",", "\n", "\"n\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"in\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"\"", ",", "\n", "\"9\"", ",", "\n", "\"2\"", ",", "\n", "\"0\"", ",", "\n", "\"0\"", ",", "\n", "\"0\"", ",", "\n", "\",\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"and\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"this\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"is\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"f\"", ",", "\n", "\"al\"", ",", "\n", "\"s\"", ",", "\n", "\"\u00e9\"", ",", "\n", "\".\"", ",", "\n", "]", ",", "\n", ")", "\n", "ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "self", ".", "assertListEqual", "(", "ids", ",", "[", "8", ",", "21", ",", "84", ",", "55", ",", "24", ",", "19", ",", "7", ",", "0", ",", "602", ",", "347", ",", "347", ",", "347", ",", "3", ",", "12", ",", "66", ",", "46", ",", "72", ",", "80", ",", "6", ",", "0", ",", "4", "]", ")", "\n", "\n", "back_tokens", "=", "tokenizer", ".", "convert_ids_to_tokens", "(", "ids", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "back_tokens", ",", "\n", "[", "\n", "SPIECE_UNDERLINE", "+", "\"I\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"was\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"b\"", ",", "\n", "\"or\"", ",", "\n", "\"n\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"in\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"\"", ",", "\n", "\"<unk>\"", ",", "\n", "\"2\"", ",", "\n", "\"0\"", ",", "\n", "\"0\"", ",", "\n", "\"0\"", ",", "\n", "\",\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"and\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"this\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"is\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"f\"", ",", "\n", "\"al\"", ",", "\n", "\"s\"", ",", "\n", "\"<unk>\"", ",", "\n", "\".\"", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xlnet.XLNetTokenizationTest.test_tokenizer_lower": [[114, 144], ["transformers.tokenization_xlnet.XLNetTokenizer", "transformers.tokenization_xlnet.XLNetTokenizer.tokenize", "test_tokenization_xlnet.XLNetTokenizationTest.assertListEqual", "test_tokenization_xlnet.XLNetTokenizationTest.assertListEqual", "transformers.tokenization_xlnet.XLNetTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "test_tokenizer_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "XLNetTokenizer", "(", "SAMPLE_VOCAB", ",", "do_lower_case", "=", "True", ")", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "\"I was born in 92000, and this is fals\u00e9.\"", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "tokens", ",", "\n", "[", "\n", "SPIECE_UNDERLINE", "+", "\"\"", ",", "\n", "\"i\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"was\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"b\"", ",", "\n", "\"or\"", ",", "\n", "\"n\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"in\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"\"", ",", "\n", "\"9\"", ",", "\n", "\"2\"", ",", "\n", "\"0\"", ",", "\n", "\"0\"", ",", "\n", "\"0\"", ",", "\n", "\",\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"and\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"this\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"is\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"f\"", ",", "\n", "\"al\"", ",", "\n", "\"se\"", ",", "\n", "\".\"", ",", "\n", "]", ",", "\n", ")", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "\"H\\u00E9llo\"", ")", ",", "[", "\"\u2581he\"", ",", "\"ll\"", ",", "\"o\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xlnet.XLNetTokenizationTest.test_tokenizer_no_lower": [[145, 171], ["transformers.tokenization_xlnet.XLNetTokenizer", "transformers.tokenization_xlnet.XLNetTokenizer.tokenize", "test_tokenization_xlnet.XLNetTokenizationTest.assertListEqual"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "test_tokenizer_no_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "XLNetTokenizer", "(", "SAMPLE_VOCAB", ",", "do_lower_case", "=", "False", ")", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "\"I was born in 92000, and this is fals\u00e9.\"", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "tokens", ",", "\n", "[", "\n", "SPIECE_UNDERLINE", "+", "\"I\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"was\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"b\"", ",", "\n", "\"or\"", ",", "\n", "\"n\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"in\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"\"", ",", "\n", "\"9\"", ",", "\n", "\"2\"", ",", "\n", "\"0\"", ",", "\n", "\"0\"", ",", "\n", "\"0\"", ",", "\n", "\",\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"and\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"this\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"is\"", ",", "\n", "SPIECE_UNDERLINE", "+", "\"f\"", ",", "\n", "\"al\"", ",", "\n", "\"se\"", ",", "\n", "\".\"", ",", "\n", "]", ",", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xlnet.XLNetTokenizationTest.test_sequence_builders": [[174, 186], ["transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained", "transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained.encode", "transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained.encode", "transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained.build_inputs_with_special_tokens", "transformers.tokenization_xlnet.XLNetTokenizer.from_pretrained.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens"], ["", "@", "slow", "\n", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "XLNetTokenizer", ".", "from_pretrained", "(", "\"xlnet-base-cased\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ",", "add_special_tokens", "=", "False", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"multi-sequence build\"", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ",", "text_2", ")", "\n", "\n", "assert", "encoded_sentence", "==", "text", "+", "[", "4", ",", "3", "]", "\n", "assert", "encoded_pair", "==", "text", "+", "[", "4", "]", "+", "text_2", "+", "[", "4", ",", "3", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert.BertTokenizationTest.setUp": [[38, 59], ["super().setUp", "os.path.join", "open", "vocab_writer.write"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "BertTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "vocab_tokens", "=", "[", "\n", "\"[UNK]\"", ",", "\n", "\"[CLS]\"", ",", "\n", "\"[SEP]\"", ",", "\n", "\"want\"", ",", "\n", "\"##want\"", ",", "\n", "\"##ed\"", ",", "\n", "\"wa\"", ",", "\n", "\"un\"", ",", "\n", "\"runn\"", ",", "\n", "\"##ing\"", ",", "\n", "\",\"", ",", "\n", "\"low\"", ",", "\n", "\"lowest\"", ",", "\n", "]", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "vocab_writer", ":", "\n", "            ", "vocab_writer", ".", "write", "(", "\"\"", ".", "join", "(", "[", "x", "+", "\"\\n\"", "for", "x", "in", "vocab_tokens", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert.BertTokenizationTest.get_tokenizer": [[60, 62], ["transformers.tokenization_bert.BertTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "BertTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert.BertTokenizationTest.get_input_output_texts": [[63, 67], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "\"UNwant\\u00E9d,running\"", "\n", "output_text", "=", "\"unwanted, running\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert.BertTokenizationTest.test_full_tokenizer": [[68, 74], ["test_tokenization_bert.BertTokenizationTest.tokenizer_class", "test_tokenization_bert.BertTokenizationTest.tokenize", "test_tokenization_bert.BertTokenizationTest.assertListEqual", "test_tokenization_bert.BertTokenizationTest.assertListEqual", "test_tokenization_bert.BertTokenizationTest.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "tokenizer_class", "(", "self", ".", "vocab_file", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "\"UNwant\\u00E9d,running\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "\"un\"", ",", "\"##want\"", ",", "\"##ed\"", ",", "\",\"", ",", "\"runn\"", ",", "\"##ing\"", "]", ")", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ",", "[", "7", ",", "4", ",", "5", ",", "10", ",", "8", ",", "9", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert.BertTokenizationTest.test_chinese": [[75, 79], ["transformers.tokenization_bert.BasicTokenizer", "test_tokenization_bert.BertTokenizationTest.assertListEqual", "transformers.tokenization_bert.BasicTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "test_chinese", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "BasicTokenizer", "(", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "\"ah\\u535A\\u63A8zz\"", ")", ",", "[", "\"ah\"", ",", "\"\\u535A\"", ",", "\"\\u63A8\"", ",", "\"zz\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert.BertTokenizationTest.test_basic_tokenizer_lower": [[80, 87], ["transformers.tokenization_bert.BasicTokenizer", "test_tokenization_bert.BertTokenizationTest.assertListEqual", "test_tokenization_bert.BertTokenizationTest.assertListEqual", "transformers.tokenization_bert.BasicTokenizer.tokenize", "transformers.tokenization_bert.BasicTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "test_basic_tokenizer_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "True", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "\" \\tHeLLo!how  \\n Are yoU?  \"", ")", ",", "[", "\"hello\"", ",", "\"!\"", ",", "\"how\"", ",", "\"are\"", ",", "\"you\"", ",", "\"?\"", "]", "\n", ")", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "\"H\\u00E9llo\"", ")", ",", "[", "\"hello\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert.BertTokenizationTest.test_basic_tokenizer_no_lower": [[88, 93], ["transformers.tokenization_bert.BasicTokenizer", "test_tokenization_bert.BertTokenizationTest.assertListEqual", "transformers.tokenization_bert.BasicTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "test_basic_tokenizer_no_lower", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "False", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "tokenize", "(", "\" \\tHeLLo!how  \\n Are yoU?  \"", ")", ",", "[", "\"HeLLo\"", ",", "\"!\"", ",", "\"how\"", ",", "\"Are\"", ",", "\"yoU\"", ",", "\"?\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert.BertTokenizationTest.test_wordpiece_tokenizer": [[95, 108], ["enumerate", "transformers.tokenization_bert.WordpieceTokenizer", "test_tokenization_bert.BertTokenizationTest.assertListEqual", "test_tokenization_bert.BertTokenizationTest.assertListEqual", "test_tokenization_bert.BertTokenizationTest.assertListEqual", "transformers.tokenization_bert.WordpieceTokenizer.tokenize", "transformers.tokenization_bert.WordpieceTokenizer.tokenize", "transformers.tokenization_bert.WordpieceTokenizer.tokenize"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "test_wordpiece_tokenizer", "(", "self", ")", ":", "\n", "        ", "vocab_tokens", "=", "[", "\"[UNK]\"", ",", "\"[CLS]\"", ",", "\"[SEP]\"", ",", "\"want\"", ",", "\"##want\"", ",", "\"##ed\"", ",", "\"wa\"", ",", "\"un\"", ",", "\"runn\"", ",", "\"##ing\"", "]", "\n", "\n", "vocab", "=", "{", "}", "\n", "for", "(", "i", ",", "token", ")", "in", "enumerate", "(", "vocab_tokens", ")", ":", "\n", "            ", "vocab", "[", "token", "]", "=", "i", "\n", "", "tokenizer", "=", "WordpieceTokenizer", "(", "vocab", "=", "vocab", ",", "unk_token", "=", "\"[UNK]\"", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "\"\"", ")", ",", "[", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "\"unwanted running\"", ")", ",", "[", "\"un\"", ",", "\"##want\"", ",", "\"##ed\"", ",", "\"runn\"", ",", "\"##ing\"", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "tokenize", "(", "\"unwantedX running\"", ")", ",", "[", "\"[UNK]\"", ",", "\"runn\"", ",", "\"##ing\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert.BertTokenizationTest.test_is_whitespace": [[109, 118], ["test_tokenization_bert.BertTokenizationTest.assertTrue", "test_tokenization_bert.BertTokenizationTest.assertTrue", "test_tokenization_bert.BertTokenizationTest.assertTrue", "test_tokenization_bert.BertTokenizationTest.assertTrue", "test_tokenization_bert.BertTokenizationTest.assertTrue", "test_tokenization_bert.BertTokenizationTest.assertFalse", "test_tokenization_bert.BertTokenizationTest.assertFalse", "transformers.tokenization_bert._is_whitespace", "transformers.tokenization_bert._is_whitespace", "transformers.tokenization_bert._is_whitespace", "transformers.tokenization_bert._is_whitespace", "transformers.tokenization_bert._is_whitespace", "transformers.tokenization_bert._is_whitespace", "transformers.tokenization_bert._is_whitespace"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad._is_whitespace", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad._is_whitespace", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad._is_whitespace", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad._is_whitespace", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad._is_whitespace", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad._is_whitespace", "home.repos.pwc.inspect_result.bcmi220_ggdp.processors.squad._is_whitespace"], ["", "def", "test_is_whitespace", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertTrue", "(", "_is_whitespace", "(", "\" \"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_whitespace", "(", "\"\\t\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_whitespace", "(", "\"\\r\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_whitespace", "(", "\"\\n\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_whitespace", "(", "\"\\u00A0\"", ")", ")", "\n", "\n", "self", ".", "assertFalse", "(", "_is_whitespace", "(", "\"A\"", ")", ")", "\n", "self", ".", "assertFalse", "(", "_is_whitespace", "(", "\"-\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert.BertTokenizationTest.test_is_control": [[119, 126], ["test_tokenization_bert.BertTokenizationTest.assertTrue", "test_tokenization_bert.BertTokenizationTest.assertFalse", "test_tokenization_bert.BertTokenizationTest.assertFalse", "test_tokenization_bert.BertTokenizationTest.assertFalse", "test_tokenization_bert.BertTokenizationTest.assertFalse", "transformers.tokenization_bert._is_control", "transformers.tokenization_bert._is_control", "transformers.tokenization_bert._is_control", "transformers.tokenization_bert._is_control", "transformers.tokenization_bert._is_control"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_control", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_control", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_control", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_control", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_control"], ["", "def", "test_is_control", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertTrue", "(", "_is_control", "(", "\"\\u0005\"", ")", ")", "\n", "\n", "self", ".", "assertFalse", "(", "_is_control", "(", "\"A\"", ")", ")", "\n", "self", ".", "assertFalse", "(", "_is_control", "(", "\" \"", ")", ")", "\n", "self", ".", "assertFalse", "(", "_is_control", "(", "\"\\t\"", ")", ")", "\n", "self", ".", "assertFalse", "(", "_is_control", "(", "\"\\r\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert.BertTokenizationTest.test_is_punctuation": [[127, 135], ["test_tokenization_bert.BertTokenizationTest.assertTrue", "test_tokenization_bert.BertTokenizationTest.assertTrue", "test_tokenization_bert.BertTokenizationTest.assertTrue", "test_tokenization_bert.BertTokenizationTest.assertTrue", "test_tokenization_bert.BertTokenizationTest.assertFalse", "test_tokenization_bert.BertTokenizationTest.assertFalse", "transformers.tokenization_bert._is_punctuation", "transformers.tokenization_bert._is_punctuation", "transformers.tokenization_bert._is_punctuation", "transformers.tokenization_bert._is_punctuation", "transformers.tokenization_bert._is_punctuation", "transformers.tokenization_bert._is_punctuation"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_punctuation", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_punctuation", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_punctuation", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_punctuation", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_punctuation", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_bert._is_punctuation"], ["", "def", "test_is_punctuation", "(", "self", ")", ":", "\n", "        ", "self", ".", "assertTrue", "(", "_is_punctuation", "(", "\"-\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_punctuation", "(", "\"$\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_punctuation", "(", "\"`\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "_is_punctuation", "(", "\".\"", ")", ")", "\n", "\n", "self", ".", "assertFalse", "(", "_is_punctuation", "(", "\"A\"", ")", ")", "\n", "self", ".", "assertFalse", "(", "_is_punctuation", "(", "\" \"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_bert.BertTokenizationTest.test_sequence_builders": [[136, 148], ["test_tokenization_bert.BertTokenizationTest.tokenizer_class.from_pretrained", "test_tokenization_bert.BertTokenizationTest.encode", "test_tokenization_bert.BertTokenizationTest.encode", "test_tokenization_bert.BertTokenizationTest.build_inputs_with_special_tokens", "test_tokenization_bert.BertTokenizationTest.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens"], ["", "@", "slow", "\n", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "tokenizer_class", ".", "from_pretrained", "(", "\"bert-base-uncased\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ",", "add_special_tokens", "=", "False", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"multi-sequence build\"", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ",", "text_2", ")", "\n", "\n", "assert", "encoded_sentence", "==", "[", "101", "]", "+", "text", "+", "[", "102", "]", "\n", "assert", "encoded_pair", "==", "[", "101", "]", "+", "text", "+", "[", "102", "]", "+", "text_2", "+", "[", "102", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_albert.AlbertTokenizationTest.setUp": [[32, 38], ["super().setUp", "transformers.tokenization_albert.AlbertTokenizer", "transformers.tokenization_albert.AlbertTokenizer.save_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.setUp", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "AlbertTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# We have a SentencePiece fixture for testing", "\n", "tokenizer", "=", "AlbertTokenizer", "(", "SAMPLE_VOCAB", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "self", ".", "tmpdirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_albert.AlbertTokenizationTest.get_tokenizer": [[39, 41], ["transformers.tokenization_albert.AlbertTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "AlbertTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_albert.AlbertTokenizationTest.get_input_output_texts": [[42, 46], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "\"this is a test\"", "\n", "output_text", "=", "\"this is a test\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_albert.AlbertTokenizationTest.test_full_tokenizer": [[47, 66], ["transformers.tokenization_albert.AlbertTokenizer", "transformers.tokenization_albert.AlbertTokenizer.tokenize", "test_tokenization_albert.AlbertTokenizationTest.assertListEqual", "test_tokenization_albert.AlbertTokenizationTest.assertListEqual", "transformers.tokenization_albert.AlbertTokenizer.tokenize", "test_tokenization_albert.AlbertTokenizationTest.assertListEqual", "transformers.tokenization_albert.AlbertTokenizer.convert_tokens_to_ids", "test_tokenization_albert.AlbertTokenizationTest.assertListEqual", "transformers.tokenization_albert.AlbertTokenizer.convert_ids_to_tokens", "test_tokenization_albert.AlbertTokenizationTest.assertListEqual", "transformers.tokenization_albert.AlbertTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "AlbertTokenizer", "(", "SAMPLE_VOCAB", ",", "keep_accents", "=", "True", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "\"This is a test\"", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "[", "\"\u2581this\"", ",", "\"\u2581is\"", ",", "\"\u2581a\"", ",", "\"\u2581test\"", "]", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ",", "[", "48", ",", "25", ",", "21", ",", "1289", "]", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "\"I was born in 92000, and this is fals\u00e9.\"", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "tokens", ",", "[", "\"\u2581i\"", ",", "\"\u2581was\"", ",", "\"\u2581born\"", ",", "\"\u2581in\"", ",", "\"\u25819\"", ",", "\"2000\"", ",", "\",\"", ",", "\"\u2581and\"", ",", "\"\u2581this\"", ",", "\"\u2581is\"", ",", "\"\u2581fal\"", ",", "\"s\"", ",", "\"\u00e9\"", ",", "\".\"", "]", "\n", ")", "\n", "ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "self", ".", "assertListEqual", "(", "ids", ",", "[", "31", ",", "23", ",", "386", ",", "19", ",", "561", ",", "3050", ",", "15", ",", "17", ",", "48", ",", "25", ",", "8256", ",", "18", ",", "1", ",", "9", "]", ")", "\n", "\n", "back_tokens", "=", "tokenizer", ".", "convert_ids_to_tokens", "(", "ids", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "back_tokens", ",", "\n", "[", "\"\u2581i\"", ",", "\"\u2581was\"", ",", "\"\u2581born\"", ",", "\"\u2581in\"", ",", "\"\u25819\"", ",", "\"2000\"", ",", "\",\"", ",", "\"\u2581and\"", ",", "\"\u2581this\"", ",", "\"\u2581is\"", ",", "\"\u2581fal\"", ",", "\"s\"", ",", "\"<unk>\"", ",", "\".\"", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_albert.AlbertTokenizationTest.test_sequence_builders": [[68, 80], ["transformers.tokenization_albert.AlbertTokenizer", "transformers.tokenization_albert.AlbertTokenizer.encode", "transformers.tokenization_albert.AlbertTokenizer.encode", "transformers.tokenization_albert.AlbertTokenizer.build_inputs_with_special_tokens", "transformers.tokenization_albert.AlbertTokenizer.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens"], ["", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "AlbertTokenizer", "(", "SAMPLE_VOCAB", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"multi-sequence build\"", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ",", "text_2", ")", "\n", "\n", "assert", "encoded_sentence", "==", "[", "tokenizer", ".", "cls_token_id", "]", "+", "text", "+", "[", "tokenizer", ".", "sep_token_id", "]", "\n", "assert", "encoded_pair", "==", "[", "tokenizer", ".", "cls_token_id", "]", "+", "text", "+", "[", "tokenizer", ".", "sep_token_id", "]", "+", "text_2", "+", "[", "\n", "tokenizer", ".", "sep_token_id", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_t5.T5ModelTest.setUp": [[195, 198], ["T5ModelTest.T5ModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "T5ModelTest", ".", "T5ModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "T5Config", ",", "d_model", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_t5.T5ModelTest.test_config": [[199, 201], ["test_modeling_t5.T5ModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_t5.T5ModelTest.test_t5_model": [[202, 205], ["test_modeling_t5.T5ModelTest.model_tester.prepare_config_and_inputs", "test_modeling_t5.T5ModelTest.model_tester.create_and_check_t5_model"], "methods", ["None"], ["", "def", "test_t5_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_t5_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_t5.T5ModelTest.test_with_lm_head": [[206, 209], ["test_modeling_t5.T5ModelTest.model_tester.prepare_config_and_inputs", "test_modeling_t5.T5ModelTest.model_tester.create_and_check_t5_with_lm_head"], "methods", ["None"], ["", "def", "test_with_lm_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_t5_with_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_t5.T5ModelTest.test_model_from_pretrained": [[210, 215], ["list", "T5Model.from_pretrained", "test_modeling_t5.T5ModelTest.assertIsNotNone", "T5_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "T5_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "T5Model", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xlnet.TFXLNetModelTest.setUp": [[368, 371], ["TFXLNetModelTest.TFXLNetModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFXLNetModelTest", ".", "TFXLNetModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "XLNetConfig", ",", "d_inner", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xlnet.TFXLNetModelTest.test_config": [[372, 374], ["test_modeling_tf_xlnet.TFXLNetModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xlnet.TFXLNetModelTest.test_xlnet_base_model": [[375, 379], ["test_modeling_tf_xlnet.TFXLNetModelTest.model_tester.set_seed", "test_modeling_tf_xlnet.TFXLNetModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_xlnet.TFXLNetModelTest.model_tester.create_and_check_xlnet_base_model"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed"], ["", "def", "test_xlnet_base_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_base_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xlnet.TFXLNetModelTest.test_xlnet_lm_head": [[380, 384], ["test_modeling_tf_xlnet.TFXLNetModelTest.model_tester.set_seed", "test_modeling_tf_xlnet.TFXLNetModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_xlnet.TFXLNetModelTest.model_tester.create_and_check_xlnet_lm_head"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed"], ["", "def", "test_xlnet_lm_head", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xlnet.TFXLNetModelTest.test_xlnet_sequence_classif": [[385, 389], ["test_modeling_tf_xlnet.TFXLNetModelTest.model_tester.set_seed", "test_modeling_tf_xlnet.TFXLNetModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_xlnet.TFXLNetModelTest.model_tester.create_and_check_xlnet_sequence_classif"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed"], ["", "def", "test_xlnet_sequence_classif", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_sequence_classif", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xlnet.TFXLNetModelTest.test_xlnet_token_classification": [[390, 393], ["test_modeling_tf_xlnet.TFXLNetModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_xlnet.TFXLNetModelTest.model_tester.create_and_check_xlnet_for_token_classification"], "methods", ["None"], ["", "def", "test_xlnet_token_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_for_token_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xlnet.TFXLNetModelTest.test_xlnet_qa": [[394, 398], ["test_modeling_tf_xlnet.TFXLNetModelTest.model_tester.set_seed", "test_modeling_tf_xlnet.TFXLNetModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_xlnet.TFXLNetModelTest.model_tester.create_and_check_xlnet_qa"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed"], ["", "def", "test_xlnet_qa", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", ".", "set_seed", "(", ")", "\n", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlnet_qa", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xlnet.TFXLNetModelTest.test_model_from_pretrained": [[399, 404], ["list", "TFXLNetModel.from_pretrained", "test_modeling_tf_xlnet.TFXLNetModelTest.assertIsNotNone", "TF_XLNET_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "TF_XLNET_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TFXLNetModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.setUp": [[27, 29], ["tempfile.mkdtemp"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "tmpdirname", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.tearDown": [[30, 32], ["shutil.rmtree"], "methods", ["None"], ["", "def", "tearDown", "(", "self", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "self", ".", "tmpdirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.get_tokenizer": [[33, 35], ["None"], "methods", ["None"], ["", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.get_input_output_texts": [[36, 38], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_tokenizers_common_properties": [[39, 60], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.assertTrue", "test_tokenization_common.TokenizerTesterMixin.assertTrue", "test_tokenization_common.TokenizerTesterMixin.assertTrue", "test_tokenization_common.TokenizerTesterMixin.assertTrue", "hasattr", "hasattr", "test_tokenization_common.TokenizerTesterMixin.assertTrue", "hasattr", "hasattr", "hasattr"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer"], ["", "def", "test_tokenizers_common_properties", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "attributes_list", "=", "[", "\n", "\"bos_token\"", ",", "\n", "\"eos_token\"", ",", "\n", "\"unk_token\"", ",", "\n", "\"sep_token\"", ",", "\n", "\"pad_token\"", ",", "\n", "\"cls_token\"", ",", "\n", "\"mask_token\"", ",", "\n", "]", "\n", "for", "attr", "in", "attributes_list", ":", "\n", "            ", "self", ".", "assertTrue", "(", "hasattr", "(", "tokenizer", ",", "attr", ")", ")", "\n", "self", ".", "assertTrue", "(", "hasattr", "(", "tokenizer", ",", "attr", "+", "\"_id\"", ")", ")", "\n", "\n", "", "self", ".", "assertTrue", "(", "hasattr", "(", "tokenizer", ",", "\"additional_special_tokens\"", ")", ")", "\n", "self", ".", "assertTrue", "(", "hasattr", "(", "tokenizer", ",", "\"additional_special_tokens_ids\"", ")", ")", "\n", "\n", "attributes_list", "=", "[", "\"max_len\"", ",", "\"init_inputs\"", ",", "\"init_kwargs\"", ",", "\"added_tokens_encoder\"", ",", "\"added_tokens_decoder\"", "]", "\n", "for", "attr", "in", "attributes_list", ":", "\n", "            ", "self", ".", "assertTrue", "(", "hasattr", "(", "tokenizer", ",", "attr", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_save_and_load_tokenizer": [[61, 81], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.assertNotEqual", "test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.encode", "tempfile.TemporaryDirectory", "test_tokenization_common.TokenizerTesterMixin.save_pretrained", "test_tokenization_common.TokenizerTesterMixin.tokenizer_class.from_pretrained", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.assertListEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.tokenizer_class.from_pretrained", "test_tokenization_common.TokenizerTesterMixin.assertEqual"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "test_save_and_load_tokenizer", "(", "self", ")", ":", "\n", "# safety check on max_len default value so we are sure the test works", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "self", ".", "assertNotEqual", "(", "tokenizer", ".", "max_len", ",", "42", ")", "\n", "\n", "# Now let's start the test", "\n", "tokenizer", "=", "self", ".", "get_tokenizer", "(", "max_len", "=", "42", ")", "\n", "\n", "before_tokens", "=", "tokenizer", ".", "encode", "(", "\"He is very happy, UNwant\\u00E9d,running\"", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdirname", ":", "\n", "            ", "tokenizer", ".", "save_pretrained", "(", "tmpdirname", ")", "\n", "tokenizer", "=", "self", ".", "tokenizer_class", ".", "from_pretrained", "(", "tmpdirname", ")", "\n", "\n", "after_tokens", "=", "tokenizer", ".", "encode", "(", "\"He is very happy, UNwant\\u00E9d,running\"", ",", "add_special_tokens", "=", "False", ")", "\n", "self", ".", "assertListEqual", "(", "before_tokens", ",", "after_tokens", ")", "\n", "\n", "self", ".", "assertEqual", "(", "tokenizer", ".", "max_len", ",", "42", ")", "\n", "tokenizer", "=", "self", ".", "tokenizer_class", ".", "from_pretrained", "(", "tmpdirname", ",", "max_len", "=", "43", ")", "\n", "self", ".", "assertEqual", "(", "tokenizer", ".", "max_len", ",", "43", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_pickle_tokenizer": [[82, 101], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.assertIsNotNone", "test_tokenization_common.TokenizerTesterMixin.tokenize", "pickle.load.tokenize", "test_tokenization_common.TokenizerTesterMixin.assertListEqual", "tempfile.TemporaryDirectory", "os.path.join", "open", "pickle.dump", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "", "def", "test_pickle_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "self", ".", "assertIsNotNone", "(", "tokenizer", ")", "\n", "\n", "text", "=", "\"Munich and Berlin are nice cities\"", "\n", "subwords", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdirname", ":", "\n", "\n", "            ", "filename", "=", "os", ".", "path", ".", "join", "(", "tmpdirname", ",", "\"tokenizer.bin\"", ")", "\n", "with", "open", "(", "filename", ",", "\"wb\"", ")", "as", "handle", ":", "\n", "                ", "pickle", ".", "dump", "(", "tokenizer", ",", "handle", ")", "\n", "\n", "", "with", "open", "(", "filename", ",", "\"rb\"", ")", "as", "handle", ":", "\n", "                ", "tokenizer_new", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "\n", "", "", "subwords_loaded", "=", "tokenizer_new", ".", "tokenize", "(", "text", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "subwords", ",", "subwords_loaded", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_added_tokens_do_lower_case": [[102, 141], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.tokenize", "test_tokenization_common.TokenizerTesterMixin.add_tokens", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.tokenize", "test_tokenization_common.TokenizerTesterMixin.tokenize", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertNotEqual", "test_tokenization_common.TokenizerTesterMixin.assertListEqual", "test_tokenization_common.TokenizerTesterMixin.tokenize", "test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.add_tokens", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.tokenize", "test_tokenization_common.TokenizerTesterMixin.tokenize", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertNotEqual", "test_tokenization_common.TokenizerTesterMixin.assertNotEqual", "len", "len", "len", "len", "test_tokenization_common.TokenizerTesterMixin.assertTrue", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.add_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.add_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "test_added_tokens_do_lower_case", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", "do_lower_case", "=", "True", ")", "\n", "\n", "special_token", "=", "tokenizer", ".", "all_special_tokens", "[", "0", "]", "\n", "\n", "text", "=", "special_token", "+", "\" aaaaa bbbbbb low cccccccccdddddddd l \"", "+", "special_token", "\n", "text2", "=", "special_token", "+", "\" AAAAA BBBBBB low CCCCCCCCCDDDDDDDD l \"", "+", "special_token", "\n", "\n", "toks0", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "# toks before adding new_toks", "\n", "\n", "new_toks", "=", "[", "\"aaaaa bbbbbb\"", ",", "\"cccccccccdddddddd\"", ",", "\"AAAAA BBBBBB\"", ",", "\"CCCCCCCCCDDDDDDDD\"", "]", "\n", "added", "=", "tokenizer", ".", "add_tokens", "(", "new_toks", ")", "\n", "self", ".", "assertEqual", "(", "added", ",", "2", ")", "\n", "\n", "toks", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "toks2", "=", "tokenizer", ".", "tokenize", "(", "text2", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "toks", ")", ",", "len", "(", "toks2", ")", ")", "\n", "self", ".", "assertNotEqual", "(", "len", "(", "toks", ")", ",", "len", "(", "toks0", ")", ")", "# toks0 should be longer", "\n", "self", ".", "assertListEqual", "(", "toks", ",", "toks2", ")", "\n", "\n", "# Check that none of the special tokens are lowercased", "\n", "sequence_with_special_tokens", "=", "\"A \"", "+", "\" yEs \"", ".", "join", "(", "tokenizer", ".", "all_special_tokens", ")", "+", "\" B\"", "\n", "tokenized_sequence", "=", "tokenizer", ".", "tokenize", "(", "sequence_with_special_tokens", ")", "\n", "\n", "for", "special_token", "in", "tokenizer", ".", "all_special_tokens", ":", "\n", "            ", "self", ".", "assertTrue", "(", "special_token", "in", "tokenized_sequence", ")", "\n", "\n", "", "tokenizer", "=", "self", ".", "get_tokenizer", "(", "do_lower_case", "=", "False", ")", "\n", "\n", "added", "=", "tokenizer", ".", "add_tokens", "(", "new_toks", ")", "\n", "self", ".", "assertEqual", "(", "added", ",", "4", ")", "\n", "\n", "toks", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "toks2", "=", "tokenizer", ".", "tokenize", "(", "text2", ")", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "toks", ")", ",", "len", "(", "toks2", ")", ")", "# Length should still be the same", "\n", "self", ".", "assertNotEqual", "(", "len", "(", "toks", ")", ",", "len", "(", "toks0", ")", ")", "\n", "self", ".", "assertNotEqual", "(", "toks", "[", "1", "]", ",", "toks2", "[", "1", "]", ")", "# But at least the first non-special tokens should differ", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_add_tokens_tokenizer": [[142, 190], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "len", "test_tokenization_common.TokenizerTesterMixin.assertNotEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.add_tokens", "len", "test_tokenization_common.TokenizerTesterMixin.assertNotEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.decode", "test_tokenization_common.TokenizerTesterMixin.assertGreaterEqual", "test_tokenization_common.TokenizerTesterMixin.assertGreater", "test_tokenization_common.TokenizerTesterMixin.assertGreater", "test_tokenization_common.TokenizerTesterMixin.add_special_tokens", "len", "test_tokenization_common.TokenizerTesterMixin.assertNotEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.decode", "test_tokenization_common.TokenizerTesterMixin.assertGreaterEqual", "test_tokenization_common.TokenizerTesterMixin.assertGreater", "test_tokenization_common.TokenizerTesterMixin.assertGreater", "test_tokenization_common.TokenizerTesterMixin.assertGreater", "test_tokenization_common.TokenizerTesterMixin.assertGreater", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "len", "len", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.add_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.add_special_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "test_add_tokens_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "\n", "vocab_size", "=", "tokenizer", ".", "vocab_size", "\n", "all_size", "=", "len", "(", "tokenizer", ")", "\n", "\n", "self", ".", "assertNotEqual", "(", "vocab_size", ",", "0", ")", "\n", "self", ".", "assertEqual", "(", "vocab_size", ",", "all_size", ")", "\n", "\n", "new_toks", "=", "[", "\"aaaaa bbbbbb\"", ",", "\"cccccccccdddddddd\"", "]", "\n", "added_toks", "=", "tokenizer", ".", "add_tokens", "(", "new_toks", ")", "\n", "vocab_size_2", "=", "tokenizer", ".", "vocab_size", "\n", "all_size_2", "=", "len", "(", "tokenizer", ")", "\n", "\n", "self", ".", "assertNotEqual", "(", "vocab_size_2", ",", "0", ")", "\n", "self", ".", "assertEqual", "(", "vocab_size", ",", "vocab_size_2", ")", "\n", "self", ".", "assertEqual", "(", "added_toks", ",", "len", "(", "new_toks", ")", ")", "\n", "self", ".", "assertEqual", "(", "all_size_2", ",", "all_size", "+", "len", "(", "new_toks", ")", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "encode", "(", "\"aaaaa bbbbbb low cccccccccdddddddd l\"", ",", "add_special_tokens", "=", "False", ")", "\n", "out_string", "=", "tokenizer", ".", "decode", "(", "tokens", ")", "\n", "\n", "self", ".", "assertGreaterEqual", "(", "len", "(", "tokens", ")", ",", "4", ")", "\n", "self", ".", "assertGreater", "(", "tokens", "[", "0", "]", ",", "tokenizer", ".", "vocab_size", "-", "1", ")", "\n", "self", ".", "assertGreater", "(", "tokens", "[", "-", "2", "]", ",", "tokenizer", ".", "vocab_size", "-", "1", ")", "\n", "\n", "new_toks_2", "=", "{", "\"eos_token\"", ":", "\">>>>|||<||<<|<<\"", ",", "\"pad_token\"", ":", "\"<<<<<|||>|>>>>|>\"", "}", "\n", "added_toks_2", "=", "tokenizer", ".", "add_special_tokens", "(", "new_toks_2", ")", "\n", "vocab_size_3", "=", "tokenizer", ".", "vocab_size", "\n", "all_size_3", "=", "len", "(", "tokenizer", ")", "\n", "\n", "self", ".", "assertNotEqual", "(", "vocab_size_3", ",", "0", ")", "\n", "self", ".", "assertEqual", "(", "vocab_size", ",", "vocab_size_3", ")", "\n", "self", ".", "assertEqual", "(", "added_toks_2", ",", "len", "(", "new_toks_2", ")", ")", "\n", "self", ".", "assertEqual", "(", "all_size_3", ",", "all_size_2", "+", "len", "(", "new_toks_2", ")", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "encode", "(", "\n", "\">>>>|||<||<<|<< aaaaabbbbbb low cccccccccdddddddd <<<<<|||>|>>>>|> l\"", ",", "add_special_tokens", "=", "False", "\n", ")", "\n", "out_string", "=", "tokenizer", ".", "decode", "(", "tokens", ")", "\n", "\n", "self", ".", "assertGreaterEqual", "(", "len", "(", "tokens", ")", ",", "6", ")", "\n", "self", ".", "assertGreater", "(", "tokens", "[", "0", "]", ",", "tokenizer", ".", "vocab_size", "-", "1", ")", "\n", "self", ".", "assertGreater", "(", "tokens", "[", "0", "]", ",", "tokens", "[", "1", "]", ")", "\n", "self", ".", "assertGreater", "(", "tokens", "[", "-", "2", "]", ",", "tokenizer", ".", "vocab_size", "-", "1", ")", "\n", "self", ".", "assertGreater", "(", "tokens", "[", "-", "2", "]", ",", "tokens", "[", "-", "3", "]", ")", "\n", "self", ".", "assertEqual", "(", "tokens", "[", "0", "]", ",", "tokenizer", ".", "eos_token_id", ")", "\n", "self", ".", "assertEqual", "(", "tokens", "[", "-", "2", "]", ",", "tokenizer", ".", "pad_token_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_add_special_tokens": [[191, 211], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.get_input_output_texts", "test_tokenization_common.TokenizerTesterMixin.add_special_tokens", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.decode", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_input_output_texts", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.add_special_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "test_add_special_tokens", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "input_text", ",", "output_text", "=", "self", ".", "get_input_output_texts", "(", ")", "\n", "\n", "special_token", "=", "\"[SPECIAL TOKEN]\"", "\n", "\n", "tokenizer", ".", "add_special_tokens", "(", "{", "\"cls_token\"", ":", "special_token", "}", ")", "\n", "encoded_special_token", "=", "tokenizer", ".", "encode", "(", "special_token", ",", "add_special_tokens", "=", "False", ")", "\n", "assert", "len", "(", "encoded_special_token", ")", "==", "1", "\n", "\n", "text", "=", "\" \"", ".", "join", "(", "[", "input_text", ",", "special_token", ",", "output_text", "]", ")", "\n", "encoded", "=", "tokenizer", ".", "encode", "(", "text", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "input_encoded", "=", "tokenizer", ".", "encode", "(", "input_text", ",", "add_special_tokens", "=", "False", ")", "\n", "output_encoded", "=", "tokenizer", ".", "encode", "(", "output_text", ",", "add_special_tokens", "=", "False", ")", "\n", "special_token_id", "=", "tokenizer", ".", "encode", "(", "special_token", ",", "add_special_tokens", "=", "False", ")", "\n", "assert", "encoded", "==", "input_encoded", "+", "special_token_id", "+", "output_encoded", "\n", "\n", "decoded", "=", "tokenizer", ".", "decode", "(", "encoded", ",", "skip_special_tokens", "=", "True", ")", "\n", "assert", "special_token", "not", "in", "decoded", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_required_methods_tokenizer": [[212, 228], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.get_input_output_texts", "test_tokenization_common.TokenizerTesterMixin.tokenize", "test_tokenization_common.TokenizerTesterMixin.convert_tokens_to_ids", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.assertListEqual", "test_tokenization_common.TokenizerTesterMixin.convert_ids_to_tokens", "test_tokenization_common.TokenizerTesterMixin.decode", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertNotEqual", "test_tokenization_common.TokenizerTesterMixin.assertIsInstance", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_input_output_texts", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_ids_to_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "test_required_methods_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "input_text", ",", "output_text", "=", "self", ".", "get_input_output_texts", "(", ")", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "input_text", ")", "\n", "ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "ids_2", "=", "tokenizer", ".", "encode", "(", "input_text", ",", "add_special_tokens", "=", "False", ")", "\n", "self", ".", "assertListEqual", "(", "ids", ",", "ids_2", ")", "\n", "\n", "tokens_2", "=", "tokenizer", ".", "convert_ids_to_tokens", "(", "ids", ")", "\n", "text_2", "=", "tokenizer", ".", "decode", "(", "ids", ")", "\n", "\n", "self", ".", "assertEqual", "(", "text_2", ",", "output_text", ")", "\n", "\n", "self", ".", "assertNotEqual", "(", "len", "(", "tokens_2", ")", ",", "0", ")", "\n", "self", ".", "assertIsInstance", "(", "text_2", ",", "str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_encode_decode_with_spaces": [[229, 238], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.add_tokens", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.decode", "test_tokenization_common.TokenizerTesterMixin.assertEqual"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.add_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.decode"], ["", "def", "test_encode_decode_with_spaces", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "\n", "new_toks", "=", "[", "\"[ABC]\"", ",", "\"[DEF]\"", ",", "\"GHI IHG\"", "]", "\n", "tokenizer", ".", "add_tokens", "(", "new_toks", ")", "\n", "input", "=", "\"[ABC] [DEF] [ABC] GHI IHG [DEF]\"", "\n", "encoded", "=", "tokenizer", ".", "encode", "(", "input", ",", "add_special_tokens", "=", "False", ")", "\n", "decoded", "=", "tokenizer", ".", "decode", "(", "encoded", ")", "\n", "self", ".", "assertEqual", "(", "decoded", ",", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_pretrained_model_lists": [[239, 247], ["list", "test_tokenization_common.TokenizerTesterMixin.tokenizer_class.pretrained_vocab_files_map.items", "test_tokenization_common.TokenizerTesterMixin.tokenizer_class.max_model_input_sizes.keys", "weights_lists_2.append", "test_tokenization_common.TokenizerTesterMixin.assertListEqual", "list", "map_list.keys"], "methods", ["None"], ["", "def", "test_pretrained_model_lists", "(", "self", ")", ":", "\n", "        ", "weights_list", "=", "list", "(", "self", ".", "tokenizer_class", ".", "max_model_input_sizes", ".", "keys", "(", ")", ")", "\n", "weights_lists_2", "=", "[", "]", "\n", "for", "file_id", ",", "map_list", "in", "self", ".", "tokenizer_class", ".", "pretrained_vocab_files_map", ".", "items", "(", ")", ":", "\n", "            ", "weights_lists_2", ".", "append", "(", "list", "(", "map_list", ".", "keys", "(", ")", ")", ")", "\n", "\n", "", "for", "weights_list_2", "in", "weights_lists_2", ":", "\n", "            ", "self", ".", "assertListEqual", "(", "weights_list", ",", "weights_list_2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_mask_output": [[248, 257], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.encode_plus", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.build_inputs_with_special_tokens.__qualname__.split", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus"], ["", "", "def", "test_mask_output", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "\n", "if", "tokenizer", ".", "build_inputs_with_special_tokens", ".", "__qualname__", ".", "split", "(", "\".\"", ")", "[", "0", "]", "!=", "\"PreTrainedTokenizer\"", ":", "\n", "            ", "seq_0", "=", "\"Test this method.\"", "\n", "seq_1", "=", "\"With these inputs.\"", "\n", "information", "=", "tokenizer", ".", "encode_plus", "(", "seq_0", ",", "seq_1", ",", "add_special_tokens", "=", "True", ")", "\n", "sequences", ",", "mask", "=", "information", "[", "\"input_ids\"", "]", ",", "information", "[", "\"token_type_ids\"", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "sequences", ")", ",", "len", "(", "mask", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_number_of_added_tokens": [[258, 270], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.encode", "len", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.num_added_tokens", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.num_added_tokens"], ["", "", "def", "test_number_of_added_tokens", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "\n", "seq_0", "=", "\"Test this method.\"", "\n", "seq_1", "=", "\"With these inputs.\"", "\n", "\n", "sequences", "=", "tokenizer", ".", "encode", "(", "seq_0", ",", "seq_1", ",", "add_special_tokens", "=", "False", ")", "\n", "attached_sequences", "=", "tokenizer", ".", "encode", "(", "seq_0", ",", "seq_1", ",", "add_special_tokens", "=", "True", ")", "\n", "\n", "# Method is implemented (e.g. not GPT-2)", "\n", "if", "len", "(", "attached_sequences", ")", "!=", "2", ":", "\n", "            ", "self", ".", "assertEqual", "(", "tokenizer", ".", "num_added_tokens", "(", "pair", "=", "True", ")", ",", "len", "(", "attached_sequences", ")", "-", "len", "(", "sequences", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_maximum_encoding_length_single_input": [[271, 291], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.num_added_tokens", "test_tokenization_common.TokenizerTesterMixin.encode_plus", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "len", "len", "len", "test_tokenization_common.TokenizerTesterMixin.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.num_added_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens"], ["", "", "def", "test_maximum_encoding_length_single_input", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "\n", "seq_0", "=", "\"This is a sentence to be encoded.\"", "\n", "stride", "=", "2", "\n", "\n", "sequence", "=", "tokenizer", ".", "encode", "(", "seq_0", ",", "add_special_tokens", "=", "False", ")", "\n", "num_added_tokens", "=", "tokenizer", ".", "num_added_tokens", "(", ")", "\n", "total_length", "=", "len", "(", "sequence", ")", "+", "num_added_tokens", "\n", "information", "=", "tokenizer", ".", "encode_plus", "(", "\n", "seq_0", ",", "max_length", "=", "total_length", "-", "2", ",", "add_special_tokens", "=", "True", ",", "stride", "=", "stride", ",", "return_overflowing_tokens", "=", "True", ",", "\n", ")", "\n", "\n", "truncated_sequence", "=", "information", "[", "\"input_ids\"", "]", "\n", "overflowing_tokens", "=", "information", "[", "\"overflowing_tokens\"", "]", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "overflowing_tokens", ")", ",", "2", "+", "stride", ")", "\n", "self", ".", "assertEqual", "(", "overflowing_tokens", ",", "sequence", "[", "-", "(", "2", "+", "stride", ")", ":", "]", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "truncated_sequence", ")", ",", "total_length", "-", "2", ")", "\n", "self", ".", "assertEqual", "(", "truncated_sequence", ",", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "sequence", "[", ":", "-", "2", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_maximum_encoding_length_pair_input": [[292, 335], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.build_inputs_with_special_tokens", "test_tokenization_common.TokenizerTesterMixin.encode_plus", "test_tokenization_common.TokenizerTesterMixin.encode_plus", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.encode", "len", "len", "test_tokenization_common.TokenizerTesterMixin.encode", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode"], ["", "def", "test_maximum_encoding_length_pair_input", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "\n", "seq_0", "=", "\"This is a sentence to be encoded.\"", "\n", "seq_1", "=", "\"This is another sentence to be encoded.\"", "\n", "stride", "=", "2", "\n", "\n", "sequence_0_no_special_tokens", "=", "tokenizer", ".", "encode", "(", "seq_0", ",", "add_special_tokens", "=", "False", ")", "\n", "sequence_1_no_special_tokens", "=", "tokenizer", ".", "encode", "(", "seq_1", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "sequence", "=", "tokenizer", ".", "encode", "(", "seq_0", ",", "seq_1", ",", "add_special_tokens", "=", "True", ")", "\n", "truncated_second_sequence", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "\n", "tokenizer", ".", "encode", "(", "seq_0", ",", "add_special_tokens", "=", "False", ")", ",", "tokenizer", ".", "encode", "(", "seq_1", ",", "add_special_tokens", "=", "False", ")", "[", ":", "-", "2", "]", ",", "\n", ")", "\n", "\n", "information", "=", "tokenizer", ".", "encode_plus", "(", "\n", "seq_0", ",", "\n", "seq_1", ",", "\n", "max_length", "=", "len", "(", "sequence", ")", "-", "2", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", "stride", "=", "stride", ",", "\n", "truncation_strategy", "=", "\"only_second\"", ",", "\n", "return_overflowing_tokens", "=", "True", ",", "\n", ")", "\n", "information_first_truncated", "=", "tokenizer", ".", "encode_plus", "(", "\n", "seq_0", ",", "\n", "seq_1", ",", "\n", "max_length", "=", "len", "(", "sequence", ")", "-", "2", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", "stride", "=", "stride", ",", "\n", "truncation_strategy", "=", "\"only_first\"", ",", "\n", "return_overflowing_tokens", "=", "True", ",", "\n", ")", "\n", "\n", "truncated_sequence", "=", "information", "[", "\"input_ids\"", "]", "\n", "overflowing_tokens", "=", "information", "[", "\"overflowing_tokens\"", "]", "\n", "overflowing_tokens_first_truncated", "=", "information_first_truncated", "[", "\"overflowing_tokens\"", "]", "\n", "\n", "self", ".", "assertEqual", "(", "len", "(", "overflowing_tokens", ")", ",", "2", "+", "stride", ")", "\n", "self", ".", "assertEqual", "(", "overflowing_tokens", ",", "sequence_1_no_special_tokens", "[", "-", "(", "2", "+", "stride", ")", ":", "]", ")", "\n", "self", ".", "assertEqual", "(", "overflowing_tokens_first_truncated", ",", "sequence_0_no_special_tokens", "[", "-", "(", "2", "+", "stride", ")", ":", "]", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "truncated_sequence", ")", ",", "len", "(", "sequence", ")", "-", "2", ")", "\n", "self", ".", "assertEqual", "(", "truncated_sequence", ",", "truncated_second_sequence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_encode_input_type": [[336, 347], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.tokenize", "test_tokenization_common.TokenizerTesterMixin.convert_tokens_to_ids", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.encode"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode"], ["", "def", "test_encode_input_type", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "\n", "sequence", "=", "\"Let's encode this sequence\"", "\n", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "sequence", ")", "\n", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "formatted_input", "=", "tokenizer", ".", "encode", "(", "sequence", ",", "add_special_tokens", "=", "True", ")", "\n", "\n", "self", ".", "assertEqual", "(", "tokenizer", ".", "encode", "(", "tokens", ",", "add_special_tokens", "=", "True", ")", ",", "formatted_input", ")", "\n", "self", ".", "assertEqual", "(", "tokenizer", ".", "encode", "(", "input_ids", ",", "add_special_tokens", "=", "True", ")", ",", "formatted_input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_special_tokens_mask": [[348, 399], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.encode_plus", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.encode_plus", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.encode_plus", "test_tokenization_common.TokenizerTesterMixin.get_special_tokens_mask", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "test_tokenization_common.TokenizerTesterMixin.assertEqual", "len", "len", "test_tokenization_common.TokenizerTesterMixin.encode", "test_tokenization_common.TokenizerTesterMixin.encode", "len", "len", "test_tokenization_common.TokenizerTesterMixin.add_special_tokens", "len", "len", "enumerate", "enumerate"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.get_special_tokens_mask", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.add_special_tokens"], ["", "def", "test_special_tokens_mask", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "\n", "sequence_0", "=", "\"Encode this.\"", "\n", "sequence_1", "=", "\"This one too please.\"", "\n", "\n", "# Testing single inputs", "\n", "encoded_sequence", "=", "tokenizer", ".", "encode", "(", "sequence_0", ",", "add_special_tokens", "=", "False", ")", "\n", "encoded_sequence_dict", "=", "tokenizer", ".", "encode_plus", "(", "\n", "sequence_0", ",", "add_special_tokens", "=", "True", ",", "return_special_tokens_mask", "=", "True", "\n", ")", "\n", "encoded_sequence_w_special", "=", "encoded_sequence_dict", "[", "\"input_ids\"", "]", "\n", "special_tokens_mask", "=", "encoded_sequence_dict", "[", "\"special_tokens_mask\"", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "special_tokens_mask", ")", ",", "len", "(", "encoded_sequence_w_special", ")", ")", "\n", "\n", "filtered_sequence", "=", "[", "\n", "(", "x", "if", "not", "special_tokens_mask", "[", "i", "]", "else", "None", ")", "for", "i", ",", "x", "in", "enumerate", "(", "encoded_sequence_w_special", ")", "\n", "]", "\n", "filtered_sequence", "=", "[", "x", "for", "x", "in", "filtered_sequence", "if", "x", "is", "not", "None", "]", "\n", "self", ".", "assertEqual", "(", "encoded_sequence", ",", "filtered_sequence", ")", "\n", "\n", "# Testing inputs pairs", "\n", "encoded_sequence", "=", "tokenizer", ".", "encode", "(", "sequence_0", ",", "add_special_tokens", "=", "False", ")", "+", "tokenizer", ".", "encode", "(", "\n", "sequence_1", ",", "add_special_tokens", "=", "False", "\n", ")", "\n", "encoded_sequence_dict", "=", "tokenizer", ".", "encode_plus", "(", "\n", "sequence_0", ",", "sequence_1", ",", "add_special_tokens", "=", "True", ",", "return_special_tokens_mask", "=", "True", "\n", ")", "\n", "encoded_sequence_w_special", "=", "encoded_sequence_dict", "[", "\"input_ids\"", "]", "\n", "special_tokens_mask", "=", "encoded_sequence_dict", "[", "\"special_tokens_mask\"", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "special_tokens_mask", ")", ",", "len", "(", "encoded_sequence_w_special", ")", ")", "\n", "\n", "filtered_sequence", "=", "[", "\n", "(", "x", "if", "not", "special_tokens_mask", "[", "i", "]", "else", "None", ")", "for", "i", ",", "x", "in", "enumerate", "(", "encoded_sequence_w_special", ")", "\n", "]", "\n", "filtered_sequence", "=", "[", "x", "for", "x", "in", "filtered_sequence", "if", "x", "is", "not", "None", "]", "\n", "self", ".", "assertEqual", "(", "encoded_sequence", ",", "filtered_sequence", ")", "\n", "\n", "# Testing with already existing special tokens", "\n", "if", "tokenizer", ".", "cls_token_id", "==", "tokenizer", ".", "unk_token_id", "and", "tokenizer", ".", "cls_token_id", "==", "tokenizer", ".", "unk_token_id", ":", "\n", "            ", "tokenizer", ".", "add_special_tokens", "(", "{", "\"cls_token\"", ":", "\"</s>\"", ",", "\"sep_token\"", ":", "\"<s>\"", "}", ")", "\n", "", "encoded_sequence_dict", "=", "tokenizer", ".", "encode_plus", "(", "\n", "sequence_0", ",", "add_special_tokens", "=", "True", ",", "return_special_tokens_mask", "=", "True", "\n", ")", "\n", "encoded_sequence_w_special", "=", "encoded_sequence_dict", "[", "\"input_ids\"", "]", "\n", "special_tokens_mask_orig", "=", "encoded_sequence_dict", "[", "\"special_tokens_mask\"", "]", "\n", "special_tokens_mask", "=", "tokenizer", ".", "get_special_tokens_mask", "(", "\n", "encoded_sequence_w_special", ",", "already_has_special_tokens", "=", "True", "\n", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "special_tokens_mask", ")", ",", "len", "(", "encoded_sequence_w_special", ")", ")", "\n", "self", ".", "assertEqual", "(", "special_tokens_mask_orig", ",", "special_tokens_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_padding_to_max_length": [[400, 441], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.encode", "len", "test_tokenization_common.TokenizerTesterMixin.encode", "len", "test_tokenization_common.TokenizerTesterMixin.encode", "len", "test_tokenization_common.TokenizerTesterMixin.encode", "len", "test_tokenization_common.TokenizerTesterMixin.encode", "len", "test_tokenization_common.TokenizerTesterMixin.encode", "len", "test_tokenization_common.TokenizerTesterMixin.encode", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode"], ["", "def", "test_padding_to_max_length", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "\n", "sequence", "=", "\"Sequence\"", "\n", "padding_size", "=", "10", "\n", "padding_idx", "=", "tokenizer", ".", "pad_token_id", "\n", "\n", "# RIGHT PADDING - Check that it correctly pads when a maximum length is specified along with the padding flag set to True", "\n", "tokenizer", ".", "padding_side", "=", "\"right\"", "\n", "encoded_sequence", "=", "tokenizer", ".", "encode", "(", "sequence", ")", "\n", "sequence_length", "=", "len", "(", "encoded_sequence", ")", "\n", "padded_sequence", "=", "tokenizer", ".", "encode", "(", "sequence", ",", "max_length", "=", "sequence_length", "+", "padding_size", ",", "pad_to_max_length", "=", "True", ")", "\n", "padded_sequence_length", "=", "len", "(", "padded_sequence", ")", "\n", "assert", "sequence_length", "+", "padding_size", "==", "padded_sequence_length", "\n", "assert", "encoded_sequence", "+", "[", "padding_idx", "]", "*", "padding_size", "==", "padded_sequence", "\n", "\n", "# LEFT PADDING - Check that it correctly pads when a maximum length is specified along with the padding flag set to True", "\n", "tokenizer", ".", "padding_side", "=", "\"left\"", "\n", "encoded_sequence", "=", "tokenizer", ".", "encode", "(", "sequence", ")", "\n", "sequence_length", "=", "len", "(", "encoded_sequence", ")", "\n", "padded_sequence", "=", "tokenizer", ".", "encode", "(", "sequence", ",", "max_length", "=", "sequence_length", "+", "padding_size", ",", "pad_to_max_length", "=", "True", ")", "\n", "padded_sequence_length", "=", "len", "(", "padded_sequence", ")", "\n", "assert", "sequence_length", "+", "padding_size", "==", "padded_sequence_length", "\n", "assert", "[", "padding_idx", "]", "*", "padding_size", "+", "encoded_sequence", "==", "padded_sequence", "\n", "\n", "# RIGHT & LEFT PADDING - Check that nothing is done when a maximum length is not specified", "\n", "encoded_sequence", "=", "tokenizer", ".", "encode", "(", "sequence", ")", "\n", "sequence_length", "=", "len", "(", "encoded_sequence", ")", "\n", "\n", "tokenizer", ".", "padding_side", "=", "\"right\"", "\n", "padded_sequence_right", "=", "tokenizer", ".", "encode", "(", "sequence", ",", "pad_to_max_length", "=", "True", ")", "\n", "padded_sequence_right_length", "=", "len", "(", "padded_sequence_right", ")", "\n", "\n", "tokenizer", ".", "padding_side", "=", "\"left\"", "\n", "padded_sequence_left", "=", "tokenizer", ".", "encode", "(", "sequence", ",", "pad_to_max_length", "=", "True", ")", "\n", "padded_sequence_left_length", "=", "len", "(", "padded_sequence_left", ")", "\n", "\n", "assert", "sequence_length", "==", "padded_sequence_right_length", "\n", "assert", "encoded_sequence", "==", "padded_sequence_right", "\n", "assert", "sequence_length", "==", "padded_sequence_left_length", "\n", "assert", "encoded_sequence", "==", "padded_sequence_left", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_common.TokenizerTesterMixin.test_encode_plus_with_padding": [[442, 496], ["test_tokenization_common.TokenizerTesterMixin.get_tokenizer", "test_tokenization_common.TokenizerTesterMixin.encode_plus", "len", "test_tokenization_common.TokenizerTesterMixin.encode_plus", "len", "test_tokenization_common.TokenizerTesterMixin.encode_plus", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode_plus"], ["", "def", "test_encode_plus_with_padding", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "\n", "sequence", "=", "\"Sequence\"", "\n", "padding_size", "=", "10", "\n", "padding_idx", "=", "tokenizer", ".", "pad_token_id", "\n", "token_type_padding_idx", "=", "tokenizer", ".", "pad_token_type_id", "\n", "\n", "encoded_sequence", "=", "tokenizer", ".", "encode_plus", "(", "sequence", ",", "return_special_tokens_mask", "=", "True", ")", "\n", "input_ids", "=", "encoded_sequence", "[", "\"input_ids\"", "]", "\n", "token_type_ids", "=", "encoded_sequence", "[", "\"token_type_ids\"", "]", "\n", "attention_mask", "=", "encoded_sequence", "[", "\"attention_mask\"", "]", "\n", "special_tokens_mask", "=", "encoded_sequence", "[", "\"special_tokens_mask\"", "]", "\n", "sequence_length", "=", "len", "(", "input_ids", ")", "\n", "\n", "# Test right padding", "\n", "tokenizer", ".", "padding_side", "=", "\"right\"", "\n", "padded_sequence", "=", "tokenizer", ".", "encode_plus", "(", "\n", "sequence", ",", "\n", "max_length", "=", "sequence_length", "+", "padding_size", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "padded_input_ids", "=", "padded_sequence", "[", "\"input_ids\"", "]", "\n", "padded_token_type_ids", "=", "padded_sequence", "[", "\"token_type_ids\"", "]", "\n", "padded_attention_mask", "=", "padded_sequence", "[", "\"attention_mask\"", "]", "\n", "padded_special_tokens_mask", "=", "padded_sequence", "[", "\"special_tokens_mask\"", "]", "\n", "padded_sequence_length", "=", "len", "(", "padded_input_ids", ")", "\n", "\n", "assert", "sequence_length", "+", "padding_size", "==", "padded_sequence_length", "\n", "assert", "input_ids", "+", "[", "padding_idx", "]", "*", "padding_size", "==", "padded_input_ids", "\n", "assert", "token_type_ids", "+", "[", "token_type_padding_idx", "]", "*", "padding_size", "==", "padded_token_type_ids", "\n", "assert", "attention_mask", "+", "[", "0", "]", "*", "padding_size", "==", "padded_attention_mask", "\n", "assert", "special_tokens_mask", "+", "[", "1", "]", "*", "padding_size", "==", "padded_special_tokens_mask", "\n", "\n", "# Test left padding", "\n", "tokenizer", ".", "padding_side", "=", "\"left\"", "\n", "padded_sequence", "=", "tokenizer", ".", "encode_plus", "(", "\n", "sequence", ",", "\n", "max_length", "=", "sequence_length", "+", "padding_size", ",", "\n", "pad_to_max_length", "=", "True", ",", "\n", "return_special_tokens_mask", "=", "True", ",", "\n", ")", "\n", "padded_input_ids", "=", "padded_sequence", "[", "\"input_ids\"", "]", "\n", "padded_token_type_ids", "=", "padded_sequence", "[", "\"token_type_ids\"", "]", "\n", "padded_attention_mask", "=", "padded_sequence", "[", "\"attention_mask\"", "]", "\n", "padded_special_tokens_mask", "=", "padded_sequence", "[", "\"special_tokens_mask\"", "]", "\n", "padded_sequence_length", "=", "len", "(", "padded_input_ids", ")", "\n", "\n", "assert", "sequence_length", "+", "padding_size", "==", "padded_sequence_length", "\n", "assert", "[", "padding_idx", "]", "*", "padding_size", "+", "input_ids", "==", "padded_input_ids", "\n", "assert", "[", "token_type_padding_idx", "]", "*", "padding_size", "+", "token_type_ids", "==", "padded_token_type_ids", "\n", "assert", "[", "0", "]", "*", "padding_size", "+", "attention_mask", "==", "padded_attention_mask", "\n", "assert", "[", "1", "]", "*", "padding_size", "+", "special_tokens_mask", "==", "padded_special_tokens_mask", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_encoder_decoder.EncoderDecoderModelTest.test_model2model_from_pretrained": [[31, 40], ["logging.basicConfig", "list", "Model2Model.from_pretrained", "test_modeling_encoder_decoder.EncoderDecoderModelTest.assertIsInstance", "test_modeling_encoder_decoder.EncoderDecoderModelTest.assertIsInstance", "test_modeling_encoder_decoder.EncoderDecoderModelTest.assertEqual", "test_modeling_encoder_decoder.EncoderDecoderModelTest.assertEqual", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["    ", "@", "slow", "\n", "def", "test_model2model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "Model2Model", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ".", "encoder", ",", "BertModel", ")", "\n", "self", ".", "assertIsInstance", "(", "model", ".", "decoder", ",", "BertForMaskedLM", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "decoder", ".", "config", ".", "is_decoder", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "encoder", ".", "config", ".", "is_decoder", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_encoder_decoder.EncoderDecoderModelTest.test_model2model_from_pretrained_not_bert": [[41, 51], ["logging.basicConfig", "test_modeling_encoder_decoder.EncoderDecoderModelTest.assertRaises", "Model2Model.from_pretrained", "test_modeling_encoder_decoder.EncoderDecoderModelTest.assertRaises", "Model2Model.from_pretrained", "test_modeling_encoder_decoder.EncoderDecoderModelTest.assertRaises", "Model2Model.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "test_model2model_from_pretrained_not_bert", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "with", "self", ".", "assertRaises", "(", "ValueError", ")", ":", "\n", "            ", "_", "=", "Model2Model", ".", "from_pretrained", "(", "\"roberta\"", ")", "\n", "\n", "", "with", "self", ".", "assertRaises", "(", "ValueError", ")", ":", "\n", "            ", "_", "=", "Model2Model", ".", "from_pretrained", "(", "\"distilbert\"", ")", "\n", "\n", "", "with", "self", ".", "assertRaises", "(", "ValueError", ")", ":", "\n", "            ", "_", "=", "Model2Model", ".", "from_pretrained", "(", "\"does-not-exist\"", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_bert.TFBertModelTest.setUp": [[273, 276], ["TFBertModelTest.TFBertModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFBertModelTest", ".", "TFBertModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "BertConfig", ",", "hidden_size", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_bert.TFBertModelTest.test_config": [[277, 279], ["test_modeling_tf_bert.TFBertModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_bert.TFBertModelTest.test_bert_model": [[280, 283], ["test_modeling_tf_bert.TFBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_bert.TFBertModelTest.model_tester.create_and_check_bert_model"], "methods", ["None"], ["", "def", "test_bert_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_bert.TFBertModelTest.test_for_masked_lm": [[284, 287], ["test_modeling_tf_bert.TFBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_bert.TFBertModelTest.model_tester.create_and_check_bert_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_bert.TFBertModelTest.test_for_multiple_choice": [[288, 291], ["test_modeling_tf_bert.TFBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_bert.TFBertModelTest.model_tester.create_and_check_bert_for_multiple_choice"], "methods", ["None"], ["", "def", "test_for_multiple_choice", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_multiple_choice", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_bert.TFBertModelTest.test_for_next_sequence_prediction": [[292, 295], ["test_modeling_tf_bert.TFBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_bert.TFBertModelTest.model_tester.create_and_check_bert_for_next_sequence_prediction"], "methods", ["None"], ["", "def", "test_for_next_sequence_prediction", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_next_sequence_prediction", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_bert.TFBertModelTest.test_for_pretraining": [[296, 299], ["test_modeling_tf_bert.TFBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_bert.TFBertModelTest.model_tester.create_and_check_bert_for_pretraining"], "methods", ["None"], ["", "def", "test_for_pretraining", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_pretraining", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_bert.TFBertModelTest.test_for_question_answering": [[300, 303], ["test_modeling_tf_bert.TFBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_bert.TFBertModelTest.model_tester.create_and_check_bert_for_question_answering"], "methods", ["None"], ["", "def", "test_for_question_answering", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_question_answering", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_bert.TFBertModelTest.test_for_sequence_classification": [[304, 307], ["test_modeling_tf_bert.TFBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_bert.TFBertModelTest.model_tester.create_and_check_bert_for_sequence_classification"], "methods", ["None"], ["", "def", "test_for_sequence_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_sequence_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_bert.TFBertModelTest.test_for_token_classification": [[308, 311], ["test_modeling_tf_bert.TFBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_bert.TFBertModelTest.model_tester.create_and_check_bert_for_token_classification"], "methods", ["None"], ["", "def", "test_for_token_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_bert_for_token_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_bert.TFBertModelTest.test_model_from_pretrained": [[312, 318], ["TFBertModel.from_pretrained", "test_modeling_tf_bert.TFBertModelTest.assertIsNotNone"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "# for model_name in list(TF_BERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys())[:1]:", "\n", "        ", "for", "model_name", "in", "[", "\"bert-base-uncased\"", "]", ":", "\n", "            ", "model", "=", "TFBertModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xlm.XLMTokenizationTest.setUp": [[31, 67], ["super().setUp", "dict", "os.path.join", "os.path.join", "zip", "open", "fp.write", "open", "fp.write", "range", "json.dumps", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "XLMTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt", "\n", "vocab", "=", "[", "\n", "\"l\"", ",", "\n", "\"o\"", ",", "\n", "\"w\"", ",", "\n", "\"e\"", ",", "\n", "\"r\"", ",", "\n", "\"s\"", ",", "\n", "\"t\"", ",", "\n", "\"i\"", ",", "\n", "\"d\"", ",", "\n", "\"n\"", ",", "\n", "\"w</w>\"", ",", "\n", "\"r</w>\"", ",", "\n", "\"t</w>\"", ",", "\n", "\"lo\"", ",", "\n", "\"low\"", ",", "\n", "\"er</w>\"", ",", "\n", "\"low</w>\"", ",", "\n", "\"lowest</w>\"", ",", "\n", "\"newer</w>\"", ",", "\n", "\"wider</w>\"", ",", "\n", "\"<unk>\"", ",", "\n", "]", "\n", "vocab_tokens", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "merges", "=", "[", "\"l o 123\"", ",", "\"lo w 1456\"", ",", "\"e r</w> 1789\"", ",", "\"\"", "]", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "self", ".", "merges_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "\"merges_file\"", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "json", ".", "dumps", "(", "vocab_tokens", ")", ")", "\n", "", "with", "open", "(", "self", ".", "merges_file", ",", "\"w\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "\"\\n\"", ".", "join", "(", "merges", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xlm.XLMTokenizationTest.get_tokenizer": [[68, 70], ["transformers.tokenization_xlm.XLMTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "XLMTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xlm.XLMTokenizationTest.get_input_output_texts": [[71, 75], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "\"lower newer\"", "\n", "output_text", "=", "\"lower newer\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xlm.XLMTokenizationTest.test_full_tokenizer": [[76, 88], ["transformers.tokenization_xlm.XLMTokenizer", "transformers.tokenization_xlm.XLMTokenizer.tokenize", "test_tokenization_xlm.XLMTokenizationTest.assertListEqual", "test_tokenization_xlm.XLMTokenizationTest.assertListEqual", "transformers.tokenization_xlm.XLMTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "\"\"\" Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt \"\"\"", "\n", "tokenizer", "=", "XLMTokenizer", "(", "self", ".", "vocab_file", ",", "self", ".", "merges_file", ")", "\n", "\n", "text", "=", "\"lower\"", "\n", "bpe_tokens", "=", "[", "\"low\"", ",", "\"er</w>\"", "]", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "bpe_tokens", ")", "\n", "\n", "input_tokens", "=", "tokens", "+", "[", "\"<unk>\"", "]", "\n", "input_bpe_tokens", "=", "[", "14", ",", "15", ",", "20", "]", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "input_tokens", ")", ",", "input_bpe_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_xlm.XLMTokenizationTest.test_sequence_builders": [[89, 101], ["transformers.tokenization_xlm.XLMTokenizer.from_pretrained", "transformers.tokenization_xlm.XLMTokenizer.from_pretrained.encode", "transformers.tokenization_xlm.XLMTokenizer.from_pretrained.encode", "transformers.tokenization_xlm.XLMTokenizer.from_pretrained.build_inputs_with_special_tokens", "transformers.tokenization_xlm.XLMTokenizer.from_pretrained.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens"], ["", "@", "slow", "\n", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "XLMTokenizer", ".", "from_pretrained", "(", "\"xlm-mlm-en-2048\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ",", "add_special_tokens", "=", "False", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"multi-sequence build\"", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ",", "text_2", ")", "\n", "\n", "assert", "encoded_sentence", "==", "[", "1", "]", "+", "text", "+", "[", "1", "]", "\n", "assert", "encoded_pair", "==", "[", "1", "]", "+", "text", "+", "[", "1", "]", "+", "text_2", "+", "[", "1", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_roberta.TFRobertaModelTest.setUp": [[188, 191], ["TFRobertaModelTest.TFRobertaModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFRobertaModelTest", ".", "TFRobertaModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "RobertaConfig", ",", "hidden_size", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_roberta.TFRobertaModelTest.test_config": [[192, 194], ["test_modeling_tf_roberta.TFRobertaModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_roberta.TFRobertaModelTest.test_roberta_model": [[195, 198], ["test_modeling_tf_roberta.TFRobertaModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_roberta.TFRobertaModelTest.model_tester.create_and_check_roberta_model"], "methods", ["None"], ["", "def", "test_roberta_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_roberta_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_roberta.TFRobertaModelTest.test_for_masked_lm": [[199, 202], ["test_modeling_tf_roberta.TFRobertaModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_roberta.TFRobertaModelTest.model_tester.create_and_check_roberta_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_roberta_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_roberta.TFRobertaModelTest.test_model_from_pretrained": [[203, 208], ["list", "TFRobertaModel.from_pretrained", "test_modeling_tf_roberta.TFRobertaModelTest.assertIsNotNone", "TF_ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "TF_ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TFRobertaModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_roberta.TFRobertaModelIntegrationTest.test_inference_masked_lm": [[211, 224], ["TFRobertaForMaskedLM.from_pretrained", "tf.constant", "test_modeling_tf_roberta.TFRobertaModelIntegrationTest.assertEqual", "tf.constant", "test_modeling_tf_roberta.TFRobertaModelIntegrationTest.assertTrue", "TFRobertaForMaskedLM.from_pretrained.", "list", "numpy.allclose", "output[].numpy", "tf.constant.numpy", "output.numpy"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["    ", "@", "slow", "\n", "def", "test_inference_masked_lm", "(", "self", ")", ":", "\n", "        ", "model", "=", "TFRobertaForMaskedLM", ".", "from_pretrained", "(", "\"roberta-base\"", ")", "\n", "\n", "input_ids", "=", "tf", ".", "constant", "(", "[", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "]", ")", "\n", "output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "expected_shape", "=", "[", "1", ",", "11", ",", "50265", "]", "\n", "self", ".", "assertEqual", "(", "list", "(", "output", ".", "numpy", "(", ")", ".", "shape", ")", ",", "expected_shape", ")", "\n", "# compare the actual values for a slice.", "\n", "expected_slice", "=", "tf", ".", "constant", "(", "\n", "[", "[", "[", "33.8843", ",", "-", "4.3107", ",", "22.7779", "]", ",", "[", "4.6533", ",", "-", "2.8099", ",", "13.6252", "]", ",", "[", "1.8222", ",", "-", "3.6898", ",", "8.8600", "]", "]", "]", "\n", ")", "\n", "self", ".", "assertTrue", "(", "numpy", ".", "allclose", "(", "output", "[", ":", ",", ":", "3", ",", ":", "3", "]", ".", "numpy", "(", ")", ",", "expected_slice", ".", "numpy", "(", ")", ",", "atol", "=", "1e-3", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_roberta.TFRobertaModelIntegrationTest.test_inference_no_head": [[225, 236], ["TFRobertaModel.from_pretrained", "tf.constant", "tf.constant", "test_modeling_tf_roberta.TFRobertaModelIntegrationTest.assertTrue", "TFRobertaModel.from_pretrained.", "numpy.allclose", "output[].numpy", "tf.constant.numpy"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_inference_no_head", "(", "self", ")", ":", "\n", "        ", "model", "=", "TFRobertaModel", ".", "from_pretrained", "(", "\"roberta-base\"", ")", "\n", "\n", "input_ids", "=", "tf", ".", "constant", "(", "[", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "]", ")", "\n", "output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "# compare the actual values for a slice.", "\n", "expected_slice", "=", "tf", ".", "constant", "(", "\n", "[", "[", "[", "-", "0.0231", ",", "0.0782", ",", "0.0074", "]", ",", "[", "-", "0.1854", ",", "0.0539", ",", "-", "0.0174", "]", ",", "[", "0.0548", ",", "0.0799", ",", "0.1687", "]", "]", "]", "\n", ")", "\n", "self", ".", "assertTrue", "(", "numpy", ".", "allclose", "(", "output", "[", ":", ",", ":", "3", ",", ":", "3", "]", ".", "numpy", "(", ")", ",", "expected_slice", ".", "numpy", "(", ")", ",", "atol", "=", "1e-3", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_roberta.TFRobertaModelIntegrationTest.test_inference_classification_head": [[237, 247], ["TFRobertaForSequenceClassification.from_pretrained", "tf.constant", "test_modeling_tf_roberta.TFRobertaModelIntegrationTest.assertEqual", "tf.constant", "test_modeling_tf_roberta.TFRobertaModelIntegrationTest.assertTrue", "TFRobertaForSequenceClassification.from_pretrained.", "list", "numpy.allclose", "output.numpy", "tf.constant.numpy", "output.numpy"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_inference_classification_head", "(", "self", ")", ":", "\n", "        ", "model", "=", "TFRobertaForSequenceClassification", ".", "from_pretrained", "(", "\"roberta-large-mnli\"", ")", "\n", "\n", "input_ids", "=", "tf", ".", "constant", "(", "[", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "]", ")", "\n", "output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "expected_shape", "=", "[", "1", ",", "3", "]", "\n", "self", ".", "assertEqual", "(", "list", "(", "output", ".", "numpy", "(", ")", ".", "shape", ")", ",", "expected_shape", ")", "\n", "expected_tensor", "=", "tf", ".", "constant", "(", "[", "[", "-", "0.9469", ",", "0.3913", ",", "0.5118", "]", "]", ")", "\n", "self", ".", "assertTrue", "(", "numpy", ".", "allclose", "(", "output", ".", "numpy", "(", ")", ",", "expected_tensor", ".", "numpy", "(", ")", ",", "atol", "=", "1e-3", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization_tf.OptimizationFTest.assertListAlmostEqual": [[17, 21], ["test_optimization_tf.OptimizationFTest.assertEqual", "zip", "len", "len", "test_optimization_tf.OptimizationFTest.assertAlmostEqual"], "methods", ["None"], ["    ", "def", "assertListAlmostEqual", "(", "self", ",", "list1", ",", "list2", ",", "tol", ")", ":", "\n", "        ", "self", ".", "assertEqual", "(", "len", "(", "list1", ")", ",", "len", "(", "list2", ")", ")", "\n", "for", "a", ",", "b", "in", "zip", "(", "list1", ",", "list2", ")", ":", "\n", "            ", "self", ".", "assertAlmostEqual", "(", "a", ",", "b", ",", "delta", "=", "tol", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization_tf.OptimizationFTest.testGradientAccumulator": [[22, 35], ["GradientAccumulator", "GradientAccumulator.", "GradientAccumulator.", "GradientAccumulator.", "test_optimization_tf.OptimizationFTest.assertEqual", "test_optimization_tf.OptimizationFTest.assertEqual", "test_optimization_tf.OptimizationFTest.assertListAlmostEqual", "GradientAccumulator.reset", "test_optimization_tf.OptimizationFTest.assertEqual", "test_optimization_tf.OptimizationFTest.assertListAlmostEqual", "test_optimization_tf.OptimizationFTest.assertRaises", "GradientAccumulator.", "len", "GradientAccumulator.gradients[].numpy().tolist", "GradientAccumulator.gradients[].numpy().tolist", "tf.constant", "tf.constant", "tf.constant", "tf.constant", "tf.constant", "GradientAccumulator.gradients[].numpy", "GradientAccumulator.gradients[].numpy"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization_tf.OptimizationFTest.assertListAlmostEqual", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator.reset", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization_tf.OptimizationFTest.assertListAlmostEqual"], ["", "", "def", "testGradientAccumulator", "(", "self", ")", ":", "\n", "        ", "accumulator", "=", "GradientAccumulator", "(", ")", "\n", "accumulator", "(", "[", "tf", ".", "constant", "(", "[", "1.0", ",", "2.0", "]", ")", "]", ")", "\n", "accumulator", "(", "[", "tf", ".", "constant", "(", "[", "-", "2.0", ",", "1.0", "]", ")", "]", ")", "\n", "accumulator", "(", "[", "tf", ".", "constant", "(", "[", "-", "1.0", ",", "2.0", "]", ")", "]", ")", "\n", "with", "self", ".", "assertRaises", "(", "ValueError", ")", ":", "\n", "            ", "accumulator", "(", "[", "tf", ".", "constant", "(", "[", "1.0", ",", "1.0", "]", ")", ",", "tf", ".", "constant", "(", "[", "2.0", ",", "2.0", "]", ")", "]", ")", "\n", "", "self", ".", "assertEqual", "(", "accumulator", ".", "step", ",", "3", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "accumulator", ".", "gradients", ")", ",", "1", ")", "\n", "self", ".", "assertListAlmostEqual", "(", "accumulator", ".", "gradients", "[", "0", "]", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ",", "[", "-", "2.0", ",", "5.0", "]", ",", "tol", "=", "1e-2", ")", "\n", "accumulator", ".", "reset", "(", ")", "\n", "self", ".", "assertEqual", "(", "accumulator", ".", "step", ",", "0", ")", "\n", "self", ".", "assertListAlmostEqual", "(", "accumulator", ".", "gradients", "[", "0", "]", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ",", "[", "0.0", ",", "0.0", "]", ",", "tol", "=", "1e-2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_optimization_tf.OptimizationFTest.testGradientAccumulatorDistributionStrategy": [[36, 84], ["ops.enable_eager_execution_internal", "tf.config.experimental.list_physical_devices", "tf.config.experimental.set_virtual_device_configuration", "tf.config.experimental.list_logical_devices", "tf.distribute.MirroredStrategy", "test_optimization_tf.OptimizationFTest.testGradientAccumulatorDistributionStrategy.accumulate"], "methods", ["None"], ["", "def", "testGradientAccumulatorDistributionStrategy", "(", "self", ")", ":", "\n", "        ", "context", ".", "_context", "=", "None", "\n", "ops", ".", "enable_eager_execution_internal", "(", ")", "\n", "physical_devices", "=", "tf", ".", "config", ".", "experimental", ".", "list_physical_devices", "(", "\"CPU\"", ")", "\n", "tf", ".", "config", ".", "experimental", ".", "set_virtual_device_configuration", "(", "\n", "physical_devices", "[", "0", "]", ",", "\n", "[", "tf", ".", "config", ".", "experimental", ".", "VirtualDeviceConfiguration", "(", ")", ",", "tf", ".", "config", ".", "experimental", ".", "VirtualDeviceConfiguration", "(", ")", "]", ",", "\n", ")", "\n", "\n", "devices", "=", "tf", ".", "config", ".", "experimental", ".", "list_logical_devices", "(", "device_type", "=", "\"CPU\"", ")", "\n", "strategy", "=", "tf", ".", "distribute", ".", "MirroredStrategy", "(", "devices", "=", "[", "device", ".", "name", "for", "device", "in", "devices", "]", ")", "\n", "\n", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "            ", "accumulator", "=", "GradientAccumulator", "(", ")", "\n", "variable", "=", "tf", ".", "Variable", "(", "[", "4.0", ",", "3.0", "]", ")", "\n", "optimizer", "=", "create_optimizer", "(", "5e-5", ",", "10", ",", "5", ")", "\n", "gradient_placeholder", "=", "tf", ".", "Variable", "(", "[", "0.0", ",", "0.0", "]", ",", "trainable", "=", "False", ")", "\n", "\n", "", "def", "accumulate_on_replica", "(", "gradient", ")", ":", "\n", "            ", "accumulator", "(", "[", "gradient", "]", ")", "\n", "\n", "", "def", "apply_on_replica", "(", ")", ":", "\n", "            ", "optimizer", ".", "apply_gradients", "(", "list", "(", "zip", "(", "accumulator", ".", "gradients", ",", "[", "variable", "]", ")", ")", ",", "1.0", ")", "\n", "\n", "", "@", "tf", ".", "function", "\n", "def", "accumulate", "(", "grad1", ",", "grad2", ")", ":", "\n", "            ", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "                ", "gradient_placeholder", ".", "values", "[", "0", "]", ".", "assign", "(", "grad1", ")", "\n", "gradient_placeholder", ".", "values", "[", "1", "]", ".", "assign", "(", "grad2", ")", "\n", "strategy", ".", "experimental_run_v2", "(", "accumulate_on_replica", ",", "args", "=", "(", "gradient_placeholder", ",", ")", ")", "\n", "\n", "", "", "@", "tf", ".", "function", "\n", "def", "apply_grad", "(", ")", ":", "\n", "            ", "with", "strategy", ".", "scope", "(", ")", ":", "\n", "                ", "strategy", ".", "experimental_run_v2", "(", "apply_on_replica", ")", "\n", "\n", "", "", "accumulate", "(", "[", "1.0", ",", "2.0", "]", ",", "[", "-", "1.0", ",", "1.0", "]", ")", "\n", "accumulate", "(", "[", "3.0", ",", "-", "1.0", "]", ",", "[", "-", "1.0", ",", "-", "1.0", "]", ")", "\n", "accumulate", "(", "[", "-", "2.0", ",", "2.0", "]", ",", "[", "3.0", ",", "-", "2.0", "]", ")", "\n", "self", ".", "assertEqual", "(", "accumulator", ".", "step", ",", "3", ")", "\n", "self", ".", "assertListAlmostEqual", "(", "accumulator", ".", "_gradients", "[", "0", "]", ".", "values", "[", "0", "]", ".", "value", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ",", "[", "2.0", ",", "3.0", "]", ",", "tol", "=", "1e-2", ")", "\n", "self", ".", "assertListAlmostEqual", "(", "accumulator", ".", "_gradients", "[", "0", "]", ".", "values", "[", "1", "]", ".", "value", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ",", "[", "1.0", ",", "-", "2.0", "]", ",", "tol", "=", "1e-2", ")", "\n", "apply_grad", "(", ")", "\n", "self", ".", "assertListAlmostEqual", "(", "variable", ".", "value", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ",", "[", "4.0", ",", "3.0", "]", ",", "tol", "=", "1e-2", ")", "\n", "accumulator", ".", "reset", "(", ")", "\n", "self", ".", "assertEqual", "(", "accumulator", ".", "step", ",", "0", ")", "\n", "self", ".", "assertListAlmostEqual", "(", "accumulator", ".", "_gradients", "[", "0", "]", ".", "values", "[", "0", "]", ".", "value", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ",", "[", "0.0", ",", "0.0", "]", ",", "tol", "=", "1e-2", ")", "\n", "self", ".", "assertListAlmostEqual", "(", "accumulator", ".", "_gradients", "[", "0", "]", ".", "values", "[", "1", "]", ".", "value", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ",", "[", "0.0", ",", "0.0", "]", ",", "tol", "=", "1e-2", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_openai_gpt.TFOpenAIGPTModelTest.setUp": [[214, 217], ["TFOpenAIGPTModelTest.TFOpenAIGPTModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFOpenAIGPTModelTest", ".", "TFOpenAIGPTModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "OpenAIGPTConfig", ",", "n_embd", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_openai_gpt.TFOpenAIGPTModelTest.test_config": [[218, 220], ["test_modeling_tf_openai_gpt.TFOpenAIGPTModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_openai_gpt.TFOpenAIGPTModelTest.test_openai_gpt_model": [[221, 224], ["test_modeling_tf_openai_gpt.TFOpenAIGPTModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_openai_gpt.TFOpenAIGPTModelTest.model_tester.create_and_check_openai_gpt_model"], "methods", ["None"], ["", "def", "test_openai_gpt_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_openai_gpt_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_openai_gpt.TFOpenAIGPTModelTest.test_openai_gpt_lm_head": [[225, 228], ["test_modeling_tf_openai_gpt.TFOpenAIGPTModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_openai_gpt.TFOpenAIGPTModelTest.model_tester.create_and_check_openai_gpt_lm_head"], "methods", ["None"], ["", "def", "test_openai_gpt_lm_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_openai_gpt_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_openai_gpt.TFOpenAIGPTModelTest.test_openai_gpt_double_head": [[229, 232], ["test_modeling_tf_openai_gpt.TFOpenAIGPTModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_openai_gpt.TFOpenAIGPTModelTest.model_tester.create_and_check_openai_gpt_double_head"], "methods", ["None"], ["", "def", "test_openai_gpt_double_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_openai_gpt_double_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_openai_gpt.TFOpenAIGPTModelTest.test_model_from_pretrained": [[233, 238], ["list", "TFOpenAIGPTModel.from_pretrained", "test_modeling_tf_openai_gpt.TFOpenAIGPTModelTest.assertIsNotNone", "TF_OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "TF_OPENAI_GPT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TFOpenAIGPTModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_t5.TFT5ModelTest.setUp": [[148, 151], ["TFT5ModelTest.TFT5ModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFT5ModelTest", ".", "TFT5ModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "T5Config", ",", "d_model", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_t5.TFT5ModelTest.test_config": [[152, 154], ["test_modeling_tf_t5.TFT5ModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_t5.TFT5ModelTest.test_t5_model": [[155, 158], ["test_modeling_tf_t5.TFT5ModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_t5.TFT5ModelTest.model_tester.create_and_check_t5_model"], "methods", ["None"], ["", "def", "test_t5_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_t5_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_t5.TFT5ModelTest.test_with_lm_head": [[159, 162], ["test_modeling_tf_t5.TFT5ModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_t5.TFT5ModelTest.model_tester.create_and_check_t5_with_lm_head"], "methods", ["None"], ["", "def", "test_with_lm_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_t5_with_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_t5.TFT5ModelTest.test_model_from_pretrained": [[163, 168], ["TFT5Model.from_pretrained", "test_modeling_tf_t5.TFT5ModelTest.assertIsNotNone"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "[", "\"t5-small\"", "]", ":", "\n", "            ", "model", "=", "TFT5Model", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_albert.AlbertModelTest.setUp": [[224, 227], ["AlbertModelTest.AlbertModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "AlbertModelTest", ".", "AlbertModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "AlbertConfig", ",", "hidden_size", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_albert.AlbertModelTest.test_config": [[228, 230], ["test_modeling_albert.AlbertModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_albert.AlbertModelTest.test_albert_model": [[231, 234], ["test_modeling_albert.AlbertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_albert.AlbertModelTest.model_tester.create_and_check_albert_model"], "methods", ["None"], ["", "def", "test_albert_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_albert_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_albert.AlbertModelTest.test_for_masked_lm": [[235, 238], ["test_modeling_albert.AlbertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_albert.AlbertModelTest.model_tester.create_and_check_albert_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_albert_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_albert.AlbertModelTest.test_for_question_answering": [[239, 242], ["test_modeling_albert.AlbertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_albert.AlbertModelTest.model_tester.create_and_check_albert_for_question_answering"], "methods", ["None"], ["", "def", "test_for_question_answering", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_albert_for_question_answering", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_albert.AlbertModelTest.test_for_sequence_classification": [[243, 246], ["test_modeling_albert.AlbertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_albert.AlbertModelTest.model_tester.create_and_check_albert_for_sequence_classification"], "methods", ["None"], ["", "def", "test_for_sequence_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_albert_for_sequence_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_albert.AlbertModelTest.test_model_from_pretrained": [[247, 252], ["list", "AlbertModel.from_pretrained", "test_modeling_albert.AlbertModelTest.assertIsNotNone", "ALBERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "ALBERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "AlbertModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_distilbert.DistilBertModelTest.setUp": [[221, 224], ["DistilBertModelTest.DistilBertModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "DistilBertModelTest", ".", "DistilBertModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "DistilBertConfig", ",", "dim", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_distilbert.DistilBertModelTest.test_config": [[225, 227], ["test_modeling_distilbert.DistilBertModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_distilbert.DistilBertModelTest.test_distilbert_model": [[228, 231], ["test_modeling_distilbert.DistilBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_distilbert.DistilBertModelTest.model_tester.create_and_check_distilbert_model"], "methods", ["None"], ["", "def", "test_distilbert_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_distilbert.DistilBertModelTest.test_for_masked_lm": [[232, 235], ["test_modeling_distilbert.DistilBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_distilbert.DistilBertModelTest.model_tester.create_and_check_distilbert_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_distilbert.DistilBertModelTest.test_for_question_answering": [[236, 239], ["test_modeling_distilbert.DistilBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_distilbert.DistilBertModelTest.model_tester.create_and_check_distilbert_for_question_answering"], "methods", ["None"], ["", "def", "test_for_question_answering", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_for_question_answering", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_distilbert.DistilBertModelTest.test_for_sequence_classification": [[240, 243], ["test_modeling_distilbert.DistilBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_distilbert.DistilBertModelTest.model_tester.create_and_check_distilbert_for_sequence_classification"], "methods", ["None"], ["", "def", "test_for_sequence_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_for_sequence_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_distilbert.DistilBertModelTest.test_for_token_classification": [[244, 247], ["test_modeling_distilbert.DistilBertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_distilbert.DistilBertModelTest.model_tester.create_and_check_distilbert_for_token_classification"], "methods", ["None"], ["", "def", "test_for_token_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_distilbert_for_token_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_roberta.RobertaModelTest.setUp": [[201, 204], ["RobertaModelTest.RobertaModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "RobertaModelTest", ".", "RobertaModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "RobertaConfig", ",", "hidden_size", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_roberta.RobertaModelTest.test_config": [[205, 207], ["test_modeling_roberta.RobertaModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_roberta.RobertaModelTest.test_roberta_model": [[208, 211], ["test_modeling_roberta.RobertaModelTest.model_tester.prepare_config_and_inputs", "test_modeling_roberta.RobertaModelTest.model_tester.create_and_check_roberta_model"], "methods", ["None"], ["", "def", "test_roberta_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_roberta_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_roberta.RobertaModelTest.test_for_masked_lm": [[212, 215], ["test_modeling_roberta.RobertaModelTest.model_tester.prepare_config_and_inputs", "test_modeling_roberta.RobertaModelTest.model_tester.create_and_check_roberta_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_roberta_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_roberta.RobertaModelTest.test_model_from_pretrained": [[216, 221], ["list", "RobertaModel.from_pretrained", "test_modeling_roberta.RobertaModelTest.assertIsNotNone", "ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "ROBERTA_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "RobertaModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_roberta.RobertaModelTest.test_create_position_ids_respects_padding_index": [[222, 240], ["RobertaEmbeddings", "torch.as_tensor", "torch.as_tensor", "RobertaEmbeddings.create_position_ids_from_input_ids", "test_modeling_roberta.RobertaModelTest.assertEqual", "test_modeling_roberta.RobertaModelTest.assertTrue", "test_modeling_roberta.RobertaModelTest.model_tester.prepare_config_and_inputs", "torch.all", "torch.eq"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaEmbeddings.create_position_ids_from_input_ids"], ["", "", "def", "test_create_position_ids_respects_padding_index", "(", "self", ")", ":", "\n", "        ", "\"\"\" Ensure that the default position ids only assign a sequential . This is a regression\n        test for https://github.com/huggingface/transformers/issues/1761\n\n        The position ids should be masked with the embedding object's padding index. Therefore, the\n        first available non-padding position index is RobertaEmbeddings.padding_idx + 1\n        \"\"\"", "\n", "config", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "[", "0", "]", "\n", "model", "=", "RobertaEmbeddings", "(", "config", "=", "config", ")", "\n", "\n", "input_ids", "=", "torch", ".", "as_tensor", "(", "[", "[", "12", ",", "31", ",", "13", ",", "model", ".", "padding_idx", "]", "]", ")", "\n", "expected_positions", "=", "torch", ".", "as_tensor", "(", "\n", "[", "[", "0", "+", "model", ".", "padding_idx", "+", "1", ",", "1", "+", "model", ".", "padding_idx", "+", "1", ",", "2", "+", "model", ".", "padding_idx", "+", "1", ",", "model", ".", "padding_idx", "]", "]", "\n", ")", "\n", "\n", "position_ids", "=", "model", ".", "create_position_ids_from_input_ids", "(", "input_ids", ")", "\n", "self", ".", "assertEqual", "(", "position_ids", ".", "shape", ",", "expected_positions", ".", "shape", ")", "\n", "self", ".", "assertTrue", "(", "torch", ".", "all", "(", "torch", ".", "eq", "(", "position_ids", ",", "expected_positions", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_roberta.RobertaModelTest.test_create_position_ids_from_inputs_embeds": [[241, 262], ["RobertaEmbeddings", "torch.Tensor", "torch.as_tensor", "RobertaEmbeddings.create_position_ids_from_inputs_embeds", "test_modeling_roberta.RobertaModelTest.assertEqual", "test_modeling_roberta.RobertaModelTest.assertTrue", "test_modeling_roberta.RobertaModelTest.model_tester.prepare_config_and_inputs", "torch.all", "torch.eq"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_roberta.RobertaEmbeddings.create_position_ids_from_inputs_embeds"], ["", "def", "test_create_position_ids_from_inputs_embeds", "(", "self", ")", ":", "\n", "        ", "\"\"\" Ensure that the default position ids only assign a sequential . This is a regression\n        test for https://github.com/huggingface/transformers/issues/1761\n\n        The position ids should be masked with the embedding object's padding index. Therefore, the\n        first available non-padding position index is RobertaEmbeddings.padding_idx + 1\n        \"\"\"", "\n", "config", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "[", "0", "]", "\n", "embeddings", "=", "RobertaEmbeddings", "(", "config", "=", "config", ")", "\n", "\n", "inputs_embeds", "=", "torch", ".", "Tensor", "(", "2", ",", "4", ",", "30", ")", "\n", "expected_single_positions", "=", "[", "\n", "0", "+", "embeddings", ".", "padding_idx", "+", "1", ",", "\n", "1", "+", "embeddings", ".", "padding_idx", "+", "1", ",", "\n", "2", "+", "embeddings", ".", "padding_idx", "+", "1", ",", "\n", "3", "+", "embeddings", ".", "padding_idx", "+", "1", ",", "\n", "]", "\n", "expected_positions", "=", "torch", ".", "as_tensor", "(", "[", "expected_single_positions", ",", "expected_single_positions", "]", ")", "\n", "position_ids", "=", "embeddings", ".", "create_position_ids_from_inputs_embeds", "(", "inputs_embeds", ")", "\n", "self", ".", "assertEqual", "(", "position_ids", ".", "shape", ",", "expected_positions", ".", "shape", ")", "\n", "self", ".", "assertTrue", "(", "torch", ".", "all", "(", "torch", ".", "eq", "(", "position_ids", ",", "expected_positions", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_roberta.RobertaModelIntegrationTest.test_inference_masked_lm": [[265, 278], ["RobertaForMaskedLM.from_pretrained", "torch.tensor", "torch.Size", "test_modeling_roberta.RobertaModelIntegrationTest.assertEqual", "torch.Tensor", "test_modeling_roberta.RobertaModelIntegrationTest.assertTrue", "RobertaForMaskedLM.from_pretrained.", "torch.allclose"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["    ", "@", "slow", "\n", "def", "test_inference_masked_lm", "(", "self", ")", ":", "\n", "        ", "model", "=", "RobertaForMaskedLM", ".", "from_pretrained", "(", "\"roberta-base\"", ")", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "]", ")", "\n", "output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "expected_shape", "=", "torch", ".", "Size", "(", "(", "1", ",", "11", ",", "50265", ")", ")", "\n", "self", ".", "assertEqual", "(", "output", ".", "shape", ",", "expected_shape", ")", "\n", "# compare the actual values for a slice.", "\n", "expected_slice", "=", "torch", ".", "Tensor", "(", "\n", "[", "[", "[", "33.8843", ",", "-", "4.3107", ",", "22.7779", "]", ",", "[", "4.6533", ",", "-", "2.8099", ",", "13.6252", "]", ",", "[", "1.8222", ",", "-", "3.6898", ",", "8.8600", "]", "]", "]", "\n", ")", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "output", "[", ":", ",", ":", "3", ",", ":", "3", "]", ",", "expected_slice", ",", "atol", "=", "1e-3", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_roberta.RobertaModelIntegrationTest.test_inference_no_head": [[279, 290], ["RobertaModel.from_pretrained", "torch.tensor", "torch.Tensor", "test_modeling_roberta.RobertaModelIntegrationTest.assertTrue", "RobertaModel.from_pretrained.", "torch.allclose"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_inference_no_head", "(", "self", ")", ":", "\n", "        ", "model", "=", "RobertaModel", ".", "from_pretrained", "(", "\"roberta-base\"", ")", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "]", ")", "\n", "output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "# compare the actual values for a slice.", "\n", "expected_slice", "=", "torch", ".", "Tensor", "(", "\n", "[", "[", "[", "-", "0.0231", ",", "0.0782", ",", "0.0074", "]", ",", "[", "-", "0.1854", ",", "0.0539", ",", "-", "0.0174", "]", ",", "[", "0.0548", ",", "0.0799", ",", "0.1687", "]", "]", "]", "\n", ")", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "output", "[", ":", ",", ":", "3", ",", ":", "3", "]", ",", "expected_slice", ",", "atol", "=", "1e-3", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_roberta.RobertaModelIntegrationTest.test_inference_classification_head": [[291, 301], ["RobertaForSequenceClassification.from_pretrained", "torch.tensor", "torch.Size", "test_modeling_roberta.RobertaModelIntegrationTest.assertEqual", "torch.Tensor", "test_modeling_roberta.RobertaModelIntegrationTest.assertTrue", "RobertaForSequenceClassification.from_pretrained.", "torch.allclose"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_inference_classification_head", "(", "self", ")", ":", "\n", "        ", "model", "=", "RobertaForSequenceClassification", ".", "from_pretrained", "(", "\"roberta-large-mnli\"", ")", "\n", "\n", "input_ids", "=", "torch", ".", "tensor", "(", "[", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", "]", ")", "\n", "output", "=", "model", "(", "input_ids", ")", "[", "0", "]", "\n", "expected_shape", "=", "torch", ".", "Size", "(", "(", "1", ",", "3", ")", ")", "\n", "self", ".", "assertEqual", "(", "output", ".", "shape", ",", "expected_shape", ")", "\n", "expected_tensor", "=", "torch", ".", "Tensor", "(", "[", "[", "-", "0.9469", ",", "0.3913", ",", "0.5118", "]", "]", ")", "\n", "self", ".", "assertTrue", "(", "torch", ".", "allclose", "(", "output", ",", "expected_tensor", ",", "atol", "=", "1e-3", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_distilbert.DistilBertTokenizationTest.get_tokenizer": [[27, 29], ["transformers.tokenization_distilbert.DistilBertTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "DistilBertTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_distilbert.DistilBertTokenizationTest.test_sequence_builders": [[30, 43], ["transformers.tokenization_distilbert.DistilBertTokenizer.from_pretrained", "transformers.tokenization_distilbert.DistilBertTokenizer.from_pretrained.encode", "transformers.tokenization_distilbert.DistilBertTokenizer.from_pretrained.encode", "transformers.tokenization_distilbert.DistilBertTokenizer.from_pretrained.build_inputs_with_special_tokens", "transformers.tokenization_distilbert.DistilBertTokenizer.from_pretrained.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens"], ["", "@", "slow", "\n", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "DistilBertTokenizer", ".", "from_pretrained", "(", "\"distilbert-base-uncased\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ",", "add_special_tokens", "=", "False", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"multi-sequence build\"", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ",", "text_2", ")", "\n", "\n", "assert", "encoded_sentence", "==", "[", "tokenizer", ".", "cls_token_id", "]", "+", "text", "+", "[", "tokenizer", ".", "sep_token_id", "]", "\n", "assert", "encoded_pair", "==", "[", "tokenizer", ".", "cls_token_id", "]", "+", "text", "+", "[", "tokenizer", ".", "sep_token_id", "]", "+", "text_2", "+", "[", "\n", "tokenizer", ".", "sep_token_id", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_roberta.RobertaTokenizationTest.setUp": [[30, 66], ["super().setUp", "dict", "os.path.join", "os.path.join", "zip", "open", "fp.write", "open", "fp.write", "range", "len", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "RobertaTokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt", "\n", "vocab", "=", "[", "\n", "\"l\"", ",", "\n", "\"o\"", ",", "\n", "\"w\"", ",", "\n", "\"e\"", ",", "\n", "\"r\"", ",", "\n", "\"s\"", ",", "\n", "\"t\"", ",", "\n", "\"i\"", ",", "\n", "\"d\"", ",", "\n", "\"n\"", ",", "\n", "\"\\u0120\"", ",", "\n", "\"\\u0120l\"", ",", "\n", "\"\\u0120n\"", ",", "\n", "\"\\u0120lo\"", ",", "\n", "\"\\u0120low\"", ",", "\n", "\"er\"", ",", "\n", "\"\\u0120lowest\"", ",", "\n", "\"\\u0120newer\"", ",", "\n", "\"\\u0120wider\"", ",", "\n", "\"<unk>\"", ",", "\n", "]", "\n", "vocab_tokens", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "merges", "=", "[", "\"#version: 0.2\"", ",", "\"\\u0120 l\"", ",", "\"\\u0120l o\"", ",", "\"\\u0120lo w\"", ",", "\"e r\"", ",", "\"\"", "]", "\n", "self", ".", "special_tokens_map", "=", "{", "\"unk_token\"", ":", "\"<unk>\"", "}", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "self", ".", "merges_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "\"merges_file\"", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "json", ".", "dumps", "(", "vocab_tokens", ")", "+", "\"\\n\"", ")", "\n", "", "with", "open", "(", "self", ".", "merges_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "\"\\n\"", ".", "join", "(", "merges", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_roberta.RobertaTokenizationTest.get_tokenizer": [[67, 70], ["kwargs.update", "transformers.tokenization_roberta.RobertaTokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "kwargs", ".", "update", "(", "self", ".", "special_tokens_map", ")", "\n", "return", "RobertaTokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_roberta.RobertaTokenizationTest.get_input_output_texts": [[71, 75], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "\"lower newer\"", "\n", "output_text", "=", "\"lower newer\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_roberta.RobertaTokenizationTest.test_full_tokenizer": [[76, 86], ["transformers.tokenization_roberta.RobertaTokenizer", "transformers.tokenization_roberta.RobertaTokenizer.tokenize", "test_tokenization_roberta.RobertaTokenizationTest.assertListEqual", "test_tokenization_roberta.RobertaTokenizationTest.assertListEqual", "transformers.tokenization_roberta.RobertaTokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "RobertaTokenizer", "(", "self", ".", "vocab_file", ",", "self", ".", "merges_file", ",", "**", "self", ".", "special_tokens_map", ")", "\n", "text", "=", "\"lower newer\"", "\n", "bpe_tokens", "=", "[", "\"\\u0120low\"", ",", "\"er\"", ",", "\"\\u0120\"", ",", "\"n\"", ",", "\"e\"", ",", "\"w\"", ",", "\"er\"", "]", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", ",", "add_prefix_space", "=", "True", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "bpe_tokens", ")", "\n", "\n", "input_tokens", "=", "tokens", "+", "[", "tokenizer", ".", "unk_token", "]", "\n", "input_bpe_tokens", "=", "[", "14", ",", "15", ",", "10", ",", "9", ",", "3", ",", "2", ",", "15", ",", "19", "]", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "input_tokens", ")", ",", "input_bpe_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_roberta.RobertaTokenizationTest.roberta_dict_integration_testing": [[87, 94], ["test_tokenization_roberta.RobertaTokenizationTest.get_tokenizer", "test_tokenization_roberta.RobertaTokenizationTest.assertListEqual", "test_tokenization_roberta.RobertaTokenizationTest.assertListEqual", "test_tokenization_roberta.RobertaTokenizationTest.encode", "test_tokenization_roberta.RobertaTokenizationTest.encode"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode"], ["", "def", "roberta_dict_integration_testing", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "self", ".", "get_tokenizer", "(", ")", "\n", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "encode", "(", "\"Hello world!\"", ",", "add_special_tokens", "=", "False", ")", ",", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "2", "]", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "tokenizer", ".", "encode", "(", "\"Hello world! c\u00e9c\u00e9 herlolip 418\"", ",", "add_special_tokens", "=", "False", ")", ",", "\n", "[", "0", ",", "31414", ",", "232", ",", "328", ",", "740", ",", "1140", ",", "12695", ",", "69", ",", "46078", ",", "1588", ",", "2", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_roberta.RobertaTokenizationTest.test_sequence_builders": [[96, 113], ["transformers.tokenization_roberta.RobertaTokenizer.from_pretrained", "transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.encode", "transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.encode", "transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.encode", "transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.encode", "transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.build_inputs_with_special_tokens", "transformers.tokenization_roberta.RobertaTokenizer.from_pretrained.build_inputs_with_special_tokens"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.encode", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.tokenization_xxx.XxxTokenizer.build_inputs_with_special_tokens"], ["", "@", "slow", "\n", "def", "test_sequence_builders", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "RobertaTokenizer", ".", "from_pretrained", "(", "\"roberta-base\"", ")", "\n", "\n", "text", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ",", "add_special_tokens", "=", "False", ")", "\n", "text_2", "=", "tokenizer", ".", "encode", "(", "\"multi-sequence build\"", ",", "add_special_tokens", "=", "False", ")", "\n", "\n", "encoded_text_from_decode", "=", "tokenizer", ".", "encode", "(", "\"sequence builders\"", ",", "add_special_tokens", "=", "True", ")", "\n", "encoded_pair_from_decode", "=", "tokenizer", ".", "encode", "(", "\n", "\"sequence builders\"", ",", "\"multi-sequence build\"", ",", "add_special_tokens", "=", "True", "\n", ")", "\n", "\n", "encoded_sentence", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ")", "\n", "encoded_pair", "=", "tokenizer", ".", "build_inputs_with_special_tokens", "(", "text", ",", "text_2", ")", "\n", "\n", "assert", "encoded_sentence", "==", "encoded_text_from_decode", "\n", "assert", "encoded_pair", "==", "encoded_pair_from_decode", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xlm.TFXLMModelTest.setUp": [[281, 284], ["TFXLMModelTest.TFXLMModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFXLMModelTest", ".", "TFXLMModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "XLMConfig", ",", "emb_dim", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xlm.TFXLMModelTest.test_config": [[285, 287], ["test_modeling_tf_xlm.TFXLMModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xlm.TFXLMModelTest.test_xlm_model": [[288, 291], ["test_modeling_tf_xlm.TFXLMModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_xlm.TFXLMModelTest.model_tester.create_and_check_xlm_model"], "methods", ["None"], ["", "def", "test_xlm_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xlm.TFXLMModelTest.test_xlm_lm_head": [[292, 295], ["test_modeling_tf_xlm.TFXLMModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_xlm.TFXLMModelTest.model_tester.create_and_check_xlm_lm_head"], "methods", ["None"], ["", "def", "test_xlm_lm_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xlm.TFXLMModelTest.test_xlm_qa": [[296, 299], ["test_modeling_tf_xlm.TFXLMModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_xlm.TFXLMModelTest.model_tester.create_and_check_xlm_qa"], "methods", ["None"], ["", "def", "test_xlm_qa", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_qa", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xlm.TFXLMModelTest.test_xlm_sequence_classif": [[300, 303], ["test_modeling_tf_xlm.TFXLMModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_xlm.TFXLMModelTest.model_tester.create_and_check_xlm_sequence_classif"], "methods", ["None"], ["", "def", "test_xlm_sequence_classif", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_xlm_sequence_classif", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_xlm.TFXLMModelTest.test_model_from_pretrained": [[304, 309], ["list", "TFXLMModel.from_pretrained", "test_modeling_tf_xlm.TFXLMModelTest.assertIsNotNone", "TF_XLM_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "TF_XLM_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TFXLMModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common.TFModelTesterMixin.test_initialization": [[52, 54], ["None"], "methods", ["None"], ["def", "test_initialization", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "# config, inputs_dict = self.model_tester.prepare_config_and_inputs_for_common()", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common.TFModelTesterMixin.test_save_load": [[64, 83], ["test_modeling_tf_common.TFModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "model_class", "model_class.from_pretrained.", "tempfile.TemporaryDirectory", "model_class.from_pretrained.save_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.", "after_outputs[].numpy", "outputs[].numpy", "np.amax", "test_modeling_tf_common.TFModelTesterMixin.assertLessEqual", "np.abs", "np.isnan", "np.isnan"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "def", "test_save_load", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "model", "=", "model_class", "(", "config", ")", "\n", "outputs", "=", "model", "(", "inputs_dict", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdirname", ":", "\n", "                ", "model", ".", "save_pretrained", "(", "tmpdirname", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "tmpdirname", ")", "\n", "after_outputs", "=", "model", "(", "inputs_dict", ")", "\n", "\n", "# Make sure we don't have nans", "\n", "out_1", "=", "after_outputs", "[", "0", "]", ".", "numpy", "(", ")", "\n", "out_2", "=", "outputs", "[", "0", "]", ".", "numpy", "(", ")", "\n", "out_1", "=", "out_1", "[", "~", "np", ".", "isnan", "(", "out_1", ")", "]", "\n", "out_2", "=", "out_2", "[", "~", "np", ".", "isnan", "(", "out_2", ")", "]", "\n", "max_diff", "=", "np", ".", "amax", "(", "np", ".", "abs", "(", "out_1", "-", "out_2", ")", ")", "\n", "self", ".", "assertLessEqual", "(", "max_diff", ",", "1e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common.TFModelTesterMixin.test_pt_tf_model_equivalence": [[84, 144], ["test_modeling_tf_common.TFModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "transformers.is_torch_available", "getattr", "model_class", "getattr.", "transformers.load_pytorch_model_in_tf2_model", "transformers.load_tf2_model_in_pytorch_model", "transformers.load_tf2_checkpoint_in_pytorch_model.eval", "dict", "transformers.load_pytorch_checkpoint_in_tf2_model.", "tfo[].numpy", "pto[].numpy", "np.amax", "test_modeling_tf_common.TFModelTesterMixin.assertLessEqual", "transformers.load_tf2_checkpoint_in_pytorch_model.eval", "dict", "transformers.load_pytorch_checkpoint_in_tf2_model.", "tfo[].numpy", "pto[].numpy", "np.amax", "test_modeling_tf_common.TFModelTesterMixin.assertLessEqual", "torch.no_grad", "transformers.load_tf2_checkpoint_in_pytorch_model.", "np.abs", "tempfile.TemporaryDirectory", "os.path.join", "torch.save", "transformers.load_pytorch_checkpoint_in_tf2_model", "os.path.join", "transformers.load_pytorch_checkpoint_in_tf2_model.save_weights", "transformers.load_tf2_checkpoint_in_pytorch_model", "torch.no_grad", "transformers.load_tf2_checkpoint_in_pytorch_model.", "np.abs", "np.isnan", "np.isnan", "transformers.load_tf2_checkpoint_in_pytorch_model.state_dict", "np.isnan", "np.isnan", "torch.from_numpy().to", "inputs_dict.items", "torch.from_numpy().to", "inputs_dict.items", "torch.from_numpy", "torch.from_numpy", "key.numpy", "key.numpy"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.file_utils.is_torch_available", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_pytorch_model_in_tf2_model", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_tf2_model_in_pytorch_model", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_pytorch_checkpoint_in_tf2_model", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_tf_pytorch_utils.load_tf2_checkpoint_in_pytorch_model"], ["", "", "", "def", "test_pt_tf_model_equivalence", "(", "self", ")", ":", "\n", "        ", "if", "not", "is_torch_available", "(", ")", ":", "\n", "            ", "return", "\n", "\n", "", "import", "torch", "\n", "import", "transformers", "\n", "\n", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "pt_model_class_name", "=", "model_class", ".", "__name__", "[", "2", ":", "]", "# Skip the \"TF\" at the beggining", "\n", "pt_model_class", "=", "getattr", "(", "transformers", ",", "pt_model_class_name", ")", "\n", "\n", "config", ".", "output_hidden_states", "=", "True", "\n", "tf_model", "=", "model_class", "(", "config", ")", "\n", "pt_model", "=", "pt_model_class", "(", "config", ")", "\n", "\n", "# Check we can load pt model in tf and vice-versa with model => model functions", "\n", "tf_model", "=", "transformers", ".", "load_pytorch_model_in_tf2_model", "(", "tf_model", ",", "pt_model", ",", "tf_inputs", "=", "inputs_dict", ")", "\n", "pt_model", "=", "transformers", ".", "load_tf2_model_in_pytorch_model", "(", "pt_model", ",", "tf_model", ")", "\n", "\n", "# Check predictions on first output (logits/hidden-states) are close enought given low-level computational differences", "\n", "pt_model", ".", "eval", "(", ")", "\n", "pt_inputs_dict", "=", "dict", "(", "\n", "(", "name", ",", "torch", ".", "from_numpy", "(", "key", ".", "numpy", "(", ")", ")", ".", "to", "(", "torch", ".", "long", ")", ")", "for", "name", ",", "key", "in", "inputs_dict", ".", "items", "(", ")", "\n", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "pto", "=", "pt_model", "(", "**", "pt_inputs_dict", ")", "\n", "", "tfo", "=", "tf_model", "(", "inputs_dict", ",", "training", "=", "False", ")", "\n", "tf_hidden_states", "=", "tfo", "[", "0", "]", ".", "numpy", "(", ")", "\n", "pt_hidden_states", "=", "pto", "[", "0", "]", ".", "numpy", "(", ")", "\n", "tf_hidden_states", "[", "np", ".", "isnan", "(", "tf_hidden_states", ")", "]", "=", "0", "\n", "pt_hidden_states", "[", "np", ".", "isnan", "(", "pt_hidden_states", ")", "]", "=", "0", "\n", "max_diff", "=", "np", ".", "amax", "(", "np", ".", "abs", "(", "tf_hidden_states", "-", "pt_hidden_states", ")", ")", "\n", "self", ".", "assertLessEqual", "(", "max_diff", ",", "2e-2", ")", "\n", "\n", "# Check we can load pt model in tf and vice-versa with checkpoint => model functions", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdirname", ":", "\n", "                ", "pt_checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "tmpdirname", ",", "\"pt_model.bin\"", ")", "\n", "torch", ".", "save", "(", "pt_model", ".", "state_dict", "(", ")", ",", "pt_checkpoint_path", ")", "\n", "tf_model", "=", "transformers", ".", "load_pytorch_checkpoint_in_tf2_model", "(", "tf_model", ",", "pt_checkpoint_path", ")", "\n", "\n", "tf_checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "tmpdirname", ",", "\"tf_model.h5\"", ")", "\n", "tf_model", ".", "save_weights", "(", "tf_checkpoint_path", ")", "\n", "pt_model", "=", "transformers", ".", "load_tf2_checkpoint_in_pytorch_model", "(", "pt_model", ",", "tf_checkpoint_path", ")", "\n", "\n", "# Check predictions on first output (logits/hidden-states) are close enought given low-level computational differences", "\n", "", "pt_model", ".", "eval", "(", ")", "\n", "pt_inputs_dict", "=", "dict", "(", "\n", "(", "name", ",", "torch", ".", "from_numpy", "(", "key", ".", "numpy", "(", ")", ")", ".", "to", "(", "torch", ".", "long", ")", ")", "for", "name", ",", "key", "in", "inputs_dict", ".", "items", "(", ")", "\n", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "pto", "=", "pt_model", "(", "**", "pt_inputs_dict", ")", "\n", "", "tfo", "=", "tf_model", "(", "inputs_dict", ")", "\n", "tfo", "=", "tfo", "[", "0", "]", ".", "numpy", "(", ")", "\n", "pto", "=", "pto", "[", "0", "]", ".", "numpy", "(", ")", "\n", "tfo", "[", "np", ".", "isnan", "(", "tfo", ")", "]", "=", "0", "\n", "pto", "[", "np", ".", "isnan", "(", "pto", ")", "]", "=", "0", "\n", "max_diff", "=", "np", ".", "amax", "(", "np", ".", "abs", "(", "tfo", "-", "pto", ")", ")", "\n", "self", ".", "assertLessEqual", "(", "max_diff", ",", "2e-2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common.TFModelTesterMixin.test_compile_tf_model": [[145, 178], ["test_modeling_tf_common.TFModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "tf.keras.optimizers.Adam", "tf.keras.losses.SparseCategoricalCrossentropy", "tf.keras.metrics.SparseCategoricalAccuracy", "tf.keras.Input", "model_class", "model_class.from_pretrained.", "tf.keras.Model", "tf.keras.Model.compile", "tf.keras.Input", "tf.keras.Input", "tempfile.TemporaryDirectory", "model_class.from_pretrained.", "model_class.from_pretrained.save_pretrained", "model_class.from_pretrained", "tf.keras.layers.Dense"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "test_compile_tf_model", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "if", "self", ".", "is_encoder_decoder", ":", "\n", "            ", "input_ids", "=", "{", "\n", "\"decoder_input_ids\"", ":", "tf", ".", "keras", ".", "Input", "(", "batch_shape", "=", "(", "2", ",", "2000", ")", ",", "name", "=", "\"decoder_input_ids\"", ",", "dtype", "=", "\"int32\"", ")", ",", "\n", "\"encoder_input_ids\"", ":", "tf", ".", "keras", ".", "Input", "(", "batch_shape", "=", "(", "2", ",", "2000", ")", ",", "name", "=", "\"encoder_input_ids\"", ",", "dtype", "=", "\"int32\"", ")", ",", "\n", "}", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "tf", ".", "keras", ".", "Input", "(", "batch_shape", "=", "(", "2", ",", "2000", ")", ",", "name", "=", "\"input_ids\"", ",", "dtype", "=", "\"int32\"", ")", "\n", "", "optimizer", "=", "tf", ".", "keras", ".", "optimizers", ".", "Adam", "(", "learning_rate", "=", "3e-5", ",", "epsilon", "=", "1e-08", ",", "clipnorm", "=", "1.0", ")", "\n", "loss", "=", "tf", ".", "keras", ".", "losses", ".", "SparseCategoricalCrossentropy", "(", "from_logits", "=", "True", ")", "\n", "metric", "=", "tf", ".", "keras", ".", "metrics", ".", "SparseCategoricalAccuracy", "(", "\"accuracy\"", ")", "\n", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "# Prepare our model", "\n", "            ", "model", "=", "model_class", "(", "config", ")", "\n", "\n", "# Let's load it from the disk to be sure we can use pretrained weights", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmpdirname", ":", "\n", "                ", "outputs", "=", "model", "(", "inputs_dict", ")", "# build the model", "\n", "model", ".", "save_pretrained", "(", "tmpdirname", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "tmpdirname", ")", "\n", "\n", "", "outputs_dict", "=", "model", "(", "input_ids", ")", "\n", "hidden_states", "=", "outputs_dict", "[", "0", "]", "\n", "\n", "# Add a dense layer on top to test intetgration with other keras modules", "\n", "outputs", "=", "tf", ".", "keras", ".", "layers", ".", "Dense", "(", "2", ",", "activation", "=", "\"softmax\"", ",", "name", "=", "\"outputs\"", ")", "(", "hidden_states", ")", "\n", "\n", "# Compile extended model", "\n", "extended_model", "=", "tf", ".", "keras", ".", "Model", "(", "inputs", "=", "[", "input_ids", "]", ",", "outputs", "=", "[", "outputs", "]", ")", "\n", "extended_model", ".", "compile", "(", "optimizer", "=", "optimizer", ",", "loss", "=", "loss", ",", "metrics", "=", "[", "metric", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common.TFModelTesterMixin.test_keyword_and_dict_args": [[179, 194], ["test_modeling_tf_common.TFModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "model_class", "model_class.", "copy.deepcopy", "copy.deepcopy.pop", "model_class.", "outputs_dict[].numpy", "outputs_keywords[].numpy", "test_modeling_tf_common.TFModelTesterMixin.assertLess", "np.sum", "np.abs"], "methods", ["None"], ["", "", "def", "test_keyword_and_dict_args", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "model", "=", "model_class", "(", "config", ")", "\n", "outputs_dict", "=", "model", "(", "inputs_dict", ")", "\n", "\n", "inputs_keywords", "=", "copy", ".", "deepcopy", "(", "inputs_dict", ")", "\n", "input_ids", "=", "inputs_keywords", ".", "pop", "(", "\"input_ids\"", "if", "not", "self", ".", "is_encoder_decoder", "else", "\"decoder_input_ids\"", ",", "None", ")", "\n", "outputs_keywords", "=", "model", "(", "input_ids", ",", "**", "inputs_keywords", ")", "\n", "\n", "output_dict", "=", "outputs_dict", "[", "0", "]", ".", "numpy", "(", ")", "\n", "output_keywords", "=", "outputs_keywords", "[", "0", "]", ".", "numpy", "(", ")", "\n", "\n", "self", ".", "assertLess", "(", "np", ".", "sum", "(", "np", ".", "abs", "(", "output_dict", "-", "output_keywords", ")", ")", ",", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common.TFModelTesterMixin.test_attention_outputs": [[195, 255], ["test_modeling_tf_common.TFModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "hasattr", "hasattr", "hasattr", "hasattr", "model_class", "model_class.", "test_modeling_tf_common.TFModelTesterMixin.assertEqual", "test_modeling_tf_common.TFModelTesterMixin.assertEqual", "test_modeling_tf_common.TFModelTesterMixin.assertEqual", "test_modeling_tf_common.TFModelTesterMixin.assertListEqual", "len", "model_class", "model_class.", "test_modeling_tf_common.TFModelTesterMixin.assertEqual", "test_modeling_tf_common.TFModelTesterMixin.assertEqual", "test_modeling_tf_common.TFModelTesterMixin.assertEqual", "test_modeling_tf_common.TFModelTesterMixin.assertEqual", "test_modeling_tf_common.TFModelTesterMixin.assertListEqual", "t.numpy", "len", "list", "test_modeling_tf_common.TFModelTesterMixin.assertEqual", "test_modeling_tf_common.TFModelTesterMixin.assertEqual", "test_modeling_tf_common.TFModelTesterMixin.assertEqual", "test_modeling_tf_common.TFModelTesterMixin.assertEqual", "test_modeling_tf_common.TFModelTesterMixin.assertListEqual", "len", "t.numpy", "len", "list", "len", "list"], "methods", ["None"], ["", "", "def", "test_attention_outputs", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "decoder_seq_length", "=", "(", "\n", "self", ".", "model_tester", ".", "decoder_seq_length", "\n", "if", "hasattr", "(", "self", ".", "model_tester", ",", "\"decoder_seq_length\"", ")", "\n", "else", "self", ".", "model_tester", ".", "seq_length", "\n", ")", "\n", "encoder_seq_length", "=", "(", "\n", "self", ".", "model_tester", ".", "encoder_seq_length", "\n", "if", "hasattr", "(", "self", ".", "model_tester", ",", "\"encoder_seq_length\"", ")", "\n", "else", "self", ".", "model_tester", ".", "seq_length", "\n", ")", "\n", "decoder_key_length", "=", "(", "\n", "self", ".", "model_tester", ".", "key_length", "if", "hasattr", "(", "self", ".", "model_tester", ",", "\"key_length\"", ")", "else", "decoder_seq_length", "\n", ")", "\n", "encoder_key_length", "=", "(", "\n", "self", ".", "model_tester", ".", "key_length", "if", "hasattr", "(", "self", ".", "model_tester", ",", "\"key_length\"", ")", "else", "encoder_seq_length", "\n", ")", "\n", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "config", ".", "output_attentions", "=", "True", "\n", "config", ".", "output_hidden_states", "=", "False", "\n", "model", "=", "model_class", "(", "config", ")", "\n", "outputs", "=", "model", "(", "inputs_dict", ")", "\n", "attentions", "=", "[", "t", ".", "numpy", "(", ")", "for", "t", "in", "outputs", "[", "-", "1", "]", "]", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_attentions", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_hidden_states", ",", "False", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "attentions", ")", ",", "self", ".", "model_tester", ".", "num_hidden_layers", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "list", "(", "attentions", "[", "0", "]", ".", "shape", "[", "-", "3", ":", "]", ")", ",", "\n", "[", "self", ".", "model_tester", ".", "num_attention_heads", ",", "encoder_seq_length", ",", "encoder_key_length", "]", ",", "\n", ")", "\n", "out_len", "=", "len", "(", "outputs", ")", "\n", "\n", "if", "self", ".", "is_encoder_decoder", ":", "\n", "                ", "self", ".", "assertEqual", "(", "out_len", "%", "2", ",", "0", ")", "\n", "decoder_attentions", "=", "outputs", "[", "(", "out_len", "//", "2", ")", "-", "1", "]", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_attentions", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_hidden_states", ",", "False", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "decoder_attentions", ")", ",", "self", ".", "model_tester", ".", "num_hidden_layers", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "list", "(", "decoder_attentions", "[", "0", "]", ".", "shape", "[", "-", "3", ":", "]", ")", ",", "\n", "[", "self", ".", "model_tester", ".", "num_attention_heads", ",", "decoder_seq_length", ",", "decoder_key_length", "]", ",", "\n", ")", "\n", "\n", "# Check attention is always last and order is fine", "\n", "", "config", ".", "output_attentions", "=", "True", "\n", "config", ".", "output_hidden_states", "=", "True", "\n", "model", "=", "model_class", "(", "config", ")", "\n", "outputs", "=", "model", "(", "inputs_dict", ")", "\n", "self", ".", "assertEqual", "(", "out_len", "+", "(", "2", "if", "self", ".", "is_encoder_decoder", "else", "1", ")", ",", "len", "(", "outputs", ")", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_attentions", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_hidden_states", ",", "True", ")", "\n", "\n", "attentions", "=", "[", "t", ".", "numpy", "(", ")", "for", "t", "in", "outputs", "[", "-", "1", "]", "]", "\n", "self", ".", "assertEqual", "(", "len", "(", "attentions", ")", ",", "self", ".", "model_tester", ".", "num_hidden_layers", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "list", "(", "attentions", "[", "0", "]", ".", "shape", "[", "-", "3", ":", "]", ")", ",", "\n", "[", "self", ".", "model_tester", ".", "num_attention_heads", ",", "encoder_seq_length", ",", "encoder_key_length", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common.TFModelTesterMixin.test_hidden_states_output": [[257, 271], ["test_modeling_tf_common.TFModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "model_class", "model_class.", "test_modeling_tf_common.TFModelTesterMixin.assertEqual", "test_modeling_tf_common.TFModelTesterMixin.assertEqual", "test_modeling_tf_common.TFModelTesterMixin.assertEqual", "test_modeling_tf_common.TFModelTesterMixin.assertListEqual", "t.numpy", "len", "list"], "methods", ["None"], ["", "", "def", "test_hidden_states_output", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "config", ".", "output_hidden_states", "=", "True", "\n", "config", ".", "output_attentions", "=", "False", "\n", "model", "=", "model_class", "(", "config", ")", "\n", "outputs", "=", "model", "(", "inputs_dict", ")", "\n", "hidden_states", "=", "[", "t", ".", "numpy", "(", ")", "for", "t", "in", "outputs", "[", "-", "1", "]", "]", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_attentions", ",", "False", ")", "\n", "self", ".", "assertEqual", "(", "model", ".", "config", ".", "output_hidden_states", ",", "True", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "hidden_states", ")", ",", "self", ".", "model_tester", ".", "num_hidden_layers", "+", "1", ")", "\n", "self", ".", "assertListEqual", "(", "\n", "list", "(", "hidden_states", "[", "0", "]", ".", "shape", "[", "-", "2", ":", "]", ")", ",", "[", "self", ".", "model_tester", ".", "seq_length", ",", "self", ".", "model_tester", ".", "hidden_size", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common.TFModelTesterMixin.test_model_common_attributes": [[273, 281], ["test_modeling_tf_common.TFModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "model_class", "isinstance", "model_class.get_output_embeddings", "model_class.get_input_embeddings", "isinstance"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxForMaskedLM.get_output_embeddings", "home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.get_input_embeddings"], ["", "", "def", "test_model_common_attributes", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "model", "=", "model_class", "(", "config", ")", "\n", "assert", "isinstance", "(", "model", ".", "get_input_embeddings", "(", ")", ",", "tf", ".", "keras", ".", "layers", ".", "Layer", ")", "\n", "x", "=", "model", ".", "get_output_embeddings", "(", ")", "\n", "assert", "x", "is", "None", "or", "isinstance", "(", "x", ",", "tf", ".", "keras", ".", "layers", ".", "Layer", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common.TFModelTesterMixin.test_determinism": [[282, 294], ["test_modeling_tf_common.TFModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "model_class", "first.numpy", "second.numpy", "np.amax", "test_modeling_tf_common.TFModelTesterMixin.assertLessEqual", "np.abs", "model_class.", "model_class.", "np.isnan", "np.isnan"], "methods", ["None"], ["", "", "def", "test_determinism", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "\n", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "model", "=", "model_class", "(", "config", ")", "\n", "first", ",", "second", "=", "model", "(", "inputs_dict", ",", "training", "=", "False", ")", "[", "0", "]", ",", "model", "(", "inputs_dict", ",", "training", "=", "False", ")", "[", "0", "]", "\n", "out_1", "=", "first", ".", "numpy", "(", ")", "\n", "out_2", "=", "second", ".", "numpy", "(", ")", "\n", "out_1", "=", "out_1", "[", "~", "np", ".", "isnan", "(", "out_1", ")", "]", "\n", "out_2", "=", "out_2", "[", "~", "np", ".", "isnan", "(", "out_2", ")", "]", "\n", "max_diff", "=", "np", ".", "amax", "(", "np", ".", "abs", "(", "out_1", "-", "out_2", ")", ")", "\n", "self", ".", "assertLessEqual", "(", "max_diff", ",", "1e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common.TFModelTesterMixin._get_embeds": [[295, 313], ["wte", "wte", "wte", "hasattr", "tf.ones", "tf.ones"], "methods", ["None"], ["", "", "def", "_get_embeds", "(", "self", ",", "wte", ",", "input_ids", ")", ":", "\n", "# ^^ In our TF models, the input_embeddings can take slightly different forms,", "\n", "# so we try a few of them.", "\n", "# We used to fall back to just synthetically creating a dummy tensor of ones:", "\n", "        ", "try", ":", "\n", "            ", "x", "=", "wte", "(", "input_ids", ",", "mode", "=", "\"embedding\"", ")", "\n", "", "except", "Exception", ":", "\n", "            ", "try", ":", "\n", "                ", "x", "=", "wte", "(", "[", "input_ids", "]", ",", "mode", "=", "\"embedding\"", ")", "\n", "", "except", "Exception", ":", "\n", "                ", "try", ":", "\n", "                    ", "x", "=", "wte", "(", "[", "input_ids", ",", "None", ",", "None", ",", "None", "]", ",", "mode", "=", "\"embedding\"", ")", "\n", "", "except", "Exception", ":", "\n", "                    ", "if", "hasattr", "(", "self", ".", "model_tester", ",", "\"embedding_size\"", ")", ":", "\n", "                        ", "x", "=", "tf", ".", "ones", "(", "input_ids", ".", "shape", "+", "[", "self", ".", "model_tester", ".", "embedding_size", "]", ",", "dtype", "=", "tf", ".", "dtypes", ".", "float32", ")", "\n", "", "else", ":", "\n", "                        ", "x", "=", "tf", ".", "ones", "(", "input_ids", ".", "shape", "+", "[", "self", ".", "model_tester", ".", "hidden_size", "]", ",", "dtype", "=", "tf", ".", "dtypes", ".", "float32", ")", "\n", "", "", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common.TFModelTesterMixin.test_inputs_embeds": [[314, 336], ["test_modeling_tf_common.TFModelTesterMixin.model_tester.prepare_config_and_inputs_for_common", "model_class", "model_class.get_input_embeddings", "model_class.", "test_modeling_tf_common.TFModelTesterMixin._get_embeds", "test_modeling_tf_common.TFModelTesterMixin._get_embeds", "test_modeling_tf_common.TFModelTesterMixin._get_embeds"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.adding_a_new_model.modeling_xxx.XxxModel.get_input_embeddings", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common.TFModelTesterMixin._get_embeds", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common.TFModelTesterMixin._get_embeds", "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common.TFModelTesterMixin._get_embeds"], ["", "def", "test_inputs_embeds", "(", "self", ")", ":", "\n", "        ", "config", ",", "inputs_dict", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs_for_common", "(", ")", "\n", "if", "not", "self", ".", "is_encoder_decoder", ":", "\n", "            ", "input_ids", "=", "inputs_dict", "[", "\"input_ids\"", "]", "\n", "del", "inputs_dict", "[", "\"input_ids\"", "]", "\n", "", "else", ":", "\n", "            ", "encoder_input_ids", "=", "inputs_dict", "[", "\"encoder_input_ids\"", "]", "\n", "decoder_input_ids", "=", "inputs_dict", "[", "\"decoder_input_ids\"", "]", "\n", "del", "inputs_dict", "[", "\"encoder_input_ids\"", "]", "\n", "del", "inputs_dict", "[", "\"decoder_input_ids\"", "]", "\n", "\n", "", "for", "model_class", "in", "self", ".", "all_model_classes", ":", "\n", "            ", "model", "=", "model_class", "(", "config", ")", "\n", "\n", "wte", "=", "model", ".", "get_input_embeddings", "(", ")", "\n", "if", "not", "self", ".", "is_encoder_decoder", ":", "\n", "                ", "inputs_dict", "[", "\"inputs_embeds\"", "]", "=", "self", ".", "_get_embeds", "(", "wte", ",", "input_ids", ")", "\n", "", "else", ":", "\n", "                ", "inputs_dict", "[", "\"encoder_inputs_embeds\"", "]", "=", "self", ".", "_get_embeds", "(", "wte", ",", "encoder_input_ids", ")", "\n", "inputs_dict", "[", "\"decoder_inputs_embeds\"", "]", "=", "self", ".", "_get_embeds", "(", "wte", ",", "decoder_input_ids", ")", "\n", "\n", "", "outputs", "=", "model", "(", "inputs_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common._config_zero_init": [[34, 40], ["copy.deepcopy", "copy.deepcopy.__dict__.keys", "setattr"], "function", ["None"], ["", "def", "_config_zero_init", "(", "config", ")", ":", "\n", "    ", "configs_no_init", "=", "copy", ".", "deepcopy", "(", "config", ")", "\n", "for", "key", "in", "configs_no_init", ".", "__dict__", ".", "keys", "(", ")", ":", "\n", "        ", "if", "\"_range\"", "in", "key", "or", "\"_std\"", "in", "key", ":", "\n", "            ", "setattr", "(", "configs_no_init", ",", "key", ",", "0.0", ")", "\n", "", "", "return", "configs_no_init", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_common.ids_tensor": [[338, 354], ["range", "tf.constant", "random.Random", "values.append", "random.Random.randint"], "function", ["None"], ["", "", "", "def", "ids_tensor", "(", "shape", ",", "vocab_size", ",", "rng", "=", "None", ",", "name", "=", "None", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates a random int32 tensor of the shape within the vocab size.\"\"\"", "\n", "if", "rng", "is", "None", ":", "\n", "        ", "rng", "=", "random", ".", "Random", "(", ")", "\n", "\n", "", "total_dims", "=", "1", "\n", "for", "dim", "in", "shape", ":", "\n", "        ", "total_dims", "*=", "dim", "\n", "\n", "", "values", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "total_dims", ")", ":", "\n", "        ", "values", ".", "append", "(", "rng", ".", "randint", "(", "0", ",", "vocab_size", "-", "1", ")", ")", "\n", "\n", "", "output", "=", "tf", ".", "constant", "(", "values", ",", "shape", "=", "shape", ",", "dtype", "=", "dtype", "if", "dtype", "is", "not", "None", "else", "tf", ".", "int32", ")", "\n", "\n", "return", "output", "\n", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_auto.AutoTokenizerTest.test_tokenizer_from_pretrained": [[32, 46], ["logging.basicConfig", "list", "transformers.AutoTokenizer.from_pretrained", "test_tokenization_auto.AutoTokenizerTest.assertIsNotNone", "test_tokenization_auto.AutoTokenizerTest.assertIsInstance", "test_tokenization_auto.AutoTokenizerTest.assertGreater", "list", "transformers.AutoTokenizer.from_pretrained", "test_tokenization_auto.AutoTokenizerTest.assertIsNotNone", "test_tokenization_auto.AutoTokenizerTest.assertIsInstance", "test_tokenization_auto.AutoTokenizerTest.assertGreater", "transformers.BERT_PRETRAINED_CONFIG_ARCHIVE_MAP.keys", "len", "transformers.GPT2_PRETRAINED_CONFIG_ARCHIVE_MAP.keys", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["    ", "@", "slow", "\n", "def", "test_tokenizer_from_pretrained", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "for", "model_name", "in", "list", "(", "BERT_PRETRAINED_CONFIG_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "tokenizer", ")", "\n", "self", ".", "assertIsInstance", "(", "tokenizer", ",", "BertTokenizer", ")", "\n", "self", ".", "assertGreater", "(", "len", "(", "tokenizer", ")", ",", "0", ")", "\n", "\n", "", "for", "model_name", "in", "list", "(", "GPT2_PRETRAINED_CONFIG_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "assertIsNotNone", "(", "tokenizer", ")", "\n", "self", ".", "assertIsInstance", "(", "tokenizer", ",", "GPT2Tokenizer", ")", "\n", "self", ".", "assertGreater", "(", "len", "(", "tokenizer", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_auto.AutoTokenizerTest.test_tokenizer_from_pretrained_identifier": [[47, 52], ["logging.basicConfig", "transformers.AutoTokenizer.from_pretrained", "test_tokenization_auto.AutoTokenizerTest.assertIsInstance", "test_tokenization_auto.AutoTokenizerTest.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "test_tokenizer_from_pretrained_identifier", "(", "self", ")", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "SMALL_MODEL_IDENTIFIER", ")", "\n", "self", ".", "assertIsInstance", "(", "tokenizer", ",", "BertTokenizer", ")", "\n", "self", ".", "assertEqual", "(", "len", "(", "tokenizer", ")", ",", "12", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.setUp": [[30, 66], ["super().setUp", "dict", "os.path.join", "os.path.join", "zip", "open", "fp.write", "open", "fp.write", "range", "len", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "GPT2TokenizationTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "\n", "# Adapted from Sennrich et al. 2015 and https://github.com/rsennrich/subword-nmt", "\n", "vocab", "=", "[", "\n", "\"l\"", ",", "\n", "\"o\"", ",", "\n", "\"w\"", ",", "\n", "\"e\"", ",", "\n", "\"r\"", ",", "\n", "\"s\"", ",", "\n", "\"t\"", ",", "\n", "\"i\"", ",", "\n", "\"d\"", ",", "\n", "\"n\"", ",", "\n", "\"\\u0120\"", ",", "\n", "\"\\u0120l\"", ",", "\n", "\"\\u0120n\"", ",", "\n", "\"\\u0120lo\"", ",", "\n", "\"\\u0120low\"", ",", "\n", "\"er\"", ",", "\n", "\"\\u0120lowest\"", ",", "\n", "\"\\u0120newer\"", ",", "\n", "\"\\u0120wider\"", ",", "\n", "\"<unk>\"", ",", "\n", "]", "\n", "vocab_tokens", "=", "dict", "(", "zip", "(", "vocab", ",", "range", "(", "len", "(", "vocab", ")", ")", ")", ")", "\n", "merges", "=", "[", "\"#version: 0.2\"", ",", "\"\\u0120 l\"", ",", "\"\\u0120l o\"", ",", "\"\\u0120lo w\"", ",", "\"e r\"", ",", "\"\"", "]", "\n", "self", ".", "special_tokens_map", "=", "{", "\"unk_token\"", ":", "\"<unk>\"", "}", "\n", "\n", "self", ".", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "self", ".", "merges_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "tmpdirname", ",", "VOCAB_FILES_NAMES", "[", "\"merges_file\"", "]", ")", "\n", "with", "open", "(", "self", ".", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "json", ".", "dumps", "(", "vocab_tokens", ")", "+", "\"\\n\"", ")", "\n", "", "with", "open", "(", "self", ".", "merges_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "fp", ":", "\n", "            ", "fp", ".", "write", "(", "\"\\n\"", ".", "join", "(", "merges", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_tokenizer": [[67, 70], ["kwargs.update", "transformers.tokenization_gpt2.GPT2Tokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "", "def", "get_tokenizer", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "kwargs", ".", "update", "(", "self", ".", "special_tokens_map", ")", "\n", "return", "GPT2Tokenizer", ".", "from_pretrained", "(", "self", ".", "tmpdirname", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.get_input_output_texts": [[71, 75], ["None"], "methods", ["None"], ["", "def", "get_input_output_texts", "(", "self", ")", ":", "\n", "        ", "input_text", "=", "\"lower newer\"", "\n", "output_text", "=", "\"lower newer\"", "\n", "return", "input_text", ",", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_tokenization_gpt2.GPT2TokenizationTest.test_full_tokenizer": [[76, 86], ["transformers.tokenization_gpt2.GPT2Tokenizer", "transformers.tokenization_gpt2.GPT2Tokenizer.tokenize", "test_tokenization_gpt2.GPT2TokenizationTest.assertListEqual", "test_tokenization_gpt2.GPT2TokenizationTest.assertListEqual", "transformers.tokenization_gpt2.GPT2Tokenizer.convert_tokens_to_ids"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "test_full_tokenizer", "(", "self", ")", ":", "\n", "        ", "tokenizer", "=", "GPT2Tokenizer", "(", "self", ".", "vocab_file", ",", "self", ".", "merges_file", ",", "**", "self", ".", "special_tokens_map", ")", "\n", "text", "=", "\"lower newer\"", "\n", "bpe_tokens", "=", "[", "\"\\u0120low\"", ",", "\"er\"", ",", "\"\\u0120\"", ",", "\"n\"", ",", "\"e\"", ",", "\"w\"", ",", "\"er\"", "]", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "text", ",", "add_prefix_space", "=", "True", ")", "\n", "self", ".", "assertListEqual", "(", "tokens", ",", "bpe_tokens", ")", "\n", "\n", "input_tokens", "=", "tokens", "+", "[", "tokenizer", ".", "unk_token", "]", "\n", "input_bpe_tokens", "=", "[", "14", ",", "15", ",", "10", ",", "9", ",", "3", ",", "2", ",", "15", ",", "19", "]", "\n", "self", ".", "assertListEqual", "(", "tokenizer", ".", "convert_tokens_to_ids", "(", "input_tokens", ")", ",", "input_bpe_tokens", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.utils.parse_flag_from_env": [[14, 28], ["distutils.util.strtobool", "ValueError"], "function", ["None"], ["# See the License for the specific language governing permissions and", "\n", "# limitations under the License.", "\n", "\n", "import", "copy", "\n", "import", "csv", "\n", "import", "json", "\n", "import", "logging", "\n", "\n", "from", "...", "file_utils", "import", "is_tf_available", ",", "is_torch_available", "\n", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "\n", "class", "InputExample", "(", "object", ")", ":", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.utils.slow": [[34, 45], ["unittest.skip"], "function", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.utils.custom_tokenizers": [[47, 58], ["unittest.skip"], "function", ["None"], ["\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n", "", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n", "", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.utils.require_torch": [[60, 70], ["unittest.skip"], "function", ["None"], ["\n", "", "", "class", "InputFeatures", "(", "object", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.utils.require_tf": [[72, 82], ["unittest.skip"], "function", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "attention_mask", "=", "attention_mask", "\n", "self", ".", "token_type_ids", "=", "token_type_ids", "\n", "self", ".", "label", "=", "label", "\n", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_gpt2.TFGPT2ModelTest.setUp": [[213, 216], ["TFGPT2ModelTest.TFGPT2ModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFGPT2ModelTest", ".", "TFGPT2ModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "GPT2Config", ",", "n_embd", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_gpt2.TFGPT2ModelTest.test_config": [[217, 219], ["test_modeling_tf_gpt2.TFGPT2ModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_gpt2.TFGPT2ModelTest.test_gpt2_model": [[220, 223], ["test_modeling_tf_gpt2.TFGPT2ModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_gpt2.TFGPT2ModelTest.model_tester.create_and_check_gpt2_model"], "methods", ["None"], ["", "def", "test_gpt2_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_gpt2_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_gpt2.TFGPT2ModelTest.test_gpt2_lm_head": [[224, 227], ["test_modeling_tf_gpt2.TFGPT2ModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_gpt2.TFGPT2ModelTest.model_tester.create_and_check_gpt2_lm_head"], "methods", ["None"], ["", "def", "test_gpt2_lm_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_gpt2_lm_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_gpt2.TFGPT2ModelTest.test_gpt2_double_head": [[228, 231], ["test_modeling_tf_gpt2.TFGPT2ModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_gpt2.TFGPT2ModelTest.model_tester.create_and_check_gpt2_double_head"], "methods", ["None"], ["", "def", "test_gpt2_double_head", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_gpt2_double_head", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_gpt2.TFGPT2ModelTest.test_model_from_pretrained": [[232, 237], ["list", "TFGPT2Model.from_pretrained", "test_modeling_tf_gpt2.TFGPT2ModelTest.assertIsNotNone", "TF_GPT2_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "TF_GPT2_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TFGPT2Model", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_gpt2.GPT2ModelTest.setUp": [[227, 230], ["GPT2ModelTest.GPT2ModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "GPT2ModelTest", ".", "GPT2ModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "GPT2Config", ",", "n_embd", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_gpt2.GPT2ModelTest.test_config": [[231, 233], ["test_modeling_gpt2.GPT2ModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_gpt2.GPT2ModelTest.test_gpt2_model": [[234, 237], ["test_modeling_gpt2.GPT2ModelTest.model_tester.prepare_config_and_inputs", "test_modeling_gpt2.GPT2ModelTest.model_tester.create_and_check_gpt2_model"], "methods", ["None"], ["", "def", "test_gpt2_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_gpt2_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_gpt2.GPT2ModelTest.test_gpt2_lm_head_model": [[238, 241], ["test_modeling_gpt2.GPT2ModelTest.model_tester.prepare_config_and_inputs", "test_modeling_gpt2.GPT2ModelTest.model_tester.create_and_check_lm_head_model"], "methods", ["None"], ["", "def", "test_gpt2_lm_head_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_lm_head_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_gpt2.GPT2ModelTest.test_gpt2_double_lm_head_model": [[242, 245], ["test_modeling_gpt2.GPT2ModelTest.model_tester.prepare_config_and_inputs", "test_modeling_gpt2.GPT2ModelTest.model_tester.create_and_check_double_lm_head_model"], "methods", ["None"], ["", "def", "test_gpt2_double_lm_head_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_double_lm_head_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_gpt2.GPT2ModelTest.test_model_from_pretrained": [[246, 251], ["list", "GPT2Model.from_pretrained", "test_modeling_gpt2.GPT2ModelTest.assertIsNotNone", "GPT2_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "GPT2_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "GPT2Model", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.setUp": [[192, 195], ["TFAlbertModelTest.TFAlbertModelTester", "test_configuration_common.ConfigTester"], "methods", ["None"], ["", "", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "model_tester", "=", "TFAlbertModelTest", ".", "TFAlbertModelTester", "(", "self", ")", "\n", "self", ".", "config_tester", "=", "ConfigTester", "(", "self", ",", "config_class", "=", "AlbertConfig", ",", "hidden_size", "=", "37", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.test_config": [[196, 198], ["test_modeling_tf_albert.TFAlbertModelTest.config_tester.run_common_tests"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_configuration_common.ConfigTester.run_common_tests"], ["", "def", "test_config", "(", "self", ")", ":", "\n", "        ", "self", ".", "config_tester", ".", "run_common_tests", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.test_albert_model": [[199, 202], ["test_modeling_tf_albert.TFAlbertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_albert.TFAlbertModelTest.model_tester.create_and_check_albert_model"], "methods", ["None"], ["", "def", "test_albert_model", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_albert_model", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.test_for_masked_lm": [[203, 206], ["test_modeling_tf_albert.TFAlbertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_albert.TFAlbertModelTest.model_tester.create_and_check_albert_for_masked_lm"], "methods", ["None"], ["", "def", "test_for_masked_lm", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_albert_for_masked_lm", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.test_for_sequence_classification": [[207, 210], ["test_modeling_tf_albert.TFAlbertModelTest.model_tester.prepare_config_and_inputs", "test_modeling_tf_albert.TFAlbertModelTest.model_tester.create_and_check_albert_for_sequence_classification"], "methods", ["None"], ["", "def", "test_for_sequence_classification", "(", "self", ")", ":", "\n", "        ", "config_and_inputs", "=", "self", ".", "model_tester", ".", "prepare_config_and_inputs", "(", ")", "\n", "self", ".", "model_tester", ".", "create_and_check_albert_for_sequence_classification", "(", "*", "config_and_inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.tests.test_modeling_tf_albert.TFAlbertModelTest.test_model_from_pretrained": [[211, 216], ["list", "TFAlbertModel.from_pretrained", "test_modeling_tf_albert.TFAlbertModelTest.assertIsNotNone", "TF_ALBERT_PRETRAINED_MODEL_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained"], ["", "@", "slow", "\n", "def", "test_model_from_pretrained", "(", "self", ")", ":", "\n", "        ", "for", "model_name", "in", "list", "(", "TF_ALBERT_PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", "[", ":", "1", "]", ":", "\n", "            ", "model", "=", "TFAlbertModel", ".", "from_pretrained", "(", "model_name", ",", "cache_dir", "=", "CACHE_DIR", ")", "\n", "self", ".", "assertIsNotNone", "(", "model", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.tree_inference.decode_MST": [[4, 213], ["numpy.array", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "dict", "tree_inference.decode_MST.chuLiuEdmonds"], "function", ["None"], ["def", "decode_MST", "(", "energies", ",", "leading_symbolic", "=", "0", ",", "labeled", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    decode best parsing tree with MST algorithm.\n    :param energies: energies: numpy 3D tensor\n        energies of each edge. the shape is [num_labels, n_steps, n_steps],\n        where the summy root is at index 0.\n    :param leading_symbolic: int\n        number of symbolic dependency labels leading in label alphabets)\n    :return:\n    \"\"\"", "\n", "\n", "def", "find_cycle", "(", "par", ")", ":", "\n", "        ", "added", "=", "np", ".", "zeros", "(", "[", "length", "]", ",", "np", ".", "bool", ")", "\n", "added", "[", "0", "]", "=", "True", "\n", "cycle", "=", "set", "(", ")", "\n", "findcycle", "=", "False", "\n", "for", "i", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "            ", "if", "findcycle", ":", "\n", "                ", "break", "\n", "\n", "", "if", "added", "[", "i", "]", "or", "not", "curr_nodes", "[", "i", "]", ":", "\n", "                ", "continue", "\n", "\n", "# init cycle", "\n", "", "tmp_cycle", "=", "set", "(", ")", "\n", "tmp_cycle", ".", "add", "(", "i", ")", "\n", "added", "[", "i", "]", "=", "True", "\n", "findcycle", "=", "True", "\n", "l", "=", "i", "\n", "\n", "while", "par", "[", "l", "]", "not", "in", "tmp_cycle", ":", "\n", "                ", "l", "=", "par", "[", "l", "]", "\n", "if", "added", "[", "l", "]", ":", "\n", "                    ", "findcycle", "=", "False", "\n", "break", "\n", "", "added", "[", "l", "]", "=", "True", "\n", "tmp_cycle", ".", "add", "(", "l", ")", "\n", "\n", "", "if", "findcycle", ":", "\n", "                ", "lorg", "=", "l", "\n", "cycle", ".", "add", "(", "lorg", ")", "\n", "l", "=", "par", "[", "lorg", "]", "\n", "while", "l", "!=", "lorg", ":", "\n", "                    ", "cycle", ".", "add", "(", "l", ")", "\n", "l", "=", "par", "[", "l", "]", "\n", "", "break", "\n", "\n", "", "", "return", "findcycle", ",", "cycle", "\n", "\n", "", "def", "chuLiuEdmonds", "(", ")", ":", "\n", "        ", "par", "=", "np", ".", "zeros", "(", "[", "length", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "# create best graph", "\n", "par", "[", "0", "]", "=", "-", "1", "\n", "for", "i", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "# only interested at current nodes", "\n", "            ", "if", "curr_nodes", "[", "i", "]", ":", "\n", "                ", "max_score", "=", "score_matrix", "[", "0", ",", "i", "]", "\n", "par", "[", "i", "]", "=", "0", "\n", "for", "j", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "                    ", "if", "j", "==", "i", "or", "not", "curr_nodes", "[", "j", "]", ":", "\n", "                        ", "continue", "\n", "\n", "", "new_score", "=", "score_matrix", "[", "j", ",", "i", "]", "\n", "if", "new_score", ">", "max_score", ":", "\n", "                        ", "max_score", "=", "new_score", "\n", "par", "[", "i", "]", "=", "j", "\n", "\n", "# find a cycle", "\n", "", "", "", "", "findcycle", ",", "cycle", "=", "find_cycle", "(", "par", ")", "\n", "# no cycles, get all edges and return them.", "\n", "if", "not", "findcycle", ":", "\n", "            ", "final_edges", "[", "0", "]", "=", "-", "1", "\n", "for", "i", "in", "range", "(", "1", ",", "length", ")", ":", "\n", "                ", "if", "not", "curr_nodes", "[", "i", "]", ":", "\n", "                    ", "continue", "\n", "\n", "", "pr", "=", "oldI", "[", "par", "[", "i", "]", ",", "i", "]", "\n", "ch", "=", "oldO", "[", "par", "[", "i", "]", ",", "i", "]", "\n", "final_edges", "[", "ch", "]", "=", "pr", "\n", "", "return", "\n", "\n", "", "cyc_len", "=", "len", "(", "cycle", ")", "\n", "cyc_weight", "=", "0.0", "\n", "cyc_nodes", "=", "np", ".", "zeros", "(", "[", "cyc_len", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "id", "=", "0", "\n", "for", "cyc_node", "in", "cycle", ":", "\n", "            ", "cyc_nodes", "[", "id", "]", "=", "cyc_node", "\n", "id", "+=", "1", "\n", "cyc_weight", "+=", "score_matrix", "[", "par", "[", "cyc_node", "]", ",", "cyc_node", "]", "\n", "\n", "", "rep", "=", "cyc_nodes", "[", "0", "]", "\n", "for", "i", "in", "range", "(", "length", ")", ":", "\n", "            ", "if", "not", "curr_nodes", "[", "i", "]", "or", "i", "in", "cycle", ":", "\n", "                ", "continue", "\n", "\n", "", "max1", "=", "float", "(", "\"-inf\"", ")", "\n", "wh1", "=", "-", "1", "\n", "max2", "=", "float", "(", "\"-inf\"", ")", "\n", "wh2", "=", "-", "1", "\n", "\n", "for", "j", "in", "range", "(", "cyc_len", ")", ":", "\n", "                ", "j1", "=", "cyc_nodes", "[", "j", "]", "\n", "if", "score_matrix", "[", "j1", ",", "i", "]", ">", "max1", ":", "\n", "                    ", "max1", "=", "score_matrix", "[", "j1", ",", "i", "]", "\n", "wh1", "=", "j1", "\n", "\n", "", "scr", "=", "cyc_weight", "+", "score_matrix", "[", "i", ",", "j1", "]", "-", "score_matrix", "[", "par", "[", "j1", "]", ",", "j1", "]", "\n", "\n", "if", "scr", ">", "max2", ":", "\n", "                    ", "max2", "=", "scr", "\n", "wh2", "=", "j1", "\n", "\n", "", "", "score_matrix", "[", "rep", ",", "i", "]", "=", "max1", "\n", "oldI", "[", "rep", ",", "i", "]", "=", "oldI", "[", "wh1", ",", "i", "]", "\n", "oldO", "[", "rep", ",", "i", "]", "=", "oldO", "[", "wh1", ",", "i", "]", "\n", "score_matrix", "[", "i", ",", "rep", "]", "=", "max2", "\n", "oldO", "[", "i", ",", "rep", "]", "=", "oldO", "[", "i", ",", "wh2", "]", "\n", "oldI", "[", "i", ",", "rep", "]", "=", "oldI", "[", "i", ",", "wh2", "]", "\n", "\n", "", "rep_cons", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "cyc_len", ")", ":", "\n", "            ", "rep_cons", ".", "append", "(", "set", "(", ")", ")", "\n", "cyc_node", "=", "cyc_nodes", "[", "i", "]", "\n", "for", "cc", "in", "reps", "[", "cyc_node", "]", ":", "\n", "                ", "rep_cons", "[", "i", "]", ".", "add", "(", "cc", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "1", ",", "cyc_len", ")", ":", "\n", "            ", "cyc_node", "=", "cyc_nodes", "[", "i", "]", "\n", "curr_nodes", "[", "cyc_node", "]", "=", "False", "\n", "for", "cc", "in", "reps", "[", "cyc_node", "]", ":", "\n", "                ", "reps", "[", "rep", "]", ".", "add", "(", "cc", ")", "\n", "\n", "", "", "chuLiuEdmonds", "(", ")", "\n", "\n", "# check each node in cycle, if one of its representatives is a key in the final_edges, it is the one.", "\n", "found", "=", "False", "\n", "wh", "=", "-", "1", "\n", "for", "i", "in", "range", "(", "cyc_len", ")", ":", "\n", "            ", "for", "repc", "in", "rep_cons", "[", "i", "]", ":", "\n", "                ", "if", "repc", "in", "final_edges", ":", "\n", "                    ", "wh", "=", "cyc_nodes", "[", "i", "]", "\n", "found", "=", "True", "\n", "break", "\n", "", "", "if", "found", ":", "\n", "                ", "break", "\n", "\n", "", "", "l", "=", "par", "[", "wh", "]", "\n", "while", "l", "!=", "wh", ":", "\n", "            ", "ch", "=", "oldO", "[", "par", "[", "l", "]", ",", "l", "]", "\n", "pr", "=", "oldI", "[", "par", "[", "l", "]", ",", "l", "]", "\n", "final_edges", "[", "ch", "]", "=", "pr", "\n", "l", "=", "par", "[", "l", "]", "\n", "\n", "", "", "if", "labeled", ":", "\n", "        ", "assert", "energies", ".", "ndim", "==", "3", ",", "'dimension of energies is not equal to 3'", "\n", "", "else", ":", "\n", "        ", "assert", "energies", ".", "ndim", "==", "2", ",", "'dimension of energies is not equal to 2'", "\n", "\n", "", "input_shape", "=", "energies", ".", "shape", "\n", "length", "=", "input_shape", "[", "1", "]", "\n", "\n", "# calc real energies matrix shape = [length, length, num_labels - #symbolic] (remove the label for symbolic labels).", "\n", "if", "labeled", ":", "\n", "        ", "energies", "=", "energies", "[", "leading_symbolic", ":", ",", ":", ",", ":", "]", "\n", "# get best label for each edge.", "\n", "label_id_matrix", "=", "energies", ".", "argmax", "(", "axis", "=", "0", ")", "+", "leading_symbolic", "\n", "energies", "=", "energies", ".", "max", "(", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "label_id_matrix", "=", "None", "\n", "# get original score matrix", "\n", "", "orig_score_matrix", "=", "energies", "\n", "# initialize score matrix to original score matrix", "\n", "score_matrix", "=", "np", ".", "array", "(", "orig_score_matrix", ",", "copy", "=", "True", ")", "\n", "\n", "oldI", "=", "np", ".", "zeros", "(", "[", "length", ",", "length", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "oldO", "=", "np", ".", "zeros", "(", "[", "length", ",", "length", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "curr_nodes", "=", "np", ".", "zeros", "(", "[", "length", "]", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "reps", "=", "[", "]", "\n", "\n", "for", "s", "in", "range", "(", "length", ")", ":", "\n", "        ", "orig_score_matrix", "[", "s", ",", "s", "]", "=", "0.0", "\n", "score_matrix", "[", "s", ",", "s", "]", "=", "0.0", "\n", "curr_nodes", "[", "s", "]", "=", "True", "\n", "reps", ".", "append", "(", "set", "(", ")", ")", "\n", "reps", "[", "s", "]", ".", "add", "(", "s", ")", "\n", "for", "t", "in", "range", "(", "s", "+", "1", ",", "length", ")", ":", "\n", "            ", "oldI", "[", "s", ",", "t", "]", "=", "s", "\n", "oldO", "[", "s", ",", "t", "]", "=", "t", "\n", "\n", "oldI", "[", "t", ",", "s", "]", "=", "t", "\n", "oldO", "[", "t", ",", "s", "]", "=", "s", "\n", "\n", "", "", "final_edges", "=", "dict", "(", ")", "\n", "chuLiuEdmonds", "(", ")", "\n", "par", "=", "np", ".", "zeros", "(", "[", "length", "]", ",", "np", ".", "int32", ")", "\n", "if", "labeled", ":", "\n", "        ", "label", "=", "np", ".", "ones", "(", "[", "length", "]", ",", "np", ".", "int32", ")", "\n", "label", "[", "0", "]", "=", "0", "\n", "", "else", ":", "\n", "        ", "label", "=", "None", "\n", "\n", "", "for", "ch", ",", "pr", "in", "final_edges", ".", "items", "(", ")", ":", "\n", "        ", "par", "[", "ch", "]", "=", "pr", "\n", "if", "labeled", "and", "ch", "!=", "0", ":", "\n", "            ", "label", "[", "ch", "]", "=", "label_id_matrix", "[", "pr", ",", "ch", "]", "\n", "\n", "", "", "par", "[", "0", "]", "=", "0", "\n", "\n", "return", "par", ".", "tolist", "(", ")", "[", "1", ":", "]", ",", "label", ".", "tolist", "(", ")", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.tree_inference.decode_GGDP_projective": [[215, 278], ["numpy.zeros", "numpy.array", "float", "numpy.ones", "energies.max.max", "len", "range", "energies.max.argmax", "range", "float", "range", "np.zeros.tolist", "np.ones.tolist", "len"], "function", ["None"], ["", "def", "decode_GGDP_projective", "(", "energies", ",", "leading_symbolic", "=", "0", ",", "labeled", "=", "True", ")", ":", "\n", "    ", "if", "labeled", ":", "\n", "        ", "assert", "energies", ".", "ndim", "==", "3", ",", "'dimension of energies is not equal to 3'", "\n", "", "else", ":", "\n", "        ", "assert", "energies", ".", "ndim", "==", "2", ",", "'dimension of energies is not equal to 2'", "\n", "\n", "", "input_shape", "=", "energies", ".", "shape", "\n", "length", "=", "input_shape", "[", "1", "]", "\n", "\n", "par", "=", "np", ".", "zeros", "(", "[", "length", "]", ",", "np", ".", "int32", ")", "\n", "if", "labeled", ":", "\n", "        ", "label", "=", "np", ".", "ones", "(", "[", "length", "]", ",", "np", ".", "int32", ")", "\n", "label", "[", "0", "]", "=", "0", "\n", "", "else", ":", "\n", "        ", "label", "=", "None", "\n", "\n", "# calc real energies matrix shape = [length, length, num_labels - #symbolic] (remove the label for symbolic labels).", "\n", "", "if", "labeled", ":", "\n", "        ", "energies", "=", "energies", "[", "leading_symbolic", ":", ",", ":", ",", ":", "]", "\n", "# get best label for each edge.", "\n", "label_id_matrix", "=", "energies", ".", "argmax", "(", "axis", "=", "0", ")", "+", "leading_symbolic", "\n", "energies", "=", "energies", ".", "max", "(", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "label_id_matrix", "=", "None", "\n", "# get original score matrix", "\n", "", "orig_score_matrix", "=", "energies", "\n", "# initialize score matrix to original score matrix", "\n", "score_matrix", "=", "np", ".", "array", "(", "orig_score_matrix", ",", "copy", "=", "True", ")", "\n", "\n", "# because ROOT will not have head", "\n", "score_matrix", "[", ":", ",", "0", "]", "=", "float", "(", "'-inf'", ")", "\n", "\n", "pending_list", "=", "[", "idx", "for", "idx", "in", "range", "(", "length", ")", "]", "\n", "\n", "while", "len", "(", "pending_list", ")", ">", "1", ":", "\n", "        ", "valid_head", ",", "valid_dep", ",", "valid_score", "=", "None", ",", "None", ",", "float", "(", "'-inf'", ")", "\n", "selected_head", ",", "selected_dep", "=", "None", ",", "None", "\n", "\n", "for", "idx", "in", "range", "(", "len", "(", "pending_list", ")", "-", "1", ")", ":", "\n", "# AttachLeft or AttachRight", "\n", "            ", "for", "op", "in", "range", "(", "2", ")", ":", "\n", "                ", "hi", ",", "di", "=", "idx", "+", "(", "1", "-", "op", ")", ",", "idx", "+", "op", "\n", "\n", "head_id", "=", "pending_list", "[", "hi", "]", "\n", "dep_id", "=", "pending_list", "[", "di", "]", "\n", "\n", "if", "valid_score", "<", "score_matrix", "[", "head_id", ",", "dep_id", "]", ":", "\n", "                    ", "valid_score", "=", "score_matrix", "[", "head_id", ",", "dep_id", "]", "\n", "valid_head", ",", "valid_dep", "=", "head_id", ",", "dep_id", "\n", "selected_head", ",", "selected_dep", "=", "hi", ",", "di", "\n", "\n", "", "", "", "assert", "valid_head", "is", "not", "None", ",", "'Fatal Error!'", "\n", "\n", "par", "[", "valid_dep", "]", "=", "valid_head", "\n", "\n", "if", "labeled", ":", "\n", "            ", "label", "[", "valid_dep", "]", "=", "label_id_matrix", "[", "valid_head", ",", "valid_dep", "]", "\n", "\n", "", "del", "pending_list", "[", "selected_dep", "]", "\n", "\n", "", "par", "[", "0", "]", "=", "0", "\n", "\n", "return", "par", ".", "tolist", "(", ")", "[", "1", ":", "]", ",", "label", ".", "tolist", "(", ")", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.tree_inference.decode_GGDP_nonprojective": [[280, 346], ["numpy.zeros", "numpy.array", "float", "float", "list", "numpy.ones", "energies.max.max", "numpy.argsort", "len", "range", "energies.max.argmax", "float", "len", "np.zeros.tolist", "np.ones.tolist"], "function", ["None"], ["", "def", "decode_GGDP_nonprojective", "(", "energies", ",", "order_scores", ",", "leading_symbolic", "=", "0", ",", "labeled", "=", "True", ")", ":", "\n", "    ", "if", "labeled", ":", "\n", "        ", "assert", "energies", ".", "ndim", "==", "3", ",", "'dimension of energies is not equal to 3'", "\n", "", "else", ":", "\n", "        ", "assert", "energies", ".", "ndim", "==", "2", ",", "'dimension of energies is not equal to 2'", "\n", "\n", "", "input_shape", "=", "energies", ".", "shape", "\n", "length", "=", "input_shape", "[", "1", "]", "\n", "\n", "par", "=", "np", ".", "zeros", "(", "[", "length", "]", ",", "np", ".", "int32", ")", "\n", "if", "labeled", ":", "\n", "        ", "label", "=", "np", ".", "ones", "(", "[", "length", "]", ",", "np", ".", "int32", ")", "\n", "label", "[", "0", "]", "=", "0", "\n", "", "else", ":", "\n", "        ", "label", "=", "None", "\n", "\n", "# calc real energies matrix shape = [length, length, num_labels - #symbolic] (remove the label for symbolic labels).", "\n", "", "if", "labeled", ":", "\n", "        ", "energies", "=", "energies", "[", "leading_symbolic", ":", ",", ":", ",", ":", "]", "\n", "# get best label for each edge.", "\n", "label_id_matrix", "=", "energies", ".", "argmax", "(", "axis", "=", "0", ")", "+", "leading_symbolic", "\n", "energies", "=", "energies", ".", "max", "(", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "label_id_matrix", "=", "None", "\n", "\n", "# get original score matrix", "\n", "", "orig_score_matrix", "=", "energies", "\n", "# initialize score matrix to original score matrix", "\n", "score_matrix", "=", "np", ".", "array", "(", "orig_score_matrix", ",", "copy", "=", "True", ")", "\n", "\n", "# because ROOT will not have head", "\n", "score_matrix", "[", ":", ",", "0", "]", "=", "float", "(", "'-inf'", ")", "\n", "\n", "# make root the last position", "\n", "order_scores", "[", "0", "]", "=", "float", "(", "'-inf'", ")", "\n", "\n", "pending_list", "=", "list", "(", "np", ".", "argsort", "(", "-", "order_scores", ")", ")", "\n", "\n", "while", "len", "(", "pending_list", ")", ">", "1", ":", "\n", "        ", "valid_head", ",", "valid_dep", ",", "valid_score", "=", "None", ",", "None", ",", "float", "(", "'-inf'", ")", "\n", "selected_head", ",", "selected_dep", "=", "None", ",", "None", "\n", "\n", "for", "idx", "in", "range", "(", "1", ",", "len", "(", "pending_list", ")", ")", ":", "\n", "\n", "            ", "hi", ",", "di", "=", "idx", ",", "0", "\n", "\n", "head_id", "=", "pending_list", "[", "hi", "]", "\n", "dep_id", "=", "pending_list", "[", "di", "]", "\n", "\n", "if", "valid_score", "<", "score_matrix", "[", "head_id", ",", "dep_id", "]", ":", "\n", "                ", "valid_score", "=", "score_matrix", "[", "head_id", ",", "dep_id", "]", "\n", "valid_head", ",", "valid_dep", "=", "head_id", ",", "dep_id", "\n", "selected_head", ",", "selected_dep", "=", "hi", ",", "di", "\n", "\n", "", "", "assert", "valid_head", "is", "not", "None", ",", "'Fatal Error!'", "\n", "\n", "par", "[", "valid_dep", "]", "=", "valid_head", "\n", "\n", "if", "labeled", ":", "\n", "            ", "label", "[", "valid_dep", "]", "=", "label_id_matrix", "[", "valid_head", ",", "valid_dep", "]", "\n", "\n", "", "del", "pending_list", "[", "selected_dep", "]", "\n", "\n", "", "par", "[", "0", "]", "=", "0", "\n", "\n", "return", "par", ".", "tolist", "(", ")", "[", "1", ":", "]", ",", "label", ".", "tolist", "(", ")", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.generate_postag_and_labels.read_conll": [[3, 18], ["open", "fin.readlines", "len", "conll_data.append", "len", "sent_data.append", "line.strip", "len", "conll_data.append", "line.strip().split", "line.strip"], "function", ["None"], ["def", "read_conll", "(", "file_name", ")", ":", "\n", "    ", "with", "open", "(", "file_name", ",", "\"r\"", ")", "as", "fin", ":", "\n", "        ", "data", "=", "fin", ".", "readlines", "(", ")", "\n", "", "conll_data", "=", "[", "]", "\n", "sent_data", "=", "[", "]", "\n", "for", "line", "in", "data", ":", "\n", "        ", "if", "len", "(", "line", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "            ", "if", "len", "(", "sent_data", ")", ">", "0", ":", "\n", "                ", "conll_data", ".", "append", "(", "sent_data", ")", "\n", "sent_data", "=", "[", "]", "\n", "", "", "else", ":", "\n", "            ", "sent_data", ".", "append", "(", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", ")", "\n", "", "", "if", "len", "(", "sent_data", ")", ">", "0", ":", "\n", "        ", "conll_data", ".", "append", "(", "sent_data", ")", "\n", "", "return", "conll_data", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.InputExample.__init__": [[39, 55], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "index", ",", "words", ",", "postags", ",", "orders", ",", "heads", ",", "labels", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            index: int. Index for the example.\n            words: list. The words of the sequence.\n            postags: (Optional) list. The postags of the sequence.\n            heads: (Optional) list. The dependency heads of the sequence.\n            labels: (Optional) list. The dependency labels for each word of the sequence.\n        \"\"\"", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "words", "=", "words", "\n", "self", ".", "postags", "=", "postags", "\n", "self", ".", "orders", "=", "orders", "\n", "self", ".", "heads", "=", "heads", "\n", "self", ".", "labels", "=", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.InputFeatures.__init__": [[59, 70], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "index", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "postag_ids", ",", "head_ids", ",", "label_ids", ",", "word_token_starts", ",", "word_token_ends", ",", "token_word_indexs", ")", ":", "\n", "        ", "self", ".", "index", "=", "index", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "postag_ids", "=", "postag_ids", "\n", "self", ".", "head_ids", "=", "head_ids", "\n", "self", ".", "label_ids", "=", "label_ids", "\n", "self", ".", "word_token_starts", "=", "word_token_starts", "\n", "self", ".", "word_token_ends", "=", "word_token_ends", "\n", "self", ".", "token_word_indexs", "=", "token_word_indexs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.InputFeaturesWithParsingOrder.__init__": [[75, 87], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "index", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "postag_ids", ",", "order_ids", ",", "head_ids", ",", "label_ids", ",", "word_token_starts", ",", "word_token_ends", ",", "token_word_indexs", ")", ":", "\n", "        ", "self", ".", "index", "=", "index", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "postag_ids", "=", "postag_ids", "\n", "self", ".", "order_ids", "=", "order_ids", "\n", "self", ".", "head_ids", "=", "head_ids", "\n", "self", ".", "label_ids", "=", "label_ids", "\n", "self", ".", "word_token_starts", "=", "word_token_starts", "\n", "self", ".", "word_token_ends", "=", "word_token_ends", "\n", "self", ".", "token_word_indexs", "=", "token_word_indexs", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.get_parsing_orders": [[24, 34], ["range", "len", "orders.append"], "function", ["None"], ["def", "get_parsing_orders", "(", "heads", ")", ":", "\n", "    ", "orders", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "heads", ")", ")", ":", "\n", "        ", "h", "=", "heads", "[", "idx", "]", "\n", "o", "=", "1", "\n", "while", "h", "!=", "0", ":", "\n", "            ", "h", "=", "heads", "[", "h", "-", "1", "]", "\n", "o", "+=", "1", "\n", "", "orders", ".", "append", "(", "o", ")", "\n", "", "return", "orders", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.read_examples_from_file": [[89, 128], ["os.path.join", "open", "examples.append", "len", "line.strip().split", "words.append", "utils_dependency_parsing.InputExample", "line.strip", "examples.append", "postags.append", "heads.append", "labels.append", "utils_dependency_parsing.InputExample", "line.strip", "int", "utils_dependency_parsing.get_parsing_orders", "utils_dependency_parsing.get_parsing_orders"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.get_parsing_orders", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.get_parsing_orders"], ["", "", "def", "read_examples_from_file", "(", "data_dir", ",", "file_name", ",", "is_training", "=", "True", ",", "use_postag", "=", "True", ",", "with_parsing_order", "=", "False", ")", ":", "\n", "    ", "file_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file_name", ")", "\n", "example_index", "=", "0", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "words", "=", "[", "]", "\n", "postags", "=", "[", "]", "\n", "heads", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "            ", "if", "len", "(", "line", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "                ", "if", "words", ":", "\n", "                    ", "examples", ".", "append", "(", "InputExample", "(", "index", "=", "example_index", ",", "\n", "words", "=", "words", ",", "\n", "postags", "=", "postags", "if", "use_postag", "else", "None", ",", "\n", "orders", "=", "get_parsing_orders", "(", "heads", ")", "if", "is_training", "and", "with_parsing_order", "else", "None", ",", "\n", "heads", "=", "heads", "if", "is_training", "else", "None", ",", "\n", "labels", "=", "labels", "if", "is_training", "else", "None", ")", ")", "\n", "example_index", "+=", "1", "\n", "words", "=", "[", "]", "\n", "postags", "=", "[", "]", "\n", "heads", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "", "", "else", ":", "\n", "                ", "splits", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "words", ".", "append", "(", "splits", "[", "1", "]", ")", "\n", "if", "use_postag", ":", "\n", "                    ", "postags", ".", "append", "(", "splits", "[", "4", "]", ")", "\n", "", "if", "is_training", ":", "\n", "                    ", "heads", ".", "append", "(", "int", "(", "splits", "[", "6", "]", ")", ")", "\n", "labels", ".", "append", "(", "splits", "[", "7", "]", ")", "\n", "", "", "", "if", "words", ":", "\n", "            ", "examples", ".", "append", "(", "InputExample", "(", "index", "=", "example_index", ",", "\n", "words", "=", "words", ",", "\n", "postags", "=", "postags", "if", "use_postag", "else", "None", ",", "\n", "orders", "=", "get_parsing_orders", "(", "heads", ")", "if", "is_training", "and", "with_parsing_order", "else", "None", ",", "\n", "heads", "=", "heads", "if", "is_training", "else", "None", ",", "\n", "labels", "=", "labels", "if", "is_training", "else", "None", ")", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.convert_examples_to_features": [[130, 395], ["enumerate", "enumerate", "tokenizer.convert_tokens_to_ids", "features.append", "logger.info", "tokenizer.tokenize", "word_token_starts.append", "tokens.extend", "token_word_indexs.extend", "word_token_ends.append", "enumerate", "enumerate", "len", "len", "len", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils_dependency_parsing.InputFeatures", "enumerate", "enumerate", "postag_map.keys", "postag_map.keys", "label_map.keys", "label_map.keys", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "len", "len", "postag_ids.extend", "postag_ids.extend", "label_ids.extend", "head_ids.extend", "head_ids.extend", "label_ids.extend", "label_ids.extend", "str", "str", "str", "str", "head_ids.append", "head_ids.append", "head_ids.append", "head_ids.append", "str", "str", "str", "range", "range"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "convert_examples_to_features", "(", "\n", "examples", ",", "\n", "max_seq_length", ",", "\n", "tokenizer", ",", "\n", "cls_token_at_end", "=", "False", ",", "\n", "cls_token", "=", "\"[CLS]\"", ",", "\n", "cls_token_segment_id", "=", "1", ",", "\n", "sep_token", "=", "\"[SEP]\"", ",", "\n", "sep_token_extra", "=", "False", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", "is_training", "=", "False", ",", "\n", "use_postag", "=", "False", ",", "\n", "postag_list", "=", "None", ",", "\n", "label_list", "=", "None", ",", "\n", "pad_postag", "=", "'_'", ",", "\n", "pad_label", "=", "'_'", ",", "\n", "convert_strategy", "=", "0", ",", "\n", "special_postag", "=", "'_'", ",", "\n", "special_label", "=", "'_'", ",", "\n", ")", ":", "\n", "    ", "\"\"\" Loads a data file into a list of `InputBatch`s\n        `cls_token_at_end` define the location of the CLS token:\n            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n    \"\"\"", "\n", "\n", "postag_map", "=", "{", "postag", ":", "i", "for", "i", ",", "postag", "in", "enumerate", "(", "postag_list", ")", "}", "if", "postag_list", "is", "not", "None", "else", "None", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "if", "label_list", "is", "not", "None", "else", "None", "\n", "\n", "if", "use_postag", ":", "\n", "        ", "assert", "postag_map", "is", "not", "None", "and", "pad_postag", "in", "postag_map", ".", "keys", "(", ")", "\n", "pad_postag_id", "=", "postag_map", "[", "pad_postag", "]", "\n", "if", "convert_strategy", ">", "0", ":", "\n", "            ", "assert", "special_postag", "in", "postag_map", ".", "keys", "(", ")", "\n", "special_postag_id", "=", "postag_map", "[", "special_postag", "]", "\n", "", "", "if", "is_training", ":", "\n", "        ", "assert", "label_map", "is", "not", "None", "and", "pad_label", "in", "label_map", ".", "keys", "(", ")", "\n", "pad_label_id", "=", "label_map", "[", "pad_label", "]", "\n", "if", "convert_strategy", ">", "0", ":", "\n", "            ", "assert", "special_label", "in", "label_map", ".", "keys", "(", ")", "\n", "special_label_id", "=", "label_map", "[", "special_label", "]", "\n", "\n", "", "", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d of %d\"", ",", "ex_index", ",", "len", "(", "examples", ")", ")", "\n", "\n", "# \u5bf9\u4e8e\u4f9d\u5b58\u53e5\u6cd5\u89e3\u6790\uff0c\u5219\u9700\u8981\u5c06word\u7ea7\u522b\u7684\u53e5\u6cd5\u6811\u8f6c\u4e3asubword\u7ea7\u522b\u53e5\u6cd5\u6811\uff0c\u7b56\u7565\u6709\uff1a", "\n", "# 0. \u5c06word\u5bf9\u5e94\u7684\u6240\u6709subword\u7684head\u8bbe\u7f6e\u4e3a\u539fword\u7684\u7b2c\u4e00\u4e2asubword\uff0clabel\u8bbe\u7f6e\u4e0eword\u76f8\u540c", "\n", "# 1. \u5c06word\u5bf9\u5e94\u7684\u7b2c\u4e00\u4e2asubword\u7684head\u8bbe\u7f6e\u4e3a\u539fword\u7684\u7b2c\u4e00\u4e2asubword\uff0clabel\u8bbe\u7f6e\u4e0eword\u76f8\u540c\uff0c\u5176\u4f59subword\u7684head\u8bbe\u7f6e\u4e3a\u7b2c\u4e00\u4e2asubword\uff0clabel\u4f7f\u7528\u7279\u6b8a\u6807\u7b7e", "\n", "# 2. \u5c06word\u5bf9\u5e94\u7684\u7b2c\u4e00\u4e2asubword\u7684head\u8bbe\u7f6e\u4e3a\u539fword\u7684\u7b2c\u4e00\u4e2asubword\uff0clabel\u8bbe\u7f6e\u4e0eword\u76f8\u540c\uff0c\u5176\u4f59subword\u7684head\u8bbe\u7f6e\u4e3a\u524d\u4e00\u4e2asubword\uff0clabel\u4f7f\u7528\u7279\u6b8a\u6807\u7b7e", "\n", "\n", "", "tokens", "=", "[", "]", "\n", "word_token_starts", "=", "[", "]", "\n", "word_token_ends", "=", "[", "]", "\n", "token_word_indexs", "=", "[", "]", "\n", "for", "word_index", ",", "word", "in", "enumerate", "(", "example", ".", "words", ")", ":", "\n", "            ", "word_tokens", "=", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "word_token_starts", ".", "append", "(", "len", "(", "tokens", ")", ")", "\n", "tokens", ".", "extend", "(", "word_tokens", ")", "\n", "token_word_indexs", ".", "extend", "(", "[", "word_index", "]", "*", "len", "(", "word_tokens", ")", ")", "\n", "word_token_ends", ".", "append", "(", "len", "(", "tokens", ")", "-", "1", ")", "\n", "\n", "", "postag_ids", "=", "None", "\n", "head_ids", "=", "None", "\n", "label_ids", "=", "None", "\n", "\n", "if", "use_postag", ":", "\n", "            ", "postag_ids", "=", "[", "]", "\n", "for", "word_index", ",", "postag", "in", "enumerate", "(", "example", ".", "postags", ")", ":", "\n", "                ", "token_span_len", "=", "word_token_ends", "[", "word_index", "]", "-", "word_token_starts", "[", "word_index", "]", "+", "1", "\n", "if", "convert_strategy", "==", "0", ":", "\n", "                    ", "postag_ids", ".", "extend", "(", "[", "postag_map", "[", "postag", "]", "]", "*", "token_span_len", ")", "\n", "", "else", ":", "\n", "                    ", "postag_ids", ".", "extend", "(", "[", "postag_map", "[", "postag", "]", "]", "+", "[", "special_postag_id", "]", "*", "(", "token_span_len", "-", "1", ")", ")", "\n", "\n", "\n", "", "", "", "if", "is_training", ":", "\n", "            ", "if", "convert_strategy", ">", "0", ":", "\n", "                ", "assert", "special_postag_id", ">=", "0", "\n", "assert", "special_label_id", ">=", "0", "\n", "", "head_ids", "=", "[", "]", "\n", "label_ids", "=", "[", "]", "\n", "for", "word_index", ",", "head", "in", "enumerate", "(", "example", ".", "heads", ")", ":", "\n", "                ", "head", "=", "head", "-", "1", "# the truely word index", "\n", "label", "=", "example", ".", "labels", "[", "word_index", "]", "\n", "token_span_len", "=", "word_token_ends", "[", "word_index", "]", "-", "word_token_starts", "[", "word_index", "]", "+", "1", "\n", "if", "convert_strategy", "==", "0", ":", "\n", "                    ", "if", "head", "==", "-", "1", ":", "# position for <ROOT>", "\n", "                        ", "head_ids", ".", "extend", "(", "[", "-", "1", "]", "*", "token_span_len", ")", "\n", "", "else", ":", "\n", "                        ", "head_ids", ".", "extend", "(", "[", "word_token_starts", "[", "head", "]", "]", "*", "token_span_len", ")", "\n", "", "label_ids", ".", "extend", "(", "[", "label_map", "[", "label", "]", "]", "*", "token_span_len", ")", "\n", "", "elif", "convert_strategy", "==", "1", ":", "\n", "                    ", "if", "head", "==", "-", "1", ":", "# position for <ROOT>", "\n", "                        ", "head_ids", ".", "append", "(", "[", "-", "1", "]", "+", "[", "word_token_starts", "[", "word_index", "]", "]", "*", "(", "token_span_len", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                        ", "head_ids", ".", "append", "(", "[", "word_token_starts", "[", "head", "]", "]", "+", "[", "word_token_starts", "[", "word_index", "]", "]", "*", "(", "token_span_len", "-", "1", ")", ")", "\n", "", "label_ids", ".", "extend", "(", "[", "label_map", "[", "label", "]", "]", "+", "[", "special_label_id", "]", "*", "(", "token_span_len", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                    ", "if", "head", "==", "-", "1", ":", "# position for <ROOT>", "\n", "                        ", "head_ids", ".", "append", "(", "[", "-", "1", "]", "+", "[", "word_token_starts", "[", "word_index", "]", "+", "idx", "for", "idx", "in", "range", "(", "token_span_len", "-", "1", ")", "]", ")", "\n", "", "else", ":", "\n", "                        ", "head_ids", ".", "append", "(", "[", "word_token_starts", "[", "head", "]", "]", "+", "[", "word_token_starts", "[", "word_index", "]", "+", "idx", "for", "idx", "in", "range", "(", "token_span_len", "-", "1", ")", "]", ")", "\n", "", "label_ids", ".", "extend", "(", "[", "label_map", "[", "label", "]", "]", "+", "[", "special_label_id", "]", "*", "(", "token_span_len", "-", "1", ")", ")", "\n", "\n", "\n", "# Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.", "\n", "", "", "", "special_tokens_count", "=", "3", "if", "sep_token_extra", "else", "2", "\n", "assert", "len", "(", "tokens", ")", "<=", "max_seq_length", "-", "special_tokens_count", ",", "(", "len", "(", "tokens", ")", ",", "max_seq_length", ",", "special_tokens_count", ")", "\n", "\n", "# The convention in BERT is:", "\n", "# (a) For sequence pairs:", "\n", "#  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]", "\n", "#  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1", "\n", "# (b) For single sequences:", "\n", "#  tokens:   [CLS] the dog is hairy . [SEP]", "\n", "#  type_ids:   0   0   0   0  0     0   0", "\n", "#", "\n", "# Where \"type_ids\" are used to indicate whether this is the first", "\n", "# sequence or the second sequence. The embedding vectors for `type=0` and", "\n", "# `type=1` were learned during pre-training and are added to the wordpiece", "\n", "# embedding vector (and position vector). This is not *strictly* necessary", "\n", "# since the [SEP] token unambiguously separates the sequences, but it makes", "\n", "# it easier for the model to learn the concept of sequences.", "\n", "#", "\n", "# For dependency parsing tasks, the first vector (corresponding to [CLS]) is", "\n", "# used as as the \"sentence vector\". Note that this only makes sense because", "\n", "# the entire model is fine-tuned.", "\n", "\n", "tokens", "+=", "[", "sep_token", "]", "\n", "token_word_indexs", "+=", "[", "None", "]", "\n", "if", "use_postag", ":", "\n", "            ", "postag_ids", "+=", "[", "pad_postag_id", "]", "\n", "", "if", "is_training", ":", "\n", "            ", "head_ids", "+=", "[", "-", "1", "]", "\n", "label_ids", "+=", "[", "pad_label_id", "]", "\n", "\n", "", "if", "sep_token_extra", ":", "\n", "# roberta uses an extra separator b/w pairs of sentences", "\n", "            ", "tokens", "+=", "[", "sep_token", "]", "\n", "token_word_indexs", "+=", "[", "None", "]", "\n", "if", "use_postag", ":", "\n", "                ", "postag_ids", "+=", "[", "pad_postag_id", "]", "\n", "", "if", "is_training", ":", "\n", "                ", "head_ids", "+=", "[", "-", "1", "]", "\n", "label_ids", "+=", "[", "pad_label_id", "]", "\n", "\n", "", "", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "# position for <ROOT>, since we use [CLS] for ROOT", "\n", "root_index", "=", "None", "\n", "\n", "if", "cls_token_at_end", ":", "# will not change the index", "\n", "            ", "root_index", "=", "len", "(", "tokens", ")", "\n", "tokens", "+=", "[", "cls_token", "]", "\n", "token_word_indexs", "+=", "[", "None", "]", "\n", "if", "use_postag", ":", "\n", "                ", "postag_ids", "+=", "[", "pad_postag_id", "]", "\n", "", "if", "is_training", ":", "\n", "                ", "head_ids", "+=", "[", "-", "1", "]", "\n", "label_ids", "+=", "[", "pad_label_id", "]", "\n", "", "segment_ids", "+=", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "# index changed", "\n", "            ", "root_index", "=", "0", "\n", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "token_word_indexs", "=", "[", "None", "]", "+", "token_word_indexs", "\n", "if", "use_postag", ":", "\n", "                ", "postag_ids", "=", "[", "pad_postag_id", "]", "+", "postag_ids", "\n", "", "if", "is_training", ":", "\n", "                ", "head_ids", "=", "[", "-", "1", "]", "+", "head_ids", "\n", "label_ids", "=", "[", "pad_label_id", "]", "+", "label_ids", "\n", "", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "# IMPORTANT!!!", "\n", "word_token_starts", "=", "[", "idx", "+", "1", "for", "idx", "in", "word_token_starts", "]", "\n", "word_token_ends", "=", "[", "idx", "+", "1", "for", "idx", "in", "word_token_ends", "]", "\n", "if", "is_training", ":", "\n", "                ", "head_ids", "=", "[", "idx", "+", "1", "if", "(", "idx", "!=", "-", "1", "and", "idx", "is", "not", "None", ")", "else", "idx", "for", "idx", "in", "head_ids", "]", "\n", "\n", "", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "# index changed", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "token_word_indexs", "=", "(", "[", "None", "]", "*", "padding_length", ")", "+", "token_word_indexs", "\n", "if", "use_postag", ":", "\n", "                ", "postag_ids", "=", "(", "[", "pad_postag_id", "]", "*", "padding_length", ")", "+", "postag_ids", "\n", "", "if", "is_training", ":", "\n", "                ", "head_ids", "=", "(", "[", "-", "1", "]", "*", "padding_length", ")", "+", "head_ids", "\n", "label_ids", "=", "(", "[", "pad_label_id", "]", "*", "padding_length", ")", "+", "label_ids", "\n", "\n", "# IMPORTANT!!!", "\n", "", "root_index", "+=", "padding_length", "\n", "word_token_starts", "=", "[", "idx", "+", "padding_length", "for", "idx", "in", "word_token_starts", "]", "\n", "word_token_ends", "=", "[", "idx", "+", "padding_length", "for", "idx", "in", "word_token_ends", "]", "\n", "if", "is_training", ":", "\n", "                ", "head_ids", "=", "[", "idx", "+", "padding_length", "if", "(", "idx", "!=", "-", "1", "and", "idx", "is", "not", "None", ")", "else", "idx", "for", "idx", "in", "head_ids", "]", "\n", "", "", "else", ":", "# will not change the index", "\n", "            ", "input_ids", "+=", "[", "pad_token", "]", "*", "padding_length", "\n", "input_mask", "+=", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", "\n", "segment_ids", "+=", "[", "pad_token_segment_id", "]", "*", "padding_length", "\n", "token_word_indexs", "=", "token_word_indexs", "+", "(", "[", "None", "]", "*", "padding_length", ")", "\n", "if", "use_postag", ":", "\n", "                ", "postag_ids", "=", "postag_ids", "+", "(", "[", "pad_postag_id", "]", "*", "padding_length", ")", "\n", "", "if", "is_training", ":", "\n", "                ", "head_ids", "=", "head_ids", "+", "(", "[", "-", "1", "]", "*", "padding_length", ")", "\n", "label_ids", "=", "label_ids", "+", "(", "[", "pad_label_id", "]", "*", "padding_length", ")", "\n", "\n", "# replace -1 to truely root position", "\n", "", "", "if", "is_training", ":", "\n", "            ", "head_ids", "=", "[", "idx", "if", "idx", "!=", "-", "1", "else", "root_index", "for", "idx", "in", "head_ids", "]", "\n", "\n", "# IMPORTANT: word length change to +1, due to <ROOT> ([CLS] in this work)", "\n", "", "word_token_starts", "=", "[", "root_index", "]", "+", "word_token_starts", "\n", "word_token_ends", "=", "[", "root_index", "]", "+", "word_token_ends", "\n", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "if", "use_postag", ":", "\n", "            ", "assert", "len", "(", "postag_ids", ")", "==", "max_seq_length", "\n", "", "if", "is_training", ":", "\n", "            ", "assert", "len", "(", "head_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "label_ids", ")", "==", "max_seq_length", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"index: %s\"", ",", "example", ".", "index", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "if", "use_postag", ":", "\n", "                ", "logger", ".", "info", "(", "\"postag_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "postag_ids", "]", ")", ")", "\n", "", "if", "is_training", ":", "\n", "                ", "logger", ".", "info", "(", "\"head_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "head_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "label_ids", "]", ")", ")", "\n", "\n", "", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "index", "=", "example", ".", "index", ",", "\n", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "postag_ids", "=", "postag_ids", ",", "\n", "head_ids", "=", "head_ids", ",", "\n", "label_ids", "=", "label_ids", ",", "\n", "word_token_starts", "=", "word_token_starts", ",", "\n", "word_token_ends", "=", "word_token_ends", ",", "\n", "token_word_indexs", "=", "token_word_indexs", "\n", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.convert_examples_to_features_with_parsing_order": [[397, 682], ["enumerate", "enumerate", "tokenizer.convert_tokens_to_ids", "features.append", "logger.info", "tokenizer.tokenize", "word_token_starts.append", "tokens.extend", "token_word_indexs.extend", "word_token_ends.append", "enumerate", "enumerate", "len", "len", "len", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils_dependency_parsing.InputFeaturesWithParsingOrder", "enumerate", "enumerate", "postag_map.keys", "postag_map.keys", "label_map.keys", "label_map.keys", "len", "len", "order_ids.extend", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "len", "len", "postag_ids.extend", "postag_ids.extend", "label_ids.extend", "head_ids.extend", "head_ids.extend", "label_ids.extend", "label_ids.extend", "str", "str", "str", "str", "head_ids.extend", "head_ids.extend", "head_ids.extend", "head_ids.extend", "str", "str", "str", "str", "range", "range"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids", "home.repos.pwc.inspect_result.bcmi220_ggdp.commands.serving.ServeCommand.tokenize"], ["", "def", "convert_examples_to_features_with_parsing_order", "(", "\n", "examples", ",", "\n", "max_seq_length", ",", "\n", "tokenizer", ",", "\n", "cls_token_at_end", "=", "False", ",", "\n", "cls_token", "=", "\"[CLS]\"", ",", "\n", "cls_token_segment_id", "=", "1", ",", "\n", "sep_token", "=", "\"[SEP]\"", ",", "\n", "sep_token_extra", "=", "False", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", "is_training", "=", "False", ",", "\n", "max_parsing_order", "=", "32", ",", "\n", "use_postag", "=", "False", ",", "\n", "postag_list", "=", "None", ",", "\n", "label_list", "=", "None", ",", "\n", "pad_postag", "=", "'_'", ",", "\n", "pad_label", "=", "'_'", ",", "\n", "convert_strategy", "=", "0", ",", "\n", "special_postag", "=", "'_'", ",", "\n", "special_label", "=", "'_'", ",", "\n", ")", ":", "\n", "    ", "\"\"\" Loads a data file into a list of `InputBatch`s\n        `cls_token_at_end` define the location of the CLS token:\n            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n    \"\"\"", "\n", "\n", "postag_map", "=", "{", "postag", ":", "i", "for", "i", ",", "postag", "in", "enumerate", "(", "postag_list", ")", "}", "if", "postag_list", "is", "not", "None", "else", "None", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "if", "label_list", "is", "not", "None", "else", "None", "\n", "\n", "if", "use_postag", ":", "\n", "        ", "assert", "postag_map", "is", "not", "None", "and", "pad_postag", "in", "postag_map", ".", "keys", "(", ")", "\n", "pad_postag_id", "=", "postag_map", "[", "pad_postag", "]", "\n", "if", "convert_strategy", ">", "0", ":", "\n", "            ", "assert", "special_postag", "in", "postag_map", ".", "keys", "(", ")", "\n", "special_postag_id", "=", "postag_map", "[", "special_postag", "]", "\n", "", "", "if", "is_training", ":", "\n", "        ", "assert", "label_map", "is", "not", "None", "and", "pad_label", "in", "label_map", ".", "keys", "(", ")", "\n", "pad_label_id", "=", "label_map", "[", "pad_label", "]", "\n", "if", "convert_strategy", ">", "0", ":", "\n", "            ", "assert", "special_label", "in", "label_map", ".", "keys", "(", ")", "\n", "special_label_id", "=", "label_map", "[", "special_label", "]", "\n", "\n", "", "", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d of %d\"", ",", "ex_index", ",", "len", "(", "examples", ")", ")", "\n", "\n", "# \u5bf9\u4e8e\u4f9d\u5b58\u53e5\u6cd5\u89e3\u6790\uff0c\u5219\u9700\u8981\u5c06word\u7ea7\u522b\u7684\u53e5\u6cd5\u6811\u8f6c\u4e3asubword\u7ea7\u522b\u53e5\u6cd5\u6811\uff0c\u7b56\u7565\u6709\uff1a", "\n", "# 0. \u5c06word\u5bf9\u5e94\u7684\u6240\u6709subword\u7684head\u8bbe\u7f6e\u4e3a\u539fword\u7684\u7b2c\u4e00\u4e2asubword\uff0clabel\u8bbe\u7f6e\u4e0eword\u76f8\u540c", "\n", "# 1. \u5c06word\u5bf9\u5e94\u7684\u7b2c\u4e00\u4e2asubword\u7684head\u8bbe\u7f6e\u4e3a\u539fword\u7684\u7b2c\u4e00\u4e2asubword\uff0clabel\u8bbe\u7f6e\u4e0eword\u76f8\u540c\uff0c\u5176\u4f59subword\u7684head\u8bbe\u7f6e\u4e3a\u7b2c\u4e00\u4e2asubword\uff0clabel\u4f7f\u7528\u7279\u6b8a\u6807\u7b7e", "\n", "# 2. \u5c06word\u5bf9\u5e94\u7684\u7b2c\u4e00\u4e2asubword\u7684head\u8bbe\u7f6e\u4e3a\u539fword\u7684\u7b2c\u4e00\u4e2asubword\uff0clabel\u8bbe\u7f6e\u4e0eword\u76f8\u540c\uff0c\u5176\u4f59subword\u7684head\u8bbe\u7f6e\u4e3a\u524d\u4e00\u4e2asubword\uff0clabel\u4f7f\u7528\u7279\u6b8a\u6807\u7b7e", "\n", "\n", "", "tokens", "=", "[", "]", "\n", "word_token_starts", "=", "[", "]", "\n", "word_token_ends", "=", "[", "]", "\n", "token_word_indexs", "=", "[", "]", "\n", "for", "word_index", ",", "word", "in", "enumerate", "(", "example", ".", "words", ")", ":", "\n", "            ", "word_tokens", "=", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "word_token_starts", ".", "append", "(", "len", "(", "tokens", ")", ")", "\n", "tokens", ".", "extend", "(", "word_tokens", ")", "\n", "token_word_indexs", ".", "extend", "(", "[", "word_index", "]", "*", "len", "(", "word_tokens", ")", ")", "\n", "word_token_ends", ".", "append", "(", "len", "(", "tokens", ")", "-", "1", ")", "\n", "\n", "", "postag_ids", "=", "None", "\n", "order_ids", "=", "None", "\n", "head_ids", "=", "None", "\n", "label_ids", "=", "None", "\n", "\n", "if", "use_postag", ":", "\n", "            ", "postag_ids", "=", "[", "]", "\n", "for", "word_index", ",", "postag", "in", "enumerate", "(", "example", ".", "postags", ")", ":", "\n", "                ", "token_span_len", "=", "word_token_ends", "[", "word_index", "]", "-", "word_token_starts", "[", "word_index", "]", "+", "1", "\n", "if", "convert_strategy", "==", "0", ":", "\n", "                    ", "postag_ids", ".", "extend", "(", "[", "postag_map", "[", "postag", "]", "]", "*", "token_span_len", ")", "\n", "", "else", ":", "\n", "                    ", "postag_ids", ".", "extend", "(", "[", "postag_map", "[", "postag", "]", "]", "+", "[", "special_postag_id", "]", "*", "(", "token_span_len", "-", "1", ")", ")", "\n", "\n", "", "", "", "if", "is_training", ":", "\n", "\n", "            ", "if", "convert_strategy", ">", "0", ":", "\n", "                ", "assert", "special_postag_id", ">=", "0", "\n", "assert", "special_label_id", ">=", "0", "\n", "\n", "", "order_ids", "=", "[", "]", "\n", "head_ids", "=", "[", "]", "\n", "label_ids", "=", "[", "]", "\n", "for", "word_index", ",", "head", "in", "enumerate", "(", "example", ".", "heads", ")", ":", "\n", "\n", "                ", "order", "=", "example", ".", "orders", "[", "word_index", "]", "\n", "# filter", "\n", "if", "order", ">", "max_parsing_order", "-", "1", ":", "\n", "                    ", "order", "=", "max_parsing_order", "-", "1", "\n", "\n", "", "head", "=", "head", "-", "1", "# the truely word index", "\n", "label", "=", "example", ".", "labels", "[", "word_index", "]", "\n", "token_span_len", "=", "word_token_ends", "[", "word_index", "]", "-", "word_token_starts", "[", "word_index", "]", "+", "1", "\n", "order_ids", ".", "extend", "(", "[", "order", "]", "*", "token_span_len", ")", "\n", "if", "convert_strategy", "==", "0", ":", "\n", "                    ", "if", "head", "==", "-", "1", ":", "# position for <ROOT>", "\n", "                        ", "head_ids", ".", "extend", "(", "[", "-", "1", "]", "*", "token_span_len", ")", "\n", "", "else", ":", "\n", "                        ", "head_ids", ".", "extend", "(", "[", "word_token_starts", "[", "head", "]", "]", "*", "token_span_len", ")", "\n", "", "label_ids", ".", "extend", "(", "[", "label_map", "[", "label", "]", "]", "*", "token_span_len", ")", "\n", "", "elif", "convert_strategy", "==", "1", ":", "\n", "                    ", "if", "head", "==", "-", "1", ":", "# position for <ROOT>", "\n", "                        ", "head_ids", ".", "extend", "(", "[", "-", "1", "]", "+", "[", "word_token_starts", "[", "word_index", "]", "]", "*", "(", "token_span_len", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                        ", "head_ids", ".", "extend", "(", "[", "word_token_starts", "[", "head", "]", "]", "+", "[", "word_token_starts", "[", "word_index", "]", "]", "*", "(", "token_span_len", "-", "1", ")", ")", "\n", "", "label_ids", ".", "extend", "(", "[", "label_map", "[", "label", "]", "]", "+", "[", "special_label_id", "]", "*", "(", "token_span_len", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                    ", "if", "head", "==", "-", "1", ":", "# position for <ROOT>", "\n", "                        ", "head_ids", ".", "extend", "(", "[", "-", "1", "]", "+", "[", "word_token_starts", "[", "word_index", "]", "+", "idx", "for", "idx", "in", "range", "(", "token_span_len", "-", "1", ")", "]", ")", "\n", "", "else", ":", "\n", "                        ", "head_ids", ".", "extend", "(", "[", "word_token_starts", "[", "head", "]", "]", "+", "[", "word_token_starts", "[", "word_index", "]", "+", "idx", "for", "idx", "in", "range", "(", "token_span_len", "-", "1", ")", "]", ")", "\n", "", "label_ids", ".", "extend", "(", "[", "label_map", "[", "label", "]", "]", "+", "[", "special_label_id", "]", "*", "(", "token_span_len", "-", "1", ")", ")", "\n", "\n", "\n", "# Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.", "\n", "", "", "", "special_tokens_count", "=", "3", "if", "sep_token_extra", "else", "2", "\n", "assert", "len", "(", "tokens", ")", "<=", "max_seq_length", "-", "special_tokens_count", ",", "(", "len", "(", "tokens", ")", ",", "max_seq_length", ",", "special_tokens_count", ")", "\n", "\n", "# The convention in BERT is:", "\n", "# (a) For sequence pairs:", "\n", "#  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]", "\n", "#  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1", "\n", "# (b) For single sequences:", "\n", "#  tokens:   [CLS] the dog is hairy . [SEP]", "\n", "#  type_ids:   0   0   0   0  0     0   0", "\n", "#", "\n", "# Where \"type_ids\" are used to indicate whether this is the first", "\n", "# sequence or the second sequence. The embedding vectors for `type=0` and", "\n", "# `type=1` were learned during pre-training and are added to the wordpiece", "\n", "# embedding vector (and position vector). This is not *strictly* necessary", "\n", "# since the [SEP] token unambiguously separates the sequences, but it makes", "\n", "# it easier for the model to learn the concept of sequences.", "\n", "#", "\n", "# For dependency parsing tasks, the first vector (corresponding to [CLS]) is", "\n", "# used as as the \"sentence vector\". Note that this only makes sense because", "\n", "# the entire model is fine-tuned.", "\n", "\n", "tokens", "+=", "[", "sep_token", "]", "\n", "token_word_indexs", "+=", "[", "None", "]", "\n", "if", "use_postag", ":", "\n", "            ", "postag_ids", "+=", "[", "pad_postag_id", "]", "\n", "", "if", "is_training", ":", "\n", "            ", "order_ids", "+=", "[", "1", "]", "# due to we set the pad and sep etc special mark is the children of ROOT, so their order is 1", "\n", "head_ids", "+=", "[", "-", "1", "]", "\n", "label_ids", "+=", "[", "pad_label_id", "]", "\n", "\n", "", "if", "sep_token_extra", ":", "\n", "# roberta uses an extra separator b/w pairs of sentences", "\n", "            ", "tokens", "+=", "[", "sep_token", "]", "\n", "token_word_indexs", "+=", "[", "None", "]", "\n", "if", "use_postag", ":", "\n", "                ", "postag_ids", "+=", "[", "pad_postag_id", "]", "\n", "", "if", "is_training", ":", "\n", "                ", "order_ids", "+=", "[", "1", "]", "\n", "head_ids", "+=", "[", "-", "1", "]", "\n", "label_ids", "+=", "[", "pad_label_id", "]", "\n", "\n", "", "", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "# position for <ROOT>, since we use [CLS] for ROOT", "\n", "root_index", "=", "None", "\n", "\n", "if", "cls_token_at_end", ":", "# will not change the index", "\n", "            ", "root_index", "=", "len", "(", "tokens", ")", "\n", "tokens", "+=", "[", "cls_token", "]", "\n", "token_word_indexs", "+=", "[", "None", "]", "\n", "if", "use_postag", ":", "\n", "                ", "postag_ids", "+=", "[", "pad_postag_id", "]", "\n", "", "if", "is_training", ":", "\n", "                ", "order_ids", "+=", "[", "0", "]", "# this is the cls token, we use it as the root, so the order is 0", "\n", "head_ids", "+=", "[", "-", "1", "]", "\n", "label_ids", "+=", "[", "pad_label_id", "]", "\n", "", "segment_ids", "+=", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "# index changed", "\n", "            ", "root_index", "=", "0", "\n", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "token_word_indexs", "=", "[", "None", "]", "+", "token_word_indexs", "\n", "if", "use_postag", ":", "\n", "                ", "postag_ids", "=", "[", "pad_postag_id", "]", "+", "postag_ids", "\n", "", "if", "is_training", ":", "\n", "                ", "order_ids", "=", "[", "0", "]", "+", "order_ids", "\n", "head_ids", "=", "[", "-", "1", "]", "+", "head_ids", "\n", "label_ids", "=", "[", "pad_label_id", "]", "+", "label_ids", "\n", "", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "# IMPORTANT!!!", "\n", "word_token_starts", "=", "[", "idx", "+", "1", "for", "idx", "in", "word_token_starts", "]", "\n", "word_token_ends", "=", "[", "idx", "+", "1", "for", "idx", "in", "word_token_ends", "]", "\n", "if", "is_training", ":", "\n", "                ", "head_ids", "=", "[", "idx", "+", "1", "if", "(", "idx", "!=", "-", "1", "and", "idx", "is", "not", "None", ")", "else", "idx", "for", "idx", "in", "head_ids", "]", "\n", "\n", "", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "# index changed", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "token_word_indexs", "=", "(", "[", "None", "]", "*", "padding_length", ")", "+", "token_word_indexs", "\n", "if", "use_postag", ":", "\n", "                ", "postag_ids", "=", "(", "[", "pad_postag_id", "]", "*", "padding_length", ")", "+", "postag_ids", "\n", "", "if", "is_training", ":", "\n", "                ", "order_ids", "=", "(", "[", "-", "100", "]", "*", "padding_length", ")", "+", "order_ids", "# -100 is default ignore index in CrossEntrophy Loss", "\n", "head_ids", "=", "(", "[", "-", "1", "]", "*", "padding_length", ")", "+", "head_ids", "\n", "label_ids", "=", "(", "[", "pad_label_id", "]", "*", "padding_length", ")", "+", "label_ids", "\n", "\n", "# IMPORTANT!!!", "\n", "", "root_index", "+=", "padding_length", "\n", "word_token_starts", "=", "[", "idx", "+", "padding_length", "for", "idx", "in", "word_token_starts", "]", "\n", "word_token_ends", "=", "[", "idx", "+", "padding_length", "for", "idx", "in", "word_token_ends", "]", "\n", "if", "is_training", ":", "\n", "                ", "head_ids", "=", "[", "idx", "+", "padding_length", "if", "(", "idx", "!=", "-", "1", "and", "idx", "is", "not", "None", ")", "else", "idx", "for", "idx", "in", "head_ids", "]", "\n", "", "", "else", ":", "# will not change the index", "\n", "            ", "input_ids", "+=", "[", "pad_token", "]", "*", "padding_length", "\n", "input_mask", "+=", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", "\n", "segment_ids", "+=", "[", "pad_token_segment_id", "]", "*", "padding_length", "\n", "token_word_indexs", "=", "token_word_indexs", "+", "(", "[", "None", "]", "*", "padding_length", ")", "\n", "if", "use_postag", ":", "\n", "                ", "postag_ids", "=", "postag_ids", "+", "(", "[", "pad_postag_id", "]", "*", "padding_length", ")", "\n", "", "if", "is_training", ":", "\n", "                ", "order_ids", "=", "order_ids", "+", "(", "[", "-", "100", "]", "*", "padding_length", ")", "# -100 is default ignore index in CrossEntrophy Loss", "\n", "head_ids", "=", "head_ids", "+", "(", "[", "-", "1", "]", "*", "padding_length", ")", "\n", "label_ids", "=", "label_ids", "+", "(", "[", "pad_label_id", "]", "*", "padding_length", ")", "\n", "\n", "# replace -1 to truely root position", "\n", "", "", "if", "is_training", ":", "\n", "            ", "head_ids", "=", "[", "idx", "if", "idx", "!=", "-", "1", "else", "root_index", "for", "idx", "in", "head_ids", "]", "\n", "\n", "# IMPORTANT: word length change to +1, due to <ROOT> ([CLS] in this work)", "\n", "", "word_token_starts", "=", "[", "root_index", "]", "+", "word_token_starts", "\n", "word_token_ends", "=", "[", "root_index", "]", "+", "word_token_ends", "\n", "\n", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "if", "use_postag", ":", "\n", "            ", "assert", "len", "(", "postag_ids", ")", "==", "max_seq_length", "\n", "", "if", "is_training", ":", "\n", "            ", "assert", "len", "(", "order_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "head_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "label_ids", ")", "==", "max_seq_length", "\n", "\n", "", "if", "ex_index", "<", "5", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"index: %s\"", ",", "example", ".", "index", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "if", "use_postag", ":", "\n", "                ", "logger", ".", "info", "(", "\"postag_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "postag_ids", "]", ")", ")", "\n", "", "if", "is_training", ":", "\n", "                ", "logger", ".", "info", "(", "\"order_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "order_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"head_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "head_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "label_ids", "]", ")", ")", "\n", "\n", "", "", "features", ".", "append", "(", "\n", "InputFeaturesWithParsingOrder", "(", "index", "=", "example", ".", "index", ",", "\n", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "postag_ids", "=", "postag_ids", ",", "\n", "order_ids", "=", "order_ids", ",", "\n", "head_ids", "=", "head_ids", ",", "\n", "label_ids", "=", "label_ids", ",", "\n", "word_token_starts", "=", "word_token_starts", ",", "\n", "word_token_ends", "=", "word_token_ends", ",", "\n", "token_word_indexs", "=", "token_word_indexs", "\n", ")", ")", "\n", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.get_labels": [[684, 688], ["open", "f.read().splitlines", "f.read"], "function", ["None"], ["", "def", "get_labels", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "labels", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.save_labels": [[690, 694], ["open", "fout.write"], "function", ["None"], ["", "def", "save_labels", "(", "path", ",", "labels", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"w\"", ")", "as", "fout", ":", "\n", "        ", "for", "item", "in", "labels", ":", "\n", "            ", "fout", ".", "write", "(", "item", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.write_conll_examples": [[696, 704], ["open", "range", "len", "len", "len", "len", "len", "range", "f.write", "len", "f.write", "len", "len", "len", "len"], "function", ["None"], ["", "", "", "def", "write_conll_examples", "(", "words", ",", "postags", ",", "heads", ",", "labels", ",", "file_path", ")", ":", "\n", "    ", "assert", "len", "(", "words", ")", "==", "len", "(", "heads", ")", "and", "len", "(", "heads", ")", "==", "len", "(", "labels", ")", "\n", "with", "open", "(", "file_path", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "words", ")", ")", ":", "\n", "            ", "assert", "len", "(", "words", "[", "i", "]", ")", "==", "len", "(", "heads", "[", "i", "]", ")", "and", "len", "(", "heads", "[", "i", "]", ")", "==", "len", "(", "labels", "[", "i", "]", ")", "\n", "for", "j", "in", "range", "(", "len", "(", "words", "[", "i", "]", ")", ")", ":", "\n", "                ", "f", ".", "write", "(", "'{}\\t{}\\t_\\t{}\\t_\\t_\\t{}\\t{}\\t_\\t_\\n'", ".", "format", "(", "j", "+", "1", ",", "words", "[", "i", "]", "[", "j", "]", ",", "postags", "[", "i", "]", "[", "j", "]", "if", "postags", "is", "not", "None", "else", "'_'", ",", "heads", "[", "i", "]", "[", "j", "]", ",", "labels", "[", "i", "]", "[", "j", "]", ")", ")", "\n", "", "f", ".", "write", "(", "'\\n'", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed": [[53, 59], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.train": [[61, 279], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "run_dependency_parsing_with_order.set_seed", "range", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "os.path.isfile", "os.path.isfile", "transformers.AdamW.load_state_dict", "transformers.get_linear_schedule_with_warmup.load_state_dict", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "logger.info", "tqdm.tqdm", "enumerate", "SummaryWriter.close", "os.path.join", "os.path.join", "torch.load", "torch.load", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "run_dependency_parsing_with_order.evaluate", "evaluate.items", "train_iterator.close", "len", "os.path.join", "os.path.join", "ImportError", "torch.distributed.get_world_size", "loss.mean.mean", "loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "SummaryWriter.add_scalar", "logger.info", "os.path.join", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "utils_dependency_parsing.save_labels", "torch.save", "torch.save", "logger.info", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "run_dependency_parsing_with_order.evaluate", "evaluate.items", "torch.distributed.get_rank", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "utils_dependency_parsing.save_labels", "os.path.join", "open", "json.dump", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "SummaryWriter.add_scalar", "logger.info", "os.path.join", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "utils_dependency_parsing.save_labels", "torch.save", "torch.save", "logger.info", "os.path.join", "os.path.join", "transformers.get_linear_schedule_with_warmup.get_lr", "torch.distributed.get_rank", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "utils_dependency_parsing.save_labels", "os.path.join", "open", "json.dump", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization.get_linear_schedule_with_warmup", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.TqdmProgressFileReader.close", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.train", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.evaluate", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.TqdmProgressFileReader.close", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator.step", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.optimization_tf.GradientAccumulator.step", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.TqdmProgressFileReader.close", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.save_labels", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.evaluate", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.save_labels", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.save_labels", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.save_labels"], ["", "", "def", "train", "(", "args", ",", "train_data", ",", "eval_data", ",", "model", ",", "tokenizer", ",", "postags", ",", "labels", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "train_dataset", "=", "train_data", "[", "0", "]", "\n", "\n", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "and", "os", ".", "path", ".", "isfile", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "best_results", "=", "{", "'las'", ":", "0.0", ",", "'uas'", ":", "0.0", "}", "\n", "model", ".", "zero_grad", "(", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "for", "global_epoch", "in", "range", "(", "int", "(", "args", ".", "num_train_epochs", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"***** Training epoch %d *****\"", ",", "global_epoch", ")", "\n", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "1", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "2", "]", ",", "\n", "\"order_ids\"", ":", "batch", "[", "5", "]", "if", "args", ".", "use_postag", "else", "batch", "[", "4", "]", ",", "\n", "\"head_ids\"", ":", "batch", "[", "6", "]", "if", "args", ".", "use_postag", "else", "batch", "[", "5", "]", ",", "\n", "\"label_ids\"", ":", "batch", "[", "7", "]", "if", "args", ".", "use_postag", "else", "batch", "[", "6", "]", "\n", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "batch", "[", "3", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "else", "None", "# XLM and RoBERTa don\"t use segment_ids", "\n", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in pytorch-transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "# Log metrics", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", "==", "1", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                    ", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "# Eval on the dev dataset every X step", "\n", "", "if", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", "and", "args", ".", "evaluate_during_training", "and", "(", "args", ".", "eval_strategy", "==", "1", "or", "args", ".", "eval_strategy", "==", "2", ")", "and", "global_step", "%", "args", ".", "eval_steps", "==", "0", ":", "\n", "\n", "                    ", "results", "=", "evaluate", "(", "args", ",", "eval_data", ",", "model", ",", "tokenizer", ",", "labels", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                        ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "has_better_model", "=", "False", "\n", "if", "results", "[", "'uas'", "]", ">", "best_results", "[", "'uas'", "]", "or", "(", "results", "[", "'uas'", "]", "==", "best_results", "[", "'uas'", "]", "and", "results", "[", "'las'", "]", ">", "best_results", "[", "'las'", "]", ")", ":", "\n", "                        ", "best_results", "=", "results", "\n", "has_better_model", "=", "True", "\n", "logger", ".", "info", "(", "\"New best results!\"", ")", "\n", "\n", "", "if", "args", ".", "save_strategy", "==", "0", "or", "(", "args", ".", "save_strategy", "==", "1", "and", "has_better_model", ")", ":", "\n", "# Save model checkpoint", "\n", "                        ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-step-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                            ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "if", "args", ".", "use_postag", ":", "\n", "                            ", "save_labels", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"postags.txt\"", ")", ",", "postags", ")", "\n", "", "save_labels", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"labels.txt\"", ")", ",", "labels", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"eval_results.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "                            ", "json", ".", "dump", "(", "results", ",", "f", ")", "\n", "\n", "", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "# Eval on the dev dataset every X epoch", "\n", "", "", "if", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", "and", "args", ".", "evaluate_during_training", "and", "(", "(", "args", ".", "eval_strategy", "==", "0", "and", "global_epoch", "%", "args", ".", "eval_steps", "==", "0", ")", "or", "args", ".", "eval_strategy", "==", "2", ")", ":", "\n", "\n", "            ", "results", "=", "evaluate", "(", "args", ",", "eval_data", ",", "model", ",", "tokenizer", ",", "labels", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "has_better_model", "=", "False", "\n", "if", "results", "[", "'uas'", "]", ">", "best_results", "[", "'uas'", "]", "or", "(", "results", "[", "'uas'", "]", "==", "best_results", "[", "'uas'", "]", "and", "results", "[", "'las'", "]", ">", "best_results", "[", "'las'", "]", ")", ":", "\n", "                ", "best_results", "=", "results", "\n", "has_better_model", "=", "True", "\n", "logger", ".", "info", "(", "\"New best results!\"", ")", "\n", "\n", "", "if", "args", ".", "save_strategy", "==", "0", "or", "(", "args", ".", "save_strategy", "==", "1", "and", "has_better_model", ")", ":", "\n", "# Save model checkpoint", "\n", "                ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-epoch-{}\"", ".", "format", "(", "global_epoch", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "(", "\n", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "if", "args", ".", "use_postag", ":", "\n", "                    ", "save_labels", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"postags.txt\"", ")", ",", "postags", ")", "\n", "", "save_labels", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"labels.txt\"", ")", ",", "labels", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"eval_results.json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "                    ", "json", ".", "dump", "(", "results", ",", "f", ")", "\n", "\n", "", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.evaluate": [[281, 408], ["torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "model.eval", "tqdm.tqdm", "os.path.join", "utils_dependency_parsing.write_conll_examples", "os.path.join", "utils_dependency_parsing.write_conll_examples", "os.popen", "os.popen.read().strip", "logger.info", "logger.info", "os.popen.close", "re.findall", "re.findall", "logger.info", "sorted", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "len", "tuple", "len", "float", "len", "float", "float", "results.keys", "logger.info", "torch.no_grad", "model", "outputs[].detach().cpu().numpy", "numpy.argmax", "batch[].cpu().numpy", "range", "os.popen.read", "str", "t.to", "outputs[].max", "outputs[].detach().cpu().numpy.detach().cpu().numpy", "outputs[].detach().cpu().numpy", "numpy.array", "words.append", "gold_heads.append", "gold_labels.append", "pred_heads.append", "pred_labels.append", "energy_order.unsqueeze().unsqueeze", "outputs[].detach().cpu", "batch[].cpu", "tree_inference.decode_MST", "postags.append", "outputs[].detach().cpu().numpy.detach().cpu", "outputs[].detach().cpu", "tree_inference.decode_GGDP_projective", "tree_inference.decode_GGDP_nonprojective", "energy_order.unsqueeze", "outputs[].detach", "order_preds.astype", "os.path.join", "outputs[].detach().cpu().numpy.detach", "outputs[].detach", "os.path.dirname", "os.path.abspath"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.write_conll_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.write_conll_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.hf_api.TqdmProgressFileReader.close", "home.repos.pwc.inspect_result.bcmi220_ggdp.None.hubconf.model", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.tree_inference.decode_MST", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.tree_inference.decode_GGDP_projective", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.tree_inference.decode_GGDP_nonprojective"], ["", "def", "evaluate", "(", "args", ",", "eval_data", ",", "model", ",", "tokenizer", ",", "labels", ")", ":", "\n", "\n", "    ", "eval_dataset", ",", "eval_examples", ",", "eval_features", "=", "eval_data", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# Eval!", "\n", "logger", ".", "info", "(", "\"***** Running evaluation *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "words", "=", "[", "]", "\n", "postags", "=", "[", "]", "if", "args", ".", "use_postag", "else", "None", "\n", "gold_heads", "=", "[", "]", "\n", "gold_labels", "=", "[", "]", "\n", "pred_heads", "=", "[", "]", "\n", "pred_labels", "=", "[", "]", "\n", "model", ".", "eval", "(", ")", "\n", "order_corr", "=", "0", "\n", "order_sum", "=", "0", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "1", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "2", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "batch", "[", "3", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "else", "None", "# XLM and RoBERTa don\"t use segment_ids", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "\n", "if", "args", ".", "infer_alg", "==", "'ggp'", ":", "\n", "# ", "\n", "                ", "_", ",", "energy_order", "=", "outputs", "[", "3", "]", ".", "max", "(", "dim", "=", "2", ")", "\n", "energy", "=", "outputs", "[", "0", "]", "+", "energy_order", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# [batch, num_labels, length, length]", "\n", "energy", "=", "energy", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "# [batch, num_labels, length, length]", "\n", "                ", "energy", "=", "outputs", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# [batch, length, max_parsing_order]", "\n", "", "order_logits", "=", "outputs", "[", "3", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# [batch, length]", "\n", "batch_order_preds", "=", "np", ".", "argmax", "(", "order_logits", ",", "axis", "=", "2", ")", "\n", "\n", "example_ids", "=", "batch", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# for every sentence", "\n", "for", "batch_i", "in", "range", "(", "energy", ".", "shape", "[", "0", "]", ")", ":", "\n", "# [length]", "\n", "                ", "order_preds", "=", "batch_order_preds", "[", "batch_i", "]", "\n", "# [num_labels, length, length]", "\n", "energy_i", "=", "energy", "[", "batch_i", "]", "\n", "example_i", "=", "eval_examples", "[", "example_ids", "[", "batch_i", "]", "]", "\n", "feature_i", "=", "eval_features", "[", "example_ids", "[", "batch_i", "]", "]", "\n", "# [num_labels, word_length, word_length], <ROOT> in the first position", "\n", "energy_i", "=", "energy_i", "[", ":", ",", "feature_i", ".", "word_token_starts", ",", ":", "]", "\n", "energy_i", "=", "energy_i", "[", ":", ",", ":", ",", "feature_i", ".", "word_token_starts", "]", "\n", "\n", "# order accuracy", "\n", "order_preds", "=", "order_preds", "[", "feature_i", ".", "word_token_starts", "]", "\n", "order_gold", "=", "np", ".", "array", "(", "example_i", ".", "orders", ")", "\n", "order_sum", "+=", "order_gold", ".", "shape", "[", "0", "]", "\n", "order_corr", "+=", "(", "order_preds", "[", "1", ":", "]", "==", "order_gold", ")", ".", "sum", "(", ")", "# remove root", "\n", "\n", "# decoding", "\n", "if", "args", ".", "infer_alg", "==", "'mst'", ":", "\n", "                    ", "head_preds", ",", "label_preds", "=", "decode_MST", "(", "energy_i", ",", "leading_symbolic", "=", "1", ",", "labeled", "=", "True", ")", "\n", "", "elif", "args", ".", "infer_alg", "==", "'ggp'", ":", "# global greedy projective", "\n", "                    ", "head_preds", ",", "label_preds", "=", "decode_GGDP_projective", "(", "energy_i", ",", "leading_symbolic", "=", "1", ",", "labeled", "=", "True", ")", "\n", "", "else", ":", "# global greedy non-projective", "\n", "                    ", "head_preds", ",", "label_preds", "=", "decode_GGDP_nonprojective", "(", "energy_i", ",", "order_preds", ".", "astype", "(", "float", ")", ",", "leading_symbolic", "=", "1", ",", "labeled", "=", "True", ")", "\n", "\n", "# map labels", "\n", "", "label_preds", "=", "[", "labels", "[", "item", "]", "for", "item", "in", "label_preds", "]", "\n", "\n", "words", ".", "append", "(", "example_i", ".", "words", ")", "\n", "if", "args", ".", "use_postag", ":", "\n", "                    ", "postags", ".", "append", "(", "example_i", ".", "postags", ")", "\n", "", "gold_heads", ".", "append", "(", "example_i", ".", "heads", ")", "\n", "gold_labels", ".", "append", "(", "example_i", ".", "labels", ")", "\n", "pred_heads", ".", "append", "(", "head_preds", ")", "\n", "pred_labels", ".", "append", "(", "label_preds", ")", "\n", "\n", "# write reference file", "\n", "", "", "", "gold_output_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'eval.gold'", ")", "\n", "write_conll_examples", "(", "words", ",", "postags", ",", "gold_heads", ",", "gold_labels", ",", "gold_output_file", ")", "\n", "# write predict file", "\n", "eval_output_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'eval.pred'", ")", "\n", "write_conll_examples", "(", "words", ",", "postags", ",", "pred_heads", ",", "pred_labels", ",", "eval_output_file", ")", "\n", "# eval", "\n", "eval_f", "=", "os", ".", "popen", "(", "\"perl \"", "+", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "abspath", "(", "__file__", ")", ")", ",", "\"eval.pl\"", ")", "+", "\" -q -g \"", "+", "gold_output_file", "+", "\" -s \"", "+", "eval_output_file", ",", "\"r\"", ")", "\n", "result_text", "=", "eval_f", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "logger", ".", "info", "(", "\"***** Eval info *****\"", ")", "\n", "logger", ".", "info", "(", "result_text", ")", "\n", "eval_f", ".", "close", "(", ")", "\n", "\n", "eval_las", "=", "re", ".", "findall", "(", "r'Labeled attachment score: \\d+ / \\d+ \\* \\d+ = ([\\d\\.]+) \\%'", ",", "result_text", ")", "\n", "if", "len", "(", "eval_las", ")", ">", "0", ":", "\n", "        ", "eval_las", "=", "float", "(", "eval_las", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "        ", "eval_las", "=", "0.0", "\n", "\n", "", "eval_uas", "=", "re", ".", "findall", "(", "r'Unlabeled attachment score: \\d+ / \\d+ \\* \\d+ = ([\\d\\.]+) \\%'", ",", "result_text", ")", "\n", "if", "len", "(", "eval_uas", ")", ">", "0", ":", "\n", "        ", "eval_uas", "=", "float", "(", "eval_uas", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "        ", "eval_uas", "=", "0.0", "\n", "\n", "", "results", "=", "{", "\n", "\"uas\"", ":", "eval_uas", ",", "\n", "\"las\"", ":", "eval_las", ",", "\n", "\"order_acc\"", ":", "float", "(", "'%.2f'", "%", "(", "order_corr", "/", "order_sum", "*", "100", ")", ")", "\n", "}", "\n", "\n", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", "in", "sorted", "(", "results", ".", "keys", "(", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"eval_%s = %s\"", ",", "key", ",", "str", "(", "results", "[", "key", "]", ")", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.predict": [[411, 500], ["torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "tqdm.tqdm", "os.path.join", "utils_dependency_parsing.write_conll_examples", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "tuple", "torch.no_grad", "torch.nn.DataParallel.", "outputs[].detach().cpu().numpy", "numpy.argmax", "batch[].cpu().numpy", "range", "t.to", "outputs[].max", "outputs[].detach().cpu().numpy.detach().cpu().numpy", "outputs[].detach().cpu().numpy", "words.append", "pred_heads.append", "pred_labels.append", "energy_order.unsqueeze().unsqueeze", "outputs[].detach().cpu", "batch[].cpu", "tree_inference.decode_MST", "postags.append", "outputs[].detach().cpu().numpy.detach().cpu", "outputs[].detach().cpu", "tree_inference.decode_GGDP_projective", "tree_inference.decode_GGDP_nonprojective", "energy_order.unsqueeze", "outputs[].detach", "order_preds.astype", "outputs[].detach().cpu().numpy.detach", "outputs[].detach"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.write_conll_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.tree_inference.decode_MST", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.tree_inference.decode_GGDP_projective", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.tree_inference.decode_GGDP_nonprojective"], ["", "def", "predict", "(", "args", ",", "predict_data", ",", "model", ",", "tokenizer", ",", "labels", ")", ":", "\n", "\n", "    ", "predict_dataset", ",", "predict_examples", ",", "predict_features", "=", "predict_data", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "predict_sampler", "=", "SequentialSampler", "(", "predict_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "predict_dataset", ")", "\n", "predict_dataloader", "=", "DataLoader", "(", "predict_dataset", ",", "sampler", "=", "predict_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running prediction *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "predict_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "words", "=", "[", "]", "\n", "postags", "=", "[", "]", "if", "args", ".", "use_postag", "else", "None", "\n", "pred_heads", "=", "[", "]", "\n", "pred_labels", "=", "[", "]", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "predict_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "1", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "2", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "batch", "[", "3", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "else", "None", "# XLM and RoBERTa don\"t use segment_ids", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "\n", "if", "args", ".", "infer_alg", "==", "'ggp'", ":", "\n", "# ", "\n", "                ", "_", ",", "energy_order", "=", "outputs", "[", "3", "]", ".", "max", "(", "dim", "=", "2", ")", "\n", "energy", "=", "outputs", "[", "0", "]", "+", "energy_order", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# [batch, num_labels, length, length]", "\n", "energy", "=", "energy", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "# [batch, num_labels, length, length]", "\n", "                ", "energy", "=", "outputs", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# [batch, length, max_parsing_order]", "\n", "", "order_logits", "=", "outputs", "[", "3", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# [batch, length]", "\n", "batch_order_preds", "=", "np", ".", "argmax", "(", "order_logits", ",", "axis", "=", "2", ")", "\n", "\n", "example_ids", "=", "batch", "[", "0", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# for every sentence", "\n", "for", "batch_i", "in", "range", "(", "energy", ".", "shape", "[", "0", "]", ")", ":", "\n", "# [length]", "\n", "                ", "order_preds", "=", "batch_order_preds", "[", "batch_i", "]", "\n", "# [num_labels, length, length]", "\n", "energy_i", "=", "energy", "[", "batch_i", "]", "\n", "example_i", "=", "predict_examples", "[", "example_ids", "[", "batch_i", "]", "]", "\n", "feature_i", "=", "predict_features", "[", "example_ids", "[", "batch_i", "]", "]", "\n", "# [num_labels, word_length, word_length], <ROOT> in the first position", "\n", "energy_i", "=", "energy_i", "[", ":", ",", "feature_i", ".", "word_token_starts", ",", ":", "]", "\n", "energy_i", "=", "energy_i", "[", ":", ",", ":", ",", "feature_i", ".", "word_token_starts", "]", "\n", "\n", "# order accuracy", "\n", "order_preds", "=", "order_preds", "[", "feature_i", ".", "word_token_starts", "]", "\n", "\n", "# decoding", "\n", "if", "args", ".", "infer_alg", "==", "'mst'", ":", "\n", "                    ", "head_preds", ",", "label_preds", "=", "decode_MST", "(", "energy_i", ",", "leading_symbolic", "=", "1", ",", "labeled", "=", "True", ")", "\n", "", "elif", "args", ".", "infer_alg", "==", "'ggp'", ":", "# global greedy projective", "\n", "                    ", "head_preds", ",", "label_preds", "=", "decode_GGDP_projective", "(", "energy_i", ",", "leading_symbolic", "=", "1", ",", "labeled", "=", "True", ")", "\n", "", "else", ":", "# global greedy non-projective", "\n", "                    ", "head_preds", ",", "label_preds", "=", "decode_GGDP_nonprojective", "(", "energy_i", ",", "order_preds", ".", "astype", "(", "float", ")", ",", "leading_symbolic", "=", "1", ",", "labeled", "=", "True", ")", "\n", "\n", "# map labels", "\n", "", "label_preds", "=", "[", "labels", "[", "item", "]", "for", "item", "in", "label_preds", "]", "\n", "\n", "words", ".", "append", "(", "example_i", ".", "words", ")", "\n", "if", "args", ".", "use_postag", ":", "\n", "                    ", "postags", ".", "append", "(", "example_i", ".", "postags", ")", "\n", "", "pred_heads", ".", "append", "(", "head_preds", ")", "\n", "pred_labels", ".", "append", "(", "label_preds", ")", "\n", "\n", "# write predict file", "\n", "", "", "", "predict_output_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "args", ".", "predict_output", ")", "\n", "write_conll_examples", "(", "words", ",", "postags", ",", "pred_heads", ",", "pred_labels", ",", "predict_output_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.load_examples": [[502, 560], ["logger.info", "utils_dependency_parsing.read_examples_from_file", "utils_dependency_parsing.convert_examples_to_features_with_parsing_order", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.distributed.barrier", "os.path.join", "torch.distributed.barrier", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "bool", "bool", "bool", "torch.utils.data.TensorDataset", "tokenizer.convert_tokens_to_ids", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.read_examples_from_file", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.convert_examples_to_features_with_parsing_order", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.tokenization_utils.PreTrainedTokenizer.convert_tokens_to_ids"], ["", "def", "load_examples", "(", "args", ",", "file_name", ",", "tokenizer", ",", "is_training", "=", "False", ",", "postags", "=", "None", ",", "labels", "=", "None", ",", "pad_postag", "=", "'_'", ",", "pad_label", "=", "'_'", ",", "convert_strategy", "=", "0", ",", "special_postag", "=", "'_'", ",", "special_label", "=", "'_'", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset", "\n", "\n", "", "logger", ".", "info", "(", "\"Creating features from dataset file: %s\"", ",", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "file_name", ")", ")", "\n", "\n", "examples", "=", "read_examples_from_file", "(", "args", ".", "data_dir", ",", "file_name", ",", "is_training", "=", "is_training", ",", "use_postag", "=", "args", ".", "use_postag", ",", "with_parsing_order", "=", "True", ")", "\n", "\n", "features", "=", "convert_examples_to_features_with_parsing_order", "(", "\n", "examples", ",", "args", ".", "max_seq_length", ",", "tokenizer", ",", "\n", "cls_token_at_end", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "\n", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "\n", "sep_token_extra", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"roberta\"", "]", ")", ",", "\n", "# roberta uses an extra separator b/w pairs of sentences, cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "\n", "# pad on the left for xlnet", "\n", "pad_token", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "tokenizer", ".", "pad_token", "]", ")", "[", "0", "]", ",", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", "is_training", "=", "is_training", ",", "\n", "max_parsing_order", "=", "args", ".", "max_parsing_order", ",", "\n", "use_postag", "=", "args", ".", "use_postag", ",", "\n", "postag_list", "=", "postags", ",", "\n", "label_list", "=", "labels", ",", "\n", "pad_postag", "=", "pad_postag", ",", "\n", "pad_label", "=", "pad_label", ",", "\n", "convert_strategy", "=", "convert_strategy", ",", "\n", "special_postag", "=", "special_postag", ",", "\n", "special_label", "=", "special_label", "\n", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_example_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "index", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "use_postag", ":", "\n", "        ", "all_postag_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "postag_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "if", "is_training", ":", "\n", "        ", "all_order_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "order_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_head_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "head_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "", "if", "args", ".", "use_postag", "and", "is_training", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_example_ids", ",", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_postag_ids", ",", "all_order_ids", ",", "all_head_ids", ",", "all_label_ids", ")", "\n", "", "elif", "args", ".", "use_postag", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_example_ids", ",", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_postag_ids", ")", "\n", "", "elif", "is_training", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_example_ids", ",", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_order_ids", ",", "all_head_ids", ",", "all_label_ids", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_example_ids", ",", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ")", "\n", "\n", "", "return", "(", "dataset", ",", "examples", ",", "features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.main": [[562, 840], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_dependency_parsing_with_order.set_seed", "parser.parse_args.model_type.lower", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "os.path.exists", "os.listdir", "ValueError", "os.makedirs", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "len", "utils_dependency_parsing.get_labels", "utils_dependency_parsing.get_labels", "torch.distributed.barrier", "config_class.from_pretrained", "config_class.from_pretrained", "torch.distributed.barrier", "run_dependency_parsing_with_order.load_examples", "run_dependency_parsing_with_order.load_examples", "run_dependency_parsing_with_order.train", "logger.info", "run_dependency_parsing_with_order.evaluate", "run_dependency_parsing_with_order.load_examples", "run_dependency_parsing_with_order.predict", "os.path.exists", "len", "utils_dependency_parsing.get_labels", "utils_dependency_parsing.get_labels", "os.path.join", "bool", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "utils_dependency_parsing.save_labels", "torch.save", "os.path.join", "len", "os.path.exists", "os.makedirs", "hasattr", "utils_dependency_parsing.save_labels", "os.path.join", "os.path.join", "MODEL_CLASSES.keys", "torch.cuda.is_available", "len", "os.path.join"], "function", ["home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.set_seed", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.get_labels", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.get_labels", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_auto.AutoConfig.from_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.load_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.load_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.train", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.evaluate", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.load_examples", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.run_dependency_parsing_with_order.predict", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.get_labels", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.get_labels", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.save_labels", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.pipelines.PipedPipelineDataFormat.save", "home.repos.pwc.inspect_result.bcmi220_ggdp.examples.utils_dependency_parsing.save_labels"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "## Required parameters", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the files for the Denpendency Parsing task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The train file name for the Denpendency Parsing task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The eval file name for the Denpendency Parsing task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--predict_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The eval file name for the Denpendency Parsing task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--predict_output\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The predict output file name for the Denpendency Parsing task.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ".", "keys", "(", ")", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--arc_space\"", ",", "default", "=", "512", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Arc hidden size.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--label_space\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Label hidden size.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--order_space\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Order hidden size.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--max_parsing_order\"", ",", "default", "=", "32", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Maximum parsing order.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--infer_alg\"", ",", "default", "=", "'mst'", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "[", "'mst'", ",", "'ggp'", ",", "'ggnp'", "]", ")", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--use_postag\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--postags\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to a file containing all postag labels.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--labels\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Path to a file containing all dependency labels.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--convert_strategy\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Word-level to subword-level dependency tree convert strategy.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--special_postag\"", ",", "default", "=", "\"_\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Special postag for the subword due to word-level to subword-level conversion.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--special_label\"", ",", "default", "=", "\"_\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Special label for the subword due to word-level to subword-level conversion.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_predict\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run predictions on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to run evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gradient_accumulation_steps\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_strategy\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Eval model strategy. 0 for every X epochs, 1 for every X steps, 2 for every X steps and every epoch.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_steps\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Eval model every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_strategy\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "\n", "help", "=", "\"Save checkpoint strategy. 0 for save all checkpoints, 1 for save better checkpoints.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--fp16\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--fp16_opt_level\"", ",", "type", "=", "str", ",", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "\n", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", "and", "not", "args", ".", "overwrite_output_dir", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare dependency parsing task", "\n", "postags", "=", "None", "\n", "if", "args", ".", "use_postag", ":", "\n", "        ", "if", "len", "(", "args", ".", "postags", ")", ">", "0", ":", "\n", "            ", "postags", "=", "get_labels", "(", "args", ".", "postags", ")", "\n", "", "else", ":", "\n", "            ", "postags", "=", "get_labels", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "'postags.txt'", ")", ")", "\n", "", "assert", "postags", "[", "0", "]", "==", "'_'", ",", "'PAD postag must be in the position 0'", "\n", "\n", "", "if", "len", "(", "args", ".", "labels", ")", ">", "0", ":", "\n", "        ", "labels", "=", "get_labels", "(", "args", ".", "labels", ")", "\n", "", "else", ":", "\n", "        ", "labels", "=", "get_labels", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "'labels.txt'", ")", ")", "\n", "", "assert", "labels", "[", "0", "]", "==", "'_'", ",", "'PAD label must be in the position 0'", "\n", "if", "args", ".", "convert_strategy", ">", "0", ":", "\n", "        ", "if", "args", ".", "use_postag", ":", "\n", "            ", "assert", "args", ".", "special_postag", "in", "postags", "\n", "", "assert", "args", ".", "special_label", "in", "labels", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "config", "=", "config_class", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", "use_postag", "=", "args", ".", "use_postag", ",", "num_postags", "=", "len", "(", "postags", ")", "if", "postags", "is", "not", "None", "else", "0", ",", "\n", "num_labels", "=", "len", "(", "labels", ")", ",", "\n", "arc_space", "=", "args", ".", "arc_space", ",", "label_space", "=", "args", ".", "label_space", ",", "\n", "max_parsing_order", "=", "args", ".", "max_parsing_order", ",", "\n", "order_space", "=", "args", ".", "order_space", "\n", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", ")", "\n", "", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "assert", "args", ".", "train_file", "\n", "train_data", "=", "load_examples", "(", "\n", "args", ",", "args", ".", "train_file", ",", "tokenizer", ",", "\n", "is_training", "=", "True", ",", "\n", "postags", "=", "postags", ",", "\n", "labels", "=", "labels", ",", "\n", "pad_postag", "=", "'_'", ",", "\n", "pad_label", "=", "'_'", ",", "\n", "convert_strategy", "=", "args", ".", "convert_strategy", ",", "\n", "special_postag", "=", "args", ".", "special_postag", ",", "\n", "special_label", "=", "args", ".", "special_label", "\n", ")", "\n", "\n", "", "if", "args", ".", "do_eval", ":", "\n", "        ", "assert", "args", ".", "eval_file", "\n", "eval_data", "=", "load_examples", "(", "\n", "args", ",", "args", ".", "eval_file", ",", "tokenizer", ",", "\n", "is_training", "=", "True", ",", "\n", "postags", "=", "postags", ",", "\n", "labels", "=", "labels", ",", "\n", "pad_postag", "=", "'_'", ",", "\n", "pad_label", "=", "'_'", ",", "\n", "convert_strategy", "=", "args", ".", "convert_strategy", ",", "\n", "special_postag", "=", "args", ".", "special_postag", ",", "\n", "special_label", "=", "args", ".", "special_label", "\n", ")", "\n", "\n", "", "if", "args", ".", "do_train", ":", "\n", "\n", "        ", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_data", ",", "eval_data", ",", "model", ",", "tokenizer", ",", "postags", ",", "labels", ")", "\n", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "# Create output directory if needed", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "if", "args", ".", "use_postag", ":", "\n", "                ", "save_labels", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"postags.txt\"", ")", ",", "postags", ")", "\n", "", "save_labels", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"labels.txt\"", ")", ",", "labels", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "", "", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "evaluate", "(", "args", ",", "eval_data", ",", "model", ",", "tokenizer", ",", "labels", ")", "\n", "\n", "", "if", "args", ".", "do_predict", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "assert", "args", ".", "predict_file", "and", "args", ".", "predict_output", "\n", "predict_data", "=", "load_examples", "(", "\n", "args", ",", "args", ".", "predict_file", ",", "tokenizer", ",", "\n", "is_training", "=", "False", ",", "\n", "postags", "=", "postags", ",", "\n", "labels", "=", "labels", ",", "\n", "pad_postag", "=", "'_'", ",", "\n", "pad_label", "=", "'_'", ",", "\n", "convert_strategy", "=", "args", ".", "convert_strategy", ",", "\n", "special_postag", "=", "args", ".", "special_postag", ",", "\n", "special_label", "=", "args", ".", "special_label", "\n", ")", "\n", "predict", "(", "args", ",", "predict_data", ",", "model", ",", "tokenizer", ",", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.modeling.utils_modeling.BiAAttention.__init__": [[13, 41], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "utils_modeling.BiAAttention.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "utils_modeling.BiAAttention.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.modeling.utils_modeling.BiLinear.reset_parameters"], ["def", "__init__", "(", "self", ",", "input_size_encoder", ",", "input_size_decoder", ",", "num_labels", ",", "biaffine", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "'''\n        Args:\n            input_size_encoder: int\n                the dimension of the encoder input.\n            input_size_decoder: int\n                the dimension of the decoder input.\n            num_labels: int\n                the number of labels of the crf layer\n            biaffine: bool\n                if apply bi-affine parameter.\n            **kwargs:\n        '''", "\n", "super", "(", "BiAAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size_encoder", "=", "input_size_encoder", "\n", "self", ".", "input_size_decoder", "=", "input_size_decoder", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "biaffine", "=", "biaffine", "\n", "\n", "self", ".", "W_d", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "self", ".", "input_size_decoder", ")", ")", "\n", "self", ".", "W_e", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "self", ".", "input_size_encoder", ")", ")", "\n", "self", ".", "b", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "1", ",", "1", ")", ")", "\n", "if", "self", ".", "biaffine", ":", "\n", "            ", "self", ".", "U", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "num_labels", ",", "self", ".", "input_size_decoder", ",", "self", ".", "input_size_encoder", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'U'", ",", "None", ")", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.modeling.utils_modeling.BiAAttention.reset_parameters": [[42, 48], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "W_d", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "W_e", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "b", ",", "0.", ")", "\n", "if", "self", ".", "biaffine", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "U", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.modeling.utils_modeling.BiAAttention.forward": [[49, 92], ["input_d.size", "input_e.size", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "torch.matmul().unsqueeze", "input_d.size", "input_e.size", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "input_d.unsqueeze", "input_e.unsqueeze().transpose", "mask_e.unsqueeze().unsqueeze", "input_d.transpose", "input_e.transpose", "mask_d.unsqueeze().unsqueeze", "input_e.unsqueeze", "mask_e.unsqueeze", "mask_d.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_d", ",", "input_e", ",", "mask_d", "=", "None", ",", "mask_e", "=", "None", ")", ":", "\n", "        ", "'''\n        Args:\n            input_d: Tensor\n                the decoder input tensor with shape = [batch, length_decoder, input_size]\n            input_e: Tensor\n                the child input tensor with shape = [batch, length_encoder, input_size]\n            mask_d: Tensor or None\n                the mask tensor for decoder with shape = [batch, length_decoder]\n            mask_e: Tensor or None\n                the mask tensor for encoder with shape = [batch, length_encoder]\n        Returns: Tensor\n            the energy tensor with shape = [batch, num_label, length, length]\n        '''", "\n", "assert", "input_d", ".", "size", "(", "0", ")", "==", "input_e", ".", "size", "(", "0", ")", ",", "'batch sizes of encoder and decoder are requires to be equal.'", "\n", "batch", ",", "length_decoder", ",", "_", "=", "input_d", ".", "size", "(", ")", "\n", "_", ",", "length_encoder", ",", "_", "=", "input_e", ".", "size", "(", ")", "\n", "\n", "# compute decoder part: [num_label, input_size_decoder] * [batch, input_size_decoder, length_decoder]", "\n", "# the output shape is [batch, num_label, length_decoder]", "\n", "out_d", "=", "torch", ".", "matmul", "(", "self", ".", "W_d", ",", "input_d", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "unsqueeze", "(", "3", ")", "\n", "# compute decoder part: [num_label, input_size_encoder] * [batch, input_size_encoder, length_encoder]", "\n", "# the output shape is [batch, num_label, length_encoder]", "\n", "out_e", "=", "torch", ".", "matmul", "(", "self", ".", "W_e", ",", "input_e", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# output shape [batch, num_label, length_decoder, length_encoder]", "\n", "if", "self", ".", "biaffine", ":", "\n", "# compute bi-affine part", "\n", "# [batch, 1, length_decoder, input_size_decoder] * [num_labels, input_size_decoder, input_size_encoder]", "\n", "# output shape [batch, num_label, length_decoder, input_size_encoder]", "\n", "            ", "output", "=", "torch", ".", "matmul", "(", "input_d", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "U", ")", "\n", "# [batch, num_label, length_decoder, input_size_encoder] * [batch, 1, input_size_encoder, length_encoder]", "\n", "# output shape [batch, num_label, length_decoder, length_encoder]", "\n", "output", "=", "torch", ".", "matmul", "(", "output", ",", "input_e", ".", "unsqueeze", "(", "1", ")", ".", "transpose", "(", "2", ",", "3", ")", ")", "\n", "\n", "output", "=", "output", "+", "out_d", "+", "out_e", "+", "self", ".", "b", "\n", "", "else", ":", "\n", "            ", "output", "=", "out_d", "+", "out_d", "+", "self", ".", "b", "\n", "\n", "", "if", "mask_d", "is", "not", "None", ":", "\n", "            ", "output", "=", "output", "*", "mask_d", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "3", ")", "*", "mask_e", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.modeling.utils_modeling.BiLinear.__init__": [[97, 121], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "utils_modeling.BiLinear.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "utils_modeling.BiLinear.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.modeling.utils_modeling.BiLinear.reset_parameters"], ["def", "__init__", "(", "self", ",", "left_features", ",", "right_features", ",", "out_features", ",", "bias", "=", "True", ")", ":", "\n", "        ", "'''\n        Args:\n            left_features: size of left input\n            right_features: size of right input\n            out_features: size of output\n            bias: If set to False, the layer will not learn an additive bias.\n                Default: True\n        '''", "\n", "super", "(", "BiLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "left_features", "=", "left_features", "\n", "self", ".", "right_features", "=", "right_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "\n", "self", ".", "U", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "out_features", ",", "self", ".", "left_features", ",", "self", ".", "right_features", ")", ")", "\n", "self", ".", "W_l", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "out_features", ",", "self", ".", "left_features", ")", ")", "\n", "self", ".", "W_r", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "out_features", ",", "self", ".", "left_features", ")", ")", "\n", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.modeling.utils_modeling.BiLinear.reset_parameters": [[122, 127], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "W_l", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "W_r", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "bias", ",", "0.", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "U", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.modeling.utils_modeling.BiLinear.forward": [[128, 153], ["input_left.view.view.size", "input_right.view.view.size", "int", "input_left.view.view.view", "input_right.view.view.view", "torch.bilinear", "torch.bilinear", "torch.bilinear", "torch.bilinear.view", "numpy.prod", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_left", ",", "input_right", ")", ":", "\n", "        ", "'''\n        Args:\n            input_left: Tensor\n                the left input tensor with shape = [batch1, batch2, ..., left_features]\n            input_right: Tensor\n                the right input tensor with shape = [batch1, batch2, ..., right_features]\n        Returns:\n        '''", "\n", "\n", "left_size", "=", "input_left", ".", "size", "(", ")", "\n", "right_size", "=", "input_right", ".", "size", "(", ")", "\n", "assert", "left_size", "[", ":", "-", "1", "]", "==", "right_size", "[", ":", "-", "1", "]", ",", "\"batch size of left and right inputs mis-match: (%s, %s)\"", "%", "(", "left_size", "[", ":", "-", "1", "]", ",", "right_size", "[", ":", "-", "1", "]", ")", "\n", "batch", "=", "int", "(", "np", ".", "prod", "(", "left_size", "[", ":", "-", "1", "]", ")", ")", "\n", "\n", "# convert left and right input to matrices [batch, left_features], [batch, right_features]", "\n", "input_left", "=", "input_left", ".", "view", "(", "batch", ",", "self", ".", "left_features", ")", "\n", "input_right", "=", "input_right", ".", "view", "(", "batch", ",", "self", ".", "right_features", ")", "\n", "\n", "# output [batch, out_features]", "\n", "output", "=", "F", ".", "bilinear", "(", "input_left", ",", "input_right", ",", "self", ".", "U", ",", "self", ".", "bias", ")", "\n", "output", "=", "output", "+", "F", ".", "linear", "(", "input_left", ",", "self", ".", "W_l", ",", "None", ")", "+", "F", ".", "linear", "(", "input_right", ",", "self", ".", "W_r", ",", "None", ")", "\n", "# convert back to [batch1, batch2, ..., out_features]", "\n", "return", "output", ".", "view", "(", "left_size", "[", ":", "-", "1", "]", "+", "(", "self", ".", "out_features", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.modeling.utils_modeling.BiLinear.__repr__": [[154, 159], ["str", "str", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "' ('", "+", "'in1_features='", "+", "str", "(", "self", ".", "left_features", ")", "+", "', in2_features='", "+", "str", "(", "self", ".", "right_features", ")", "+", "', out_features='", "+", "str", "(", "self", ".", "out_features", ")", "+", "')'", "", "", "", ""]], "home.repos.pwc.inspect_result.bcmi220_ggdp.modeling.modeling_bert.BertForDependencyParsing.__init__": [[17, 38], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "utils_modeling.BiAAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "utils_modeling.BiLinear", "modeling_bert.BertForDependencyParsing.init_weights", "torch.nn.Embedding", "torch.nn.Embedding"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["\n", "\n", "import", "logging", "\n", "import", "math", "\n", "import", "os", "\n", "\n", "import", "torch", "\n", "from", "torch", "import", "nn", "\n", "from", "torch", ".", "nn", "import", "CrossEntropyLoss", ",", "MSELoss", "\n", "\n", "from", ".", "configuration_bert", "import", "BertConfig", "\n", "from", ".", "file_utils", "import", "add_start_docstrings", "\n", "from", ".", "modeling_utils", "import", "PreTrainedModel", ",", "prune_linear_layer", "\n", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "BERT_PRETRAINED_MODEL_ARCHIVE_MAP", "=", "{", "\n", "\"bert-base-uncased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin\"", ",", "\n", "\"bert-large-uncased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-pytorch_model.bin\"", ",", "\n", "\"bert-base-cased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin\"", ",", "\n", "\"bert-large-cased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-pytorch_model.bin\"", ",", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.modeling.modeling_bert.BertForDependencyParsing.forward": [[39, 145], ["modeling_bert.BertForDependencyParsing.bert", "modeling_bert.BertForDependencyParsing.dropout", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_bert.BertForDependencyParsing.dropout", "modeling_bert.BertForDependencyParsing.chunk", "modeling_bert.BertForDependencyParsing.dropout", "modeling_bert.BertForDependencyParsing.chunk", "label_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.contiguous", "label_c.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.contiguous", "modeling_bert.BertForDependencyParsing.attention().squeeze", "label_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.size", "modeling_bert.BertForDependencyParsing.arc_h", "modeling_bert.BertForDependencyParsing.arc_c", "modeling_bert.BertForDependencyParsing.label_h", "modeling_bert.BertForDependencyParsing.label_c", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "label_h[].transpose().contiguous", "modeling_bert.BertForDependencyParsing.bilinear", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "child_index.type_as().long.type_as().long.type_as().long", "label_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous", "label_c.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous", "modeling_bert.BertForDependencyParsing.bilinear", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax().permute", "torch.log_softmax().permute", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "modeling_bert.BertForDependencyParsing.attention", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "label_h[].transpose", "minus_mask.unsqueeze", "attention_mask.unsqueeze", "attention_mask.unsqueeze", "attention_mask.sum", "float", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "child_index.type_as().long.type_as().long.type_as", "label_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand", "label_c.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand", "minus_mask.unsqueeze", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax.unsqueeze", "minus_mask.unsqueeze", "attention_mask.unsqueeze", "torch.log_softmax.sum", "torch.log_softmax.sum", "minus_mask.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "head_ids.t", "label_ids.t", "label_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze", "label_c.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze", "head_ids.t"], "methods", ["None"], ["\"bert-base-multilingual-uncased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-pytorch_model.bin\"", ",", "\n", "\"bert-base-multilingual-cased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-pytorch_model.bin\"", ",", "\n", "\"bert-base-chinese\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-pytorch_model.bin\"", ",", "\n", "\"bert-base-german-cased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-cased-pytorch_model.bin\"", ",", "\n", "\"bert-large-uncased-whole-word-masking\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-pytorch_model.bin\"", ",", "\n", "\"bert-large-cased-whole-word-masking\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-pytorch_model.bin\"", ",", "\n", "\"bert-large-uncased-whole-word-masking-finetuned-squad\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-finetuned-squad-pytorch_model.bin\"", ",", "\n", "\"bert-large-cased-whole-word-masking-finetuned-squad\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-finetuned-squad-pytorch_model.bin\"", ",", "\n", "\"bert-base-cased-finetuned-mrpc\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-finetuned-mrpc-pytorch_model.bin\"", ",", "\n", "\"bert-base-german-dbmdz-cased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-cased-pytorch_model.bin\"", ",", "\n", "\"bert-base-german-dbmdz-uncased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-uncased-pytorch_model.bin\"", ",", "\n", "\"bert-base-japanese\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-pytorch_model.bin\"", ",", "\n", "\"bert-base-japanese-whole-word-masking\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-whole-word-masking-pytorch_model.bin\"", ",", "\n", "\"bert-base-japanese-char\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-pytorch_model.bin\"", ",", "\n", "\"bert-base-japanese-char-whole-word-masking\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-whole-word-masking-pytorch_model.bin\"", ",", "\n", "\"bert-base-finnish-cased-v1\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-cased-v1/pytorch_model.bin\"", ",", "\n", "\"bert-base-finnish-uncased-v1\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-uncased-v1/pytorch_model.bin\"", ",", "\n", "}", "\n", "\n", "\n", "def", "load_tf_weights_in_bert", "(", "model", ",", "config", ",", "tf_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", ".", "split", "(", "\"/\"", ")", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "any", "(", "n", "in", "[", "\"adam_v\"", ",", "\"adam_m\"", ",", "\"global_step\"", "]", "for", "n", "in", "name", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r\"[A-Za-z]+_\\d+\"", ",", "m_name", ")", ":", "\n", "                ", "scope_names", "=", "re", ".", "split", "(", "r\"_(\\d+)\"", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "scope_names", "=", "[", "m_name", "]", "\n", "", "if", "scope_names", "[", "0", "]", "==", "\"kernel\"", "or", "scope_names", "[", "0", "]", "==", "\"gamma\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"output_bias\"", "or", "scope_names", "[", "0", "]", "==", "\"beta\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"bias\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"output_weights\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"squad\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"classifier\"", ")", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "", "if", "len", "(", "scope_names", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "scope_names", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "if", "m_name", "[", "-", "11", ":", "]", "==", "\"_embeddings\"", ":", "\n", "            ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "m_name", "==", "\"kernel\"", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n", "\n", "", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Original Implementation of the gelu activation function in Google Bert repo when initially created.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n", "\n", "", "def", "gelu_new", "(", "x", ")", ":", "\n", "    ", "\"\"\" Implementation of the gelu activation function currently in Google Bert repo (identical to OpenAI GPT).\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n", "\n", "", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.modeling.modeling_bert.BertForDependencyParsingWithOrder.__init__": [[148, 173], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "utils_modeling.BiAAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "utils_modeling.BiLinear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "modeling_bert.BertForDependencyParsingWithOrder.init_weights", "torch.nn.Embedding", "torch.nn.Embedding"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__", "home.repos.pwc.inspect_result.bcmi220_ggdp.transformers.modeling_utils.PreTrainedModel.init_weights"], ["", "def", "mish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "tanh", "(", "nn", ".", "functional", ".", "softplus", "(", "x", ")", ")", "\n", "\n", "\n", "", "ACT2FN", "=", "{", "\"gelu\"", ":", "gelu", ",", "\"relu\"", ":", "torch", ".", "nn", ".", "functional", ".", "relu", ",", "\"swish\"", ":", "swish", ",", "\"gelu_new\"", ":", "gelu_new", ",", "\"mish\"", ":", "mish", "}", "\n", "\n", "\n", "BertLayerNorm", "=", "torch", ".", "nn", ".", "LayerNorm", "\n", "\n", "\n", "class", "BertEmbeddings", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Construct the embeddings from word, position and token_type embeddings.\n    \"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "inputs_embeds", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.modeling.modeling_bert.BertForDependencyParsingWithOrder.forward": [[174, 299], ["modeling_bert.BertForDependencyParsingWithOrder.bert", "modeling_bert.BertForDependencyParsingWithOrder.dropout", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.elu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_bert.BertForDependencyParsingWithOrder.dropout", "modeling_bert.BertForDependencyParsingWithOrder.chunk", "modeling_bert.BertForDependencyParsingWithOrder.dropout", "modeling_bert.BertForDependencyParsingWithOrder.chunk", "label_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.contiguous", "label_c.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.contiguous", "modeling_bert.BertForDependencyParsingWithOrder.dropout", "modeling_bert.BertForDependencyParsingWithOrder.attention().squeeze", "modeling_bert.BertForDependencyParsingWithOrder.order_classifier", "label_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.size", "modeling_bert.BertForDependencyParsingWithOrder.arc_h", "modeling_bert.BertForDependencyParsingWithOrder.arc_c", "modeling_bert.BertForDependencyParsingWithOrder.label_h", "modeling_bert.BertForDependencyParsingWithOrder.label_c", "modeling_bert.BertForDependencyParsingWithOrder.order_hidden", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "torch.arange().type_as().long", "label_h[].transpose().contiguous", "modeling_bert.BertForDependencyParsingWithOrder.bilinear", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "torch.arange().view().expand", "child_index.type_as().long.type_as().long.type_as().long", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "label_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous", "label_c.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous", "modeling_bert.BertForDependencyParsingWithOrder.bilinear", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax().permute", "torch.log_softmax().permute", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "modeling_bert.BertForDependencyParsingWithOrder.attention", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "torch.arange().type_as", "label_h[].transpose", "minus_mask.unsqueeze", "attention_mask.unsqueeze", "attention_mask.unsqueeze", "attention_mask.sum", "float", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "child_index.type_as().long.type_as().long.type_as", "attention_mask.view", "modeling_bert.BertForDependencyParsingWithOrder.view", "order_ids.view", "modeling_bert.BertForDependencyParsingWithOrder.view", "order_ids.view", "label_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand", "label_c.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze().expand", "minus_mask.unsqueeze", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax.unsqueeze", "minus_mask.unsqueeze", "attention_mask.unsqueeze", "minus_mask.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "head_ids.t", "label_ids.t", "torch.log_softmax.sum", "torch.log_softmax.sum", "label_h.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze", "label_c.unsqueeze().expand().contiguous.unsqueeze().expand().contiguous.unsqueeze", "head_ids.t"], "methods", ["None"], ["        ", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "seq_length", "=", "input_shape", "[", "1", "]", "\n", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "if", "position_ids", "is", "None", ":", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "input_shape", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros", "(", "input_shape", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "inputs_embeds", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n", "\n", "", "", "class", "BertSelfAttention", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", "\n", ")", "\n", "", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n", "", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n", "", "def", "forward", "(", "\n", "self", ",", "\n", "hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "encoder_hidden_states", "=", "None", ",", "\n", "encoder_attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "\n", "# If this is instantiated as a cross-attention module, the keys", "\n", "# and values come from an encoder; the attention mask needs to be", "\n", "# such that the encoder's padding tokens are not attended to.", "\n", "if", "encoder_hidden_states", "is", "not", "None", ":", "\n", "            ", "mixed_key_layer", "=", "self", ".", "key", "(", "encoder_hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "encoder_hidden_states", ")", "\n", "attention_mask", "=", "encoder_attention_mask", "\n", "", "else", ":", "\n", "            ", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "            ", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attention_probs", "=", "attention_probs", "*", "head_mask", "\n", "\n", "", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "\n", "outputs", "=", "(", "context_layer", ",", "attention_probs", ")", "if", "self", ".", "output_attentions", "else", "(", "context_layer", ",", ")", "\n", "return", "outputs", "\n", "\n", "\n", "", "", "class", "BertSelfOutput", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n", "\n", "", "", "class", "BertAttention", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n", "", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingConfig.__init__": [[5, 46], ["transformers.BertConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["# Licensed under the Apache License, Version 2.0 (the \"License\");", "\n", "# you may not use this file except in compliance with the License.", "\n", "# You may obtain a copy of the License at", "\n", "#", "\n", "#     http://www.apache.org/licenses/LICENSE-2.0", "\n", "#", "\n", "# Unless required by applicable law or agreed to in writing, software", "\n", "# distributed under the License is distributed on an \"AS IS\" BASIS,", "\n", "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.", "\n", "# See the License for the specific language governing permissions and", "\n", "# limitations under the License.", "\n", "\"\"\" BERT model configuration \"\"\"", "\n", "\n", "\n", "import", "logging", "\n", "\n", "from", ".", "configuration_utils", "import", "PretrainedConfig", "\n", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "\n", "BERT_PRETRAINED_CONFIG_ARCHIVE_MAP", "=", "{", "\n", "\"bert-base-uncased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json\"", ",", "\n", "\"bert-large-uncased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-config.json\"", ",", "\n", "\"bert-base-cased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json\"", ",", "\n", "\"bert-large-cased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-config.json\"", ",", "\n", "\"bert-base-multilingual-uncased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-uncased-config.json\"", ",", "\n", "\"bert-base-multilingual-cased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-multilingual-cased-config.json\"", ",", "\n", "\"bert-base-chinese\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-chinese-config.json\"", ",", "\n", "\"bert-base-german-cased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-cased-config.json\"", ",", "\n", "\"bert-large-uncased-whole-word-masking\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-config.json\"", ",", "\n", "\"bert-large-cased-whole-word-masking\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-config.json\"", ",", "\n", "\"bert-large-uncased-whole-word-masking-finetuned-squad\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-whole-word-masking-finetuned-squad-config.json\"", ",", "\n", "\"bert-large-cased-whole-word-masking-finetuned-squad\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased-whole-word-masking-finetuned-squad-config.json\"", ",", "\n", "\"bert-base-cased-finetuned-mrpc\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-finetuned-mrpc-config.json\"", ",", "\n", "\"bert-base-german-dbmdz-cased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-cased-config.json\"", ",", "\n", "\"bert-base-german-dbmdz-uncased\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-german-dbmdz-uncased-config.json\"", ",", "\n", "\"bert-base-japanese\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-config.json\"", ",", "\n", "\"bert-base-japanese-whole-word-masking\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-whole-word-masking-config.json\"", ",", "\n", "\"bert-base-japanese-char\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-config.json\"", ",", "\n", "\"bert-base-japanese-char-whole-word-masking\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/cl-tohoku/bert-base-japanese-char-whole-word-masking-config.json\"", ",", "\n", "\"bert-base-finnish-cased-v1\"", ":", "\"https://s3.amazonaws.com/models.huggingface.co/bert/TurkuNLP/bert-base-finnish-cased-v1/config.json\"", ",", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__": [[49, 94], ["transformers.BertConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.bcmi220_ggdp.configuration.configuration_bert.BertForDependencyParsingWithOrderConfig.__init__"], ["\n", "\n", "class", "BertConfig", "(", "PretrainedConfig", ")", ":", "\n", "    ", "r\"\"\"\n        :class:`~transformers.BertConfig` is the configuration class to store the configuration of a\n        `BertModel`.\n\n\n        Arguments:\n            vocab_size: Vocabulary size of `inputs_ids` in `BertModel`.\n            hidden_size: Size of the encoder layers and the pooler layer.\n            num_hidden_layers: Number of hidden layers in the Transformer encoder.\n            num_attention_heads: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n                layer in the Transformer encoder.\n            hidden_act: The non-linear activation function (function or string) in the\n                encoder and pooler. If string, \"gelu\", \"relu\", \"swish\" and \"gelu_new\" are supported.\n            hidden_dropout_prob: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            attention_probs_dropout_prob: The dropout ratio for the attention\n                probabilities.\n            max_position_embeddings: The maximum sequence length that this model might\n                ever be used with. Typically set this to something large just in case\n                (e.g., 512 or 1024 or 2048).\n            type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n                `BertModel`.\n            initializer_range: The sttdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n            layer_norm_eps: The epsilon used by LayerNorm.\n    \"\"\"", "\n", "pretrained_config_archive_map", "=", "BERT_PRETRAINED_CONFIG_ARCHIVE_MAP", "\n", "\n", "def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "30522", ",", "\n", "hidden_size", "=", "768", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "intermediate_size", "=", "3072", ",", "\n", "hidden_act", "=", "\"gelu\"", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "type_vocab_size", "=", "2", ",", "\n", "initializer_range", "=", "0.02", ",", "\n"]], "home.repos.pwc.inspect_result.bcmi220_ggdp.source.conf.setup": [[183, 187], ["app.add_stylesheet", "app.add_stylesheet", "app.add_js_file"], "function", ["None"], ["def", "setup", "(", "app", ")", ":", "\n", "    ", "app", ".", "add_stylesheet", "(", "'css/huggingface.css'", ")", "\n", "app", ".", "add_stylesheet", "(", "'css/code-snippets.css'", ")", "\n", "app", ".", "add_js_file", "(", "'js/custom.js'", ")", "\n", "\n"]]}