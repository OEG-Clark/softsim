{"home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.resume.run": [[12, 52], ["vars", "os.path.dirname", "shell_logger.info", "dm_cls", "shell_logger.info", "shell_logger.info", "shell_logger.info", "dm_cls.load_encoders", "dm_cls.prepare_data", "dm_cls.setup", "shell_logger.info", "model_cls.load_from_checkpoint", "shell_logger.info", "pytorch_lightning.Trainer.from_argparse_args", "Trainer.from_argparse_args.fit", "shell_logger.info", "Trainer.from_argparse_args.test"], "function", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.base.BaseDataModule.load_encoders", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.ag_news.AgNewsDataModule.prepare_data", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.ag_news.AgNewsDataModule.setup"], ["def", "run", "(", "args", ")", ":", "\n", "    ", "dict_args", "=", "vars", "(", "args", ")", "\n", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "dirname", "(", "args", ".", "ckpt", ")", "\n", "\n", "# load data and tokenizer", "\n", "shell_logger", ".", "info", "(", "\"Building data: {}...\"", ".", "format", "(", "args", ".", "dm", ")", ")", "\n", "dm_cls", "=", "available_data_modules", "[", "args", ".", "dm", "]", "\n", "dm", "=", "dm_cls", "(", "d_params", "=", "dict_args", ")", "\n", "shell_logger", ".", "info", "(", "\"Loading encoders from {}\"", ".", "format", "(", "checkpoint_dir", ")", ")", "\n", "shell_logger", ".", "info", "(", "\"Loading tokenizer: {}...\"", ".", "format", "(", "args", ".", "load_tokenizer", ")", ")", "\n", "shell_logger", ".", "info", "(", "\"Loading label encoder: {}...\"", ".", "format", "(", "args", ".", "load_label_encoder", ")", ")", "\n", "dm", ".", "load_encoders", "(", "\n", "checkpoint_dir", ",", "\n", "load_tokenizer", "=", "args", ".", "load_tokenizer", ",", "\n", "load_label_encoder", "=", "args", ".", "load_label_encoder", ",", "\n", ")", "\n", "dm", ".", "prepare_data", "(", ")", "\n", "dm", ".", "setup", "(", ")", "\n", "\n", "# rebuild model and load weights from last checkpoint", "\n", "shell_logger", ".", "info", "(", "\"Building model and loading checkpoint...\"", ")", "\n", "model_cls", "=", "available_models", "[", "args", ".", "model", "]", "\n", "model", "=", "model_cls", ".", "load_from_checkpoint", "(", "\n", "args", ".", "ckpt", ",", "\n", "tokenizer", "=", "dm", ".", "tokenizer", ",", "\n", "nb_classes", "=", "dm", ".", "nb_classes", ",", "\n", "is_multilabel", "=", "dm", ".", "is_multilabel", ",", "\n", "h_params", "=", "dict_args", ",", "# note that dict_args should match training's", "\n", ")", "\n", "\n", "# resume training", "\n", "shell_logger", ".", "info", "(", "\"Resuming training...\"", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "args", ",", "resume_from_checkpoint", "=", "args", ".", "ckpt", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "datamodule", "=", "dm", ")", "\n", "\n", "# perform test", "\n", "shell_logger", ".", "info", "(", "\"Testing...\"", ")", "\n", "# load the best checkpoint automatically", "\n", "trainer", ".", "test", "(", "datamodule", "=", "dm", ",", "verbose", "=", "True", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.predict.run": [[12, 48], ["vars", "os.path.dirname", "shell_logger.info", "dm_cls", "shell_logger.info", "shell_logger.info", "shell_logger.info", "dm_cls.load_encoders", "dm_cls.prepare_data", "dm_cls.setup", "shell_logger.info", "model_cls.load_from_checkpoint", "shell_logger.info", "pytorch_lightning.Trainer.from_argparse_args", "Trainer.from_argparse_args.test"], "function", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.base.BaseDataModule.load_encoders", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.ag_news.AgNewsDataModule.prepare_data", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.ag_news.AgNewsDataModule.setup"], ["def", "run", "(", "args", ")", ":", "\n", "    ", "dict_args", "=", "vars", "(", "args", ")", "\n", "\n", "# /a/b/c.ext to a/b/", "\n", "checkpoint_dir", "=", "os", ".", "path", ".", "dirname", "(", "args", ".", "ckpt", ")", "\n", "\n", "# load data and tokenizer", "\n", "shell_logger", ".", "info", "(", "\"Building data: {}...\"", ".", "format", "(", "args", ".", "dm", ")", ")", "\n", "dm_cls", "=", "available_data_modules", "[", "args", ".", "dm", "]", "\n", "dm", "=", "dm_cls", "(", "d_params", "=", "dict_args", ")", "\n", "shell_logger", ".", "info", "(", "\"Loading encoders from {}\"", ".", "format", "(", "checkpoint_dir", ")", ")", "\n", "shell_logger", ".", "info", "(", "\"Loading tokenizer: {}...\"", ".", "format", "(", "args", ".", "load_tokenizer", ")", ")", "\n", "shell_logger", ".", "info", "(", "\"Loading label encoder: {}...\"", ".", "format", "(", "args", ".", "load_label_encoder", ")", ")", "\n", "dm", ".", "load_encoders", "(", "\n", "checkpoint_dir", ",", "\n", "load_tokenizer", "=", "args", ".", "load_tokenizer", ",", "\n", "load_label_encoder", "=", "args", ".", "load_label_encoder", ",", "\n", ")", "\n", "dm", ".", "prepare_data", "(", ")", "\n", "dm", ".", "setup", "(", ")", "\n", "\n", "# rebuild model and load weights from last checkpoint", "\n", "shell_logger", ".", "info", "(", "\"Building model and loading checkpoint...\"", ")", "\n", "model_cls", "=", "available_models", "[", "args", ".", "model", "]", "\n", "model", "=", "model_cls", ".", "load_from_checkpoint", "(", "\n", "args", ".", "ckpt", ",", "\n", "tokenizer", "=", "dm", ".", "tokenizer", ",", "\n", "nb_classes", "=", "dm", ".", "nb_classes", ",", "\n", "is_multilabel", "=", "dm", ".", "is_multilabel", ",", "\n", "h_params", "=", "dict_args", ",", "# note that dict_args should match training's", "\n", ")", "\n", "\n", "# test", "\n", "shell_logger", ".", "info", "(", "\"Testing...\"", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "args", ")", "\n", "trainer", ".", "test", "(", "model", ",", "datamodule", "=", "dm", ",", "verbose", "=", "True", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.train.run": [[17, 123], ["vars", "shell_logger.info", "dm_cls", "dm_cls.prepare_data", "dm_cls.setup", "shell_logger.info", "rationalizers.utils.setup_wandb_logger", "shell_logger.info", "Trainer.from_argparse_args.fit", "shell_logger.info", "shell_logger.info", "shell_logger.info", "dm_cls.save_encoders", "shell_logger.info", "Trainer.from_argparse_args.test", "vars.keys", "shell_logger.info", "model_cls", "pytorch_lightning.Trainer", "shell_logger.info", "pytorch_lightning.callbacks.EarlyStopping", "callbacks.append", "callbacks.append", "shell_logger.info", "model_cls", "shell_logger.info", "pytorch_lightning.Trainer.from_argparse_args", "shell_logger.info", "shell_logger.info", "shell_logger.info", "shell_logger.info", "rationalizers.utils.save_config_to_csv", "pytorch_lightning.callbacks.ModelCheckpoint", "pytorch_lightning.callbacks.ModelCheckpoint", "os.path.split", "vars.keys", "sum", "sum", "os.path.join", "os.path.join", "p.numel", "p.numel", "model_cls.parameters", "model_cls.parameters"], "function", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.ag_news.AgNewsDataModule.prepare_data", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.ag_news.AgNewsDataModule.setup", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.setup_wandb_logger", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.base.BaseDataModule.save_encoders", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.save_config_to_csv"], ["def", "run", "(", "args", ")", ":", "\n", "    ", "dict_args", "=", "vars", "(", "args", ")", "\n", "shell_logger", ".", "info", "(", "\"Building data: {}...\"", ".", "format", "(", "args", ".", "dm", ")", ")", "\n", "dm_cls", "=", "available_data_modules", "[", "args", ".", "dm", "]", "\n", "dm", "=", "dm_cls", "(", "d_params", "=", "dict_args", ")", "\n", "dm", ".", "prepare_data", "(", ")", "\n", "dm", ".", "setup", "(", ")", "\n", "\n", "shell_logger", ".", "info", "(", "\"Building board loggers...\"", ")", "\n", "logger", "=", "setup_wandb_logger", "(", "args", ".", "default_root_dir", ")", "\n", "\n", "if", "\"ckpt\"", "in", "dict_args", ".", "keys", "(", ")", ":", "\n", "        ", "shell_logger", ".", "info", "(", "\"Building model: {}...\"", ".", "format", "(", "args", ".", "model", ")", ")", "\n", "model_cls", "=", "available_models", "[", "args", ".", "model", "]", "\n", "model", "=", "model_cls", "(", "\n", "dm", ".", "tokenizer", ",", "dm", ".", "nb_classes", ",", "dm", ".", "is_multilabel", ",", "h_params", "=", "dict_args", "\n", ")", "\n", "trainer", "=", "Trainer", "(", "resume_from_checkpoint", "=", "args", ".", "ckpt", ")", "\n", "", "else", ":", "\n", "        ", "shell_logger", ".", "info", "(", "\"Building callbacks...\"", ")", "\n", "callbacks", "=", "[", "]", "\n", "early_stop_callback", "=", "EarlyStopping", "(", "\n", "monitor", "=", "args", ".", "monitor", ",", "\n", "mode", "=", "args", ".", "monitor_mode", ",", "\n", "patience", "=", "args", ".", "monitor_patience", ",", "\n", "verbose", "=", "True", ",", "\n", ")", "\n", "callbacks", ".", "append", "(", "early_stop_callback", ")", "\n", "\n", "early_stopping", "=", "(", "\n", "dict_args", "[", "\"early_stopping\"", "]", "\n", "if", "\"early_stopping\"", "in", "dict_args", ".", "keys", "(", ")", "\n", "else", "True", "\n", ")", "\n", "\n", "# Disregard Early Stopping and save the model from last epoch", "\n", "if", "not", "early_stopping", ":", "\n", "            ", "checkpoint_callback", "=", "ModelCheckpoint", "(", "\n", "dirpath", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "default_root_dir", ",", "\n", "f\"version{logger.version}\"", ",", "\n", "\"checkpoints\"", ",", "\n", ")", ",", "\n", "filename", "=", "\"{epoch}\"", ",", "\n", "verbose", "=", "True", ",", "\n", "save_last", "=", "True", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "checkpoint_callback", "=", "ModelCheckpoint", "(", "\n", "dirpath", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "default_root_dir", ",", "\n", "f\"version{logger.version}\"", ",", "\n", "\"checkpoints\"", ",", "\n", ")", ",", "\n", "filename", "=", "\"{epoch}\"", ",", "\n", "monitor", "=", "args", ".", "monitor", ",", "\n", "verbose", "=", "True", ",", "\n", "mode", "=", "args", ".", "monitor_mode", ",", "\n", "save_top_k", "=", "1", ",", "\n", ")", "\n", "", "callbacks", ".", "append", "(", "checkpoint_callback", ")", "\n", "version_path", "=", "os", ".", "path", ".", "split", "(", "checkpoint_callback", ".", "dirpath", ")", "[", "0", "]", "\n", "shell_logger", ".", "info", "(", "\"Building model: {}...\"", ".", "format", "(", "args", ".", "model", ")", ")", "\n", "model_cls", "=", "available_models", "[", "args", ".", "model", "]", "\n", "model", "=", "model_cls", "(", "\n", "dm", ".", "tokenizer", ",", "dm", ".", "nb_classes", ",", "dm", ".", "is_multilabel", ",", "h_params", "=", "dict_args", "\n", ")", "\n", "\n", "shell_logger", ".", "info", "(", "\"Building trainer...\"", ")", "\n", "trainer", "=", "Trainer", ".", "from_argparse_args", "(", "\n", "args", ",", "\n", "logger", "=", "logger", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "checkpoint_callback", "=", "checkpoint_callback", ",", "\n", "weights_summary", "=", "\"full\"", ",", "\n", ")", "\n", "\n", "# log stuff", "\n", "shell_logger", ".", "info", "(", "\"Vocab size: {}\"", ".", "format", "(", "dm", ".", "tokenizer", ".", "vocab_size", ")", ")", "\n", "shell_logger", ".", "info", "(", "\"Nb labels: {}\"", ".", "format", "(", "dm", ".", "nb_classes", ")", ")", "\n", "shell_logger", ".", "info", "(", "\n", "\"Total params: {}\"", ".", "format", "(", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", ")", ")", "\n", ")", "\n", "shell_logger", ".", "info", "(", "\n", "\"Learnable params: {}\"", ".", "format", "(", "\n", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", ")", "\n", ")", "\n", "save_config_to_csv", "(", "dict_args", ",", "version_path", ")", "\n", "\n", "# start training", "\n", "", "shell_logger", ".", "info", "(", "\"Starting fit...\"", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "dm", ")", "\n", "\n", "# save encoders in the best model dir", "\n", "shell_logger", ".", "info", "(", "\"Saving encoders in {}\"", ".", "format", "(", "checkpoint_callback", ".", "dirpath", ")", ")", "\n", "shell_logger", ".", "info", "(", "\"Saving tokenizer: {}...\"", ".", "format", "(", "args", ".", "save_tokenizer", ")", ")", "\n", "shell_logger", ".", "info", "(", "\"Saving label encoder: {}...\"", ".", "format", "(", "args", ".", "save_label_encoder", ")", ")", "\n", "dm", ".", "save_encoders", "(", "\n", "checkpoint_callback", ".", "dirpath", ",", "args", ".", "save_tokenizer", ",", "args", ".", "save_label_encoder", "\n", ")", "\n", "\n", "# perform test", "\n", "shell_logger", ".", "info", "(", "\"Testing...\"", ")", "\n", "# load the best checkpoint automatically", "\n", "trainer", ".", "test", "(", "datamodule", "=", "dm", ",", "verbose", "=", "True", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_sentence_encoder": [[9, 19], ["rationalizers.modules.sentence_encoders.LSTMEncoder", "Exception"], "function", ["None"], ["def", "build_sentence_encoder", "(", "\n", "layer", ":", "str", ",", "\n", "in_features", ":", "int", ",", "\n", "hidden_size", ":", "int", ",", "\n", "bidirectional", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "    ", "if", "layer", "==", "\"lstm\"", ":", "\n", "        ", "return", "LSTMEncoder", "(", "in_features", ",", "hidden_size", ",", "bidirectional", "=", "bidirectional", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "f\"Sentence encoder layer `{layer}` not available.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_embedding_weights": [[21, 27], ["print", "rationalizers.utils.load_glove_embeddings"], "function", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.load_glove_embeddings"], ["", "", "def", "build_embedding_weights", "(", "vocab", ":", "dict", ",", "emb_type", ":", "str", ",", "emb_path", ":", "str", ",", "emb_size", ":", "int", ")", ":", "\n", "    ", "if", "emb_type", "==", "\"glove\"", ":", "\n", "        ", "return", "load_glove_embeddings", "(", "vocab", ",", "emb_path", ",", "emb_size", ")", "\n", "# nn.Embedding will initialize the weights randomly", "\n", "", "print", "(", "\"Random weights will be used as embeddings.\"", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_optimizer": [[29, 102], ["torch.optim.Adam", "torch.optim.Adadelta", "torch.optim.Adagrad", "torch.optim.Adamax", "torch.optim.AdamW", "torch.optim.SparseAdam", "torch.optim.SGD", "torch.optim.ASGD", "torch.optim.RMSprop", "Exception"], "function", ["None"], ["", "def", "build_optimizer", "(", "model_parameters", ",", "h_params", ":", "dict", ")", ":", "\n", "# get valid parameters (unfreezed ones)", "\n", "# parameters = filter(lambda p: p.requires_grad, model_parameters)", "\n", "    ", "parameters", "=", "model_parameters", "\n", "if", "h_params", "[", "\"optimizer\"", "]", "==", "\"adam\"", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "Adam", "(", "\n", "parameters", ",", "\n", "lr", "=", "h_params", "[", "\"lr\"", "]", ",", "\n", "betas", "=", "h_params", "[", "\"betas\"", "]", ",", "\n", "weight_decay", "=", "h_params", "[", "\"weight_decay\"", "]", ",", "\n", "amsgrad", "=", "h_params", "[", "\"amsgrad\"", "]", ",", "\n", ")", "\n", "", "elif", "h_params", "[", "\"optimizer\"", "]", "==", "\"adadelta\"", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "Adadelta", "(", "\n", "parameters", ",", "\n", "lr", "=", "h_params", "[", "\"lr\"", "]", ",", "\n", "rho", "=", "h_params", "[", "\"rho\"", "]", ",", "\n", "weight_decay", "=", "h_params", "[", "\"weight_decay\"", "]", ",", "\n", ")", "\n", "", "elif", "h_params", "[", "\"optimizer\"", "]", "==", "\"adadelta\"", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "Adagrad", "(", "\n", "parameters", ",", "lr", "=", "h_params", "[", "\"lr\"", "]", ",", "weight_decay", "=", "h_params", "[", "\"weight_decay\"", "]", "\n", ")", "\n", "", "elif", "h_params", "[", "\"optimizer\"", "]", "==", "\"adamax\"", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "Adamax", "(", "\n", "parameters", ",", "\n", "lr", "=", "h_params", "[", "\"lr\"", "]", ",", "\n", "betas", "=", "h_params", "[", "\"betas\"", "]", ",", "\n", "weight_decay", "=", "h_params", "[", "\"weight_decay\"", "]", ",", "\n", ")", "\n", "", "elif", "h_params", "[", "\"optimizer\"", "]", "==", "\"adamw\"", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "AdamW", "(", "\n", "parameters", ",", "\n", "lr", "=", "h_params", "[", "\"lr\"", "]", ",", "\n", "betas", "=", "h_params", "[", "\"betas\"", "]", ",", "\n", "weight_decay", "=", "h_params", "[", "\"weight_decay\"", "]", ",", "\n", "amsgrad", "=", "h_params", "[", "\"amsgrad\"", "]", ",", "\n", ")", "\n", "", "elif", "h_params", "[", "\"optimizer\"", "]", "==", "\"sparseadam\"", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "SparseAdam", "(", "\n", "parameters", ",", "\n", "lr", "=", "h_params", "[", "\"lr\"", "]", ",", "\n", "betas", "=", "h_params", "[", "\"betas\"", "]", ",", "\n", ")", "\n", "", "elif", "h_params", "[", "\"optimizer\"", "]", "==", "\"sgd\"", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "SGD", "(", "\n", "parameters", ",", "\n", "lr", "=", "h_params", "[", "\"lr\"", "]", ",", "\n", "momentum", "=", "h_params", "[", "\"momentum\"", "]", ",", "\n", "dampening", "=", "h_params", "[", "\"dampening\"", "]", ",", "\n", "weight_decay", "=", "h_params", "[", "\"weight_decay\"", "]", ",", "\n", "nesterov", "=", "h_params", "[", "\"nesterov\"", "]", ",", "\n", ")", "\n", "", "elif", "h_params", "[", "\"optimizer\"", "]", "==", "\"asgd\"", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "ASGD", "(", "\n", "parameters", ",", "\n", "lr", "=", "h_params", "[", "\"lr\"", "]", ",", "\n", "lambd", "=", "h_params", "[", "\"lambd\"", "]", ",", "\n", "alpha", "=", "h_params", "[", "\"alpha\"", "]", ",", "\n", "t0", "=", "h_params", "[", "\"t0\"", "]", ",", "\n", "weight_decay", "=", "h_params", "[", "\"weight_decay\"", "]", ",", "\n", ")", "\n", "", "elif", "h_params", "[", "\"optimizer\"", "]", "==", "\"rmsprop\"", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "RMSprop", "(", "\n", "parameters", ",", "\n", "lr", "=", "h_params", "[", "\"lr\"", "]", ",", "\n", "alpha", "=", "h_params", "[", "\"alpha\"", "]", ",", "\n", "weight_decay", "=", "h_params", "[", "\"weight_decay\"", "]", ",", "\n", "momentum", "=", "h_params", "[", "\"momentum\"", "]", ",", "\n", "centered", "=", "h_params", "[", "\"centered\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "f\"Optimizer `{h_params['optimizer']}` not available.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_scheduler": [[104, 143], ["torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.MultiStepLR", "torch.optim.lr_scheduler.ExponentialLR", "torch.optim.lr_scheduler.CosineAnnealingLR", "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts", "torch.optim.lr_scheduler.ReduceLROnPlateau", "Exception"], "function", ["None"], ["", "", "def", "build_scheduler", "(", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "h_params", ":", "dict", ")", ":", "\n", "    ", "\"\"\"Returns a torch lr_scheduler object or None in case a scheduler is not specified.\"\"\"", "\n", "if", "\"scheduler\"", "not", "in", "h_params", "or", "h_params", "[", "\"scheduler\"", "]", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "elif", "h_params", "[", "\"scheduler\"", "]", "==", "\"step\"", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "\n", "optimizer", ",", "step_size", "=", "h_params", "[", "\"step_size\"", "]", ",", "gamma", "=", "h_params", "[", "\"lr_decay\"", "]", "\n", ")", "\n", "", "elif", "h_params", "[", "\"scheduler\"", "]", "==", "\"multistep\"", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "lr_scheduler", ".", "MultiStepLR", "(", "\n", "optimizer", ",", "milestones", "=", "h_params", "[", "\"milestones\"", "]", ",", "gamma", "=", "h_params", "[", "\"lr_decay\"", "]", "\n", ")", "\n", "", "elif", "h_params", "[", "\"scheduler\"", "]", "==", "\"exponential\"", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "lr_scheduler", ".", "ExponentialLR", "(", "\n", "optimizer", ",", "gamma", "=", "h_params", "[", "\"lr_decay\"", "]", "\n", ")", "\n", "", "elif", "h_params", "[", "\"scheduler\"", "]", "==", "\"cosine-annealing\"", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "lr_scheduler", ".", "CosineAnnealingLR", "(", "\n", "optimizer", ",", "T_max", "=", "h_params", "[", "\"T_max\"", "]", ",", "eta_min", "=", "h_params", "[", "\"eta_min\"", "]", "\n", ")", "\n", "", "elif", "h_params", "[", "\"scheduler\"", "]", "==", "\"cosine-annealing\"", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "lr_scheduler", ".", "CosineAnnealingWarmRestarts", "(", "\n", "optimizer", ",", "\n", "T_0", "=", "h_params", "[", "\"T_0\"", "]", ",", "\n", "T_mult", "=", "h_params", "[", "\"T_mult\"", "]", ",", "\n", "eta_min", "=", "h_params", "[", "\"eta_min\"", "]", ",", "\n", ")", "\n", "", "elif", "h_params", "[", "\"scheduler\"", "]", "==", "\"plateau\"", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "lr_scheduler", ".", "ReduceLROnPlateau", "(", "\n", "optimizer", ",", "\n", "mode", "=", "\"min\"", ",", "\n", "factor", "=", "h_params", "[", "\"lr_decay\"", "]", ",", "\n", "patience", "=", "h_params", "[", "\"patience\"", "]", ",", "\n", "cooldown", "=", "h_params", "[", "\"cooldown\"", "]", ",", "\n", "threshold", "=", "h_params", "[", "\"threshold\"", "]", ",", "\n", "min_lr", "=", "h_params", "[", "\"min_lr\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "f\"Scheduler `{h_params['scheduler']}` not available.\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.configure_output_dir": [[24, 34], ["pathlib.Path", "pathlib.Path.mkdir", "str"], "function", ["None"], ["def", "configure_output_dir", "(", "output_dir", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Create a directory (recursively) and ignore errors if they already exist.\n\n    :param output_dir: path to the output directory\n    :return: output_path\n    \"\"\"", "\n", "output_path", "=", "Path", "(", "output_dir", ")", "\n", "output_path", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "return", "str", "(", "output_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.configure_seed": [[36, 45], ["pytorch_lightning.seed_everything"], "function", ["None"], ["", "def", "configure_seed", "(", "seed", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Seed everything: python, random, numpy, torch, torch.cuda.\n\n    :param seed: seed integer (if None, a random seed will be created)\n    :return: seed integer\n    \"\"\"", "\n", "seed", "=", "seed_everything", "(", "seed", ")", "\n", "return", "seed", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.configure_shell_logger": [[47, 56], ["logging.basicConfig", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger().addHandler", "os.path.join", "logging.Formatter", "logging.getLogger"], "function", ["None"], ["", "def", "configure_shell_logger", "(", "output_dir", ":", "str", ")", ":", "\n", "    ", "\"\"\"Configure logger with a proper log format and save log to a file.\"\"\"", "\n", "log_format", "=", "\"[%(asctime)s] %(levelname)s: %(message)s\"", "\n", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ",", "format", "=", "log_format", ")", "\n", "if", "output_dir", "is", "not", "None", ":", "\n", "        ", "fh", "=", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"out.log\"", ")", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "fh", ".", "setFormatter", "(", "logging", ".", "Formatter", "(", "log_format", ")", ")", "\n", "logging", ".", "getLogger", "(", ")", ".", "addHandler", "(", "fh", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.save_object": [[58, 67], ["open", "pickle.dump"], "function", ["None"], ["", "", "def", "save_object", "(", "obj", ":", "object", ",", "path", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Dump an object (e.g. tokenizer or label encoder) via pickle.\n\n    :param obj: any object (e.g. pytorch-nlp's tokenizer instance)\n    :param path: path to save the object\n    \"\"\"", "\n", "with", "open", "(", "path", ",", "\"wb\"", ")", "as", "handle", ":", "\n", "        ", "pickle", ".", "dump", "(", "obj", ",", "handle", ",", "protocol", "=", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.save_config_to_csv": [[69, 83], ["os.path.join", "os.path.exists", "os.mkdir", "open", "csv.writer", "dict_args.items", "csv.writer.writerow"], "function", ["None"], ["", "", "def", "save_config_to_csv", "(", "dict_args", ":", "dict", ",", "path", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Save the meta data config to csv in the run folder as \"meta_tags.csv\"\n\n    :param obj: dict with the data\n    :param path: path to save the object\n    \"\"\"", "\n", "meta_tags_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"meta_tags.csv\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "path", ")", "\n", "", "with", "open", "(", "meta_tags_path", ",", "\"w\"", ")", "as", "csv_file", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "csv_file", ")", "\n", "for", "key", ",", "value", "in", "dict_args", ".", "items", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "key", ",", "value", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.load_object": [[85, 95], ["open", "pickle.load"], "function", ["None"], ["", "", "", "def", "load_object", "(", "path", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Unpickle a saved object.\n\n    :param path: path to a pickled object\n    :return: the object\n    \"\"\"", "\n", "with", "open", "(", "path", ",", "\"rb\"", ")", "as", "handle", ":", "\n", "        ", "tokenizer", "=", "pickle", ".", "load", "(", "handle", ")", "\n", "", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.load_yaml_config": [[97, 109], ["open", "yaml.safe_load"], "function", ["None"], ["", "def", "load_yaml_config", "(", "path", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    From: https://github.com/joeynmt/joeynmt/\n\n    Loads and parses a YAML configuration file.\n\n    :param path: path to YAML configuration file\n    :return: configuration dict\n    \"\"\"", "\n", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "ymlfile", ":", "\n", "        ", "cfg", "=", "yaml", ".", "safe_load", "(", "ymlfile", ")", "\n", "", "return", "cfg", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.setup_wandb_logger": [[111, 122], ["uuid.uuid4", "pytorch_lightning.loggers.WandbLogger", "str"], "function", ["None"], ["", "def", "setup_wandb_logger", "(", "default_root_dir", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Function that sets the WanbLogger to be used.\n\n    :param default_root_dir: logs save dir.\n    \"\"\"", "\n", "id", "=", "uuid", ".", "uuid4", "(", ")", "\n", "return", "WandbLogger", "(", "\n", "project", "=", "\"SPECTRA\"", ",", "\n", "save_dir", "=", "default_root_dir", ",", "\n", "version", "=", "str", "(", "id", ".", "fields", "[", "1", "]", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.find_last_checkpoint_version": [[125, 145], ["os.listdir", "os.listdir.sort", "os.path.join", "os.listdir", "os.listdir.sort", "os.path.join", "len", "len", "int", "x[].split"], "function", ["None"], ["", "def", "find_last_checkpoint_version", "(", "path_to_logs", ":", "str", ")", ":", "\n", "    ", "\"\"\"Sort the log directory to pick the last timestamped checkpoint filename.\"\"\"", "\n", "\n", "def", "get_time_from_version_name", "(", "name", ":", "str", ")", ":", "\n", "# name format example `version_16-10-2020_08-12-48`", "\n", "        ", "timestamp", "=", "name", "[", "6", ":", "]", "\n", "return", "timestamp", "\n", "\n", "", "ckpt_versions", "=", "os", ".", "listdir", "(", "path_to_logs", ")", "\n", "if", "len", "(", "ckpt_versions", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "", "ckpt_versions", ".", "sort", "(", "key", "=", "get_time_from_version_name", ")", "\n", "\n", "ckpt_dir", "=", "os", ".", "path", ".", "join", "(", "path_to_logs", ",", "ckpt_versions", "[", "-", "1", "]", ",", "\"checkpoints/\"", ")", "\n", "ckpt_epochs", "=", "os", ".", "listdir", "(", "ckpt_dir", ")", "\n", "if", "len", "(", "ckpt_epochs", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "", "ckpt_epochs", ".", "sort", "(", "key", "=", "lambda", "x", ":", "int", "(", "x", "[", "6", ":", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", ")", ")", "# e.g. epoch=2.ckpt", "\n", "\n", "return", "os", ".", "path", ".", "join", "(", "ckpt_dir", ",", "ckpt_epochs", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.load_ckpt_config": [[147, 157], ["os.path.dirname", "os.path.join", "pytorch_lightning.core.saving.load_hparams_from_tags_csv", "os.path.dirname"], "function", ["None"], ["", "def", "load_ckpt_config", "(", "ckpt_path", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Load the .csv config file stored with the checkpoint and transform it to a dict object.\n    :param ckpt_path: path to a saved checkpoint.\n    :return: config dict\n    \"\"\"", "\n", "csv_config_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "dirname", "(", "ckpt_path", ")", ")", "\n", "csv_config_path", "=", "os", ".", "path", ".", "join", "(", "csv_config_dir", ",", "\"meta_tags.csv\"", ")", "\n", "config_dict", "=", "load_hparams_from_tags_csv", "(", "csv_config_path", ")", "\n", "return", "config_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.get_rationales": [[159, 180], ["z.cuda.cuda", "tokenizer.batch_decode"], "function", ["None"], ["", "def", "get_rationales", "(", "\n", "tokenizer", ":", "StaticTokenizerEncoder", ",", "\n", "input_ids", ":", "torch", ".", "LongTensor", ",", "\n", "z", ":", "torch", ".", "FloatTensor", ",", "\n", "lengths", ":", "torch", ".", "LongTensor", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Get rationales from a list of tokens masked by the generator's selection z.\n\n    :param tokenizer:\n    :param input_ids: ids LongTensor with shape [B, T]\n    :param z: binary FloatTensor with shape [B, T]\n    :param lengths: original length LongTensor of each sample with shape [B, ]\n\n    :return: list of lists containing the selected rationales\n    \"\"\"", "\n", "z", "=", "z", ".", "cuda", "(", ")", "\n", "selected_ids", "=", "(", "z", "*", "input_ids", ")", ".", "long", "(", ")", "\n", "selected_rationales", "=", "tokenizer", ".", "batch_decode", "(", "selected_ids", ",", "lengths", ")", "\n", "\n", "return", "selected_ids", ",", "selected_rationales", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.get_z_stats": [[182, 204], ["torch.where.cuda", "torch.where", "mask.sum().item", "torch.where.new_full", "mask.sum"], "function", ["None"], ["", "def", "get_z_stats", "(", "z", "=", "None", ",", "mask", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    From: https://github.com/bastings/interpretable_predictions\n\n    Computes statistics about how many zs are\n    exactly 0, continuous (between 0 and 1), or exactly 1.\n\n    :param z:\n    :param mask: mask in [B, T]\n    :return:\n    \"\"\"", "\n", "z", "=", "z", ".", "cuda", "(", ")", "\n", "z", "=", "torch", ".", "where", "(", "mask", ",", "z", ",", "z", ".", "new_full", "(", "[", "1", "]", ",", "1e2", ")", ")", "\n", "\n", "num_0", "=", "(", "z", "==", "0.0", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_c", "=", "(", "(", "z", ">", "0.0", ")", "&", "(", "z", "<", "1.0", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_1", "=", "(", "z", "==", "1.0", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "num_0", "+", "num_c", "+", "num_1", "\n", "mask_total", "=", "mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "# assert total == mask_total, \"total mismatch\"", "\n", "return", "num_0", ",", "num_c", ",", "num_1", ",", "mask_total", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.load_glove_embeddings": [[206, 240], ["set", "torch.FloatTensor().uniform_", "torchnlp.word_to_vector.GloVe", "torch.FloatTensor", "enumerate", "len", "torch.FloatTensor", "torch.zeros", "torch.FloatTensor().uniform_", "torch.FloatTensor"], "function", ["None"], ["", "def", "load_glove_embeddings", "(", "vocab", ":", "list", ",", "name", ":", "str", ",", "emb_size", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Load pre-trained Glove embeddings using PyTorch-NLP interface:\n    https://pytorchnlp.readthedocs.io/en/latest/source/torchnlp.word_to_vector.html\n\n    :param vocab: list of tokens\n    :param name: Glove name version (e.g. \u2018840B\u2019, \u2018twitter.27B\u2019, \u20186B\u2019, \u201842B\u2019)\n    :param emb_size: word embedding size\n    :return: Torch.FloatTensor with shape (vocab_size, emb_dim)\n    \"\"\"", "\n", "vocab_set", "=", "set", "(", "vocab", ")", "\n", "unk_vector", "=", "torch", ".", "FloatTensor", "(", "emb_size", ")", ".", "uniform_", "(", "-", "0.05", ",", "0.05", ")", "\n", "unk_init", "=", "lambda", "v", ":", "unk_vector", "\n", "pretrained_embedding", "=", "GloVe", "(", "\n", "name", "=", "name", ",", "\n", "dim", "=", "emb_size", ",", "\n", "unk_init", "=", "unk_init", ",", "\n", "is_include", "=", "lambda", "w", ":", "w", "in", "vocab_set", ",", "\n", ")", "\n", "embedding_weights", "=", "torch", ".", "FloatTensor", "(", "len", "(", "vocab", ")", ",", "emb_size", ")", "\n", "for", "idx", ",", "token", "in", "enumerate", "(", "vocab", ")", ":", "\n", "        ", "if", "token", "in", "[", "constants", ".", "PAD", ",", "constants", ".", "SOS", ",", "constants", ".", "EOS", "]", ":", "\n", "            ", "if", "token", "in", "pretrained_embedding", ".", "token_to_index", ":", "\n", "                ", "embedding_weights", "[", "idx", "]", "=", "pretrained_embedding", "[", "token", "]", "\n", "", "else", ":", "\n", "                ", "if", "token", "==", "constants", ".", "PAD", ":", "# zero vector for padding", "\n", "                    ", "embedding_weights", "[", "idx", "]", "=", "torch", ".", "zeros", "(", "emb_size", ")", "\n", "", "else", ":", "# random token for everything else", "\n", "                    ", "embedding_weights", "[", "idx", "]", "=", "torch", ".", "FloatTensor", "(", "emb_size", ")", ".", "uniform_", "(", "\n", "-", "0.05", ",", "0.05", "\n", ")", "\n", "", "", "", "else", ":", "\n", "            ", "embedding_weights", "[", "idx", "]", "=", "pretrained_embedding", "[", "token", "]", "\n", "", "", "return", "embedding_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.unroll": [[242, 257], ["isinstance", "isinstance", "utils.unroll"], "function", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.unroll"], ["", "def", "unroll", "(", "list_of_lists", ",", "rec", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Unroll a list of lists\n    Args:\n        list_of_lists (list): a list that contains lists\n        rec (bool): unroll recursively\n    Returns:\n        a single list\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "list_of_lists", "[", "0", "]", ",", "(", "np", ".", "ndarray", ",", "list", ",", "torch", ".", "Tensor", ")", ")", ":", "\n", "        ", "return", "list_of_lists", "\n", "", "new_list", "=", "[", "item", "for", "ell", "in", "list_of_lists", "for", "item", "in", "ell", "]", "\n", "if", "rec", "and", "isinstance", "(", "new_list", "[", "0", "]", ",", "(", "np", ".", "ndarray", ",", "list", ",", "torch", ".", "Tensor", ")", ")", ":", "\n", "        ", "return", "unroll", "(", "new_list", ",", "rec", "=", "rec", ")", "\n", "", "return", "new_list", "\n", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.custom_hf_datasets.sst.SSTDatasetConfig.__init__": [[46, 78], ["collections.OrderedDict", "len", "datasets.BuilderConfig.__init__", "list", "sst.SSTDatasetConfig.granularity_map.values"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["def", "__init__", "(", "self", ",", "granularity", ":", "str", "=", "\"2\"", ",", "subtrees", ":", "bool", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            granularity: The labeling granularity: `2`, `3` or `5`.\n            subtrees: Whether to include sentiment-tagged subphrases in addition to complete examples.\n            **kwargs: keyword arguments forwarded to super.\n        \"\"\"", "\n", "assert", "granularity", "in", "[", "\"2\"", ",", "\"3\"", ",", "\"5\"", "]", "\n", "self", ".", "granularity", "=", "granularity", "\n", "self", ".", "subtrees", "=", "subtrees", "\n", "self", ".", "granularity_map", "=", "OrderedDict", "(", "\n", "{", "\n", "\"0\"", ":", "\"very negative\"", ",", "\n", "\"1\"", ":", "\"negative\"", ",", "\n", "\"2\"", ":", "\"neutral\"", ",", "\n", "\"3\"", ":", "\"positive\"", ",", "\n", "\"4\"", ":", "\"very positive\"", ",", "\n", "None", ":", "None", ",", "\n", "}", "\n", ")", "\n", "self", ".", "names", "=", "list", "(", "self", ".", "granularity_map", ".", "values", "(", ")", ")", "[", ":", "-", "1", "]", "\n", "if", "granularity", "==", "\"2\"", ":", "\n", "            ", "self", ".", "granularity_map", "[", "\"0\"", "]", "=", "\"negative\"", "\n", "self", ".", "granularity_map", "[", "\"2\"", "]", "=", "None", "\n", "self", ".", "granularity_map", "[", "\"4\"", "]", "=", "\"positive\"", "\n", "self", ".", "names", "=", "[", "\"negative\"", ",", "\"positive\"", "]", "\n", "", "elif", "granularity", "==", "\"3\"", ":", "\n", "            ", "self", ".", "granularity_map", "[", "\"0\"", "]", "=", "\"negative\"", "\n", "self", ".", "granularity_map", "[", "\"4\"", "]", "=", "\"positive\"", "\n", "self", ".", "names", "=", "[", "\"negative\"", ",", "\"neutral\"", ",", "\"positive\"", "]", "\n", "", "self", ".", "nb_classes", "=", "len", "(", "self", ".", "names", ")", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.custom_hf_datasets.sst.SSTDataset._info": [[97, 117], ["datasets.DatasetInfo", "datasets.Features", "datasets.Value", "datasets.Value"], "methods", ["None"], ["def", "_info", "(", "self", ")", ":", "\n", "        ", "return", "datasets", ".", "DatasetInfo", "(", "\n", "# This is the description that will appear on the datasets page.", "\n", "description", "=", "_DESCRIPTION", ",", "\n", "# This defines the different columns of the dataset and their types", "\n", "features", "=", "datasets", ".", "Features", "(", "\n", "{", "\n", "\"tokens\"", ":", "datasets", ".", "Value", "(", "\"string\"", ")", ",", "\n", "\"label\"", ":", "datasets", ".", "Value", "(", "\"string\"", ")", ",", "\n", "# map to integers using the order of self.config.names", "\n", "# \"label\": datasets.ClassLabel(self.config.nb_classes, names=self.config.names)", "\n", "}", "\n", ")", ",", "\n", "# If there's a common (input, target) tuple from the features,", "\n", "# specify them here. They'll be used if as_supervised=True in", "\n", "# builder.as_dataset.", "\n", "supervised_keys", "=", "None", ",", "\n", "# Homepage of the dataset for documentation", "\n", "homepage", "=", "\"https://nlp.stanford.edu/sentiment/\"", ",", "\n", "citation", "=", "_CITATION", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.custom_hf_datasets.sst.SSTDataset._split_generators": [[119, 150], ["dl_manager.download_and_extract", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "datasets.SplitGenerator", "datasets.SplitGenerator", "datasets.SplitGenerator"], "methods", ["None"], ["", "def", "_split_generators", "(", "self", ",", "dl_manager", ")", ":", "\n", "        ", "\"\"\"Returns SplitGenerators.\"\"\"", "\n", "\n", "# dl_manager is a datasets.download.DownloadManager that can be used to", "\n", "# download and extract URLs", "\n", "data_dir", "=", "dl_manager", ".", "download_and_extract", "(", "_URL", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"trees/\"", ")", "\n", "filepaths", "=", "{", "\n", "\"train\"", ":", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.txt\"", ")", ",", "\n", "\"dev\"", ":", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.txt\"", ")", ",", "\n", "\"test\"", ":", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.txt\"", ")", ",", "\n", "}", "\n", "\n", "return", "[", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "TRAIN", ",", "\n", "gen_kwargs", "=", "{", "\n", "\"filepath\"", ":", "filepaths", "[", "\"train\"", "]", ",", "\n", "\"split\"", ":", "\"train\"", ",", "\n", "}", ",", "\n", ")", ",", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "VALIDATION", ",", "\n", "gen_kwargs", "=", "{", "\n", "\"filepath\"", ":", "filepaths", "[", "\"dev\"", "]", ",", "\n", "\"split\"", ":", "\"dev\"", ",", "\n", "}", ",", "\n", ")", ",", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "TEST", ",", "\n", "gen_kwargs", "=", "{", "\"filepath\"", ":", "filepaths", "[", "\"test\"", "]", ",", "\"split\"", ":", "\"test\"", "}", ",", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.custom_hf_datasets.sst.SSTDataset._generate_examples": [[153, 184], ["open", "row.strip", "nltk.tree.Tree.fromstring", "nltk.tree.Tree.fromstring.subtrees", "nltk.tree.Tree.fromstring.leaves", "subtree.leaves", "subtree.label", "nltk.tree.Tree.fromstring.label", "subtree.label"], "methods", ["None"], ["", "def", "_generate_examples", "(", "self", ",", "filepath", ",", "split", ")", ":", "\n", "        ", "\"\"\"Yields examples.\"\"\"", "\n", "id_", "=", "-", "1", "\n", "with", "open", "(", "filepath", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "            ", "for", "row", "in", "f", ":", "\n", "                ", "data", "=", "row", ".", "strip", "(", ")", "\n", "tree", "=", "Tree", ".", "fromstring", "(", "data", ")", "\n", "if", "self", ".", "config", ".", "subtrees", ":", "\n", "                    ", "for", "subtree", "in", "tree", ".", "subtrees", "(", ")", ":", "\n", "                        ", "tokens", "=", "\" \"", ".", "join", "(", "subtree", ".", "leaves", "(", ")", ")", "\n", "label", "=", "self", ".", "config", ".", "granularity_map", "[", "subtree", ".", "label", "(", ")", "]", "\n", "if", "(", "\n", "subtree", ".", "label", "(", ")", "is", "None", "\n", ")", ":", "# ignore invalid entries or (granularity=2 and label=neutral)", "\n", "                            ", "continue", "\n", "", "id_", "+=", "1", "\n", "yield", "id_", ",", "{", "\n", "\"tokens\"", ":", "tokens", ",", "\n", "\"label\"", ":", "label", ",", "\n", "}", "\n", "", "", "else", ":", "\n", "                    ", "tokens", "=", "\" \"", ".", "join", "(", "tree", ".", "leaves", "(", ")", ")", "\n", "label", "=", "self", ".", "config", ".", "granularity_map", "[", "tree", ".", "label", "(", ")", "]", "\n", "if", "(", "\n", "label", "is", "None", "\n", ")", ":", "# ignore invalid entries or (granularity=2 and label=neutral)", "\n", "                        ", "continue", "\n", "", "id_", "+=", "1", "\n", "yield", "id_", ",", "{", "\n", "\"tokens\"", ":", "tokens", ",", "\n", "\"label\"", ":", "label", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.custom_hf_datasets.hotel_location_proc.HotelLocationDatasetConfig.__init__": [[47, 53], ["datasets.BuilderConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            **kwargs: keyword arguments forwarded to super.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.custom_hf_datasets.hotel_location_proc.HotelLocationDataset._info": [[68, 94], ["datasets.DatasetInfo", "datasets.Features", "datasets.Value", "datasets.features.Sequence", "datasets.features.Sequence", "datasets.Value", "datasets.features.Sequence", "datasets.features.Sequence", "datasets.Value"], "methods", ["None"], ["def", "_info", "(", "self", ")", ":", "\n", "        ", "return", "datasets", ".", "DatasetInfo", "(", "\n", "# This is the description that will appear on the datasets page.", "\n", "description", "=", "_DESCRIPTION", ",", "\n", "# This defines the different columns of the dataset and their types", "\n", "features", "=", "datasets", ".", "Features", "(", "\n", "{", "\n", "\"tokens\"", ":", "datasets", ".", "Value", "(", "\"string\"", ")", ",", "\n", "# we have five scores (one for each aspect) normalized between 0 and 1", "\n", "\"scores\"", ":", "datasets", ".", "features", ".", "Sequence", "(", "\n", "datasets", ".", "Value", "(", "\"float\"", ")", ",", "length", "=", "1", "\n", ")", ",", "\n", "\"annotations\"", ":", "datasets", ".", "features", ".", "Sequence", "(", "\n", "datasets", ".", "features", ".", "Sequence", "(", "\n", "datasets", ".", "features", ".", "Sequence", "(", "datasets", ".", "Value", "(", "\"int32\"", ")", ")", "\n", ")", "\n", ")", ",", "\n", "}", "\n", ")", ",", "\n", "# If there's a common (input, target) tuple from the features,", "\n", "# specify them here. They'll be used if as_supervised=True in", "\n", "# builder.as_dataset.", "\n", "supervised_keys", "=", "None", ",", "\n", "# Homepage of the dataset for documentation", "\n", "homepage", "=", "\"https://www.cs.virginia.edu/~hw5x/dataset.html\"", ",", "\n", "citation", "=", "_CITATION", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.custom_hf_datasets.hotel_location_proc.HotelLocationDataset._split_generators": [[96, 127], ["dl_manager.download_and_extract", "os.path.join", "os.path.join", "os.path.join", "datasets.SplitGenerator", "datasets.SplitGenerator", "datasets.SplitGenerator"], "methods", ["None"], ["", "def", "_split_generators", "(", "self", ",", "dl_manager", ")", ":", "\n", "        ", "\"\"\"Returns SplitGenerators.\"\"\"", "\n", "\n", "# dl_manager is a datasets.download.DownloadManager that can be used to", "\n", "# download and extract URLs", "\n", "dl_dir", "=", "dl_manager", ".", "download_and_extract", "(", "_URL", ")", "\n", "data_dir", "=", "dl_dir", "\n", "filepaths", "=", "{", "\n", "\"train\"", ":", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"hotel_location/hotel_Location_train.csv\"", ")", ",", "\n", "\"dev\"", ":", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"hotel_location/hotel_Location_dev.csv\"", ")", ",", "\n", "\"test\"", ":", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"hotel_location/hotel_Location_test.csv\"", ")", ",", "\n", "}", "\n", "\n", "return", "[", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "TRAIN", ",", "\n", "gen_kwargs", "=", "{", "\n", "\"filepath\"", ":", "filepaths", "[", "\"train\"", "]", ",", "\n", "\"split\"", ":", "\"train\"", ",", "\n", "}", ",", "\n", ")", ",", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "VALIDATION", ",", "\n", "gen_kwargs", "=", "{", "\n", "\"filepath\"", ":", "filepaths", "[", "\"dev\"", "]", ",", "\n", "\"split\"", ":", "\"dev\"", ",", "\n", "}", ",", "\n", ")", ",", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "TEST", ",", "\n", "gen_kwargs", "=", "{", "\"filepath\"", ":", "filepaths", "[", "\"test\"", "]", ",", "\"split\"", ":", "\"test\"", "}", ",", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.custom_hf_datasets.hotel_location_proc.HotelLocationDataset._generate_examples": [[130, 173], ["open", "enumerate", "csv.DictReader", "csv.DictReader", "numpy.array", "numpy.roll", "float", "len", "range", "annotations.append", "float", "int", "len", "annotations.append", "row[].split", "numpy.nonzero", "numpy.nonzero", "[].item", "[].item", "numpy.nonzero", "numpy.nonzero"], "methods", ["None"], ["", "def", "_generate_examples", "(", "self", ",", "filepath", ",", "split", ")", ":", "\n", "        ", "\"\"\"Yields examples.\"\"\"", "\n", "with", "open", "(", "filepath", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "            ", "if", "split", "==", "\"train\"", ":", "\n", "                ", "f", "=", "csv", ".", "DictReader", "(", "f", ",", "delimiter", "=", "\";\"", ")", "\n", "", "else", ":", "\n", "                ", "f", "=", "csv", ".", "DictReader", "(", "f", ",", "delimiter", "=", "\"\\t\"", ")", "\n", "", "for", "id_", ",", "row", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "annotations", "=", "[", "]", "\n", "if", "split", "==", "\"test\"", ":", "\n", "                    ", "tokens", "=", "row", "[", "\"text\"", "]", "\n", "scores", "=", "[", "float", "(", "row", "[", "\"label\"", "]", ")", "]", "\n", "raw_annotations", "=", "np", ".", "array", "(", "\n", "[", "int", "(", "s", ")", "for", "s", "in", "row", "[", "\"rationale\"", "]", ".", "split", "(", ")", "]", "\n", ")", "\n", "a1", "=", "raw_annotations", ">", "0", "\n", "a1_rshifted", "=", "np", ".", "roll", "(", "a1", ",", "1", ")", "\n", "starts", "=", "a1", "&", "~", "a1_rshifted", "\n", "ends", "=", "~", "a1", "&", "a1_rshifted", "\n", "if", "len", "(", "np", ".", "nonzero", "(", "starts", ")", "[", "0", "]", ")", ">", "0", ":", "\n", "                        ", "for", "i", "in", "range", "(", "len", "(", "np", ".", "nonzero", "(", "starts", ")", "[", "0", "]", ")", ")", ":", "\n", "                            ", "annotations", ".", "append", "(", "\n", "[", "\n", "np", ".", "nonzero", "(", "starts", ")", "[", "0", "]", "[", "i", "]", ".", "item", "(", ")", ",", "\n", "np", ".", "nonzero", "(", "ends", ")", "[", "0", "]", "[", "i", "]", ".", "item", "(", ")", ",", "\n", "]", "\n", ")", "\n", "", "", "else", ":", "\n", "                        ", "annotations", ".", "append", "(", "[", "]", ")", "\n", "\n", "", "yield", "id_", ",", "{", "\n", "\"tokens\"", ":", "tokens", ",", "\n", "\"scores\"", ":", "scores", ",", "\n", "\"annotations\"", ":", "[", "annotations", "]", ",", "\n", "}", "\n", "\n", "", "else", ":", "\n", "                    ", "tokens", "=", "row", "[", "\"text\"", "]", "\n", "scores", "=", "[", "float", "(", "row", "[", "\"label\"", "]", ")", "]", "\n", "yield", "id_", ",", "{", "\n", "\"tokens\"", ":", "tokens", ",", "\n", "\"scores\"", ":", "scores", ",", "\n", "\"annotations\"", ":", "[", "[", "[", "0", "]", "]", "]", ",", "# dummy value", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.custom_hf_datasets.beer.BeerAdvocateDatasetConfig.__init__": [[52, 60], ["datasets.BuilderConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["def", "__init__", "(", "self", ",", "aspect_subset", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            aspect_subset: the aspect subset (aspect0, aspect1, aspect2, 260k)\n            **kwargs: keyword arguments forwarded to super.\n        \"\"\"", "\n", "self", ".", "aspect_subset", "=", "aspect_subset", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.custom_hf_datasets.beer.BeerAdvocateDataset._info": [[77, 103], ["datasets.DatasetInfo", "datasets.Features", "datasets.Value", "datasets.features.Sequence", "datasets.features.Sequence", "datasets.Value", "datasets.features.Sequence", "datasets.features.Sequence", "datasets.Value"], "methods", ["None"], ["def", "_info", "(", "self", ")", ":", "\n", "        ", "return", "datasets", ".", "DatasetInfo", "(", "\n", "# This is the description that will appear on the datasets page.", "\n", "description", "=", "_DESCRIPTION", ",", "\n", "# This defines the different columns of the dataset and their types", "\n", "features", "=", "datasets", ".", "Features", "(", "\n", "{", "\n", "\"tokens\"", ":", "datasets", ".", "Value", "(", "\"string\"", ")", ",", "\n", "# we have five scores (one for each aspect) normalized between 0 and 1", "\n", "\"scores\"", ":", "datasets", ".", "features", ".", "Sequence", "(", "\n", "datasets", ".", "Value", "(", "\"float\"", ")", ",", "length", "=", "5", "\n", ")", ",", "\n", "\"annotations\"", ":", "datasets", ".", "features", ".", "Sequence", "(", "\n", "datasets", ".", "features", ".", "Sequence", "(", "\n", "datasets", ".", "features", ".", "Sequence", "(", "datasets", ".", "Value", "(", "\"int32\"", ")", ")", "\n", ")", "\n", ")", ",", "\n", "}", "\n", ")", ",", "\n", "# If there's a common (input, target) tuple from the features,", "\n", "# specify them here. They'll be used if as_supervised=True in", "\n", "# builder.as_dataset.", "\n", "supervised_keys", "=", "None", ",", "\n", "# Homepage of the dataset for documentation", "\n", "homepage", "=", "\"http://snap.stanford.edu/data/web-BeerAdvocate.html\"", ",", "\n", "citation", "=", "_CITATION", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.custom_hf_datasets.beer.BeerAdvocateDataset._split_generators": [[105, 148], ["dl_manager.download_and_extract", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "datasets.SplitGenerator", "datasets.SplitGenerator", "datasets.SplitGenerator"], "methods", ["None"], ["", "def", "_split_generators", "(", "self", ",", "dl_manager", ")", ":", "\n", "        ", "\"\"\"Returns SplitGenerators.\"\"\"", "\n", "\n", "# dl_manager is a datasets.download.DownloadManager that can be used to", "\n", "# download and extract URLs", "\n", "dl_dir", "=", "dl_manager", ".", "download_and_extract", "(", "_URL", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "dl_dir", ",", "\"beeradvocate\"", ")", "\n", "filepaths", "=", "{", "\n", "\"train\"", ":", "os", ".", "path", ".", "join", "(", "\n", "data_dir", ",", "\"reviews.{}.train.txt\"", ".", "format", "(", "self", ".", "config", ".", "aspect_subset", ")", "\n", ")", ",", "\n", "\"dev\"", ":", "os", ".", "path", ".", "join", "(", "\n", "data_dir", ",", "\"reviews.{}.heldout.txt\"", ".", "format", "(", "self", ".", "config", ".", "aspect_subset", ")", "\n", ")", ",", "\n", "\"test\"", ":", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"annotations.json\"", ")", ",", "\n", "}", "\n", "\n", "# using original files from Tao Lei's website:", "\n", "# dl_files = [", "\n", "#     dl_manager.download_and_extract(_ORIGINAL_URL_TRAIN.format(self.config.aspect_subset)),", "\n", "#     dl_manager.download_and_extract(_ORIGINAL_URL_DEV.format(self.config.aspect_subset)),", "\n", "#     dl_manager.download(_ORIGINAL_URL_TEST)", "\n", "# ]", "\n", "# filepaths = {\"train\": dl_files[0], \"dev\": dl_files[1], \"test\": dl_files[2]}", "\n", "\n", "return", "[", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "TRAIN", ",", "\n", "gen_kwargs", "=", "{", "\n", "\"filepath\"", ":", "filepaths", "[", "\"train\"", "]", ",", "\n", "\"split\"", ":", "\"train\"", ",", "\n", "}", ",", "\n", ")", ",", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "VALIDATION", ",", "\n", "gen_kwargs", "=", "{", "\n", "\"filepath\"", ":", "filepaths", "[", "\"dev\"", "]", ",", "\n", "\"split\"", ":", "\"dev\"", ",", "\n", "}", ",", "\n", ")", ",", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "TEST", ",", "\n", "gen_kwargs", "=", "{", "\"filepath\"", ":", "filepaths", "[", "\"test\"", "]", ",", "\"split\"", ":", "\"test\"", "}", ",", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.custom_hf_datasets.beer.BeerAdvocateDataset._generate_examples": [[151, 179], ["open", "enumerate", "json.loads", "row.split", "list", "map"], "methods", ["None"], ["", "def", "_generate_examples", "(", "self", ",", "filepath", ",", "split", ")", ":", "\n", "        ", "\"\"\"Yields examples.\"\"\"", "\n", "with", "open", "(", "filepath", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "            ", "for", "id_", ",", "row", "in", "enumerate", "(", "f", ")", ":", "\n", "                ", "if", "split", "==", "\"test\"", ":", "\n", "                    ", "data", "=", "json", ".", "loads", "(", "row", ")", "\n", "tokens", "=", "\" \"", ".", "join", "(", "data", "[", "\"x\"", "]", "[", ":", "256", "]", ")", "\n", "scores", "=", "data", "[", "\"y\"", "]", "\n", "annotations", "=", "[", "\n", "data", "[", "\"0\"", "]", ",", "\n", "data", "[", "\"1\"", "]", ",", "\n", "data", "[", "\"2\"", "]", ",", "\n", "data", "[", "\"3\"", "]", ",", "\n", "data", "[", "\"4\"", "]", ",", "\n", "]", "\n", "yield", "id_", ",", "{", "\n", "\"tokens\"", ":", "tokens", ",", "\n", "\"scores\"", ":", "scores", ",", "\n", "\"annotations\"", ":", "annotations", ",", "\n", "}", "\n", "", "else", ":", "\n", "                    ", "data", "=", "row", ".", "split", "(", ")", "\n", "tokens", "=", "\" \"", ".", "join", "(", "data", "[", "5", ":", "]", "[", ":", "256", "]", ")", "\n", "scores", "=", "list", "(", "map", "(", "float", ",", "data", "[", ":", "5", "]", ")", ")", "\n", "yield", "id_", ",", "{", "\n", "\"tokens\"", ":", "tokens", ",", "\n", "\"scores\"", ":", "scores", ",", "\n", "\"annotations\"", ":", "[", "[", "[", "0", "]", "]", "]", ",", "# dummy value", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.base.BaseDataModule.__init__": [[12, 24], ["pytorch_lightning.LightningDataModule.__init__"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["def", "__init__", "(", "self", ",", "d_params", ":", "dict", ")", ":", "\n", "        ", "\"\"\"\n        :param d_params: hyperparams dict.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# base hyperparams", "\n", "self", ".", "batch_size", "=", "2", "\n", "self", ".", "num_workers", "=", "0", "\n", "# base objects", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "label_encoder", "=", "None", "\n", "self", ".", "tokenizer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.base.BaseDataModule.load_encoders": [[25, 31], ["rationalizers.utils.load_object", "rationalizers.utils.load_object", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.load_object", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.load_object"], ["", "def", "load_encoders", "(", "self", ",", "root_dir", ",", "load_tokenizer", ",", "load_label_encoder", ")", ":", "\n", "        ", "if", "load_tokenizer", ":", "\n", "            ", "self", ".", "tokenizer", "=", "load_object", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"tokenizer.pickle\"", ")", ")", "\n", "", "if", "load_label_encoder", ":", "\n", "            ", "self", ".", "label_encoder", "=", "load_object", "(", "\n", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"label_encoder.pickle\"", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.base.BaseDataModule.save_encoders": [[33, 39], ["rationalizers.utils.save_object", "rationalizers.utils.save_object", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.save_object", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.save_object"], ["", "", "def", "save_encoders", "(", "self", ",", "root_dir", ",", "save_tokenizer", ",", "save_label_encoder", ")", ":", "\n", "        ", "if", "save_tokenizer", ":", "\n", "            ", "save_object", "(", "self", ".", "tokenizer", ",", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"tokenizer.pickle\"", ")", ")", "\n", "", "if", "save_label_encoder", ":", "\n", "            ", "save_object", "(", "\n", "self", ".", "label_encoder", ",", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"label_encoder.pickle\"", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.base.BaseDataModule._collate_fn": [[41, 43], ["None"], "methods", ["None"], ["", "", "def", "_collate_fn", "(", "self", ",", "samples", ":", "list", ",", "are_samples_batched", ":", "bool", "=", "False", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.base.BaseDataModule.train_dataloader": [[44, 53], ["torch.utils.data.RandomSampler", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "# use a standard random sampler:", "\n", "        ", "sampler", "=", "RandomSampler", "(", "self", ".", "dataset", "[", "\"train\"", "]", ")", "\n", "return", "DataLoader", "(", "\n", "self", ".", "dataset", "[", "\"train\"", "]", ",", "\n", "sampler", "=", "sampler", ",", "\n", "collate_fn", "=", "self", ".", "_collate_fn", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.base.BaseDataModule.val_dataloader": [[70, 78], ["torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "sampler", "=", "SequentialSampler", "(", "self", ".", "dataset", "[", "\"validation\"", "]", ")", "\n", "return", "DataLoader", "(", "\n", "self", ".", "dataset", "[", "\"validation\"", "]", ",", "\n", "sampler", "=", "sampler", ",", "\n", "collate_fn", "=", "self", ".", "_collate_fn", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.base.BaseDataModule.test_dataloader": [[80, 88], ["torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "sampler", "=", "SequentialSampler", "(", "self", ".", "dataset", "[", "\"test\"", "]", ")", "\n", "return", "DataLoader", "(", "\n", "self", ".", "dataset", "[", "\"test\"", "]", ",", "\n", "sampler", "=", "sampler", ",", "\n", "collate_fn", "=", "self", ".", "_collate_fn", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.sst.SSTDataModule.__init__": [[17, 69], ["rationalizers.data_modules.base.BaseDataModule.__init__", "d_params.get", "d_params.get", "d_params.get", "d_params.get", "d_params.get", "functools.partial", "functools.partial", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["from", "__future__", "import", "absolute_import", ",", "division", ",", "print_function", "\n", "\n", "import", "os", "\n", "from", "collections", "import", "OrderedDict", "\n", "\n", "import", "datasets", "\n", "from", "nltk", ".", "tree", "import", "Tree", "\n", "\n", "_CITATION", "=", "\"\"\"\\\n@inproceedings{socher2013recursive,\n  title={Recursive deep models for semantic compositionality over a sentiment treebank},\n  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason\n             and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},\n  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},\n  pages={1631--1642},\n  year={2013}\n}\n\"\"\"", "\n", "\n", "_DESCRIPTION", "=", "\"\"\"\\\nThis dataset consists of movie reviews from Stanford Sentiment Treebank.\n\"\"\"", "\n", "\n", "_URL", "=", "\"http://nlp.stanford.edu/sentiment/trainDevTestTrees_PTB.zip\"", "\n", "\n", "\n", "class", "SSTDatasetConfig", "(", "datasets", ".", "BuilderConfig", ")", ":", "\n", "    ", "\"\"\"BuilderConfig for BeerAdvocateDataset\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "granularity", ":", "str", "=", "\"2\"", ",", "subtrees", ":", "bool", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            granularity: The labeling granularity: `2`, `3` or `5`.\n            subtrees: Whether to include sentiment-tagged subphrases in addition to complete examples.\n            **kwargs: keyword arguments forwarded to super.\n        \"\"\"", "\n", "assert", "granularity", "in", "[", "\"2\"", ",", "\"3\"", ",", "\"5\"", "]", "\n", "self", ".", "granularity", "=", "granularity", "\n", "self", ".", "subtrees", "=", "subtrees", "\n", "self", ".", "granularity_map", "=", "OrderedDict", "(", "\n", "{", "\n", "\"0\"", ":", "\"very negative\"", ",", "\n", "\"1\"", ":", "\"negative\"", ",", "\n", "\"2\"", ":", "\"neutral\"", ",", "\n", "\"3\"", ":", "\"positive\"", ",", "\n", "\"4\"", ":", "\"very positive\"", ",", "\n", "None", ":", "None", ",", "\n", "}", "\n", ")", "\n", "self", ".", "names", "=", "list", "(", "self", ".", "granularity_map", ".", "values", "(", ")", ")", "[", ":", "-", "1", "]", "\n", "if", "granularity", "==", "\"2\"", ":", "\n", "            ", "self", ".", "granularity_map", "[", "\"0\"", "]", "=", "\"negative\"", "\n", "self", ".", "granularity_map", "[", "\"2\"", "]", "=", "None", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.sst.SSTDataModule._collate_fn": [[70, 104], ["torchnlp.utils.collate_tensors", "torchnlp.encoders.text.stack_and_pad_tensors", "isinstance", "torch.stack"], "methods", ["None"], ["self", ".", "granularity_map", "[", "\"4\"", "]", "=", "\"positive\"", "\n", "self", ".", "names", "=", "[", "\"negative\"", ",", "\"positive\"", "]", "\n", "", "elif", "granularity", "==", "\"3\"", ":", "\n", "            ", "self", ".", "granularity_map", "[", "\"0\"", "]", "=", "\"negative\"", "\n", "self", ".", "granularity_map", "[", "\"4\"", "]", "=", "\"positive\"", "\n", "self", ".", "names", "=", "[", "\"negative\"", ",", "\"neutral\"", ",", "\"positive\"", "]", "\n", "", "self", ".", "nb_classes", "=", "len", "(", "self", ".", "names", ")", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "\n", "", "", "class", "SSTDataset", "(", "datasets", ".", "GeneratorBasedBuilder", ")", ":", "\n", "    ", "\"\"\"Movie reviews from Stanford Sentiment Treebank.\"\"\"", "\n", "\n", "VERSION", "=", "datasets", ".", "Version", "(", "\"1.0.0\"", ")", "\n", "\n", "BUILDER_CONFIG_CLASS", "=", "SSTDatasetConfig", "\n", "BUILDER_CONFIGS", "=", "[", "\n", "SSTDatasetConfig", "(", "\n", "name", "=", "\"sst_dataset_{}_{}\"", ".", "format", "(", "granularity", ",", "subtrees", ")", ",", "\n", "description", "=", "\"Movie reviews from SST.\"", ",", "\n", "granularity", "=", "granularity", ",", "\n", "subtrees", "=", "subtrees", ",", "\n", ")", "\n", "for", "granularity", "in", "[", "\"2\"", ",", "\"3\"", ",", "\"5\"", "]", "\n", "for", "subtrees", "in", "[", "False", ",", "True", "]", "\n", "]", "\n", "\n", "def", "_info", "(", "self", ")", ":", "\n", "        ", "return", "datasets", ".", "DatasetInfo", "(", "\n", "# This is the description that will appear on the datasets page.", "\n", "description", "=", "_DESCRIPTION", ",", "\n", "# This defines the different columns of the dataset and their types", "\n", "features", "=", "datasets", ".", "Features", "(", "\n", "{", "\n", "\"tokens\"", ":", "datasets", ".", "Value", "(", "\"string\"", ")", ",", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.sst.SSTDataModule.prepare_data": [[105, 113], ["datasets.load_dataset"], "methods", ["None"], ["\"label\"", ":", "datasets", ".", "Value", "(", "\"string\"", ")", ",", "\n", "# map to integers using the order of self.config.names", "\n", "# \"label\": datasets.ClassLabel(self.config.nb_classes, names=self.config.names)", "\n", "}", "\n", ")", ",", "\n", "# If there's a common (input, target) tuple from the features,", "\n", "# specify them here. They'll be used if as_supervised=True in", "\n", "# builder.as_dataset.", "\n", "supervised_keys", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.sst.SSTDataModule.setup": [[115, 149], ["datasets.load_dataset", "len", "sst.SSTDataModule.dataset.map", "sst.SSTDataModule.dataset.set_format", "itertools.chain", "sst.SSTDataModule.tokenizer_cls", "itertools.chain", "sst.SSTDataModule.label_encoder_cls", "sst.SSTDataModule.tokenizer.encode", "sst.SSTDataModule.label_encoder.encode", "example[].strip"], "methods", ["None"], ["homepage", "=", "\"https://nlp.stanford.edu/sentiment/\"", ",", "\n", "citation", "=", "_CITATION", ",", "\n", ")", "\n", "\n", "", "def", "_split_generators", "(", "self", ",", "dl_manager", ")", ":", "\n", "        ", "\"\"\"Returns SplitGenerators.\"\"\"", "\n", "\n", "# dl_manager is a datasets.download.DownloadManager that can be used to", "\n", "# download and extract URLs", "\n", "data_dir", "=", "dl_manager", ".", "download_and_extract", "(", "_URL", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"trees/\"", ")", "\n", "filepaths", "=", "{", "\n", "\"train\"", ":", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train.txt\"", ")", ",", "\n", "\"dev\"", ":", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"dev.txt\"", ")", ",", "\n", "\"test\"", ":", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"test.txt\"", ")", ",", "\n", "}", "\n", "\n", "return", "[", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "TRAIN", ",", "\n", "gen_kwargs", "=", "{", "\n", "\"filepath\"", ":", "filepaths", "[", "\"train\"", "]", ",", "\n", "\"split\"", ":", "\"train\"", ",", "\n", "}", ",", "\n", ")", ",", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "VALIDATION", ",", "\n", "gen_kwargs", "=", "{", "\n", "\"filepath\"", ":", "filepaths", "[", "\"dev\"", "]", ",", "\n", "\"split\"", ":", "\"dev\"", ",", "\n", "}", ",", "\n", ")", ",", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "TEST", ",", "\n", "gen_kwargs", "=", "{", "\"filepath\"", ":", "filepaths", "[", "\"test\"", "]", ",", "\"split\"", ":", "\"test\"", "}", ",", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.imdb.ImdbDataModule.__init__": [[16, 54], ["rationalizers.data_modules.base.BaseDataModule.__init__", "d_params.get", "d_params.get", "d_params.get", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["def", "__init__", "(", "self", ",", "d_params", ":", "dict", ")", ":", "\n", "        ", "\"\"\"\n        :param d_params: hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "d_params", ")", "\n", "# hard-coded stuff", "\n", "self", ".", "path", "=", "\"imdb\"", "# hf_datasets will handle everything", "\n", "self", ".", "is_multilabel", "=", "True", "\n", "self", ".", "nb_classes", "=", "2", "# neg, pos", "\n", "\n", "# hyperparams", "\n", "self", ".", "batch_size", "=", "d_params", ".", "get", "(", "\"batch_size\"", ",", "64", ")", "\n", "self", ".", "num_workers", "=", "d_params", ".", "get", "(", "\"num_workers\"", ",", "0", ")", "\n", "self", ".", "vocab_min_occurrences", "=", "d_params", ".", "get", "(", "\"vocab_min_occurrences\"", ",", "1", ")", "\n", "\n", "# objects", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "label_encoder", "=", "None", "# no label encoder for this dataset", "\n", "self", ".", "tokenizer", "=", "None", "\n", "self", ".", "tokenizer_cls", "=", "partial", "(", "\n", "# WhitespaceEncoder,", "\n", "# TreebankEncoder,", "\n", "StaticTokenizerEncoder", ",", "\n", "tokenize", "=", "nltk", ".", "wordpunct_tokenize", ",", "\n", "min_occurrences", "=", "self", ".", "vocab_min_occurrences", ",", "\n", "reserved_tokens", "=", "[", "\n", "constants", ".", "PAD", ",", "\n", "constants", ".", "UNK", ",", "\n", "constants", ".", "EOS", ",", "\n", "constants", ".", "SOS", ",", "\n", "\"<copy>\"", ",", "\n", "]", ",", "\n", "padding_index", "=", "constants", ".", "PAD_ID", ",", "\n", "unknown_index", "=", "constants", ".", "UNK_ID", ",", "\n", "eos_index", "=", "constants", ".", "EOS_ID", ",", "\n", "sos_index", "=", "constants", ".", "SOS_ID", ",", "\n", "append_sos", "=", "False", ",", "\n", "append_eos", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.imdb.ImdbDataModule._collate_fn": [[56, 90], ["torchnlp.utils.collate_tensors", "torchnlp.encoders.text.stack_and_pad_tensors", "isinstance", "torch.stack"], "methods", ["None"], ["", "def", "_collate_fn", "(", "self", ",", "samples", ":", "list", ",", "are_samples_batched", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param samples: a list of dicts\n        :param are_samples_batched: in case a batch/bucket sampler are being used\n        :return: dict of features, label (Tensor)\n        \"\"\"", "\n", "if", "are_samples_batched", ":", "\n", "# dataloader batch size is 1 -> the sampler is responsible for batching", "\n", "            ", "samples", "=", "samples", "[", "0", "]", "\n", "\n", "# convert list of dicts to dict of lists", "\n", "", "collated_samples", "=", "collate_tensors", "(", "samples", ",", "stack_tensors", "=", "list", ")", "\n", "\n", "# pad and stack input ids", "\n", "input_ids", ",", "lengths", "=", "stack_and_pad_tensors", "(", "\n", "collated_samples", "[", "\"input_ids\"", "]", ",", "padding_index", "=", "self", ".", "tokenizer", ".", "padding_index", "\n", ")", "\n", "\n", "# stack labels", "\n", "labels", "=", "collated_samples", "[", "\"label\"", "]", "\n", "if", "isinstance", "(", "labels", ",", "list", ")", ":", "\n", "            ", "labels", "=", "torch", ".", "stack", "(", "labels", ",", "dim", "=", "0", ")", "\n", "\n", "# keep tokens in raw format", "\n", "", "tokens", "=", "collated_samples", "[", "\"text\"", "]", "\n", "\n", "# return batch to the data loader", "\n", "batch", "=", "{", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"lengths\"", ":", "lengths", ",", "\n", "\"tokens\"", ":", "tokens", ",", "\n", "\"labels\"", ":", "labels", ",", "\n", "}", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.imdb.ImdbDataModule.prepare_data": [[91, 96], ["datasets.load_dataset"], "methods", ["None"], ["", "def", "prepare_data", "(", "self", ")", ":", "\n", "# download data, prepare and store it (do not assign to self vars)", "\n", "        ", "_", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "self", ".", "path", ",", "\n", "save_infos", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.imdb.ImdbDataModule.setup": [[98, 130], ["datasets.load_dataset", "[].train_test_split", "imdb.ImdbDataModule.dataset.map", "imdb.ImdbDataModule.dataset.set_format", "itertools.chain", "imdb.ImdbDataModule.tokenizer_cls", "imdb.ImdbDataModule.tokenizer.encode", "example[].strip", "datasets.load_dataset"], "methods", ["None"], ["", "def", "setup", "(", "self", ",", "stage", ":", "str", "=", "None", ")", ":", "\n", "# Assign train/val/test datasets for use in dataloaders", "\n", "        ", "self", ".", "dataset", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "self", ".", "path", ",", "\n", ")", "\n", "\n", "modified_dataset", "=", "hf_datasets", ".", "load_dataset", "(", "\"imdb\"", ")", "[", "\"train\"", "]", ".", "train_test_split", "(", "\n", "test_size", "=", "0.1", "\n", ")", "\n", "\n", "self", ".", "dataset", "[", "\"train\"", "]", "=", "modified_dataset", "[", "\"train\"", "]", "\n", "self", ".", "dataset", "[", "\"validation\"", "]", "=", "modified_dataset", "[", "\"test\"", "]", "\n", "\n", "# build tokenize rand label encoder", "\n", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "# build tokenizer info (vocab + special tokens) based on train and validation set", "\n", "            ", "tok_samples", "=", "chain", "(", "\n", "self", ".", "dataset", "[", "\"train\"", "]", "[", "\"text\"", "]", ",", "\n", ")", "\n", "self", ".", "tokenizer", "=", "self", ".", "tokenizer_cls", "(", "tok_samples", ")", "\n", "\n", "# map strings to ids", "\n", "", "def", "_encode", "(", "example", ":", "dict", ")", ":", "\n", "            ", "example", "[", "\"input_ids\"", "]", "=", "self", ".", "tokenizer", ".", "encode", "(", "example", "[", "\"text\"", "]", ".", "strip", "(", ")", ")", "\n", "return", "example", "\n", "\n", "", "self", ".", "dataset", "=", "self", ".", "dataset", ".", "map", "(", "_encode", ")", "\n", "# convert `columns` to pytorch tensors and keep un-formatted columns", "\n", "self", ".", "dataset", ".", "set_format", "(", "\n", "type", "=", "\"torch\"", ",", "\n", "columns", "=", "[", "\"input_ids\"", ",", "\"label\"", "]", ",", "\n", "output_all_columns", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.snli.SNLIDataModule.__init__": [[16, 54], ["rationalizers.data_modules.base.BaseDataModule.__init__", "d_params.get", "d_params.get", "d_params.get", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["def", "__init__", "(", "self", ",", "d_params", ":", "dict", ")", ":", "\n", "        ", "\"\"\"\n        :param d_params: hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "d_params", ")", "\n", "# hard-coded stuff", "\n", "self", ".", "path", "=", "\"esnli\"", "# hf_datasets will handle everything", "\n", "self", ".", "is_multilabel", "=", "True", "\n", "self", ".", "nb_classes", "=", "3", "# entailment, neutral, contradiction", "\n", "\n", "# hyperparams", "\n", "self", ".", "batch_size", "=", "d_params", ".", "get", "(", "\"batch_size\"", ",", "64", ")", "\n", "self", ".", "num_workers", "=", "d_params", ".", "get", "(", "\"num_workers\"", ",", "0", ")", "\n", "self", ".", "vocab_min_occurrences", "=", "d_params", ".", "get", "(", "\"vocab_min_occurrences\"", ",", "1", ")", "\n", "\n", "# objects", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "label_encoder", "=", "None", "# no label encoder for this dataset", "\n", "self", ".", "tokenizer", "=", "None", "\n", "self", ".", "tokenizer_cls", "=", "partial", "(", "\n", "# WhitespaceEncoder,", "\n", "# TreebankEncoder,", "\n", "StaticTokenizerEncoder", ",", "\n", "tokenize", "=", "nltk", ".", "wordpunct_tokenize", ",", "\n", "min_occurrences", "=", "self", ".", "vocab_min_occurrences", ",", "\n", "reserved_tokens", "=", "[", "\n", "constants", ".", "PAD", ",", "\n", "constants", ".", "UNK", ",", "\n", "constants", ".", "EOS", ",", "\n", "constants", ".", "SOS", ",", "\n", "\"<copy>\"", ",", "\n", "]", ",", "\n", "padding_index", "=", "constants", ".", "PAD_ID", ",", "\n", "unknown_index", "=", "constants", ".", "UNK_ID", ",", "\n", "eos_index", "=", "constants", ".", "EOS_ID", ",", "\n", "sos_index", "=", "constants", ".", "SOS_ID", ",", "\n", "append_sos", "=", "False", ",", "\n", "append_eos", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.snli.SNLIDataModule._collate_fn": [[56, 97], ["torchnlp.utils.collate_tensors", "torchnlp.encoders.text.stack_and_pad_tensors", "torchnlp.encoders.text.stack_and_pad_tensors", "isinstance", "torch.stack"], "methods", ["None"], ["", "def", "_collate_fn", "(", "self", ",", "samples", ":", "list", ",", "are_samples_batched", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param samples: a list of dicts\n        :param are_samples_batched: in case a batch/bucket sampler are being used\n        :return: dict of features, label (Tensor)\n        \"\"\"", "\n", "if", "are_samples_batched", ":", "\n", "# dataloader batch size is 1 -> the sampler is responsible for batching", "\n", "            ", "samples", "=", "samples", "[", "0", "]", "\n", "\n", "# convert list of dicts to dict of lists", "\n", "", "collated_samples", "=", "collate_tensors", "(", "samples", ",", "stack_tensors", "=", "list", ")", "\n", "\n", "# pad and stack input ids", "\n", "x1_ids", ",", "x1_lengths", "=", "stack_and_pad_tensors", "(", "\n", "collated_samples", "[", "\"x1_ids\"", "]", ",", "padding_index", "=", "self", ".", "tokenizer", ".", "padding_index", "\n", ")", "\n", "x2_ids", ",", "x2_lengths", "=", "stack_and_pad_tensors", "(", "\n", "collated_samples", "[", "\"x2_ids\"", "]", ",", "padding_index", "=", "self", ".", "tokenizer", ".", "padding_index", "\n", ")", "\n", "\n", "# stack labels", "\n", "labels", "=", "collated_samples", "[", "\"label\"", "]", "\n", "if", "isinstance", "(", "labels", ",", "list", ")", ":", "\n", "            ", "labels", "=", "torch", ".", "stack", "(", "labels", ",", "dim", "=", "0", ")", "\n", "\n", "# keep tokens in raw format", "\n", "", "x1", "=", "collated_samples", "[", "\"premise\"", "]", "\n", "x2", "=", "collated_samples", "[", "\"hypothesis\"", "]", "\n", "\n", "# return batch to the data loader", "\n", "batch", "=", "{", "\n", "\"x1_ids\"", ":", "x1_ids", ",", "\n", "\"x2_ids\"", ":", "x2_ids", ",", "\n", "\"x1_lengths\"", ":", "x1_lengths", ",", "\n", "\"x2_lengths\"", ":", "x2_lengths", ",", "\n", "\"x1\"", ":", "x1", ",", "\n", "\"x2\"", ":", "x2", ",", "\n", "\"labels\"", ":", "labels", ",", "\n", "}", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.snli.SNLIDataModule.prepare_data": [[98, 104], ["datasets.load_dataset"], "methods", ["None"], ["", "def", "prepare_data", "(", "self", ")", ":", "\n", "# download data, prepare and store it (do not assign to self vars)", "\n", "        ", "_", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "self", ".", "path", ",", "\n", "download_mode", "=", "hf_datasets", ".", "GenerateMode", ".", "REUSE_DATASET_IF_EXISTS", ",", "\n", "save_infos", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.snli.SNLIDataModule.setup": [[106, 136], ["datasets.load_dataset", "snli.SNLIDataModule.dataset.map", "snli.SNLIDataModule.dataset.set_format", "itertools.chain", "snli.SNLIDataModule.tokenizer_cls", "snli.SNLIDataModule.tokenizer.encode", "snli.SNLIDataModule.tokenizer.encode", "example[].strip", "example[].strip"], "methods", ["None"], ["", "def", "setup", "(", "self", ",", "stage", ":", "str", "=", "None", ")", ":", "\n", "# Assign train/val/test datasets for use in dataloaders", "\n", "        ", "self", ".", "dataset", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "self", ".", "path", ",", "\n", "download_mode", "=", "hf_datasets", ".", "GenerateMode", ".", "REUSE_DATASET_IF_EXISTS", ",", "\n", ")", "\n", "\n", "# build tokenize rand label encoder", "\n", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "# build tokenizer info (vocab + special tokens) based on train and validation set", "\n", "            ", "tok_samples", "=", "chain", "(", "\n", "self", ".", "dataset", "[", "\"train\"", "]", "[", "\"premise\"", "]", ",", "\n", "self", ".", "dataset", "[", "\"train\"", "]", "[", "\"hypothesis\"", "]", ",", "\n", "self", ".", "dataset", "[", "\"validation\"", "]", "[", "\"premise\"", "]", ",", "\n", "self", ".", "dataset", "[", "\"validation\"", "]", "[", "\"hypothesis\"", "]", ",", "\n", ")", "\n", "self", ".", "tokenizer", "=", "self", ".", "tokenizer_cls", "(", "tok_samples", ")", "\n", "\n", "# map strings to ids", "\n", "", "def", "_encode", "(", "example", ":", "dict", ")", ":", "\n", "            ", "example", "[", "\"x1_ids\"", "]", "=", "self", ".", "tokenizer", ".", "encode", "(", "example", "[", "\"premise\"", "]", ".", "strip", "(", ")", ")", "\n", "example", "[", "\"x2_ids\"", "]", "=", "self", ".", "tokenizer", ".", "encode", "(", "example", "[", "\"hypothesis\"", "]", ".", "strip", "(", ")", ")", "\n", "return", "example", "\n", "\n", "", "self", ".", "dataset", "=", "self", ".", "dataset", ".", "map", "(", "_encode", ")", "\n", "# convert `columns` to pytorch tensors and keep un-formatted columns", "\n", "self", ".", "dataset", ".", "set_format", "(", "\n", "type", "=", "\"torch\"", ",", "\n", "columns", "=", "[", "\"x1_ids\"", ",", "\"x2_ids\"", ",", "\"label\"", "]", ",", "\n", "output_all_columns", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.hans.HANSDataModule.__init__": [[16, 56], ["rationalizers.data_modules.base.BaseDataModule.__init__", "d_params.get", "d_params.get", "d_params.get", "functools.partial", "d_params.get"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["def", "__init__", "(", "self", ",", "d_params", ":", "dict", ")", ":", "\n", "        ", "\"\"\"\n        :param d_params: hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "d_params", ")", "\n", "# hard-coded stuff", "\n", "self", ".", "path", "=", "\"hans\"", "# hf_datasets will handle everything", "\n", "self", ".", "is_multilabel", "=", "True", "\n", "self", ".", "nb_classes", "=", "2", "# entailment, neutral, contradiction", "\n", "\n", "# hyperparams", "\n", "self", ".", "batch_size", "=", "d_params", ".", "get", "(", "\"batch_size\"", ",", "64", ")", "\n", "self", ".", "num_workers", "=", "d_params", ".", "get", "(", "\"num_workers\"", ",", "0", ")", "\n", "self", ".", "vocab_min_occurrences", "=", "d_params", ".", "get", "(", "\"vocab_min_occurrences\"", ",", "1", ")", "\n", "\n", "# objects", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "label_encoder", "=", "None", "# no label encoder for this dataset", "\n", "self", ".", "tokenizer", "=", "None", "\n", "self", ".", "tokenizer_cls", "=", "partial", "(", "\n", "# WhitespaceEncoder,", "\n", "# TreebankEncoder,", "\n", "StaticTokenizerEncoder", ",", "\n", "tokenize", "=", "nltk", ".", "wordpunct_tokenize", ",", "\n", "min_occurrences", "=", "self", ".", "vocab_min_occurrences", ",", "\n", "reserved_tokens", "=", "[", "\n", "constants", ".", "PAD", ",", "\n", "constants", ".", "UNK", ",", "\n", "constants", ".", "EOS", ",", "\n", "constants", ".", "SOS", ",", "\n", "\"<copy>\"", ",", "\n", "]", ",", "\n", "padding_index", "=", "constants", ".", "PAD_ID", ",", "\n", "unknown_index", "=", "constants", ".", "UNK_ID", ",", "\n", "eos_index", "=", "constants", ".", "EOS_ID", ",", "\n", "sos_index", "=", "constants", ".", "SOS_ID", ",", "\n", "append_sos", "=", "False", ",", "\n", "append_eos", "=", "False", ",", "\n", ")", "\n", "self", ".", "version", "=", "d_params", ".", "get", "(", "\"version\"", ",", "\"vanilla\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.hans.HANSDataModule._collate_fn": [[57, 98], ["torchnlp.utils.collate_tensors", "torchnlp.encoders.text.stack_and_pad_tensors", "torchnlp.encoders.text.stack_and_pad_tensors", "isinstance", "torch.stack"], "methods", ["None"], ["", "def", "_collate_fn", "(", "self", ",", "samples", ":", "list", ",", "are_samples_batched", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param samples: a list of dicts\n        :param are_samples_batched: in case a batch/bucket sampler are being used\n        :return: dict of features, label (Tensor)\n        \"\"\"", "\n", "if", "are_samples_batched", ":", "\n", "# dataloader batch size is 1 -> the sampler is responsible for batching", "\n", "            ", "samples", "=", "samples", "[", "0", "]", "\n", "\n", "# convert list of dicts to dict of lists", "\n", "", "collated_samples", "=", "collate_tensors", "(", "samples", ",", "stack_tensors", "=", "list", ")", "\n", "\n", "# pad and stack input ids", "\n", "x1_ids", ",", "x1_lengths", "=", "stack_and_pad_tensors", "(", "\n", "collated_samples", "[", "\"x1_ids\"", "]", ",", "padding_index", "=", "self", ".", "tokenizer", ".", "padding_index", "\n", ")", "\n", "x2_ids", ",", "x2_lengths", "=", "stack_and_pad_tensors", "(", "\n", "collated_samples", "[", "\"x2_ids\"", "]", ",", "padding_index", "=", "self", ".", "tokenizer", ".", "padding_index", "\n", ")", "\n", "\n", "# stack labels", "\n", "labels", "=", "collated_samples", "[", "\"label\"", "]", "\n", "if", "isinstance", "(", "labels", ",", "list", ")", ":", "\n", "            ", "labels", "=", "torch", ".", "stack", "(", "labels", ",", "dim", "=", "0", ")", "\n", "\n", "# keep tokens in raw format", "\n", "", "x2", "=", "collated_samples", "[", "\"hypothesis\"", "]", "\n", "x1", "=", "collated_samples", "[", "\"premise\"", "]", "\n", "\n", "# return batch to the data loader", "\n", "batch", "=", "{", "\n", "\"x1_ids\"", ":", "x1_ids", ",", "\n", "\"x2_ids\"", ":", "x2_ids", ",", "\n", "\"x1_lengths\"", ":", "x1_lengths", ",", "\n", "\"x2_lengths\"", ":", "x2_lengths", ",", "\n", "\"x1\"", ":", "x1", ",", "\n", "\"x2\"", ":", "x2", ",", "\n", "\"labels\"", ":", "labels", ",", "\n", "}", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.hans.HANSDataModule.prepare_data": [[99, 115], ["datasets.load_dataset", "datasets.load_dataset", "datasets.load_dataset"], "methods", ["None"], ["", "def", "prepare_data", "(", "self", ")", ":", "\n", "# download data, prepare and store it (do not assign to self vars)", "\n", "        ", "_", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "self", ".", "path", ",", "\n", "download_mode", "=", "hf_datasets", ".", "GenerateMode", ".", "REUSE_DATASET_IF_EXISTS", ",", "\n", "save_infos", "=", "True", ",", "\n", ")", "\n", "_", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "\"esnli\"", ",", "\n", "download_mode", "=", "hf_datasets", ".", "GenerateMode", ".", "REUSE_DATASET_IF_EXISTS", ",", "\n", "save_infos", "=", "True", ",", "\n", ")", "\n", "_", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "\"multi_nli\"", ",", "\n", "download_mode", "=", "hf_datasets", ".", "GenerateMode", ".", "REUSE_DATASET_IF_EXISTS", ",", "\n", "save_infos", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.hans.HANSDataModule.setup": [[117, 180], ["datasets.load_dataset", "datasets.load_dataset", "hans.HANSDataModule.hans_dataset.map", "hans.HANSDataModule.dataset.map", "hans.HANSDataModule.dataset.set_format", "datasets.concatenate_datasets", "itertools.chain", "hans.HANSDataModule.tokenizer_cls", "hans.HANSDataModule.tokenizer.encode", "hans.HANSDataModule.tokenizer.encode", "example[].strip", "example[].strip", "hans.HANSDataModule.hans_dataset[].flatten_indices", "hans.HANSDataModule.multinli_dataset[].flatten_indices"], "methods", ["None"], ["", "def", "setup", "(", "self", ",", "stage", ":", "str", "=", "None", ")", ":", "\n", "# Assign train/val/test datasets for use in dataloaders", "\n", "        ", "self", ".", "hans_dataset", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "self", ".", "path", ",", "\n", ")", "\n", "\n", "self", ".", "hans_dataset", "[", "\"test\"", "]", "=", "self", ".", "hans_dataset", "[", "\"validation\"", "]", "\n", "\n", "self", ".", "multinli_dataset", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "\"multi_nli\"", ",", "\n", ")", "\n", "\n", "# TRAIN MLNI; VALIDATION: MNLI; TEST: HANS", "\n", "if", "self", ".", "version", "==", "\"vanilla\"", ":", "\n", "            ", "self", ".", "hans_dataset", "[", "\"train\"", "]", "=", "self", ".", "multinli_dataset", "[", "\"train\"", "]", "\n", "self", ".", "hans_dataset", "[", "\"validation\"", "]", "=", "self", ".", "multinli_dataset", "[", "\n", "\"validation_matched\"", "\n", "]", "\n", "", "else", ":", "\n", "# TRAIN MLNI + 30 000 SAMPLES HANS; VALIDATION: MNLI; TEST: HANS", "\n", "            ", "concat_data_train", "=", "hf_datasets", ".", "concatenate_datasets", "(", "\n", "[", "\n", "self", ".", "hans_dataset", "[", "\"train\"", "]", ".", "flatten_indices", "(", ")", ",", "\n", "self", ".", "multinli_dataset", "[", "\"train\"", "]", ".", "flatten_indices", "(", ")", ",", "\n", "]", "\n", ")", "\n", "self", ".", "hans_dataset", "[", "\"train\"", "]", "=", "concat_data_train", "\n", "self", ".", "hans_dataset", "[", "\"validation\"", "]", "=", "self", ".", "multinli_dataset", "[", "\n", "\"validation_matched\"", "\n", "]", "\n", "\n", "# change multinli labels to match hans labels", "\n", "", "def", "_collapselabels", "(", "example", ":", "dict", ")", ":", "\n", "            ", "if", "example", "[", "\"label\"", "]", "==", "2", ":", "\n", "                ", "example", "[", "\"label\"", "]", "=", "1", "\n", "", "return", "example", "\n", "\n", "", "self", ".", "dataset", "=", "self", ".", "hans_dataset", ".", "map", "(", "_collapselabels", ")", "\n", "\n", "# build tokenize rand label encoder", "\n", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "# build tokenizer info (vocab + special tokens) based on train and validation set", "\n", "            ", "tok_samples", "=", "chain", "(", "\n", "self", ".", "dataset", "[", "\"train\"", "]", "[", "\"premise\"", "]", ",", "\n", "self", ".", "dataset", "[", "\"train\"", "]", "[", "\"hypothesis\"", "]", ",", "\n", "self", ".", "dataset", "[", "\"validation\"", "]", "[", "\"premise\"", "]", ",", "\n", "self", ".", "dataset", "[", "\"validation\"", "]", "[", "\"hypothesis\"", "]", ",", "\n", ")", "\n", "self", ".", "tokenizer", "=", "self", ".", "tokenizer_cls", "(", "tok_samples", ")", "\n", "\n", "# map strings to ids", "\n", "", "def", "_encode", "(", "example", ":", "dict", ")", ":", "\n", "            ", "example", "[", "\"x2_ids\"", "]", "=", "self", ".", "tokenizer", ".", "encode", "(", "example", "[", "\"hypothesis\"", "]", ".", "strip", "(", ")", ")", "\n", "example", "[", "\"x1_ids\"", "]", "=", "self", ".", "tokenizer", ".", "encode", "(", "example", "[", "\"premise\"", "]", ".", "strip", "(", ")", ")", "\n", "return", "example", "\n", "\n", "", "self", ".", "dataset", "=", "self", ".", "dataset", ".", "map", "(", "_encode", ")", "\n", "\n", "# convert `columns` to pytorch tensors and keep un-formatted columns", "\n", "self", ".", "dataset", ".", "set_format", "(", "\n", "type", "=", "\"torch\"", ",", "\n", "columns", "=", "[", "\"x1_ids\"", ",", "\"x2_ids\"", ",", "\"label\"", "]", ",", "\n", "output_all_columns", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.beer.BeerDataModule.__init__": [[16, 60], ["rationalizers.data_modules.base.BaseDataModule.__init__", "d_params.get", "d_params.get", "d_params.get", "d_params.get", "d_params.get", "functools.partial", "int"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["\n", "from", "__future__", "import", "absolute_import", ",", "division", ",", "print_function", "\n", "\n", "import", "json", "\n", "import", "os", "\n", "import", "datasets", "\n", "\n", "_CITATION", "=", "\"\"\"\\\n@inproceedings{mcauley2012learning,\n  title={Learning attitudes and attributes from multi-aspect reviews},\n  author={McAuley, Julian and Leskovec, Jure and Jurafsky, Dan},\n  booktitle={2012 IEEE 12th International Conference on Data Mining},\n  pages={1020--1025},\n  year={2012},\n  organization={IEEE}\n}\n\"\"\"", "\n", "\n", "_DESCRIPTION", "=", "\"\"\"\\\nThis dataset consists of beer reviews from beeradvocate.\nThe data span a period of more than 10 years, including all ~1.5 million reviews up to November 2011.\nEach review includes ratings in terms of five \"aspects\": appearance, aroma, palate, taste, and overall impression.\nReviews include product and user information, followed by each of these five ratings, and a plaintext review.\n\"\"\"", "\n", "\n", "_URL", "=", "(", "\n", "\"https://ndownloader.figshare.com/files/24730187?private_link=bef748392370c9eb1e55\"", "\n", ")", "\n", "_ORIGINAL_URL_TRAIN", "=", "\"http://people.csail.mit.edu/taolei/beer/reviews.{}.train.txt.gz\"", "\n", "_ORIGINAL_URL_DEV", "=", "\"http://people.csail.mit.edu/taolei/beer/reviews.{}.heldout.txt.gz\"", "\n", "_ORIGINAL_URL_TEST", "=", "\"http://people.csail.mit.edu/taolei/beer/annotations.json\"", "\n", "\n", "\n", "class", "BeerAdvocateDatasetConfig", "(", "datasets", ".", "BuilderConfig", ")", ":", "\n", "    ", "\"\"\"BuilderConfig for BeerAdvocateDataset\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "aspect_subset", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            aspect_subset: the aspect subset (aspect0, aspect1, aspect2, 260k)\n            **kwargs: keyword arguments forwarded to super.\n        \"\"\"", "\n", "self", ".", "aspect_subset", "=", "aspect_subset", "\n", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.beer.BeerDataModule._collate_fn": [[62, 113], ["torchnlp.utils.collate_tensors", "torchnlp.encoders.text.stack_and_pad_tensors", "isinstance", "torch.stack", "scores[].unsqueeze.argmax", "scores[].unsqueeze"], "methods", ["None"], ["", "", "class", "BeerAdvocateDataset", "(", "datasets", ".", "GeneratorBasedBuilder", ")", ":", "\n", "    ", "\"\"\"Beer reviews from beeradvocate. Version preprocessed by McAuley et al. (2012).\"\"\"", "\n", "\n", "VERSION", "=", "datasets", ".", "Version", "(", "\"1.0.0\"", ")", "\n", "\n", "BUILDER_CONFIG_CLASS", "=", "BeerAdvocateDatasetConfig", "\n", "BUILDER_CONFIGS", "=", "[", "\n", "BeerAdvocateDatasetConfig", "(", "\n", "name", "=", "\"beer_advocate_dataset_\"", "+", "aspect_subset", ",", "\n", "description", "=", "\"Beer reviews from beeradvocate.\"", ",", "\n", "aspect_subset", "=", "aspect_subset", ",", "\n", ")", "\n", "for", "aspect_subset", "in", "[", "\"aspect0\"", ",", "\"aspect1\"", ",", "\"aspect2\"", ",", "\"260k\"", "]", "\n", "]", "\n", "\n", "def", "_info", "(", "self", ")", ":", "\n", "        ", "return", "datasets", ".", "DatasetInfo", "(", "\n", "# This is the description that will appear on the datasets page.", "\n", "description", "=", "_DESCRIPTION", ",", "\n", "# This defines the different columns of the dataset and their types", "\n", "features", "=", "datasets", ".", "Features", "(", "\n", "{", "\n", "\"tokens\"", ":", "datasets", ".", "Value", "(", "\"string\"", ")", ",", "\n", "# we have five scores (one for each aspect) normalized between 0 and 1", "\n", "\"scores\"", ":", "datasets", ".", "features", ".", "Sequence", "(", "\n", "datasets", ".", "Value", "(", "\"float\"", ")", ",", "length", "=", "5", "\n", ")", ",", "\n", "\"annotations\"", ":", "datasets", ".", "features", ".", "Sequence", "(", "\n", "datasets", ".", "features", ".", "Sequence", "(", "\n", "datasets", ".", "features", ".", "Sequence", "(", "datasets", ".", "Value", "(", "\"int32\"", ")", ")", "\n", ")", "\n", ")", ",", "\n", "}", "\n", ")", ",", "\n", "# If there's a common (input, target) tuple from the features,", "\n", "# specify them here. They'll be used if as_supervised=True in", "\n", "# builder.as_dataset.", "\n", "supervised_keys", "=", "None", ",", "\n", "# Homepage of the dataset for documentation", "\n", "homepage", "=", "\"http://snap.stanford.edu/data/web-BeerAdvocate.html\"", ",", "\n", "citation", "=", "_CITATION", ",", "\n", ")", "\n", "\n", "", "def", "_split_generators", "(", "self", ",", "dl_manager", ")", ":", "\n", "        ", "\"\"\"Returns SplitGenerators.\"\"\"", "\n", "\n", "# dl_manager is a datasets.download.DownloadManager that can be used to", "\n", "# download and extract URLs", "\n", "dl_dir", "=", "dl_manager", ".", "download_and_extract", "(", "_URL", ")", "\n", "data_dir", "=", "os", ".", "path", ".", "join", "(", "dl_dir", ",", "\"beeradvocate\"", ")", "\n", "filepaths", "=", "{", "\n", "\"train\"", ":", "os", ".", "path", ".", "join", "(", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.beer.BeerDataModule.prepare_data": [[114, 121], ["datasets.load_dataset"], "methods", ["None"], ["data_dir", ",", "\"reviews.{}.train.txt\"", ".", "format", "(", "self", ".", "config", ".", "aspect_subset", ")", "\n", ")", ",", "\n", "\"dev\"", ":", "os", ".", "path", ".", "join", "(", "\n", "data_dir", ",", "\"reviews.{}.heldout.txt\"", ".", "format", "(", "self", ".", "config", ".", "aspect_subset", ")", "\n", ")", ",", "\n", "\"test\"", ":", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"annotations.json\"", ")", ",", "\n", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.beer.BeerDataModule.setup": [[123, 146], ["datasets.load_dataset", "itertools.chain", "beer.BeerDataModule.tokenizer_cls", "beer.BeerDataModule.dataset.map", "beer.BeerDataModule.dataset.set_format", "beer.BeerDataModule.tokenizer.encode", "example[].strip"], "methods", ["None"], ["# dl_files = [", "\n", "#     dl_manager.download_and_extract(_ORIGINAL_URL_TRAIN.format(self.config.aspect_subset)),", "\n", "#     dl_manager.download_and_extract(_ORIGINAL_URL_DEV.format(self.config.aspect_subset)),", "\n", "#     dl_manager.download(_ORIGINAL_URL_TEST)", "\n", "# ]", "\n", "# filepaths = {\"train\": dl_files[0], \"dev\": dl_files[1], \"test\": dl_files[2]}", "\n", "\n", "return", "[", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "TRAIN", ",", "\n", "gen_kwargs", "=", "{", "\n", "\"filepath\"", ":", "filepaths", "[", "\"train\"", "]", ",", "\n", "\"split\"", ":", "\"train\"", ",", "\n", "}", ",", "\n", ")", ",", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "VALIDATION", ",", "\n", "gen_kwargs", "=", "{", "\n", "\"filepath\"", ":", "filepaths", "[", "\"dev\"", "]", ",", "\n", "\"split\"", ":", "\"dev\"", ",", "\n", "}", ",", "\n", ")", ",", "\n", "datasets", ".", "SplitGenerator", "(", "\n", "name", "=", "datasets", ".", "Split", ".", "TEST", ",", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.hotel_location.HotelLocationDataModule.__init__": [[16, 55], ["rationalizers.data_modules.base.BaseDataModule.__init__", "d_params.get", "d_params.get", "d_params.get", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["def", "__init__", "(", "self", ",", "d_params", ":", "dict", ")", ":", "\n", "        ", "\"\"\"\n        :param d_params: hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "d_params", ")", "\n", "# hard-coded stuff", "\n", "self", ".", "path", "=", "\"./rationalizers/custom_hf_datasets/hotel_location_proc.py\"", "\n", "\n", "# hyperparams", "\n", "self", ".", "batch_size", "=", "d_params", ".", "get", "(", "\"batch_size\"", ",", "32", ")", "\n", "self", ".", "num_workers", "=", "d_params", ".", "get", "(", "\"num_workers\"", ",", "0", ")", "\n", "self", ".", "vocab_min_occurrences", "=", "d_params", ".", "get", "(", "\"vocab_min_occurrences\"", ",", "1", ")", "\n", "self", ".", "is_multilabel", "=", "True", "\n", "\n", "# deal with single aspect experiments", "\n", "self", ".", "nb_classes", "=", "2", "\n", "\n", "# objects", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "tokenizer", "=", "None", "\n", "self", ".", "tokenizer_cls", "=", "partial", "(", "\n", "WhitespaceEncoder", ",", "# Beer dataset was already tokenized by Lei et al.", "\n", "min_occurrences", "=", "self", ".", "vocab_min_occurrences", ",", "\n", "reserved_tokens", "=", "[", "\n", "constants", ".", "PAD", ",", "\n", "constants", ".", "UNK", ",", "\n", "constants", ".", "EOS", ",", "\n", "constants", ".", "SOS", ",", "\n", "\"<copy>\"", ",", "\n", "]", ",", "\n", "padding_index", "=", "constants", ".", "PAD_ID", ",", "\n", "unknown_index", "=", "constants", ".", "UNK_ID", ",", "\n", "eos_index", "=", "constants", ".", "EOS_ID", ",", "\n", "sos_index", "=", "constants", ".", "SOS_ID", ",", "\n", "append_sos", "=", "False", ",", "\n", "append_eos", "=", "False", ",", "\n", ")", "\n", "self", ".", "label_encoder", "=", "(", "\n", "None", "# no need of label encoder -> predefined labels from self.dataset", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.hotel_location.HotelLocationDataModule._collate_fn": [[57, 94], ["torchnlp.utils.collate_tensors", "torchnlp.encoders.text.stack_and_pad_tensors", "isinstance", "torch.stack.long", "torch.stack"], "methods", ["None"], ["", "def", "_collate_fn", "(", "self", ",", "samples", ":", "list", ",", "are_samples_batched", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param samples: a list of dicts\n        :param are_samples_batched: in case a batch/bucket sampler are being used\n        :return: dict of features, label (Tensor)\n        \"\"\"", "\n", "if", "are_samples_batched", ":", "\n", "# dataloader batch size is 1 -> the sampler is responsible for batching", "\n", "            ", "samples", "=", "samples", "[", "0", "]", "\n", "\n", "# convert list of dicts to dict of lists", "\n", "", "collated_samples", "=", "collate_tensors", "(", "samples", ",", "stack_tensors", "=", "list", ")", "\n", "\n", "# pad and stack input ids", "\n", "input_ids", ",", "lengths", "=", "stack_and_pad_tensors", "(", "\n", "collated_samples", "[", "\"input_ids\"", "]", ",", "padding_index", "=", "self", ".", "tokenizer", ".", "padding_index", "\n", ")", "\n", "\n", "# stack scores", "\n", "scores", "=", "collated_samples", "[", "\"scores\"", "]", "\n", "if", "isinstance", "(", "scores", ",", "list", ")", ":", "\n", "            ", "scores", "=", "torch", ".", "stack", "(", "scores", ",", "dim", "=", "0", ")", "\n", "", "scores", "=", "scores", ".", "long", "(", ")", "\n", "\n", "# keep annotations and tokens in raw format", "\n", "annotations", "=", "collated_samples", "[", "\"annotations\"", "]", "\n", "tokens", "=", "collated_samples", "[", "\"tokens\"", "]", "\n", "\n", "# return batch to the data loaders", "\n", "batch", "=", "{", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"lengths\"", ":", "lengths", ",", "\n", "\"annotations\"", ":", "annotations", ",", "\n", "\"tokens\"", ":", "tokens", ",", "\n", "\"labels\"", ":", "scores", ",", "\n", "}", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.hotel_location.HotelLocationDataModule.prepare_data": [[95, 101], ["datasets.load_dataset"], "methods", ["None"], ["", "def", "prepare_data", "(", "self", ")", ":", "\n", "# download data, prepare and store it (do not assign to self vars)", "\n", "        ", "_", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "self", ".", "path", ",", "\n", "download_mode", "=", "hf_datasets", ".", "GenerateMode", ".", "REUSE_DATASET_IF_EXISTS", ",", "\n", "save_infos", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.hotel_location.HotelLocationDataModule.setup": [[103, 125], ["datasets.load_dataset", "itertools.chain", "hotel_location.HotelLocationDataModule.tokenizer_cls", "hotel_location.HotelLocationDataModule.dataset.map", "hotel_location.HotelLocationDataModule.dataset.set_format", "hotel_location.HotelLocationDataModule.tokenizer.encode", "example[].strip"], "methods", ["None"], ["", "def", "setup", "(", "self", ",", "stage", ":", "str", "=", "None", ")", ":", "\n", "# Assign train/val/test datasets for use in dataloaders", "\n", "        ", "self", ".", "dataset", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "self", ".", "path", ",", "\n", "download_mode", "=", "hf_datasets", ".", "GenerateMode", ".", "REUSE_DATASET_IF_EXISTS", ",", "\n", ")", "\n", "\n", "# build tokenizer info (vocab + special tokens) based on train and validation set", "\n", "tok_samples", "=", "chain", "(", "\n", "self", ".", "dataset", "[", "\"train\"", "]", "[", "\"tokens\"", "]", ",", "self", ".", "dataset", "[", "\"validation\"", "]", "[", "\"tokens\"", "]", "\n", ")", "\n", "self", ".", "tokenizer", "=", "self", ".", "tokenizer_cls", "(", "tok_samples", ")", "\n", "\n", "# map strings to ids", "\n", "def", "_encode", "(", "example", ":", "dict", ")", ":", "\n", "            ", "example", "[", "\"input_ids\"", "]", "=", "self", ".", "tokenizer", ".", "encode", "(", "example", "[", "\"tokens\"", "]", ".", "strip", "(", ")", ")", "\n", "return", "example", "\n", "\n", "", "self", ".", "dataset", "=", "self", ".", "dataset", ".", "map", "(", "_encode", ")", "\n", "# convert `columns` to pytorch tensors and keep un-formatted columns", "\n", "self", ".", "dataset", ".", "set_format", "(", "\n", "type", "=", "\"torch\"", ",", "columns", "=", "[", "\"input_ids\"", ",", "\"scores\"", "]", ",", "output_all_columns", "=", "True", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.multinli.MultiNLIDataModule.__init__": [[16, 54], ["rationalizers.data_modules.base.BaseDataModule.__init__", "d_params.get", "d_params.get", "d_params.get", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["def", "__init__", "(", "self", ",", "d_params", ":", "dict", ")", ":", "\n", "        ", "\"\"\"\n        :param d_params: hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "d_params", ")", "\n", "# hard-coded stuff", "\n", "self", ".", "path", "=", "\"multi_nli\"", "# hf_datasets will handle everything", "\n", "self", ".", "is_multilabel", "=", "True", "\n", "self", ".", "nb_classes", "=", "3", "# entailment, neutral, contradiction", "\n", "\n", "# hyperparams", "\n", "self", ".", "batch_size", "=", "d_params", ".", "get", "(", "\"batch_size\"", ",", "64", ")", "\n", "self", ".", "num_workers", "=", "d_params", ".", "get", "(", "\"num_workers\"", ",", "0", ")", "\n", "self", ".", "vocab_min_occurrences", "=", "d_params", ".", "get", "(", "\"vocab_min_occurrences\"", ",", "1", ")", "\n", "\n", "# objects", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "label_encoder", "=", "None", "# no label encoder for this dataset", "\n", "self", ".", "tokenizer", "=", "None", "\n", "self", ".", "tokenizer_cls", "=", "partial", "(", "\n", "# WhitespaceEncoder,", "\n", "# TreebankEncoder,", "\n", "StaticTokenizerEncoder", ",", "\n", "tokenize", "=", "nltk", ".", "wordpunct_tokenize", ",", "\n", "min_occurrences", "=", "self", ".", "vocab_min_occurrences", ",", "\n", "reserved_tokens", "=", "[", "\n", "constants", ".", "PAD", ",", "\n", "constants", ".", "UNK", ",", "\n", "constants", ".", "EOS", ",", "\n", "constants", ".", "SOS", ",", "\n", "\"<copy>\"", ",", "\n", "]", ",", "\n", "padding_index", "=", "constants", ".", "PAD_ID", ",", "\n", "unknown_index", "=", "constants", ".", "UNK_ID", ",", "\n", "eos_index", "=", "constants", ".", "EOS_ID", ",", "\n", "sos_index", "=", "constants", ".", "SOS_ID", ",", "\n", "append_sos", "=", "False", ",", "\n", "append_eos", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.multinli.MultiNLIDataModule._collate_fn": [[56, 97], ["torchnlp.utils.collate_tensors", "torchnlp.encoders.text.stack_and_pad_tensors", "torchnlp.encoders.text.stack_and_pad_tensors", "isinstance", "torch.stack"], "methods", ["None"], ["", "def", "_collate_fn", "(", "self", ",", "samples", ":", "list", ",", "are_samples_batched", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param samples: a list of dicts\n        :param are_samples_batched: in case a batch/bucket sampler are being used\n        :return: dict of features, label (Tensor)\n        \"\"\"", "\n", "if", "are_samples_batched", ":", "\n", "# dataloader batch size is 1 -> the sampler is responsible for batching", "\n", "            ", "samples", "=", "samples", "[", "0", "]", "\n", "\n", "# convert list of dicts to dict of lists", "\n", "", "collated_samples", "=", "collate_tensors", "(", "samples", ",", "stack_tensors", "=", "list", ")", "\n", "\n", "# pad and stack input ids", "\n", "x1_ids", ",", "x1_lengths", "=", "stack_and_pad_tensors", "(", "\n", "collated_samples", "[", "\"x1_ids\"", "]", ",", "padding_index", "=", "self", ".", "tokenizer", ".", "padding_index", "\n", ")", "\n", "x2_ids", ",", "x2_lengths", "=", "stack_and_pad_tensors", "(", "\n", "collated_samples", "[", "\"x2_ids\"", "]", ",", "padding_index", "=", "self", ".", "tokenizer", ".", "padding_index", "\n", ")", "\n", "\n", "# stack labels", "\n", "labels", "=", "collated_samples", "[", "\"label\"", "]", "\n", "if", "isinstance", "(", "labels", ",", "list", ")", ":", "\n", "            ", "labels", "=", "torch", ".", "stack", "(", "labels", ",", "dim", "=", "0", ")", "\n", "\n", "# keep tokens in raw format", "\n", "", "x1", "=", "collated_samples", "[", "\"premise\"", "]", "\n", "x2", "=", "collated_samples", "[", "\"hypothesis\"", "]", "\n", "\n", "# return batch to the data loader", "\n", "batch", "=", "{", "\n", "\"x1_ids\"", ":", "x1_ids", ",", "\n", "\"x2_ids\"", ":", "x2_ids", ",", "\n", "\"x1_lengths\"", ":", "x1_lengths", ",", "\n", "\"x2_lengths\"", ":", "x2_lengths", ",", "\n", "\"x1\"", ":", "x1", ",", "\n", "\"x2\"", ":", "x2", ",", "\n", "\"labels\"", ":", "labels", ",", "\n", "}", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.multinli.MultiNLIDataModule.prepare_data": [[98, 104], ["datasets.load_dataset"], "methods", ["None"], ["", "def", "prepare_data", "(", "self", ")", ":", "\n", "# download data, prepare and store it (do not assign to self vars)", "\n", "        ", "_", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "self", ".", "path", ",", "\n", "download_mode", "=", "hf_datasets", ".", "GenerateMode", ".", "REUSE_DATASET_IF_EXISTS", ",", "\n", "save_infos", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.multinli.MultiNLIDataModule.setup": [[106, 143], ["datasets.load_dataset", "multinli.MultiNLIDataModule.dataset[].train_test_split", "multinli.MultiNLIDataModule.dataset.map", "multinli.MultiNLIDataModule.dataset.set_format", "itertools.chain", "multinli.MultiNLIDataModule.tokenizer_cls", "multinli.MultiNLIDataModule.tokenizer.encode", "multinli.MultiNLIDataModule.tokenizer.encode", "example[].strip", "example[].strip"], "methods", ["None"], ["", "def", "setup", "(", "self", ",", "stage", ":", "str", "=", "None", ")", ":", "\n", "# Assign train/val/test datasets for use in dataloaders", "\n", "        ", "self", ".", "dataset", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "self", ".", "path", ",", "\n", "download_mode", "=", "hf_datasets", ".", "GenerateMode", ".", "REUSE_DATASET_IF_EXISTS", ",", "\n", ")", "\n", "\n", "modified_dataset", "=", "self", ".", "dataset", "[", "\"validation_matched\"", "]", ".", "train_test_split", "(", "\n", "test_size", "=", "0.5", "\n", ")", "\n", "\n", "self", ".", "dataset", "[", "\"validation\"", "]", "=", "modified_dataset", "[", "\"train\"", "]", "\n", "self", ".", "dataset", "[", "\"test\"", "]", "=", "modified_dataset", "[", "\"test\"", "]", "\n", "\n", "# build tokenize rand label encoder", "\n", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "# build tokenizer info (vocab + special tokens) based on train and validation set", "\n", "            ", "tok_samples", "=", "chain", "(", "\n", "self", ".", "dataset", "[", "\"train\"", "]", "[", "\"premise\"", "]", ",", "\n", "self", ".", "dataset", "[", "\"train\"", "]", "[", "\"hypothesis\"", "]", ",", "\n", "self", ".", "dataset", "[", "\"validation\"", "]", "[", "\"premise\"", "]", ",", "\n", "self", ".", "dataset", "[", "\"validation\"", "]", "[", "\"hypothesis\"", "]", ",", "\n", ")", "\n", "self", ".", "tokenizer", "=", "self", ".", "tokenizer_cls", "(", "tok_samples", ")", "\n", "\n", "# map strings to ids", "\n", "", "def", "_encode", "(", "example", ":", "dict", ")", ":", "\n", "            ", "example", "[", "\"x1_ids\"", "]", "=", "self", ".", "tokenizer", ".", "encode", "(", "example", "[", "\"premise\"", "]", ".", "strip", "(", ")", ")", "\n", "example", "[", "\"x2_ids\"", "]", "=", "self", ".", "tokenizer", ".", "encode", "(", "example", "[", "\"hypothesis\"", "]", ".", "strip", "(", ")", ")", "\n", "return", "example", "\n", "\n", "", "self", ".", "dataset", "=", "self", ".", "dataset", ".", "map", "(", "_encode", ")", "\n", "# convert `columns` to pytorch tensors and keep un-formatted columns", "\n", "self", ".", "dataset", ".", "set_format", "(", "\n", "type", "=", "\"torch\"", ",", "\n", "columns", "=", "[", "\"x1_ids\"", ",", "\"x2_ids\"", ",", "\"label\"", "]", ",", "\n", "output_all_columns", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.ag_news.AgNewsDataModule.__init__": [[16, 54], ["rationalizers.data_modules.base.BaseDataModule.__init__", "d_params.get", "d_params.get", "d_params.get", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["def", "__init__", "(", "self", ",", "d_params", ":", "dict", ")", ":", "\n", "        ", "\"\"\"\n        :param d_params: hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "d_params", ")", "\n", "# hard-coded stuff", "\n", "self", ".", "path", "=", "\"ag_news\"", "# hf_datasets will handle everything", "\n", "self", ".", "is_multilabel", "=", "True", "\n", "self", ".", "nb_classes", "=", "4", "# 0:\"World\" 1:\"Sports\" 2:\"Business\" 3:\"Sci/Tech\"", "\n", "\n", "# hyperparams", "\n", "self", ".", "batch_size", "=", "d_params", ".", "get", "(", "\"batch_size\"", ",", "64", ")", "\n", "self", ".", "num_workers", "=", "d_params", ".", "get", "(", "\"num_workers\"", ",", "0", ")", "\n", "self", ".", "vocab_min_occurrences", "=", "d_params", ".", "get", "(", "\"vocab_min_occurrences\"", ",", "1", ")", "\n", "\n", "# objects", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "label_encoder", "=", "None", "# no label encoder for this dataset", "\n", "self", ".", "tokenizer", "=", "None", "\n", "self", ".", "tokenizer_cls", "=", "partial", "(", "\n", "# WhitespaceEncoder,", "\n", "# TreebankEncoder,", "\n", "StaticTokenizerEncoder", ",", "\n", "tokenize", "=", "nltk", ".", "wordpunct_tokenize", ",", "\n", "min_occurrences", "=", "self", ".", "vocab_min_occurrences", ",", "\n", "reserved_tokens", "=", "[", "\n", "constants", ".", "PAD", ",", "\n", "constants", ".", "UNK", ",", "\n", "constants", ".", "EOS", ",", "\n", "constants", ".", "SOS", ",", "\n", "\"<copy>\"", ",", "\n", "]", ",", "\n", "padding_index", "=", "constants", ".", "PAD_ID", ",", "\n", "unknown_index", "=", "constants", ".", "UNK_ID", ",", "\n", "eos_index", "=", "constants", ".", "EOS_ID", ",", "\n", "sos_index", "=", "constants", ".", "SOS_ID", ",", "\n", "append_sos", "=", "False", ",", "\n", "append_eos", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.ag_news.AgNewsDataModule._collate_fn": [[56, 90], ["torchnlp.utils.collate_tensors", "torchnlp.encoders.text.stack_and_pad_tensors", "isinstance", "torch.stack"], "methods", ["None"], ["", "def", "_collate_fn", "(", "self", ",", "samples", ":", "list", ",", "are_samples_batched", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param samples: a list of dicts\n        :param are_samples_batched: in case a batch/bucket sampler are being used\n        :return: dict of features, label (Tensor)\n        \"\"\"", "\n", "if", "are_samples_batched", ":", "\n", "# dataloader batch size is 1 -> the sampler is responsible for batching", "\n", "            ", "samples", "=", "samples", "[", "0", "]", "\n", "\n", "# convert list of dicts to dict of lists", "\n", "", "collated_samples", "=", "collate_tensors", "(", "samples", ",", "stack_tensors", "=", "list", ")", "\n", "\n", "# pad and stack input ids", "\n", "input_ids", ",", "lengths", "=", "stack_and_pad_tensors", "(", "\n", "collated_samples", "[", "\"input_ids\"", "]", ",", "padding_index", "=", "self", ".", "tokenizer", ".", "padding_index", "\n", ")", "\n", "\n", "# stack labels", "\n", "labels", "=", "collated_samples", "[", "\"label\"", "]", "\n", "if", "isinstance", "(", "labels", ",", "list", ")", ":", "\n", "            ", "labels", "=", "torch", ".", "stack", "(", "labels", ",", "dim", "=", "0", ")", "\n", "\n", "# keep tokens in raw format", "\n", "", "tokens", "=", "collated_samples", "[", "\"text\"", "]", "\n", "\n", "# return batch to the data loader", "\n", "batch", "=", "{", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"lengths\"", ":", "lengths", ",", "\n", "\"tokens\"", ":", "tokens", ",", "\n", "\"labels\"", ":", "labels", ",", "\n", "}", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.ag_news.AgNewsDataModule.prepare_data": [[91, 97], ["datasets.load_dataset"], "methods", ["None"], ["", "def", "prepare_data", "(", "self", ")", ":", "\n", "# download data, prepare and store it (do not assign to self vars)", "\n", "        ", "_", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "self", ".", "path", ",", "\n", "download_mode", "=", "hf_datasets", ".", "GenerateMode", ".", "REUSE_DATASET_IF_EXISTS", ",", "\n", "save_infos", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.data_modules.ag_news.AgNewsDataModule.setup": [[99, 135], ["datasets.load_dataset", "datasets.load_dataset", "datasets.load_dataset", "ag_news.AgNewsDataModule.dataset.map", "ag_news.AgNewsDataModule.dataset.set_format", "itertools.chain", "ag_news.AgNewsDataModule.tokenizer_cls", "ag_news.AgNewsDataModule.tokenizer.encode", "example[].strip"], "methods", ["None"], ["", "def", "setup", "(", "self", ",", "stage", ":", "str", "=", "None", ")", ":", "\n", "# Assign train/val/test datasets for use in dataloaders", "\n", "        ", "self", ".", "dataset", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "self", ".", "path", ",", "\n", "download_mode", "=", "hf_datasets", ".", "GenerateMode", ".", "REUSE_DATASET_IF_EXISTS", ",", "\n", ")", "\n", "self", ".", "dataset", "[", "\"train\"", "]", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "self", ".", "path", ",", "\n", "download_mode", "=", "hf_datasets", ".", "GenerateMode", ".", "REUSE_DATASET_IF_EXISTS", ",", "\n", "split", "=", "\"train[:85%]\"", ",", "\n", ")", "\n", "self", ".", "dataset", "[", "\"validation\"", "]", "=", "hf_datasets", ".", "load_dataset", "(", "\n", "path", "=", "self", ".", "path", ",", "\n", "download_mode", "=", "hf_datasets", ".", "GenerateMode", ".", "REUSE_DATASET_IF_EXISTS", ",", "\n", "split", "=", "\"train[-15%:]\"", ",", "\n", ")", "\n", "\n", "# build tokenize rand label encoder", "\n", "if", "self", ".", "tokenizer", "is", "None", ":", "\n", "# build tokenizer info (vocab + special tokens) based on train and validation set", "\n", "            ", "tok_samples", "=", "chain", "(", "\n", "self", ".", "dataset", "[", "\"train\"", "]", "[", "\"text\"", "]", ",", "\n", ")", "\n", "self", ".", "tokenizer", "=", "self", ".", "tokenizer_cls", "(", "tok_samples", ")", "\n", "\n", "# map strings to ids", "\n", "", "def", "_encode", "(", "example", ":", "dict", ")", ":", "\n", "            ", "example", "[", "\"input_ids\"", "]", "=", "self", ".", "tokenizer", ".", "encode", "(", "example", "[", "\"text\"", "]", ".", "strip", "(", ")", ")", "\n", "return", "example", "\n", "\n", "", "self", ".", "dataset", "=", "self", ".", "dataset", ".", "map", "(", "_encode", ")", "\n", "# convert `columns` to pytorch tensors and keep un-formatted columns", "\n", "self", ".", "dataset", ".", "set_format", "(", "\n", "type", "=", "\"torch\"", ",", "\n", "columns", "=", "[", "\"input_ids\"", ",", "\"label\"", "]", ",", "\n", "output_all_columns", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.base_matching.BaseMatching.__init__": [[21, 80], ["pytorch_lightning.LightningModule.__init__", "h_params.get", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Recall", "pytorch_lightning.metrics.Recall", "pytorch_lightning.metrics.Recall", "criterion_cls", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "base_matching.BaseMatching.save_hyperparameters", "shell_logger.info", "h_params.get"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ":", "StaticTokenizerEncoder", ",", "\n", "nb_classes", ":", "int", ",", "\n", "is_multilabel", ":", "bool", ",", "\n", "h_params", ":", "dict", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param tokenizer (object): torchnlp tokenizer object\n        :param h_params (dict): hyperparams dict. See docs for more info.\n        :param nb_classes (int): number of classes used to create the last layer\n        :param multilabel (bool): whether the problem is multilabel or not (it depends on the dataset)\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# the tokenizer will be used to convert indices to strings", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "# to be used at the output layer", "\n", "self", ".", "nb_classes", "=", "nb_classes", "\n", "self", ".", "is_multilabel", "=", "is_multilabel", "\n", "self", ".", "dataset", "=", "h_params", ".", "get", "(", "\"dm\"", ",", "None", ")", "\n", "\n", "# define metrics", "\n", "self", ".", "train_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "val_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "test_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "train_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "average", "=", "\"macro\"", "\n", ")", "\n", "self", ".", "val_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "average", "=", "\"macro\"", "\n", ")", "\n", "self", ".", "test_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "average", "=", "\"macro\"", "\n", ")", "\n", "self", ".", "train_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "num_classes", "=", "nb_classes", ",", "average", "=", "\"macro\"", ")", "\n", "self", ".", "val_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "num_classes", "=", "nb_classes", ",", "average", "=", "\"macro\"", ")", "\n", "self", ".", "test_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "num_classes", "=", "nb_classes", ",", "average", "=", "\"macro\"", ")", "\n", "\n", "# define loss function", "\n", "criterion_cls", "=", "nn", ".", "MSELoss", "if", "not", "self", ".", "is_multilabel", "else", "nn", ".", "NLLLoss", "\n", "self", ".", "criterion", "=", "criterion_cls", "(", "reduction", "=", "\"none\"", ")", "\n", "\n", "# model arch:", "\n", "self", ".", "vocab_size", "=", "tokenizer", ".", "vocab_size", "\n", "self", ".", "emb_type", "=", "h_params", ".", "get", "(", "\"emb_type\"", ",", "\"random\"", ")", "\n", "self", ".", "emb_path", "=", "h_params", ".", "get", "(", "\"emb_path\"", ",", "None", ")", "\n", "self", ".", "emb_size", "=", "h_params", ".", "get", "(", "\"emb_size\"", ",", "300", ")", "\n", "self", ".", "emb_requires_grad", "=", "not", "h_params", ".", "get", "(", "\"embed_fixed\"", ",", "True", ")", "\n", "self", ".", "hidden_size", "=", "h_params", ".", "get", "(", "\"hidden_size\"", ",", "150", ")", "\n", "self", ".", "dropout", "=", "h_params", ".", "get", "(", "\"dropout\"", ",", "0.5", ")", "\n", "self", ".", "sentence_encoder_layer_type", "=", "h_params", ".", "get", "(", "\n", "\"sentence_encoder_layer_type\"", ",", "\"lstm\"", "\n", ")", "\n", "\n", "self", ".", "predicting", "=", "h_params", ".", "get", "(", "\"predicting\"", ",", "False", ")", "\n", "\n", "# save hyperparams to be accessed via self.hparams", "\n", "self", ".", "save_hyperparameters", "(", "h_params", ")", "\n", "shell_logger", ".", "info", "(", "h_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.base_matching.BaseMatching.forward": [[81, 100], ["base_matching.BaseMatching.matching_model"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "x1", ":", "torch", ".", "LongTensor", ",", "\n", "x2", ":", "torch", ".", "LongTensor", ",", "\n", "mask_x1", ":", "torch", ".", "BoolTensor", "=", "None", ",", "\n", "mask_x2", ":", "torch", ".", "BoolTensor", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Compute forward-pass.\n\n        :param x1: input x1 ids tensor. torch.LongTensor of shape [B, T]\n        :param x2: input x2 ids tensor. torch.LongTensor of shape [B, D]\n        :param mask_x1: mask tensor for padding positions for the x1ise. torch.BoolTensor of shape [B, T]\n        :param mask_x2: mask tensor for padding positions for the x2thesis. torch.BoolTensor of shape [B, D]\n\n        :return: the output from SentimentPredictor. Torch.Tensor of shape [B, C]\n        \"\"\"", "\n", "z", ",", "y_hat", "=", "self", ".", "matching_model", "(", "x1", ",", "x2", ",", "mask", "=", "[", "mask_x1", ",", "mask_x2", "]", ")", "\n", "return", "z", ",", "y_hat", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.base_matching.BaseMatching.training_step": [[101, 144], ["base_matching.BaseMatching.", "base_matching.BaseMatching.get_loss", "base_matching.BaseMatching.log", "base_matching.BaseMatching.logger.agg_and_log_metrics", "y_hat.view", "labels.view", "loss.item"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.get_loss"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Compute forward-pass, calculate loss and log metrics.\n\n        :param batch: The dict output from the data module with the following items:\n            `input_ids`: torch.LongTensor of shape [B, T],\n            `lengths`: torch.LongTensor of shape [B]\n            `labels`: torch.LongTensor of shape [B, C]\n            `tokens`: list of strings\n        :param batch_idx: integer displaying index of this batch\n        :return: pytorch_lightning.Result log object\n        \"\"\"", "\n", "prefix", "=", "\"train\"", "\n", "x1", "=", "batch", "[", "\"x1_ids\"", "]", "\n", "x2", "=", "batch", "[", "\"x2_ids\"", "]", "\n", "labels", "=", "batch", "[", "\"labels\"", "]", "\n", "mask_x1", "=", "x1", "!=", "constants", ".", "PAD_ID", "\n", "mask_x2", "=", "x2", "!=", "constants", ".", "PAD_ID", "\n", "\n", "# forward-pass", "\n", "z", ",", "y_hat", "=", "self", "(", "x1", ",", "x2", ",", "mask_x1", "=", "mask_x1", ",", "mask_x2", "=", "mask_x2", ")", "\n", "\n", "# compute loss", "\n", "y_hat", "=", "y_hat", "if", "not", "self", ".", "is_multilabel", "else", "y_hat", ".", "view", "(", "-", "1", ",", "self", ".", "nb_classes", ")", "\n", "y", "=", "labels", "if", "not", "self", ".", "is_multilabel", "else", "labels", ".", "view", "(", "-", "1", ")", "\n", "loss", ",", "loss_stats", "=", "self", ".", "get_loss", "(", "\n", "y_hat", ",", "y", ",", "prefix", "=", "prefix", ",", "mask_x1", "=", "mask_x1", ",", "mask_x2", "=", "mask_x2", "\n", ")", "\n", "\n", "# logger=False because they are going to be logged via loss_stats", "\n", "self", ".", "log", "(", "\n", "\"train_sum_loss\"", ",", "\n", "loss", ".", "item", "(", ")", ",", "\n", "prog_bar", "=", "True", ",", "\n", "logger", "=", "False", ",", "\n", "on_step", "=", "True", ",", "\n", "on_epoch", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "logger", ".", "agg_and_log_metrics", "(", "loss_stats", ",", "self", ".", "global_step", ")", "\n", "\n", "# return the loss tensor to PTL", "\n", "return", "{", "\"loss\"", ":", "loss", "}", "# \"ps\": loss_stats[prefix + \"_ps\"]}", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.base_matching.BaseMatching.validation_step": [[145, 148], ["base_matching.BaseMatching._shared_eval_step"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_step"], ["", "def", "validation_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ")", ":", "\n", "        ", "output", "=", "self", ".", "_shared_eval_step", "(", "batch", ",", "batch_idx", ",", "prefix", "=", "\"val\"", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.base_matching.BaseMatching.test_step": [[149, 152], ["base_matching.BaseMatching._shared_eval_step"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_step"], ["", "def", "test_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ")", ":", "\n", "        ", "output", "=", "self", ".", "_shared_eval_step", "(", "batch", ",", "batch_idx", ",", "prefix", "=", "\"test\"", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.base_matching.BaseMatching._shared_eval_step": [[153, 185], ["base_matching.BaseMatching.", "base_matching.BaseMatching.get_loss", "base_matching.BaseMatching.logger.log_metrics", "y_hat.view", "labels.view", "loss.item", "batch[].tolist"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.get_loss"], ["", "def", "_shared_eval_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ",", "prefix", ":", "str", ")", ":", "\n", "        ", "x1", "=", "batch", "[", "\"x1_ids\"", "]", "\n", "x2", "=", "batch", "[", "\"x2_ids\"", "]", "\n", "labels", "=", "batch", "[", "\"labels\"", "]", "\n", "mask_x1", "=", "x1", "!=", "constants", ".", "PAD_ID", "\n", "mask_x2", "=", "x2", "!=", "constants", ".", "PAD_ID", "\n", "\n", "# forward-pass", "\n", "z", ",", "y_hat", "=", "self", "(", "x1", ",", "x2", ",", "mask_x1", "=", "mask_x1", ",", "mask_x2", "=", "mask_x2", ")", "\n", "\n", "# compute loss", "\n", "y_hat", "=", "y_hat", "if", "not", "self", ".", "is_multilabel", "else", "y_hat", ".", "view", "(", "-", "1", ",", "self", ".", "nb_classes", ")", "\n", "y", "=", "labels", "if", "not", "self", ".", "is_multilabel", "else", "labels", ".", "view", "(", "-", "1", ")", "\n", "loss", ",", "loss_stats", "=", "self", ".", "get_loss", "(", "\n", "y_hat", ",", "y", ",", "prefix", "=", "prefix", ",", "mask_x1", "=", "mask_x1", ",", "mask_x2", "=", "mask_x2", "\n", ")", "\n", "\n", "metrics_to_wandb", "=", "{", "f\"{prefix}_loss\"", ":", "loss_stats", "[", "f\"{prefix}_criterion\"", "]", "}", "\n", "self", ".", "logger", ".", "log_metrics", "(", "metrics_to_wandb", ",", "self", ".", "global_step", ")", "\n", "\n", "# output to be stacked across iterations", "\n", "output", "=", "{", "\n", "f\"{prefix}_sum_loss\"", ":", "loss", ".", "item", "(", ")", ",", "\n", "f\"{prefix}_predictions\"", ":", "y_hat", ",", "\n", "f\"{prefix}_labels\"", ":", "batch", "[", "\"labels\"", "]", ".", "tolist", "(", ")", ",", "\n", "f\"{prefix}_tokens_x1\"", ":", "batch", "[", "\"x1\"", "]", ",", "\n", "f\"{prefix}_tokens_x2\"", ":", "batch", "[", "\"x2\"", "]", ",", "\n", "}", "\n", "if", "prefix", "==", "\"test\"", ":", "\n", "            ", "output", "[", "\"test_probs\"", "]", "=", "z", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.base_matching.BaseMatching.training_epoch_end": [[186, 193], ["print"], "methods", ["None"], ["", "def", "training_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", ":", "\n", "        ", "\"\"\"\n        PTL hook.\n\n        :param outputs: list of dicts representing the stacked outputs from training_step\n        \"\"\"", "\n", "print", "(", "\"\\nEpoch ended.\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.base_matching.BaseMatching.validation_epoch_end": [[194, 196], ["base_matching.BaseMatching._shared_eval_epoch_end"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_epoch_end"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", ":", "\n", "        ", "self", ".", "_shared_eval_epoch_end", "(", "outputs", ",", "prefix", "=", "\"val\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.base_matching.BaseMatching.test_epoch_end": [[197, 199], ["base_matching.BaseMatching._shared_eval_epoch_end"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_epoch_end"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", ":", "\n", "        ", "self", ".", "_shared_eval_epoch_end", "(", "outputs", ",", "prefix", "=", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.base_matching.BaseMatching._shared_eval_epoch_end": [[200, 304], ["shell_logger.info", "base_matching.BaseMatching.logger.agg_and_log_metrics", "base_matching.BaseMatching.log", "numpy.mean", "base_matching.BaseMatching.logger.log_metrics", "shell_logger.info", "shell_logger.info", "shell_logger.info", "shell_logger.info", "base_matching.BaseMatching.log", "outputs[].keys", "torch.argmax", "torch.tensor", "base_matching.BaseMatching.val_accuracy", "base_matching.BaseMatching.val_precision", "base_matching.BaseMatching.val_recall", "torch.argmax", "torch.tensor", "base_matching.BaseMatching.test_accuracy", "base_matching.BaseMatching.test_precision", "base_matching.BaseMatching.test_recall", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean"], ["", "def", "_shared_eval_epoch_end", "(", "self", ",", "outputs", ":", "list", ",", "prefix", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        PTL hook. Perform validation at the end of an epoch.\n\n        :param outputs: list of dicts representing the stacked outputs from validation_step\n        :param prefix: `val` or `test`\n        \"\"\"", "\n", "# assume that `outputs` is a list containing dicts with the same keys", "\n", "stacked_outputs", "=", "{", "k", ":", "[", "x", "[", "k", "]", "for", "x", "in", "outputs", "]", "for", "k", "in", "outputs", "[", "0", "]", ".", "keys", "(", ")", "}", "\n", "\n", "# average across batches", "\n", "avg_outputs", "=", "{", "\n", "f\"avg_{prefix}_sum_loss\"", ":", "np", ".", "mean", "(", "stacked_outputs", "[", "f\"{prefix}_sum_loss\"", "]", ")", ",", "\n", "# f\"avg_{prefix}_ps\": np.mean(stacked_outputs[f\"{prefix}_ps\"]),", "\n", "}", "\n", "shell_logger", ".", "info", "(", "\n", "f\"\\nAvg {prefix} sum loss: {avg_outputs[f'avg_{prefix}_sum_loss']:.4}\"", "\n", ")", "\n", "# shell_logger.info(f\"Avg {prefix} ps: {avg_outputs[f'avg_{prefix}_ps']:.4}\")", "\n", "\n", "dict_metrics", "=", "{", "f\"avg_{prefix}_sum_loss\"", ":", "avg_outputs", "[", "f\"avg_{prefix}_sum_loss\"", "]", "}", "\n", "self", ".", "logger", ".", "agg_and_log_metrics", "(", "dict_metrics", ",", "self", ".", "current_epoch", ")", "\n", "\n", "# log classification metrics", "\n", "if", "self", ".", "is_multilabel", ":", "\n", "            ", "if", "prefix", "==", "\"val\"", ":", "\n", "                ", "val_preds", "=", "torch", ".", "argmax", "(", "\n", "torch", ".", "cat", "(", "stacked_outputs", "[", "\"val_predictions\"", "]", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "val_labels", "=", "torch", ".", "tensor", "(", "\n", "[", "\n", "item", "\n", "for", "sublist", "in", "stacked_outputs", "[", "\"val_labels\"", "]", "\n", "for", "item", "in", "sublist", "\n", "]", ",", "\n", "device", "=", "val_preds", ".", "device", ",", "\n", ")", "\n", "accuracy", "=", "self", ".", "val_accuracy", "(", "val_preds", ",", "val_labels", ")", "\n", "precision", "=", "self", ".", "val_precision", "(", "val_preds", ",", "val_labels", ")", "\n", "recall", "=", "self", ".", "val_recall", "(", "val_preds", ",", "val_labels", ")", "\n", "f1_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "class_metrics", "=", "{", "\n", "f\"{prefix}_precision\"", ":", "precision", ",", "\n", "f\"{prefix}_recall\"", ":", "recall", ",", "\n", "f\"{prefix}_f1score\"", ":", "f1_score", ",", "\n", "f\"{prefix}_accuracy\"", ":", "accuracy", ",", "\n", "}", "\n", "\n", "", "else", ":", "\n", "                ", "test_preds", "=", "torch", ".", "argmax", "(", "\n", "torch", ".", "cat", "(", "stacked_outputs", "[", "\"test_predictions\"", "]", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "test_labels", "=", "torch", ".", "tensor", "(", "\n", "[", "\n", "item", "\n", "for", "sublist", "in", "stacked_outputs", "[", "\"test_labels\"", "]", "\n", "for", "item", "in", "sublist", "\n", "]", ",", "\n", "device", "=", "test_preds", ".", "device", ",", "\n", ")", "\n", "accuracy", "=", "self", ".", "test_accuracy", "(", "test_preds", ",", "test_labels", ")", "\n", "precision", "=", "self", ".", "test_precision", "(", "test_preds", ",", "test_labels", ")", "\n", "recall", "=", "self", ".", "test_recall", "(", "test_preds", ",", "test_labels", ")", "\n", "f1_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "class_metrics", "=", "{", "\n", "f\"{prefix}_precision\"", ":", "precision", ",", "\n", "f\"{prefix}_recall\"", ":", "recall", ",", "\n", "f\"{prefix}_f1score\"", ":", "f1_score", ",", "\n", "f\"{prefix}_accuracy\"", ":", "accuracy", ",", "\n", "}", "\n", "\n", "", "self", ".", "logger", ".", "log_metrics", "(", "class_metrics", ",", "step", "=", "None", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} accuracy: {accuracy:.4}\"", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} precision: {precision:.4}\"", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} recall: {recall:.4}\"", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} f1: {f1_score:.4}\"", ")", "\n", "\n", "self", ".", "log", "(", "\n", "f\"{prefix}_f1score\"", ",", "\n", "f1_score", ",", "\n", "prog_bar", "=", "False", ",", "\n", "logger", "=", "True", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "\n", ")", "\n", "\n", "", "self", ".", "log", "(", "\n", "f\"avg_{prefix}_sum_loss\"", ",", "\n", "dict_metrics", "[", "f\"avg_{prefix}_sum_loss\"", "]", ",", "\n", "prog_bar", "=", "False", ",", "\n", "logger", "=", "True", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "\n", ")", "\n", "\n", "output", "=", "{", "\n", "f\"avg_{prefix}_sum_loss\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_sum_loss\"", "]", ",", "\n", "f\"{prefix}_precision\"", ":", "precision", ",", "\n", "f\"{prefix}_recall\"", ":", "recall", ",", "\n", "f\"{prefix}_f1score\"", ":", "f1_score", ",", "\n", "f\"{prefix}_accuracy\"", ":", "accuracy", ",", "\n", "}", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.base_matching.BaseMatching.configure_optimizers": [[305, 314], ["rationalizers.builders.build_optimizer", "rationalizers.builders.build_scheduler", "base_matching.BaseMatching.parameters"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_optimizer", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_scheduler"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "\"\"\"Configure optimizers and lr schedulers for Trainer.\"\"\"", "\n", "optimizer", "=", "build_optimizer", "(", "self", ".", "parameters", "(", ")", ",", "self", ".", "hparams", ")", "\n", "scheduler", "=", "build_scheduler", "(", "optimizer", ",", "self", ".", "hparams", ")", "\n", "output", "=", "{", "\"optimizer\"", ":", "optimizer", "}", "\n", "if", "scheduler", "is", "not", "None", ":", "\n", "            ", "output", "[", "\"scheduler\"", "]", "=", "scheduler", "\n", "# output[\"monitor\"] = self.criterion  # not sure we need this", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.base_matching.BaseMatching.init_weights": [[315, 352], ["base_matching.BaseMatching.named_parameters", "torch.no_grad", "torch.nn.init._calculate_fan_in_and_fan_out", "torch.nn.init.uniform_", "name.startswith", "print", "math.sqrt", "math.sqrt", "print", "base_matching.BaseMatching.init_weights.xavier_uniform_n_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Model initialization.\n        \"\"\"", "\n", "\n", "def", "xavier_uniform_n_", "(", "w", ",", "gain", "=", "1.0", ",", "n", "=", "4", ")", ":", "\n", "            ", "\"\"\"\n            Xavier initializer for parameters that combine multiple matrices in one\n            parameter for efficiency. This is e.g. used for GRU and LSTM parameters,\n            where e.g. all gates are computed at the same time by 1 big matrix.\n            :param w:\n            :param gain:\n            :param n:\n            :return:\n            \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "fan_in", ",", "fan_out", "=", "_calculate_fan_in_and_fan_out", "(", "w", ")", "\n", "assert", "fan_out", "%", "n", "==", "0", ",", "\"fan_out should be divisible by n\"", "\n", "fan_out", "=", "fan_out", "//", "n", "\n", "std", "=", "gain", "*", "math", ".", "sqrt", "(", "2.0", "/", "(", "fan_in", "+", "fan_out", ")", ")", "\n", "a", "=", "math", ".", "sqrt", "(", "3.0", ")", "*", "std", "\n", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "w", ",", "-", "a", ",", "a", ")", "\n", "\n", "", "", "for", "name", ",", "p", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "name", ".", "startswith", "(", "\"emb\"", ")", "or", "\"lagrange\"", "in", "name", ":", "\n", "                ", "print", "(", "\"{:10s} {:20s} {}\"", ".", "format", "(", "\"unchanged\"", ",", "name", ",", "p", ".", "shape", ")", ")", "\n", "", "elif", "\"lstm\"", "in", "name", "and", "len", "(", "p", ".", "shape", ")", ">", "1", ":", "\n", "                ", "print", "(", "\"{:10s} {:20s} {}\"", ".", "format", "(", "\"xavier_n\"", ",", "name", ",", "p", ".", "shape", ")", ")", "\n", "xavier_uniform_n_", "(", "p", ")", "\n", "", "elif", "len", "(", "p", ".", "shape", ")", ">", "1", ":", "\n", "                ", "print", "(", "\"{:10s} {:20s} {}\"", ".", "format", "(", "\"xavier\"", ",", "name", ",", "p", ".", "shape", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "p", ")", "\n", "", "elif", "\"bias\"", "in", "name", ":", "\n", "                ", "print", "(", "\"{:10s} {:20s} {}\"", ".", "format", "(", "\"zeros\"", ",", "name", ",", "p", ".", "shape", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "constant_", "(", "p", ",", "0.0", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "\"{:10s} {:20s} {}\"", ".", "format", "(", "\"unchanged\"", ",", "name", ",", "p", ".", "shape", ")", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.esim_matching.ESIMMatching.__init__": [[14, 60], ["rationalizers.lightning_models.matchings.base_matching.BaseMatching.__init__", "esim_matching.ESIMMatching.save_hyperparameters", "h_params.get", "rationalizers.builders.build_embedding_weights", "torch.nn.Embedding", "rationalizers.modules.matchings.ESIMFaithfulMatching", "esim_matching.ESIMMatching.init_weights"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_embedding_weights", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SelfAdditiveScorer.init_weights"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ":", "StaticTokenizerEncoder", ",", "\n", "nb_classes", ":", "int", ",", "\n", "is_multilabel", ":", "bool", ",", "\n", "h_params", ":", "dict", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param tokenizer (object): torchnlp tokenizer object\n        :param nb_classes (int): number of classes used to create the last layer\n        :param multilabel (bool): whether the problem is multilabel or not (it depends on the dataset)\n        :param h_params (dict): hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "tokenizer", ",", "nb_classes", ",", "is_multilabel", ",", "h_params", ")", "\n", "\n", "# save hyperparams to checkpoint", "\n", "self", ".", "save_hyperparameters", "(", "h_params", ")", "\n", "self", ".", "temperature", "=", "h_params", ".", "get", "(", "\"temperature\"", ",", "1.0", ")", "\n", "\n", "# load word embedding weights based on `emb_type` and define the embedding layer", "\n", "embedding_weights", "=", "build_embedding_weights", "(", "\n", "self", ".", "tokenizer", ".", "vocab", ",", "self", ".", "emb_type", ",", "self", ".", "emb_path", ",", "self", ".", "emb_size", "\n", ")", "\n", "self", ".", "emb_layer", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "vocab_size", ",", "\n", "self", ".", "emb_size", ",", "\n", "padding_idx", "=", "constants", ".", "PAD_ID", ",", "\n", "_weight", "=", "embedding_weights", ",", "\n", ")", "\n", "self", ".", "emb_layer", ".", "weight", ".", "requires_grad", "=", "self", ".", "emb_requires_grad", "\n", "\n", "# create predictor", "\n", "nonlinearity_str", "=", "\"sigmoid\"", "if", "not", "self", ".", "is_multilabel", "else", "\"log_softmax\"", "\n", "\n", "self", ".", "matching_model", "=", "ESIMFaithfulMatching", "(", "\n", "temperature", "=", "self", ".", "temperature", ",", "\n", "embed", "=", "self", ".", "emb_layer", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ",", "\n", "output_size", "=", "self", ".", "nb_classes", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "layer", "=", "self", ".", "sentence_encoder_layer_type", ",", "\n", "nonlinearity", "=", "nonlinearity_str", ",", "\n", ")", "\n", "\n", "# initialize params using xavier initialization for weights and zero for biases", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.esim_matching.ESIMMatching.get_loss": [[61, 81], ["esim_matching.ESIMMatching.criterion", "loss_vec.mean.mean.mean", "loss_vec.mean.mean.item", "loss_vec.mean.mean.mean"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean"], ["", "def", "get_loss", "(", "self", ",", "y_hat", ",", "y", ",", "prefix", ",", "mask_x1", ",", "mask_x2", ")", ":", "\n", "        ", "\"\"\"\n        :param y_hat: predictions from SentimentPredictor. Torch.Tensor of shape [B, C]\n        :param y: tensor with gold labels. torch.BoolTensor of shape [B]\n        :param mask: mask tensor for padding positions. torch.BoolTensor of shape [B, T]\n        :return: tuple containing:\n            `loss cost (torch.FloatTensor)`: the result of the loss function\n            `loss stats (dict): dict with loss statistics\n        \"\"\"", "\n", "stats", "=", "{", "}", "\n", "loss_vec", "=", "self", ".", "criterion", "(", "y_hat", ",", "y", ")", "# [B] or [B,C]", "\n", "# main MSE loss for p(y | x,z)", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "loss_vec", "=", "loss_vec", ".", "mean", "(", "1", ")", "# [B,C] -> [B]", "\n", "", "loss", "=", "loss_vec", ".", "mean", "(", ")", "# [1]", "\n", "stats", "[", "prefix", "+", "\"_criterion\"", "]", "=", "loss", ".", "item", "(", ")", "# [1]", "\n", "\n", "# latent selection stats", "\n", "# num_0, num_c, num_1, total = get_z_matching_stats(self.generator.z, mask)", "\n", "return", "loss", ",", "stats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.gumbel_matching.GumbelMatching.__init__": [[14, 60], ["rationalizers.lightning_models.matchings.base_matching.BaseMatching.__init__", "gumbel_matching.GumbelMatching.save_hyperparameters", "h_params.get", "rationalizers.builders.build_embedding_weights", "torch.nn.Embedding", "rationalizers.modules.matchings.GumbelFaithfulMatching", "gumbel_matching.GumbelMatching.init_weights"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_embedding_weights", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SelfAdditiveScorer.init_weights"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ":", "StaticTokenizerEncoder", ",", "\n", "nb_classes", ":", "int", ",", "\n", "is_multilabel", ":", "bool", ",", "\n", "h_params", ":", "dict", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param tokenizer (object): torchnlp tokenizer object\n        :param nb_classes (int): number of classes used to create the last layer\n        :param multilabel (bool): whether the problem is multilabel or not (it depends on the dataset)\n        :param h_params (dict): hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "tokenizer", ",", "nb_classes", ",", "is_multilabel", ",", "h_params", ")", "\n", "\n", "# save hyperparams to checkpoint", "\n", "self", ".", "save_hyperparameters", "(", "h_params", ")", "\n", "self", ".", "temperature", "=", "h_params", ".", "get", "(", "\"temperature\"", ",", "1.0", ")", "\n", "\n", "# load word embedding weights based on `emb_type` and define the embedding layer", "\n", "embedding_weights", "=", "build_embedding_weights", "(", "\n", "self", ".", "tokenizer", ".", "vocab", ",", "self", ".", "emb_type", ",", "self", ".", "emb_path", ",", "self", ".", "emb_size", "\n", ")", "\n", "self", ".", "emb_layer", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "vocab_size", ",", "\n", "self", ".", "emb_size", ",", "\n", "padding_idx", "=", "constants", ".", "PAD_ID", ",", "\n", "_weight", "=", "embedding_weights", ",", "\n", ")", "\n", "self", ".", "emb_layer", ".", "weight", ".", "requires_grad", "=", "self", ".", "emb_requires_grad", "\n", "\n", "# create predictor", "\n", "nonlinearity_str", "=", "\"sigmoid\"", "if", "not", "self", ".", "is_multilabel", "else", "\"log_softmax\"", "\n", "\n", "self", ".", "matching_model", "=", "GumbelFaithfulMatching", "(", "\n", "temperature", "=", "self", ".", "temperature", ",", "\n", "embed", "=", "self", ".", "emb_layer", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ",", "\n", "output_size", "=", "self", ".", "nb_classes", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "layer", "=", "self", ".", "sentence_encoder_layer_type", ",", "\n", "nonlinearity", "=", "nonlinearity_str", ",", "\n", ")", "\n", "\n", "# initialize params using xavier initialization for weights and zero for biases", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.gumbel_matching.GumbelMatching.get_loss": [[61, 81], ["gumbel_matching.GumbelMatching.criterion", "loss_vec.mean.mean.mean", "loss_vec.mean.mean.item", "loss_vec.mean.mean.mean"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean"], ["", "def", "get_loss", "(", "self", ",", "y_hat", ",", "y", ",", "prefix", ",", "mask_x1", ",", "mask_x2", ")", ":", "\n", "        ", "\"\"\"\n        :param y_hat: predictions from SentimentPredictor. Torch.Tensor of shape [B, C]\n        :param y: tensor with gold labels. torch.BoolTensor of shape [B]\n        :param mask: mask tensor for padding positions. torch.BoolTensor of shape [B, T]\n        :return: tuple containing:\n            `loss cost (torch.FloatTensor)`: the result of the loss function\n            `loss stats (dict): dict with loss statistics\n        \"\"\"", "\n", "stats", "=", "{", "}", "\n", "loss_vec", "=", "self", ".", "criterion", "(", "y_hat", ",", "y", ")", "# [B] or [B,C]", "\n", "# main MSE loss for p(y | x,z)", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "loss_vec", "=", "loss_vec", ".", "mean", "(", "1", ")", "# [B,C] -> [B]", "\n", "", "loss", "=", "loss_vec", ".", "mean", "(", ")", "# [1]", "\n", "stats", "[", "prefix", "+", "\"_criterion\"", "]", "=", "loss", ".", "item", "(", ")", "# [1]", "\n", "\n", "# latent selection stats", "\n", "# num_0, num_c, num_1, total = get_z_matching_stats(self.generator.z, mask)", "\n", "return", "loss", ",", "stats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.sparsemap_matching.SparseMAPMatching.__init__": [[16, 83], ["rationalizers.lightning_models.matchings.base_matching.BaseMatching.__init__", "sparsemap_matching.SparseMAPMatching.save_hyperparameters", "h_params.get", "h_params.get", "h_params.get", "rationalizers.builders.build_embedding_weights", "torch.nn.Embedding", "rationalizers.modules.matchings.LPSparseMAPMatching", "sparsemap_matching.SparseMAPMatching.init_weights"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_embedding_weights", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SelfAdditiveScorer.init_weights"], ["def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ":", "StaticTokenizerEncoder", ",", "\n", "nb_classes", ":", "int", ",", "\n", "is_multilabel", ":", "bool", ",", "\n", "h_params", ":", "dict", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param tokenizer (object): torchnlp tokenizer object\n        :param nb_classes (int): number of classes used to create the last layer\n        :param multilabel (bool): whether the problem is multilabel or not (it depends on the dataset)\n        :param h_params (dict): hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "tokenizer", ",", "nb_classes", ",", "is_multilabel", ",", "h_params", ")", "\n", "\n", "# save hyperparams to checkpoint", "\n", "self", ".", "save_hyperparameters", "(", "h_params", ")", "\n", "self", ".", "temperature", "=", "h_params", ".", "get", "(", "\"temperature\"", ",", "1.0", ")", "\n", "self", ".", "matching_type", "=", "h_params", ".", "get", "(", "\"matching_type\"", ",", "\"AtMostONE\"", ")", "\n", "self", ".", "budget", "=", "h_params", ".", "get", "(", "\"budget\"", ",", "1.0", ")", "\n", "\n", "# load word embedding weights based on `emb_type` and define the embedding layer", "\n", "embedding_weights", "=", "build_embedding_weights", "(", "\n", "self", ".", "tokenizer", ".", "vocab", ",", "self", ".", "emb_type", ",", "self", ".", "emb_path", ",", "self", ".", "emb_size", "\n", ")", "\n", "self", ".", "emb_layer", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "vocab_size", ",", "\n", "self", ".", "emb_size", ",", "\n", "padding_idx", "=", "constants", ".", "PAD_ID", ",", "\n", "_weight", "=", "embedding_weights", ",", "\n", ")", "\n", "self", ".", "emb_layer", ".", "weight", ".", "requires_grad", "=", "self", ".", "emb_requires_grad", "\n", "\n", "# create generator", "\n", "# self.generator = SparsemapMatching(", "\n", "#     embed=self.emb_layer,", "\n", "#     hidden_size=self.hidden_size,", "\n", "#     dropout=self.dropout,", "\n", "#     layer=self.sentence_encoder_layer_type,", "\n", "#     temperature=self.temperature,", "\n", "# )", "\n", "\n", "# create predictor", "\n", "nonlinearity_str", "=", "\"sigmoid\"", "if", "not", "self", ".", "is_multilabel", "else", "\"log_softmax\"", "\n", "# self.predictor = MatchingPredictor(", "\n", "#     embed=self.emb_layer,", "\n", "#     hidden_size=self.hidden_size,", "\n", "#     output_size=self.nb_classes,", "\n", "#     dropout=self.dropout,", "\n", "#     layer=self.sentence_encoder_layer_type,", "\n", "#     nonlinearity=nonlinearity_str,", "\n", "# )", "\n", "\n", "self", ".", "matching_model", "=", "LPSparseMAPMatching", "(", "\n", "temperature", "=", "self", ".", "temperature", ",", "\n", "embed", "=", "self", ".", "emb_layer", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ",", "\n", "output_size", "=", "self", ".", "nb_classes", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "layer", "=", "self", ".", "sentence_encoder_layer_type", ",", "\n", "nonlinearity", "=", "nonlinearity_str", ",", "\n", "matching_type", "=", "self", ".", "matching_type", ",", "\n", "budget", "=", "self", ".", "budget", ",", "\n", ")", "\n", "\n", "# initialize params using xavier initialization for weights and zero for biases", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.sparsemap_matching.SparseMAPMatching.get_loss": [[84, 104], ["sparsemap_matching.SparseMAPMatching.criterion", "loss_vec.mean.mean.mean", "loss_vec.mean.mean.item", "loss_vec.mean.mean.mean"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean"], ["", "def", "get_loss", "(", "self", ",", "y_hat", ",", "y", ",", "prefix", ",", "mask_x1", ",", "mask_x2", ")", ":", "\n", "        ", "\"\"\"\n        :param y_hat: predictions from SentimentPredictor. Torch.Tensor of shape [B, C]\n        :param y: tensor with gold labels. torch.BoolTensor of shape [B]\n        :param mask: mask tensor for padding positions. torch.BoolTensor of shape [B, T]\n        :return: tuple containing:\n            `loss cost (torch.FloatTensor)`: the result of the loss function\n            `loss stats (dict): dict with loss statistics\n        \"\"\"", "\n", "stats", "=", "{", "}", "\n", "loss_vec", "=", "self", ".", "criterion", "(", "y_hat", ",", "y", ")", "# [B] or [B,C]", "\n", "# main MSE loss for p(y | x,z)", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "loss_vec", "=", "loss_vec", ".", "mean", "(", "1", ")", "# [B,C] -> [B]", "\n", "", "loss", "=", "loss_vec", ".", "mean", "(", ")", "# [1]", "\n", "stats", "[", "prefix", "+", "\"_criterion\"", "]", "=", "loss", ".", "item", "(", ")", "# [1]", "\n", "\n", "# latent selection stats", "\n", "# num_0, num_c, num_1, total = get_z_matching_stats(self.generator.z, mask)", "\n", "return", "loss", ",", "stats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.faithful_sparsemap_matching.SparseMAPFaithfulMatching.__init__": [[16, 85], ["rationalizers.lightning_models.matchings.base_matching.BaseMatching.__init__", "faithful_sparsemap_matching.SparseMAPFaithfulMatching.save_hyperparameters", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "rationalizers.builders.build_embedding_weights", "torch.nn.Embedding", "rationalizers.modules.matchings.LPSparseMAPFaithfulMatching", "faithful_sparsemap_matching.SparseMAPFaithfulMatching.init_weights"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_embedding_weights", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SelfAdditiveScorer.init_weights"], ["def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ":", "StaticTokenizerEncoder", ",", "\n", "nb_classes", ":", "int", ",", "\n", "is_multilabel", ":", "bool", ",", "\n", "h_params", ":", "dict", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param tokenizer (object): torchnlp tokenizer object\n        :param nb_classes (int): number of classes used to create the last layer\n        :param multilabel (bool): whether the problem is multilabel or not (it depends on the dataset)\n        :param h_params (dict): hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "tokenizer", ",", "nb_classes", ",", "is_multilabel", ",", "h_params", ")", "\n", "\n", "# save hyperparams to checkpoint", "\n", "self", ".", "save_hyperparameters", "(", "h_params", ")", "\n", "self", ".", "temperature", "=", "h_params", ".", "get", "(", "\"temperature\"", ",", "1.0", ")", "\n", "self", ".", "matching_type", "=", "h_params", ".", "get", "(", "\"matching_type\"", ",", "\"AtMostONE\"", ")", "\n", "self", ".", "budget", "=", "h_params", ".", "get", "(", "\"budget\"", ",", "1.0", ")", "\n", "self", ".", "faithful", "=", "h_params", ".", "get", "(", "\"faithful\"", ",", "True", ")", "\n", "\n", "# load word embedding weights based on `emb_type` and define the embedding layer", "\n", "embedding_weights", "=", "build_embedding_weights", "(", "\n", "self", ".", "tokenizer", ".", "vocab", ",", "self", ".", "emb_type", ",", "self", ".", "emb_path", ",", "self", ".", "emb_size", "\n", ")", "\n", "self", ".", "emb_layer", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "vocab_size", ",", "\n", "self", ".", "emb_size", ",", "\n", "padding_idx", "=", "constants", ".", "PAD_ID", ",", "\n", "_weight", "=", "embedding_weights", ",", "\n", ")", "\n", "self", ".", "emb_layer", ".", "weight", ".", "requires_grad", "=", "self", ".", "emb_requires_grad", "\n", "\n", "# create generator", "\n", "# self.generator = SparsemapMatching(", "\n", "#     embed=self.emb_layer,", "\n", "#     hidden_size=self.hidden_size,", "\n", "#     dropout=self.dropout,", "\n", "#     layer=self.sentence_encoder_layer_type,", "\n", "#     temperature=self.temperature,", "\n", "# )", "\n", "\n", "# create predictor", "\n", "nonlinearity_str", "=", "\"sigmoid\"", "if", "not", "self", ".", "is_multilabel", "else", "\"log_softmax\"", "\n", "# self.predictor = MatchingPredictor(", "\n", "#     embed=self.emb_layer,", "\n", "#     hidden_size=self.hidden_size,", "\n", "#     output_size=self.nb_classes,", "\n", "#     dropout=self.dropout,", "\n", "#     layer=self.sentence_encoder_layer_type,", "\n", "#     nonlinearity=nonlinearity_str,", "\n", "# )", "\n", "\n", "self", ".", "matching_model", "=", "LPSparseMAPFaithfulMatching", "(", "\n", "temperature", "=", "self", ".", "temperature", ",", "\n", "embed", "=", "self", ".", "emb_layer", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ",", "\n", "output_size", "=", "self", ".", "nb_classes", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "layer", "=", "self", ".", "sentence_encoder_layer_type", ",", "\n", "nonlinearity", "=", "nonlinearity_str", ",", "\n", "matching_type", "=", "self", ".", "matching_type", ",", "\n", "budget", "=", "self", ".", "budget", ",", "\n", "faithful", "=", "self", ".", "faithful", ",", "\n", ")", "\n", "\n", "# initialize params using xavier initialization for weights and zero for biases", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.matchings.faithful_sparsemap_matching.SparseMAPFaithfulMatching.get_loss": [[86, 106], ["faithful_sparsemap_matching.SparseMAPFaithfulMatching.criterion", "loss_vec.mean.mean.mean", "loss_vec.mean.mean.item", "loss_vec.mean.mean.mean"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean"], ["", "def", "get_loss", "(", "self", ",", "y_hat", ",", "y", ",", "prefix", ",", "mask_x1", ",", "mask_x2", ")", ":", "\n", "        ", "\"\"\"\n        :param y_hat: predictions from SentimentPredictor. Torch.Tensor of shape [B, C]\n        :param y: tensor with gold labels. torch.BoolTensor of shape [B]\n        :param mask: mask tensor for padding positions. torch.BoolTensor of shape [B, T]\n        :return: tuple containing:\n            `loss cost (torch.FloatTensor)`: the result of the loss function\n            `loss stats (dict): dict with loss statistics\n        \"\"\"", "\n", "stats", "=", "{", "}", "\n", "loss_vec", "=", "self", ".", "criterion", "(", "y_hat", ",", "y", ")", "# [B] or [B,C]", "\n", "# main MSE loss for p(y | x,z)", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "loss_vec", "=", "loss_vec", ".", "mean", "(", "1", ")", "# [B,C] -> [B]", "\n", "", "loss", "=", "loss_vec", ".", "mean", "(", ")", "# [1]", "\n", "stats", "[", "prefix", "+", "\"_criterion\"", "]", "=", "loss", ".", "item", "(", ")", "# [1]", "\n", "\n", "# latent selection stats", "\n", "# num_0, num_c, num_1, total = get_z_matching_stats(self.generator.z, mask)", "\n", "return", "loss", ",", "stats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.sparsemax.SparsemaxRationalizer.__init__": [[19, 76], ["rationalizers.lightning_models.highlights.base.BaseRationalizer.__init__", "sparsemax.SparsemaxRationalizer.save_hyperparameters", "h_params.get", "rationalizers.builders.build_embedding_weights", "torch.nn.Embedding", "rationalizers.modules.generators.SparsemaxGenerator", "rationalizers.modules.predictors.SentimentPredictor", "criterion_cls", "sparsemax.SparsemaxRationalizer.init_weights"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_embedding_weights", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SelfAdditiveScorer.init_weights"], ["def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ":", "StaticTokenizerEncoder", ",", "\n", "nb_classes", ":", "int", ",", "\n", "is_multilabel", ":", "bool", ",", "\n", "h_params", ":", "dict", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param tokenizer (object): torchnlp tokenizer object\n        :param nb_classes (int): number of classes used to create the last layer\n        :param multilabel (bool): whether the problem is multilabel or not (it depends on the dataset)\n        :param h_params (dict): hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "tokenizer", ",", "nb_classes", ",", "is_multilabel", ",", "h_params", ")", "\n", "\n", "# save hyperparams to checkpoint", "\n", "self", ".", "save_hyperparameters", "(", "h_params", ")", "\n", "self", ".", "temperature", "=", "h_params", ".", "get", "(", "\"temperature\"", ",", "1.0", ")", "\n", "\n", "# load word embedding weights based on `emb_type` and define the embedding layer", "\n", "embedding_weights", "=", "build_embedding_weights", "(", "\n", "self", ".", "tokenizer", ".", "vocab", ",", "self", ".", "emb_type", ",", "self", ".", "emb_path", ",", "self", ".", "emb_size", "\n", ")", "\n", "self", ".", "emb_layer", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "vocab_size", ",", "\n", "self", ".", "emb_size", ",", "\n", "padding_idx", "=", "constants", ".", "PAD_ID", ",", "\n", "_weight", "=", "embedding_weights", ",", "\n", ")", "\n", "self", ".", "emb_layer", ".", "weight", ".", "requires_grad", "=", "self", ".", "emb_requires_grad", "\n", "\n", "# create generator", "\n", "self", ".", "generator", "=", "SparsemaxGenerator", "(", "\n", "embed", "=", "self", ".", "emb_layer", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "layer", "=", "self", ".", "sentence_encoder_layer_type", ",", "\n", "temperature", "=", "self", ".", "temperature", ",", "\n", ")", "\n", "\n", "# create predictor", "\n", "nonlinearity_str", "=", "\"sigmoid\"", "if", "not", "self", ".", "is_multilabel", "else", "\"log_softmax\"", "\n", "self", ".", "predictor", "=", "SentimentPredictor", "(", "\n", "embed", "=", "self", ".", "emb_layer", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ",", "\n", "output_size", "=", "self", ".", "nb_classes", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "layer", "=", "self", ".", "sentence_encoder_layer_type", ",", "\n", "nonlinearity", "=", "nonlinearity_str", ",", "\n", ")", "\n", "\n", "# define loss function", "\n", "criterion_cls", "=", "nn", ".", "MSELoss", "if", "not", "self", ".", "is_multilabel", "else", "nn", ".", "NLLLoss", "\n", "self", ".", "criterion", "=", "criterion_cls", "(", "reduction", "=", "\"none\"", ")", "\n", "\n", "# initialize params using xavier initialization for weights and zero for biases", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.sparsemax.SparsemaxRationalizer.get_loss": [[77, 104], ["sparsemax.SparsemaxRationalizer.criterion", "rationalizers.utils.get_z_stats", "sparsemax.SparsemaxRationalizer.mean", "sparsemax.SparsemaxRationalizer.mean.item", "sparsemax.SparsemaxRationalizer.mean", "sparsemax.SparsemaxRationalizer.mean.item", "float", "float", "float", "float"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.get_z_stats", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean"], ["", "def", "get_loss", "(", "self", ",", "y_hat", ",", "y", ",", "prefix", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param y_hat: predictions from SentimentPredictor. Torch.Tensor of shape [B, C]\n        :param y: tensor with gold labels. torch.BoolTensor of shape [B]\n        :param mask: mask tensor for padding positions. torch.BoolTensor of shape [B, T]\n        :return: tuple containing:\n            `loss cost (torch.FloatTensor)`: the result of the loss function\n            `loss stats (dict): dict with loss statistics\n        \"\"\"", "\n", "stats", "=", "{", "}", "\n", "loss_vec", "=", "self", ".", "criterion", "(", "y_hat", ",", "y", ")", "# [B] or [B,C]", "\n", "# main MSE loss for p(y | x,z)", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "loss", "=", "loss_vec", ".", "mean", "(", "0", ")", "# [B,C] -> [B]", "\n", "stats", "[", "\"mse\"", "]", "=", "loss", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss_vec", ".", "mean", "(", ")", "# [1]", "\n", "stats", "[", "\"criterion\"", "]", "=", "loss", ".", "item", "(", ")", "# [1]", "\n", "\n", "# latent selection stats", "\n", "", "num_0", ",", "num_c", ",", "num_1", ",", "total", "=", "get_z_stats", "(", "self", ".", "generator", ".", "z", ",", "mask", ")", "\n", "stats", "[", "prefix", "+", "\"_p0\"", "]", "=", "num_0", "/", "float", "(", "total", ")", "\n", "stats", "[", "prefix", "+", "\"_pc\"", "]", "=", "num_c", "/", "float", "(", "total", ")", "\n", "stats", "[", "prefix", "+", "\"_p1\"", "]", "=", "num_1", "/", "float", "(", "total", ")", "\n", "stats", "[", "prefix", "+", "\"_ps\"", "]", "=", "(", "num_c", "+", "num_1", ")", "/", "float", "(", "total", ")", "\n", "\n", "return", "loss", ",", "stats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.base.BaseRationalizer.__init__": [[21, 83], ["pytorch_lightning.LightningModule.__init__", "criterion_cls", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "base.BaseRationalizer.save_hyperparameters", "shell_logger.info", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Recall", "pytorch_lightning.metrics.Recall", "pytorch_lightning.metrics.Recall", "h_params.get"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["self", ".", "dataset", "=", "None", "\n", "self", ".", "label_encoder", "=", "None", "\n", "self", ".", "tokenizer", "=", "None", "\n", "\n", "", "def", "load_encoders", "(", "self", ",", "root_dir", ",", "load_tokenizer", ",", "load_label_encoder", ")", ":", "\n", "        ", "if", "load_tokenizer", ":", "\n", "            ", "self", ".", "tokenizer", "=", "load_object", "(", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"tokenizer.pickle\"", ")", ")", "\n", "", "if", "load_label_encoder", ":", "\n", "            ", "self", ".", "label_encoder", "=", "load_object", "(", "\n", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"label_encoder.pickle\"", ")", "\n", ")", "\n", "\n", "", "", "def", "save_encoders", "(", "self", ",", "root_dir", ",", "save_tokenizer", ",", "save_label_encoder", ")", ":", "\n", "        ", "if", "save_tokenizer", ":", "\n", "            ", "save_object", "(", "self", ".", "tokenizer", ",", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"tokenizer.pickle\"", ")", ")", "\n", "", "if", "save_label_encoder", ":", "\n", "            ", "save_object", "(", "\n", "self", ".", "label_encoder", ",", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"label_encoder.pickle\"", ")", "\n", ")", "\n", "\n", "", "", "def", "_collate_fn", "(", "self", ",", "samples", ":", "list", ",", "are_samples_batched", ":", "bool", "=", "False", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "def", "train_dataloader", "(", "self", ")", ":", "\n", "# use a standard random sampler:", "\n", "        ", "sampler", "=", "RandomSampler", "(", "self", ".", "dataset", "[", "\"train\"", "]", ")", "\n", "return", "DataLoader", "(", "\n", "self", ".", "dataset", "[", "\"train\"", "]", ",", "\n", "sampler", "=", "sampler", ",", "\n", "collate_fn", "=", "self", ".", "_collate_fn", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", ")", "\n", "# bucket examples of similar size together:", "\n", "# sampler = SequentialSampler(self.dataset['train'])", "\n", "# sampler = BucketBatchSampler(", "\n", "#     sampler,", "\n", "#     drop_last=False,", "\n", "#     batch_size=self.batch_size,", "\n", "#     sort_key=lambda i: len(self.dataset['train'][i]['input_ids'])", "\n", "# )", "\n", "# return DataLoader(", "\n", "#     self.dataset['train'],", "\n", "#     sampler=sampler,", "\n", "#     collate_fn=self._collate_fn,", "\n", "#     collate_fn=partial(self._collate_fn, are_samples_batched=True),", "\n", "#     num_workers=self.num_workers,", "\n", "# )", "\n", "\n", "", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "sampler", "=", "SequentialSampler", "(", "self", ".", "dataset", "[", "\"validation\"", "]", ")", "\n", "return", "DataLoader", "(", "\n", "self", ".", "dataset", "[", "\"validation\"", "]", ",", "\n", "sampler", "=", "sampler", ",", "\n", "collate_fn", "=", "self", ".", "_collate_fn", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", ")", "\n", "\n", "", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "sampler", "=", "SequentialSampler", "(", "self", ".", "dataset", "[", "\"test\"", "]", ")", "\n", "return", "DataLoader", "(", "\n", "self", ".", "dataset", "[", "\"test\"", "]", ",", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.base.BaseRationalizer.forward": [[84, 97], ["base.BaseRationalizer.generator", "base.BaseRationalizer.predictor"], "methods", ["None"], ["sampler", "=", "sampler", ",", "\n", "collate_fn", "=", "self", ".", "_collate_fn", ",", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.base.BaseRationalizer.training_step": [[98, 156], ["base.BaseRationalizer.", "base.BaseRationalizer.get_loss", "base.BaseRationalizer.log", "base.BaseRationalizer.log", "base.BaseRationalizer.logger.log_metrics", "y_hat.view", "labels.view", "loss.item"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.get_loss"], []], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.base.BaseRationalizer.validation_step": [[157, 160], ["base.BaseRationalizer._shared_eval_step"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_step"], []], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.base.BaseRationalizer.test_step": [[161, 164], ["base.BaseRationalizer._shared_eval_step"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_step"], []], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.base.BaseRationalizer._shared_eval_step": [[165, 212], ["base.BaseRationalizer.", "base.BaseRationalizer.get_loss", "base.BaseRationalizer.logger.agg_and_log_metrics", "rationalizers.utils.get_rationales", "base.BaseRationalizer.log", "y_hat.view", "labels.view", "loss.item", "loss.item", "batch[].tolist", "batch[].tolist", "batch.keys", "loss_stats.keys"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.get_loss", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.get_rationales"], []], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.base.BaseRationalizer.training_epoch_end": [[213, 220], ["print"], "methods", ["None"], []], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.base.BaseRationalizer.validation_epoch_end": [[221, 223], ["base.BaseRationalizer._shared_eval_epoch_end"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_epoch_end"], []], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.base.BaseRationalizer.test_epoch_end": [[224, 226], ["base.BaseRationalizer._shared_eval_epoch_end"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_epoch_end"], []], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.base.BaseRationalizer._shared_eval_epoch_end": [[227, 355], ["shell_logger.info", "shell_logger.info", "base.BaseRationalizer.logger.agg_and_log_metrics", "base.BaseRationalizer.log", "numpy.mean", "numpy.mean", "rationalizers.modules.metrics.evaluate_rationale", "shell_logger.info", "shell_logger.info", "shell_logger.info", "torch.argmax", "torch.tensor", "shell_logger.info", "shell_logger.info", "shell_logger.info", "shell_logger.info", "base.BaseRationalizer.log", "numpy.mean", "shell_logger.info", "base.BaseRationalizer.log", "outputs[].keys", "stacked_outputs.keys", "torch.cat", "base.BaseRationalizer.val_accuracy", "base.BaseRationalizer.val_precision", "base.BaseRationalizer.val_recall", "base.BaseRationalizer.test_accuracy", "base.BaseRationalizer.test_precision", "base.BaseRationalizer.test_recall"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.metrics.evaluate_rationale", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean"], []], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.base.BaseRationalizer.configure_optimizers": [[356, 365], ["rationalizers.builders.build_optimizer", "rationalizers.builders.build_scheduler", "base.BaseRationalizer.parameters"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_optimizer", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_scheduler"], []], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.base.BaseRationalizer.init_weights": [[366, 403], ["base.BaseRationalizer.named_parameters", "torch.no_grad", "torch.nn.init._calculate_fan_in_and_fan_out", "torch.nn.init.uniform_", "name.startswith", "print", "math.sqrt", "math.sqrt", "print", "base.BaseRationalizer.init_weights.xavier_uniform_n_"], "methods", ["None"], []], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.relaxed_bernoulli.RelaxedBernoulliRationalizer.__init__": [[22, 135], ["rationalizers.lightning_models.highlights.base.BaseRationalizer.__init__", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "relaxed_bernoulli.RelaxedBernoulliRationalizer.save_hyperparameters", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Recall", "pytorch_lightning.metrics.Recall", "pytorch_lightning.metrics.Recall", "rationalizers.builders.build_embedding_weights", "torch.nn.Embedding", "rationalizers.modules.generators.BernoulliIndependentGenerator", "rationalizers.modules.predictors.SentimentPredictor", "relaxed_bernoulli.RelaxedBernoulliRationalizer.init_weights", "h_params.get"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_embedding_weights", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SelfAdditiveScorer.init_weights"], ["def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ":", "StaticTokenizerEncoder", ",", "\n", "nb_classes", ":", "int", ",", "\n", "is_multilabel", ":", "bool", ",", "\n", "h_params", ":", "dict", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param tokenizer (object): torchnlp tokenizer object\n        :param nb_classes (int): number of classes used to create the last layer\n        :param multilabel (bool): whether the problem is multilabel or not (it depends on the dataset)\n        :param h_params (dict): hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "tokenizer", ",", "nb_classes", ",", "is_multilabel", ",", "h_params", ")", "\n", "\n", "# model arch:", "\n", "self", ".", "vocab_size", "=", "tokenizer", ".", "vocab_size", "\n", "self", ".", "emb_type", "=", "h_params", ".", "get", "(", "\"emb_type\"", ",", "\"random\"", ")", "\n", "self", ".", "emb_path", "=", "h_params", ".", "get", "(", "\"emb_path\"", ",", "None", ")", "\n", "self", ".", "emb_size", "=", "h_params", ".", "get", "(", "\"emb_size\"", ",", "300", ")", "\n", "self", ".", "emb_requires_grad", "=", "not", "h_params", ".", "get", "(", "\"embed_fixed\"", ",", "True", ")", "\n", "self", ".", "hidden_size", "=", "h_params", ".", "get", "(", "\"hidden_size\"", ",", "150", ")", "\n", "self", ".", "dropout", "=", "h_params", ".", "get", "(", "\"dropout\"", ",", "0.5", ")", "\n", "self", ".", "sentence_encoder_layer_type", "=", "h_params", ".", "get", "(", "\n", "\"sentence_encoder_layer_type\"", ",", "\"rcnn\"", "\n", ")", "\n", "self", ".", "use_dependent_generator", "=", "h_params", ".", "get", "(", "\"use_dependent_generator\"", ",", "False", ")", "\n", "self", ".", "contiguous", "=", "h_params", ".", "get", "(", "\"contiguous\"", ",", "False", ")", "\n", "self", ".", "topk", "=", "h_params", ".", "get", "(", "\"topk\"", ",", "False", ")", "\n", "self", ".", "relaxed", "=", "h_params", ".", "get", "(", "\"relaxed\"", ",", "False", ")", "\n", "self", ".", "budget", "=", "h_params", ".", "get", "(", "\"budget\"", ",", "10", ")", "\n", "\n", "# loss fn:", "\n", "self", ".", "lambda_0", "=", "h_params", ".", "get", "(", "\"lambda_0\"", ",", "0.0", ")", "\n", "self", ".", "lambda_1", "=", "h_params", ".", "get", "(", "\"lambda_1\"", ",", "0.0", ")", "\n", "self", ".", "baseline", "=", "h_params", ".", "get", "(", "\"baseline\"", ",", "False", ")", "\n", "\n", "if", "self", ".", "baseline", ":", "\n", "            ", "self", ".", "mean_baseline", "=", "0", "\n", "self", ".", "n_points", "=", "0", "\n", "\n", "# global steps for board loggers", "\n", "", "self", ".", "eval_global_step", "=", "{", "\"val\"", ":", "0", ",", "\"test\"", ":", "0", "}", "\n", "\n", "# save hyperparams to checkpoint", "\n", "self", ".", "save_hyperparameters", "(", "h_params", ")", "\n", "\n", "# define metrics", "\n", "self", ".", "train_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "val_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "test_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "train_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "val_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "test_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "train_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "val_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "test_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "\n", "# load word embedding weights based on `emb_type` and define the embedding layer", "\n", "embedding_weights", "=", "build_embedding_weights", "(", "\n", "self", ".", "tokenizer", ".", "vocab", ",", "self", ".", "emb_type", ",", "self", ".", "emb_path", ",", "self", ".", "emb_size", "\n", ")", "\n", "self", ".", "emb_layer", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "vocab_size", ",", "\n", "self", ".", "emb_size", ",", "\n", "padding_idx", "=", "constants", ".", "PAD_ID", ",", "\n", "_weight", "=", "embedding_weights", ",", "\n", ")", "\n", "self", ".", "emb_layer", ".", "weight", ".", "requires_grad", "=", "self", ".", "emb_requires_grad", "\n", "\n", "# create generator", "\n", "self", ".", "generator", "=", "BernoulliIndependentGenerator", "(", "\n", "embed", "=", "self", ".", "emb_layer", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "layer", "=", "self", ".", "sentence_encoder_layer_type", ",", "\n", "budget", "=", "self", ".", "budget", ",", "\n", "contiguous", "=", "self", ".", "contiguous", ",", "\n", "relaxed", "=", "self", ".", "relaxed", ",", "\n", "topk", "=", "self", ".", "topk", ",", "\n", ")", "\n", "\n", "# create predictor", "\n", "nonlinearity_str", "=", "\"sigmoid\"", "if", "not", "self", ".", "is_multilabel", "else", "\"log_softmax\"", "\n", "self", ".", "predictor", "=", "SentimentPredictor", "(", "\n", "embed", "=", "self", ".", "emb_layer", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ",", "\n", "output_size", "=", "self", ".", "nb_classes", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "layer", "=", "self", ".", "sentence_encoder_layer_type", ",", "\n", "nonlinearity", "=", "nonlinearity_str", ",", "\n", ")", "\n", "\n", "# initialize params using xavier initialization for weights and zero for biases", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.relaxed_bernoulli.RelaxedBernoulliRationalizer.get_loss": [[136, 198], ["relaxed_bernoulli.RelaxedBernoulliRationalizer.criterion", "loss_vec.mean.mean.mean", "relaxed_bernoulli.RelaxedBernoulliRationalizer.generator.z.squeeze", "z.view.view.view", "z.view.view.sum", "zdiff.abs().sum.abs().sum.abs().sum", "zsum_cost.item", "zdiff_cost.mean().item", "sparsity_cost.item", "loss_vec.mean.mean.item", "rationalizers.utils.get_z_stats", "float", "loss_vec.mean.mean.item", "loss_vec.mean.mean.mean", "loss_vec.mean.mean.item", "z.view.sum.mean", "zdiff.abs().sum.abs().sum.mean", "pred_diff.mean.mean.mean", "pred_diff.mean.mean.item", "float", "float", "float", "zdiff.abs().sum.abs().sum.abs", "zdiff_cost.mean", "y_hat.max", "y_hat.min"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.get_z_stats", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean"], ["", "def", "get_loss", "(", "self", ",", "y_hat", ",", "y", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param y_hat: predictions from SentimentPredictor. Torch.Tensor of shape [B, C]\n        :param y: tensor with gold labels. torch.BoolTensor of shape [B]\n        :param mask: mask tensor for padding positions. torch.BoolTensor of shape [B, T]\n        :return: tuple containing:\n            `loss cost (torch.FloatTensor)`: the result of the loss function\n            `loss stats (dict): dict with loss statistics\n        \"\"\"", "\n", "stats", "=", "{", "}", "\n", "\n", "loss_vec", "=", "self", ".", "criterion", "(", "y_hat", ",", "y", ")", "# [B] or [B,C]", "\n", "\n", "# main MSE loss for p(y | x,z)", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "loss_vec", "=", "loss_vec", ".", "mean", "(", "1", ")", "# [B,C] -> [B]", "\n", "", "loss", "=", "loss_vec", ".", "mean", "(", ")", "# [1]", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "stats", "[", "\"mse\"", "]", "=", "loss", ".", "item", "(", ")", "# [1]", "\n", "\n", "", "coherent_factor", "=", "self", ".", "lambda_1", "\n", "sparsity_factor", "=", "self", ".", "lambda_0", "\n", "\n", "# compute generator loss", "\n", "z", "=", "self", ".", "generator", ".", "z", ".", "squeeze", "(", ")", "# [B, T]", "\n", "\n", "z", "=", "z", ".", "view", "(", "loss_vec", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "# sparsity regularization", "\n", "zsum", "=", "z", ".", "sum", "(", "1", ")", "\n", "zdiff", "=", "z", "[", ":", ",", "1", ":", "]", "-", "z", "[", ":", ",", ":", "-", "1", "]", "\n", "zdiff", "=", "zdiff", ".", "abs", "(", ")", ".", "sum", "(", "1", ")", "# [B]", "\n", "\n", "zsum_cost", "=", "sparsity_factor", "*", "zsum", ".", "mean", "(", "0", ")", "\n", "stats", "[", "\"zsum_cost\"", "]", "=", "zsum_cost", ".", "item", "(", ")", "\n", "\n", "zdiff_cost", "=", "coherent_factor", "*", "zdiff", ".", "mean", "(", "0", ")", "\n", "stats", "[", "\"zdiff_cost\"", "]", "=", "zdiff_cost", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "sparsity_cost", "=", "zsum_cost", "+", "zdiff_cost", "\n", "stats", "[", "\"sparsity_cost\"", "]", "=", "sparsity_cost", ".", "item", "(", ")", "\n", "\n", "loss", "+=", "zsum_cost", "+", "zdiff_cost", "\n", "\n", "stats", "[", "\"obj\"", "]", "=", "loss", ".", "item", "(", ")", "\n", "\n", "# pred diff doesn't do anything if only 1 aspect being trained", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "pred_diff", "=", "y_hat", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "-", "y_hat", ".", "min", "(", "dim", "=", "1", ")", "[", "0", "]", "\n", "pred_diff", "=", "pred_diff", ".", "mean", "(", ")", "\n", "stats", "[", "\"pred_diff\"", "]", "=", "pred_diff", ".", "item", "(", ")", "\n", "\n", "# latent selection stats", "\n", "", "num_0", ",", "num_c", ",", "num_1", ",", "total", "=", "get_z_stats", "(", "self", ".", "generator", ".", "z", ",", "mask", ")", "\n", "stats", "[", "\"p0\"", "]", "=", "num_0", "/", "float", "(", "total", ")", "\n", "stats", "[", "\"pc\"", "]", "=", "num_c", "/", "float", "(", "total", ")", "\n", "stats", "[", "\"p1\"", "]", "=", "num_1", "/", "float", "(", "total", ")", "\n", "stats", "[", "\"selected\"", "]", "=", "num_1", "\n", "stats", "[", "\"total\"", "]", "=", "float", "(", "total", ")", "\n", "\n", "stats", "[", "\"main_loss\"", "]", "=", "loss", ".", "item", "(", ")", "\n", "return", "loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.relaxed_bernoulli.RelaxedBernoulliRationalizer.training_step": [[199, 253], ["relaxed_bernoulli.RelaxedBernoulliRationalizer.", "relaxed_bernoulli.RelaxedBernoulliRationalizer.get_loss", "relaxed_bernoulli.RelaxedBernoulliRationalizer.log", "relaxed_bernoulli.RelaxedBernoulliRationalizer.log", "relaxed_bernoulli.RelaxedBernoulliRationalizer.log", "y_hat.view", "labels.view", "loss.item"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.get_loss"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Compute forward-pass, calculate loss and log metrics.\n\n        :param batch: The dict output from the data module with the following items:\n            `input_ids`: torch.LongTensor of shape [B, T],\n            `lengths`: torch.LongTensor of shape [B]\n            `labels`: torch.LongTensor of shape [B, C]\n            `tokens`: list of strings\n        :param batch_idx: integer displaying index of this batch\n        :return: pytorch_lightning.Result log object\n        \"\"\"", "\n", "input_ids", "=", "batch", "[", "\"input_ids\"", "]", "\n", "labels", "=", "batch", "[", "\"labels\"", "]", "\n", "mask", "=", "input_ids", "!=", "constants", ".", "PAD_ID", "\n", "\n", "# forward-pass", "\n", "z", ",", "y_hat", "=", "self", "(", "input_ids", ",", "mask", "=", "mask", ")", "\n", "# compute loss", "\n", "y_hat", "=", "y_hat", "if", "not", "self", ".", "is_multilabel", "else", "y_hat", ".", "view", "(", "-", "1", ",", "self", ".", "nb_classes", ")", "\n", "y", "=", "labels", "if", "not", "self", ".", "is_multilabel", "else", "labels", ".", "view", "(", "-", "1", ")", "\n", "loss", ",", "loss_stats", "=", "self", ".", "get_loss", "(", "y_hat", ",", "y", ",", "mask", "=", "mask", ")", "\n", "\n", "# logger=False because they are going to be logged via loss_stats", "\n", "self", ".", "log", "(", "\n", "\"p1\"", ",", "\n", "loss_stats", "[", "\"p1\"", "]", ",", "\n", "prog_bar", "=", "True", ",", "\n", "logger", "=", "False", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "False", ",", "\n", ")", "\n", "self", ".", "log", "(", "\n", "\"train_sum_loss\"", ",", "\n", "loss", ".", "item", "(", ")", ",", "\n", "prog_bar", "=", "True", ",", "\n", "logger", "=", "False", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "False", ",", "\n", ")", "\n", "self", ".", "log", "(", "\n", "\"train_obj_loss\"", ",", "\n", "loss_stats", "[", "\"obj\"", "]", ",", "\n", "prog_bar", "=", "True", ",", "\n", "logger", "=", "False", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "False", ",", "\n", ")", "\n", "# compute metrics for this step", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "y", "=", "(", "y", ">=", "0.5", ")", ".", "long", "(", ")", "\n", "\n", "# return the loss tensor to PTL", "\n", "", "return", "{", "\"loss\"", ":", "loss", ",", "\"obj\"", ":", "loss_stats", "[", "\"obj\"", "]", ",", "\"p1\"", ":", "loss_stats", "[", "\"p1\"", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.relaxed_bernoulli.RelaxedBernoulliRationalizer.validation_step": [[254, 257], ["relaxed_bernoulli.RelaxedBernoulliRationalizer._shared_eval_step"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_step"], ["", "def", "validation_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ")", ":", "\n", "        ", "output", "=", "self", ".", "_shared_eval_step", "(", "batch", ",", "batch_idx", ",", "prefix", "=", "\"val\"", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.relaxed_bernoulli.RelaxedBernoulliRationalizer.test_step": [[258, 261], ["relaxed_bernoulli.RelaxedBernoulliRationalizer._shared_eval_step"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_step"], ["", "def", "test_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ")", ":", "\n", "        ", "output", "=", "self", ".", "_shared_eval_step", "(", "batch", ",", "batch_idx", ",", "prefix", "=", "\"test\"", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.relaxed_bernoulli.RelaxedBernoulliRationalizer._shared_eval_step": [[262, 311], ["relaxed_bernoulli.RelaxedBernoulliRationalizer.", "relaxed_bernoulli.RelaxedBernoulliRationalizer.get_loss", "relaxed_bernoulli.RelaxedBernoulliRationalizer.log", "rationalizers.utils.get_rationales", "y_hat.view", "labels.view", "loss.item", "loss.item", "batch[].tolist", "batch[].tolist", "batch.keys", "loss_stats.keys"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.get_loss", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.get_rationales"], ["", "def", "_shared_eval_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ",", "prefix", ":", "str", ")", ":", "\n", "        ", "input_ids", "=", "batch", "[", "\"input_ids\"", "]", "\n", "labels", "=", "batch", "[", "\"labels\"", "]", "\n", "mask", "=", "input_ids", "!=", "constants", ".", "PAD_ID", "\n", "\n", "# forward-pass", "\n", "z", ",", "y_hat", "=", "self", "(", "input_ids", ",", "mask", "=", "mask", ")", "\n", "\n", "# compute loss", "\n", "y_hat", "=", "y_hat", "if", "not", "self", ".", "is_multilabel", "else", "y_hat", ".", "view", "(", "-", "1", ",", "self", ".", "nb_classes", ")", "\n", "y", "=", "labels", "if", "not", "self", ".", "is_multilabel", "else", "labels", ".", "view", "(", "-", "1", ")", "\n", "loss", ",", "loss_stats", "=", "self", ".", "get_loss", "(", "y_hat", ",", "y", ",", "mask", "=", "mask", ")", "\n", "\n", "# log stats", "\n", "self", ".", "log", "(", "\n", "f\"{prefix}_sum_loss\"", ",", "\n", "loss", ".", "item", "(", ")", ",", "\n", "prog_bar", "=", "True", ",", "\n", "logger", "=", "True", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "\n", ")", "\n", "\n", "# compute metrics for this step", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "y", "=", "(", "y", ">=", "0.5", ")", ".", "long", "(", ")", "\n", "\n", "# log rationales", "\n", "", "ids_rationales", ",", "rationales", "=", "get_rationales", "(", "\n", "self", ".", "tokenizer", ",", "input_ids", ",", "z", ",", "batch", "[", "\"lengths\"", "]", "\n", ")", "\n", "\n", "# output to be stacked across iterations", "\n", "output", "=", "{", "\n", "f\"{prefix}_sum_loss\"", ":", "loss", ".", "item", "(", ")", ",", "\n", "f\"{prefix}_p1\"", ":", "loss_stats", "[", "\"p1\"", "]", ",", "\n", "f\"{prefix}_ids_rationales\"", ":", "ids_rationales", ",", "\n", "f\"{prefix}_rationales\"", ":", "rationales", ",", "\n", "f\"{prefix}_predictions\"", ":", "y_hat", ",", "\n", "f\"{prefix}_tokens\"", ":", "batch", "[", "\"tokens\"", "]", ",", "\n", "f\"{prefix}_labels\"", ":", "batch", "[", "\"labels\"", "]", ".", "tolist", "(", ")", ",", "\n", "f\"{prefix}_lengths\"", ":", "batch", "[", "\"lengths\"", "]", ".", "tolist", "(", ")", ",", "\n", "}", "\n", "if", "\"annotations\"", "in", "batch", ".", "keys", "(", ")", ":", "\n", "            ", "output", "[", "f\"{prefix}_annotations\"", "]", "=", "batch", "[", "\"annotations\"", "]", "\n", "", "if", "\"mse\"", "in", "loss_stats", ".", "keys", "(", ")", ":", "\n", "            ", "output", "[", "f\"{prefix}_mse\"", "]", "=", "loss_stats", "[", "\"mse\"", "]", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.relaxed_bernoulli.RelaxedBernoulliRationalizer.training_epoch_end": [[312, 319], ["print"], "methods", ["None"], ["", "def", "training_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", ":", "\n", "        ", "\"\"\"\n        PTL hook.\n\n        :param outputs: list of dicts representing the stacked outputs from training_step\n        \"\"\"", "\n", "print", "(", "\"\\n Epoch Ended. \\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.relaxed_bernoulli.RelaxedBernoulliRationalizer.validation_epoch_end": [[320, 322], ["relaxed_bernoulli.RelaxedBernoulliRationalizer._shared_eval_epoch_end"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_epoch_end"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", ":", "\n", "        ", "self", ".", "_shared_eval_epoch_end", "(", "outputs", ",", "prefix", "=", "\"val\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.relaxed_bernoulli.RelaxedBernoulliRationalizer.test_epoch_end": [[323, 325], ["relaxed_bernoulli.RelaxedBernoulliRationalizer._shared_eval_epoch_end"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_epoch_end"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", ":", "\n", "        ", "self", ".", "_shared_eval_epoch_end", "(", "outputs", ",", "prefix", "=", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.relaxed_bernoulli.RelaxedBernoulliRationalizer._shared_eval_epoch_end": [[326, 471], ["shell_logger.info", "shell_logger.info", "relaxed_bernoulli.RelaxedBernoulliRationalizer.logger.agg_and_log_metrics", "relaxed_bernoulli.RelaxedBernoulliRationalizer.log", "numpy.mean", "numpy.mean", "numpy.mean", "shell_logger.info", "relaxed_bernoulli.RelaxedBernoulliRationalizer.log", "rationalizers.modules.metrics.evaluate_rationale", "shell_logger.info", "shell_logger.info", "shell_logger.info", "relaxed_bernoulli.RelaxedBernoulliRationalizer.logger.log_metrics", "shell_logger.info", "shell_logger.info", "shell_logger.info", "shell_logger.info", "relaxed_bernoulli.RelaxedBernoulliRationalizer.log", "outputs[].keys", "stacked_outputs.keys", "torch.argmax", "torch.tensor", "relaxed_bernoulli.RelaxedBernoulliRationalizer.val_accuracy", "relaxed_bernoulli.RelaxedBernoulliRationalizer.val_precision", "relaxed_bernoulli.RelaxedBernoulliRationalizer.val_recall", "torch.argmax", "torch.tensor", "relaxed_bernoulli.RelaxedBernoulliRationalizer.test_accuracy", "relaxed_bernoulli.RelaxedBernoulliRationalizer.test_precision", "relaxed_bernoulli.RelaxedBernoulliRationalizer.test_recall", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.metrics.evaluate_rationale"], ["", "def", "_shared_eval_epoch_end", "(", "self", ",", "outputs", ":", "list", ",", "prefix", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        PTL hook. Perform validation at the end of an epoch.\n\n        :param outputs: list of dicts representing the stacked outputs from validation_step\n        :param prefix: `val` or `test`\n        \"\"\"", "\n", "# assume that `outputs` is a list containing dicts with the same keys", "\n", "stacked_outputs", "=", "{", "k", ":", "[", "x", "[", "k", "]", "for", "x", "in", "outputs", "]", "for", "k", "in", "outputs", "[", "0", "]", ".", "keys", "(", ")", "}", "\n", "\n", "# average across batches", "\n", "avg_outputs", "=", "{", "\n", "f\"avg_{prefix}_sum_loss\"", ":", "np", ".", "mean", "(", "stacked_outputs", "[", "f\"{prefix}_sum_loss\"", "]", ")", ",", "\n", "f\"avg_{prefix}_p1\"", ":", "np", ".", "mean", "(", "stacked_outputs", "[", "f\"{prefix}_p1\"", "]", ")", ",", "\n", "}", "\n", "\n", "shell_logger", ".", "info", "(", "\n", "f\"Avg {prefix} sum loss: {avg_outputs[f'avg_{prefix}_sum_loss']:.4}\"", "\n", ")", "\n", "\n", "shell_logger", ".", "info", "(", "f\"Avg {prefix} p1: {avg_outputs[f'avg_{prefix}_p1']:.4}\"", ")", "\n", "\n", "dict_metrics", "=", "{", "\n", "f\"avg_{prefix}_p1\"", ":", "avg_outputs", "[", "f\"avg_{prefix}_p1\"", "]", ",", "\n", "f\"avg_{prefix}_sum_loss\"", ":", "avg_outputs", "[", "f\"avg_{prefix}_sum_loss\"", "]", ",", "\n", "}", "\n", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "avg_outputs", "[", "f\"avg_{prefix}_mse\"", "]", "=", "np", ".", "mean", "(", "stacked_outputs", "[", "f\"{prefix}_mse\"", "]", ")", "\n", "shell_logger", ".", "info", "(", "\n", "f\"Avg {prefix} MSE: {avg_outputs[f'avg_{prefix}_mse']:.4}\"", "\n", ")", "\n", "dict_metrics", "[", "f\"avg_{prefix}_mse\"", "]", "=", "avg_outputs", "[", "f\"avg_{prefix}_mse\"", "]", "\n", "\n", "self", ".", "log", "(", "\n", "f\"{prefix}_MSE\"", ",", "\n", "dict_metrics", "[", "f\"avg_{prefix}_mse\"", "]", ",", "\n", "prog_bar", "=", "False", ",", "\n", "logger", "=", "True", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "\n", ")", "\n", "\n", "", "self", ".", "logger", ".", "agg_and_log_metrics", "(", "dict_metrics", ",", "self", ".", "current_epoch", ")", "\n", "\n", "# only evaluate rationales on the test set and if we have annotation (only for beer dataset)", "\n", "if", "prefix", "==", "\"test\"", "and", "\"test_annotations\"", "in", "stacked_outputs", ".", "keys", "(", ")", ":", "\n", "            ", "metrics", "=", "evaluate_rationale", "(", "\n", "stacked_outputs", "[", "\"test_ids_rationales\"", "]", ",", "\n", "stacked_outputs", "[", "\"test_annotations\"", "]", ",", "\n", "stacked_outputs", "[", "\"test_lengths\"", "]", ",", "\n", ")", "\n", "\n", "shell_logger", ".", "info", "(", "\n", "f\"Rationales macro precision: {metrics[f'macro_precision']:.4}\"", "\n", ")", "\n", "shell_logger", ".", "info", "(", "f\"Rationales macro recall: {metrics[f'macro_recall']:.4}\"", ")", "\n", "shell_logger", ".", "info", "(", "f\"Rationales macro f1: {metrics[f'f1_score']:.4}\"", ")", "\n", "\n", "# log classification metrics", "\n", "", "if", "self", ".", "is_multilabel", ":", "\n", "            ", "if", "prefix", "==", "\"val\"", ":", "\n", "                ", "val_preds", "=", "torch", ".", "argmax", "(", "\n", "torch", ".", "cat", "(", "stacked_outputs", "[", "\"val_predictions\"", "]", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "val_labels", "=", "torch", ".", "tensor", "(", "\n", "[", "\n", "item", "\n", "for", "sublist", "in", "stacked_outputs", "[", "\"val_labels\"", "]", "\n", "for", "item", "in", "sublist", "\n", "]", ",", "\n", "device", "=", "val_preds", ".", "device", ",", "\n", ")", "\n", "accuracy", "=", "self", ".", "val_accuracy", "(", "val_preds", ",", "val_labels", ")", "\n", "precision", "=", "self", ".", "val_precision", "(", "val_preds", ",", "val_labels", ")", "\n", "recall", "=", "self", ".", "val_recall", "(", "val_preds", ",", "val_labels", ")", "\n", "f1_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "class_metrics", "=", "{", "\n", "f\"{prefix}_precision\"", ":", "precision", ",", "\n", "f\"{prefix}_recall\"", ":", "recall", ",", "\n", "f\"{prefix}_f1score\"", ":", "f1_score", ",", "\n", "f\"{prefix}_accuracy\"", ":", "accuracy", ",", "\n", "}", "\n", "\n", "", "else", ":", "\n", "                ", "test_preds", "=", "torch", ".", "argmax", "(", "\n", "torch", ".", "cat", "(", "stacked_outputs", "[", "\"test_predictions\"", "]", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "test_labels", "=", "torch", ".", "tensor", "(", "\n", "[", "\n", "item", "\n", "for", "sublist", "in", "stacked_outputs", "[", "\"test_labels\"", "]", "\n", "for", "item", "in", "sublist", "\n", "]", ",", "\n", "device", "=", "test_preds", ".", "device", ",", "\n", ")", "\n", "accuracy", "=", "self", ".", "test_accuracy", "(", "test_preds", ",", "test_labels", ")", "\n", "precision", "=", "self", ".", "test_precision", "(", "test_preds", ",", "test_labels", ")", "\n", "recall", "=", "self", ".", "test_recall", "(", "test_preds", ",", "test_labels", ")", "\n", "f1_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "class_metrics", "=", "{", "\n", "f\"{prefix}_precision\"", ":", "precision", ",", "\n", "f\"{prefix}_recall\"", ":", "recall", ",", "\n", "f\"{prefix}_f1score\"", ":", "f1_score", ",", "\n", "f\"{prefix}_accuracy\"", ":", "accuracy", ",", "\n", "}", "\n", "\n", "", "self", ".", "logger", ".", "log_metrics", "(", "class_metrics", ",", "step", "=", "None", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} accuracy: {accuracy:.4}\"", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} precision: {precision:.4}\"", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} recall: {recall:.4}\"", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} f1: {f1_score:.4}\"", ")", "\n", "\n", "self", ".", "log", "(", "\n", "f\"{prefix}_f1score\"", ",", "\n", "f1_score", ",", "\n", "prog_bar", "=", "False", ",", "\n", "logger", "=", "True", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "\n", ")", "\n", "\n", "", "self", ".", "log", "(", "\n", "f\"avg_{prefix}_sum_loss\"", ",", "\n", "dict_metrics", "[", "f\"avg_{prefix}_sum_loss\"", "]", ",", "\n", "prog_bar", "=", "False", ",", "\n", "logger", "=", "True", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "\n", ")", "\n", "\n", "if", "self", ".", "is_multilabel", ":", "\n", "            ", "output", "=", "{", "\n", "f\"avg_{prefix}_sum_loss\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_sum_loss\"", "]", ",", "\n", "f\"avg_{prefix}_p1\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_p1\"", "]", ",", "\n", "f\"{prefix}_precision\"", ":", "precision", ",", "\n", "f\"{prefix}_recall\"", ":", "recall", ",", "\n", "f\"{prefix}_f1score\"", ":", "f1_score", ",", "\n", "f\"{prefix}_accuracy\"", ":", "accuracy", ",", "\n", "}", "\n", "", "else", ":", "\n", "            ", "output", "=", "{", "\n", "f\"avg_{prefix}_sum_loss\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_sum_loss\"", "]", ",", "\n", "f\"avg_{prefix}_p1\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_p1\"", "]", ",", "\n", "f\"avg_{prefix}_MSE\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_mse\"", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.hardkuma.HardKumaRationalizer.__init__": [[23, 150], ["rationalizers.lightning_models.highlights.base.BaseRationalizer.__init__", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "hardkuma.HardKumaRationalizer.register_buffer", "hardkuma.HardKumaRationalizer.register_buffer", "hardkuma.HardKumaRationalizer.register_buffer", "hardkuma.HardKumaRationalizer.register_buffer", "hardkuma.HardKumaRationalizer.save_hyperparameters", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Recall", "pytorch_lightning.metrics.Recall", "pytorch_lightning.metrics.Recall", "rationalizers.builders.build_embedding_weights", "torch.nn.Embedding", "rationalizers.modules.generators.KumaIndependentLatentModel", "rationalizers.modules.predictors.SentimentPredictor", "hardkuma.HardKumaRationalizer.init_weights", "h_params.get", "h_params.get", "torch.full", "torch.full", "torch.full", "torch.full"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_embedding_weights", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SelfAdditiveScorer.init_weights"], ["def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ":", "StaticTokenizerEncoder", ",", "\n", "nb_classes", ":", "int", ",", "\n", "is_multilabel", ":", "bool", ",", "\n", "h_params", ":", "dict", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param tokenizer (object): torchnlp tokenizer object\n        :param nb_classes (int): number of classes used to create the last layer\n        :param multilabel (bool): whether the problem is multilabel or not (it depends on the dataset)\n        :param h_params (dict): hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "tokenizer", ",", "nb_classes", ",", "is_multilabel", ",", "h_params", ")", "\n", "\n", "# model arch:", "\n", "self", ".", "vocab_size", "=", "tokenizer", ".", "vocab_size", "\n", "self", ".", "emb_type", "=", "h_params", ".", "get", "(", "\"emb_type\"", ",", "\"random\"", ")", "\n", "self", ".", "emb_path", "=", "h_params", ".", "get", "(", "\"emb_path\"", ",", "None", ")", "\n", "self", ".", "emb_size", "=", "h_params", ".", "get", "(", "\"emb_size\"", ",", "300", ")", "\n", "self", ".", "emb_requires_grad", "=", "not", "h_params", ".", "get", "(", "\"embed_fixed\"", ",", "True", ")", "\n", "self", ".", "hidden_size", "=", "h_params", ".", "get", "(", "\"hidden_size\"", ",", "150", ")", "\n", "self", ".", "dropout", "=", "h_params", ".", "get", "(", "\"dropout\"", ",", "0.5", ")", "\n", "self", ".", "sentence_encoder_layer_type", "=", "h_params", ".", "get", "(", "\n", "\"sentence_encoder_layer_type\"", ",", "\"rcnn\"", "\n", ")", "\n", "self", ".", "use_dependent_generator", "=", "h_params", ".", "get", "(", "\"use_dependent_generator\"", ",", "False", ")", "\n", "self", ".", "contiguous", "=", "h_params", ".", "get", "(", "\"contiguous\"", ",", "False", ")", "\n", "self", ".", "topk", "=", "h_params", ".", "get", "(", "\"topk\"", ",", "False", ")", "\n", "self", ".", "relaxed", "=", "h_params", ".", "get", "(", "\"relaxed\"", ",", "False", ")", "\n", "self", ".", "selection", "=", "h_params", ".", "get", "(", "\"budget\"", ",", "10", ")", "/", "100", "\n", "self", ".", "lasso", "=", "h_params", ".", "get", "(", "\"lasso\"", ",", "0", ")", "\n", "self", ".", "budget", "=", "self", ".", "selection", "\n", "\n", "# loss fn:", "\n", "self", ".", "lambda_0", "=", "h_params", ".", "get", "(", "\"lambda_0\"", ",", "0.0", ")", "\n", "self", ".", "lambda_1", "=", "h_params", ".", "get", "(", "\"lambda_1\"", ",", "0.0", ")", "\n", "self", ".", "baseline", "=", "h_params", ".", "get", "(", "\"baseline\"", ",", "False", ")", "\n", "\n", "# constrained lagrangian:", "\n", "self", ".", "lagrange_lr", "=", "h_params", ".", "get", "(", "\"lagrange_lr\"", ",", "0.01", ")", "\n", "self", ".", "lambda_init", "=", "h_params", ".", "get", "(", "\"lambda_init\"", ",", "1e-4", ")", "\n", "self", ".", "alpha", "=", "h_params", ".", "get", "(", "\"alpha\"", ",", "0.99", ")", "\n", "self", ".", "lambda_min", "=", "h_params", ".", "get", "(", "\"lambda_min\"", ",", "1e-6", ")", "\n", "self", ".", "lambda_max", "=", "h_params", ".", "get", "(", "\"lambda_max\"", ",", "1", ")", "\n", "\n", "# lagrange buffers", "\n", "self", ".", "register_buffer", "(", "\"lambda0\"", ",", "torch", ".", "full", "(", "(", "1", ",", ")", ",", "self", ".", "lambda_init", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"lambda1\"", ",", "torch", ".", "full", "(", "(", "1", ",", ")", ",", "self", ".", "lambda_init", ")", ")", "\n", "self", ".", "register_buffer", "(", "\"c0_ma\"", ",", "torch", ".", "full", "(", "(", "1", ",", ")", ",", "0.0", ")", ")", "# moving average", "\n", "self", ".", "register_buffer", "(", "\"c1_ma\"", ",", "torch", ".", "full", "(", "(", "1", ",", ")", ",", "0.0", ")", ")", "# moving average", "\n", "\n", "if", "self", ".", "baseline", ":", "\n", "            ", "self", ".", "mean_baseline", "=", "0", "\n", "self", ".", "n_points", "=", "0", "\n", "\n", "# global steps for board loggers", "\n", "", "self", ".", "eval_global_step", "=", "{", "\"val\"", ":", "0", ",", "\"test\"", ":", "0", "}", "\n", "\n", "# save hyperparams to checkpoint", "\n", "self", ".", "save_hyperparameters", "(", "h_params", ")", "\n", "\n", "# define metrics", "\n", "self", ".", "train_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "val_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "test_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "train_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "val_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "test_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "train_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "val_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "test_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "\n", "# load word embedding weights based on `emb_type` and define the embedding layer", "\n", "embedding_weights", "=", "build_embedding_weights", "(", "\n", "self", ".", "tokenizer", ".", "vocab", ",", "self", ".", "emb_type", ",", "self", ".", "emb_path", ",", "self", ".", "emb_size", "\n", ")", "\n", "self", ".", "emb_layer", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "vocab_size", ",", "\n", "self", ".", "emb_size", ",", "\n", "padding_idx", "=", "constants", ".", "PAD_ID", ",", "\n", "_weight", "=", "embedding_weights", ",", "\n", ")", "\n", "self", ".", "emb_layer", ".", "weight", ".", "requires_grad", "=", "self", ".", "emb_requires_grad", "\n", "\n", "# create generator", "\n", "self", ".", "generator", "=", "KumaIndependentLatentModel", "(", "\n", "embed", "=", "self", ".", "emb_layer", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "layer", "=", "self", ".", "sentence_encoder_layer_type", ",", "\n", "budget", "=", "self", ".", "budget", ",", "\n", "contiguous", "=", "self", ".", "contiguous", ",", "\n", "topk", "=", "self", ".", "topk", ",", "\n", ")", "\n", "\n", "# create predictor", "\n", "nonlinearity_str", "=", "\"sigmoid\"", "if", "not", "self", ".", "is_multilabel", "else", "\"log_softmax\"", "\n", "self", ".", "predictor", "=", "SentimentPredictor", "(", "\n", "embed", "=", "self", ".", "emb_layer", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ",", "\n", "output_size", "=", "self", ".", "nb_classes", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "layer", "=", "self", ".", "sentence_encoder_layer_type", ",", "\n", "nonlinearity", "=", "nonlinearity_str", ",", "\n", ")", "\n", "\n", "# initialize params using xavier initialization for weights and zero for biases", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.hardkuma.HardKumaRationalizer.get_loss": [[151, 277], ["hardkuma.HardKumaRationalizer.criterion", "loss_vec.mean.mean.mean", "mask.size", "mask.sum().float", "torch.stack.squeeze", "torch.where", "torch.where", "hardkuma.HardKumaRationalizer.lambda0.clamp", "hardkuma.HardKumaRationalizer.lambda1.clamp", "rationalizers.utils.get_z_stats", "loss_vec.mean.mean.item", "loss_vec.mean.mean.mean", "loss_vec.mean.mean.item", "len", "z_dists[].pdf", "range", "torch.stack", "torch.stack.new_zeros", "torch.where.new_zeros", "torch.where.sum", "l0.sum", "torch.exp", "torch.no_grad", "l0.item", "c0_hat.item", "c0.item", "hardkuma.HardKumaRationalizer.lambda0.item", "z_dists[].a.mean().item", "z_dists[].b.mean().item", "lasso_cost.sum", "lasso_cost.sum", "torch.exp", "torch.no_grad", "lasso_cost.item", "c1_hat.item", "c1.item", "hardkuma.HardKumaRationalizer.lambda1.item", "float", "float", "float", "mask.sum", "len", "z_dists[].pdf", "torch.stack.append", "c0_hat.item", "hardkuma.HardKumaRationalizer.c0_ma.detach", "c0_hat.detach", "hardkuma.HardKumaRationalizer.lambda0.detach", "mask.float", "c1_hat.detach", "hardkuma.HardKumaRationalizer.c1_ma.detach", "c1_hat.detach", "hardkuma.HardKumaRationalizer.lambda1.detach", "c0.detach", "z_dists[].a.mean", "z_dists[].b.mean", "c1.detach"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.get_z_stats", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.RV.pdf", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.RV.pdf", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean"], ["", "def", "get_loss", "(", "self", ",", "y_hat", ",", "y", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param y_hat: predictions from SentimentPredictor. Torch.Tensor of shape [B, C]\n        :param y: tensor with gold labels. torch.BoolTensor of shape [B]\n        :param mask: mask tensor for padding positions. torch.BoolTensor of shape [B, T]\n        :return: tuple containing:\n            `loss cost (torch.FloatTensor)`: the result of the loss function\n            `loss stats (dict): dict with loss statistics\n        \"\"\"", "\n", "stats", "=", "{", "}", "\n", "\n", "loss_vec", "=", "self", ".", "criterion", "(", "y_hat", ",", "y", ")", "# [B] or [B,C]", "\n", "\n", "# main MSE loss for p(y | x,z)", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "loss_vec", "=", "loss_vec", ".", "mean", "(", "1", ")", "# [B,C] -> [B]", "\n", "", "loss", "=", "loss_vec", ".", "mean", "(", ")", "# [1]", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "stats", "[", "\"mse\"", "]", "=", "loss", ".", "item", "(", ")", "# [1]", "\n", "\n", "", "batch_size", "=", "mask", ".", "size", "(", "0", ")", "\n", "lengths", "=", "mask", ".", "sum", "(", "1", ")", ".", "float", "(", ")", "# [B]", "\n", "\n", "# L0 regularizer (sparsity constraint)", "\n", "# pre-compute for regularizers: pdf(0.)", "\n", "z_dists", "=", "self", ".", "generator", ".", "z_dists", "\n", "if", "len", "(", "z_dists", ")", "==", "1", ":", "\n", "            ", "pdf0", "=", "z_dists", "[", "0", "]", ".", "pdf", "(", "0.0", ")", "\n", "", "else", ":", "\n", "            ", "pdf0", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "len", "(", "z_dists", ")", ")", ":", "\n", "                ", "pdf_t", "=", "z_dists", "[", "t", "]", ".", "pdf", "(", "0.0", ")", "\n", "pdf0", ".", "append", "(", "pdf_t", ")", "\n", "", "pdf0", "=", "torch", ".", "stack", "(", "pdf0", ",", "dim", "=", "1", ")", "# [B, T, 1]", "\n", "\n", "", "pdf0", "=", "pdf0", ".", "squeeze", "(", "-", "1", ")", "\n", "pdf0", "=", "torch", ".", "where", "(", "mask", ",", "pdf0", ",", "pdf0", ".", "new_zeros", "(", "[", "1", "]", ")", ")", "# [B, T]", "\n", "\n", "pdf_nonzero", "=", "1.0", "-", "pdf0", "# [B, T]", "\n", "pdf_nonzero", "=", "torch", ".", "where", "(", "mask", ",", "pdf_nonzero", ",", "pdf_nonzero", ".", "new_zeros", "(", "[", "1", "]", ")", ")", "\n", "\n", "l0", "=", "pdf_nonzero", ".", "sum", "(", "1", ")", "/", "(", "lengths", "+", "1e-9", ")", "# [B]", "\n", "l0", "=", "l0", ".", "sum", "(", ")", "/", "batch_size", "\n", "\n", "# `l0` now has the expected selection rate for this mini-batch", "\n", "# we now follow the steps Algorithm 1 (page 7) of this paper:", "\n", "# https://arxiv.org/abs/1810.00597", "\n", "# to enforce the constraint that we want l0 to be not higher", "\n", "# than `self.selection` (the target sparsity rate)", "\n", "\n", "# lagrange dissatisfaction, batch average of the constraint", "\n", "c0_hat", "=", "l0", "-", "self", ".", "selection", "\n", "\n", "# moving average of the constraint", "\n", "self", ".", "c0_ma", "=", "self", ".", "alpha", "*", "self", ".", "c0_ma", "+", "(", "1", "-", "self", ".", "alpha", ")", "*", "c0_hat", ".", "item", "(", ")", "\n", "\n", "# compute smoothed constraint (equals moving average c0_ma)", "\n", "c0", "=", "c0_hat", "+", "(", "self", ".", "c0_ma", ".", "detach", "(", ")", "-", "c0_hat", ".", "detach", "(", ")", ")", "\n", "\n", "# update lambda", "\n", "self", ".", "lambda0", "=", "self", ".", "lambda0", "*", "torch", ".", "exp", "(", "self", ".", "lagrange_lr", "*", "c0", ".", "detach", "(", ")", ")", "\n", "self", ".", "lambda0", "=", "self", ".", "lambda0", ".", "clamp", "(", "self", ".", "lambda_min", ",", "self", ".", "lambda_max", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "stats", "[", "\"cost0_l0\"", "]", "=", "l0", ".", "item", "(", ")", "\n", "stats", "[", "\"target0\"", "]", "=", "self", ".", "selection", "\n", "stats", "[", "\"c0_hat\"", "]", "=", "c0_hat", ".", "item", "(", ")", "\n", "stats", "[", "\"c0\"", "]", "=", "c0", ".", "item", "(", ")", "# same as moving average", "\n", "stats", "[", "\"lambda0\"", "]", "=", "self", ".", "lambda0", ".", "item", "(", ")", "\n", "stats", "[", "\"lagrangian0\"", "]", "=", "(", "self", ".", "lambda0", "*", "c0_hat", ")", ".", "item", "(", ")", "\n", "stats", "[", "\"a\"", "]", "=", "z_dists", "[", "0", "]", ".", "a", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "stats", "[", "\"b\"", "]", "=", "z_dists", "[", "0", "]", ".", "b", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "loss", "=", "loss", "+", "self", ".", "lambda0", ".", "detach", "(", ")", "*", "c0", "\n", "\n", "# fused lasso (coherence constraint)", "\n", "\n", "# cost z_t = 0, z_{t+1} = non-zero", "\n", "zt_zero", "=", "pdf0", "[", ":", ",", ":", "-", "1", "]", "\n", "ztp1_nonzero", "=", "pdf_nonzero", "[", ":", ",", "1", ":", "]", "\n", "\n", "# cost z_t = non-zero, z_{t+1} = zero", "\n", "zt_nonzero", "=", "pdf_nonzero", "[", ":", ",", ":", "-", "1", "]", "\n", "ztp1_zero", "=", "pdf0", "[", ":", ",", "1", ":", "]", "\n", "\n", "# number of transitions per sentence normalized by length", "\n", "lasso_cost", "=", "zt_zero", "*", "ztp1_nonzero", "+", "zt_nonzero", "*", "ztp1_zero", "\n", "lasso_cost", "=", "lasso_cost", "*", "mask", ".", "float", "(", ")", "[", ":", ",", ":", "-", "1", "]", "\n", "lasso_cost", "=", "lasso_cost", ".", "sum", "(", "1", ")", "/", "(", "lengths", "+", "1e-9", ")", "# [B]", "\n", "lasso_cost", "=", "lasso_cost", ".", "sum", "(", ")", "/", "batch_size", "\n", "\n", "# lagrange coherence dissatisfaction (batch average)", "\n", "target1", "=", "self", ".", "lasso", "\n", "\n", "# lagrange dissatisfaction, batch average of the constraint", "\n", "c1_hat", "=", "lasso_cost", "-", "target1", "\n", "\n", "# update moving average", "\n", "self", ".", "c1_ma", "=", "self", ".", "alpha", "*", "self", ".", "c1_ma", "+", "(", "1", "-", "self", ".", "alpha", ")", "*", "c1_hat", ".", "detach", "(", ")", "\n", "\n", "# compute smoothed constraint", "\n", "c1", "=", "c1_hat", "+", "(", "self", ".", "c1_ma", ".", "detach", "(", ")", "-", "c1_hat", ".", "detach", "(", ")", ")", "\n", "\n", "# update lambda", "\n", "self", ".", "lambda1", "=", "self", ".", "lambda1", "*", "torch", ".", "exp", "(", "self", ".", "lagrange_lr", "*", "c1", ".", "detach", "(", ")", ")", "\n", "self", ".", "lambda1", "=", "self", ".", "lambda1", ".", "clamp", "(", "self", ".", "lambda_min", ",", "self", ".", "lambda_max", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "stats", "[", "\"cost1_lasso\"", "]", "=", "lasso_cost", ".", "item", "(", ")", "\n", "stats", "[", "\"target1\"", "]", "=", "target1", "\n", "stats", "[", "\"c1_hat\"", "]", "=", "c1_hat", ".", "item", "(", ")", "\n", "stats", "[", "\"c1\"", "]", "=", "c1", ".", "item", "(", ")", "# same as moving average", "\n", "stats", "[", "\"lambda1\"", "]", "=", "self", ".", "lambda1", ".", "item", "(", ")", "\n", "stats", "[", "\"lagrangian1\"", "]", "=", "(", "self", ".", "lambda1", "*", "c1_hat", ")", ".", "item", "(", ")", "\n", "\n", "", "loss", "=", "loss", "+", "self", ".", "lambda1", ".", "detach", "(", ")", "*", "c1", "\n", "\n", "# z statistics", "\n", "num_0", ",", "num_c", ",", "num_1", ",", "total", "=", "get_z_stats", "(", "self", ".", "generator", ".", "z", ",", "mask", ")", "\n", "stats", "[", "\"p0\"", "]", "=", "num_0", "/", "float", "(", "total", ")", "\n", "stats", "[", "\"pc\"", "]", "=", "num_c", "/", "float", "(", "total", ")", "\n", "stats", "[", "\"p1\"", "]", "=", "num_1", "/", "float", "(", "total", ")", "\n", "stats", "[", "\"p1\"", "]", "=", "stats", "[", "\"pc\"", "]", "+", "stats", "[", "\"p1\"", "]", "\n", "\n", "stats", "[", "\"main_loss\"", "]", "=", "loss", ".", "item", "(", ")", "\n", "return", "loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.hardkuma.HardKumaRationalizer.training_step": [[278, 324], ["hardkuma.HardKumaRationalizer.", "hardkuma.HardKumaRationalizer.get_loss", "hardkuma.HardKumaRationalizer.log", "hardkuma.HardKumaRationalizer.log", "y_hat.view", "labels.view", "loss.item"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.get_loss"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Compute forward-pass, calculate loss and log metrics.\n\n        :param batch: The dict output from the data module with the following items:\n            `input_ids`: torch.LongTensor of shape [B, T],\n            `lengths`: torch.LongTensor of shape [B]\n            `labels`: torch.LongTensor of shape [B, C]\n            `tokens`: list of strings\n        :param batch_idx: integer displaying index of this batch\n        :return: pytorch_lightning.Result log object\n        \"\"\"", "\n", "input_ids", "=", "batch", "[", "\"input_ids\"", "]", "\n", "labels", "=", "batch", "[", "\"labels\"", "]", "\n", "mask", "=", "input_ids", "!=", "constants", ".", "PAD_ID", "\n", "\n", "# forward-pass", "\n", "z", ",", "y_hat", "=", "self", "(", "input_ids", ",", "mask", "=", "mask", ")", "\n", "# compute loss", "\n", "y_hat", "=", "y_hat", "if", "not", "self", ".", "is_multilabel", "else", "y_hat", ".", "view", "(", "-", "1", ",", "self", ".", "nb_classes", ")", "\n", "y", "=", "labels", "if", "not", "self", ".", "is_multilabel", "else", "labels", ".", "view", "(", "-", "1", ")", "\n", "loss", ",", "loss_stats", "=", "self", ".", "get_loss", "(", "y_hat", ",", "y", ",", "mask", "=", "mask", ")", "\n", "\n", "self", ".", "log", "(", "\n", "\"p1\"", ",", "\n", "loss_stats", "[", "\"p1\"", "]", ",", "\n", "prog_bar", "=", "True", ",", "\n", "logger", "=", "False", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "False", ",", "\n", ")", "\n", "self", ".", "log", "(", "\n", "\"train_sum_loss\"", ",", "\n", "loss", ".", "item", "(", ")", ",", "\n", "prog_bar", "=", "True", ",", "\n", "logger", "=", "False", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "False", ",", "\n", ")", "\n", "\n", "# compute metrics for this step", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "y", "=", "(", "y", ">=", "0.5", ")", ".", "long", "(", ")", "\n", "\n", "# return the loss tensor to PTL", "\n", "", "return", "{", "\"loss\"", ":", "loss", ",", "\"p1\"", ":", "loss_stats", "[", "\"p1\"", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.hardkuma.HardKumaRationalizer.validation_step": [[325, 328], ["hardkuma.HardKumaRationalizer._shared_eval_step"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_step"], ["", "def", "validation_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ")", ":", "\n", "        ", "output", "=", "self", ".", "_shared_eval_step", "(", "batch", ",", "batch_idx", ",", "prefix", "=", "\"val\"", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.hardkuma.HardKumaRationalizer.test_step": [[329, 332], ["hardkuma.HardKumaRationalizer._shared_eval_step"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_step"], ["", "def", "test_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ")", ":", "\n", "        ", "output", "=", "self", ".", "_shared_eval_step", "(", "batch", ",", "batch_idx", ",", "prefix", "=", "\"test\"", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.hardkuma.HardKumaRationalizer._shared_eval_step": [[333, 382], ["hardkuma.HardKumaRationalizer.", "hardkuma.HardKumaRationalizer.get_loss", "hardkuma.HardKumaRationalizer.log", "rationalizers.utils.get_rationales", "y_hat.view", "labels.view", "loss.item", "loss.item", "batch[].tolist", "batch[].tolist", "batch.keys", "loss_stats.keys"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.get_loss", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.get_rationales"], ["", "def", "_shared_eval_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ",", "prefix", ":", "str", ")", ":", "\n", "        ", "input_ids", "=", "batch", "[", "\"input_ids\"", "]", "\n", "labels", "=", "batch", "[", "\"labels\"", "]", "\n", "mask", "=", "input_ids", "!=", "constants", ".", "PAD_ID", "\n", "\n", "# forward-pass", "\n", "z", ",", "y_hat", "=", "self", "(", "input_ids", ",", "mask", "=", "mask", ")", "\n", "\n", "# compute loss", "\n", "y_hat", "=", "y_hat", "if", "not", "self", ".", "is_multilabel", "else", "y_hat", ".", "view", "(", "-", "1", ",", "self", ".", "nb_classes", ")", "\n", "y", "=", "labels", "if", "not", "self", ".", "is_multilabel", "else", "labels", ".", "view", "(", "-", "1", ")", "\n", "loss", ",", "loss_stats", "=", "self", ".", "get_loss", "(", "y_hat", ",", "y", ",", "mask", "=", "mask", ")", "\n", "\n", "# log stats", "\n", "self", ".", "log", "(", "\n", "f\"{prefix}_sum_loss\"", ",", "\n", "loss", ".", "item", "(", ")", ",", "\n", "prog_bar", "=", "True", ",", "\n", "logger", "=", "True", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "\n", ")", "\n", "\n", "# log rationales", "\n", "ids_rationales", ",", "rationales", "=", "get_rationales", "(", "\n", "self", ".", "tokenizer", ",", "input_ids", ",", "z", ",", "batch", "[", "\"lengths\"", "]", "\n", ")", "\n", "\n", "# compute metrics for this step", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "y", "=", "(", "y", ">=", "0.5", ")", ".", "long", "(", ")", "\n", "\n", "# output to be stacked across iterations", "\n", "", "output", "=", "{", "\n", "f\"{prefix}_sum_loss\"", ":", "loss", ".", "item", "(", ")", ",", "\n", "f\"{prefix}_p1\"", ":", "loss_stats", "[", "\"p1\"", "]", ",", "\n", "f\"{prefix}_ids_rationales\"", ":", "ids_rationales", ",", "\n", "f\"{prefix}_rationales\"", ":", "rationales", ",", "\n", "f\"{prefix}_predictions\"", ":", "y_hat", ",", "\n", "f\"{prefix}_tokens\"", ":", "batch", "[", "\"tokens\"", "]", ",", "\n", "f\"{prefix}_labels\"", ":", "batch", "[", "\"labels\"", "]", ".", "tolist", "(", ")", ",", "\n", "f\"{prefix}_lengths\"", ":", "batch", "[", "\"lengths\"", "]", ".", "tolist", "(", ")", ",", "\n", "}", "\n", "if", "\"annotations\"", "in", "batch", ".", "keys", "(", ")", ":", "\n", "            ", "output", "[", "f\"{prefix}_annotations\"", "]", "=", "batch", "[", "\"annotations\"", "]", "\n", "", "if", "\"mse\"", "in", "loss_stats", ".", "keys", "(", ")", ":", "\n", "            ", "output", "[", "f\"{prefix}_mse\"", "]", "=", "loss_stats", "[", "\"mse\"", "]", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.hardkuma.HardKumaRationalizer.training_epoch_end": [[383, 390], ["print"], "methods", ["None"], ["", "def", "training_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", ":", "\n", "        ", "\"\"\"\n        PTL hook.\n\n        :param outputs: list of dicts representing the stacked outputs from training_step\n        \"\"\"", "\n", "print", "(", "\"\\n Epoch Ended. \\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.hardkuma.HardKumaRationalizer.validation_epoch_end": [[391, 393], ["hardkuma.HardKumaRationalizer._shared_eval_epoch_end"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_epoch_end"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", ":", "\n", "        ", "self", ".", "_shared_eval_epoch_end", "(", "outputs", ",", "prefix", "=", "\"val\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.hardkuma.HardKumaRationalizer.test_epoch_end": [[394, 396], ["hardkuma.HardKumaRationalizer._shared_eval_epoch_end"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_epoch_end"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", ":", "\n", "        ", "self", ".", "_shared_eval_epoch_end", "(", "outputs", ",", "prefix", "=", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.hardkuma.HardKumaRationalizer._shared_eval_epoch_end": [[397, 542], ["shell_logger.info", "shell_logger.info", "hardkuma.HardKumaRationalizer.logger.agg_and_log_metrics", "hardkuma.HardKumaRationalizer.log", "numpy.mean", "numpy.mean", "numpy.mean", "shell_logger.info", "hardkuma.HardKumaRationalizer.log", "rationalizers.modules.metrics.evaluate_rationale", "shell_logger.info", "shell_logger.info", "shell_logger.info", "hardkuma.HardKumaRationalizer.logger.log_metrics", "shell_logger.info", "shell_logger.info", "shell_logger.info", "shell_logger.info", "hardkuma.HardKumaRationalizer.log", "outputs[].keys", "stacked_outputs.keys", "torch.argmax", "torch.tensor", "hardkuma.HardKumaRationalizer.val_accuracy", "hardkuma.HardKumaRationalizer.val_precision", "hardkuma.HardKumaRationalizer.val_recall", "torch.argmax", "torch.tensor", "hardkuma.HardKumaRationalizer.test_accuracy", "hardkuma.HardKumaRationalizer.test_precision", "hardkuma.HardKumaRationalizer.test_recall", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.metrics.evaluate_rationale"], ["", "def", "_shared_eval_epoch_end", "(", "self", ",", "outputs", ":", "list", ",", "prefix", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        PTL hook. Perform validation at the end of an epoch.\n\n        :param outputs: list of dicts representing the stacked outputs from validation_step\n        :param prefix: `val` or `test`\n        \"\"\"", "\n", "# assume that `outputs` is a list containing dicts with the same keys", "\n", "stacked_outputs", "=", "{", "k", ":", "[", "x", "[", "k", "]", "for", "x", "in", "outputs", "]", "for", "k", "in", "outputs", "[", "0", "]", ".", "keys", "(", ")", "}", "\n", "\n", "# average across batches", "\n", "avg_outputs", "=", "{", "\n", "f\"avg_{prefix}_sum_loss\"", ":", "np", ".", "mean", "(", "stacked_outputs", "[", "f\"{prefix}_sum_loss\"", "]", ")", ",", "\n", "f\"avg_{prefix}_p1\"", ":", "np", ".", "mean", "(", "stacked_outputs", "[", "f\"{prefix}_p1\"", "]", ")", ",", "\n", "}", "\n", "\n", "shell_logger", ".", "info", "(", "\n", "f\"Avg {prefix} sum loss: {avg_outputs[f'avg_{prefix}_sum_loss']:.4}\"", "\n", ")", "\n", "\n", "shell_logger", ".", "info", "(", "f\"Avg {prefix} p1: {avg_outputs[f'avg_{prefix}_p1']:.4}\"", ")", "\n", "\n", "dict_metrics", "=", "{", "\n", "f\"avg_{prefix}_p1\"", ":", "avg_outputs", "[", "f\"avg_{prefix}_p1\"", "]", ",", "\n", "f\"avg_{prefix}_sum_loss\"", ":", "avg_outputs", "[", "f\"avg_{prefix}_sum_loss\"", "]", ",", "\n", "}", "\n", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "avg_outputs", "[", "f\"avg_{prefix}_mse\"", "]", "=", "np", ".", "mean", "(", "stacked_outputs", "[", "f\"{prefix}_mse\"", "]", ")", "\n", "shell_logger", ".", "info", "(", "\n", "f\"Avg {prefix} MSE: {avg_outputs[f'avg_{prefix}_mse']:.4}\"", "\n", ")", "\n", "dict_metrics", "[", "f\"avg_{prefix}_mse\"", "]", "=", "avg_outputs", "[", "f\"avg_{prefix}_mse\"", "]", "\n", "\n", "self", ".", "log", "(", "\n", "f\"{prefix}_MSE\"", ",", "\n", "dict_metrics", "[", "f\"avg_{prefix}_mse\"", "]", ",", "\n", "prog_bar", "=", "False", ",", "\n", "logger", "=", "True", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "\n", ")", "\n", "\n", "", "self", ".", "logger", ".", "agg_and_log_metrics", "(", "dict_metrics", ",", "self", ".", "current_epoch", ")", "\n", "\n", "# only evaluate rationales on the test set and if we have annotation (only for beer dataset)", "\n", "if", "prefix", "==", "\"test\"", "and", "\"test_annotations\"", "in", "stacked_outputs", ".", "keys", "(", ")", ":", "\n", "            ", "metrics", "=", "evaluate_rationale", "(", "\n", "stacked_outputs", "[", "\"test_ids_rationales\"", "]", ",", "\n", "stacked_outputs", "[", "\"test_annotations\"", "]", ",", "\n", "stacked_outputs", "[", "\"test_lengths\"", "]", ",", "\n", ")", "\n", "\n", "shell_logger", ".", "info", "(", "\n", "f\"Rationales macro precision: {metrics[f'macro_precision']:.4}\"", "\n", ")", "\n", "shell_logger", ".", "info", "(", "f\"Rationales macro recall: {metrics[f'macro_recall']:.4}\"", ")", "\n", "shell_logger", ".", "info", "(", "f\"Rationales macro f1: {metrics[f'f1_score']:.4}\"", ")", "\n", "\n", "# log classification metrics", "\n", "", "if", "self", ".", "is_multilabel", ":", "\n", "            ", "if", "prefix", "==", "\"val\"", ":", "\n", "                ", "val_preds", "=", "torch", ".", "argmax", "(", "\n", "torch", ".", "cat", "(", "stacked_outputs", "[", "\"val_predictions\"", "]", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "val_labels", "=", "torch", ".", "tensor", "(", "\n", "[", "\n", "item", "\n", "for", "sublist", "in", "stacked_outputs", "[", "\"val_labels\"", "]", "\n", "for", "item", "in", "sublist", "\n", "]", ",", "\n", "device", "=", "val_preds", ".", "device", ",", "\n", ")", "\n", "accuracy", "=", "self", ".", "val_accuracy", "(", "val_preds", ",", "val_labels", ")", "\n", "precision", "=", "self", ".", "val_precision", "(", "val_preds", ",", "val_labels", ")", "\n", "recall", "=", "self", ".", "val_recall", "(", "val_preds", ",", "val_labels", ")", "\n", "f1_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "class_metrics", "=", "{", "\n", "f\"{prefix}_precision\"", ":", "precision", ",", "\n", "f\"{prefix}_recall\"", ":", "recall", ",", "\n", "f\"{prefix}_f1score\"", ":", "f1_score", ",", "\n", "f\"{prefix}_accuracy\"", ":", "accuracy", ",", "\n", "}", "\n", "\n", "", "else", ":", "\n", "                ", "test_preds", "=", "torch", ".", "argmax", "(", "\n", "torch", ".", "cat", "(", "stacked_outputs", "[", "\"test_predictions\"", "]", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "test_labels", "=", "torch", ".", "tensor", "(", "\n", "[", "\n", "item", "\n", "for", "sublist", "in", "stacked_outputs", "[", "\"test_labels\"", "]", "\n", "for", "item", "in", "sublist", "\n", "]", ",", "\n", "device", "=", "test_preds", ".", "device", ",", "\n", ")", "\n", "accuracy", "=", "self", ".", "test_accuracy", "(", "test_preds", ",", "test_labels", ")", "\n", "precision", "=", "self", ".", "test_precision", "(", "test_preds", ",", "test_labels", ")", "\n", "recall", "=", "self", ".", "test_recall", "(", "test_preds", ",", "test_labels", ")", "\n", "f1_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "class_metrics", "=", "{", "\n", "f\"{prefix}_precision\"", ":", "precision", ",", "\n", "f\"{prefix}_recall\"", ":", "recall", ",", "\n", "f\"{prefix}_f1score\"", ":", "f1_score", ",", "\n", "f\"{prefix}_accuracy\"", ":", "accuracy", ",", "\n", "}", "\n", "\n", "", "self", ".", "logger", ".", "log_metrics", "(", "class_metrics", ",", "step", "=", "None", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} accuracy: {accuracy:.4}\"", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} precision: {precision:.4}\"", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} recall: {recall:.4}\"", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} f1: {f1_score:.4}\"", ")", "\n", "\n", "self", ".", "log", "(", "\n", "f\"{prefix}_f1score\"", ",", "\n", "f1_score", ",", "\n", "prog_bar", "=", "False", ",", "\n", "logger", "=", "True", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "\n", ")", "\n", "\n", "", "self", ".", "log", "(", "\n", "f\"avg_{prefix}_sum_loss\"", ",", "\n", "dict_metrics", "[", "f\"avg_{prefix}_sum_loss\"", "]", ",", "\n", "prog_bar", "=", "False", ",", "\n", "logger", "=", "True", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "\n", ")", "\n", "\n", "if", "self", ".", "is_multilabel", ":", "\n", "            ", "output", "=", "{", "\n", "f\"avg_{prefix}_sum_loss\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_sum_loss\"", "]", ",", "\n", "f\"avg_{prefix}_p1\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_p1\"", "]", ",", "\n", "f\"{prefix}_precision\"", ":", "precision", ",", "\n", "f\"{prefix}_recall\"", ":", "recall", ",", "\n", "f\"{prefix}_f1score\"", ":", "f1_score", ",", "\n", "f\"{prefix}_accuracy\"", ":", "accuracy", ",", "\n", "}", "\n", "", "else", ":", "\n", "            ", "output", "=", "{", "\n", "f\"avg_{prefix}_sum_loss\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_sum_loss\"", "]", ",", "\n", "f\"avg_{prefix}_p1\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_p1\"", "]", ",", "\n", "f\"avg_{prefix}_MSE\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_mse\"", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.vanilla.VanillaClassifier.__init__": [[25, 126], ["rationalizers.lightning_models.highlights.base.BaseRationalizer.__init__", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "vanilla.VanillaClassifier.save_hyperparameters", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Recall", "pytorch_lightning.metrics.Recall", "pytorch_lightning.metrics.Recall", "rationalizers.builders.build_embedding_weights", "torch.nn.Embedding", "rationalizers.modules.predictors.SentimentPredictor", "vanilla.VanillaClassifier.init_weights", "h_params.get"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_embedding_weights", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SelfAdditiveScorer.init_weights"], ["def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ":", "StaticTokenizerEncoder", ",", "\n", "nb_classes", ":", "int", ",", "\n", "is_multilabel", ":", "bool", ",", "\n", "h_params", ":", "dict", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param tokenizer (object): torchnlp tokenizer object\n        :param nb_classes (int): number of classes used to create the last layer\n        :param multilabel (bool): whether the problem is multilabel or not (it depends on the dataset)\n        :param h_params (dict): hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "tokenizer", ",", "nb_classes", ",", "is_multilabel", ",", "h_params", ")", "\n", "\n", "# model arch:", "\n", "self", ".", "vocab_size", "=", "tokenizer", ".", "vocab_size", "\n", "self", ".", "emb_type", "=", "h_params", ".", "get", "(", "\"emb_type\"", ",", "\"random\"", ")", "\n", "self", ".", "emb_path", "=", "h_params", ".", "get", "(", "\"emb_path\"", ",", "None", ")", "\n", "self", ".", "emb_size", "=", "h_params", ".", "get", "(", "\"emb_size\"", ",", "300", ")", "\n", "self", ".", "emb_requires_grad", "=", "not", "h_params", ".", "get", "(", "\"embed_fixed\"", ",", "True", ")", "\n", "self", ".", "hidden_size", "=", "h_params", ".", "get", "(", "\"hidden_size\"", ",", "150", ")", "\n", "self", ".", "dropout", "=", "h_params", ".", "get", "(", "\"dropout\"", ",", "0.5", ")", "\n", "self", ".", "sentence_encoder_layer_type", "=", "h_params", ".", "get", "(", "\n", "\"sentence_encoder_layer_type\"", ",", "\"rcnn\"", "\n", ")", "\n", "self", ".", "use_dependent_generator", "=", "h_params", ".", "get", "(", "\"use_dependent_generator\"", ",", "False", ")", "\n", "self", ".", "contiguous", "=", "h_params", ".", "get", "(", "\"contiguous\"", ",", "False", ")", "\n", "self", ".", "topk", "=", "h_params", ".", "get", "(", "\"topk\"", ",", "False", ")", "\n", "self", ".", "relaxed", "=", "h_params", ".", "get", "(", "\"relaxed\"", ",", "False", ")", "\n", "self", ".", "budget", "=", "h_params", ".", "get", "(", "\"budget\"", ",", "10", ")", "\n", "\n", "# loss fn:", "\n", "self", ".", "lambda_0", "=", "h_params", ".", "get", "(", "\"lambda_0\"", ",", "0.0", ")", "\n", "self", ".", "lambda_1", "=", "h_params", ".", "get", "(", "\"lambda_1\"", ",", "0.0", ")", "\n", "self", ".", "baseline", "=", "h_params", ".", "get", "(", "\"baseline\"", ",", "False", ")", "\n", "\n", "if", "self", ".", "baseline", ":", "\n", "            ", "self", ".", "mean_baseline", "=", "0", "\n", "self", ".", "n_points", "=", "0", "\n", "\n", "# global steps for board loggers", "\n", "", "self", ".", "eval_global_step", "=", "{", "\"val\"", ":", "0", ",", "\"test\"", ":", "0", "}", "\n", "\n", "# save hyperparams to checkpoint", "\n", "self", ".", "save_hyperparameters", "(", "h_params", ")", "\n", "\n", "# define metrics", "\n", "self", ".", "train_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "val_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "test_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "train_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "val_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "test_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "train_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "val_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "test_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "\n", "# load word embedding weights based on `emb_type` and define the embedding layer", "\n", "embedding_weights", "=", "build_embedding_weights", "(", "\n", "self", ".", "tokenizer", ".", "vocab", ",", "self", ".", "emb_type", ",", "self", ".", "emb_path", ",", "self", ".", "emb_size", "\n", ")", "\n", "self", ".", "emb_layer", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "vocab_size", ",", "\n", "self", ".", "emb_size", ",", "\n", "padding_idx", "=", "constants", ".", "PAD_ID", ",", "\n", "_weight", "=", "embedding_weights", ",", "\n", ")", "\n", "self", ".", "emb_layer", ".", "weight", ".", "requires_grad", "=", "self", ".", "emb_requires_grad", "\n", "\n", "# create predictor", "\n", "nonlinearity_str", "=", "\"sigmoid\"", "if", "not", "self", ".", "is_multilabel", "else", "\"log_softmax\"", "\n", "self", ".", "predictor", "=", "SentimentPredictor", "(", "\n", "embed", "=", "self", ".", "emb_layer", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ",", "\n", "output_size", "=", "self", ".", "nb_classes", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "layer", "=", "self", ".", "sentence_encoder_layer_type", ",", "\n", "nonlinearity", "=", "nonlinearity_str", ",", "\n", ")", "\n", "\n", "# initialize params using xavier initialization for weights and zero for biases", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.vanilla.VanillaClassifier.forward": [[127, 140], ["torch.ones", "vanilla.VanillaClassifier.predictor"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "x", ":", "torch", ".", "LongTensor", ",", "current_epoch", "=", "None", ",", "mask", ":", "torch", ".", "BoolTensor", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Compute forward-pass.\n\n        :param x: input ids tensor. torch.LongTensor of shape [B, T]\n        :param mask: mask tensor for padding positions. torch.BoolTensor of shape [B, T]\n        :return: the output from SentimentPredictor. Torch.Tensor of shape [B, C]\n        \"\"\"", "\n", "z", "=", "torch", ".", "ones", "(", "x", ".", "shape", ")", "\n", "y_hat", "=", "self", ".", "predictor", "(", "x", ",", "z", ",", "mask", "=", "mask", ")", "\n", "return", "z", ",", "y_hat", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.vanilla.VanillaClassifier.get_loss": [[141, 168], ["vanilla.VanillaClassifier.criterion", "loss_vec.mean.mean.mean", "float", "loss_vec.mean.mean.mean", "float", "loss_vec.mean.mean.item", "loss_vec.mean.mean.item"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean"], ["", "def", "get_loss", "(", "self", ",", "y_hat", ",", "y", ",", "prefix", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param y_hat: predictions from SentimentPredictor. Torch.Tensor of shape [B, C]\n        :param y: tensor with gold labels. torch.BoolTensor of shape [B]\n        :param mask: mask tensor for padding positions. torch.BoolTensor of shape [B, T]\n        :return: tuple containing:\n            `loss cost (torch.FloatTensor)`: the result of the loss function\n            `loss stats (dict): dict with loss statistics\n        \"\"\"", "\n", "stats", "=", "{", "}", "\n", "loss_vec", "=", "self", ".", "criterion", "(", "y_hat", ",", "y", ")", "# [B] or [B,C]", "\n", "\n", "# main MSE loss for p(y | x,z)", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "loss_vec", "=", "loss_vec", ".", "mean", "(", "1", ")", "# [B,C] -> [B]", "\n", "stats", "[", "\"mse\"", "]", "=", "float", "(", "loss_vec", ".", "item", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss_vec", ".", "mean", "(", ")", "# [1]", "\n", "stats", "[", "\"criterion\"", "]", "=", "float", "(", "loss", ".", "item", "(", ")", ")", "# [1]", "\n", "\n", "# latent selection stats", "\n", "", "stats", "[", "prefix", "+", "\"_p0\"", "]", "=", "0", "\n", "stats", "[", "prefix", "+", "\"_pc\"", "]", "=", "1", "\n", "stats", "[", "prefix", "+", "\"_p1\"", "]", "=", "1", "\n", "stats", "[", "prefix", "+", "\"_ps\"", "]", "=", "1", "\n", "\n", "return", "loss", ",", "stats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.spectra.SPECTRARationalizer.__init__": [[22, 113], ["rationalizers.lightning_models.highlights.base.BaseRationalizer.__init__", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "spectra.SPECTRARationalizer.save_hyperparameters", "rationalizers.builders.build_embedding_weights", "torch.nn.Embedding", "rationalizers.modules.generators.SPECTRAGenerator", "rationalizers.modules.predictors.SentimentPredictor", "spectra.SPECTRARationalizer.init_weights", "h_params.get", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Recall", "pytorch_lightning.metrics.Recall", "pytorch_lightning.metrics.Recall"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_embedding_weights", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SelfAdditiveScorer.init_weights"], ["def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ":", "StaticTokenizerEncoder", ",", "\n", "nb_classes", ":", "int", ",", "\n", "is_multilabel", ":", "bool", ",", "\n", "h_params", ":", "dict", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param tokenizer (object): torchnlp tokenizer object\n        :param nb_classes (int): number of classes used to create the last layer\n        :param multilabel (bool): whether the problem is multilabel or not (it depends on the dataset)\n        :param h_params (dict): hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "tokenizer", ",", "nb_classes", ",", "is_multilabel", ",", "h_params", ")", "\n", "\n", "# model arch:", "\n", "self", ".", "vocab_size", "=", "tokenizer", ".", "vocab_size", "\n", "self", ".", "emb_type", "=", "h_params", ".", "get", "(", "\"emb_type\"", ",", "\"random\"", ")", "\n", "self", ".", "emb_path", "=", "h_params", ".", "get", "(", "\"emb_path\"", ",", "None", ")", "\n", "self", ".", "emb_size", "=", "h_params", ".", "get", "(", "\"emb_size\"", ",", "300", ")", "\n", "self", ".", "emb_requires_grad", "=", "not", "h_params", ".", "get", "(", "\"embed_fixed\"", ",", "True", ")", "\n", "self", ".", "hidden_size", "=", "h_params", ".", "get", "(", "\"hidden_size\"", ",", "150", ")", "\n", "self", ".", "dropout", "=", "h_params", ".", "get", "(", "\"dropout\"", ",", "0.5", ")", "\n", "self", ".", "sentence_encoder_layer_type", "=", "h_params", ".", "get", "(", "\n", "\"sentence_encoder_layer_type\"", ",", "\"lstm\"", "\n", ")", "\n", "self", ".", "transition", "=", "h_params", ".", "get", "(", "\"transition\"", ",", "0.0", ")", "\n", "self", ".", "budget", "=", "h_params", ".", "get", "(", "\"budget\"", ",", "0", ")", "\n", "self", ".", "temperature", "=", "h_params", ".", "get", "(", "\"temperature\"", ",", "0.01", ")", "\n", "\n", "# save hyperparams to checkpoint", "\n", "self", ".", "save_hyperparameters", "(", "h_params", ")", "\n", "\n", "# define metrics", "\n", "if", "self", ".", "is_multilabel", ":", "\n", "            ", "self", ".", "train_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "val_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "test_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "train_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "average", "=", "\"macro\"", "\n", ")", "\n", "self", ".", "val_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "average", "=", "\"macro\"", "\n", ")", "\n", "self", ".", "test_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "average", "=", "\"macro\"", "\n", ")", "\n", "self", ".", "train_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "\n", "num_classes", "=", "nb_classes", ",", "average", "=", "\"macro\"", "\n", ")", "\n", "self", ".", "val_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "num_classes", "=", "nb_classes", ",", "average", "=", "\"macro\"", ")", "\n", "self", ".", "test_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "\n", "num_classes", "=", "nb_classes", ",", "average", "=", "\"macro\"", "\n", ")", "\n", "\n", "# load word embedding weights based on `emb_type` and define the embedding layer", "\n", "", "embedding_weights", "=", "build_embedding_weights", "(", "\n", "self", ".", "tokenizer", ".", "vocab", ",", "self", ".", "emb_type", ",", "self", ".", "emb_path", ",", "self", ".", "emb_size", "\n", ")", "\n", "self", ".", "emb_layer", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "vocab_size", ",", "\n", "self", ".", "emb_size", ",", "\n", "padding_idx", "=", "constants", ".", "PAD_ID", ",", "\n", "_weight", "=", "embedding_weights", ",", "\n", ")", "\n", "self", ".", "emb_layer", ".", "weight", ".", "requires_grad", "=", "self", ".", "emb_requires_grad", "\n", "\n", "# create generator", "\n", "self", ".", "generator", "=", "SPECTRAGenerator", "(", "\n", "embed", "=", "self", ".", "emb_layer", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "layer", "=", "self", ".", "sentence_encoder_layer_type", ",", "\n", "transition", "=", "self", ".", "transition", ",", "\n", "budget", "=", "self", ".", "budget", ",", "\n", "temperature", "=", "self", ".", "temperature", ",", "\n", ")", "\n", "\n", "# create predictor", "\n", "nonlinearity_str", "=", "\"sigmoid\"", "if", "not", "self", ".", "is_multilabel", "else", "\"log_softmax\"", "\n", "self", ".", "predictor", "=", "SentimentPredictor", "(", "\n", "embed", "=", "self", ".", "emb_layer", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ",", "\n", "output_size", "=", "self", ".", "nb_classes", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "layer", "=", "self", ".", "sentence_encoder_layer_type", ",", "\n", "nonlinearity", "=", "nonlinearity_str", ",", "\n", ")", "\n", "\n", "# initialize params using xavier initialization for weights and zero for biases", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.spectra.SPECTRARationalizer.forward": [[114, 127], ["spectra.SPECTRARationalizer.generator", "spectra.SPECTRARationalizer.predictor"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "x", ":", "torch", ".", "LongTensor", ",", "current_epoch", "=", "None", ",", "mask", ":", "torch", ".", "BoolTensor", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Compute forward-pass.\n\n        :param x: input ids tensor. torch.LongTensor of shape [B, T]\n        :param mask: mask tensor for padding positions. torch.BoolTensor of shape [B, T]\n        :return: the output from SentimentPredictor. Torch.Tensor of shape [B, C]\n        \"\"\"", "\n", "z", "=", "self", ".", "generator", "(", "x", ",", "current_epoch", "=", "self", ".", "current_epoch", ",", "mask", "=", "mask", ")", "\n", "y_hat", "=", "self", ".", "predictor", "(", "x", ",", "z", ",", "mask", "=", "mask", ")", "\n", "return", "z", ",", "y_hat", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.spectra.SPECTRARationalizer.get_loss": [[128, 155], ["spectra.SPECTRARationalizer.criterion", "rationalizers.utils.get_z_stats", "loss_vec.mean.mean.mean", "float", "loss_vec.mean.mean.mean", "float", "float", "float", "float", "loss_vec.mean.mean.item", "loss_vec.mean.mean.item"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.get_z_stats", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean"], ["", "def", "get_loss", "(", "self", ",", "y_hat", ",", "y", ",", "prefix", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param y_hat: predictions from SentimentPredictor. Torch.Tensor of shape [B, C]\n        :param y: tensor with gold labels. torch.BoolTensor of shape [B]\n        :param mask: mask tensor for padding positions. torch.BoolTensor of shape [B, T]\n        :return: tuple containing:\n            `loss cost (torch.FloatTensor)`: the result of the loss function\n            `loss stats (dict): dict with loss statistics\n        \"\"\"", "\n", "stats", "=", "{", "}", "\n", "loss_vec", "=", "self", ".", "criterion", "(", "y_hat", ",", "y", ")", "# [B] or [B,C]", "\n", "\n", "# main MSE loss for p(y | x,z)", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "loss_vec", "=", "loss_vec", ".", "mean", "(", "1", ")", "# [B,C] -> [B]", "\n", "stats", "[", "\"mse\"", "]", "=", "float", "(", "loss_vec", ".", "item", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "loss", "=", "loss_vec", ".", "mean", "(", ")", "# [1]", "\n", "stats", "[", "\"criterion\"", "]", "=", "float", "(", "loss", ".", "item", "(", ")", ")", "# [1]", "\n", "\n", "# latent selection stats", "\n", "", "num_0", ",", "num_c", ",", "num_1", ",", "total", "=", "get_z_stats", "(", "self", ".", "generator", ".", "z", ",", "mask", ")", "\n", "stats", "[", "prefix", "+", "\"_p0\"", "]", "=", "num_0", "/", "float", "(", "total", ")", "\n", "stats", "[", "prefix", "+", "\"_pc\"", "]", "=", "num_c", "/", "float", "(", "total", ")", "\n", "stats", "[", "prefix", "+", "\"_ps\"", "]", "=", "(", "num_c", "+", "num_1", ")", "/", "float", "(", "total", ")", "\n", "\n", "return", "loss", ",", "stats", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.__init__": [[24, 136], ["rationalizers.lightning_models.highlights.base.BaseRationalizer.__init__", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "h_params.get", "bernoulli.BernoulliRationalizer.save_hyperparameters", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Accuracy", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Precision", "pytorch_lightning.metrics.Recall", "pytorch_lightning.metrics.Recall", "pytorch_lightning.metrics.Recall", "rationalizers.builders.build_embedding_weights", "torch.nn.Embedding", "rationalizers.modules.generators.BernoulliIndependentGenerator", "rationalizers.modules.predictors.SentimentPredictor", "bernoulli.BernoulliRationalizer.init_weights", "h_params.get"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_embedding_weights", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SelfAdditiveScorer.init_weights"], ["def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ":", "StaticTokenizerEncoder", ",", "\n", "nb_classes", ":", "int", ",", "\n", "is_multilabel", ":", "bool", ",", "\n", "h_params", ":", "dict", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param tokenizer (object): torchnlp tokenizer object\n        :param nb_classes (int): number of classes used to create the last layer\n        :param multilabel (bool): whether the problem is multilabel or not (it depends on the dataset)\n        :param h_params (dict): hyperparams dict. See docs for more info.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "tokenizer", ",", "nb_classes", ",", "is_multilabel", ",", "h_params", ")", "\n", "\n", "# model arch:", "\n", "self", ".", "vocab_size", "=", "tokenizer", ".", "vocab_size", "\n", "self", ".", "emb_type", "=", "h_params", ".", "get", "(", "\"emb_type\"", ",", "\"random\"", ")", "\n", "self", ".", "emb_path", "=", "h_params", ".", "get", "(", "\"emb_path\"", ",", "None", ")", "\n", "self", ".", "emb_size", "=", "h_params", ".", "get", "(", "\"emb_size\"", ",", "300", ")", "\n", "self", ".", "emb_requires_grad", "=", "not", "h_params", ".", "get", "(", "\"embed_fixed\"", ",", "True", ")", "\n", "self", ".", "hidden_size", "=", "h_params", ".", "get", "(", "\"hidden_size\"", ",", "150", ")", "\n", "self", ".", "dropout", "=", "h_params", ".", "get", "(", "\"dropout\"", ",", "0.5", ")", "\n", "self", ".", "sentence_encoder_layer_type", "=", "h_params", ".", "get", "(", "\n", "\"sentence_encoder_layer_type\"", ",", "\"rcnn\"", "\n", ")", "\n", "self", ".", "contiguous", "=", "h_params", ".", "get", "(", "\"contiguous\"", ",", "False", ")", "\n", "self", ".", "topk", "=", "h_params", ".", "get", "(", "\"topk\"", ",", "False", ")", "\n", "self", ".", "relaxed", "=", "h_params", ".", "get", "(", "\"relaxed\"", ",", "False", ")", "\n", "self", ".", "budget", "=", "h_params", ".", "get", "(", "\"budget\"", ",", "10", ")", "\n", "\n", "# loss fn:", "\n", "self", ".", "lambda_0", "=", "h_params", ".", "get", "(", "\"lambda_0\"", ",", "0.0", ")", "\n", "self", ".", "lambda_1", "=", "h_params", ".", "get", "(", "\"lambda_1\"", ",", "0.0", ")", "\n", "self", ".", "baseline", "=", "h_params", ".", "get", "(", "\"baseline\"", ",", "False", ")", "\n", "\n", "if", "self", ".", "baseline", ":", "\n", "            ", "self", ".", "mean_baseline", "=", "0", "\n", "self", ".", "n_points", "=", "0", "\n", "\n", "# global steps for board loggers", "\n", "", "self", ".", "eval_global_step", "=", "{", "\"val\"", ":", "0", ",", "\"test\"", ":", "0", "}", "\n", "\n", "# save hyperparams to checkpoint", "\n", "self", ".", "save_hyperparameters", "(", "h_params", ")", "\n", "\n", "# define metrics", "\n", "self", ".", "train_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "val_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "test_accuracy", "=", "pl", ".", "metrics", ".", "Accuracy", "(", ")", "\n", "self", ".", "train_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "val_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "test_precision", "=", "pl", ".", "metrics", ".", "Precision", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "train_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "val_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "self", ".", "test_recall", "=", "pl", ".", "metrics", ".", "Recall", "(", "\n", "num_classes", "=", "nb_classes", ",", "\n", "average", "=", "\"macro\"", ",", "\n", ")", "\n", "\n", "# load word embedding weights based on `emb_type` and define the embedding layer", "\n", "embedding_weights", "=", "build_embedding_weights", "(", "\n", "self", ".", "tokenizer", ".", "vocab", ",", "self", ".", "emb_type", ",", "self", ".", "emb_path", ",", "self", ".", "emb_size", "\n", ")", "\n", "self", ".", "emb_layer", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "vocab_size", ",", "\n", "self", ".", "emb_size", ",", "\n", "padding_idx", "=", "constants", ".", "PAD_ID", ",", "\n", "_weight", "=", "embedding_weights", ",", "\n", ")", "\n", "self", ".", "emb_layer", ".", "weight", ".", "requires_grad", "=", "self", ".", "emb_requires_grad", "\n", "\n", "# create generator", "\n", "self", ".", "generator", "=", "BernoulliIndependentGenerator", "(", "\n", "embed", "=", "self", ".", "emb_layer", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "layer", "=", "self", ".", "sentence_encoder_layer_type", ",", "\n", "budget", "=", "self", ".", "budget", ",", "\n", "contiguous", "=", "self", ".", "contiguous", ",", "\n", "topk", "=", "self", ".", "topk", ",", "\n", "relaxed", "=", "self", ".", "relaxed", ",", "\n", ")", "\n", "\n", "# create predictor", "\n", "nonlinearity_str", "=", "\"sigmoid\"", "if", "not", "self", ".", "is_multilabel", "else", "\"log_softmax\"", "\n", "self", ".", "predictor", "=", "SentimentPredictor", "(", "\n", "embed", "=", "self", ".", "emb_layer", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ",", "\n", "output_size", "=", "self", ".", "nb_classes", ",", "\n", "dropout", "=", "self", ".", "dropout", ",", "\n", "layer", "=", "self", ".", "sentence_encoder_layer_type", ",", "\n", "nonlinearity", "=", "nonlinearity_str", ",", "\n", ")", "\n", "\n", "# initialize params using xavier initialization for weights and zero for biases", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.get_loss": [[137, 228], ["bernoulli.BernoulliRationalizer.criterion", "loss_vec.mean.mean.mean", "bernoulli.BernoulliRationalizer.generator.z.squeeze", "m.log_prob().squeeze", "m.log_prob().squeeze", "torch.where", "torch.where", "z.view.view.view", "z.view.view.sum", "zdiff.abs().sum.abs().sum.abs().sum", "zsum_cost.item", "zdiff_cost.mean().item", "sparsity_cost.item", "cost_vec.mean", "cost_vec.mean.item", "cost_logpz.item", "loss_vec.mean.mean.item", "rationalizers.utils.get_z_stats", "float", "main_loss.item", "loss_vec.mean.mean.mean", "loss_vec.mean.mean.item", "torch.where.new_zeros", "z.view.sum.mean", "zdiff.abs().sum.abs().sum.mean", "pred_diff.mean.mean.mean", "pred_diff.mean.mean.item", "float", "float", "float", "m.log_prob", "m.log_prob", "zdiff.abs().sum.abs().sum.abs", "zdiff_cost.mean", "loss_vec.mean.mean.detach", "cost_vec.detach().mean", "y_hat.max", "y_hat.min", "torch.where.sum", "torch.where.sum", "cost_vec.detach"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.get_z_stats", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean"], ["", "def", "get_loss", "(", "self", ",", "y_hat", ",", "y", ",", "mask", "=", "None", ",", "baseline", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param y_hat: predictions from SentimentPredictor. Torch.Tensor of shape [B, C]\n        :param y: tensor with gold labels. torch.BoolTensor of shape [B]\n        :param mask: mask tensor for padding positions. torch.BoolTensor of shape [B, T]\n        :return: tuple containing:\n            `loss cost (torch.FloatTensor)`: the result of the loss function\n            `loss stats (dict): dict with loss statistics\n        \"\"\"", "\n", "stats", "=", "{", "}", "\n", "\n", "loss_vec", "=", "self", ".", "criterion", "(", "y_hat", ",", "y", ")", "# [B] or [B,C]", "\n", "\n", "# main MSE loss for p(y | x,z)", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "loss_vec", "=", "loss_vec", ".", "mean", "(", "1", ")", "# [B,C] -> [B]", "\n", "", "loss", "=", "loss_vec", ".", "mean", "(", ")", "# [1]", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "stats", "[", "\"mse\"", "]", "=", "loss", ".", "item", "(", ")", "# [1]", "\n", "\n", "", "coherent_factor", "=", "self", ".", "lambda_1", "\n", "sparsity_factor", "=", "self", ".", "lambda_0", "\n", "\n", "# compute generator loss", "\n", "z", "=", "self", ".", "generator", ".", "z", ".", "squeeze", "(", ")", "# [B, T]", "\n", "\n", "# get P(z = 0 | x) and P(z = 1 | x)", "\n", "m", "=", "self", ".", "generator", ".", "z_dists", "[", "0", "]", "\n", "logp_z0", "=", "m", ".", "log_prob", "(", "0.0", ")", ".", "squeeze", "(", "2", ")", "# [B,T], log P(z = 0 | x)", "\n", "logp_z1", "=", "m", ".", "log_prob", "(", "1.0", ")", ".", "squeeze", "(", "2", ")", "# [B,T], log P(z = 1 | x)", "\n", "\n", "# compute log p(z|x) for each case (z==0 and z==1) and mask", "\n", "logpz", "=", "torch", ".", "where", "(", "z", "==", "0", ",", "logp_z0", ",", "logp_z1", ")", "\n", "logpz", "=", "torch", ".", "where", "(", "mask", ",", "logpz", ",", "logpz", ".", "new_zeros", "(", "[", "1", "]", ")", ")", "\n", "\n", "z", "=", "z", ".", "view", "(", "loss_vec", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "# sparsity regularization", "\n", "zsum", "=", "z", ".", "sum", "(", "1", ")", "\n", "zdiff", "=", "z", "[", ":", ",", "1", ":", "]", "-", "z", "[", ":", ",", ":", "-", "1", "]", "\n", "zdiff", "=", "zdiff", ".", "abs", "(", ")", ".", "sum", "(", "1", ")", "# [B]", "\n", "\n", "zsum_cost", "=", "sparsity_factor", "*", "zsum", ".", "mean", "(", "0", ")", "\n", "stats", "[", "\"zsum_cost\"", "]", "=", "zsum_cost", ".", "item", "(", ")", "\n", "\n", "zdiff_cost", "=", "coherent_factor", "*", "zdiff", ".", "mean", "(", "0", ")", "\n", "stats", "[", "\"zdiff_cost\"", "]", "=", "zdiff_cost", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n", "sparsity_cost", "=", "zsum_cost", "+", "zdiff_cost", "\n", "stats", "[", "\"sparsity_cost\"", "]", "=", "sparsity_cost", ".", "item", "(", ")", "\n", "\n", "cost_vec", "=", "loss_vec", ".", "detach", "(", ")", "+", "zsum", "*", "sparsity_factor", "+", "zdiff", "*", "coherent_factor", "\n", "\n", "if", "self", ".", "baseline", ":", "\n", "            ", "cost_logpz", "=", "(", "(", "cost_vec", "-", "self", ".", "mean_baseline", ")", "*", "logpz", ".", "sum", "(", "1", ")", ")", ".", "mean", "(", "\n", "0", "\n", ")", "# cost_vec is neg reward", "\n", "", "else", ":", "\n", "            ", "cost_logpz", "=", "(", "cost_vec", "*", "logpz", ".", "sum", "(", "1", ")", ")", ".", "mean", "(", "0", ")", "# cost_vec is neg reward", "\n", "", "obj", "=", "cost_vec", ".", "mean", "(", ")", "# MSE with regularizers = neg reward", "\n", "stats", "[", "\"obj\"", "]", "=", "obj", ".", "item", "(", ")", "\n", "\n", "if", "self", ".", "baseline", ":", "\n", "            ", "self", ".", "n_points", "+=", "1.0", "\n", "self", ".", "mean_baseline", "+=", "(", "\n", "cost_vec", ".", "detach", "(", ")", ".", "mean", "(", ")", "-", "self", ".", "mean_baseline", "\n", ")", "/", "self", ".", "n_points", "\n", "\n", "# pred diff doesn't do anything if only 1 aspect being trained", "\n", "", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "pred_diff", "=", "y_hat", ".", "max", "(", "dim", "=", "1", ")", "[", "0", "]", "-", "y_hat", ".", "min", "(", "dim", "=", "1", ")", "[", "0", "]", "\n", "pred_diff", "=", "pred_diff", ".", "mean", "(", ")", "\n", "stats", "[", "\"pred_diff\"", "]", "=", "pred_diff", ".", "item", "(", ")", "\n", "\n", "# generator cost", "\n", "", "stats", "[", "\"cost_g\"", "]", "=", "cost_logpz", ".", "item", "(", ")", "\n", "\n", "# predictor cost", "\n", "stats", "[", "\"cost_p\"", "]", "=", "loss", ".", "item", "(", ")", "\n", "\n", "# latent selection stats", "\n", "num_0", ",", "num_c", ",", "num_1", ",", "total", "=", "get_z_stats", "(", "self", ".", "generator", ".", "z", ",", "mask", ")", "\n", "stats", "[", "\"p0\"", "]", "=", "num_0", "/", "float", "(", "total", ")", "\n", "stats", "[", "\"pc\"", "]", "=", "num_c", "/", "float", "(", "total", ")", "\n", "stats", "[", "\"p1\"", "]", "=", "num_1", "/", "float", "(", "total", ")", "\n", "stats", "[", "\"selected\"", "]", "=", "num_1", "\n", "stats", "[", "\"total\"", "]", "=", "float", "(", "total", ")", "\n", "\n", "main_loss", "=", "loss", "+", "cost_logpz", "\n", "stats", "[", "\"main_loss\"", "]", "=", "main_loss", ".", "item", "(", ")", "\n", "return", "main_loss", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.training_step": [[229, 283], ["bernoulli.BernoulliRationalizer.", "bernoulli.BernoulliRationalizer.get_loss", "bernoulli.BernoulliRationalizer.log", "bernoulli.BernoulliRationalizer.log", "bernoulli.BernoulliRationalizer.log", "y_hat.view", "labels.view", "loss.item"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.get_loss"], ["", "def", "training_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Compute forward-pass, calculate loss and log metrics.\n\n        :param batch: The dict output from the data module with the following items:\n            `input_ids`: torch.LongTensor of shape [B, T],\n            `lengths`: torch.LongTensor of shape [B]\n            `labels`: torch.LongTensor of shape [B, C]\n            `tokens`: list of strings\n        :param batch_idx: integer displaying index of this batch\n        :return: pytorch_lightning.Result log object\n        \"\"\"", "\n", "input_ids", "=", "batch", "[", "\"input_ids\"", "]", "\n", "labels", "=", "batch", "[", "\"labels\"", "]", "\n", "mask", "=", "input_ids", "!=", "constants", ".", "PAD_ID", "\n", "\n", "# forward-pass", "\n", "z", ",", "y_hat", "=", "self", "(", "input_ids", ",", "mask", "=", "mask", ")", "\n", "# compute loss", "\n", "y_hat", "=", "y_hat", "if", "not", "self", ".", "is_multilabel", "else", "y_hat", ".", "view", "(", "-", "1", ",", "self", ".", "nb_classes", ")", "\n", "y", "=", "labels", "if", "not", "self", ".", "is_multilabel", "else", "labels", ".", "view", "(", "-", "1", ")", "\n", "loss", ",", "loss_stats", "=", "self", ".", "get_loss", "(", "y_hat", ",", "y", ",", "mask", "=", "mask", ")", "\n", "\n", "# logger=False because they are going to be logged via loss_stats", "\n", "self", ".", "log", "(", "\n", "\"p1\"", ",", "\n", "loss_stats", "[", "\"p1\"", "]", ",", "\n", "prog_bar", "=", "True", ",", "\n", "logger", "=", "False", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "False", ",", "\n", ")", "\n", "self", ".", "log", "(", "\n", "\"train_sum_loss\"", ",", "\n", "loss", ".", "item", "(", ")", ",", "\n", "prog_bar", "=", "True", ",", "\n", "logger", "=", "False", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "False", ",", "\n", ")", "\n", "self", ".", "log", "(", "\n", "\"train_obj_loss\"", ",", "\n", "loss_stats", "[", "\"obj\"", "]", ",", "\n", "prog_bar", "=", "True", ",", "\n", "logger", "=", "False", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "False", ",", "\n", ")", "\n", "# compute metrics for this step", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "y", "=", "(", "y", ">=", "0.5", ")", ".", "long", "(", ")", "\n", "\n", "# return the loss tensor to PTL", "\n", "", "return", "{", "\"loss\"", ":", "loss", ",", "\"obj\"", ":", "loss_stats", "[", "\"obj\"", "]", ",", "\"p1\"", ":", "loss_stats", "[", "\"p1\"", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.validation_step": [[284, 287], ["bernoulli.BernoulliRationalizer._shared_eval_step"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_step"], ["", "def", "validation_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ")", ":", "\n", "        ", "output", "=", "self", ".", "_shared_eval_step", "(", "batch", ",", "batch_idx", ",", "prefix", "=", "\"val\"", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.test_step": [[288, 291], ["bernoulli.BernoulliRationalizer._shared_eval_step"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_step"], ["", "def", "test_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ")", ":", "\n", "        ", "output", "=", "self", ".", "_shared_eval_step", "(", "batch", ",", "batch_idx", ",", "prefix", "=", "\"test\"", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_step": [[292, 350], ["bernoulli.BernoulliRationalizer.", "bernoulli.BernoulliRationalizer.get_loss", "bernoulli.BernoulliRationalizer.log", "bernoulli.BernoulliRationalizer.log", "rationalizers.utils.get_rationales", "y_hat.view", "labels.view", "loss.item", "loss.item", "batch[].tolist", "batch[].tolist", "batch.keys", "loss_stats.keys"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.get_loss", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.get_rationales"], ["", "def", "_shared_eval_step", "(", "self", ",", "batch", ":", "dict", ",", "batch_idx", ":", "int", ",", "prefix", ":", "str", ")", ":", "\n", "        ", "input_ids", "=", "batch", "[", "\"input_ids\"", "]", "\n", "labels", "=", "batch", "[", "\"labels\"", "]", "\n", "mask", "=", "input_ids", "!=", "constants", ".", "PAD_ID", "\n", "\n", "# forward-pass", "\n", "z", ",", "y_hat", "=", "self", "(", "input_ids", ",", "mask", "=", "mask", ")", "\n", "\n", "# compute loss", "\n", "y_hat", "=", "y_hat", "if", "not", "self", ".", "is_multilabel", "else", "y_hat", ".", "view", "(", "-", "1", ",", "self", ".", "nb_classes", ")", "\n", "y", "=", "labels", "if", "not", "self", ".", "is_multilabel", "else", "labels", ".", "view", "(", "-", "1", ")", "\n", "loss", ",", "loss_stats", "=", "self", ".", "get_loss", "(", "y_hat", ",", "y", ",", "mask", "=", "mask", ")", "\n", "\n", "# log stats", "\n", "self", ".", "log", "(", "\n", "f\"{prefix}_sum_loss\"", ",", "\n", "loss", ".", "item", "(", ")", ",", "\n", "prog_bar", "=", "True", ",", "\n", "logger", "=", "True", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "\n", ")", "\n", "self", ".", "log", "(", "\n", "f\"{prefix}_obj_loss\"", ",", "\n", "loss_stats", "[", "\"obj\"", "]", ",", "\n", "prog_bar", "=", "True", ",", "\n", "logger", "=", "True", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "\n", ")", "\n", "\n", "# log rationales", "\n", "ids_rationales", ",", "rationales", "=", "get_rationales", "(", "\n", "self", ".", "tokenizer", ",", "input_ids", ",", "z", ",", "batch", "[", "\"lengths\"", "]", "\n", ")", "\n", "\n", "# compute metrics for this step", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "y", "=", "(", "y", ">=", "0.5", ")", ".", "long", "(", ")", "\n", "\n", "# output to be stacked across iterations", "\n", "", "output", "=", "{", "\n", "f\"{prefix}_sum_loss\"", ":", "loss", ".", "item", "(", ")", ",", "\n", "f\"{prefix}_obj_loss\"", ":", "loss_stats", "[", "\"obj\"", "]", ",", "\n", "f\"{prefix}_p1\"", ":", "loss_stats", "[", "\"p1\"", "]", ",", "\n", "f\"{prefix}_ids_rationales\"", ":", "ids_rationales", ",", "\n", "f\"{prefix}_rationales\"", ":", "rationales", ",", "\n", "f\"{prefix}_predictions\"", ":", "y_hat", ",", "\n", "f\"{prefix}_tokens\"", ":", "batch", "[", "\"tokens\"", "]", ",", "\n", "f\"{prefix}_labels\"", ":", "batch", "[", "\"labels\"", "]", ".", "tolist", "(", ")", ",", "\n", "f\"{prefix}_lengths\"", ":", "batch", "[", "\"lengths\"", "]", ".", "tolist", "(", ")", ",", "\n", "}", "\n", "if", "\"annotations\"", "in", "batch", ".", "keys", "(", ")", ":", "\n", "            ", "output", "[", "f\"{prefix}_annotations\"", "]", "=", "batch", "[", "\"annotations\"", "]", "\n", "", "if", "\"mse\"", "in", "loss_stats", ".", "keys", "(", ")", ":", "\n", "            ", "output", "[", "f\"{prefix}_mse\"", "]", "=", "loss_stats", "[", "\"mse\"", "]", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.training_epoch_end": [[351, 358], ["print"], "methods", ["None"], ["", "def", "training_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", ":", "\n", "        ", "\"\"\"\n        PTL hook.\n\n        :param outputs: list of dicts representing the stacked outputs from training_step\n        \"\"\"", "\n", "print", "(", "\"\\n Epoch Ended. \\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.validation_epoch_end": [[359, 361], ["bernoulli.BernoulliRationalizer._shared_eval_epoch_end"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_epoch_end"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", ":", "\n", "        ", "self", ".", "_shared_eval_epoch_end", "(", "outputs", ",", "prefix", "=", "\"val\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer.test_epoch_end": [[362, 364], ["bernoulli.BernoulliRationalizer._shared_eval_epoch_end"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_epoch_end"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ":", "list", ")", ":", "\n", "        ", "self", ".", "_shared_eval_epoch_end", "(", "outputs", ",", "prefix", "=", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.highlights.bernoulli.BernoulliRationalizer._shared_eval_epoch_end": [[365, 513], ["shell_logger.info", "shell_logger.info", "shell_logger.info", "bernoulli.BernoulliRationalizer.logger.agg_and_log_metrics", "bernoulli.BernoulliRationalizer.log", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "shell_logger.info", "bernoulli.BernoulliRationalizer.log", "rationalizers.modules.metrics.evaluate_rationale", "shell_logger.info", "shell_logger.info", "shell_logger.info", "bernoulli.BernoulliRationalizer.logger.log_metrics", "shell_logger.info", "shell_logger.info", "shell_logger.info", "shell_logger.info", "bernoulli.BernoulliRationalizer.log", "outputs[].keys", "stacked_outputs.keys", "torch.argmax", "torch.tensor", "bernoulli.BernoulliRationalizer.val_accuracy", "bernoulli.BernoulliRationalizer.val_precision", "bernoulli.BernoulliRationalizer.val_recall", "torch.argmax", "torch.tensor", "bernoulli.BernoulliRationalizer.test_accuracy", "bernoulli.BernoulliRationalizer.test_precision", "bernoulli.BernoulliRationalizer.test_recall", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.metrics.evaluate_rationale"], ["", "def", "_shared_eval_epoch_end", "(", "self", ",", "outputs", ":", "list", ",", "prefix", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        PTL hook. Perform validation at the end of an epoch.\n\n        :param outputs: list of dicts representing the stacked outputs from validation_step\n        :param prefix: `val` or `test`\n        \"\"\"", "\n", "# assume that `outputs` is a list containing dicts with the same keys", "\n", "stacked_outputs", "=", "{", "k", ":", "[", "x", "[", "k", "]", "for", "x", "in", "outputs", "]", "for", "k", "in", "outputs", "[", "0", "]", ".", "keys", "(", ")", "}", "\n", "\n", "# average across batches", "\n", "avg_outputs", "=", "{", "\n", "f\"avg_{prefix}_sum_loss\"", ":", "np", ".", "mean", "(", "stacked_outputs", "[", "f\"{prefix}_sum_loss\"", "]", ")", ",", "\n", "f\"avg_{prefix}_obj_loss\"", ":", "np", ".", "mean", "(", "stacked_outputs", "[", "f\"{prefix}_obj_loss\"", "]", ")", ",", "\n", "f\"avg_{prefix}_p1\"", ":", "np", ".", "mean", "(", "stacked_outputs", "[", "f\"{prefix}_p1\"", "]", ")", ",", "\n", "}", "\n", "\n", "shell_logger", ".", "info", "(", "\n", "f\"Avg {prefix} sum loss: {avg_outputs[f'avg_{prefix}_sum_loss']:.4}\"", "\n", ")", "\n", "shell_logger", ".", "info", "(", "\n", "f\"Avg {prefix} obj loss: {avg_outputs[f'avg_{prefix}_obj_loss']:.4}\"", "\n", ")", "\n", "shell_logger", ".", "info", "(", "f\"Avg {prefix} p1: {avg_outputs[f'avg_{prefix}_p1']:.4}\"", ")", "\n", "\n", "dict_metrics", "=", "{", "\n", "f\"avg_{prefix}_p1\"", ":", "avg_outputs", "[", "f\"avg_{prefix}_p1\"", "]", ",", "\n", "f\"avg_{prefix}_sum_loss\"", ":", "avg_outputs", "[", "f\"avg_{prefix}_sum_loss\"", "]", ",", "\n", "}", "\n", "\n", "if", "not", "self", ".", "is_multilabel", ":", "\n", "            ", "avg_outputs", "[", "f\"avg_{prefix}_mse\"", "]", "=", "np", ".", "mean", "(", "stacked_outputs", "[", "f\"{prefix}_mse\"", "]", ")", "\n", "shell_logger", ".", "info", "(", "\n", "f\"Avg {prefix} MSE: {avg_outputs[f'avg_{prefix}_mse']:.4}\"", "\n", ")", "\n", "dict_metrics", "[", "f\"avg_{prefix}_mse\"", "]", "=", "avg_outputs", "[", "f\"avg_{prefix}_mse\"", "]", "\n", "\n", "self", ".", "log", "(", "\n", "f\"{prefix}_MSE\"", ",", "\n", "dict_metrics", "[", "f\"avg_{prefix}_mse\"", "]", ",", "\n", "prog_bar", "=", "False", ",", "\n", "logger", "=", "True", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "\n", ")", "\n", "\n", "", "self", ".", "logger", ".", "agg_and_log_metrics", "(", "dict_metrics", ",", "self", ".", "current_epoch", ")", "\n", "\n", "# only evaluate rationales on the test set and if we have annotation (only for beer dataset)", "\n", "if", "prefix", "==", "\"test\"", "and", "\"test_annotations\"", "in", "stacked_outputs", ".", "keys", "(", ")", ":", "\n", "            ", "metrics", "=", "evaluate_rationale", "(", "\n", "stacked_outputs", "[", "\"test_ids_rationales\"", "]", ",", "\n", "stacked_outputs", "[", "\"test_annotations\"", "]", ",", "\n", "stacked_outputs", "[", "\"test_lengths\"", "]", ",", "\n", ")", "\n", "\n", "shell_logger", ".", "info", "(", "\n", "f\"Rationales macro precision: {metrics[f'macro_precision']:.4}\"", "\n", ")", "\n", "shell_logger", ".", "info", "(", "f\"Rationales macro recall: {metrics[f'macro_recall']:.4}\"", ")", "\n", "shell_logger", ".", "info", "(", "f\"Rationales macro f1: {metrics[f'f1_score']:.4}\"", ")", "\n", "\n", "# log classification metrics", "\n", "", "if", "self", ".", "is_multilabel", ":", "\n", "            ", "if", "prefix", "==", "\"val\"", ":", "\n", "                ", "val_preds", "=", "torch", ".", "argmax", "(", "\n", "torch", ".", "cat", "(", "stacked_outputs", "[", "\"val_predictions\"", "]", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "val_labels", "=", "torch", ".", "tensor", "(", "\n", "[", "\n", "item", "\n", "for", "sublist", "in", "stacked_outputs", "[", "\"val_labels\"", "]", "\n", "for", "item", "in", "sublist", "\n", "]", ",", "\n", "device", "=", "val_preds", ".", "device", ",", "\n", ")", "\n", "accuracy", "=", "self", ".", "val_accuracy", "(", "val_preds", ",", "val_labels", ")", "\n", "precision", "=", "self", ".", "val_precision", "(", "val_preds", ",", "val_labels", ")", "\n", "recall", "=", "self", ".", "val_recall", "(", "val_preds", ",", "val_labels", ")", "\n", "f1_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "class_metrics", "=", "{", "\n", "f\"{prefix}_precision\"", ":", "precision", ",", "\n", "f\"{prefix}_recall\"", ":", "recall", ",", "\n", "f\"{prefix}_f1score\"", ":", "f1_score", ",", "\n", "f\"{prefix}_accuracy\"", ":", "accuracy", ",", "\n", "}", "\n", "\n", "", "else", ":", "\n", "                ", "test_preds", "=", "torch", ".", "argmax", "(", "\n", "torch", ".", "cat", "(", "stacked_outputs", "[", "\"test_predictions\"", "]", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "test_labels", "=", "torch", ".", "tensor", "(", "\n", "[", "\n", "item", "\n", "for", "sublist", "in", "stacked_outputs", "[", "\"test_labels\"", "]", "\n", "for", "item", "in", "sublist", "\n", "]", ",", "\n", "device", "=", "test_preds", ".", "device", ",", "\n", ")", "\n", "accuracy", "=", "self", ".", "test_accuracy", "(", "test_preds", ",", "test_labels", ")", "\n", "precision", "=", "self", ".", "test_precision", "(", "test_preds", ",", "test_labels", ")", "\n", "recall", "=", "self", ".", "test_recall", "(", "test_preds", ",", "test_labels", ")", "\n", "f1_score", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", ")", "\n", "class_metrics", "=", "{", "\n", "f\"{prefix}_precision\"", ":", "precision", ",", "\n", "f\"{prefix}_recall\"", ":", "recall", ",", "\n", "f\"{prefix}_f1score\"", ":", "f1_score", ",", "\n", "f\"{prefix}_accuracy\"", ":", "accuracy", ",", "\n", "}", "\n", "\n", "", "self", ".", "logger", ".", "log_metrics", "(", "class_metrics", ",", "step", "=", "None", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} accuracy: {accuracy:.4}\"", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} precision: {precision:.4}\"", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} recall: {recall:.4}\"", ")", "\n", "shell_logger", ".", "info", "(", "f\"{prefix} f1: {f1_score:.4}\"", ")", "\n", "\n", "self", ".", "log", "(", "\n", "f\"{prefix}_f1score\"", ",", "\n", "f1_score", ",", "\n", "prog_bar", "=", "False", ",", "\n", "logger", "=", "True", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "\n", ")", "\n", "\n", "", "self", ".", "log", "(", "\n", "f\"avg_{prefix}_sum_loss\"", ",", "\n", "dict_metrics", "[", "f\"avg_{prefix}_sum_loss\"", "]", ",", "\n", "prog_bar", "=", "False", ",", "\n", "logger", "=", "True", ",", "\n", "on_step", "=", "False", ",", "\n", "on_epoch", "=", "True", ",", "\n", ")", "\n", "\n", "if", "self", ".", "is_multilabel", ":", "\n", "            ", "output", "=", "{", "\n", "f\"avg_{prefix}_sum_loss\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_sum_loss\"", "]", ",", "\n", "f\"avg_{prefix}_p1\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_p1\"", "]", ",", "\n", "f\"{prefix}_precision\"", ":", "precision", ",", "\n", "f\"{prefix}_recall\"", ":", "recall", ",", "\n", "f\"{prefix}_f1score\"", ":", "f1_score", ",", "\n", "f\"{prefix}_accuracy\"", ":", "accuracy", ",", "\n", "}", "\n", "", "else", ":", "\n", "            ", "output", "=", "{", "\n", "f\"avg_{prefix}_sum_loss\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_sum_loss\"", "]", ",", "\n", "f\"avg_{prefix}_p1\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_p1\"", "]", ",", "\n", "f\"avg_{prefix}_MSE\"", ":", "dict_metrics", "[", "f\"avg_{prefix}_mse\"", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings.LPSparseMAPFaithfulMatching.__init__": [[26, 80], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "rationalizers.builders.build_sentence_encoder", "rationalizers.builders.build_sentence_encoder", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_sentence_encoder", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_sentence_encoder"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed", ":", "nn", ".", "Embedding", "=", "None", ",", "\n", "hidden_size", ":", "int", "=", "200", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "layer", ":", "str", "=", "\"lstm\"", ",", "\n", "bidirectional", ":", "bool", "=", "True", ",", "\n", "temperature", ":", "float", "=", "1.0", ",", "\n", "budget", ":", "float", "=", "1.0", ",", "\n", "nonlinearity", ":", "str", "=", "\"sigmoid\"", ",", "\n", "output_size", ":", "int", "=", "1", ",", "\n", "matching_type", ":", "str", "=", "\"AtMostONE\"", ",", "\n", "faithful", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "faithful", "=", "faithful", "\n", "self", ".", "matching_type", "=", "matching_type", "\n", "emb_size", "=", "embed", ".", "weight", ".", "shape", "[", "1", "]", "\n", "enc_size", "=", "2", "*", "hidden_size", "if", "bidirectional", "else", "hidden_size", "\n", "self", ".", "embed_layer", "=", "nn", ".", "Sequential", "(", "embed", ",", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "self", ".", "context_lstm", "=", "build_sentence_encoder", "(", "\n", "layer", ",", "\n", "emb_size", ",", "\n", "hidden_size", ",", "\n", "bidirectional", "=", "True", ",", "\n", ")", "\n", "self", ".", "z", "=", "None", "# z samples", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "budget", "=", "budget", "\n", "\n", "if", "self", ".", "faithful", ":", "\n", "            ", "self", ".", "projection_x1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "enc_size", ",", "hidden_size", ")", ",", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "self", ".", "projection_x2", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "enc_size", "+", "enc_size", ",", "hidden_size", ")", ",", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "projection", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "4", "*", "2", "*", "hidden_size", ",", "hidden_size", ")", ",", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "\n", "", "self", ".", "composition_lstm", "=", "build_sentence_encoder", "(", "\n", "layer", ",", "\n", "hidden_size", ",", "\n", "hidden_size", ",", "\n", "bidirectional", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "output_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "4", "*", "enc_size", ",", "output_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "if", "nonlinearity", "==", "\"sigmoid\"", "else", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings.LPSparseMAPFaithfulMatching.forward": [[82, 178], ["mask[].long().sum", "mask[].long().sum", "matchings.LPSparseMAPFaithfulMatching.embed_layer", "matchings.LPSparseMAPFaithfulMatching.embed_layer", "matchings.LPSparseMAPFaithfulMatching.context_lstm", "matchings.LPSparseMAPFaithfulMatching.context_lstm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "range", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "torch.stack().squeeze", "z.to.to.to", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "matchings.LPSparseMAPFaithfulMatching.composition_lstm", "matchings.LPSparseMAPFaithfulMatching.composition_lstm", "rationalizers.modules.matchings_utils.apply_multiple", "rationalizers.modules.matchings_utils.apply_multiple", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "matchings.LPSparseMAPFaithfulMatching.output_layer", "x2_h.transpose", "z.to.to.append", "z.to.to.transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "matchings.LPSparseMAPFaithfulMatching.projection_x1", "matchings.LPSparseMAPFaithfulMatching.projection_x2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "matchings.LPSparseMAPFaithfulMatching.projection", "matchings.LPSparseMAPFaithfulMatching.projection", "mask[].long", "mask[].long", "[].unsqueeze", "[].unsqueeze", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "rationalizers.modules.sparsemap.matching_smap_atmostone", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "rationalizers.modules.sparsemap.matching_smap_atmostone", "rationalizers.modules.sparsemap.matching_smap", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "rationalizers.modules.sparsemap.matching_smap", "rationalizers.modules.sparsemap.matching_smap_atmostone_budget", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "rationalizers.modules.sparsemap.matching_smap_atmostone_budget", "rationalizers.modules.matchings_utils.submul", "rationalizers.modules.matchings_utils.submul"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings_utils.apply_multiple", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings_utils.apply_multiple", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.sparsemap.matching_smap_atmostone", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.sparsemap.matching_smap_atmostone", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.sparsemap.matching_smap", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.sparsemap.matching_smap", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.sparsemap.matching_smap_atmostone_budget", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.sparsemap.matching_smap_atmostone_budget", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings_utils.submul", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings_utils.submul"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        :param x1: premise embeddings\n        :param x2: hypothesis embeddings\n        :param mask: list [mask_x1, mask_x2] -- mask should be true/1 for valid positions, false/0 for invalid ones.\n        \"\"\"", "\n", "batch_size", ",", "_", "=", "x1", ".", "shape", "\n", "\n", "lengths_x1", "=", "mask", "[", "0", "]", ".", "long", "(", ")", ".", "sum", "(", "1", ")", "\n", "lengths_x2", "=", "mask", "[", "1", "]", ".", "long", "(", ")", ".", "sum", "(", "1", ")", "\n", "mask_x1", "=", "mask", "[", "0", "]", "\n", "mask_x2", "=", "mask", "[", "1", "]", "\n", "\n", "emb_x1", "=", "self", ".", "embed_layer", "(", "x1", ")", "# [B, T, E]", "\n", "emb_x2", "=", "self", ".", "embed_layer", "(", "x2", ")", "# [B, D, E]", "\n", "\n", "# BiLSTM representation of the x1ise and x2thesis", "\n", "x1_h", ",", "_", "=", "self", ".", "context_lstm", "(", "emb_x1", ",", "mask_x1", ",", "lengths_x1", ")", "\n", "x2_h", ",", "_", "=", "self", ".", "context_lstm", "(", "emb_x2", ",", "mask_x2", ",", "lengths_x2", ")", "\n", "\n", "# [B, T, D]", "\n", "h_alignments", "=", "torch", ".", "bmm", "(", "x1_h", ",", "x2_h", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "\n", "z", "=", "[", "]", "\n", "for", "k", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "scores", "=", "h_alignments", "[", "k", "]", "/", "self", ".", "temperature", "\n", "\n", "if", "self", ".", "matching_type", "==", "\"AtMostONE\"", ":", "\n", "                ", "if", "self", ".", "training", ":", "\n", "                    ", "z_probs", "=", "matching_smap_atmostone", "(", "scores", ",", "max_iter", "=", "10", ")", "# [T,D]", "\n", "", "else", ":", "\n", "                    ", "z_probs", "=", "torch", ".", "zeros", "(", "scores", ".", "shape", ",", "device", "=", "scores", ".", "device", ")", "\n", "z_probs_sparsemap", "=", "matching_smap_atmostone", "(", "\n", "scores", "[", ":", "lengths_x1", "[", "k", "]", ",", ":", "lengths_x2", "[", "k", "]", "]", "/", "1e-3", ",", "max_iter", "=", "1000", "\n", ")", "\n", "z_probs", "[", ":", "lengths_x1", "[", "k", "]", ",", ":", "lengths_x2", "[", "k", "]", "]", "=", "z_probs_sparsemap", "\n", "\n", "", "", "if", "self", ".", "matching_type", "==", "\"XOR-AtMostONE\"", ":", "\n", "                ", "if", "self", ".", "training", ":", "\n", "                    ", "z_probs", "=", "matching_smap", "(", "scores", ",", "max_iter", "=", "10", ")", "# [T,D]", "\n", "", "else", ":", "\n", "                    ", "z_probs", "=", "torch", ".", "zeros", "(", "scores", ".", "shape", ",", "device", "=", "scores", ".", "device", ")", "\n", "z_probs_sparsemap", "=", "matching_smap", "(", "\n", "scores", "[", ":", "lengths_x1", "[", "k", "]", ",", ":", "lengths_x2", "[", "k", "]", "]", "/", "1e-3", ",", "max_iter", "=", "1000", "\n", ")", "\n", "z_probs", "[", ":", "lengths_x1", "[", "k", "]", ",", ":", "lengths_x2", "[", "k", "]", "]", "=", "z_probs_sparsemap", "\n", "\n", "", "", "if", "self", ".", "matching_type", "==", "\"AtMostONE-Budget\"", ":", "\n", "                ", "if", "self", ".", "training", ":", "\n", "                    ", "z_probs", "=", "matching_smap_atmostone_budget", "(", "\n", "scores", ",", "max_iter", "=", "10", ",", "budget", "=", "self", ".", "budget", "\n", ")", "# [T,D]", "\n", "", "else", ":", "\n", "                    ", "z_probs", "=", "torch", ".", "zeros", "(", "scores", ".", "shape", ",", "device", "=", "scores", ".", "device", ")", "\n", "z_probs_sparsemap", "=", "matching_smap_atmostone_budget", "(", "\n", "scores", "[", ":", "lengths_x1", "[", "k", "]", ",", ":", "lengths_x2", "[", "k", "]", "]", "/", "1e-3", ",", "\n", "max_iter", "=", "1000", ",", "\n", "budget", "=", "self", ".", "budget", ",", "\n", ")", "\n", "z_probs", "[", ":", "lengths_x1", "[", "k", "]", ",", ":", "lengths_x2", "[", "k", "]", "]", "=", "z_probs_sparsemap", "\n", "\n", "", "", "z_probs", "=", "z_probs", "*", "mask", "[", "1", "]", "[", "k", "]", ".", "unsqueeze", "(", "0", ")", "\n", "z_probs", "=", "z_probs", "*", "mask", "[", "0", "]", "[", "k", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "z", ".", "append", "(", "z_probs", ")", "\n", "\n", "", "z", "=", "torch", ".", "stack", "(", "z", ",", "dim", "=", "0", ")", ".", "squeeze", "(", "-", "1", ")", "# [B, T, D]", "\n", "z", "=", "z", ".", "to", "(", "h_alignments", ".", "device", ")", "\n", "self", ".", "z", "=", "z", "\n", "\n", "x1_align", "=", "torch", ".", "matmul", "(", "z", ",", "x2_h", ")", "\n", "x2_align", "=", "torch", ".", "matmul", "(", "z", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ",", "x1_h", ")", "\n", "\n", "if", "self", ".", "faithful", ":", "\n", "            ", "x1_combined", "=", "x1_align", "\n", "x2_combined", "=", "torch", ".", "cat", "(", "[", "x2_h", ",", "x2_align", "]", ",", "-", "1", ")", "\n", "\n", "x1_combined", "=", "self", ".", "projection_x1", "(", "x1_combined", ")", "\n", "x2_combined", "=", "self", ".", "projection_x2", "(", "x2_combined", ")", "\n", "", "else", ":", "\n", "            ", "x1_combined", "=", "torch", ".", "cat", "(", "[", "x1_h", ",", "x1_align", ",", "submul", "(", "x1_h", ",", "x1_align", ")", "]", ",", "-", "1", ")", "\n", "x2_combined", "=", "torch", ".", "cat", "(", "[", "x2_h", ",", "x2_align", ",", "submul", "(", "x2_h", ",", "x2_align", ")", "]", ",", "-", "1", ")", "\n", "\n", "x1_combined", "=", "self", ".", "projection", "(", "x1_combined", ")", "\n", "x2_combined", "=", "self", ".", "projection", "(", "x2_combined", ")", "\n", "\n", "", "x1_compose", ",", "_", "=", "self", ".", "composition_lstm", "(", "x1_combined", ",", "mask_x1", ",", "lengths_x1", ")", "\n", "x2_compose", ",", "_", "=", "self", ".", "composition_lstm", "(", "x2_combined", ",", "mask_x2", ",", "lengths_x2", ")", "\n", "\n", "x1_rep", "=", "apply_multiple", "(", "x1_compose", ")", "\n", "x2_rep", "=", "apply_multiple", "(", "x2_compose", ")", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x1_rep", ",", "x2_rep", "]", ",", "-", "1", ")", "\n", "\n", "y_hat", "=", "self", ".", "output_layer", "(", "x", ")", "\n", "\n", "return", "z", ",", "y_hat", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings.GumbelFaithfulMatching.__init__": [[185, 235], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "rationalizers.builders.build_sentence_encoder", "rationalizers.builders.build_sentence_encoder", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_sentence_encoder", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_sentence_encoder"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed", ":", "nn", ".", "Embedding", "=", "None", ",", "\n", "hidden_size", ":", "int", "=", "200", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "layer", ":", "str", "=", "\"lstm\"", ",", "\n", "bidirectional", ":", "bool", "=", "True", ",", "\n", "temperature", ":", "float", "=", "1.0", ",", "\n", "nonlinearity", ":", "str", "=", "\"sigmoid\"", ",", "\n", "output_size", ":", "int", "=", "1", ",", "\n", "faithful", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "faithful", "=", "faithful", "\n", "emb_size", "=", "embed", ".", "weight", ".", "shape", "[", "1", "]", "\n", "enc_size", "=", "2", "*", "hidden_size", "if", "bidirectional", "else", "hidden_size", "\n", "self", ".", "embed_layer", "=", "nn", ".", "Sequential", "(", "embed", ",", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "self", ".", "context_lstm", "=", "build_sentence_encoder", "(", "\n", "layer", ",", "\n", "emb_size", ",", "\n", "hidden_size", ",", "\n", "bidirectional", "=", "True", ",", "\n", ")", "\n", "self", ".", "z", "=", "None", "# z samples", "\n", "self", ".", "temperature", "=", "temperature", "\n", "\n", "if", "self", ".", "faithful", ":", "\n", "            ", "self", ".", "projection_x1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "enc_size", ",", "hidden_size", ")", ",", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "self", ".", "projection_x2", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "enc_size", "+", "enc_size", ",", "hidden_size", ")", ",", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "projection", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "4", "*", "2", "*", "hidden_size", ",", "hidden_size", ")", ",", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "\n", "", "self", ".", "composition_lstm", "=", "build_sentence_encoder", "(", "\n", "layer", ",", "\n", "hidden_size", ",", "\n", "hidden_size", ",", "\n", "bidirectional", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "output_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "4", "*", "enc_size", ",", "output_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "if", "nonlinearity", "==", "\"sigmoid\"", "else", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings.GumbelFaithfulMatching.forward": [[237, 301], ["mask[].long().sum", "mask[].long().sum", "matchings.GumbelFaithfulMatching.embed_layer", "matchings.GumbelFaithfulMatching.embed_layer", "matchings.GumbelFaithfulMatching.context_lstm", "matchings.GumbelFaithfulMatching.context_lstm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "matchings.GumbelFaithfulMatching.composition_lstm", "matchings.GumbelFaithfulMatching.composition_lstm", "rationalizers.modules.matchings_utils.apply_multiple", "rationalizers.modules.matchings_utils.apply_multiple", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "matchings.GumbelFaithfulMatching.output_layer", "x2_h.transpose", "torch.gumbel_softmax", "torch.gumbel_softmax", "torch.gumbel_softmax", "torch.gumbel_softmax", "torch.gumbel_softmax", "torch.gumbel_softmax", "torch.gumbel_softmax", "torch.gumbel_softmax", "torch.gumbel_softmax.transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "matchings.GumbelFaithfulMatching.projection_x1", "matchings.GumbelFaithfulMatching.projection_x2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "matchings.GumbelFaithfulMatching.projection", "matchings.GumbelFaithfulMatching.projection", "mask[].long", "mask[].long", "rationalizers.modules.matchings_utils.submul", "rationalizers.modules.matchings_utils.submul"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings_utils.apply_multiple", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings_utils.apply_multiple", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings_utils.submul", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings_utils.submul"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        :param x1: premise embeddings\n        :param x2: hypothesis embeddings\n        :param mask: list [mask_x1, mask_x2] -- mask should be true/1 for valid positions, false/0 for invalid ones.\n        \"\"\"", "\n", "\n", "batch_size", ",", "_", "=", "x1", ".", "shape", "\n", "lengths_x1", "=", "mask", "[", "0", "]", ".", "long", "(", ")", ".", "sum", "(", "1", ")", "\n", "lengths_x2", "=", "mask", "[", "1", "]", ".", "long", "(", ")", ".", "sum", "(", "1", ")", "\n", "mask_x1", "=", "mask", "[", "0", "]", "\n", "mask_x2", "=", "mask", "[", "1", "]", "\n", "\n", "emb_x1", "=", "self", ".", "embed_layer", "(", "x1", ")", "# [B, T, E]", "\n", "emb_x2", "=", "self", ".", "embed_layer", "(", "x2", ")", "# [B, D, E]", "\n", "\n", "# BiLSTM representation of the x1ise and x2thesis", "\n", "x1_h", ",", "_", "=", "self", ".", "context_lstm", "(", "emb_x1", ",", "mask_x1", ",", "lengths_x1", ")", "\n", "x2_h", ",", "_", "=", "self", ".", "context_lstm", "(", "emb_x2", ",", "mask_x2", ",", "lengths_x2", ")", "\n", "\n", "# [B, T, D]", "\n", "h_alignments", "=", "torch", ".", "bmm", "(", "x1_h", ",", "x2_h", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "row_x1_probs", "=", "F", ".", "gumbel_softmax", "(", "\n", "h_alignments", "/", "1e-6", ",", "tau", "=", "self", ".", "temperature", ",", "dim", "=", "1", ",", "hard", "=", "True", "\n", ")", "\n", "column_x2_probs", "=", "F", ".", "gumbel_softmax", "(", "\n", "h_alignments", "/", "1e-6", ",", "tau", "=", "self", ".", "temperature", ",", "dim", "=", "2", ",", "hard", "=", "True", "\n", ")", "\n", "", "else", ":", "\n", "            ", "row_x1_probs", "=", "F", ".", "gumbel_softmax", "(", "h_alignments", ",", "tau", "=", "self", ".", "temperature", ",", "dim", "=", "1", ")", "\n", "column_x2_probs", "=", "F", ".", "gumbel_softmax", "(", "\n", "h_alignments", ",", "tau", "=", "self", ".", "temperature", ",", "dim", "=", "2", "\n", ")", "\n", "\n", "", "x1_align", "=", "torch", ".", "matmul", "(", "row_x1_probs", ",", "x2_h", ")", "\n", "x2_align", "=", "torch", ".", "matmul", "(", "column_x2_probs", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "x1_h", ")", "\n", "\n", "if", "self", ".", "faithful", ":", "\n", "            ", "x1_combined", "=", "x1_align", "\n", "x2_combined", "=", "torch", ".", "cat", "(", "[", "x2_h", ",", "x2_align", "]", ",", "-", "1", ")", "\n", "\n", "x1_combined", "=", "self", ".", "projection_x1", "(", "x1_combined", ")", "\n", "x2_combined", "=", "self", ".", "projection_x2", "(", "x2_combined", ")", "\n", "", "else", ":", "\n", "            ", "x1_combined", "=", "torch", ".", "cat", "(", "[", "x1_h", ",", "x1_align", ",", "submul", "(", "x1_h", ",", "x1_align", ")", "]", ",", "-", "1", ")", "\n", "x2_combined", "=", "torch", ".", "cat", "(", "[", "x2_h", ",", "x2_align", ",", "submul", "(", "x2_h", ",", "x2_align", ")", "]", ",", "-", "1", ")", "\n", "\n", "x1_combined", "=", "self", ".", "projection", "(", "x1_combined", ")", "\n", "x2_combined", "=", "self", ".", "projection", "(", "x2_combined", ")", "\n", "\n", "", "x1_compose", ",", "_", "=", "self", ".", "composition_lstm", "(", "x1_combined", ",", "mask_x1", ",", "lengths_x1", ")", "\n", "x2_compose", ",", "_", "=", "self", ".", "composition_lstm", "(", "x2_combined", ",", "mask_x2", ",", "lengths_x2", ")", "\n", "\n", "x1_rep", "=", "apply_multiple", "(", "x1_compose", ")", "\n", "x2_rep", "=", "apply_multiple", "(", "x2_compose", ")", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x1_rep", ",", "x2_rep", "]", ",", "-", "1", ")", "\n", "\n", "y_hat", "=", "self", ".", "output_layer", "(", "x", ")", "\n", "z", "=", "[", "row_x1_probs", ",", "column_x2_probs", "]", "\n", "\n", "return", "z", ",", "y_hat", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings.ESIMFaithfulMatching.__init__": [[308, 358], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "rationalizers.builders.build_sentence_encoder", "rationalizers.builders.build_sentence_encoder", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.LogSoftmax", "torch.nn.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_sentence_encoder", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_sentence_encoder"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed", ":", "nn", ".", "Embedding", "=", "None", ",", "\n", "hidden_size", ":", "int", "=", "200", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "layer", ":", "str", "=", "\"lstm\"", ",", "\n", "bidirectional", ":", "bool", "=", "True", ",", "\n", "temperature", ":", "float", "=", "1.0", ",", "\n", "nonlinearity", ":", "str", "=", "\"sigmoid\"", ",", "\n", "output_size", ":", "int", "=", "1", ",", "\n", "faithful", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "faithful", "=", "faithful", "\n", "emb_size", "=", "embed", ".", "weight", ".", "shape", "[", "1", "]", "\n", "enc_size", "=", "2", "*", "hidden_size", "if", "bidirectional", "else", "hidden_size", "\n", "self", ".", "embed_layer", "=", "nn", ".", "Sequential", "(", "embed", ",", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "self", ".", "context_lstm", "=", "build_sentence_encoder", "(", "\n", "layer", ",", "\n", "emb_size", ",", "\n", "hidden_size", ",", "\n", "bidirectional", "=", "True", ",", "\n", ")", "\n", "self", ".", "z", "=", "None", "# z samples", "\n", "self", ".", "temperature", "=", "temperature", "\n", "\n", "if", "self", ".", "faithful", ":", "\n", "            ", "self", ".", "projection_x1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "enc_size", ",", "hidden_size", ")", ",", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "self", ".", "projection_x2", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "enc_size", "+", "enc_size", ",", "hidden_size", ")", ",", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "projection", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "4", "*", "2", "*", "hidden_size", ",", "hidden_size", ")", ",", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "\n", "", "self", ".", "composition_lstm", "=", "build_sentence_encoder", "(", "\n", "layer", ",", "\n", "hidden_size", ",", "\n", "hidden_size", ",", "\n", "bidirectional", "=", "True", ",", "\n", ")", "\n", "\n", "self", ".", "output_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "4", "*", "enc_size", ",", "output_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "if", "nonlinearity", "==", "\"sigmoid\"", "else", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings.ESIMFaithfulMatching.forward": [[360, 409], ["mask[].long().sum", "mask[].long().sum", "matchings.ESIMFaithfulMatching.embed_layer", "matchings.ESIMFaithfulMatching.embed_layer", "matchings.ESIMFaithfulMatching.context_lstm", "matchings.ESIMFaithfulMatching.context_lstm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "matchings.ESIMFaithfulMatching.composition_lstm", "matchings.ESIMFaithfulMatching.composition_lstm", "rationalizers.modules.matchings_utils.apply_multiple", "rationalizers.modules.matchings_utils.apply_multiple", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "matchings.ESIMFaithfulMatching.output_layer", "x2_h.transpose", "torch.softmax.transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "matchings.ESIMFaithfulMatching.projection_x1", "matchings.ESIMFaithfulMatching.projection_x2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "matchings.ESIMFaithfulMatching.projection", "matchings.ESIMFaithfulMatching.projection", "mask[].long", "mask[].long", "rationalizers.modules.matchings_utils.submul", "rationalizers.modules.matchings_utils.submul"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings_utils.apply_multiple", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings_utils.apply_multiple", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings_utils.submul", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings_utils.submul"], ["", "def", "forward", "(", "self", ",", "x1", ",", "x2", ",", "mask", ")", ":", "\n", "        ", "batch_size", ",", "_", "=", "x1", ".", "shape", "\n", "\n", "lengths_x1", "=", "mask", "[", "0", "]", ".", "long", "(", ")", ".", "sum", "(", "1", ")", "\n", "lengths_x2", "=", "mask", "[", "1", "]", ".", "long", "(", ")", ".", "sum", "(", "1", ")", "\n", "mask_x1", "=", "mask", "[", "0", "]", "\n", "mask_x2", "=", "mask", "[", "1", "]", "\n", "\n", "emb_x1", "=", "self", ".", "embed_layer", "(", "x1", ")", "# [B, T, E]", "\n", "emb_x2", "=", "self", ".", "embed_layer", "(", "x2", ")", "# [B, D, E]", "\n", "\n", "# BiLSTM representation of the x1ise and x2thesis", "\n", "x1_h", ",", "_", "=", "self", ".", "context_lstm", "(", "emb_x1", ",", "mask_x1", ",", "lengths_x1", ")", "\n", "x2_h", ",", "_", "=", "self", ".", "context_lstm", "(", "emb_x2", ",", "mask_x2", ",", "lengths_x2", ")", "\n", "\n", "# [B, T, D]", "\n", "h_alignments", "=", "torch", ".", "bmm", "(", "x1_h", ",", "x2_h", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "\n", "row_x1_probs", "=", "F", ".", "softmax", "(", "h_alignments", ",", "dim", "=", "1", ")", "\n", "column_x2_probs", "=", "F", ".", "softmax", "(", "h_alignments", ",", "dim", "=", "2", ")", "\n", "\n", "x1_align", "=", "torch", ".", "matmul", "(", "row_x1_probs", ",", "x2_h", ")", "\n", "x2_align", "=", "torch", ".", "matmul", "(", "column_x2_probs", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "x1_h", ")", "\n", "\n", "if", "self", ".", "faithful", ":", "\n", "            ", "x1_combined", "=", "x1_align", "\n", "x2_combined", "=", "torch", ".", "cat", "(", "[", "x2_h", ",", "x2_align", "]", ",", "-", "1", ")", "\n", "\n", "x1_combined", "=", "self", ".", "projection_x1", "(", "x1_combined", ")", "\n", "x2_combined", "=", "self", ".", "projection_x2", "(", "x2_combined", ")", "\n", "", "else", ":", "\n", "            ", "x1_combined", "=", "torch", ".", "cat", "(", "[", "x1_h", ",", "x1_align", ",", "submul", "(", "x1_h", ",", "x1_align", ")", "]", ",", "-", "1", ")", "\n", "x2_combined", "=", "torch", ".", "cat", "(", "[", "x2_h", ",", "x2_align", ",", "submul", "(", "x2_h", ",", "x2_align", ")", "]", ",", "-", "1", ")", "\n", "\n", "x1_combined", "=", "self", ".", "projection", "(", "x1_combined", ")", "\n", "x2_combined", "=", "self", ".", "projection", "(", "x2_combined", ")", "\n", "\n", "", "x1_compose", ",", "_", "=", "self", ".", "composition_lstm", "(", "x1_combined", ",", "mask_x1", ",", "lengths_x1", ")", "\n", "x2_compose", ",", "_", "=", "self", ".", "composition_lstm", "(", "x2_combined", ",", "mask_x2", ",", "lengths_x2", ")", "\n", "\n", "x1_rep", "=", "apply_multiple", "(", "x1_compose", ")", "\n", "x2_rep", "=", "apply_multiple", "(", "x2_compose", ")", "\n", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x1_rep", ",", "x2_rep", "]", ",", "-", "1", ")", "\n", "\n", "y_hat", "=", "self", ".", "output_layer", "(", "x", ")", "\n", "z", "=", "[", "row_x1_probs", ",", "column_x2_probs", "]", "\n", "\n", "return", "z", ",", "y_hat", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.sparsemap.seq_budget_smap": [[17, 37], ["lpsmap.TorchFactorGraph", "lpsmap.TorchFactorGraph.variable_from", "lpsmap.TorchFactorGraph.add", "lpsmap.TorchFactorGraph.solve", "fg.variable_from.value.cuda", "lpsmap.SequenceBudget"], "function", ["None"], ["def", "seq_budget_smap", "(", "\n", "unary_scores", ",", "\n", "transition_scores", ",", "\n", "max_iter", "=", "1", ",", "\n", "step_size", "=", "0", ",", "\n", "init", "=", "True", ",", "\n", "budget", "=", "5", ",", "\n", "temperature", "=", "0.01", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    H:SeqBudget strategy for highlights extraction\n    \"\"\"", "\n", "unary_scores", ".", "shape", "[", "0", "]", "\n", "\n", "fg", "=", "TorchFactorGraph", "(", ")", "\n", "u", "=", "fg", ".", "variable_from", "(", "unary_scores", ")", "\n", "fg", ".", "add", "(", "SequenceBudget", "(", "u", ",", "transition_scores", ",", "budget", ")", ")", "\n", "fg", ".", "solve", "(", "max_iter", "=", "max_iter", ",", "step_size", "=", "step_size", ")", "\n", "u", ".", "value", ".", "cuda", "(", ")", "\n", "return", "u", ".", "value", "[", ":", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.sparsemap.matching_smap": [[39, 53], ["lpsmap.TorchFactorGraph", "lpsmap.TorchFactorGraph.variable_from", "range", "range", "lpsmap.TorchFactorGraph.lp_map_solve", "fg.variable_from.value.cuda", "lpsmap.TorchFactorGraph.add", "lpsmap.TorchFactorGraph.add", "lpsmap.Xor", "lpsmap.AtMostOne"], "function", ["None"], ["", "def", "matching_smap", "(", "scores", ",", "max_iter", "=", "5", ",", "temperature", "=", "1", ",", "init", "=", "True", ",", "budget", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    M:XORAtMostOne strategy for matchings extraction\n    \"\"\"", "\n", "\n", "m", ",", "n", "=", "scores", ".", "shape", "\n", "fg", "=", "TorchFactorGraph", "(", ")", "\n", "z", "=", "fg", ".", "variable_from", "(", "scores", "/", "temperature", ")", "\n", "for", "i", "in", "range", "(", "m", ")", ":", "\n", "        ", "fg", ".", "add", "(", "Xor", "(", "z", "[", "i", ",", ":", "]", ")", ")", "\n", "", "for", "j", "in", "range", "(", "n", ")", ":", "\n", "        ", "fg", ".", "add", "(", "AtMostOne", "(", "z", "[", ":", ",", "j", "]", ")", ")", "# some cols may be 0", "\n", "", "fg", ".", "lp_map_solve", "(", "max_iter", "=", "max_iter", ")", "\n", "return", "z", ".", "value", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.sparsemap.matching_smap_atmostone": [[55, 69], ["lpsmap.TorchFactorGraph", "lpsmap.TorchFactorGraph.variable_from", "range", "range", "lpsmap.TorchFactorGraph.solve", "fg.variable_from.value.cuda", "lpsmap.TorchFactorGraph.add", "lpsmap.TorchFactorGraph.add", "lpsmap.AtMostOne", "lpsmap.AtMostOne"], "function", ["None"], ["", "def", "matching_smap_atmostone", "(", "scores", ",", "max_iter", "=", "5", ",", "temperature", "=", "1", ",", "init", "=", "True", ",", "budget", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    M:AtMostOne2 strategy for matchings extraction\n    \"\"\"", "\n", "\n", "m", ",", "n", "=", "scores", ".", "shape", "\n", "fg", "=", "TorchFactorGraph", "(", ")", "\n", "z", "=", "fg", ".", "variable_from", "(", "scores", "/", "temperature", ")", "\n", "for", "i", "in", "range", "(", "m", ")", ":", "\n", "        ", "fg", ".", "add", "(", "AtMostOne", "(", "z", "[", "i", ",", ":", "]", ")", ")", "\n", "", "for", "j", "in", "range", "(", "n", ")", ":", "\n", "        ", "fg", ".", "add", "(", "AtMostOne", "(", "z", "[", ":", ",", "j", "]", ")", ")", "# some cols may be 0", "\n", "", "fg", ".", "solve", "(", "max_iter", "=", "max_iter", ")", "\n", "return", "z", ".", "value", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.sparsemap.matching_smap_atmostone_budget": [[71, 88], ["lpsmap.TorchFactorGraph", "lpsmap.TorchFactorGraph.variable_from", "lpsmap.TorchFactorGraph.add", "range", "range", "lpsmap.TorchFactorGraph.solve", "fg.variable_from.value.cuda", "lpsmap.Budget", "lpsmap.TorchFactorGraph.add", "lpsmap.TorchFactorGraph.add", "lpsmap.AtMostOne", "lpsmap.AtMostOne"], "function", ["None"], ["", "def", "matching_smap_atmostone_budget", "(", "\n", "scores", ",", "max_iter", "=", "5", ",", "temperature", "=", "1", ",", "init", "=", "True", ",", "budget", "=", "None", "\n", ")", ":", "\n", "    ", "\"\"\"\n    M:Budget strategy for matchings extraction\n    \"\"\"", "\n", "\n", "m", ",", "n", "=", "scores", ".", "shape", "\n", "fg", "=", "TorchFactorGraph", "(", ")", "\n", "z", "=", "fg", ".", "variable_from", "(", "scores", "/", "temperature", ")", "\n", "fg", ".", "add", "(", "Budget", "(", "z", ",", "budget", "=", "budget", ")", ")", "\n", "for", "i", "in", "range", "(", "m", ")", ":", "\n", "        ", "fg", ".", "add", "(", "AtMostOne", "(", "z", "[", "i", ",", ":", "]", ")", ")", "\n", "", "for", "j", "in", "range", "(", "n", ")", ":", "\n", "        ", "fg", ".", "add", "(", "AtMostOne", "(", "z", "[", ":", ",", "j", "]", ")", ")", "# some cols may be 0", "\n", "", "fg", ".", "solve", "(", "max_iter", "=", "max_iter", ")", "\n", "return", "z", ".", "value", ".", "cuda", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.sentence_encoders.LSTMEncoder.__init__": [[12, 31], ["torch.nn.Module.__init__", "torch.nn.LSTM"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_features", ",", "\n", "hidden_size", ":", "int", "=", "200", ",", "\n", "batch_first", ":", "bool", "=", "True", ",", "\n", "bidirectional", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param in_features:\n        :param hidden_size:\n        :param batch_first:\n        :param bidirectional:\n        \"\"\"", "\n", "super", "(", "LSTMEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "\n", "in_features", ",", "\n", "hidden_size", ",", "\n", "batch_first", "=", "batch_first", ",", "\n", "bidirectional", "=", "bidirectional", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.sentence_encoders.LSTMEncoder.forward": [[33, 51], ["torch.nn.utils.rnn.pack_padded_sequence", "sentence_encoders.LSTMEncoder.lstm", "torch.nn.utils.rnn.pad_packed_sequence", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ",", "lengths", ")", ":", "\n", "        ", "\"\"\"\n        :param x: sequence of word embeddings, shape [B, T, E]\n        :param mask: byte mask that is 0 for invalid positions, shape [B, T]\n        :param lengths: the lengths of each input sequence [B]\n        :return:\n        \"\"\"", "\n", "packed_sequence", "=", "pack_padded_sequence", "(", "\n", "x", ",", "lengths", ",", "batch_first", "=", "True", ",", "enforce_sorted", "=", "False", "\n", ")", "\n", "outputs", ",", "(", "hx", ",", "cx", ")", "=", "self", ".", "lstm", "(", "packed_sequence", ")", "\n", "outputs", ",", "_", "=", "pad_packed_sequence", "(", "outputs", ",", "batch_first", "=", "True", ")", "\n", "# classify from concatenation of final states", "\n", "if", "self", ".", "lstm", ".", "bidirectional", ":", "\n", "            ", "final", "=", "torch", ".", "cat", "(", "[", "hx", "[", "-", "2", "]", ",", "hx", "[", "-", "1", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "# classify from final state", "\n", "            ", "final", "=", "hx", "[", "-", "1", "]", "\n", "", "return", "outputs", ",", "final", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings_utils.submul": [[5, 9], ["torch.cat", "torch.cat"], "function", ["None"], ["def", "submul", "(", "x1", ",", "x2", ")", ":", "\n", "    ", "mul", "=", "x1", "*", "x2", "\n", "sub", "=", "x1", "-", "x2", "\n", "return", "torch", ".", "cat", "(", "[", "sub", ",", "mul", "]", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.matchings_utils.apply_multiple": [[11, 17], ["torch.avg_pool1d().squeeze", "torch.max_pool1d().squeeze", "torch.cat", "torch.cat", "torch.avg_pool1d", "torch.max_pool1d", "x.transpose", "x.size", "x.transpose", "x.size"], "function", ["None"], ["", "def", "apply_multiple", "(", "x", ")", ":", "\n", "# input: batch_size * seq_len * (2 * hidden_size)", "\n", "    ", "p1", "=", "F", ".", "avg_pool1d", "(", "x", ".", "transpose", "(", "1", ",", "2", ")", ",", "x", ".", "size", "(", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "p2", "=", "F", ".", "max_pool1d", "(", "x", ".", "transpose", "(", "1", ",", "2", ")", ",", "x", ".", "size", "(", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "# output: batch_size * (4 * hidden_size)", "\n", "return", "torch", ".", "cat", "(", "[", "p1", ",", "p2", "]", ",", "1", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.metrics.evaluate_rationale": [[7, 64], ["rationalizers.utils.unroll", "rationalizers.utils.unroll", "rationalizers.utils.unroll", "range", "len", "z_ex_nonzero.sum().item", "sum", "sum", "ell.tolist", "len", "float", "float", "z_ex_nonzero.sum", "enumerate", "enumerate", "any", "any"], "function", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.unroll", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.unroll", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.utils.unroll"], ["def", "evaluate_rationale", "(", "test_ids", ",", "annotations", ",", "lengths", ")", "->", "dict", ":", "\n", "    ", "\"\"\"\n    Function that computes the token F1 Score (matching with annotations).\n\n    :param y: Ground-truth labels.\n    :param y_hat: Model label predictions.\n    \"\"\"", "\n", "correct", ",", "total", ",", "macro_prec_total", ",", "macro_rec_total", ",", "macro_n", "=", "0", ",", "0", ",", "0", ",", "0", ",", "0", "\n", "\n", "test_ids", "=", "unroll", "(", "test_ids", ")", "\n", "annotations", "=", "unroll", "(", "annotations", ")", "\n", "lengths", "=", "unroll", "(", "lengths", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "test_ids", ")", ")", ":", "\n", "        ", "z_ex", "=", "test_ids", "[", "i", "]", "[", ":", "lengths", "[", "i", "]", "]", "\n", "z_ex_nonzero", "=", "(", "z_ex", ">", "0", ")", ".", "float", "(", ")", "\n", "z_ex_nonzero_sum", "=", "z_ex_nonzero", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "# make this work for multiple aspects", "\n", "aspect_annotations", "=", "[", "ell", ".", "tolist", "(", ")", "for", "ell", "in", "annotations", "[", "i", "]", "[", "0", "]", "]", "\n", "if", "len", "(", "aspect_annotations", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "annotations_range", "=", "[", "[", "a", "[", "0", "]", ",", "a", "[", "1", "]", "]", "for", "a", "in", "aspect_annotations", "]", "\n", "matched", "=", "sum", "(", "\n", "1", "\n", "for", "i", ",", "zi", "in", "enumerate", "(", "z_ex", ")", "\n", "if", "zi", ">", "0", "and", "any", "(", "range", "[", "0", "]", "<=", "i", "<", "range", "[", "1", "]", "for", "range", "in", "annotations_range", ")", "\n", ")", "\n", "non_matched", "=", "sum", "(", "\n", "1", "\n", "for", "i", ",", "zi", "in", "enumerate", "(", "z_ex", ")", "\n", "if", "zi", "==", "0", "and", "any", "(", "range", "[", "0", "]", "<=", "i", "<", "range", "[", "1", "]", "for", "range", "in", "annotations_range", ")", "\n", ")", "\n", "precision", "=", "matched", "/", "(", "z_ex_nonzero_sum", "+", "1e-9", ")", "\n", "recall", "=", "matched", "/", "(", "matched", "+", "non_matched", "+", "1e-9", ")", "\n", "macro_prec_total", "+=", "precision", "\n", "macro_rec_total", "+=", "recall", "\n", "correct", "+=", "matched", "\n", "total", "+=", "z_ex_nonzero_sum", "\n", "if", "z_ex_nonzero_sum", ">", "0", ":", "\n", "            ", "macro_n", "+=", "1", "\n", "\n", "", "", "precision", "=", "correct", "/", "(", "total", "+", "1e-9", ")", "\n", "macro_precision", "=", "macro_prec_total", "/", "(", "float", "(", "macro_n", ")", "+", "1e-9", ")", "\n", "macro_recall", "=", "macro_rec_total", "/", "(", "float", "(", "macro_n", ")", "+", "1e-9", ")", "\n", "f1_score", "=", "(", "\n", "2", "*", "macro_precision", "*", "macro_recall", "/", "(", "macro_precision", "+", "macro_recall", "+", "1e-9", ")", "\n", ")", "\n", "\n", "report", "=", "{", "\n", "\"macro_precision\"", ":", "macro_precision", ",", "\n", "\"precision\"", ":", "precision", ",", "\n", "\"macro_recall\"", ":", "macro_recall", ",", "\n", "\"f1_score\"", ":", "f1_score", ",", "\n", "}", "\n", "\n", "return", "report", "\n", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.gates.BernoulliGate.__init__": [[18, 22], ["torch.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", "=", "1", ")", ":", "\n", "        ", "super", "(", "BernoulliGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "layer", "=", "Sequential", "(", "Linear", "(", "in_features", ",", "out_features", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.gates.BernoulliGate.forward": [[23, 34], ["gates.BernoulliGate.layer", "logits.unsqueeze.unsqueeze.unsqueeze", "torch.distributions.bernoulli.Bernoulli", "torch.distributions.bernoulli.Bernoulli", "logits.unsqueeze.unsqueeze.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        Compute Binomial gate\n        :param x: word represenatations [B, T, D]\n        :return: gate distribution\n        \"\"\"", "\n", "logits", "=", "self", ".", "layer", "(", "x", ")", "# [B, T, 1]", "\n", "logits", "=", "logits", ".", "squeeze", "(", "-", "1", ")", "*", "mask", "\n", "logits", "=", "logits", ".", "unsqueeze", "(", "-", "1", ")", "\n", "dist", "=", "Bernoulli", "(", "logits", "=", "logits", ")", "\n", "return", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.gates.RelaxedBernoulliGate.__init__": [[42, 46], ["torch.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", "=", "1", ")", ":", "\n", "        ", "super", "(", "RelaxedBernoulliGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "layer", "=", "Sequential", "(", "Linear", "(", "in_features", ",", "out_features", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.gates.RelaxedBernoulliGate.forward": [[47, 60], ["gates.RelaxedBernoulliGate.layer", "logits.unsqueeze.unsqueeze.unsqueeze", "torch.distributions.relaxed_bernoulli.RelaxedBernoulli", "torch.distributions.relaxed_bernoulli.RelaxedBernoulli", "logits.unsqueeze.unsqueeze.squeeze", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n        Compute Relaxed Binomial gate\n        :param x: word represenatations [B, T, D]\n        :return: gate distribution\n        \"\"\"", "\n", "logits", "=", "self", ".", "layer", "(", "x", ")", "# [B, T, 1]", "\n", "logits", "=", "logits", ".", "squeeze", "(", "-", "1", ")", "*", "mask", "\n", "logits", "=", "logits", ".", "unsqueeze", "(", "-", "1", ")", "\n", "dist", "=", "RelaxedBernoulli", "(", "\n", "temperature", "=", "torch", ".", "tensor", "(", "[", "0.1", "]", ",", "device", "=", "logits", ".", "device", ")", ",", "logits", "=", "logits", "\n", ")", "\n", "return", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.gates.KumaGate.__init__": [[67, 84], ["torch.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Softplus", "torch.nn.Softplus", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Softplus", "torch.nn.Softplus"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["def", "__init__", "(", "\n", "self", ",", "in_features", ",", "out_features", "=", "1", ",", "support", "=", "(", "-", "0.1", ",", "1.1", ")", ",", "dist_type", "=", "\"hardkuma\"", "\n", ")", ":", "\n", "        ", "super", "(", "KumaGate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dist_type", "=", "dist_type", "\n", "\n", "self", ".", "layer_a", "=", "Sequential", "(", "Linear", "(", "in_features", ",", "out_features", ")", ",", "Softplus", "(", ")", ")", "\n", "self", ".", "layer_b", "=", "Sequential", "(", "Linear", "(", "in_features", ",", "out_features", ")", ",", "Softplus", "(", ")", ")", "\n", "\n", "# support must be Tensors", "\n", "s_min", "=", "torch", ".", "Tensor", "(", "[", "support", "[", "0", "]", "]", ")", "\n", "s_max", "=", "torch", ".", "Tensor", "(", "[", "support", "[", "1", "]", "]", ")", "\n", "self", ".", "support", "=", "[", "s_min", ",", "s_max", "]", "\n", "\n", "self", ".", "a", "=", "None", "\n", "self", ".", "b", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.gates.KumaGate.forward": [[85, 109], ["gates.KumaGate.layer_a", "gates.KumaGate.layer_b", "a.clamp.clamp.clamp", "b.clamp.clamp.clamp", "rationalizers.modules.kuma.Kuma", "rationalizers.modules.kuma.HardKuma", "ValueError"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Compute latent gate\n        :param x: word represenatations [B, T, D]\n        :return: gate distribution\n        \"\"\"", "\n", "a", "=", "self", ".", "layer_a", "(", "x", ")", "\n", "b", "=", "self", ".", "layer_b", "(", "x", ")", "\n", "\n", "a", "=", "a", ".", "clamp", "(", "1e-6", ",", "100.0", ")", "# extreme values could result in NaNs", "\n", "b", "=", "b", ".", "clamp", "(", "1e-6", ",", "100.0", ")", "# extreme values could result in NaNs", "\n", "\n", "self", ".", "a", "=", "a", "\n", "self", ".", "b", "=", "b", "\n", "\n", "# we return a distribution (from which we can sample if we want)", "\n", "if", "self", ".", "dist_type", "==", "\"kuma\"", ":", "\n", "            ", "dist", "=", "Kuma", "(", "[", "a", ",", "b", "]", ")", "\n", "", "elif", "self", ".", "dist_type", "==", "\"hardkuma\"", ":", "\n", "            ", "dist", "=", "HardKuma", "(", "[", "a", ",", "b", "]", ",", "support", "=", "self", ".", "support", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"unknown dist\"", ")", "\n", "\n", "", "return", "dist", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SPECTRAGenerator.__init__": [[21, 51], ["torch.nn.Module.__init__", "torch.nn.Sequential", "rationalizers.builders.build_sentence_encoder", "torch.nn.Linear", "generators.SelfAdditiveScorer", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_sentence_encoder"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed", ":", "nn", ".", "Embedding", "=", "None", ",", "\n", "hidden_size", ":", "int", "=", "200", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "layer", ":", "str", "=", "\"lstm\"", ",", "\n", "bidirectional", ":", "bool", "=", "True", ",", "\n", "budget", ":", "int", "=", "0", ",", "\n", "init", ":", "bool", "=", "False", ",", "\n", "max_iter", ":", "int", "=", "100", ",", "\n", "transition", ":", "int", "=", "0", ",", "\n", "temperature", ":", "float", "=", "0.01", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "emb_size", "=", "embed", ".", "weight", ".", "shape", "[", "1", "]", "\n", "enc_size", "=", "2", "*", "hidden_size", "if", "bidirectional", "else", "hidden_size", "\n", "self", ".", "embed_layer", "=", "nn", ".", "Sequential", "(", "embed", ",", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "self", ".", "enc_layer", "=", "build_sentence_encoder", "(", "\n", "layer", ",", "emb_size", ",", "hidden_size", ",", "bidirectional", "=", "bidirectional", "\n", ")", "\n", "self", ".", "layer", "=", "nn", ".", "Linear", "(", "enc_size", ",", "1", ")", "\n", "self", ".", "self_scorer", "=", "SelfAdditiveScorer", "(", "enc_size", ",", "enc_size", ")", "\n", "self", ".", "init", "=", "init", "\n", "self", ".", "max_iter", "=", "max_iter", "\n", "self", ".", "z", "=", "None", "# z samples", "\n", "self", ".", "z_dists", "=", "[", "]", "# z distribution(s)", "\n", "self", ".", "transition", "=", "transition", "\n", "self", ".", "budget", "=", "budget", "\n", "self", ".", "temperature", "=", "temperature", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SPECTRAGenerator.forward": [[52, 129], ["mask.long().sum", "generators.SPECTRAGenerator.embed_layer", "generators.SPECTRAGenerator.enc_layer", "generators.SPECTRAGenerator.layer", "torch.full", "range", "torch.stack().squeeze", "torch.where.cuda", "torch.where", "float", "h1[].view", "torch.round", "torch.cat", "torch.tensor", "torch.zeros", "rationalizers.modules.sparsemap.seq_budget_smap.cuda", "torch.where.append", "torch.where.new_zeros", "mask.long", "rationalizers.modules.sparsemap.seq_budget_smap", "rationalizers.modules.sparsemap.seq_budget_smap", "torch.stack", "torch.zeros", "h1[].view.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.sparsemap.seq_budget_smap", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.sparsemap.seq_budget_smap"], ["", "def", "forward", "(", "self", ",", "x", ",", "current_epoch", ",", "mask", ")", ":", "\n", "# encode sentence", "\n", "        ", "batch_size", ",", "target_size", "=", "x", ".", "shape", "\n", "lengths", "=", "mask", ".", "long", "(", ")", ".", "sum", "(", "1", ")", "\n", "emb", "=", "self", ".", "embed_layer", "(", "x", ")", "# [B, T, E]", "\n", "\n", "# [B, T, H]", "\n", "h", ",", "_", "=", "self", ".", "enc_layer", "(", "emb", ",", "mask", ",", "lengths", ")", "\n", "\n", "# compute attention scores", "\n", "# [B, T, H] -> [B, T, 1]", "\n", "h1", "=", "self", ".", "layer", "(", "h", ")", "\n", "\n", "t", "=", "torch", ".", "full", "(", "(", "batch_size", ",", "target_size", "+", "1", ")", ",", "float", "(", "self", ".", "transition", ")", ")", "\n", "z", "=", "[", "]", "\n", "num_states", "=", "2", "\n", "\n", "for", "k", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "scores", "=", "h1", "[", "k", "]", ".", "view", "(", "-", "1", ")", "\n", "budget", "=", "torch", ".", "round", "(", "self", ".", "budget", "/", "100", "*", "lengths", "[", "k", "]", ")", "\n", "length", "=", "scores", ".", "shape", "[", "0", "]", "\n", "\n", "# Set unary scores for valid positions", "\n", "x", "=", "torch", ".", "cat", "(", "\n", "(", "\n", "scores", ".", "unsqueeze", "(", "-", "1", ")", "/", "self", ".", "temperature", ",", "\n", "torch", ".", "zeros", "(", "(", "length", ",", "1", ")", ",", "device", "=", "scores", ".", "device", ")", ",", "\n", ")", ",", "\n", "dim", "=", "-", "1", ",", "\n", ")", "\n", "x", "[", "lengths", "[", "k", "]", ":", ",", "0", "]", "=", "-", "1e12", "\n", "\n", "# Set transition scores for valid positions", "\n", "transition_scores", "=", "torch", ".", "tensor", "(", "t", "[", "k", "]", ",", "device", "=", "scores", ".", "device", ")", "\n", "transition", "=", "torch", ".", "zeros", "(", "\n", "(", "length", "+", "1", ",", "num_states", ",", "num_states", ")", ",", "device", "=", "scores", ".", "device", "\n", ")", "\n", "transition", "[", ":", "lengths", "[", "k", "]", "+", "1", ",", "0", ",", "0", "]", "=", "(", "\n", "transition_scores", "[", ":", "lengths", "[", "k", "]", "+", "1", "]", "/", "self", ".", "temperature", "\n", ")", "\n", "\n", "# H:SeqBudget consists of a single factor so, in this particular case, the LP-SparseMAP solution is", "\n", "# indeed the SparseMAP solution and it can be found within a single iteration.", "\n", "self", ".", "max_iter", "=", "1", "\n", "self", ".", "step_size", "=", "0.0", "\n", "\n", "if", "self", ".", "training", ":", "\n", "                ", "z_probs", "=", "seq_budget_smap", "(", "\n", "x", ",", "\n", "transition", ",", "\n", "budget", "=", "budget", ",", "\n", "temperature", "=", "self", ".", "temperature", ",", "\n", "init", "=", "self", ".", "init", ",", "\n", "max_iter", "=", "self", ".", "max_iter", ",", "\n", "step_size", "=", "self", ".", "step_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "test_temperature", "=", "1e-3", "\n", "z_probs", "=", "seq_budget_smap", "(", "\n", "x", "/", "test_temperature", ",", "\n", "transition", "/", "test_temperature", ",", "\n", "budget", "=", "budget", ",", "\n", "temperature", "=", "test_temperature", ",", "\n", "init", "=", "self", ".", "init", ",", "\n", "max_iter", "=", "self", ".", "max_iter", ",", "\n", "step_size", "=", "self", ".", "step_size", ",", "\n", ")", "\n", "\n", "", "z_probs", ".", "cuda", "(", ")", "\n", "z", ".", "append", "(", "z_probs", ")", "\n", "\n", "", "z", "=", "torch", ".", "stack", "(", "z", ",", "dim", "=", "0", ")", ".", "squeeze", "(", "-", "1", ")", "# [B, T]", "\n", "z", "=", "z", ".", "cuda", "(", ")", "\n", "z", "=", "torch", ".", "where", "(", "mask", ",", "z", ",", "z", ".", "new_zeros", "(", "[", "1", "]", ")", ")", "\n", "self", ".", "z", "=", "z", "\n", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.BernoulliIndependentGenerator.__init__": [[136, 167], ["torch.nn.Module.__init__", "torch.nn.Sequential", "rationalizers.builders.build_sentence_encoder", "generators.SelfAdditiveScorer", "torch.nn.Dropout", "rationalizers.modules.gates.RelaxedBernoulliGate", "rationalizers.modules.gates.BernoulliGate"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_sentence_encoder"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed", ":", "nn", ".", "Embedding", "=", "None", ",", "\n", "hidden_size", ":", "int", "=", "200", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "layer", ":", "str", "=", "\"lstm\"", ",", "\n", "budget", ":", "int", "=", "10", ",", "\n", "contiguous", ":", "bool", "=", "False", ",", "\n", "relaxed", ":", "bool", "=", "False", ",", "\n", "topk", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "emb_size", "=", "embed", ".", "weight", ".", "shape", "[", "1", "]", "\n", "enc_size", "=", "hidden_size", "*", "2", "\n", "\n", "self", ".", "embed_layer", "=", "nn", ".", "Sequential", "(", "embed", ",", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "self", ".", "enc_layer", "=", "build_sentence_encoder", "(", "layer", ",", "emb_size", ",", "hidden_size", ")", "\n", "self", ".", "self_scorer", "=", "SelfAdditiveScorer", "(", "enc_size", ",", "enc_size", ")", "\n", "self", ".", "contiguous", "=", "contiguous", "\n", "self", ".", "budget", "=", "budget", "\n", "self", ".", "relaxed", "=", "relaxed", "\n", "self", ".", "topk", "=", "topk", "\n", "\n", "if", "self", ".", "relaxed", ":", "\n", "            ", "self", ".", "z_layer", "=", "RelaxedBernoulliGate", "(", "enc_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "z_layer", "=", "BernoulliGate", "(", "enc_size", ")", "\n", "\n", "", "self", ".", "z", "=", "None", "# z samples", "\n", "self", ".", "z_dists", "=", "[", "]", "# z distribution(s)", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.BernoulliIndependentGenerator.forward": [[168, 251], ["mask.long().sum", "generators.BernoulliIndependentGenerator.embed_layer", "generators.BernoulliIndependentGenerator.enc_layer", "generators.BernoulliIndependentGenerator.z_layer", "torch.where", "generators.BernoulliIndependentGenerator.sample.view", "generators.BernoulliIndependentGenerator.sample.new_zeros", "mask.long", "generators.BernoulliIndependentGenerator.sample.squeeze", "range", "torch.stack", "generators.BernoulliIndependentGenerator.sample.squeeze", "generators.BernoulliIndependentGenerator.rsample", "generators.BernoulliIndependentGenerator.sample", "torch.cumsum", "int", "torch.tensor", "torch.tensor", "z_sel.long().squeeze.long().squeeze.long().squeeze", "generators.BernoulliIndependentGenerator.sample.append", "generators.BernoulliIndependentGenerator.sample.squeeze", "range", "torch.stack", "torch.round().item", "torch.argmax", "generators.BernoulliIndependentGenerator.rsample", "generators.BernoulliIndependentGenerator.sample", "int", "torch.topk", "z_sel.long().squeeze.long().squeeze.long().squeeze", "generators.BernoulliIndependentGenerator.sample.append", "generators.BernoulliIndependentGenerator.rsample", "generators.BernoulliIndependentGenerator.sample", "numpy.setdiff1d", "z_sel.long().squeeze.long().squeeze.long", "torch.round().item", "z_probs.squeeze", "torch.round", "range", "range", "numpy.arange", "numpy.setdiff1d", "z_sel.long().squeeze.long().squeeze.long", "torch.round", "numpy.arange", "idx.cpu", "len", "z_probs.cpu"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.sample", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.sample", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.sample"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "\n", "# encode sentence", "\n", "        ", "lengths", "=", "mask", ".", "long", "(", ")", ".", "sum", "(", "1", ")", "\n", "emb", "=", "self", ".", "embed_layer", "(", "x", ")", "# [B, T, E]", "\n", "h", ",", "_", "=", "self", ".", "enc_layer", "(", "emb", ",", "mask", ",", "lengths", ")", "\n", "\n", "# compute parameters for Bernoulli p(z|x)", "\n", "z_dist", "=", "self", ".", "z_layer", "(", "h", ",", "mask", ")", "\n", "\n", "if", "self", ".", "contiguous", ":", "\n", "            ", "z", "=", "[", "]", "\n", "z_probs_batch", "=", "z_dist", ".", "probs", "\n", "if", "self", ".", "training", ":", "\n", "                ", "if", "self", ".", "relaxed", ":", "\n", "                    ", "z", "=", "z_dist", ".", "rsample", "(", ")", "\n", "", "else", ":", "\n", "                    ", "z", "=", "z_dist", ".", "sample", "(", ")", "\n", "", "z", "=", "z", ".", "squeeze", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "for", "k", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "z_probs", "=", "z_probs_batch", "[", "k", "]", "\n", "z_probs", "[", "lengths", "[", "k", "]", ":", "]", "=", "0", "\n", "cumsum", "=", "torch", ".", "cumsum", "(", "z_probs", ",", "0", ")", "\n", "length", "=", "int", "(", "torch", ".", "round", "(", "self", ".", "budget", "/", "100", "*", "lengths", "[", "k", "]", ")", ".", "item", "(", ")", ")", "\n", "score", "=", "torch", ".", "tensor", "(", "\n", "[", "\n", "cumsum", "[", "j", "+", "length", "]", "-", "cumsum", "[", "j", "]", "\n", "if", "j", ">", "0", "\n", "else", "cumsum", "[", "j", "+", "length", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "z_probs", ")", "-", "length", ")", "\n", "]", "\n", ")", "\n", "index", "=", "torch", ".", "argmax", "(", "score", ")", "+", "1", "\n", "indices", "=", "torch", ".", "tensor", "(", "[", "index", "+", "i", "for", "i", "in", "range", "(", "length", ")", "]", ")", "\n", "z_probs", "[", "\n", "np", ".", "setdiff1d", "(", "np", ".", "arange", "(", "z_probs", ".", "shape", "[", "0", "]", ")", ",", "indices", ",", "True", ")", "\n", "]", "=", "0", "\n", "z_sel", "=", "z_probs", ">", "0", "\n", "z_sel", "=", "z_sel", ".", "long", "(", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "z", ".", "append", "(", "z_sel", "*", "1.0", ")", "\n", "", "z", "=", "torch", ".", "stack", "(", "z", ",", "dim", "=", "0", ")", "\n", "\n", "", "", "elif", "self", ".", "topk", ":", "\n", "            ", "z", "=", "[", "]", "\n", "z_probs_batch", "=", "z_dist", ".", "probs", "\n", "if", "self", ".", "training", ":", "\n", "                ", "if", "self", ".", "relaxed", ":", "\n", "                    ", "z", "=", "z_dist", ".", "rsample", "(", ")", "\n", "", "else", ":", "\n", "                    ", "z", "=", "z_dist", ".", "sample", "(", ")", "\n", "", "z", "=", "z", ".", "squeeze", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "for", "k", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "z_probs", "=", "z_probs_batch", "[", "k", "]", "\n", "z_probs", "[", "lengths", "[", "k", "]", ":", "]", "=", "0", "\n", "length", "=", "int", "(", "torch", ".", "round", "(", "self", ".", "budget", "/", "100", "*", "lengths", "[", "k", "]", ")", ".", "item", "(", ")", ")", "\n", "topk", ",", "idx", "=", "torch", ".", "topk", "(", "z_probs", ".", "squeeze", "(", "-", "1", ")", ",", "length", ")", "\n", "z_probs", "[", "\n", "np", ".", "setdiff1d", "(", "np", ".", "arange", "(", "z_probs", ".", "cpu", "(", ")", ".", "shape", "[", "0", "]", ")", ",", "idx", ".", "cpu", "(", ")", ",", "True", ")", "\n", "]", "=", "0", "\n", "z_sel", "=", "z_probs", ">", "0", "\n", "z_sel", "=", "z_sel", ".", "long", "(", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "z", ".", "append", "(", "z_sel", "*", "1.0", ")", "\n", "", "z", "=", "torch", ".", "stack", "(", "z", ",", "dim", "=", "0", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "training", ":", "# sample", "\n", "                ", "if", "self", ".", "relaxed", ":", "\n", "                    ", "z", "=", "z_dist", ".", "rsample", "(", ")", "\n", "", "else", ":", "\n", "                    ", "z", "=", "z_dist", ".", "sample", "(", ")", "\n", "", "", "else", ":", "# deterministic", "\n", "                ", "z", "=", "(", "z_dist", ".", "probs", ">=", "0.5", ")", ".", "float", "(", ")", "# [B, T, 1]", "\n", "", "z", "=", "z", ".", "squeeze", "(", "-", "1", ")", "# [B, T, 1]  -> [B, T]", "\n", "\n", "", "z", "=", "torch", ".", "where", "(", "mask", ",", "z", ",", "z", ".", "new_zeros", "(", "[", "1", "]", ")", ")", "\n", "z", "=", "z", ".", "view", "(", "emb", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "self", ".", "z", "=", "z", "\n", "self", ".", "z_dists", "=", "[", "z_dist", "]", "\n", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SparsemaxGenerator.__init__": [[258, 278], ["torch.nn.Module.__init__", "torch.nn.Sequential", "rationalizers.builders.build_sentence_encoder", "generators.SelfAdditiveScorer", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_sentence_encoder"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed", ":", "nn", ".", "Embedding", "=", "None", ",", "\n", "hidden_size", ":", "int", "=", "200", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "layer", ":", "str", "=", "\"lstm\"", ",", "\n", "bidirectional", ":", "bool", "=", "True", ",", "\n", "temperature", ":", "float", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "emb_size", "=", "embed", ".", "weight", ".", "shape", "[", "1", "]", "\n", "enc_size", "=", "2", "*", "hidden_size", "if", "bidirectional", "else", "hidden_size", "\n", "self", ".", "embed_layer", "=", "nn", ".", "Sequential", "(", "embed", ",", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "self", ".", "enc_layer", "=", "build_sentence_encoder", "(", "\n", "layer", ",", "emb_size", ",", "hidden_size", ",", "bidirectional", "=", "bidirectional", "\n", ")", "\n", "self", ".", "self_scorer", "=", "SelfAdditiveScorer", "(", "enc_size", ",", "enc_size", ")", "\n", "self", ".", "z", "=", "None", "# z samples", "\n", "self", ".", "temperature", "=", "temperature", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SparsemaxGenerator.forward": [[279, 296], ["mask.long().sum", "generators.SparsemaxGenerator.embed_layer", "generators.SparsemaxGenerator.enc_layer", "generators.SparsemaxGenerator.self_scorer", "entmax.sparsemax", "torch.where", "torch.where.new_zeros", "mask.long"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "\n", "# encode sentence", "\n", "        ", "lengths", "=", "mask", ".", "long", "(", ")", ".", "sum", "(", "1", ")", "\n", "emb", "=", "self", ".", "embed_layer", "(", "x", ")", "# [B, T, E]", "\n", "\n", "# [B, T, H]", "\n", "h", ",", "_", "=", "self", ".", "enc_layer", "(", "emb", ",", "mask", ",", "lengths", ")", "\n", "\n", "# compute sparsemax", "\n", "# [B, T, H] -> [B, T]", "\n", "h", "=", "self", ".", "self_scorer", "(", "h", ",", "h", ")", "\n", "z", "=", "sparsemax", "(", "h", "/", "self", ".", "temperature", ",", "dim", "=", "-", "1", ")", "\n", "z", "=", "torch", ".", "where", "(", "mask", ",", "z", ",", "z", ".", "new_zeros", "(", "[", "1", "]", ")", ")", "\n", "self", ".", "z", "=", "z", "\n", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.KumaIndependentLatentModel.__init__": [[305, 333], ["torch.nn.Module.__init__", "torch.nn.Sequential", "rationalizers.builders.build_sentence_encoder", "rationalizers.modules.gates.KumaGate", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_sentence_encoder"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed", ":", "nn", ".", "Embedding", "=", "None", ",", "\n", "hidden_size", ":", "int", "=", "200", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "layer", ":", "str", "=", "\"lstm\"", ",", "\n", "budget", ":", "int", "=", "10", ",", "\n", "contiguous", ":", "bool", "=", "False", ",", "\n", "topk", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "topk", "=", "topk", "\n", "self", ".", "contiguous", "=", "contiguous", "\n", "self", ".", "budget", "=", "budget", "\n", "\n", "self", ".", "layer", "=", "layer", "\n", "emb_size", "=", "embed", ".", "weight", ".", "shape", "[", "1", "]", "\n", "enc_size", "=", "hidden_size", "*", "2", "\n", "\n", "self", ".", "embed_layer", "=", "nn", ".", "Sequential", "(", "embed", ",", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "self", ".", "enc_layer", "=", "build_sentence_encoder", "(", "layer", ",", "emb_size", ",", "hidden_size", ")", "\n", "\n", "self", ".", "z_layer", "=", "KumaGate", "(", "enc_size", ")", "\n", "\n", "self", ".", "z", "=", "None", "# z samples", "\n", "self", ".", "z_dists", "=", "[", "]", "# z distribution(s)", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.KumaIndependentLatentModel.forward": [[334, 411], ["mask.sum", "generators.KumaIndependentLatentModel.embed_layer", "generators.KumaIndependentLatentModel.enc_layer", "generators.KumaIndependentLatentModel.z_layer", "torch.where.squeeze.squeeze", "torch.where", "hasattr", "generators.KumaIndependentLatentModel.mean", "torch.where.squeeze.new_zeros", "generators.KumaIndependentLatentModel.rsample", "generators.KumaIndependentLatentModel.sample", "range", "torch.stack", "torch.cumsum", "int", "torch.tensor", "torch.tensor", "torch.where.long().squeeze", "torch.where.squeeze.append", "range", "torch.stack", "torch.round().item", "torch.argmax", "int", "torch.topk", "torch.where.long().squeeze", "torch.where.squeeze.append", "generators.KumaIndependentLatentModel.pdf", "generators.KumaIndependentLatentModel.pdf", "torch.where", "torch.where", "torch.where.squeeze", "numpy.setdiff1d", "torch.where.long", "torch.round().item", "z_probs.squeeze", "h.new_zeros", "h.new_ones", "h.new_zeros", "h.new_ones", "generators.KumaIndependentLatentModel.mean", "torch.round", "range", "range", "numpy.arange", "numpy.setdiff1d", "torch.where.long", "torch.round", "numpy.arange", "idx.cpu", "len", "z_probs.cpu"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.sample", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.RV.pdf", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.RV.pdf", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ",", "**", "kwargs", ")", ":", "\n", "\n", "# encode sentence", "\n", "        ", "lengths", "=", "mask", ".", "sum", "(", "1", ")", "\n", "\n", "emb", "=", "self", ".", "embed_layer", "(", "x", ")", "# [B, T, E]", "\n", "h", ",", "_", "=", "self", ".", "enc_layer", "(", "emb", ",", "mask", ",", "lengths", ")", "\n", "\n", "z_dist", "=", "self", ".", "z_layer", "(", "h", "/", "0.01", ")", "\n", "\n", "# we sample once since the state was already repeated num_samples", "\n", "if", "self", ".", "training", ":", "\n", "            ", "if", "hasattr", "(", "z_dist", ",", "\"rsample\"", ")", ":", "\n", "                ", "z", "=", "z_dist", ".", "rsample", "(", ")", "# use rsample() if it's there", "\n", "", "else", ":", "\n", "                ", "z", "=", "z_dist", ".", "sample", "(", ")", "# [B, M, 1]", "\n", "", "", "else", ":", "\n", "            ", "z", "=", "[", "]", "\n", "z_probs_batch", "=", "z_dist", ".", "mean", "(", ")", "\n", "\n", "if", "self", ".", "contiguous", ":", "\n", "                ", "for", "k", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "z_probs", "=", "z_probs_batch", "[", "k", "]", "\n", "z_probs", "[", "lengths", "[", "k", "]", ":", "]", "=", "0", "\n", "cumsum", "=", "torch", ".", "cumsum", "(", "z_probs", ",", "0", ")", "\n", "length", "=", "int", "(", "torch", ".", "round", "(", "self", ".", "budget", "/", "100", "*", "lengths", "[", "k", "]", ")", ".", "item", "(", ")", ")", "\n", "score", "=", "torch", ".", "tensor", "(", "\n", "[", "\n", "cumsum", "[", "j", "+", "length", "]", "-", "cumsum", "[", "j", "]", "\n", "if", "j", ">", "0", "\n", "else", "cumsum", "[", "j", "+", "length", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "z_probs", ")", "-", "length", ")", "\n", "]", "\n", ")", "\n", "index", "=", "torch", ".", "argmax", "(", "score", ")", "+", "1", "\n", "indices", "=", "torch", ".", "tensor", "(", "[", "index", "+", "i", "for", "i", "in", "range", "(", "length", ")", "]", ")", "\n", "z_probs", "[", "\n", "np", ".", "setdiff1d", "(", "np", ".", "arange", "(", "z_probs", ".", "shape", "[", "0", "]", ")", ",", "indices", ",", "True", ")", "\n", "]", "=", "0", "\n", "z_sel", "=", "z_probs", ">", "0", "\n", "z_sel", "=", "z_sel", ".", "long", "(", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "z", ".", "append", "(", "z_sel", "*", "1.0", ")", "\n", "", "z", "=", "torch", ".", "stack", "(", "z", ",", "dim", "=", "0", ")", "\n", "\n", "", "elif", "self", ".", "topk", ":", "\n", "                ", "for", "k", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "z_probs", "=", "z_probs_batch", "[", "k", "]", "\n", "z_probs", "[", "lengths", "[", "k", "]", ":", "]", "=", "0", "\n", "length", "=", "int", "(", "torch", ".", "round", "(", "self", ".", "budget", "/", "100", "*", "lengths", "[", "k", "]", ")", ".", "item", "(", ")", ")", "\n", "topk", ",", "idx", "=", "torch", ".", "topk", "(", "z_probs", ".", "squeeze", "(", "-", "1", ")", ",", "length", ")", "\n", "z_probs", "[", "\n", "np", ".", "setdiff1d", "(", "np", ".", "arange", "(", "z_probs", ".", "cpu", "(", ")", ".", "shape", "[", "0", "]", ")", ",", "idx", ".", "cpu", "(", ")", ",", "True", ")", "\n", "]", "=", "0", "\n", "z_sel", "=", "z_probs", ">", "0", "\n", "z_sel", "=", "z_sel", ".", "long", "(", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "z", ".", "append", "(", "z_sel", "*", "1.0", ")", "\n", "", "z", "=", "torch", ".", "stack", "(", "z", ",", "dim", "=", "0", ")", "\n", "\n", "", "elif", "not", "self", ".", "topk", "and", "not", "self", ".", "contiguous", ":", "\n", "# deterministic strategy", "\n", "                ", "p0", "=", "z_dist", ".", "pdf", "(", "h", ".", "new_zeros", "(", "(", ")", ")", ")", "\n", "p1", "=", "z_dist", ".", "pdf", "(", "h", ".", "new_ones", "(", "(", ")", ")", ")", "\n", "pc", "=", "1.0", "-", "p0", "-", "p1", "# prob. of sampling a continuous value [B, M]", "\n", "zero_one", "=", "torch", ".", "where", "(", "p0", ">", "p1", ",", "h", ".", "new_zeros", "(", "[", "1", "]", ")", ",", "h", ".", "new_ones", "(", "[", "1", "]", ")", ")", "\n", "z_sel", "=", "torch", ".", "where", "(", "\n", "(", "pc", ">", "p0", ")", "&", "(", "pc", ">", "p1", ")", ",", "z_dist", ".", "mean", "(", ")", ",", "zero_one", "\n", ")", "# [B, M]", "\n", "z", "=", "z_sel", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "# mask invalid positions", "\n", "", "", "z", "=", "z", ".", "squeeze", "(", "-", "1", ")", "\n", "z", "=", "torch", ".", "where", "(", "mask", ",", "z", ",", "z", ".", "new_zeros", "(", "[", "1", "]", ")", ")", "\n", "\n", "self", ".", "z", "=", "z", "# [B, T]", "\n", "self", ".", "z_dists", "=", "[", "z_dist", "]", "\n", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SelfAdditiveScorer.__init__": [[419, 426], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Tanh", "generators.SelfAdditiveScorer.init_weights", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SelfAdditiveScorer.init_weights"], ["def", "__init__", "(", "self", ",", "vector_size", ",", "attn_hidden_size", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "W", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "attn_hidden_size", ",", "vector_size", ")", ")", "\n", "self", ".", "b", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "attn_hidden_size", ")", ")", "\n", "self", ".", "v", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "attn_hidden_size", ")", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SelfAdditiveScorer.init_weights": [[427, 432], ["torch.nn.init.kaiming_uniform_", "torch.nn.init.uniform_", "torch.nn.init.kaiming_uniform_", "math.sqrt", "math.sqrt", "math.sqrt"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "nn", ".", "init", ".", "kaiming_uniform_", "(", "self", ".", "W", ",", "a", "=", "math", ".", "sqrt", "(", "5", ")", ")", "\n", "bound", "=", "1", "/", "math", ".", "sqrt", "(", "self", ".", "W", ".", "shape", "[", "1", "]", ")", "\n", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "b", ",", "-", "bound", ",", "bound", ")", "\n", "nn", ".", "init", ".", "kaiming_uniform_", "(", "self", ".", "v", ",", "a", "=", "math", ".", "sqrt", "(", "5", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SelfAdditiveScorer.forward": [[433, 448], ["generators.SelfAdditiveScorer.activation", "torch.matmul().squeeze", "torch.matmul", "math.sqrt", "generators.SelfAdditiveScorer.W.t", "torch.matmul", "keys.size", "generators.SelfAdditiveScorer.v.t"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "query", ",", "keys", ")", ":", "\n", "        ", "\"\"\"Computes scores for each key of size n given the queries of size m.\n\n        Args:\n            query (torch.FloatTensor): query matrix (bs, ..., target_len, d_q)\n            keys (torch.FloatTensor): keys matrix (bs, ..., source_len, d_k)\n\n        Returns:\n            torch.FloatTensor: scores between source and target words: (bs, ..., target_len, source_len)\n        \"\"\"", "\n", "# assume query = keys", "\n", "x", "=", "torch", ".", "matmul", "(", "query", ",", "self", ".", "W", ".", "t", "(", ")", ")", "+", "self", ".", "b", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "score", "=", "torch", ".", "matmul", "(", "x", ",", "self", ".", "v", ".", "t", "(", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "return", "score", "/", "math", ".", "sqrt", "(", "keys", ".", "size", "(", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.SoftmaxAttention.forward": [[516, 557], ["premise_batch.bmm", "generators.masked_softmax", "generators.masked_softmax", "generators.weighted_sum", "generators.weighted_sum", "hypothesis_batch.transpose().contiguous", "premise_batch.bmm.transpose().contiguous", "hypothesis_batch.transpose", "premise_batch.bmm.transpose"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.masked_softmax", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.masked_softmax", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.weighted_sum", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.weighted_sum"], ["def", "forward", "(", "self", ",", "premise_batch", ",", "premise_mask", ",", "hypothesis_batch", ",", "hypothesis_mask", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            premise_batch: A batch of sequences of vectors representing the\n                premises in some NLI task. The batch is assumed to have the\n                size (batch, sequences, vector_dim).\n            premise_mask: A mask for the sequences in the premise batch, to\n                ignore padding data in the sequences during the computation of\n                the attention.\n            hypothesis_batch: A batch of sequences of vectors representing the\n                hypotheses in some NLI task. The batch is assumed to have the\n                size (batch, sequences, vector_dim).\n            hypothesis_mask: A mask for the sequences in the hypotheses batch,\n                to ignore padding data in the sequences during the computation\n                of the attention.\n        Returns:\n            attended_premises: The sequences of attention vectors for the\n                premises in the input batch.\n            attended_hypotheses: The sequences of attention vectors for the\n                hypotheses in the input batch.\n        \"\"\"", "\n", "# Dot product between premises and hypotheses in each sequence of", "\n", "# the batch.", "\n", "similarity_matrix", "=", "premise_batch", ".", "bmm", "(", "\n", "hypothesis_batch", ".", "transpose", "(", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", ")", "\n", "\n", "# Softmax attention weights.", "\n", "prem_hyp_attn", "=", "masked_softmax", "(", "similarity_matrix", ",", "hypothesis_mask", ")", "\n", "hyp_prem_attn", "=", "masked_softmax", "(", "\n", "similarity_matrix", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ",", "premise_mask", "\n", ")", "\n", "\n", "# Weighted sums of the hypotheses for the the premises attention,", "\n", "# and vice-versa for the attention of the hypotheses.", "\n", "attended_premises", "=", "weighted_sum", "(", "hypothesis_batch", ",", "prem_hyp_attn", ",", "premise_mask", ")", "\n", "attended_hypotheses", "=", "weighted_sum", "(", "\n", "premise_batch", ",", "hyp_prem_attn", ",", "hypothesis_mask", "\n", ")", "\n", "\n", "return", "attended_premises", ",", "attended_hypotheses", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.masked_softmax": [[452, 480], ["tensor.size", "tensor.view", "mask.unsqueeze.expand_as().contiguous().float", "mask.unsqueeze.view", "torch.nn.functional.softmax", "nn.functional.softmax.view", "mask.unsqueeze.dim", "tensor.dim", "mask.unsqueeze.unsqueeze", "mask.unsqueeze.expand_as().contiguous", "mask.unsqueeze.size", "nn.functional.softmax.sum", "mask.unsqueeze.expand_as"], "function", ["None"], ["", "", "def", "masked_softmax", "(", "tensor", ",", "mask", ")", ":", "\n", "    ", "\"\"\"\n    Apply a masked softmax on the last dimension of a tensor.\n    The input tensor and mask should be of size (batch, *, sequence_length).\n    Args:\n        tensor: The tensor on which the softmax function must be applied along\n            the last dimension.\n        mask: A mask of the same size as the tensor with 0s in the positions of\n            the values that must be masked and 1s everywhere else.\n    Returns:\n        A tensor of the same size as the inputs containing the result of the\n        softmax.\n    \"\"\"", "\n", "tensor_shape", "=", "tensor", ".", "size", "(", ")", "\n", "reshaped_tensor", "=", "tensor", ".", "view", "(", "-", "1", ",", "tensor_shape", "[", "-", "1", "]", ")", "\n", "\n", "# Reshape the mask so it matches the size of the input tensor.", "\n", "while", "mask", ".", "dim", "(", ")", "<", "tensor", ".", "dim", "(", ")", ":", "\n", "        ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "", "mask", "=", "mask", ".", "expand_as", "(", "tensor", ")", ".", "contiguous", "(", ")", ".", "float", "(", ")", "\n", "reshaped_mask", "=", "mask", ".", "view", "(", "-", "1", ",", "mask", ".", "size", "(", ")", "[", "-", "1", "]", ")", "\n", "\n", "result", "=", "nn", ".", "functional", ".", "softmax", "(", "reshaped_tensor", "*", "reshaped_mask", ",", "dim", "=", "-", "1", ")", "\n", "result", "=", "result", "*", "reshaped_mask", "\n", "# 1e-13 is added to avoid divisions by zero.", "\n", "result", "=", "result", "/", "(", "result", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "+", "1e-13", ")", "\n", "\n", "return", "result", ".", "view", "(", "*", "tensor_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.generators.weighted_sum": [[484, 504], ["weights.bmm", "mask.unsqueeze.transpose", "mask.unsqueeze.expand_as().contiguous().float", "mask.unsqueeze.dim", "weights.bmm.dim", "mask.unsqueeze.unsqueeze", "mask.unsqueeze.expand_as().contiguous", "mask.unsqueeze.expand_as"], "function", ["None"], ["", "def", "weighted_sum", "(", "tensor", ",", "weights", ",", "mask", ")", ":", "\n", "    ", "\"\"\"\n    Apply a weighted sum on the vectors along the last dimension of 'tensor',\n    and mask the vectors in the result with 'mask'.\n    Args:\n        tensor: A tensor of vectors on which a weighted sum must be applied.\n        weights: The weights to use in the weighted sum.\n        mask: A mask to apply on the result of the weighted sum.\n    Returns:\n        A new tensor containing the result of the weighted sum after the mask\n        has been applied on it.\n    \"\"\"", "\n", "weighted_sum", "=", "weights", ".", "bmm", "(", "tensor", ")", "\n", "\n", "while", "mask", ".", "dim", "(", ")", "<", "weighted_sum", ".", "dim", "(", ")", ":", "\n", "        ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "", "mask", "=", "mask", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "weighted_sum", ")", ".", "contiguous", "(", ")", ".", "float", "(", ")", "\n", "\n", "return", "weighted_sum", "*", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.predictors.SentimentPredictor.__init__": [[19, 46], ["torch.nn.Module.__init__", "torch.nn.Sequential", "rationalizers.builders.build_sentence_encoder", "hasattr", "torch.nn.Sequential", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Sigmoid", "torch.nn.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.rationalizers.builders.build_sentence_encoder"], ["def", "__init__", "(", "\n", "self", ",", "\n", "embed", ":", "nn", ".", "Embedding", "=", "None", ",", "\n", "hidden_size", ":", "int", "=", "200", ",", "\n", "output_size", ":", "int", "=", "1", ",", "\n", "dropout", ":", "float", "=", "0.1", ",", "\n", "layer", ":", "str", "=", "\"rcnn\"", ",", "\n", "nonlinearity", ":", "str", "=", "\"sigmoid\"", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "emb_size", "=", "embed", ".", "weight", ".", "shape", "[", "1", "]", "\n", "\n", "self", ".", "embed_layer", "=", "nn", ".", "Sequential", "(", "embed", ",", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "\n", "self", ".", "enc_layer", "=", "build_sentence_encoder", "(", "layer", ",", "emb_size", ",", "hidden_size", ")", "\n", "\n", "if", "hasattr", "(", "self", ".", "enc_layer", ",", "\"cnn\"", ")", ":", "\n", "            ", "enc_size", "=", "self", ".", "enc_layer", ".", "cnn", ".", "out_channels", "\n", "", "else", ":", "\n", "            ", "enc_size", "=", "hidden_size", "*", "2", "\n", "\n", "", "self", ".", "output_layer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ",", "\n", "nn", ".", "Linear", "(", "enc_size", ",", "output_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", "if", "nonlinearity", "==", "\"sigmoid\"", "else", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.predictors.SentimentPredictor.forward": [[48, 70], ["x.cuda.cuda.cuda", "z.cuda.cuda.cuda", "mask.cuda.cuda.cuda", "predictors.SentimentPredictor.embed_layer", "mask.cuda.cuda.long().sum", "predictors.SentimentPredictor.enc_layer", "predictors.SentimentPredictor.output_layer", "z_mask.squeeze", "mask.cuda.cuda.long", "mask.cuda.cuda.float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "z", ",", "mask", "=", "None", ")", ":", "\n", "        ", "x", "=", "x", ".", "cuda", "(", ")", "\n", "z", "=", "z", ".", "cuda", "(", ")", "\n", "mask", "=", "mask", ".", "cuda", "(", ")", "\n", "rnn_mask", "=", "mask", "\n", "emb", "=", "self", ".", "embed_layer", "(", "x", ")", "\n", "# apply z to main inputs", "\n", "if", "z", "is", "not", "None", ":", "\n", "            ", "z_mask", "=", "(", "mask", ".", "float", "(", ")", "*", "z", ")", ".", "unsqueeze", "(", "-", "1", ")", "# [B, T, 1]", "\n", "rnn_mask", "=", "z_mask", ".", "squeeze", "(", "-", "1", ")", ">", "0.0", "# z could be continuous", "\n", "emb", "=", "emb", "*", "z_mask", "\n", "\n", "# z is also used to control when the encoder layer is active", "\n", "", "lengths", "=", "mask", ".", "long", "(", ")", ".", "sum", "(", "1", ")", "\n", "\n", "# encode the sentence", "\n", "_", ",", "final", "=", "self", ".", "enc_layer", "(", "emb", ",", "rnn_mask", ",", "lengths", ")", "\n", "\n", "# predict sentiment from final state(s)", "\n", "y", "=", "self", ".", "output_layer", "(", "final", ")", "\n", "\n", "return", "y", "\n", "", "", ""]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.RV.params": [[45, 47], ["NotImplementedError"], "methods", ["None"], ["    ", "def", "params", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Implement me\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.RV.sample": [[48, 50], ["NotImplementedError"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "size", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Implement me\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.RV.log_pdf": [[51, 53], ["NotImplementedError"], "methods", ["None"], ["", "def", "log_pdf", "(", "self", ",", "x", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Implement me\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.RV.log_cdf": [[54, 56], ["NotImplementedError"], "methods", ["None"], ["", "def", "log_cdf", "(", "self", ",", "x", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Implement me\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.RV.entropy": [[57, 59], ["NotImplementedError"], "methods", ["None"], ["", "def", "entropy", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Implement me\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.RV.pdf": [[60, 66], ["isinstance", "kuma.RV.log_pdf().exp", "[].new_tensor", "kuma.RV.log_pdf", "kuma.RV.params"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.log_pdf", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.params"], ["", "def", "pdf", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "x", ",", "float", ")", ":", "\n", "            ", "x", "=", "self", ".", "params", "(", ")", "[", "0", "]", ".", "new_tensor", "(", "[", "x", "]", ")", "\n", "\n", "", "return", "self", ".", "log_pdf", "(", "x", ")", ".", "exp", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.RV.cdf": [[67, 73], ["isinstance", "kuma.RV.log_cdf().exp", "[].new_tensor", "kuma.RV.log_cdf", "kuma.RV.params"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.log_cdf", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.params"], ["", "def", "cdf", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "x", ",", "float", ")", ":", "\n", "            ", "x", "=", "self", ".", "params", "(", ")", "[", "0", "]", ".", "new_tensor", "(", "[", "x", "]", ")", "\n", "\n", "", "return", "self", ".", "log_cdf", "(", "x", ")", ".", "exp", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.Kuma.__init__": [[94, 97], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "params", ":", "list", ")", ":", "\n", "        ", "self", ".", "a", "=", "params", "[", "0", "]", "\n", "self", ".", "b", "=", "params", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.Kuma.params": [[98, 100], ["None"], "methods", ["None"], ["", "def", "params", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "a", ",", "self", ".", "b", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.Kuma.mean": [[101, 103], ["kuma.kuma_moments"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.kuma_moments"], ["", "def", "mean", "(", "self", ")", ":", "\n", "        ", "return", "kuma_moments", "(", "self", ".", "a", ",", "self", ".", "b", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.Kuma.sample": [[104, 114], ["torch.zeros_like().uniform_", "isinstance", "kuma.Kuma.a.reciprocal", "kuma.Kuma.a.new_zeros().uniform_", "kuma.Kuma.a.new_zeros().uniform_", "torch.zeros_like", "kuma.Kuma.b.reciprocal", "kuma.Kuma.a.new_zeros", "kuma.Kuma.a.new_zeros", "list"], "methods", ["None"], ["", "def", "sample", "(", "self", ",", "size", "=", "None", ",", "eps", "=", "0.001", ")", ":", "\n", "\n", "        ", "if", "size", "is", "None", ":", "\n", "            ", "u", "=", "torch", ".", "zeros_like", "(", "self", ".", "a", ")", ".", "uniform_", "(", "eps", ",", "1.0", "-", "eps", ")", "\n", "", "elif", "isinstance", "(", "size", ",", "int", ")", ":", "\n", "            ", "u", "=", "self", ".", "a", ".", "new_zeros", "(", "[", "size", "]", "+", "list", "(", "self", ".", "a", ".", "shape", ")", ")", ".", "uniform_", "(", "eps", ",", "1.0", "-", "eps", ")", "\n", "", "else", ":", "# assume full shape", "\n", "            ", "u", "=", "self", ".", "a", ".", "new_zeros", "(", "size", ")", ".", "uniform_", "(", "eps", ",", "1.0", "-", "eps", ")", "\n", "\n", "", "return", "(", "1.0", "-", "(", "1", "-", "u", ")", "**", "self", ".", "b", ".", "reciprocal", "(", ")", ")", "**", "self", ".", "a", ".", "reciprocal", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.Kuma.log_pdf": [[115, 129], ["isinstance", "torch.log", "[].new_tensor", "torch.log", "torch.log", "torch.log", "kuma.Kuma.params"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.params"], ["", "def", "log_pdf", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Kuma(x|a, b) = U(s(x)|0, 1) |det J_s|\n            where x = t(u) and u = s(x) and J_s is the Jacobian matrix of s(x)\n        \"\"\"", "\n", "if", "isinstance", "(", "x", ",", "float", ")", ":", "\n", "            ", "x", "=", "self", ".", "params", "(", ")", "[", "0", "]", ".", "new_tensor", "(", "[", "x", "]", ")", "\n", "\n", "", "t1", "=", "torch", ".", "log", "(", "self", ".", "a", ")", "+", "torch", ".", "log", "(", "self", ".", "b", ")", "\n", "t2", "=", "(", "self", ".", "a", "-", "1.0", "+", "EPS", ")", "*", "torch", ".", "log", "(", "x", ")", "\n", "pow_x_a", "=", "(", "x", "**", "self", ".", "a", ")", "+", "EPS", "\n", "t3b", "=", "torch", ".", "log", "(", "1.0", "-", "pow_x_a", ")", "\n", "t3", "=", "(", "self", ".", "b", "-", "1.0", "+", "EPS", ")", "*", "t3b", "\n", "return", "t1", "+", "t2", "+", "t3", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.Kuma.log_cdf": [[130, 137], ["isinstance", "torch.log", "torch.log.clamp", "[].new_tensor", "math.log", "math.log", "kuma.Kuma.params"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.params"], ["", "def", "log_cdf", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "isinstance", "(", "x", ",", "float", ")", ":", "\n", "            ", "x", "=", "self", ".", "params", "(", ")", "[", "0", "]", ".", "new_tensor", "(", "[", "x", "]", ")", "\n", "\n", "", "r", "=", "1.0", "-", "(", "(", "1.0", "-", "(", "x", "**", "self", ".", "a", ")", ")", "**", "self", ".", "b", ")", "\n", "r", "=", "torch", ".", "log", "(", "r", "+", "EPS", ")", "\n", "return", "r", ".", "clamp", "(", "math", ".", "log", "(", "EPS", ")", ",", "math", ".", "log", "(", "1", "-", "EPS", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.StretchedVariable.__init__": [[151, 164], ["isinstance", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dist", ":", "RelaxedBinary", ",", "support", ":", "list", ")", ":", "\n", "        ", "\"\"\"\n        :param dist: a RelaxedBinary variable (e.g. BinaryConcrete or Kuma)\n        :param support: a pair specifying the limits of the stretched support (e.g. [-1, 2])\n            we use these values to compute location = pair[0] and scale = pair[1] - pair[0]\n        \"\"\"", "\n", "assert", "isinstance", "(", "\n", "dist", ",", "RelaxedBinary", "\n", ")", ",", "\"I need a RelaxedBinary variable, got %s\"", "%", "type", "(", "dist", ")", "\n", "assert", "support", "[", "0", "]", "<", "support", "[", "1", "]", ",", "\"I need an ordered support, got %s\"", "%", "support", "\n", "self", ".", "_dist", "=", "dist", "\n", "self", ".", "loc", "=", "support", "[", "0", "]", "\n", "self", ".", "scale", "=", "support", "[", "1", "]", "-", "support", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.StretchedVariable.params": [[165, 167], ["kuma.StretchedVariable._dist.params"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.params"], ["", "def", "params", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_dist", ".", "params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.StretchedVariable.sample": [[168, 175], ["kuma.StretchedVariable._dist.sample", "kuma.StretchedVariable.loc.to", "kuma.StretchedVariable.scale.to"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.sample"], ["", "def", "sample", "(", "self", ",", "size", "=", "None", ")", ":", "\n", "# sample a relaxed binary variable", "\n", "        ", "x_", "=", "self", ".", "_dist", ".", "sample", "(", "size", "=", "size", ")", "\n", "self", ".", "loc", "=", "self", ".", "loc", ".", "to", "(", "x_", ".", "device", ")", "\n", "self", ".", "scale", "=", "self", ".", "scale", ".", "to", "(", "x_", ".", "device", ")", "\n", "# and stretch it", "\n", "return", "x_", "*", "self", ".", "scale", "+", "self", ".", "loc", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.StretchedVariable.log_pdf": [[176, 192], ["isinstance", "isinstance", "kuma.StretchedVariable.loc.to", "kuma.StretchedVariable.scale.to", "[].new_tensor", "[].new_tensor", "kuma.StretchedVariable._dist.log_pdf", "torch.log", "kuma.StretchedVariable.params", "kuma.StretchedVariable.params"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.log_pdf", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.params", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.params"], ["", "def", "log_pdf", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "x", ",", "float", ")", ":", "\n", "            ", "x", "=", "self", ".", "params", "(", ")", "[", "0", "]", ".", "new_tensor", "(", "[", "x", "]", ")", "\n", "\n", "", "if", "isinstance", "(", "self", ".", "scale", ",", "float", ")", ":", "\n", "            ", "self", ".", "scale", "=", "self", ".", "params", "(", ")", "[", "0", "]", ".", "new_tensor", "(", "[", "self", ".", "scale", "]", ")", "\n", "\n", "", "self", ".", "loc", "=", "self", ".", "loc", ".", "to", "(", "x", ".", "device", ")", "\n", "self", ".", "scale", "=", "self", ".", "scale", ".", "to", "(", "x", ".", "device", ")", "\n", "\n", "# shrink the stretched variable", "\n", "x_", "=", "(", "x", "-", "self", ".", "loc", ")", "/", "self", ".", "scale", "\n", "# and assess the stretched pdf using the original pdf", "\n", "# see eq 25 (left) of Louizos et al", "\n", "return", "self", ".", "_dist", ".", "log_pdf", "(", "x_", ")", "-", "torch", ".", "log", "(", "self", ".", "scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.StretchedVariable.log_cdf": [[193, 206], ["isinstance", "kuma.StretchedVariable.loc.to", "kuma.StretchedVariable.scale.to", "kuma.StretchedVariable._dist.log_cdf().clamp", "[].new_tensor", "math.log", "math.log", "kuma.StretchedVariable._dist.log_cdf", "kuma.StretchedVariable.params"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.log_cdf", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.params"], ["", "def", "log_cdf", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "x", ",", "float", ")", ":", "\n", "            ", "x", "=", "self", ".", "params", "(", ")", "[", "0", "]", ".", "new_tensor", "(", "[", "x", "]", ")", "\n", "\n", "", "self", ".", "loc", "=", "self", ".", "loc", ".", "to", "(", "x", ".", "device", ")", "\n", "self", ".", "scale", "=", "self", ".", "scale", ".", "to", "(", "x", ".", "device", ")", "\n", "\n", "# shrink the stretched variable", "\n", "x_", "=", "(", "x", "-", "self", ".", "loc", ")", "/", "self", ".", "scale", "\n", "# assess its cdf", "\n", "# see eq 25 (right) of Louizos et al", "\n", "return", "self", ".", "_dist", ".", "log_cdf", "(", "x_", ")", ".", "clamp", "(", "math", ".", "log", "(", "EPS", ")", ",", "math", ".", "log", "(", "1", "-", "EPS", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.__init__": [[218, 221], ["isinstance"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dist", ":", "StretchedVariable", ")", ":", "\n", "        ", "assert", "isinstance", "(", "dist", ",", "StretchedVariable", ")", ",", "\"I need a stretched variable\"", "\n", "self", ".", "_dist", "=", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.params": [[222, 224], ["kuma.HardBinary._dist.params"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.params"], ["", "def", "params", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_dist", ".", "params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.sample": [[225, 229], ["kuma.HardBinary._dist.sample", "torch.nn.functional.hardtanh"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.sample"], ["", "def", "sample", "(", "self", ",", "size", "=", "None", ")", ":", "\n", "# sample a stretched variable and rectify it", "\n", "        ", "x_", "=", "self", ".", "_dist", ".", "sample", "(", "size", "=", "size", ")", "\n", "return", "F", ".", "hardtanh", "(", "x_", ",", "min_val", "=", "0.0", ",", "max_val", "=", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.log_pdf": [[230, 259], ["isinstance", "kuma.HardBinary._dist.log_cdf", "kuma.HardBinary._dist.cdf", "torch.where", "torch.where", "[].new_tensor", "[].new_tensor.new_zeros().to", "[].new_tensor.new_ones", "torch.log", "kuma.HardBinary._dist.log_pdf", "[].new_tensor.new_zeros", "kuma.HardBinary.params"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.log_cdf", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.RV.cdf", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.log_pdf", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.params"], ["", "def", "log_pdf", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        We obtain pdf(0) by integrating the stretched variable over the interval [left, 0]\n            HardBinary.pdf(0) = StretchedVariable.cdf(0)\n         and pdf(1) by integrating the stretched variable over the interval [1, right], or equivalently,\n            HardBinary.pdf(1) = 1 - StretchedVariable.cdf(1)\n         finally, for values in the open (0, 1) we scale the pdf of the stretched variable by the remaining probability\n         mass HardBinary.pdf(x) = StretchedVariable.pdf(x) * (1 - HardBinary.pdf(0) - HardBinary.pdf(1))\n        See that the total mass over the discrete set {0, 1} is\n            HardBinary.pdf(0) + HardBinary.pdf(1)\n         in other words, with this probability we will be sampling a discrete value.\n         Whenever this probability is greater than 0.5, most probability mass is away from continuous samples.\n        \"\"\"", "\n", "\n", "if", "isinstance", "(", "x", ",", "float", ")", ":", "\n", "            ", "x", "=", "self", ".", "params", "(", ")", "[", "0", "]", ".", "new_tensor", "(", "[", "x", "]", ")", "\n", "\n", "# cache these for faster computation", "\n", "", "log_cdf_0", "=", "self", ".", "_dist", ".", "log_cdf", "(", "x", ".", "new_zeros", "(", "1", ")", ".", "to", "(", "x", ".", "device", ")", ")", "\n", "cdf_1", "=", "self", ".", "_dist", ".", "cdf", "(", "x", ".", "new_ones", "(", "1", ")", ")", "\n", "\n", "# first we fix log_pdf for 0s and 1s", "\n", "log_p", "=", "torch", ".", "where", "(", "\n", "x", "==", "0.0", ",", "log_cdf_0", ",", "torch", ".", "log", "(", "1.0", "-", "cdf_1", ")", "\n", ")", "# log Q(0)  # log (1-Q(1))", "\n", "# then for those that are in the open (0, 1)", "\n", "log_p", "=", "torch", ".", "where", "(", "(", "0.0", "<", "x", ")", "&", "(", "x", "<", "1.0", ")", ",", "self", ".", "_dist", ".", "log_pdf", "(", "x", ")", ",", "log_p", ")", "\n", "# see eq 26 of Louizos et al", "\n", "return", "log_p", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.log_cdf": [[260, 274], ["isinstance", "torch.where", "torch.where.clamp", "[].new_tensor", "kuma.HardBinary._dist.log_cdf", "[].new_tensor.new_zeros", "math.log", "math.log", "[].new_tensor.size", "kuma.HardBinary.params"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.log_cdf", "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardBinary.params"], ["", "def", "log_cdf", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Note that HardKuma.cdf(0) = HardKuma.pdf(0) by definition of HardKuma.pdf(0),\n         also note that HardKuma.cdf(1) = 1 by definition because\n         the support of HardKuma is the *closed* interval [0, 1]\n         and not the open interval (left, right) which is the support of the stretched variable.\n        \"\"\"", "\n", "if", "isinstance", "(", "x", ",", "float", ")", ":", "\n", "            ", "x", "=", "self", ".", "params", "(", ")", "[", "0", "]", ".", "new_tensor", "(", "[", "x", "]", ")", "\n", "\n", "", "log_c", "=", "torch", ".", "where", "(", "\n", "x", "<", "1.0", ",", "self", ".", "_dist", ".", "log_cdf", "(", "x", ")", ",", "x", ".", "new_zeros", "(", "x", ".", "size", "(", ")", ")", "\n", ")", "# all of the mass", "\n", "return", "log_c", ".", "clamp", "(", "math", ".", "log", "(", "EPS", ")", ",", "math", ".", "log", "(", "1", "-", "EPS", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__": [[277, 283], ["kuma.HardBinary.__init__", "kuma.StretchedVariable", "kuma.Kuma"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.__init__"], ["    ", "def", "__init__", "(", "self", ",", "params", ":", "list", ",", "support", ":", "list", ")", ":", "\n", "        ", "super", "(", "HardKuma", ",", "self", ")", ".", "__init__", "(", "StretchedVariable", "(", "Kuma", "(", "params", ")", ",", "support", ")", ")", "\n", "\n", "# shortcut to underlying a and b", "\n", "self", ".", "a", "=", "self", ".", "_dist", ".", "_dist", ".", "a", "\n", "self", ".", "b", "=", "self", ".", "_dist", ".", "_dist", ".", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.HardKuma.mean": [[284, 286], ["kuma.kuma_moments"], "methods", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.kuma_moments"], ["", "def", "mean", "(", "self", ")", ":", "\n", "        ", "return", "kuma_moments", "(", "self", ".", "a", ",", "self", ".", "b", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.convert_to_tensor": [[11, 15], ["isinstance", "torch.Tensor"], "function", ["None"], ["def", "convert_to_tensor", "(", "x", ")", ":", "\n", "    ", "if", "isinstance", "(", "x", ",", "float", ")", ":", "\n", "        ", "return", "torch", ".", "Tensor", "(", "[", "x", "]", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.lbeta": [[21, 25], ["torch.lgamma().sum", "torch.lgamma", "x.sum", "torch.lgamma"], "function", ["None"], ["", "def", "lbeta", "(", "x", ")", ":", "\n", "    ", "log_prod_gamma_x", "=", "torch", ".", "lgamma", "(", "x", ")", ".", "sum", "(", "-", "1", ")", "\n", "log_gamma_sum_x", "=", "torch", ".", "lgamma", "(", "x", ".", "sum", "(", "-", "1", ")", ")", "\n", "return", "log_prod_gamma_x", "-", "log_gamma_sum_x", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma._harmonic_number": [[27, 42], ["x.new_ones", "torch.digamma", "torch.digamma"], "function", ["None"], ["", "def", "_harmonic_number", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    From Tensorflow Probability.\n    Compute the harmonic number from its analytic continuation.\n    Derivation from [here](\n    https://en.wikipedia.org/wiki/Digamma_function#Relation_to_harmonic_numbers)\n    and [Euler's constant](\n    https://en.wikipedia.org/wiki/Euler%E2%80%93Mascheroni_constant).\n    Args:\n      x: input float.\n    Returns:\n      z: The analytic continuation of the harmonic number for the input.\n    \"\"\"", "\n", "one", "=", "x", ".", "new_ones", "(", "[", "1", "]", ")", "\n", "return", "torch", ".", "digamma", "(", "x", "+", "one", ")", "-", "torch", ".", "digamma", "(", "one", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.kuma_mean": [[288, 290], ["kuma.kuma_moments"], "function", ["home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.kuma_moments"], ["", "", "def", "kuma_mean", "(", "a", ",", "b", ")", ":", "\n", "    ", "return", "kuma_moments", "(", "a", ",", "b", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.deep-spin_spectra-rationalization.modules.kuma.kuma_moments": [[292, 303], ["torch.lgamma", "torch.exp", "torch.lgamma", "torch.lgamma"], "function", ["None"], ["", "def", "kuma_moments", "(", "a", ",", "b", ",", "n", ")", ":", "\n", "    ", "\"\"\"\n    Computes nth moment of Kumaraswamy using using torch.lgamma\n    :param a:\n    :param b:\n    :param n:\n    :return: nth moment\n    \"\"\"", "\n", "arg1", "=", "1", "+", "n", "/", "a", "\n", "log_value", "=", "torch", ".", "lgamma", "(", "arg1", ")", "+", "torch", ".", "lgamma", "(", "b", ")", "-", "torch", ".", "lgamma", "(", "arg1", "+", "b", ")", "\n", "return", "b", "*", "torch", ".", "exp", "(", "log_value", ")", "\n", "", ""]]}