{"home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupRandomCrop.__init__": [[12, 17], ["isinstance", "int", "int"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "if", "isinstance", "(", "size", ",", "numbers", ".", "Number", ")", ":", "\n", "            ", "self", ".", "size", "=", "(", "int", "(", "size", ")", ",", "int", "(", "size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupRandomCrop.__call__": [[18, 36], ["list", "random.randint", "random.randint", "list.append", "list.append", "img.crop"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "img_group", ")", ":", "\n", "\n", "        ", "w", ",", "h", "=", "img_group", "[", "0", "]", ".", "size", "\n", "th", ",", "tw", "=", "self", ".", "size", "\n", "\n", "out_images", "=", "list", "(", ")", "\n", "\n", "x1", "=", "random", ".", "randint", "(", "0", ",", "w", "-", "tw", ")", "\n", "y1", "=", "random", ".", "randint", "(", "0", ",", "h", "-", "th", ")", "\n", "\n", "for", "img", "in", "img_group", ":", "\n", "            ", "assert", "(", "img", ".", "size", "[", "0", "]", "==", "w", "and", "img", ".", "size", "[", "1", "]", "==", "h", ")", "\n", "if", "w", "==", "tw", "and", "h", "==", "th", ":", "\n", "                ", "out_images", ".", "append", "(", "img", ")", "\n", "", "else", ":", "\n", "                ", "out_images", ".", "append", "(", "img", ".", "crop", "(", "(", "x1", ",", "y1", ",", "x1", "+", "tw", ",", "y1", "+", "th", ")", ")", ")", "\n", "\n", "", "", "return", "out_images", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupCenterCrop.__init__": [[39, 41], ["torchvision.transforms.CenterCrop"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "self", ".", "worker", "=", "torchvision", ".", "transforms", ".", "CenterCrop", "(", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupCenterCrop.__call__": [[42, 44], ["transforms.GroupCenterCrop.worker"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img_group", ")", ":", "\n", "        ", "return", "[", "self", ".", "worker", "(", "img", ")", "for", "img", "in", "img_group", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupRandomHorizontalFlip.__init__": [[49, 51], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "is_flow", "=", "False", ")", ":", "\n", "        ", "self", ".", "is_flow", "=", "is_flow", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupRandomHorizontalFlip.__call__": [[52, 62], ["random.random", "img.transpose", "range", "len", "PIL.ImageOps.invert"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img_group", ",", "is_flow", "=", "False", ")", ":", "\n", "        ", "v", "=", "random", ".", "random", "(", ")", "\n", "if", "v", "<", "0.5", ":", "\n", "            ", "ret", "=", "[", "img", ".", "transpose", "(", "Image", ".", "FLIP_LEFT_RIGHT", ")", "for", "img", "in", "img_group", "]", "\n", "if", "self", ".", "is_flow", ":", "\n", "                ", "for", "i", "in", "range", "(", "0", ",", "len", "(", "ret", ")", ",", "2", ")", ":", "\n", "                    ", "ret", "[", "i", "]", "=", "ImageOps", ".", "invert", "(", "ret", "[", "i", "]", ")", "# invert flow pixel values when flipping", "\n", "", "", "return", "ret", "\n", "", "else", ":", "\n", "            ", "return", "img_group", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupNormalize.__init__": [[65, 68], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "mean", ",", "std", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupNormalize.__call__": [[69, 78], ["zip", "t.sub_().div_", "len", "len", "tensor.size", "tensor.size", "t.sub_"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "rep_mean", "=", "self", ".", "mean", "*", "(", "tensor", ".", "size", "(", ")", "[", "0", "]", "//", "len", "(", "self", ".", "mean", ")", ")", "\n", "rep_std", "=", "self", ".", "std", "*", "(", "tensor", ".", "size", "(", ")", "[", "0", "]", "//", "len", "(", "self", ".", "std", ")", ")", "\n", "\n", "# TODO: make efficient", "\n", "for", "t", ",", "m", ",", "s", "in", "zip", "(", "tensor", ",", "rep_mean", ",", "rep_std", ")", ":", "\n", "            ", "t", ".", "sub_", "(", "m", ")", ".", "div_", "(", "s", ")", "\n", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupScale.__init__": [[89, 91], ["torchvision.transforms.Scale"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "interpolation", "=", "Image", ".", "BILINEAR", ")", ":", "\n", "        ", "self", ".", "worker", "=", "torchvision", ".", "transforms", ".", "Scale", "(", "size", ",", "interpolation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupScale.__call__": [[92, 94], ["transforms.GroupScale.worker"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img_group", ")", ":", "\n", "        ", "return", "[", "self", ".", "worker", "(", "img", ")", "for", "img", "in", "img_group", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupOverSample.__init__": [[97, 104], ["transforms.GroupScale", "isinstance"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "crop_size", ",", "scale_size", "=", "None", ")", ":", "\n", "        ", "self", ".", "crop_size", "=", "crop_size", "if", "not", "isinstance", "(", "crop_size", ",", "int", ")", "else", "(", "crop_size", ",", "crop_size", ")", "\n", "\n", "if", "scale_size", "is", "not", "None", ":", "\n", "            ", "self", ".", "scale_worker", "=", "GroupScale", "(", "scale_size", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "scale_worker", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupOverSample.__call__": [[105, 134], ["transforms.GroupMultiScaleCrop.fill_fix_offset", "list", "transforms.GroupOverSample.scale_worker", "list", "list", "enumerate", "list.extend", "img.crop", "list.append"], "methods", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupMultiScaleCrop.fill_fix_offset"], ["", "", "def", "__call__", "(", "self", ",", "img_group", ")", ":", "\n", "\n", "        ", "if", "self", ".", "scale_worker", "is", "not", "None", ":", "\n", "            ", "img_group", "=", "self", ".", "scale_worker", "(", "img_group", ")", "\n", "\n", "", "image_w", ",", "image_h", "=", "img_group", "[", "0", "]", ".", "size", "\n", "crop_w", ",", "crop_h", "=", "self", ".", "crop_size", "\n", "\n", "offsets", "=", "GroupMultiScaleCrop", ".", "fill_fix_offset", "(", "True", ",", "image_w", ",", "image_h", ",", "crop_w", ",", "crop_h", ")", "\n", "oversample_group", "=", "list", "(", ")", "\n", "for", "o_w", ",", "o_h", "in", "offsets", ":", "\n", "            ", "normal_group", "=", "list", "(", ")", "\n", "flip_group", "=", "list", "(", ")", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "img_group", ")", ":", "\n", "#print(img.size)", "\n", "                ", "crop", "=", "img", ".", "crop", "(", "(", "o_w", ",", "o_h", ",", "o_w", "+", "crop_w", ",", "o_h", "+", "crop_h", ")", ")", "\n", "#print([o_w, o_h, o_w + crop_w, o_h + crop_h])", "\n", "normal_group", ".", "append", "(", "crop", ")", "\n", "#flip_crop = crop.copy().transpose(Image.FLIP_LEFT_RIGHT)", "\n", "#flip_group.append(flip_crop)", "\n", "\n", "#if img.mode == 'L' and i % 2 == 0:", "\n", "#flip_group.append(ImageOps.invert(flip_crop))", "\n", "#else:", "\n", "#flip_group.append(flip_crop)", "\n", "\n", "", "oversample_group", ".", "extend", "(", "normal_group", ")", "\n", "#oversample_group.extend(flip_group)", "\n", "", "return", "oversample_group", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupSpatialElasticDisplacement.__init__": [[137, 141], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "displacement", "=", "20", "\n", "self", ".", "displacement_kernel", "=", "25", "\n", "self", ".", "displacement_magnification", "=", "0.60", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupSpatialElasticDisplacement.__call__": [[143, 163], ["random.random", "cv2.GaussianBlur", "numpy.floor().astype", "numpy.clip", "numpy.clip", "numpy.tile().T.astype", "numpy.tile().astype", "PIL.Image.fromarray", "numpy.floor", "[].reshape", "numpy.random.rand", "numpy.tile", "numpy.tile", "numpy.arange", "numpy.asarray", "numpy.arange", "numpy.asarray", "numpy.clip.flatten", "numpy.clip.flatten"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img_group", ")", ":", "\n", "        ", "v", "=", "random", ".", "random", "(", ")", "\n", "if", "v", "<", "0.5", ":", "\n", "            ", "im_size", "=", "img_group", "[", "0", "]", ".", "size", "\n", "image_w", ",", "image_h", "=", "im_size", "[", "0", "]", ",", "im_size", "[", "1", "]", "\n", "displacement_map", "=", "np", ".", "random", ".", "rand", "(", "image_h", ",", "image_w", ",", "2", ")", "*", "2", "*", "self", ".", "displacement", "-", "self", ".", "displacement", "\n", "displacement_map", "=", "cv2", ".", "GaussianBlur", "(", "displacement_map", ",", "None", ",", "self", ".", "displacement_kernel", ")", "\n", "displacement_map", "*=", "self", ".", "displacement_magnification", "*", "self", ".", "displacement_kernel", "\n", "displacement_map", "=", "np", ".", "floor", "(", "displacement_map", ")", ".", "astype", "(", "'int32'", ")", "\n", "\n", "displacement_map_rows", "=", "displacement_map", "[", "...", ",", "0", "]", "+", "np", ".", "tile", "(", "np", ".", "arange", "(", "image_h", ")", ",", "(", "image_w", ",", "1", ")", ")", ".", "T", ".", "astype", "(", "'int32'", ")", "\n", "displacement_map_rows", "=", "np", ".", "clip", "(", "displacement_map_rows", ",", "0", ",", "image_h", "-", "1", ")", "\n", "\n", "displacement_map_cols", "=", "displacement_map", "[", "...", ",", "1", "]", "+", "np", ".", "tile", "(", "np", ".", "arange", "(", "image_w", ")", ",", "(", "image_h", ",", "1", ")", ")", ".", "astype", "(", "'int32'", ")", "\n", "displacement_map_cols", "=", "np", ".", "clip", "(", "displacement_map_cols", ",", "0", ",", "image_w", "-", "1", ")", "\n", "ret_img_group", "=", "[", "Image", ".", "fromarray", "(", "np", ".", "asarray", "(", "img", ")", "[", "(", "displacement_map_rows", ".", "flatten", "(", ")", ",", "displacement_map_cols", ".", "flatten", "(", ")", ")", "]", ".", "reshape", "(", "np", ".", "asarray", "(", "img", ")", ".", "shape", ")", ")", "for", "img", "in", "img_group", "]", "\n", "return", "ret_img_group", "\n", "\n", "", "else", ":", "\n", "            ", "return", "img_group", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupMultiScaleResize.__init__": [[168, 170], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "scale", ")", ":", "\n", "        ", "self", ".", "scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupMultiScaleResize.__call__": [[171, 177], ["random.uniform", "img.resize", "int", "int"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img_group", ")", ":", "\n", "        ", "im_size", "=", "img_group", "[", "0", "]", ".", "size", "\n", "self", ".", "resize_const", "=", "random", ".", "uniform", "(", "1.0", "-", "self", ".", "scale", ",", "1.0", "+", "self", ".", "scale", ")", "# Aplly random resize constant ", "\n", "resize_img_group", "=", "[", "img", ".", "resize", "(", "(", "int", "(", "im_size", "[", "0", "]", "*", "self", ".", "resize_const", ")", ",", "int", "(", "im_size", "[", "1", "]", "*", "self", ".", "resize_const", ")", ")", ")", "for", "img", "in", "img_group", "]", "\n", "\n", "return", "resize_img_group", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupMultiScaleRotate.__init__": [[182, 185], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "degree", ")", ":", "\n", "        ", "self", ".", "degree", "=", "degree", "\n", "self", ".", "interpolation", "=", "Image", ".", "BILINEAR", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupMultiScaleRotate.__call__": [[186, 192], ["random.randint", "img.rotate"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img_group", ")", ":", "\n", "        ", "im_size", "=", "img_group", "[", "0", "]", ".", "size", "\n", "self", ".", "rotate_angle", "=", "random", ".", "randint", "(", "-", "self", ".", "degree", ",", "self", ".", "degree", ")", "# Aplly random rotation angle", "\n", "ret_img_group", "=", "[", "img", ".", "rotate", "(", "self", ".", "rotate_angle", ",", "resample", "=", "self", ".", "interpolation", ")", "for", "img", "in", "img_group", "]", "\n", "\n", "return", "ret_img_group", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupMultiScaleCrop.__init__": [[197, 204], ["isinstance"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "scales", "=", "None", ",", "max_distort", "=", "1", ",", "fix_crop", "=", "True", ",", "more_fix_crop", "=", "False", ")", ":", "\n", "        ", "self", ".", "scales", "=", "scales", "if", "scales", "is", "not", "None", "else", "[", "1", ",", "875", ",", ".75", ",", ".66", "]", "\n", "self", ".", "max_distort", "=", "max_distort", "\n", "self", ".", "fix_crop", "=", "fix_crop", "\n", "self", ".", "more_fix_crop", "=", "more_fix_crop", "\n", "self", ".", "input_size", "=", "input_size", "if", "not", "isinstance", "(", "input_size", ",", "int", ")", "else", "[", "input_size", ",", "input_size", "]", "\n", "self", ".", "interpolation", "=", "Image", ".", "BILINEAR", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupMultiScaleCrop.__call__": [[205, 216], ["transforms.GroupMultiScaleCrop._sample_crop_size", "img.crop", "img.resize"], "methods", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupMultiScaleCrop._sample_crop_size"], ["", "def", "__call__", "(", "self", ",", "img_group", ")", ":", "\n", "\n", "        ", "im_size", "=", "img_group", "[", "0", "]", ".", "size", "\n", "#self.scales = [1, random.uniform(0.85, 1.0)]", "\n", "\n", "crop_w", ",", "crop_h", ",", "offset_w", ",", "offset_h", "=", "self", ".", "_sample_crop_size", "(", "im_size", ")", "\n", "crop_img_group", "=", "[", "img", ".", "crop", "(", "(", "offset_w", ",", "offset_h", ",", "offset_w", "+", "crop_w", ",", "offset_h", "+", "crop_h", ")", ")", "for", "img", "in", "img_group", "]", "\n", "ret_img_group", "=", "[", "img", ".", "resize", "(", "(", "self", ".", "input_size", "[", "0", "]", ",", "self", ".", "input_size", "[", "1", "]", ")", ",", "self", ".", "interpolation", ")", "\n", "for", "img", "in", "crop_img_group", "]", "\n", "\n", "return", "ret_img_group", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupMultiScaleCrop._sample_crop_size": [[217, 240], ["min", "enumerate", "random.choice", "int", "enumerate", "random.randint", "random.randint", "transforms.GroupMultiScaleCrop._sample_fix_offset", "abs", "abs", "abs", "pairs.append"], "methods", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupMultiScaleCrop._sample_fix_offset"], ["", "def", "_sample_crop_size", "(", "self", ",", "im_size", ")", ":", "\n", "        ", "image_w", ",", "image_h", "=", "im_size", "[", "0", "]", ",", "im_size", "[", "1", "]", "\n", "\n", "# find a crop size", "\n", "base_size", "=", "min", "(", "image_w", ",", "image_h", ")", "\n", "crop_sizes", "=", "[", "int", "(", "base_size", "*", "x", ")", "for", "x", "in", "self", ".", "scales", "]", "\n", "crop_h", "=", "[", "self", ".", "input_size", "[", "1", "]", "if", "abs", "(", "x", "-", "self", ".", "input_size", "[", "1", "]", ")", "<", "3", "else", "x", "for", "x", "in", "crop_sizes", "]", "\n", "crop_w", "=", "[", "self", ".", "input_size", "[", "0", "]", "if", "abs", "(", "x", "-", "self", ".", "input_size", "[", "0", "]", ")", "<", "3", "else", "x", "for", "x", "in", "crop_sizes", "]", "\n", "\n", "pairs", "=", "[", "]", "\n", "for", "i", ",", "h", "in", "enumerate", "(", "crop_h", ")", ":", "\n", "            ", "for", "j", ",", "w", "in", "enumerate", "(", "crop_w", ")", ":", "\n", "                ", "if", "abs", "(", "i", "-", "j", ")", "<=", "self", ".", "max_distort", ":", "\n", "                    ", "pairs", ".", "append", "(", "(", "w", ",", "h", ")", ")", "\n", "\n", "", "", "", "crop_pair", "=", "random", ".", "choice", "(", "pairs", ")", "\n", "if", "not", "self", ".", "fix_crop", ":", "\n", "            ", "w_offset", "=", "random", ".", "randint", "(", "0", ",", "image_w", "-", "crop_pair", "[", "0", "]", ")", "\n", "h_offset", "=", "random", ".", "randint", "(", "0", ",", "image_h", "-", "crop_pair", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "w_offset", ",", "h_offset", "=", "self", ".", "_sample_fix_offset", "(", "image_w", ",", "image_h", ",", "crop_pair", "[", "0", "]", ",", "crop_pair", "[", "1", "]", ")", "\n", "\n", "", "return", "crop_pair", "[", "0", "]", ",", "crop_pair", "[", "1", "]", ",", "w_offset", ",", "h_offset", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupMultiScaleCrop._sample_fix_offset": [[241, 244], ["transforms.GroupMultiScaleCrop.fill_fix_offset", "random.choice"], "methods", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupMultiScaleCrop.fill_fix_offset"], ["", "def", "_sample_fix_offset", "(", "self", ",", "image_w", ",", "image_h", ",", "crop_w", ",", "crop_h", ")", ":", "\n", "        ", "offsets", "=", "self", ".", "fill_fix_offset", "(", "self", ".", "more_fix_crop", ",", "image_w", ",", "image_h", ",", "crop_w", ",", "crop_h", ")", "\n", "return", "random", ".", "choice", "(", "offsets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupMultiScaleCrop.fill_fix_offset": [[245, 269], ["list", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append", "list.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "fill_fix_offset", "(", "more_fix_crop", ",", "image_w", ",", "image_h", ",", "crop_w", ",", "crop_h", ")", ":", "\n", "        ", "w_step", "=", "(", "image_w", "-", "crop_w", ")", "//", "4", "\n", "h_step", "=", "(", "image_h", "-", "crop_h", ")", "//", "4", "\n", "\n", "ret", "=", "list", "(", ")", "\n", "ret", ".", "append", "(", "(", "0", ",", "0", ")", ")", "# upper left", "\n", "ret", ".", "append", "(", "(", "4", "*", "w_step", ",", "0", ")", ")", "# upper right", "\n", "ret", ".", "append", "(", "(", "0", ",", "4", "*", "h_step", ")", ")", "# lower left", "\n", "ret", ".", "append", "(", "(", "4", "*", "w_step", ",", "4", "*", "h_step", ")", ")", "# lower right", "\n", "ret", ".", "append", "(", "(", "2", "*", "w_step", ",", "2", "*", "h_step", ")", ")", "# center", "\n", "\n", "if", "more_fix_crop", ":", "\n", "            ", "ret", ".", "append", "(", "(", "0", "*", "w_step", ",", "2", "*", "h_step", ")", ")", "# center left", "\n", "ret", ".", "append", "(", "(", "4", "*", "w_step", ",", "2", "*", "h_step", ")", ")", "# center right", "\n", "ret", ".", "append", "(", "(", "2", "*", "w_step", ",", "4", "*", "h_step", ")", ")", "# lower center", "\n", "ret", ".", "append", "(", "(", "2", "*", "w_step", ",", "0", "*", "h_step", ")", ")", "# upper center", "\n", "\n", "ret", ".", "append", "(", "(", "1", "*", "w_step", ",", "1", "*", "h_step", ")", ")", "# upper left quarter", "\n", "ret", ".", "append", "(", "(", "3", "*", "w_step", ",", "1", "*", "h_step", ")", ")", "# upper right quarter", "\n", "ret", ".", "append", "(", "(", "1", "*", "w_step", ",", "3", "*", "h_step", ")", ")", "# lower left quarter", "\n", "ret", ".", "append", "(", "(", "3", "*", "w_step", ",", "3", "*", "h_step", ")", ")", "# lower righ quarter", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupRandomSizedCrop.__init__": [[278, 281], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "size", ",", "interpolation", "=", "Image", ".", "BILINEAR", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "interpolation", "=", "interpolation", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.GroupRandomSizedCrop.__call__": [[282, 316], ["range", "random.uniform", "int", "int", "list", "transforms.GroupScale", "transforms.GroupRandomCrop", "GroupRandomCrop.", "random.uniform", "round", "round", "random.random", "random.randint", "random.randint", "img.crop.crop.crop", "list.append", "GroupScale.", "math.sqrt", "math.sqrt", "img.crop.crop.resize"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img_group", ")", ":", "\n", "        ", "for", "attempt", "in", "range", "(", "10", ")", ":", "\n", "            ", "area", "=", "img_group", "[", "0", "]", ".", "size", "[", "0", "]", "*", "img_group", "[", "0", "]", ".", "size", "[", "1", "]", "\n", "target_area", "=", "random", ".", "uniform", "(", "0.08", ",", "1.0", ")", "*", "area", "\n", "aspect_ratio", "=", "random", ".", "uniform", "(", "3.", "/", "4", ",", "4.", "/", "3", ")", "\n", "\n", "w", "=", "int", "(", "round", "(", "math", ".", "sqrt", "(", "target_area", "*", "aspect_ratio", ")", ")", ")", "\n", "h", "=", "int", "(", "round", "(", "math", ".", "sqrt", "(", "target_area", "/", "aspect_ratio", ")", ")", ")", "\n", "\n", "if", "random", ".", "random", "(", ")", "<", "0.5", ":", "\n", "                ", "w", ",", "h", "=", "h", ",", "w", "\n", "\n", "", "if", "w", "<=", "img_group", "[", "0", "]", ".", "size", "[", "0", "]", "and", "h", "<=", "img_group", "[", "0", "]", ".", "size", "[", "1", "]", ":", "\n", "                ", "x1", "=", "random", ".", "randint", "(", "0", ",", "img_group", "[", "0", "]", ".", "size", "[", "0", "]", "-", "w", ")", "\n", "y1", "=", "random", ".", "randint", "(", "0", ",", "img_group", "[", "0", "]", ".", "size", "[", "1", "]", "-", "h", ")", "\n", "found", "=", "True", "\n", "break", "\n", "", "", "else", ":", "\n", "            ", "found", "=", "False", "\n", "x1", "=", "0", "\n", "y1", "=", "0", "\n", "\n", "", "if", "found", ":", "\n", "            ", "out_group", "=", "list", "(", ")", "\n", "for", "img", "in", "img_group", ":", "\n", "                ", "img", "=", "img", ".", "crop", "(", "(", "x1", ",", "y1", ",", "x1", "+", "w", ",", "y1", "+", "h", ")", ")", "\n", "assert", "(", "img", ".", "size", "==", "(", "w", ",", "h", ")", ")", "\n", "out_group", ".", "append", "(", "img", ".", "resize", "(", "(", "self", ".", "size", ",", "self", ".", "size", ")", ",", "self", ".", "interpolation", ")", ")", "\n", "", "return", "out_group", "\n", "", "else", ":", "\n", "# Fallback", "\n", "            ", "scale", "=", "GroupScale", "(", "self", ".", "size", ",", "interpolation", "=", "self", ".", "interpolation", ")", "\n", "crop", "=", "GroupRandomCrop", "(", "self", ".", "size", ")", "\n", "return", "crop", "(", "scale", "(", "img_group", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.Stack.__init__": [[320, 323], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "roll", "=", "False", ",", "isRGBFlow", "=", "False", ")", ":", "\n", "        ", "self", ".", "roll", "=", "roll", "\n", "self", ".", "isRGBFlow", "=", "isRGBFlow", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.Stack.__call__": [[324, 349], ["numpy.array", "numpy.concatenate", "numpy.expand_dims", "numpy.concatenate", "numpy.expand_dims", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.expand_dims", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "img_group", ")", ":", "\n", "        ", "if", "self", ".", "isRGBFlow", ":", "\n", "            ", "stacked_array", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "for", "x", "in", "img_group", ":", "\n", "                ", "if", "x", ".", "mode", "==", "'L'", ":", "\n", "                    ", "if", "stacked_array", ".", "size", "==", "0", ":", "\n", "                        ", "stacked_array", "=", "np", ".", "expand_dims", "(", "x", ",", "2", ")", "\n", "", "else", ":", "\n", "                        ", "stacked_array", "=", "np", ".", "concatenate", "(", "[", "stacked_array", ",", "np", ".", "expand_dims", "(", "x", ",", "2", ")", "]", ",", "axis", "=", "2", ")", "\n", "", "", "elif", "x", ".", "mode", "==", "'RGB'", ":", "\n", "                    ", "if", "self", ".", "roll", ":", "\n", "                        ", "stacked_array", "=", "np", ".", "concatenate", "(", "[", "stacked_array", ",", "np", ".", "array", "(", "x", ")", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "]", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "                        ", "stacked_array", "=", "np", ".", "concatenate", "(", "[", "stacked_array", ",", "np", ".", "array", "(", "x", ")", "]", ",", "axis", "=", "2", ")", "\n", "", "", "", "return", "stacked_array", "\n", "\n", "", "else", ":", "\n", "            ", "if", "img_group", "[", "0", "]", ".", "mode", "==", "'L'", ":", "\n", "                ", "return", "np", ".", "concatenate", "(", "[", "np", ".", "expand_dims", "(", "x", ",", "2", ")", "for", "x", "in", "img_group", "]", ",", "axis", "=", "2", ")", "\n", "", "elif", "img_group", "[", "0", "]", ".", "mode", "==", "'RGB'", ":", "\n", "                ", "if", "self", ".", "roll", ":", "\n", "                    ", "asd", "=", "np", ".", "concatenate", "(", "[", "np", ".", "array", "(", "x", ")", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "for", "x", "in", "img_group", "]", ",", "axis", "=", "2", ")", "\n", "return", "np", ".", "concatenate", "(", "[", "np", ".", "array", "(", "x", ")", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", "for", "x", "in", "img_group", "]", ",", "axis", "=", "2", ")", "\n", "", "else", ":", "\n", "                    ", "return", "np", ".", "concatenate", "(", "img_group", ",", "axis", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.ToTorchFormatTensor.__init__": [[354, 356], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "div", "=", "True", ")", ":", "\n", "        ", "self", ".", "div", "=", "div", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.ToTorchFormatTensor.__call__": [[357, 369], ["isinstance", "torch.from_numpy().permute().contiguous", "torch.ByteTensor", "img.transpose().transpose().contiguous.transpose().transpose().contiguous.view", "img.transpose().transpose().contiguous.transpose().transpose().contiguous.transpose().transpose().contiguous", "img.transpose().transpose().contiguous.transpose().transpose().contiguous.float().div", "img.transpose().transpose().contiguous.transpose().transpose().contiguous.float", "torch.ByteStorage.from_buffer", "len", "torch.from_numpy().permute", "pic.tobytes", "img.transpose().transpose().contiguous.transpose().transpose().contiguous.transpose().transpose", "img.transpose().transpose().contiguous.transpose().transpose().contiguous.float", "torch.from_numpy", "img.transpose().transpose().contiguous.transpose().transpose().contiguous.transpose"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "pic", ")", ":", "\n", "        ", "if", "isinstance", "(", "pic", ",", "np", ".", "ndarray", ")", ":", "\n", "# handle numpy array", "\n", "            ", "img", "=", "torch", ".", "from_numpy", "(", "pic", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "# handle PIL Image", "\n", "            ", "img", "=", "torch", ".", "ByteTensor", "(", "torch", ".", "ByteStorage", ".", "from_buffer", "(", "pic", ".", "tobytes", "(", ")", ")", ")", "\n", "img", "=", "img", ".", "view", "(", "pic", ".", "size", "[", "1", "]", ",", "pic", ".", "size", "[", "0", "]", ",", "len", "(", "pic", ".", "mode", ")", ")", "\n", "# put it from HWC to CHW format", "\n", "# yikes, this transpose takes 80% of the loading time/CPU", "\n", "img", "=", "img", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "0", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "", "return", "img", ".", "float", "(", ")", ".", "div", "(", "255", ")", "if", "self", ".", "div", "else", "img", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.transforms.IdentityTransform.__call__": [[373, 375], ["None"], "methods", ["None"], ["    ", "def", "__call__", "(", "self", ",", "data", ")", ":", "\n", "        ", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN.__init__": [[11, 79], ["torch.nn.Module.__init__", "models.TSN._prepare_base_model", "models.TSN._prepare_tsn", "ValueError", "print", "print", "models.TSN._construct_flow_model", "print", "MLPmodule.return_MLP", "ops.basic_ops.ConsensusModule", "torch.nn.Softmax", "models.TSN.partialBN", "print", "models.TSN._construct_diff_model", "print", "print", "models.TSN._construct_rgbflow_model", "print"], "methods", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.basic_ops.ConsensusModule.__init__", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN._prepare_base_model", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN._prepare_tsn", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN._construct_flow_model", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.MLPmodule.return_MLP", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN.partialBN", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN._construct_diff_model", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN._construct_rgbflow_model"], ["    ", "def", "__init__", "(", "self", ",", "num_class", ",", "num_segments", ",", "modality", ",", "\n", "base_model", "=", "'resnet101'", ",", "new_length", "=", "None", ",", "\n", "consensus_type", "=", "'avg'", ",", "before_softmax", "=", "True", ",", "num_motion", "=", "3", ",", "\n", "dropout", "=", "0.8", ",", "img_feature_dim", "=", "256", ",", "dataset", "=", "'jester'", ",", "\n", "crop_num", "=", "1", ",", "partial_bn", "=", "True", ",", "print_spec", "=", "True", ")", ":", "\n", "        ", "super", "(", "TSN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "modality", "=", "modality", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "num_motion", "=", "num_motion", "\n", "self", ".", "reshape", "=", "True", "\n", "self", ".", "before_softmax", "=", "before_softmax", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "crop_num", "=", "crop_num", "\n", "self", ".", "consensus_type", "=", "consensus_type", "\n", "self", ".", "img_feature_dim", "=", "img_feature_dim", "# the dimension of the CNN feature to represent each frame", "\n", "if", "not", "before_softmax", "and", "consensus_type", "!=", "'avg'", ":", "\n", "            ", "raise", "ValueError", "(", "\"Only avg consensus can be used after Softmax\"", ")", "\n", "\n", "", "if", "new_length", "is", "None", ":", "\n", "            ", "if", "modality", "==", "\"RGB\"", ":", "\n", "                ", "self", ".", "new_length", "=", "1", "\n", "", "elif", "modality", "==", "\"Flow\"", ":", "\n", "                ", "self", ".", "new_length", "=", "5", "\n", "", "elif", "modality", "==", "\"RGBFlow\"", ":", "\n", "#self.new_length = 1", "\n", "                ", "self", ".", "new_length", "=", "self", ".", "num_motion", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "new_length", "=", "new_length", "\n", "", "if", "print_spec", "==", "True", ":", "\n", "            ", "print", "(", "(", "\"\"\"\n    Initializing TSN with base model: {}.\n    TSN Configurations:\n        input_modality:     {}\n        num_segments:       {}\n        new_length:         {}\n        consensus_module:   {}\n        dropout_ratio:      {}\n        img_feature_dim:    {}\n            \"\"\"", ".", "format", "(", "base_model", ",", "self", ".", "modality", ",", "self", ".", "num_segments", ",", "self", ".", "new_length", ",", "consensus_type", ",", "self", ".", "dropout", ",", "self", ".", "img_feature_dim", ")", ")", ")", "\n", "\n", "", "self", ".", "_prepare_base_model", "(", "base_model", ")", "\n", "\n", "feature_dim", "=", "self", ".", "_prepare_tsn", "(", "num_class", ")", "\n", "\n", "if", "self", ".", "modality", "==", "'Flow'", ":", "\n", "            ", "print", "(", "\"Converting the ImageNet model to a flow init model\"", ")", "\n", "self", ".", "base_model", "=", "self", ".", "_construct_flow_model", "(", "self", ".", "base_model", ")", "\n", "print", "(", "\"Done. Flow model ready...\"", ")", "\n", "", "elif", "self", ".", "modality", "==", "'RGBDiff'", ":", "\n", "            ", "print", "(", "\"Converting the ImageNet model to RGB+Diff init model\"", ")", "\n", "self", ".", "base_model", "=", "self", ".", "_construct_diff_model", "(", "self", ".", "base_model", ")", "\n", "print", "(", "\"Done. RGBDiff model ready.\"", ")", "\n", "", "elif", "self", ".", "modality", "==", "'RGBFlow'", ":", "\n", "            ", "print", "(", "\"Converting the ImageNet model to RGB+Flow init model\"", ")", "\n", "self", ".", "base_model", "=", "self", ".", "_construct_rgbflow_model", "(", "self", ".", "base_model", ")", "\n", "print", "(", "\"Done. RGBFlow model ready.\"", ")", "\n", "", "if", "consensus_type", "==", "'MLP'", ":", "\n", "            ", "self", ".", "consensus", "=", "MLPmodule", ".", "return_MLP", "(", "consensus_type", ",", "self", ".", "img_feature_dim", ",", "self", ".", "num_segments", ",", "num_class", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "consensus", "=", "ConsensusModule", "(", "consensus_type", ")", "\n", "\n", "", "if", "not", "self", ".", "before_softmax", ":", "\n", "            ", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", ")", "\n", "\n", "", "self", ".", "_enable_pbn", "=", "partial_bn", "\n", "if", "partial_bn", ":", "\n", "            ", "self", ".", "partialBN", "(", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN._prepare_tsn": [[81, 103], ["getattr", "setattr", "setattr", "torch.nn.init.normal", "torch.nn.init.constant", "torch.nn.init.normal", "torch.nn.init.constant", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "getattr", "getattr"], "methods", ["None"], ["", "", "def", "_prepare_tsn", "(", "self", ",", "num_class", ")", ":", "\n", "        ", "feature_dim", "=", "getattr", "(", "self", ".", "base_model", ",", "self", ".", "base_model", ".", "last_layer_name", ")", ".", "in_features", "\n", "if", "self", ".", "dropout", "==", "0", ":", "\n", "            ", "setattr", "(", "self", ".", "base_model", ",", "self", ".", "base_model", ".", "last_layer_name", ",", "nn", ".", "Linear", "(", "feature_dim", ",", "num_class", ")", ")", "\n", "self", ".", "new_fc", "=", "None", "\n", "", "else", ":", "\n", "            ", "setattr", "(", "self", ".", "base_model", ",", "self", ".", "base_model", ".", "last_layer_name", ",", "nn", ".", "Dropout", "(", "p", "=", "self", ".", "dropout", ")", ")", "\n", "if", "self", ".", "consensus_type", "==", "'MLP'", ":", "\n", "# set the MFFs feature dimension", "\n", "                ", "self", ".", "new_fc", "=", "nn", ".", "Linear", "(", "feature_dim", ",", "self", ".", "img_feature_dim", ")", "\n", "", "else", ":", "\n", "# the default consensus types in TSN", "\n", "                ", "self", ".", "new_fc", "=", "nn", ".", "Linear", "(", "feature_dim", ",", "num_class", ")", "\n", "\n", "", "", "std", "=", "0.001", "\n", "if", "self", ".", "new_fc", "is", "None", ":", "\n", "            ", "normal", "(", "getattr", "(", "self", ".", "base_model", ",", "self", ".", "base_model", ".", "last_layer_name", ")", ".", "weight", ",", "0", ",", "std", ")", "\n", "constant", "(", "getattr", "(", "self", ".", "base_model", ",", "self", ".", "base_model", ".", "last_layer_name", ")", ".", "bias", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "normal", "(", "self", ".", "new_fc", ".", "weight", ",", "0", ",", "std", ")", "\n", "constant", "(", "self", ".", "new_fc", ".", "bias", ",", "0", ")", "\n", "", "return", "feature_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN._prepare_base_model": [[104, 146], ["np.mean", "print", "ValueError", "np.mean"], "methods", ["None"], ["", "def", "_prepare_base_model", "(", "self", ",", "base_model", ")", ":", "\n", "\n", "        ", "if", "'resnet'", "in", "base_model", "or", "'vgg'", "in", "base_model", "or", "'squeezenet1_1'", "in", "base_model", ":", "\n", "            ", "self", ".", "base_model", "=", "pretrainedmodels", ".", "__dict__", "[", "base_model", "]", "(", "num_classes", "=", "1000", ",", "pretrained", "=", "'imagenet'", ")", "\n", "if", "base_model", "==", "'squeezenet1_1'", ":", "\n", "                ", "self", ".", "base_model", "=", "self", ".", "base_model", ".", "features", "\n", "self", ".", "base_model", ".", "last_layer_name", "=", "'12'", "\n", "", "else", ":", "\n", "                ", "self", ".", "base_model", ".", "last_layer_name", "=", "'fc'", "\n", "", "self", ".", "input_size", "=", "224", "\n", "self", ".", "input_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "self", ".", "input_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "\n", "if", "self", ".", "modality", "==", "'Flow'", ":", "\n", "                ", "self", ".", "input_mean", "=", "[", "0.5", "]", "\n", "self", ".", "input_std", "=", "[", "np", ".", "mean", "(", "self", ".", "input_std", ")", "]", "\n", "", "elif", "self", ".", "modality", "==", "'RGBDiff'", ":", "\n", "                ", "self", ".", "input_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "+", "[", "0", "]", "*", "3", "*", "self", ".", "new_length", "\n", "self", ".", "input_std", "=", "self", ".", "input_std", "+", "[", "np", ".", "mean", "(", "self", ".", "input_std", ")", "*", "2", "]", "*", "3", "*", "self", ".", "new_length", "\n", "", "", "elif", "base_model", "==", "'BNInception'", ":", "\n", "            ", "self", ".", "base_model", "=", "pretrainedmodels", ".", "__dict__", "[", "'bninception'", "]", "(", "num_classes", "=", "1000", ",", "pretrained", "=", "'imagenet'", ")", "\n", "self", ".", "base_model", ".", "last_layer_name", "=", "'last_linear'", "\n", "self", ".", "input_size", "=", "224", "\n", "self", ".", "input_mean", "=", "[", "104", ",", "117", ",", "128", "]", "\n", "self", ".", "input_std", "=", "[", "1", "]", "\n", "if", "self", ".", "modality", "==", "'Flow'", ":", "\n", "                ", "self", ".", "input_mean", "=", "[", "128", "]", "\n", "", "elif", "self", ".", "modality", "==", "'RGBDiff'", ":", "\n", "                ", "self", ".", "input_mean", "=", "self", ".", "input_mean", "*", "(", "1", "+", "self", ".", "new_length", ")", "\n", "", "", "elif", "'resnext101'", "in", "base_model", ":", "\n", "            ", "self", ".", "base_model", "=", "pretrainedmodels", ".", "__dict__", "[", "base_model", "]", "(", "num_classes", "=", "1000", ",", "pretrained", "=", "'imagenet'", ")", "\n", "print", "(", "self", ".", "base_model", ")", "\n", "self", ".", "base_model", ".", "last_layer_name", "=", "'last_linear'", "\n", "self", ".", "input_size", "=", "224", "\n", "self", ".", "input_mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", "\n", "self", ".", "input_std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", "if", "self", ".", "modality", "==", "'Flow'", ":", "\n", "                ", "self", ".", "input_mean", "=", "[", "128", "]", "\n", "", "elif", "self", ".", "modality", "==", "'RGBDiff'", ":", "\n", "                ", "self", ".", "input_mean", "=", "self", ".", "input_mean", "*", "(", "1", "+", "self", ".", "new_length", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown base model: {}'", ".", "format", "(", "base_model", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN.train": [[147, 165], ["super().train", "print", "models.TSN.base_model.modules", "isinstance", "m.eval"], "methods", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.train"], ["", "", "def", "train", "(", "self", ",", "mode", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Override the default train() to freeze the BN parameters\n        :return:\n        \"\"\"", "\n", "super", "(", "TSN", ",", "self", ")", ".", "train", "(", "mode", ")", "\n", "count", "=", "0", "\n", "if", "self", ".", "_enable_pbn", ":", "\n", "            ", "print", "(", "\"Freezing BatchNorm2D except the first one.\"", ")", "\n", "for", "m", "in", "self", ".", "base_model", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                    ", "count", "+=", "1", "\n", "if", "count", ">=", "(", "2", "if", "self", ".", "_enable_pbn", "else", "1", ")", ":", "\n", "                        ", "m", ".", "eval", "(", ")", "\n", "\n", "# shutdown update in frozen mode", "\n", "m", ".", "weight", ".", "requires_grad", "=", "False", "\n", "m", ".", "bias", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN.partialBN": [[167, 169], ["None"], "methods", ["None"], ["", "", "", "", "", "def", "partialBN", "(", "self", ",", "enable", ")", ":", "\n", "        ", "self", ".", "_enable_pbn", "=", "enable", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN.get_optim_policies": [[170, 219], ["models.TSN.modules", "isinstance", "isinstance", "list", "isinstance", "m.parameters", "first_conv_weight.append", "normal_weight.append", "list", "normal_weight.append", "isinstance", "len", "first_conv_bias.append", "len", "normal_bias.append", "m.parameters", "len", "normal_bias.append", "bn.extend", "isinstance", "list", "m.parameters", "bn.extend", "len", "list", "len", "ValueError", "m.parameters", "list", "m.parameters", "type"], "methods", ["None"], ["", "def", "get_optim_policies", "(", "self", ")", ":", "\n", "        ", "first_conv_weight", "=", "[", "]", "\n", "first_conv_bias", "=", "[", "]", "\n", "normal_weight", "=", "[", "]", "\n", "normal_bias", "=", "[", "]", "\n", "bn", "=", "[", "]", "\n", "\n", "conv_cnt", "=", "0", "\n", "bn_cnt", "=", "0", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "Conv1d", ")", ":", "\n", "                ", "ps", "=", "list", "(", "m", ".", "parameters", "(", ")", ")", "\n", "conv_cnt", "+=", "1", "\n", "if", "conv_cnt", "==", "1", ":", "\n", "                    ", "first_conv_weight", ".", "append", "(", "ps", "[", "0", "]", ")", "\n", "if", "len", "(", "ps", ")", "==", "2", ":", "\n", "                        ", "first_conv_bias", ".", "append", "(", "ps", "[", "1", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "normal_weight", ".", "append", "(", "ps", "[", "0", "]", ")", "\n", "if", "len", "(", "ps", ")", "==", "2", ":", "\n", "                        ", "normal_bias", ".", "append", "(", "ps", "[", "1", "]", ")", "\n", "", "", "", "elif", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "Linear", ")", ":", "\n", "                ", "ps", "=", "list", "(", "m", ".", "parameters", "(", ")", ")", "\n", "normal_weight", ".", "append", "(", "ps", "[", "0", "]", ")", "\n", "if", "len", "(", "ps", ")", "==", "2", ":", "\n", "                    ", "normal_bias", ".", "append", "(", "ps", "[", "1", "]", ")", "\n", "\n", "", "", "elif", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "BatchNorm1d", ")", ":", "\n", "                ", "bn", ".", "extend", "(", "list", "(", "m", ".", "parameters", "(", ")", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "torch", ".", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "bn_cnt", "+=", "1", "\n", "# later BN's are frozen", "\n", "if", "not", "self", ".", "_enable_pbn", "or", "bn_cnt", "==", "1", ":", "\n", "                    ", "bn", ".", "extend", "(", "list", "(", "m", ".", "parameters", "(", ")", ")", ")", "\n", "", "", "elif", "len", "(", "m", ".", "_modules", ")", "==", "0", ":", "\n", "                ", "if", "len", "(", "list", "(", "m", ".", "parameters", "(", ")", ")", ")", ">", "0", ":", "\n", "                    ", "raise", "ValueError", "(", "\"New atomic module type: {}. Need to give it a learning policy\"", ".", "format", "(", "type", "(", "m", ")", ")", ")", "\n", "\n", "", "", "", "return", "[", "\n", "{", "'params'", ":", "first_conv_weight", ",", "'lr_mult'", ":", "5", "if", "self", ".", "modality", "==", "'Flow'", "else", "1", ",", "'decay_mult'", ":", "1", ",", "\n", "'name'", ":", "\"first_conv_weight\"", "}", ",", "\n", "{", "'params'", ":", "first_conv_bias", ",", "'lr_mult'", ":", "10", "if", "self", ".", "modality", "==", "'Flow'", "else", "2", ",", "'decay_mult'", ":", "0", ",", "\n", "'name'", ":", "\"first_conv_bias\"", "}", ",", "\n", "{", "'params'", ":", "normal_weight", ",", "'lr_mult'", ":", "1", ",", "'decay_mult'", ":", "1", ",", "\n", "'name'", ":", "\"normal_weight\"", "}", ",", "\n", "{", "'params'", ":", "normal_bias", ",", "'lr_mult'", ":", "2", ",", "'decay_mult'", ":", "0", ",", "\n", "'name'", ":", "\"normal_bias\"", "}", ",", "\n", "{", "'params'", ":", "bn", ",", "'lr_mult'", ":", "1", ",", "'decay_mult'", ":", "0", ",", "\n", "'name'", ":", "\"BN scale/shift\"", "}", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN.forward": [[221, 243], ["models.TSN.base_model", "models.TSN.consensus", "models.TSN.squeeze", "models.TSN._get_diff", "models.TSN.view", "models.TSN.new_fc", "models.TSN.softmax", "base_out.view.view.view", "models.TSN.size", "base_out.view.view.size"], "methods", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN._get_diff", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.utils.softmax"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "sample_len", "=", "(", "3", "if", "self", ".", "modality", "==", "\"RGB\"", "else", "2", ")", "*", "self", ".", "new_length", "\n", "\n", "if", "self", ".", "modality", "==", "'RGBDiff'", ":", "\n", "            ", "sample_len", "=", "3", "*", "self", ".", "new_length", "\n", "input", "=", "self", ".", "_get_diff", "(", "input", ")", "\n", "\n", "", "if", "self", ".", "modality", "==", "'RGBFlow'", ":", "\n", "            ", "sample_len", "=", "3", "+", "2", "*", "self", ".", "new_length", "\n", "\n", "", "base_out", "=", "self", ".", "base_model", "(", "input", ".", "view", "(", "(", "-", "1", ",", "sample_len", ")", "+", "input", ".", "size", "(", ")", "[", "-", "2", ":", "]", ")", ")", "\n", "\n", "if", "self", ".", "dropout", ">", "0", ":", "\n", "            ", "base_out", "=", "self", ".", "new_fc", "(", "base_out", ")", "\n", "\n", "", "if", "not", "self", ".", "before_softmax", ":", "\n", "            ", "base_out", "=", "self", ".", "softmax", "(", "base_out", ")", "\n", "", "if", "self", ".", "reshape", ":", "\n", "            ", "base_out", "=", "base_out", ".", "view", "(", "(", "-", "1", ",", "self", ".", "num_segments", ")", "+", "base_out", ".", "size", "(", ")", "[", "1", ":", "]", ")", "\n", "\n", "", "output", "=", "self", ".", "consensus", "(", "base_out", ")", "\n", "return", "output", ".", "squeeze", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN._get_diff": [[244, 259], ["input.view", "reversed", "input.view.clone", "input_view[].clone", "list", "range", "input.size"], "methods", ["None"], ["", "def", "_get_diff", "(", "self", ",", "input", ",", "keep_rgb", "=", "False", ")", ":", "\n", "        ", "input_c", "=", "3", "if", "self", ".", "modality", "in", "[", "\"RGB\"", ",", "\"RGBDiff\"", "]", "else", "2", "\n", "input_view", "=", "input", ".", "view", "(", "(", "-", "1", ",", "self", ".", "num_segments", ",", "self", ".", "new_length", "+", "1", ",", "input_c", ",", ")", "+", "input", ".", "size", "(", ")", "[", "2", ":", "]", ")", "\n", "if", "keep_rgb", ":", "\n", "            ", "new_data", "=", "input_view", ".", "clone", "(", ")", "\n", "", "else", ":", "\n", "            ", "new_data", "=", "input_view", "[", ":", ",", ":", ",", "1", ":", ",", ":", ",", ":", ",", ":", "]", ".", "clone", "(", ")", "\n", "\n", "", "for", "x", "in", "reversed", "(", "list", "(", "range", "(", "1", ",", "self", ".", "new_length", "+", "1", ")", ")", ")", ":", "\n", "            ", "if", "keep_rgb", ":", "\n", "                ", "new_data", "[", ":", ",", ":", ",", "x", ",", ":", ",", ":", ",", ":", "]", "=", "input_view", "[", ":", ",", ":", ",", "x", ",", ":", ",", ":", ",", ":", "]", "-", "input_view", "[", ":", ",", ":", ",", "x", "-", "1", ",", ":", ",", ":", ",", ":", "]", "\n", "", "else", ":", "\n", "                ", "new_data", "[", ":", ",", ":", ",", "x", "-", "1", ",", ":", ",", ":", ",", ":", "]", "=", "input_view", "[", ":", ",", ":", ",", "x", ",", ":", ",", ":", ",", ":", "]", "-", "input_view", "[", ":", ",", ":", ",", "x", "-", "1", ",", ":", ",", ":", ",", ":", "]", "\n", "\n", "", "", "return", "new_data", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN._construct_rgbflow_model": [[268, 296], ["list", "filter", "next", "params[].size", "torch.cat", "torch.nn.Conv2d", "setattr", "models.TSN.base_model.modules", "list", "x.clone", "len", "isinstance", "range", "conv_layer.parameters", "params[].data.mean().expand().contiguous", "list", "len", "container.state_dict().keys", "params[].data.mean().expand", "len", "container.state_dict", "params[].data.mean"], "methods", ["None"], ["def", "_construct_rgbflow_model", "(", "self", ",", "base_model", ")", ":", "\n", "# modify the convolution layers", "\n", "# Torch models are usually defined in a hierarchical way.", "\n", "# nn.modules.children() return all sub modules in a DFS manner", "\n", "        ", "modules", "=", "list", "(", "self", ".", "base_model", ".", "modules", "(", ")", ")", "\n", "filter_conv2d", "=", "filter", "(", "lambda", "x", ":", "isinstance", "(", "modules", "[", "x", "]", ",", "nn", ".", "Conv2d", ")", ",", "list", "(", "range", "(", "len", "(", "modules", ")", ")", ")", ")", "\n", "first_conv_idx", "=", "next", "(", "filter_conv2d", ")", "\n", "conv_layer", "=", "modules", "[", "first_conv_idx", "]", "\n", "container", "=", "modules", "[", "first_conv_idx", "-", "1", "]", "\n", "\n", "# modify parameters, assume the first blob contains the convolution kernels", "\n", "params", "=", "[", "x", ".", "clone", "(", ")", "for", "x", "in", "conv_layer", ".", "parameters", "(", ")", "]", "\n", "kernel_size", "=", "params", "[", "0", "]", ".", "size", "(", ")", "\n", "new_kernel_size", "=", "kernel_size", "[", ":", "1", "]", "+", "(", "2", "*", "self", ".", "new_length", ",", ")", "+", "kernel_size", "[", "2", ":", "]", "\n", "new_kernels", "=", "torch", ".", "cat", "(", "(", "params", "[", "0", "]", ".", "data", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ".", "expand", "(", "new_kernel_size", ")", ".", "contiguous", "(", ")", ",", "params", "[", "0", "]", ".", "data", ")", ",", "1", ")", "# NOTE: Concatanating might be other way around. Check it!", "\n", "new_kernel_size", "=", "kernel_size", "[", ":", "1", "]", "+", "(", "3", "+", "2", "*", "self", ".", "new_length", ",", ")", "+", "kernel_size", "[", "2", ":", "]", "\n", "\n", "new_conv", "=", "nn", ".", "Conv2d", "(", "new_kernel_size", "[", "1", "]", ",", "conv_layer", ".", "out_channels", ",", "\n", "conv_layer", ".", "kernel_size", ",", "conv_layer", ".", "stride", ",", "conv_layer", ".", "padding", ",", "\n", "bias", "=", "True", "if", "len", "(", "params", ")", "==", "2", "else", "False", ")", "\n", "new_conv", ".", "weight", ".", "data", "=", "new_kernels", "\n", "if", "len", "(", "params", ")", "==", "2", ":", "\n", "            ", "new_conv", ".", "bias", ".", "data", "=", "params", "[", "1", "]", ".", "data", "# add bias if neccessary", "\n", "", "layer_name", "=", "list", "(", "container", ".", "state_dict", "(", ")", ".", "keys", "(", ")", ")", "[", "0", "]", "[", ":", "-", "7", "]", "# remove .weight suffix to get the layer name", "\n", "\n", "# replace the first convolution layer", "\n", "setattr", "(", "container", ",", "layer_name", ",", "new_conv", ")", "\n", "return", "base_model", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN._construct_flow_model": [[297, 325], ["list", "params[].size", "print", "print", "params[].data.mean().expand().contiguous", "torch.nn.Conv2d", "setattr", "models.TSN.base_model.modules", "list", "x.clone", "len", "filter", "conv_layer.parameters", "params[].data.mean().expand", "list", "list", "container.state_dict().keys", "isinstance", "range", "params[].data.mean", "len", "len", "container.state_dict"], "methods", ["None"], ["", "def", "_construct_flow_model", "(", "self", ",", "base_model", ")", ":", "\n", "# modify the convolution layers", "\n", "# Torch models are usually defined in a hierarchical way.", "\n", "# nn.modules.children() return all sub modules in a DFS manner", "\n", "        ", "modules", "=", "list", "(", "self", ".", "base_model", ".", "modules", "(", ")", ")", "\n", "first_conv_idx", "=", "list", "(", "filter", "(", "lambda", "x", ":", "isinstance", "(", "modules", "[", "x", "]", ",", "nn", ".", "Conv2d", ")", ",", "list", "(", "range", "(", "len", "(", "modules", ")", ")", ")", ")", ")", "[", "0", "]", "\n", "conv_layer", "=", "modules", "[", "first_conv_idx", "]", "\n", "container", "=", "modules", "[", "first_conv_idx", "-", "1", "]", "\n", "\n", "# modify parameters, assume the first blob contains the convolution kernels", "\n", "params", "=", "[", "x", ".", "clone", "(", ")", "for", "x", "in", "conv_layer", ".", "parameters", "(", ")", "]", "\n", "kernel_size", "=", "params", "[", "0", "]", ".", "size", "(", ")", "\n", "print", "(", "kernel_size", ")", "\n", "new_kernel_size", "=", "kernel_size", "[", ":", "1", "]", "+", "(", "2", "*", "self", ".", "new_length", ",", ")", "+", "kernel_size", "[", "2", ":", "]", "\n", "print", "(", "new_kernel_size", ")", "\n", "new_kernels", "=", "params", "[", "0", "]", ".", "data", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ".", "expand", "(", "new_kernel_size", ")", ".", "contiguous", "(", ")", "\n", "\n", "new_conv", "=", "nn", ".", "Conv2d", "(", "2", "*", "self", ".", "new_length", ",", "conv_layer", ".", "out_channels", ",", "\n", "conv_layer", ".", "kernel_size", ",", "conv_layer", ".", "stride", ",", "conv_layer", ".", "padding", ",", "\n", "bias", "=", "True", "if", "len", "(", "params", ")", "==", "2", "else", "False", ")", "\n", "new_conv", ".", "weight", ".", "data", "=", "new_kernels", "\n", "if", "len", "(", "params", ")", "==", "2", ":", "\n", "            ", "new_conv", ".", "bias", ".", "data", "=", "params", "[", "1", "]", ".", "data", "# add bias if neccessary", "\n", "", "layer_name", "=", "list", "(", "container", ".", "state_dict", "(", ")", ".", "keys", "(", ")", ")", "[", "0", "]", "[", ":", "-", "7", "]", "# remove .weight suffix to get the layer name", "\n", "\n", "# replace the first convlution layer", "\n", "setattr", "(", "container", ",", "layer_name", ",", "new_conv", ")", "\n", "return", "base_model", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN._construct_diff_model": [[326, 358], ["list", "params[].size", "torch.nn.Conv2d", "setattr", "models.TSN.base_model.modules", "filter", "x.clone", "params[].data.mean().expand().contiguous", "torch.cat", "len", "list", "conv_layer.parameters", "list", "isinstance", "range", "params[].data.mean().expand", "params[].data.mean().expand().contiguous", "container.state_dict().keys", "len", "len", "params[].data.mean", "params[].data.mean().expand", "container.state_dict", "params[].data.mean"], "methods", ["None"], ["", "def", "_construct_diff_model", "(", "self", ",", "base_model", ",", "keep_rgb", "=", "False", ")", ":", "\n", "# modify the convolution layers", "\n", "# Torch models are usually defined in a hierarchical way.", "\n", "# nn.modules.children() return all sub modules in a DFS manner", "\n", "        ", "modules", "=", "list", "(", "self", ".", "base_model", ".", "modules", "(", ")", ")", "\n", "first_conv_idx", "=", "filter", "(", "lambda", "x", ":", "isinstance", "(", "modules", "[", "x", "]", ",", "nn", ".", "Conv2d", ")", ",", "list", "(", "range", "(", "len", "(", "modules", ")", ")", ")", ")", "[", "0", "]", "\n", "conv_layer", "=", "modules", "[", "first_conv_idx", "]", "\n", "container", "=", "modules", "[", "first_conv_idx", "-", "1", "]", "\n", "\n", "# modify parameters, assume the first blob contains the convolution kernels", "\n", "params", "=", "[", "x", ".", "clone", "(", ")", "for", "x", "in", "conv_layer", ".", "parameters", "(", ")", "]", "\n", "kernel_size", "=", "params", "[", "0", "]", ".", "size", "(", ")", "\n", "if", "not", "keep_rgb", ":", "\n", "            ", "new_kernel_size", "=", "kernel_size", "[", ":", "1", "]", "+", "(", "3", "*", "self", ".", "new_length", ",", ")", "+", "kernel_size", "[", "2", ":", "]", "\n", "new_kernels", "=", "params", "[", "0", "]", ".", "data", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ".", "expand", "(", "new_kernel_size", ")", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "            ", "new_kernel_size", "=", "kernel_size", "[", ":", "1", "]", "+", "(", "3", "*", "self", ".", "new_length", ",", ")", "+", "kernel_size", "[", "2", ":", "]", "\n", "new_kernels", "=", "torch", ".", "cat", "(", "(", "params", "[", "0", "]", ".", "data", ",", "params", "[", "0", "]", ".", "data", ".", "mean", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ".", "expand", "(", "new_kernel_size", ")", ".", "contiguous", "(", ")", ")", ",", "\n", "1", ")", "\n", "new_kernel_size", "=", "kernel_size", "[", ":", "1", "]", "+", "(", "3", "+", "3", "*", "self", ".", "new_length", ",", ")", "+", "kernel_size", "[", "2", ":", "]", "\n", "\n", "", "new_conv", "=", "nn", ".", "Conv2d", "(", "new_kernel_size", "[", "1", "]", ",", "conv_layer", ".", "out_channels", ",", "\n", "conv_layer", ".", "kernel_size", ",", "conv_layer", ".", "stride", ",", "conv_layer", ".", "padding", ",", "\n", "bias", "=", "True", "if", "len", "(", "params", ")", "==", "2", "else", "False", ")", "\n", "new_conv", ".", "weight", ".", "data", "=", "new_kernels", "\n", "if", "len", "(", "params", ")", "==", "2", ":", "\n", "            ", "new_conv", ".", "bias", ".", "data", "=", "params", "[", "1", "]", ".", "data", "# add bias if neccessary", "\n", "", "layer_name", "=", "list", "(", "container", ".", "state_dict", "(", ")", ".", "keys", "(", ")", ")", "[", "0", "]", "[", ":", "-", "7", "]", "# remove .weight suffix to get the layer name", "\n", "\n", "# replace the first convolution layer", "\n", "setattr", "(", "container", ",", "layer_name", ",", "new_conv", ")", "\n", "return", "base_model", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN.crop_size": [[359, 362], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "crop_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "input_size", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN.scale_size": [[363, 366], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scale_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "input_size", "*", "256", "//", "224", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN.get_augmentation": [[367, 385], ["torchvision.transforms.Compose", "torchvision.transforms.Compose", "transforms.GroupMultiScaleCrop", "transforms.GroupRandomHorizontalFlip", "torchvision.transforms.Compose", "transforms.GroupMultiScaleCrop", "transforms.GroupRandomHorizontalFlip", "torchvision.transforms.Compose", "transforms.GroupMultiScaleCrop", "transforms.GroupRandomHorizontalFlip", "transforms.GroupMultiScaleResize", "transforms.GroupMultiScaleRotate", "transforms.GroupMultiScaleCrop"], "methods", ["None"], ["", "def", "get_augmentation", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "modality", "==", "'RGB'", ":", "\n", "            ", "return", "torchvision", ".", "transforms", ".", "Compose", "(", "[", "GroupMultiScaleCrop", "(", "self", ".", "input_size", ",", "[", "1", ",", ".875", ",", ".75", ",", ".66", "]", ")", ",", "\n", "GroupRandomHorizontalFlip", "(", "is_flow", "=", "False", ")", "]", ")", "\n", "", "elif", "self", ".", "modality", "==", "'Flow'", ":", "\n", "            ", "return", "torchvision", ".", "transforms", ".", "Compose", "(", "[", "GroupMultiScaleCrop", "(", "self", ".", "input_size", ",", "[", "1", ",", ".875", ",", ".75", "]", ")", ",", "\n", "GroupRandomHorizontalFlip", "(", "is_flow", "=", "True", ")", "]", ")", "\n", "", "elif", "self", ".", "modality", "==", "'RGBDiff'", ":", "\n", "            ", "return", "torchvision", ".", "transforms", ".", "Compose", "(", "[", "GroupMultiScaleCrop", "(", "self", ".", "input_size", ",", "[", "1", ",", ".875", ",", ".75", "]", ")", ",", "\n", "GroupRandomHorizontalFlip", "(", "is_flow", "=", "False", ")", "]", ")", "\n", "", "elif", "self", ".", "modality", "==", "'RGBFlow'", ":", "\n", "            ", "return", "torchvision", ".", "transforms", ".", "Compose", "(", "[", "GroupMultiScaleResize", "(", "0.2", ")", ",", "\n", "GroupMultiScaleRotate", "(", "20", ")", ",", "\n", "#GroupSpatialElasticDisplacement(),", "\n", "GroupMultiScaleCrop", "(", "self", ".", "input_size", ",", "\n", "[", "1", ",", ".875", ",", "\n", ".75", ",", "\n", ".66", "]", ")", ",", "\n", "#GroupRandomHorizontalFlip(is_flow=False)", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.test_models.AverageMeter.__init__": [[42, 44], ["test_models.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.test_models.AverageMeter.reset": [[45, 50], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.test_models.AverageMeter.update": [[51, 56], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.test_models.accuracy": [[57, 69], ["max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["", "", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "         ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.test_models.eval_video": [[141, 171], ["torch.autograd.Variable", "torch.autograd.Variable", "net", "rst.reshape().mean().reshape.data.cpu().numpy().copy", "data.view", "torch.nn.functional.softmax", "rst.reshape().mean().reshape.reshape", "rst.reshape().mean().reshape.reshape().mean().reshape", "data.size", "data.size", "rst.reshape().mean().reshape.data.cpu().numpy", "rst.reshape().mean().reshape.reshape().mean", "ValueError", "rst.reshape().mean().reshape.data.cpu", "rst.reshape().mean().reshape.reshape"], "function", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.utils.softmax"], ["def", "eval_video", "(", "video_data", ")", ":", "\n", "    ", "i", ",", "data", ",", "label", "=", "video_data", "\n", "num_crop", "=", "args", ".", "test_crops", "\n", "\n", "if", "args", ".", "modality", "==", "'RGB'", ":", "\n", "        ", "length", "=", "3", "\n", "", "elif", "args", ".", "modality", "==", "'Flow'", ":", "\n", "        ", "length", "=", "10", "\n", "", "elif", "args", ".", "modality", "==", "'RGBDiff'", ":", "\n", "        ", "length", "=", "18", "\n", "", "elif", "args", ".", "modality", "==", "'RGBFlow'", ":", "\n", "        ", "length", "=", "3", "+", "2", "*", "args", ".", "num_motion", "# 3 rgb channels and 3*2=6 flow channels ", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown modality \"", "+", "args", ".", "modality", ")", "\n", "\n", "", "input_var", "=", "torch", ".", "autograd", ".", "Variable", "(", "data", ".", "view", "(", "-", "1", ",", "length", ",", "data", ".", "size", "(", "2", ")", ",", "data", ".", "size", "(", "3", ")", ")", ",", "\n", "volatile", "=", "True", ")", "\n", "rst", "=", "net", "(", "input_var", ")", "\n", "if", "args", ".", "softmax", "==", "1", ":", "\n", "# take the softmax to normalize the output to probability", "\n", "        ", "rst", "=", "F", ".", "softmax", "(", "rst", ")", "\n", "\n", "", "rst", "=", "rst", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "copy", "(", ")", "\n", "\n", "if", "args", ".", "consensus_type", "in", "[", "'MLP'", "]", ":", "\n", "        ", "rst", "=", "rst", ".", "reshape", "(", "-", "1", ",", "1", ",", "num_class", ")", "\n", "", "else", ":", "\n", "        ", "rst", "=", "rst", ".", "reshape", "(", "(", "num_crop", ",", "args", ".", "test_segments", ",", "num_class", ")", ")", ".", "mean", "(", "axis", "=", "0", ")", ".", "reshape", "(", "(", "args", ".", "test_segments", ",", "1", ",", "num_class", ")", ")", "\n", "\n", "", "return", "i", ",", "rst", ",", "label", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.AverageMeter.__init__": [[281, 283], ["main.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.AverageMeter.reset": [[284, 289], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.AverageMeter.update": [[290, 295], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.main": [[23, 152], ["opts.parser.parse_args", "main.check_rootfolders", "datasets_video.return_dataset", "len", "print", "models.TSN", "torch.nn.DataParallel().cuda.get_augmentation", "torch.nn.DataParallel().cuda.get_optim_policies", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "print", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "open", "range", "os.path.isfile", "transforms.GroupNormalize", "transforms.IdentityTransform", "dataset.TSNDataSet", "dataset.TSNDataSet", "torch.nn.CrossEntropyLoss().cuda", "torch.nn.CrossEntropyLoss().cuda", "torch.nn.CrossEntropyLoss().cuda", "torch.nn.CrossEntropyLoss().cuda", "ValueError", "print", "main.validate", "os.path.join", "main.adjust_learning_rate", "main.train", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.nn.DataParallel().cuda.load_state_dict", "print", "print", "main.validate", "max", "main.save_checkpoint", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "len", "len", "torch.nn.DataParallel().cuda.state_dict", "transforms.Stack", "transforms.ToTorchFormatTensor", "transforms.GroupScale", "transforms.GroupCenterCrop", "transforms.Stack", "transforms.ToTorchFormatTensor", "int"], "function", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.check_rootfolders", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.datasets_video.return_dataset", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN.get_augmentation", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN.get_optim_policies", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.validate", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.adjust_learning_rate", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.train", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.validate", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.save_checkpoint"], ["def", "main", "(", ")", ":", "\n", "    ", "global", "args", ",", "best_prec1", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "check_rootfolders", "(", ")", "\n", "\n", "categories", ",", "args", ".", "train_list", ",", "args", ".", "val_list", ",", "args", ".", "root_path", ",", "prefix", "=", "datasets_video", ".", "return_dataset", "(", "args", ".", "dataset", ",", "args", ".", "modality", ")", "\n", "num_class", "=", "len", "(", "categories", ")", "\n", "\n", "\n", "args", ".", "store_name", "=", "'_'", ".", "join", "(", "[", "'MFF'", ",", "args", ".", "dataset", ",", "args", ".", "modality", ",", "args", ".", "arch", ",", "\n", "'segment%d'", "%", "args", ".", "num_segments", ",", "'%df1c'", "%", "args", ".", "num_motion", "]", ")", "\n", "print", "(", "'storing name: '", "+", "args", ".", "store_name", ")", "\n", "\n", "model", "=", "TSN", "(", "num_class", ",", "args", ".", "num_segments", ",", "args", ".", "modality", ",", "\n", "base_model", "=", "args", ".", "arch", ",", "\n", "consensus_type", "=", "args", ".", "consensus_type", ",", "\n", "dropout", "=", "args", ".", "dropout", ",", "num_motion", "=", "args", ".", "num_motion", ",", "\n", "img_feature_dim", "=", "args", ".", "img_feature_dim", ",", "\n", "partial_bn", "=", "not", "args", ".", "no_partialbn", ",", "\n", "dataset", "=", "args", ".", "dataset", ")", "\n", "\n", "crop_size", "=", "model", ".", "crop_size", "\n", "scale_size", "=", "model", ".", "scale_size", "\n", "input_mean", "=", "model", ".", "input_mean", "\n", "input_std", "=", "model", ".", "input_std", "\n", "train_augmentation", "=", "model", ".", "get_augmentation", "(", ")", "\n", "\n", "policies", "=", "model", ".", "get_optim_policies", "(", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "args", ".", "gpus", ")", ".", "cuda", "(", ")", "\n", "\n", "if", "args", ".", "resume", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "args", ".", "resume", ")", ":", "\n", "            ", "print", "(", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "args", ".", "resume", ")", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "resume", ")", "\n", "args", ".", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "best_prec1", "=", "checkpoint", "[", "'best_prec1'", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "print", "(", "(", "\"=> loaded checkpoint '{}' (epoch {})\"", "\n", ".", "format", "(", "args", ".", "evaluate", ",", "checkpoint", "[", "'epoch'", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "(", "\"=> no checkpoint found at '{}'\"", ".", "format", "(", "args", ".", "resume", ")", ")", ")", "\n", "\n", "", "", "print", "(", "model", ")", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "\n", "# Data loading code", "\n", "if", "(", "(", "args", ".", "modality", "!=", "'RGBDiff'", ")", "|", "(", "args", ".", "modality", "!=", "'RGBFlow'", ")", ")", ":", "\n", "        ", "normalize", "=", "GroupNormalize", "(", "input_mean", ",", "input_std", ")", "\n", "", "else", ":", "\n", "        ", "normalize", "=", "IdentityTransform", "(", ")", "\n", "\n", "", "if", "args", ".", "modality", "==", "'RGB'", ":", "\n", "        ", "data_length", "=", "1", "\n", "", "elif", "args", ".", "modality", "in", "[", "'Flow'", ",", "'RGBDiff'", "]", ":", "\n", "        ", "data_length", "=", "5", "\n", "", "elif", "args", ".", "modality", "==", "'RGBFlow'", ":", "\n", "        ", "data_length", "=", "args", ".", "num_motion", "\n", "\n", "", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "TSNDataSet", "(", "args", ".", "root_path", ",", "args", ".", "train_list", ",", "num_segments", "=", "args", ".", "num_segments", ",", "\n", "new_length", "=", "data_length", ",", "\n", "modality", "=", "args", ".", "modality", ",", "\n", "image_tmpl", "=", "prefix", ",", "\n", "dataset", "=", "args", ".", "dataset", ",", "\n", "transform", "=", "torchvision", ".", "transforms", ".", "Compose", "(", "[", "\n", "train_augmentation", ",", "\n", "Stack", "(", "roll", "=", "(", "args", ".", "arch", "in", "[", "'BNInception'", ",", "'InceptionV3'", "]", ")", ",", "isRGBFlow", "=", "(", "args", ".", "modality", "==", "'RGBFlow'", ")", ")", ",", "\n", "ToTorchFormatTensor", "(", "div", "=", "(", "args", ".", "arch", "not", "in", "[", "'BNInception'", ",", "'InceptionV3'", "]", ")", ")", ",", "\n", "normalize", ",", "\n", "]", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "False", ")", "\n", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "TSNDataSet", "(", "args", ".", "root_path", ",", "args", ".", "val_list", ",", "num_segments", "=", "args", ".", "num_segments", ",", "\n", "new_length", "=", "data_length", ",", "\n", "modality", "=", "args", ".", "modality", ",", "\n", "image_tmpl", "=", "prefix", ",", "\n", "dataset", "=", "args", ".", "dataset", ",", "\n", "random_shift", "=", "False", ",", "\n", "transform", "=", "torchvision", ".", "transforms", ".", "Compose", "(", "[", "\n", "GroupScale", "(", "int", "(", "scale_size", ")", ")", ",", "\n", "GroupCenterCrop", "(", "crop_size", ")", ",", "\n", "Stack", "(", "roll", "=", "(", "args", ".", "arch", "in", "[", "'BNInception'", ",", "'InceptionV3'", "]", ")", ",", "isRGBFlow", "=", "(", "args", ".", "modality", "==", "'RGBFlow'", ")", ")", ",", "\n", "ToTorchFormatTensor", "(", "div", "=", "(", "args", ".", "arch", "not", "in", "[", "'BNInception'", ",", "'InceptionV3'", "]", ")", ")", ",", "\n", "normalize", ",", "\n", "]", ")", ")", ",", "\n", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "pin_memory", "=", "False", ")", "\n", "\n", "# define loss function (criterion) and optimizer", "\n", "if", "args", ".", "loss_type", "==", "'nll'", ":", "\n", "        ", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unknown loss type\"", ")", "\n", "\n", "", "for", "group", "in", "policies", ":", "\n", "        ", "print", "(", "(", "'group: {} has {} params, lr_mult: {}, decay_mult: {}'", ".", "format", "(", "\n", "group", "[", "'name'", "]", ",", "len", "(", "group", "[", "'params'", "]", ")", ",", "group", "[", "'lr_mult'", "]", ",", "group", "[", "'decay_mult'", "]", ")", ")", ")", "\n", "\n", "", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "policies", ",", "\n", "args", ".", "lr", ",", "\n", "momentum", "=", "args", ".", "momentum", ",", "\n", "weight_decay", "=", "args", ".", "weight_decay", ")", "\n", "\n", "if", "args", ".", "evaluate", ":", "\n", "        ", "validate", "(", "val_loader", ",", "model", ",", "criterion", ",", "0", ")", "\n", "return", "\n", "\n", "", "log_training", "=", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "root_log", ",", "'%s.csv'", "%", "args", ".", "store_name", ")", ",", "'w'", ")", "\n", "for", "epoch", "in", "range", "(", "args", ".", "start_epoch", ",", "args", ".", "epochs", ")", ":", "\n", "        ", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ",", "args", ".", "lr_steps", ")", "\n", "\n", "# train for one epoch", "\n", "train", "(", "train_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "log_training", ")", "\n", "\n", "# evaluate on validation set", "\n", "if", "(", "epoch", "+", "1", ")", "%", "args", ".", "eval_freq", "==", "0", "or", "epoch", "==", "args", ".", "epochs", "-", "1", ":", "\n", "            ", "prec1", "=", "validate", "(", "val_loader", ",", "model", ",", "criterion", ",", "(", "epoch", "+", "1", ")", "*", "len", "(", "train_loader", ")", ",", "log_training", ")", "\n", "\n", "# remember best prec@1 and save checkpoint", "\n", "is_best", "=", "prec1", ">", "best_prec1", "\n", "best_prec1", "=", "max", "(", "prec1", ",", "best_prec1", ")", "\n", "save_checkpoint", "(", "{", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "\n", "'arch'", ":", "args", ".", "arch", ",", "\n", "'state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'best_prec1'", ":", "best_prec1", ",", "\n", "}", ",", "is_best", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.train": [[154, 217], ["main.AverageMeter", "main.AverageMeter", "main.AverageMeter", "main.AverageMeter", "main.AverageMeter", "model.train", "time.time", "enumerate", "model.module.partialBN", "model.module.partialBN", "main.AverageMeter.update", "target.cuda.cuda", "torch.autograd.Variable", "torch.autograd.Variable", "model", "criterion", "main.accuracy", "main.AverageMeter.update", "main.AverageMeter.update", "main.AverageMeter.update", "optimizer.zero_grad", "criterion.backward", "optimizer.step", "main.AverageMeter.update", "time.time", "input.size", "input.size", "input.size", "torch.nn.utils.clip_grad_norm", "print", "log.write", "log.flush", "time.time", "model.parameters", "time.time", "len"], "function", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.train", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN.partialBN", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.models.TSN.partialBN", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.AverageMeter.update", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.accuracy", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.AverageMeter.update", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.AverageMeter.update", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.AverageMeter.update", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.basic_ops.SegmentConsensus.backward", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.AverageMeter.update"], ["", "", "", "def", "train", "(", "train_loader", ",", "model", ",", "criterion", ",", "optimizer", ",", "epoch", ",", "log", ")", ":", "\n", "    ", "batch_time", "=", "AverageMeter", "(", ")", "\n", "data_time", "=", "AverageMeter", "(", ")", "\n", "losses", "=", "AverageMeter", "(", ")", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "\n", "if", "args", ".", "no_partialbn", ":", "\n", "        ", "model", ".", "module", ".", "partialBN", "(", "False", ")", "\n", "", "else", ":", "\n", "        ", "model", ".", "module", ".", "partialBN", "(", "True", ")", "\n", "\n", "# switch to train mode", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "input", ",", "target", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "# measure data loading time", "\n", "        ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "\n", "target", "=", "target", ".", "cuda", "(", ")", "\n", "input_var", "=", "Variable", "(", "input", ")", "\n", "target_var", "=", "Variable", "(", "target", ")", "\n", "\n", "# compute output", "\n", "output", "=", "model", "(", "input_var", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "target_var", ")", "\n", "\n", "# measure accuracy and record loss", "\n", "prec1", ",", "prec5", "=", "accuracy", "(", "output", ".", "data", ",", "target", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "losses", ".", "update", "(", "loss", ".", "data", "[", "0", "]", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "prec1", "[", "0", "]", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "prec5", "[", "0", "]", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "\n", "\n", "# compute gradient and do SGD step", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "if", "args", ".", "clip_gradient", "is", "not", "None", ":", "\n", "            ", "total_norm", "=", "clip_grad_norm", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "clip_gradient", ")", "\n", "# if total_norm > args.clip_gradient:", "\n", "# print(\"clipping gradient: {} with coef {}\".format(total_norm, args.clip_gradient / total_norm))", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "i", "%", "args", ".", "print_freq", "==", "0", ":", "\n", "            ", "output", "=", "(", "'Epoch: [{0}][{1}/{2}], lr: {lr:.5f}\\t'", "\n", "'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'", "\n", "'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'", "\n", "'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'", "\n", "'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'", "\n", "'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'", ".", "format", "(", "\n", "epoch", ",", "i", ",", "len", "(", "train_loader", ")", ",", "batch_time", "=", "batch_time", ",", "\n", "data_time", "=", "data_time", ",", "loss", "=", "losses", ",", "top1", "=", "top1", ",", "top5", "=", "top5", ",", "lr", "=", "optimizer", ".", "param_groups", "[", "-", "1", "]", "[", "'lr'", "]", ")", ")", "\n", "print", "(", "output", ")", "\n", "log", ".", "write", "(", "output", "+", "'\\n'", ")", "\n", "log", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.validate": [[220, 272], ["main.AverageMeter", "main.AverageMeter", "main.AverageMeter", "main.AverageMeter", "model.eval", "time.time", "enumerate", "print", "print", "log.write", "log.flush", "target.cuda.cuda", "model", "criterion", "main.accuracy", "main.AverageMeter.update", "main.AverageMeter.update", "main.AverageMeter.update", "main.AverageMeter.update", "time.time", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.autograd.Variable", "torch.autograd.Variable", "input.size", "input.size", "input.size", "print", "log.write", "log.flush", "time.time", "len"], "function", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.accuracy", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.AverageMeter.update", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.AverageMeter.update", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.AverageMeter.update", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.AverageMeter.update"], ["", "", "", "def", "validate", "(", "val_loader", ",", "model", ",", "criterion", ",", "iter", ",", "log", ")", ":", "\n", "    ", "batch_time", "=", "AverageMeter", "(", ")", "\n", "losses", "=", "AverageMeter", "(", ")", "\n", "top1", "=", "AverageMeter", "(", ")", "\n", "top5", "=", "AverageMeter", "(", ")", "\n", "\n", "# switch to evaluate mode", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "input", ",", "target", ")", "in", "enumerate", "(", "val_loader", ")", ":", "\n", "        ", "target", "=", "target", ".", "cuda", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "input_var", "=", "Variable", "(", "input", ")", "\n", "target_var", "=", "Variable", "(", "target", ")", "\n", "\n", "# compute output", "\n", "", "output", "=", "model", "(", "input_var", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "target_var", ")", "\n", "\n", "# measure accuracy and record loss", "\n", "prec1", ",", "prec5", "=", "accuracy", "(", "output", ".", "data", ",", "target", ",", "topk", "=", "(", "1", ",", "5", ")", ")", "\n", "\n", "losses", ".", "update", "(", "loss", ".", "data", "[", "0", "]", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "top1", ".", "update", "(", "prec1", "[", "0", "]", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "prec5", "[", "0", "]", ",", "input", ".", "size", "(", "0", ")", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "i", "%", "args", ".", "print_freq", "==", "0", ":", "\n", "            ", "output", "=", "(", "'Test: [{0}/{1}]\\t'", "\n", "'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'", "\n", "'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'", "\n", "'Prec@1 {top1.val:.3f} ({top1.avg:.3f})\\t'", "\n", "'Prec@5 {top5.val:.3f} ({top5.avg:.3f})'", ".", "format", "(", "\n", "i", ",", "len", "(", "val_loader", ")", ",", "batch_time", "=", "batch_time", ",", "loss", "=", "losses", ",", "\n", "top1", "=", "top1", ",", "top5", "=", "top5", ")", ")", "\n", "print", "(", "output", ")", "\n", "log", ".", "write", "(", "output", "+", "'\\n'", ")", "\n", "log", ".", "flush", "(", ")", "\n", "\n", "", "", "output", "=", "(", "'Testing Results: Prec@1 {top1.avg:.3f} Prec@5 {top5.avg:.3f} Loss {loss.avg:.5f}'", "\n", ".", "format", "(", "top1", "=", "top1", ",", "top5", "=", "top5", ",", "loss", "=", "losses", ")", ")", "\n", "print", "(", "output", ")", "\n", "output_best", "=", "'\\nBest Prec@1: %.3f'", "%", "(", "best_prec1", ")", "\n", "print", "(", "output_best", ")", "\n", "log", ".", "write", "(", "output", "+", "' '", "+", "output_best", "+", "'\\n'", ")", "\n", "log", ".", "flush", "(", ")", "\n", "\n", "return", "top1", ".", "avg", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.save_checkpoint": [[274, 278], ["torch.save", "torch.save", "torch.save", "torch.save", "shutil.copyfile"], "function", ["None"], ["", "def", "save_checkpoint", "(", "state", ",", "is_best", ",", "filename", "=", "'checkpoint.pth.tar'", ")", ":", "\n", "    ", "torch", ".", "save", "(", "state", ",", "'%s/%s_checkpoint.pth.tar'", "%", "(", "args", ".", "root_model", ",", "args", ".", "store_name", ")", ")", "\n", "if", "is_best", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "'%s/%s_checkpoint.pth.tar'", "%", "(", "args", ".", "root_model", ",", "args", ".", "store_name", ")", ",", "'%s/%s_best.pth.tar'", "%", "(", "args", ".", "root_model", ",", "args", ".", "store_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.adjust_learning_rate": [[297, 305], ["sum", "np.array"], "function", ["None"], ["", "", "def", "adjust_learning_rate", "(", "optimizer", ",", "epoch", ",", "lr_steps", ")", ":", "\n", "    ", "\"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"", "\n", "decay", "=", "0.5", "**", "(", "sum", "(", "epoch", ">=", "np", ".", "array", "(", "lr_steps", ")", ")", ")", "\n", "lr", "=", "args", ".", "lr", "*", "decay", "\n", "decay", "=", "args", ".", "weight_decay", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "*", "param_group", "[", "'lr_mult'", "]", "\n", "param_group", "[", "'weight_decay'", "]", "=", "decay", "*", "param_group", "[", "'decay_mult'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.accuracy": [[307, 321], ["max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["", "", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.count_parameters": [[323, 325], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["", "def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.main.check_rootfolders": [[327, 334], ["os.path.exists", "print", "os.mkdir"], "function", ["None"], ["", "def", "check_rootfolders", "(", ")", ":", "\n", "    ", "\"\"\"Create log and model folder\"\"\"", "\n", "folders_util", "=", "[", "args", ".", "root_log", ",", "args", ".", "root_model", ",", "args", ".", "root_output", "]", "\n", "for", "folder", "in", "folders_util", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "folder", ")", ":", "\n", "            ", "print", "(", "'creating folder '", "+", "folder", ")", "\n", "os", ".", "mkdir", "(", "folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.datasets_video.return_jester": [[9, 23], ["print", "os.exit"], "function", ["None"], ["def", "return_jester", "(", "modality", ")", ":", "\n", "    ", "filename_categories", "=", "'jester/category.txt'", "\n", "filename_imglist_train", "=", "'jester/train_videofolder.txt'", "\n", "filename_imglist_val", "=", "'jester/val_videofolder.txt'", "\n", "if", "modality", "==", "'RGB'", ":", "\n", "        ", "prefix", "=", "'{:05d}.jpg'", "\n", "root_data", "=", "'/usr/home/kop/MFF-pytorch/datasets/jester'", "\n", "", "elif", "modality", "==", "'RGBFlow'", ":", "\n", "        ", "prefix", "=", "'{:05d}.jpg'", "\n", "root_data", "=", "'/usr/home/kop/MFF-pytorch/datasets/jester'", "\n", "", "else", ":", "\n", "        ", "print", "(", "'no such modality:'", "+", "modality", ")", "\n", "os", ".", "exit", "(", ")", "\n", "", "return", "filename_categories", ",", "filename_imglist_train", ",", "filename_imglist_val", ",", "root_data", ",", "prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.datasets_video.return_nvgesture": [[24, 38], ["print", "os.exit"], "function", ["None"], ["", "def", "return_nvgesture", "(", "modality", ")", ":", "\n", "    ", "filename_categories", "=", "'nvgesture/category.txt'", "\n", "filename_imglist_train", "=", "'nvgesture/train_videofolder.txt'", "\n", "filename_imglist_val", "=", "'nvgesture/val_videofolder.txt'", "\n", "if", "modality", "==", "'RGB'", ":", "\n", "        ", "prefix", "=", "'{:05d}.jpg'", "\n", "root_data", "=", "'/data2/nvGesture'", "\n", "", "elif", "modality", "==", "'RGBFlow'", ":", "\n", "        ", "prefix", "=", "'{:05d}.jpg'", "\n", "root_data", "=", "'/data2/nvGesture'", "\n", "", "else", ":", "\n", "        ", "print", "(", "'no such modality:'", "+", "modality", ")", "\n", "os", ".", "exit", "(", ")", "\n", "", "return", "filename_categories", ",", "filename_imglist_train", ",", "filename_imglist_val", ",", "root_data", ",", "prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.datasets_video.return_chalearn": [[39, 54], ["print", "os.exit"], "function", ["None"], ["", "def", "return_chalearn", "(", "modality", ")", ":", "\n", "    ", "filename_categories", "=", "'chalearn/category.txt'", "\n", "filename_imglist_train", "=", "'chalearn/train_videofolder.txt'", "\n", "filename_imglist_val", "=", "'chalearn/val_videofolder.txt'", "\n", "#filename_imglist_val = 'chalearn/test_videofolder.txt'", "\n", "if", "modality", "==", "'RGB'", ":", "\n", "        ", "prefix", "=", "'{:05d}.jpg'", "\n", "root_data", "=", "'/data2/ChaLearn'", "\n", "", "elif", "modality", "==", "'RGBFlow'", ":", "\n", "        ", "prefix", "=", "'{:05d}.jpg'", "\n", "root_data", "=", "'/data2/ChaLearn'", "\n", "", "else", ":", "\n", "        ", "print", "(", "'no such modality:'", "+", "modality", ")", "\n", "os", ".", "exit", "(", ")", "\n", "", "return", "filename_categories", ",", "filename_imglist_train", ",", "filename_imglist_val", ",", "root_data", ",", "prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.datasets_video.return_dataset": [[55, 69], ["os.path.join", "os.path.join", "os.path.join", "ValueError", "open", "f.readlines", "item.rstrip"], "function", ["None"], ["", "def", "return_dataset", "(", "dataset", ",", "modality", ")", ":", "\n", "    ", "dict_single", "=", "{", "'jester'", ":", "return_jester", ",", "'nvgesture'", ":", "return_nvgesture", ",", "'chalearn'", ":", "return_chalearn", "}", "\n", "if", "dataset", "in", "dict_single", ":", "\n", "        ", "file_categories", ",", "file_imglist_train", ",", "file_imglist_val", ",", "root_data", ",", "prefix", "=", "dict_single", "[", "dataset", "]", "(", "modality", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown dataset '", "+", "dataset", ")", "\n", "\n", "", "file_imglist_train", "=", "os", ".", "path", ".", "join", "(", "ROOT_DATASET", ",", "file_imglist_train", ")", "\n", "file_imglist_val", "=", "os", ".", "path", ".", "join", "(", "ROOT_DATASET", ",", "file_imglist_val", ")", "\n", "file_categories", "=", "os", ".", "path", ".", "join", "(", "ROOT_DATASET", ",", "file_categories", ")", "\n", "with", "open", "(", "file_categories", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "categories", "=", "[", "item", ".", "rstrip", "(", ")", "for", "item", "in", "lines", "]", "\n", "return", "categories", ",", "file_imglist_train", ",", "file_imglist_val", ",", "root_data", ",", "prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.MLPmodule.MLPmodule.__init__": [[9, 22], ["super().__init__", "torch.Sequential", "torch.Sequential", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.basic_ops.ConsensusModule.__init__"], ["def", "__init__", "(", "self", ",", "img_feature_dim", ",", "num_frames", ",", "num_class", ")", ":", "\n", "        ", "super", "(", "MLPmodule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_frames", "=", "num_frames", "\n", "self", ".", "num_class", "=", "num_class", "\n", "self", ".", "img_feature_dim", "=", "img_feature_dim", "\n", "self", ".", "num_bottleneck", "=", "512", "\n", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "num_frames", "*", "self", ".", "img_feature_dim", ",", "\n", "self", ".", "num_bottleneck", ")", ",", "\n", "#nn.Dropout(0.90), # Add an extra DO if necess.", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "self", ".", "num_bottleneck", ",", "self", ".", "num_class", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.MLPmodule.MLPmodule.forward": [[23, 27], ["MLPmodule.MLPmodule.view", "MLPmodule.MLPmodule.classifier", "MLPmodule.MLPmodule.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "input", "=", "input", ".", "view", "(", "input", ".", "size", "(", "0", ")", ",", "self", ".", "num_frames", "*", "self", ".", "img_feature_dim", ")", "\n", "input", "=", "self", ".", "classifier", "(", "input", ")", "\n", "return", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.MLPmodule.return_MLP": [[29, 33], ["MLPmodule.MLPmodule"], "function", ["None"], ["", "", "def", "return_MLP", "(", "relation_type", ",", "img_feature_dim", ",", "num_frames", ",", "num_class", ")", ":", "\n", "    ", "MLPmodel", "=", "MLPmodule", "(", "img_feature_dim", ",", "num_frames", ",", "num_class", ")", "\n", "\n", "return", "MLPmodel", "\n", "", ""]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.VideoRecord.__init__": [[11, 13], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "row", ")", ":", "\n", "        ", "self", ".", "_data", "=", "row", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.VideoRecord.path": [[14, 17], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "path", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_data", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.VideoRecord.num_frames": [[18, 21], ["int"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_frames", "(", "self", ")", ":", "\n", "        ", "return", "int", "(", "self", ".", "_data", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.VideoRecord.label": [[22, 25], ["int"], "methods", ["None"], ["", "@", "property", "\n", "def", "label", "(", "self", ")", ":", "\n", "        ", "return", "int", "(", "self", ".", "_data", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet.__init__": [[28, 49], ["dataset.TSNDataSet._parse_list"], "methods", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet._parse_list"], ["    ", "def", "__init__", "(", "self", ",", "root_path", ",", "list_file", ",", "\n", "num_segments", "=", "3", ",", "new_length", "=", "1", ",", "modality", "=", "'RGB'", ",", "\n", "image_tmpl", "=", "'img_{:05d}.jpg'", ",", "transform", "=", "None", ",", "\n", "force_grayscale", "=", "False", ",", "random_shift", "=", "True", ",", "\n", "test_mode", "=", "False", ",", "dataset", "=", "'jester'", ")", ":", "\n", "\n", "        ", "self", ".", "root_path", "=", "root_path", "\n", "self", ".", "list_file", "=", "list_file", "\n", "self", ".", "num_segments", "=", "num_segments", "\n", "self", ".", "new_length", "=", "new_length", "\n", "self", ".", "modality", "=", "modality", "\n", "self", ".", "image_tmpl", "=", "image_tmpl", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "random_shift", "=", "random_shift", "\n", "self", ".", "test_mode", "=", "test_mode", "\n", "self", ".", "dataset", "=", "dataset", "\n", "\n", "if", "self", ".", "modality", "==", "'RGBDiff'", "or", "self", ".", "modality", "==", "'RGBFlow'", ":", "\n", "            ", "self", ".", "new_length", "+=", "1", "# Diff needs one more image to calculate diff", "\n", "\n", "", "self", ".", "_parse_list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet._load_image": [[50, 75], ["PIL.Image.open().convert", "print", "PIL.Image.open().convert", "PIL.Image.open().convert", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "PIL.Image.open().convert", "print", "PIL.Image.open().convert", "PIL.Image.open().convert", "PIL.Image.open().convert", "PIL.Image.open().convert", "PIL.Image.open", "dataset.TSNDataSet.image_tmpl.format", "PIL.Image.open", "PIL.Image.open", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "PIL.Image.open().convert", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "PIL.Image.open", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "dataset.TSNDataSet.image_tmpl.format", "PIL.Image.open", "PIL.Image.open", "PIL.Image.open", "PIL.Image.open", "dataset.TSNDataSet.image_tmpl.format", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "dataset.TSNDataSet.image_tmpl.format", "dataset.TSNDataSet.image_tmpl.format", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "PIL.Image.open", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "dataset.TSNDataSet.image_tmpl.format", "dataset.TSNDataSet.image_tmpl.format", "dataset.TSNDataSet.image_tmpl.format", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "dataset.TSNDataSet.image_tmpl.format", "dataset.TSNDataSet.image_tmpl.format", "dataset.TSNDataSet.image_tmpl.format"], "methods", ["None"], ["", "def", "_load_image", "(", "self", ",", "directory", ",", "idx", ",", "isLast", "=", "False", ")", ":", "\n", "        ", "if", "self", ".", "modality", "==", "'RGB'", "or", "self", ".", "modality", "==", "'RGBDiff'", ":", "\n", "            ", "try", ":", "\n", "                ", "return", "[", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"rgb\"", ",", "directory", ",", "self", ".", "image_tmpl", ".", "format", "(", "idx", ")", ")", ")", ".", "convert", "(", "'RGB'", ")", "]", "\n", "", "except", "Exception", ":", "\n", "                ", "print", "(", "'error loading image:'", ",", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"rgb\"", ",", "directory", ",", "self", ".", "image_tmpl", ".", "format", "(", "idx", ")", ")", ")", "\n", "return", "[", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"rgb\"", ",", "directory", ",", "self", ".", "image_tmpl", ".", "format", "(", "1", ")", ")", ")", ".", "convert", "(", "'RGB'", ")", "]", "\n", "\n", "", "", "elif", "self", ".", "modality", "==", "'Flow'", ":", "\n", "            ", "try", ":", "\n", "                ", "x_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"flow/u\"", ",", "directory", ",", "self", ".", "image_tmpl", ".", "format", "(", "idx", ")", ")", ")", ".", "convert", "(", "'L'", ")", "\n", "y_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"flow/v\"", ",", "directory", ",", "self", ".", "image_tmpl", ".", "format", "(", "idx", ")", ")", ")", ".", "convert", "(", "'L'", ")", "\n", "", "except", "Exception", ":", "\n", "                ", "print", "(", "'error loading flow file:'", ",", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"flow/v\"", ",", "directory", ",", "self", ".", "image_tmpl", ".", "format", "(", "idx", ")", ")", ")", "\n", "x_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"flow/u\"", ",", "directory", ",", "self", ".", "image_tmpl", ".", "format", "(", "1", ")", ")", ")", ".", "convert", "(", "'L'", ")", "\n", "y_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"flow/v\"", ",", "directory", ",", "self", ".", "image_tmpl", ".", "format", "(", "1", ")", ")", ")", ".", "convert", "(", "'L'", ")", "\n", "", "return", "[", "x_img", ",", "y_img", "]", "\n", "\n", "", "elif", "self", ".", "modality", "==", "'RGBFlow'", ":", "\n", "            ", "if", "isLast", ":", "\n", "                ", "return", "[", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"rgb\"", ",", "directory", ",", "self", ".", "image_tmpl", ".", "format", "(", "idx", ")", ")", ")", ".", "convert", "(", "'RGB'", ")", "]", "\n", "", "else", ":", "\n", "                ", "x_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"flow/u\"", ",", "directory", ",", "self", ".", "image_tmpl", ".", "format", "(", "idx", ")", ")", ")", ".", "convert", "(", "'L'", ")", "\n", "y_img", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"flow/v\"", ",", "directory", ",", "self", ".", "image_tmpl", ".", "format", "(", "idx", ")", ")", ")", ".", "convert", "(", "'L'", ")", "\n", "return", "[", "x_img", ",", "y_img", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet._parse_list": [[77, 84], ["print", "x.strip().split", "dataset.VideoRecord", "open", "len", "x.strip", "int"], "methods", ["None"], ["", "", "", "def", "_parse_list", "(", "self", ")", ":", "\n", "# check the frame number is large >3:", "\n", "# usualy it is [video_id, num_frames, class_idx]", "\n", "        ", "tmp", "=", "[", "x", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "for", "x", "in", "open", "(", "self", ".", "list_file", ")", "]", "\n", "tmp", "=", "[", "item", "for", "item", "in", "tmp", "if", "int", "(", "item", "[", "1", "]", ")", ">=", "3", "]", "\n", "self", ".", "video_list", "=", "[", "VideoRecord", "(", "item", ")", "for", "item", "in", "tmp", "]", "\n", "print", "(", "'video number:%d'", "%", "(", "len", "(", "self", ".", "video_list", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet._sample_indices": [[85, 100], ["numpy.multiply", "numpy.random.randint", "numpy.sort", "numpy.zeros", "list", "numpy.random.randint", "range"], "methods", ["None"], ["", "def", "_sample_indices", "(", "self", ",", "record", ")", ":", "\n", "        ", "\"\"\"\n\n        :param record: VideoRecord\n        :return: list\n        \"\"\"", "\n", "average_duration", "=", "(", "record", ".", "num_frames", "-", "self", ".", "new_length", "+", "1", ")", "//", "self", ".", "num_segments", "\n", "\n", "if", "average_duration", ">", "0", ":", "\n", "            ", "offsets", "=", "np", ".", "multiply", "(", "list", "(", "range", "(", "self", ".", "num_segments", ")", ")", ",", "average_duration", ")", "+", "randint", "(", "average_duration", ",", "size", "=", "self", ".", "num_segments", ")", "\n", "", "elif", "record", ".", "num_frames", ">", "self", ".", "num_segments", ":", "\n", "            ", "offsets", "=", "np", ".", "sort", "(", "randint", "(", "record", ".", "num_frames", "-", "self", ".", "new_length", "+", "1", ",", "size", "=", "self", ".", "num_segments", ")", ")", "\n", "", "else", ":", "\n", "            ", "offsets", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_segments", ",", ")", ")", "\n", "", "return", "offsets", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet._get_val_indices": [[101, 108], ["numpy.array", "numpy.zeros", "float", "int", "range"], "methods", ["None"], ["", "def", "_get_val_indices", "(", "self", ",", "record", ")", ":", "\n", "        ", "if", "record", ".", "num_frames", ">", "self", ".", "num_segments", "+", "self", ".", "new_length", "-", "1", ":", "\n", "            ", "tick", "=", "(", "record", ".", "num_frames", "-", "self", ".", "new_length", "+", "1", ")", "/", "float", "(", "self", ".", "num_segments", ")", "\n", "offsets", "=", "np", ".", "array", "(", "[", "int", "(", "tick", "/", "2.0", "+", "tick", "*", "x", ")", "for", "x", "in", "range", "(", "self", ".", "num_segments", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "offsets", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_segments", ",", ")", ")", "\n", "", "return", "offsets", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet._get_test_indices": [[109, 113], ["numpy.array", "float", "int", "range"], "methods", ["None"], ["", "def", "_get_test_indices", "(", "self", ",", "record", ")", ":", "\n", "        ", "tick", "=", "(", "record", ".", "num_frames", "-", "self", ".", "new_length", "+", "1", ")", "/", "float", "(", "self", ".", "num_segments", ")", "\n", "offsets", "=", "np", ".", "array", "(", "[", "int", "(", "tick", "/", "2.0", "+", "tick", "*", "x", ")", "for", "x", "in", "range", "(", "self", ".", "num_segments", ")", "]", ")", "\n", "return", "offsets", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet.__getitem__": [[114, 132], ["dataset.TSNDataSet.get", "dataset.TSNDataSet._get_test_indices", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "numpy.random.randint", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "numpy.random.randint", "dataset.TSNDataSet._sample_indices", "dataset.TSNDataSet._get_val_indices", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "dataset.TSNDataSet.image_tmpl.format", "dataset.TSNDataSet.image_tmpl.format"], "methods", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet.get", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet._get_test_indices", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet._sample_indices", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet._get_val_indices"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "record", "=", "self", ".", "video_list", "[", "index", "]", "\n", "# check this is a legit video folder", "\n", "if", "self", ".", "modality", "==", "'RGBFlow'", ":", "\n", "            ", "while", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"rgb\"", ",", "record", ".", "path", ",", "self", ".", "image_tmpl", ".", "format", "(", "1", ")", ")", ")", ":", "\n", "                ", "index", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "self", ".", "video_list", ")", ")", "\n", "record", "=", "self", ".", "video_list", "[", "index", "]", "\n", "", "", "else", ":", "\n", "            ", "while", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"rgb\"", ",", "record", ".", "path", ",", "self", ".", "image_tmpl", ".", "format", "(", "1", ")", ")", ")", ":", "\n", "                ", "index", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "self", ".", "video_list", ")", ")", "\n", "record", "=", "self", ".", "video_list", "[", "index", "]", "\n", "\n", "", "", "if", "not", "self", ".", "test_mode", ":", "\n", "            ", "segment_indices", "=", "self", ".", "_sample_indices", "(", "record", ")", "if", "self", ".", "random_shift", "else", "self", ".", "_get_val_indices", "(", "record", ")", "\n", "", "else", ":", "\n", "            ", "segment_indices", "=", "self", ".", "_get_test_indices", "(", "record", ")", "\n", "\n", "", "return", "self", ".", "get", "(", "record", ",", "segment_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet.get": [[133, 155], ["list", "dataset.TSNDataSet.transform", "int", "range", "list.extend", "dataset.TSNDataSet._load_image", "dataset.TSNDataSet._load_image", "dataset.TSNDataSet._load_image", "dataset.TSNDataSet._load_image"], "methods", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet._load_image", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet._load_image", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet._load_image", "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet._load_image"], ["", "def", "get", "(", "self", ",", "record", ",", "indices", ")", ":", "\n", "        ", "images", "=", "list", "(", ")", "\n", "for", "seg_ind", "in", "indices", ":", "\n", "            ", "p", "=", "int", "(", "seg_ind", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "new_length", ")", ":", "\n", "                ", "if", "self", ".", "modality", "==", "'RGBFlow'", ":", "\n", "                    ", "if", "i", "==", "self", ".", "new_length", "-", "1", ":", "\n", "                        ", "seg_imgs", "=", "self", ".", "_load_image", "(", "record", ".", "path", ",", "p", ",", "True", ")", "\n", "", "else", ":", "\n", "                        ", "if", "p", "==", "record", ".", "num_frames", ":", "\n", "                            ", "seg_imgs", "=", "self", ".", "_load_image", "(", "record", ".", "path", ",", "p", "-", "1", ")", "\n", "", "else", ":", "\n", "                            ", "seg_imgs", "=", "self", ".", "_load_image", "(", "record", ".", "path", ",", "p", ")", "\n", "", "", "", "else", ":", "\n", "                    ", "seg_imgs", "=", "self", ".", "_load_image", "(", "record", ".", "path", ",", "p", ")", "\n", "\n", "", "images", ".", "extend", "(", "seg_imgs", ")", "\n", "if", "p", "<", "record", ".", "num_frames", ":", "\n", "                    ", "p", "+=", "1", "\n", "\n", "", "", "", "process_data", "=", "self", ".", "transform", "(", "images", ")", "\n", "return", "process_data", ",", "record", ".", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.None.dataset.TSNDataSet.__len__": [[156, 158], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "video_list", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.basic_ops.Identity.forward": [[6, 8], ["None"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.basic_ops.SegmentConsensus.__init__": [[12, 16], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "consensus_type", ",", "dim", "=", "1", ")", ":", "\n", "        ", "self", ".", "consensus_type", "=", "consensus_type", "\n", "self", ".", "dim", "=", "dim", "\n", "self", ".", "shape", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.basic_ops.SegmentConsensus.forward": [[17, 27], ["input_tensor.size", "input_tensor.mean"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_tensor", ")", ":", "\n", "        ", "self", ".", "shape", "=", "input_tensor", ".", "size", "(", ")", "\n", "if", "self", ".", "consensus_type", "==", "'avg'", ":", "\n", "            ", "output", "=", "input_tensor", ".", "mean", "(", "dim", "=", "self", ".", "dim", ",", "keepdim", "=", "True", ")", "\n", "", "elif", "self", ".", "consensus_type", "==", "'identity'", ":", "\n", "            ", "output", "=", "input_tensor", "\n", "", "else", ":", "\n", "            ", "output", "=", "None", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.basic_ops.SegmentConsensus.backward": [[28, 37], ["grad_output.expand", "float"], "methods", ["None"], ["", "def", "backward", "(", "self", ",", "grad_output", ")", ":", "\n", "        ", "if", "self", ".", "consensus_type", "==", "'avg'", ":", "\n", "            ", "grad_in", "=", "grad_output", ".", "expand", "(", "self", ".", "shape", ")", "/", "float", "(", "self", ".", "shape", "[", "self", ".", "dim", "]", ")", "\n", "", "elif", "self", ".", "consensus_type", "==", "'identity'", ":", "\n", "            ", "grad_in", "=", "grad_output", "\n", "", "else", ":", "\n", "            ", "grad_in", "=", "None", "\n", "\n", "", "return", "grad_in", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.basic_ops.ConsensusModule.__init__": [[41, 45], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.basic_ops.ConsensusModule.__init__"], ["    ", "def", "__init__", "(", "self", ",", "consensus_type", ",", "dim", "=", "1", ")", ":", "\n", "        ", "super", "(", "ConsensusModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "consensus_type", "=", "consensus_type", "if", "consensus_type", "!=", "'rnn'", "else", "'identity'", "\n", "self", ".", "dim", "=", "dim", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.basic_ops.ConsensusModule.forward": [[46, 48], ["basic_ops.SegmentConsensus"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "SegmentConsensus", "(", "self", ".", "consensus_type", ",", "self", ".", "dim", ")", "(", "input", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.utils.get_grad_hook": [[5, 15], ["print", "print", "print", "print", "print", "grad_out[].size", "grad_in[].size", "grad_out[].data.abs().mean", "grad_in[].data.abs().mean", "grad_out[].data.abs", "grad_in[].data.abs"], "function", ["None"], ["def", "get_grad_hook", "(", "name", ")", ":", "\n", "    ", "def", "hook", "(", "m", ",", "grad_in", ",", "grad_out", ")", ":", "\n", "        ", "print", "(", "(", "name", ",", "grad_out", "[", "0", "]", ".", "data", ".", "abs", "(", ")", ".", "mean", "(", ")", ",", "grad_in", "[", "0", "]", ".", "data", ".", "abs", "(", ")", ".", "mean", "(", ")", ")", ")", "\n", "print", "(", "(", "grad_out", "[", "0", "]", ".", "size", "(", ")", ")", ")", "\n", "print", "(", "(", "grad_in", "[", "0", "]", ".", "size", "(", ")", ")", ")", "\n", "\n", "print", "(", "(", "grad_out", "[", "0", "]", ")", ")", "\n", "print", "(", "(", "grad_in", "[", "0", "]", ")", ")", "\n", "\n", "", "return", "hook", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.utils.softmax": [[17, 20], ["numpy.exp", "np.exp.sum", "scores.max"], "function", ["None"], ["", "def", "softmax", "(", "scores", ")", ":", "\n", "    ", "es", "=", "np", ".", "exp", "(", "scores", "-", "scores", ".", "max", "(", "axis", "=", "-", "1", ")", "[", "...", ",", "None", "]", ")", "\n", "return", "es", "/", "es", ".", "sum", "(", "axis", "=", "-", "1", ")", "[", "...", ",", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.utils.log_add": [[22, 24], ["numpy.log", "numpy.exp"], "function", ["None"], ["", "def", "log_add", "(", "log_a", ",", "log_b", ")", ":", "\n", "    ", "return", "log_a", "+", "np", ".", "log", "(", "1", "+", "np", ".", "exp", "(", "log_b", "-", "log_a", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.okankop_MFF-pytorch.ops.utils.class_accuracy": [[26, 36], ["sklearn.metrics.confusion_matrix", "sklearn.metrics.confusion_matrix.sum", "numpy.diag", "cls_acc.mean", "cf.sum.astype"], "function", ["None"], ["", "def", "class_accuracy", "(", "prediction", ",", "label", ")", ":", "\n", "    ", "cf", "=", "confusion_matrix", "(", "prediction", ",", "label", ")", "\n", "cls_cnt", "=", "cf", ".", "sum", "(", "axis", "=", "1", ")", "\n", "cls_hit", "=", "np", ".", "diag", "(", "cf", ")", "\n", "\n", "cls_acc", "=", "cls_hit", "/", "cls_cnt", ".", "astype", "(", "float", ")", "\n", "\n", "mean_cls_acc", "=", "cls_acc", ".", "mean", "(", ")", "\n", "\n", "return", "cls_acc", ",", "mean_cls_acc", "", "", ""]]}