{"home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_ICT_model.adjust_learning_rate": [[31, 49], ["None"], "function", ["None"], ["def", "adjust_learning_rate", "(", "optimizer", ",", "rampup_value", ",", "rampdown_value", "=", "1", ")", ":", "\n", "    ", "\"\"\" adjust the learning rate\n    Args:\n        optimizer: torch.Module, the optimizer to be updated\n        rampup_value: float, the float value between 0 and 1 that should increases linearly\n        rampdown_value: float, the float between 1 and 0 that should decrease linearly\n    Returns:\n\n    \"\"\"", "\n", "# LR warm-up to handle large minibatch sizes from https://arxiv.org/abs/1706.02677", "\n", "# We commented parts on betas and weight decay to match 2nd system of last year from Orange", "\n", "lr", "=", "rampup_value", "*", "rampdown_value", "*", "cfg", ".", "max_learning_rate", "\n", "# beta1 = rampdown_value * cfg.beta1_before_rampdown + (1. - rampdown_value) * cfg.beta1_after_rampdown", "\n", "# beta2 = (1. - rampup_value) * cfg.beta2_during_rampdup + rampup_value * cfg.beta2_after_rampup", "\n", "# weight_decay = (1 - rampup_value) * cfg.weight_decay_during_rampup + cfg.weight_decay_after_rampup * rampup_value", "\n", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "# param_group['betas'] = (beta1, beta2)", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_ICT_model.update_ema_variables": [[53, 58], ["min", "zip", "ema_model.parameters", "model.parameters", "ema_params.data.mul_().add_", "ema_params.data.mul_"], "function", ["None"], ["", "", "def", "update_ema_variables", "(", "model", ",", "ema_model", ",", "alpha", ",", "global_step", ")", ":", "\n", "# Use the true average until the exponential average is more correct", "\n", "    ", "alpha", "=", "min", "(", "1", "-", "1", "/", "(", "global_step", "+", "1", ")", ",", "alpha", ")", "\n", "for", "ema_params", ",", "params", "in", "zip", "(", "ema_model", ".", "parameters", "(", ")", ",", "model", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "ema_params", ".", "data", ".", "mul_", "(", "alpha", ")", ".", "add_", "(", "1", "-", "alpha", ",", "params", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_ICT_model.train": [[60, 210], ["utilities.Logger.create_logger", "torch.nn.BCELoss", "torch.nn.MSELoss", "utilities.utils.to_cuda_if_available", "utilities.utils.AverageMeterSet", "utilities.Logger.create_logger.debug", "time.time", "enumerate", "utilities.Logger.create_logger.info", "utilities.ramps.exp_rampup", "utilities.utils.AverageMeterSet.update", "utilities.utils.to_cuda_if_available", "ema_model", "strong_pred_ema.detach.detach", "weak_pred_ema.detach.detach", "model", "int", "ema_model", "numpy.arange", "range", "torch.cat", "torch.reshape().cuda", "torch.cat", "torch.reshape().cuda", "torch.cat", "torch.reshape().cuda", "model", "utilities.utils.AverageMeterSet.update", "optimizer.zero_grad", "loss.backward", "optimizer.step", "time.time", "len", "main_ICT_model.adjust_learning_rate", "torch.rand().cuda", "numpy.random.shuffle", "torch.reshape().cuda.append", "torch.reshape().cuda.append", "torch.reshape().cuda.append", "target.max", "nn.BCELoss.", "nn.BCELoss.", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "nn.BCELoss.", "utilities.utils.AverageMeterSet.update", "nn.BCELoss.", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "loss.item", "loss.item", "main_ICT_model.update_ema_variables", "len", "len", "torch.reshape", "torch.reshape", "torch.reshape", "utilities.Logger.create_logger.debug", "class_criterion.item", "class_criterion.item", "class_criterion.item", "class_criterion.item", "nn.MSELoss.", "consistency_loss_strong.item", "nn.MSELoss.", "consistency_loss_weak.item", "numpy.isnan", "loss.item", "inspect.currentframe", "torch.rand", "loss.item", "loss.item", "target.mean", "target[].sum", "batch_input.mean"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Logger.create_logger", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.ramps.exp_rampup", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.adjust_learning_rate", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.update_ema_variables", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["", "", "def", "train", "(", "train_loader", ",", "model", ",", "optimizer", ",", "c_epoch", ",", "ema_model", "=", "None", ",", "mask_weak", "=", "None", ",", "mask_strong", "=", "None", ",", "adjust_lr", "=", "False", ")", ":", "\n", "    ", "\"\"\" One epoch of a Mean Teacher model\n    Args:\n        train_loader: torch.utils.data.DataLoader, iterator of training batches for an epoch.\n            Should return a tuple: ((teacher input, student input), labels)\n        model: torch.Module, model to be trained, should return a weak and strong prediction\n        optimizer: torch.Module, optimizer used to train the model\n        c_epoch: int, the current epoch of training\n        ema_model: torch.Module, student model, should return a weak and strong prediction\n        mask_weak: slice or list, mask the batch to get only the weak labeled data (used to calculate the loss)\n        mask_strong: slice or list, mask the batch to get only the strong labeled data (used to calcultate the loss)\n        adjust_lr: bool, Whether or not to adjust the learning rate during training (params in config)\n    \"\"\"", "\n", "log", "=", "create_logger", "(", "__name__", "+", "\"/\"", "+", "inspect", ".", "currentframe", "(", ")", ".", "f_code", ".", "co_name", ",", "terminal_level", "=", "cfg", ".", "terminal_level", ")", "\n", "class_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "consistency_criterion", "=", "nn", ".", "MSELoss", "(", ")", "\n", "class_criterion", ",", "consistency_criterion", "=", "to_cuda_if_available", "(", "class_criterion", ",", "consistency_criterion", ")", "\n", "\n", "meters", "=", "AverageMeterSet", "(", ")", "\n", "log", ".", "debug", "(", "\"Nb batches: {}\"", ".", "format", "(", "len", "(", "train_loader", ")", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "(", "batch_input", ",", "ema_batch_input", ")", ",", "target", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "        ", "global_step", "=", "c_epoch", "*", "len", "(", "train_loader", ")", "+", "i", "\n", "rampup_value", "=", "ramps", ".", "exp_rampup", "(", "global_step", ",", "cfg", ".", "n_epoch_rampup", "*", "len", "(", "train_loader", ")", ")", "\n", "\n", "if", "adjust_lr", ":", "\n", "            ", "adjust_learning_rate", "(", "optimizer", ",", "rampup_value", ")", "\n", "", "meters", ".", "update", "(", "'lr'", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", "\n", "batch_input", ",", "ema_batch_input", ",", "target", "=", "to_cuda_if_available", "(", "batch_input", ",", "ema_batch_input", ",", "target", ")", "\n", "# Outputs", "\n", "strong_pred_ema", ",", "weak_pred_ema", "=", "ema_model", "(", "ema_batch_input", ")", "\n", "strong_pred_ema", "=", "strong_pred_ema", ".", "detach", "(", ")", "\n", "weak_pred_ema", "=", "weak_pred_ema", ".", "detach", "(", ")", "\n", "strong_pred", ",", "weak_pred", "=", "model", "(", "batch_input", ")", "\n", "\n", "# core for Interpolation Consistency Training (ICT) ", "\n", "#this version: about 36.55 % in validation", "\n", "n_unlabeled", "=", "int", "(", "3", "*", "cfg", ".", "batch_size", "/", "4", ")", "\n", "unlabeled_data", "=", "batch_input", "[", ":", "n_unlabeled", "]", "\n", "strong_prediction", ",", "weak_prediction", "=", "ema_model", "(", "unlabeled_data", ")", "\n", "\n", "mixed_unlabeled_data", "=", "[", "]", "\n", "mixed_strong_plabel", "=", "[", "]", "\n", "mixed_weak_plabel", "=", "[", "]", "\n", "idx", "=", "np", ".", "arange", "(", "n_unlabeled", ")", "\n", "for", "iter", "in", "range", "(", "n_unlabeled", ")", ":", "\n", "            ", "lambda_", "=", "torch", ".", "rand", "(", "1", ")", ".", "cuda", "(", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "\n", "idx1", "=", "idx", "[", "0", "]", "\n", "idx2", "=", "idx", "[", "1", "]", "\n", "mixed", "=", "lambda_", "*", "unlabeled_data", "[", "idx1", "]", "+", "(", "1.0", "-", "lambda_", ")", "*", "unlabeled_data", "[", "idx2", "]", "\n", "mixed_unlabeled_data", ".", "append", "(", "mixed", ")", "\n", "\n", "spred", "=", "lambda_", "*", "strong_prediction", "[", "idx1", "]", "+", "(", "1.0", "-", "lambda_", ")", "*", "strong_prediction", "[", "idx2", "]", "\n", "mixed_strong_plabel", ".", "append", "(", "spred", ")", "\n", "\n", "wpred", "=", "lambda_", "*", "weak_prediction", "[", "idx1", "]", "+", "(", "1.0", "-", "lambda_", ")", "*", "weak_prediction", "[", "idx2", "]", "\n", "mixed_weak_plabel", ".", "append", "(", "wpred", ")", "\n", "", "mixed_unlabeled_data", "=", "torch", ".", "cat", "(", "mixed_unlabeled_data", ",", "dim", "=", "0", ")", "\n", "mixed_unlabeled_data", "=", "torch", ".", "reshape", "(", "mixed_unlabeled_data", ",", "(", "n_unlabeled", ",", "1", ",", "628", ",", "128", ")", ")", ".", "cuda", "(", ")", "\n", "mixed_strong_plabel", "=", "torch", ".", "cat", "(", "mixed_strong_plabel", ",", "dim", "=", "0", ")", "\n", "mixed_strong_plabel", "=", "torch", ".", "reshape", "(", "mixed_strong_plabel", ",", "(", "n_unlabeled", ",", "157", ",", "10", ")", ")", ".", "cuda", "(", ")", "\n", "mixed_weak_plabel", "=", "torch", ".", "cat", "(", "mixed_weak_plabel", ",", "dim", "=", "0", ")", "\n", "mixed_weak_plabel", "=", "torch", ".", "reshape", "(", "mixed_weak_plabel", ",", "(", "n_unlabeled", ",", "10", ")", ")", ".", "cuda", "(", ")", "\n", "\n", "'''#this version is equal to add noise with random SNR depending on lambda_\n        n_unlabeled = int(3*cfg.batch_size/4)\t# mask for unlabeled and weakly labeled data\n        unlabeled_data1 = batch_input[:n_unlabeled]\n        unlabeled_data2 = ema_batch_input[:n_unlabeled]\n\n        strong_prediction1, weak_prediction1 = ema_model(unlabeled_data1)\n        strong_prediction2, weak_prediction2 = ema_model(unlabeled_data2)\n\n        lambda_ = torch.rand(1).cuda()\n        mixed_unlabeled_data = lambda_*unlabeled_data1 + (1.0-lambda_)*unlabeled_data2\n        mixed_strong_plabel = lambda_*strong_prediction1 + (1.0-lambda_)*strong_prediction2\n        mixed_weak_plabel = lambda_*weak_prediction1 + (1.0-lambda_)*weak_prediction2\n        '''", "\n", "strong_prediction_mixed", ",", "weak_prediction_mixed", "=", "model", "(", "mixed_unlabeled_data", ")", "\n", "\n", "#sample = target[mask_strong].sum(2)", "\n", "#sample = sample.cpu().numpy()", "\n", "#print(np.where(sample[-1,:]>1))", "\n", "\n", "loss", "=", "None", "\n", "# Weak BCE Loss", "\n", "target_weak", "=", "target", ".", "max", "(", "-", "2", ")", "[", "0", "]", "# Take the max in the time axis", "\n", "if", "mask_weak", "is", "not", "None", ":", "\n", "            ", "weak_class_loss", "=", "class_criterion", "(", "weak_pred", "[", "mask_weak", "]", ",", "target_weak", "[", "mask_weak", "]", ")", "\n", "ema_class_loss", "=", "class_criterion", "(", "weak_pred_ema", "[", "mask_weak", "]", ",", "target_weak", "[", "mask_weak", "]", ")", "\n", "loss", "=", "weak_class_loss", "\n", "\n", "if", "i", "==", "0", ":", "\n", "                ", "log", ".", "debug", "(", "f\"target: {target.mean(-2)} \\n Target_weak: {target_weak} \\n \"", "\n", "f\"Target weak mask: {target_weak[mask_weak]} \\n \"", "\n", "f\"Target strong mask: {target[mask_strong].sum(-2)}\\n\"", "\n", "f\"weak loss: {weak_class_loss} \\t rampup_value: {rampup_value}\"", "\n", "f\"tensor mean: {batch_input.mean()}\"", ")", "\n", "", "meters", ".", "update", "(", "'weak_class_loss'", ",", "weak_class_loss", ".", "item", "(", ")", ")", "\n", "meters", ".", "update", "(", "'Weak EMA loss'", ",", "ema_class_loss", ".", "item", "(", ")", ")", "\n", "\n", "# Strong BCE loss", "\n", "", "if", "mask_strong", "is", "not", "None", ":", "\n", "            ", "strong_class_loss", "=", "class_criterion", "(", "strong_pred", "[", "mask_strong", "]", ",", "target", "[", "mask_strong", "]", ")", "\n", "meters", ".", "update", "(", "'Strong loss'", ",", "strong_class_loss", ".", "item", "(", ")", ")", "\n", "\n", "strong_ema_class_loss", "=", "class_criterion", "(", "strong_pred_ema", "[", "mask_strong", "]", ",", "target", "[", "mask_strong", "]", ")", "\n", "meters", ".", "update", "(", "'Strong EMA loss'", ",", "strong_ema_class_loss", ".", "item", "(", ")", ")", "\n", "\n", "if", "loss", "is", "not", "None", ":", "\n", "                ", "loss", "+=", "strong_class_loss", "\n", "", "else", ":", "\n", "                ", "loss", "=", "strong_class_loss", "\n", "\n", "# Teacher-student consistency cost", "\n", "", "", "if", "ema_model", "is", "not", "None", ":", "\n", "            ", "consistency_cost", "=", "cfg", ".", "max_consistency_cost", "*", "rampup_value", "\n", "meters", ".", "update", "(", "'Consistency weight'", ",", "consistency_cost", ")", "\n", "# Take consistency about strong predictions (all data)", "\n", "consistency_loss_strong", "=", "consistency_cost", "*", "consistency_criterion", "(", "strong_prediction_mixed", ",", "mixed_strong_plabel", ")", "\n", "meters", ".", "update", "(", "'Consistency strong'", ",", "consistency_loss_strong", ".", "item", "(", ")", ")", "\n", "if", "loss", "is", "not", "None", ":", "\n", "                ", "loss", "+=", "consistency_loss_strong", "\n", "", "else", ":", "\n", "                ", "loss", "=", "consistency_loss_strong", "\n", "", "meters", ".", "update", "(", "'Consistency weight'", ",", "consistency_cost", ")", "\n", "# Take consistency about weak predictions (all data)", "\n", "consistency_loss_weak", "=", "consistency_cost", "*", "consistency_criterion", "(", "weak_prediction_mixed", ",", "mixed_weak_plabel", ")", "\n", "meters", ".", "update", "(", "'Consistency weak'", ",", "consistency_loss_weak", ".", "item", "(", ")", ")", "\n", "if", "loss", "is", "not", "None", ":", "\n", "                ", "loss", "+=", "consistency_loss_weak", "\n", "", "else", ":", "\n", "                ", "loss", "=", "consistency_loss_weak", "\n", "\n", "", "", "assert", "not", "(", "np", ".", "isnan", "(", "loss", ".", "item", "(", ")", ")", "or", "loss", ".", "item", "(", ")", ">", "1e5", ")", ",", "'Loss explosion: {}'", ".", "format", "(", "loss", ".", "item", "(", ")", ")", "\n", "assert", "not", "loss", ".", "item", "(", ")", "<", "0", ",", "'Loss problem, cannot be negative'", "\n", "meters", ".", "update", "(", "'Loss'", ",", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# compute gradient and do optimizer step", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "global_step", "+=", "1", "\n", "if", "ema_model", "is", "not", "None", ":", "\n", "            ", "update_ema_variables", "(", "model", ",", "ema_model", ",", "0.999", ",", "global_step", ")", "\n", "\n", "", "", "epoch_time", "=", "time", ".", "time", "(", ")", "-", "start", "\n", "log", ".", "info", "(", "f\"Epoch: {c_epoch}\\t Time {epoch_time:.2f}\\t {meters}\"", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_ICT_model.get_dfs": [[212, 251], ["utilities.Logger.create_logger", "desed_dataset.initialize_and_get_df", "desed_dataset.initialize_and_get_df", "desed_dataset.initialize_and_get_df", "utilities.Logger.create_logger.debug", "desed_dataset.initialize_and_get_df", "desed_dataset.initialize_and_get_df.filename.drop_duplicates().sample", "desed_dataset.initialize_and_get_df.drop().reset_index", "utilities.Logger.create_logger.debug", "synthetic_df.drop().reset_index.event_label.value_counts", "desed_dataset.initialize_and_get_df.filename.drop_duplicates", "desed_dataset.initialize_and_get_df.filename.isin", "desed_dataset.initialize_and_get_df.drop", "desed_dataset.initialize_and_get_df.head", "inspect.currentframe"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Logger.create_logger", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df"], ["", "def", "get_dfs", "(", "desed_dataset", ",", "nb_files", "=", "None", ",", "separated_sources", "=", "False", ")", ":", "\n", "    ", "log", "=", "create_logger", "(", "__name__", "+", "\"/\"", "+", "inspect", ".", "currentframe", "(", ")", ".", "f_code", ".", "co_name", ",", "terminal_level", "=", "cfg", ".", "terminal_level", ")", "\n", "audio_weak_ss", "=", "None", "\n", "audio_unlabel_ss", "=", "None", "\n", "audio_validation_ss", "=", "None", "\n", "audio_synthetic_ss", "=", "None", "\n", "if", "separated_sources", ":", "\n", "        ", "audio_weak_ss", "=", "cfg", ".", "weak_ss", "\n", "audio_unlabel_ss", "=", "cfg", ".", "unlabel_ss", "\n", "audio_validation_ss", "=", "cfg", ".", "validation_ss", "\n", "audio_synthetic_ss", "=", "cfg", ".", "synthetic_ss", "\n", "\n", "", "weak_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "weak", ",", "audio_dir_ss", "=", "audio_weak_ss", ",", "nb_files", "=", "nb_files", ")", "\n", "unlabel_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "unlabel", ",", "audio_dir_ss", "=", "audio_unlabel_ss", ",", "nb_files", "=", "nb_files", ")", "\n", "# Event if synthetic not used for training, used on validation purpose", "\n", "synthetic_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "synthetic", ",", "audio_dir_ss", "=", "audio_synthetic_ss", ",", "\n", "nb_files", "=", "nb_files", ",", "download", "=", "False", ")", "\n", "log", ".", "debug", "(", "f\"synthetic: {synthetic_df.head()}\"", ")", "\n", "validation_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "validation", ",", "audio_dir", "=", "cfg", ".", "audio_validation_dir", ",", "\n", "audio_dir_ss", "=", "audio_validation_ss", ",", "nb_files", "=", "nb_files", ")", "\n", "# Divide synthetic in train and valid", "\n", "filenames_train", "=", "synthetic_df", ".", "filename", ".", "drop_duplicates", "(", ")", ".", "sample", "(", "frac", "=", "0.8", ",", "random_state", "=", "26", ")", "\n", "train_synth_df", "=", "synthetic_df", "[", "synthetic_df", ".", "filename", ".", "isin", "(", "filenames_train", ")", "]", "\n", "valid_synth_df", "=", "synthetic_df", ".", "drop", "(", "train_synth_df", ".", "index", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "# Put train_synth in frames so many_hot_encoder can work.", "\n", "#  Not doing it for valid, because not using labels (when prediction) and event based metric expect sec.", "\n", "train_synth_df", ".", "onset", "=", "train_synth_df", ".", "onset", "*", "cfg", ".", "sample_rate", "//", "cfg", ".", "hop_size", "//", "pooling_time_ratio", "\n", "train_synth_df", ".", "offset", "=", "train_synth_df", ".", "offset", "*", "cfg", ".", "sample_rate", "//", "cfg", ".", "hop_size", "//", "pooling_time_ratio", "\n", "log", ".", "debug", "(", "valid_synth_df", ".", "event_label", ".", "value_counts", "(", ")", ")", "\n", "\n", "data_dfs", "=", "{", "\"weak\"", ":", "weak_df", ",", "\n", "\"unlabel\"", ":", "unlabel_df", ",", "\n", "\"synthetic\"", ":", "synthetic_df", ",", "\n", "\"train_synthetic\"", ":", "train_synth_df", ",", "\n", "\"valid_synthetic\"", ":", "valid_synth_df", ",", "\n", "\"validation\"", ":", "validation_df", ",", "\n", "}", "\n", "\n", "return", "data_dfs", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_SRST_model.adjust_learning_rate": [[31, 49], ["None"], "function", ["None"], ["def", "adjust_learning_rate", "(", "optimizer", ",", "rampup_value", ",", "rampdown_value", "=", "1", ")", ":", "\n", "    ", "\"\"\" adjust the learning rate\n    Args:\n        optimizer: torch.Module, the optimizer to be updated\n        rampup_value: float, the float value between 0 and 1 that should increases linearly\n        rampdown_value: float, the float between 1 and 0 that should decrease linearly\n    Returns:\n\n    \"\"\"", "\n", "#LR warm-up to handle large minibatch sizes from https://arxiv.org/abs/1706.02677", "\n", "#We commented parts on betas and weight decay to match 2nd system of last year from Orange", "\n", "lr", "=", "rampup_value", "*", "rampdown_value", "*", "cfg", ".", "max_learning_rate", "\n", "# beta1 = rampdown_value * cfg.beta1_before_rampdown + (1. - rampdown_value) * cfg.beta1_after_rampdown", "\n", "# beta2 = (1. - rampup_value) * cfg.beta2_during_rampdup + rampup_value * cfg.beta2_after_rampup", "\n", "# weight_decay = (1 - rampup_value) * cfg.weight_decay_during_rampup + cfg.weight_decay_after_rampup * rampup_value", "\n", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "# param_group['betas'] = (beta1, beta2)", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_SRST_model.update_ema_variables": [[53, 58], ["min", "zip", "ema_model.parameters", "model.parameters", "ema_params.data.mul_().add_", "ema_params.data.mul_"], "function", ["None"], ["", "", "def", "update_ema_variables", "(", "model", ",", "ema_model", ",", "alpha", ",", "global_step", ")", ":", "\n", "# Use the true average until the exponential average is more correct", "\n", "    ", "alpha", "=", "min", "(", "1", "-", "1", "/", "(", "global_step", "+", "1", ")", ",", "alpha", ")", "\n", "for", "ema_params", ",", "params", "in", "zip", "(", "ema_model", ".", "parameters", "(", ")", ",", "model", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "ema_params", ".", "data", ".", "mul_", "(", "alpha", ")", ".", "add_", "(", "1", "-", "alpha", ",", "params", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_SRST_model.train": [[60, 239], ["utilities.Logger.create_logger", "torch.nn.BCELoss", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss", "torch.nn.Softmax", "torch.tensor().cuda", "utilities.utils.to_cuda_if_available", "utilities.utils.AverageMeterSet", "utilities.Logger.create_logger.debug", "time.time", "enumerate", "utilities.Logger.create_logger.info", "utilities.ramps.exp_rampup", "utilities.utils.AverageMeterSet.update", "utilities.utils.to_cuda_if_available", "model", "ema_model", "ema_model", "strong_predict.detach.detach", "weak_predict.detach.detach", "int", "ema_model", "ema_model", "torch.rand().cuda", "model", "torch.zeros().cuda", "range", "torch.zeros().cuda.mean", "torch.clamp", "utilities.utils.AverageMeterSet.update", "nn.MSELoss.mean", "nn.MSELoss.mean", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "time.time", "torch.tensor", "len", "main_SRST_model.adjust_learning_rate", "target.max", "nn.BCELoss.", "class_criterion.mean", "utilities.utils.AverageMeterSet.update", "nn.BCELoss.", "class_criterion.mean", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "torch.clamp", "torch.log", "torch.log", "torch.log.sum", "range", "torch.cat", "torch.cat", "nn.Softmax.", "torch.sort", "prob_v.sum", "torch.mul().sum", "torch.squeeze", "nn.BCELoss.mean", "torch.clamp.item", "pred_loss.mean", "expect_loss.item", "loss.item", "numpy.isnan", "print", "optimizer.zero_grad", "loss.backward", "optimizer.step", "len", "len", "torch.rand", "utilities.Logger.create_logger.debug", "temp.mean.item", "temp.mean.item", "nn.MSELoss.mean", "consistency_loss_strong.item", "nn.MSELoss.mean", "consistency_loss_weak.item", "torch.zeros", "torch.cat.append", "nn.MSELoss.", "nn.MSELoss.", "loss.item", "loss.item", "main_SRST_model.update_ema_variables", "inspect.currentframe", "p_h0.sum.reshape", "torch.mul", "nn.BCELoss.", "nn.MSELoss.", "nn.MSELoss.", "prob_i.tolist", "target.mean", "target[].sum", "batch_input.mean"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Logger.create_logger", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.ramps.exp_rampup", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.adjust_learning_rate", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.update_ema_variables", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["", "", "def", "train", "(", "train_loader", ",", "model", ",", "optimizer", ",", "c_epoch", ",", "ema_model", "=", "None", ",", "mask_weak", "=", "None", ",", "mask_strong", "=", "None", ",", "adjust_lr", "=", "False", ")", ":", "\n", "    ", "\"\"\" One epoch of a Mean Teacher model\n    Args:\n        train_loader: torch.utils.data.DataLoader, iterator of training batches for an epoch.\n            Should return a tuple: ((teacher input, student input), labels)\n        model: torch.Module, model to be trained, should return a weak and strong prediction\n        optimizer: torch.Module, optimizer used to train the model\n        c_epoch: int, the current epoch of training\n        ema_model: torch.Module, student model, should return a weak and strong prediction\n        mask_weak: slice or list, mask the batch to get only the weak labeled data (used to calculate the loss)\n        mask_strong: slice or list, mask the batch to get only the strong labeled data (used to calcultate the loss)\n        adjust_lr: bool, Whether or not to adjust the learning rate during training (params in config)\n    \"\"\"", "\n", "\n", "log", "=", "create_logger", "(", "__name__", "+", "\"/\"", "+", "inspect", ".", "currentframe", "(", ")", ".", "f_code", ".", "co_name", ",", "terminal_level", "=", "cfg", ".", "terminal_level", ")", "\n", "class_criterion", "=", "nn", ".", "BCELoss", "(", "reduction", "=", "'none'", ")", "\n", "mse_criterion", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "'none'", ")", "\n", "reliability_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "\n", "class_label", "=", "torch", ".", "tensor", "(", "cfg", ".", "class_label", ")", ".", "cuda", "(", ")", "\n", "class_criterion", ",", "mse_criterion", ",", "softmax", "=", "to_cuda_if_available", "(", "class_criterion", ",", "mse_criterion", ",", "softmax", ")", "\n", "\n", "meters", "=", "AverageMeterSet", "(", ")", "\n", "log", ".", "debug", "(", "\"Nb batches: {}\"", ".", "format", "(", "len", "(", "train_loader", ")", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "#plabel = []", "\n", "for", "i", ",", "(", "(", "batch_input", ",", "batch_input_ema", ")", ",", "target", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "        ", "global_step", "=", "c_epoch", "*", "len", "(", "train_loader", ")", "+", "i", "\n", "rampup_value", "=", "ramps", ".", "exp_rampup", "(", "global_step", ",", "cfg", ".", "n_epoch_rampup2", "*", "len", "(", "train_loader", ")", ")", "\n", "\n", "if", "adjust_lr", ":", "\n", "            ", "adjust_learning_rate", "(", "optimizer", ",", "rampup_value", ")", "\n", "", "meters", ".", "update", "(", "'lr'", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", "\n", "batch_input", ",", "batch_input_ema", ",", "target", "=", "to_cuda_if_available", "(", "batch_input", ",", "batch_input_ema", ",", "target", ")", "\n", "\n", "# Outputs", "\n", "strong_pred", ",", "weak_pred", "=", "model", "(", "batch_input", ")", "\n", "strong_predict1", ",", "weak_predict1", "=", "ema_model", "(", "batch_input", ")", "\n", "strong_predict2", ",", "weak_predict2", "=", "ema_model", "(", "batch_input_ema", ")", "\n", "\n", "strong_predict", "=", "(", "strong_predict1", "+", "strong_predict2", ")", "/", "2", "\n", "weak_predict", "=", "(", "weak_predict1", "+", "weak_predict2", ")", "/", "2", "\n", "strong_predict", "=", "strong_predict", ".", "detach", "(", ")", "\n", "weak_predict", "=", "weak_predict", ".", "detach", "(", ")", "\n", "\n", "# core for Interpolation Consistency Training (ICT) ", "\n", "n_unlabeled", "=", "int", "(", "3", "*", "cfg", ".", "batch_size", "/", "4", ")", "# mask for unlabeled and weakly labeled data", "\n", "unlabeled_data1", "=", "batch_input", "[", ":", "n_unlabeled", "]", "\n", "unlabeled_data2", "=", "batch_input_ema", "[", ":", "n_unlabeled", "]", "\n", "\n", "strong_prediction1", ",", "weak_prediction1", "=", "ema_model", "(", "unlabeled_data1", ")", "\n", "strong_prediction2", ",", "weak_prediction2", "=", "ema_model", "(", "unlabeled_data2", ")", "\n", "\n", "lambda_", "=", "torch", ".", "rand", "(", "1", ")", ".", "cuda", "(", ")", "\n", "mixed_unlabeled_data", "=", "lambda_", "*", "unlabeled_data1", "+", "(", "1.0", "-", "lambda_", ")", "*", "unlabeled_data2", "\n", "mixed_strong_plabel", "=", "lambda_", "*", "strong_prediction1", "+", "(", "1.0", "-", "lambda_", ")", "*", "strong_prediction2", "\n", "mixed_weak_plabel", "=", "lambda_", "*", "weak_prediction1", "+", "(", "1.0", "-", "lambda_", ")", "*", "weak_prediction2", "\n", "\n", "strong_prediction_mixed", ",", "weak_prediction_mixed", "=", "model", "(", "mixed_unlabeled_data", ")", "\n", "\n", "loss", "=", "None", "\n", "# Weak BCE Loss", "\n", "target_weak", "=", "target", ".", "max", "(", "-", "2", ")", "[", "0", "]", "# Take the max in the time axis", "\n", "if", "mask_weak", "is", "not", "None", ":", "\n", "            ", "temp", "=", "class_criterion", "(", "weak_pred", "[", "mask_weak", "]", ",", "target_weak", "[", "mask_weak", "]", ")", "\n", "weak_class_loss", "=", "temp", ".", "mean", "(", ")", "\n", "\n", "if", "i", "==", "0", ":", "\n", "                ", "log", ".", "debug", "(", "f\"target: {target.mean(-2)} \\n Target_weak: {target_weak} \\n \"", "\n", "f\"Target weak mask: {target_weak[mask_weak]} \\n \"", "\n", "f\"Target strong mask: {target[mask_strong].sum(-2)}\\n\"", "\n", "f\"weak loss: {weak_class_loss} \\t rampup_value: {rampup_value}\"", "\n", "f\"tensor mean: {batch_input.mean()}\"", ")", "\n", "", "meters", ".", "update", "(", "'weak_class_loss'", ",", "weak_class_loss", ".", "item", "(", ")", ")", "\n", "#meters.update('Weak EMA loss', ema_class_loss.mean().item())", "\n", "\n", "# Strong BCE loss", "\n", "", "if", "mask_strong", "is", "not", "None", ":", "\n", "            ", "temp", "=", "class_criterion", "(", "strong_pred", "[", "mask_strong", "]", ",", "target", "[", "mask_strong", "]", ")", "\n", "strong_class_loss", "=", "temp", ".", "mean", "(", ")", "\n", "meters", ".", "update", "(", "'Strong loss'", ",", "strong_class_loss", ".", "item", "(", ")", ")", "\n", "\n", "# Teacher-student consistency cost", "\n", "", "if", "ema_model", "is", "not", "None", ":", "\n", "            ", "rampup_weight", "=", "cfg", ".", "max_rampup_weight", "*", "rampup_value", "\n", "meters", ".", "update", "(", "'Rampup weight'", ",", "rampup_weight", ")", "\n", "\n", "# Take consistency about strong predictions (all data)", "\n", "consistency_loss_strong", "=", "rampup_weight", "*", "mse_criterion", "(", "strong_prediction_mixed", ",", "mixed_strong_plabel", ")", ".", "mean", "(", ")", "\n", "meters", ".", "update", "(", "'Consistency strong'", ",", "consistency_loss_strong", ".", "item", "(", ")", ")", "\n", "#if loss is not None:", "\n", "#    loss += consistency_loss_strong", "\n", "#else:", "\n", "#    loss = consistency_loss_strong", "\n", "#meters.update('Consistency weight', consistency_cost)", "\n", "# Take consistency about weak predictions (all data)", "\n", "consistency_loss_weak", "=", "rampup_weight", "*", "mse_criterion", "(", "weak_prediction_mixed", ",", "mixed_weak_plabel", ")", ".", "mean", "(", ")", "\n", "meters", ".", "update", "(", "'Consistency weak'", ",", "consistency_loss_weak", ".", "item", "(", ")", ")", "\n", "#if loss is not None:", "\n", "#    loss += consistency_loss_weak", "\n", "#else:", "\n", "#    loss = consistency_loss_weak", "\n", "\n", "# Self-labeling", "\n", "", "est_strong_target", "=", "torch", ".", "zeros", "(", "cfg", ".", "batch_size", ",", "157", ",", "cfg", ".", "nClass", ")", ".", "cuda", "(", ")", "\n", "for", "bter", "in", "range", "(", "cfg", ".", "batch_size", ")", ":", "\n", "            ", "sp", "=", "strong_predict", "[", "bter", "]", "\n", "sp", "=", "torch", ".", "clamp", "(", "sp", ",", "0.0001", ",", "0.9999", ")", "\n", "p_h1", "=", "torch", ".", "log", "(", "sp", ")", "\n", "p_h0", "=", "torch", ".", "log", "(", "1", "-", "sp", ")", "\n", "\n", "# K = 0", "\n", "P0", "=", "p_h0", ".", "sum", "(", "1", ")", "\n", "\n", "# K = 1", "\n", "P1", "=", "P0", "[", ":", ",", "None", "]", "+", "p_h1", "-", "p_h0", "\n", "#P  = torch.cat([P0.reshape(157,1), P1], 1)", "\n", "\n", "# K = 2", "\n", "P2", "=", "[", "]", "\n", "for", "cter", "in", "range", "(", "1", ",", "cfg", ".", "nClass", ")", ":", "\n", "                ", "P2", ".", "append", "(", "P1", "[", ":", ",", ":", "-", "cter", "]", "+", "P1", "[", ":", ",", "cter", ":", "]", ")", "\n", "", "P2", "=", "torch", ".", "cat", "(", "P2", ",", "1", ")", "\n", "P2", "=", "P2", "-", "P0", "[", ":", ",", "None", "]", "\n", "P", "=", "torch", ".", "cat", "(", "[", "P0", ".", "reshape", "(", "157", ",", "1", ")", ",", "P1", ",", "P2", "]", ",", "1", ")", "\n", "\n", "# K: up to 3", "\n", "#P3 = []", "\n", "#for cter1 in range(1,cfg.nClass):", "\n", "#    for cter2 in range(1, cfg.nClass-cter1):", "\n", "#        P3.append(P1[:,:-(cter1+cter2)]+P1[:,cter1:-cter2]+P1[:,(cter1+cter2):])", "\n", "#P3 = torch.cat(P3,1)", "\n", "#P3 = P3 - 2*P0[:,None]", "\n", "#P  = torch.cat([P0.reshape(157,1), P1, P2, P3], 1)", "\n", "\n", "P", "=", "softmax", "(", "P", ")", "\n", "prob_v", ",", "prob_i", "=", "torch", ".", "sort", "(", "P", ",", "dim", "=", "1", ",", "descending", "=", "True", ")", "\n", "\n", "norm_p", "=", "prob_v", ".", "sum", "(", "1", ")", "\n", "prob_v", "=", "prob_v", "/", "norm_p", "[", ":", ",", "None", "]", "\n", "\n", "cl", "=", "class_label", "[", "prob_i", ".", "tolist", "(", ")", ",", ":", "]", "\n", "cl", "=", "torch", ".", "mul", "(", "cl", ",", "prob_v", "[", ":", ",", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", "\n", "\n", "est_strong_target", "[", "bter", ",", ":", ",", ":", "]", "=", "torch", ".", "squeeze", "(", "cl", ")", "\n", "\n", "", "est_weak_target", "=", "est_strong_target", ".", "mean", "(", "1", ")", "\n", "\n", "reliability", "=", "rampup_weight", "/", "class_criterion", "(", "est_strong_target", "[", "mask_strong", "]", ",", "target", "[", "mask_strong", "]", ")", ".", "mean", "(", ")", "\n", "reliability", "=", "torch", ".", "clamp", "(", "reliability", ",", "0", ",", "2", "*", "rampup_weight", ")", "\n", "meters", ".", "update", "(", "'Reliability of pseudo label'", ",", "reliability", ".", "item", "(", ")", ")", "\n", "\n", "# classification error with pseudo label", "\n", "pred_strong_loss", "=", "mse_criterion", "(", "strong_pred", "[", ":", "n_unlabeled", "]", ",", "est_strong_target", "[", ":", "n_unlabeled", "]", ")", ".", "mean", "(", "[", "1", ",", "2", "]", ")", "\n", "pred_weak_loss", "=", "mse_criterion", "(", "weak_pred", "[", ":", "n_unlabeled", "]", ",", "est_weak_target", "[", ":", "n_unlabeled", "]", ")", ".", "mean", "(", "1", ")", "\n", "\n", "pred_loss", "=", "pred_strong_loss", "+", "pred_weak_loss", "\n", "expect_loss", "=", "reliability", "*", "pred_loss", ".", "mean", "(", ")", "\n", "meters", ".", "update", "(", "'Expectation of predict loss'", ",", "expect_loss", ".", "item", "(", ")", ")", "\n", "\n", "loss", "=", "weak_class_loss", "+", "strong_class_loss", "+", "consistency_loss_strong", "+", "consistency_loss_weak", "+", "expect_loss", "\n", "meters", ".", "update", "(", "'Loss'", ",", "loss", ".", "item", "(", ")", ")", "\n", "\n", "if", "(", "np", ".", "isnan", "(", "loss", ".", "item", "(", ")", ")", "or", "loss", ".", "item", "(", ")", ">", "1e5", ")", ":", "\n", "            ", "print", "(", "loss", ")", "\n", "", "else", ":", "\n", "# compute gradient and do optimizer step", "\n", "            ", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "global_step", "+=", "1", "\n", "if", "ema_model", "is", "not", "None", ":", "\n", "                ", "update_ema_variables", "(", "model", ",", "ema_model", ",", "0.999", ",", "global_step", ")", "\n", "\n", "", "", "", "epoch_time", "=", "time", ".", "time", "(", ")", "-", "start", "\n", "log", ".", "info", "(", "f\"Epoch: {c_epoch}\\t Time {epoch_time:.2f}\\t {meters}\"", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_SRST_model.get_dfs": [[240, 279], ["utilities.Logger.create_logger", "desed_dataset.initialize_and_get_df", "desed_dataset.initialize_and_get_df", "desed_dataset.initialize_and_get_df", "utilities.Logger.create_logger.debug", "desed_dataset.initialize_and_get_df", "desed_dataset.initialize_and_get_df.filename.drop_duplicates().sample", "desed_dataset.initialize_and_get_df.drop().reset_index", "utilities.Logger.create_logger.debug", "synthetic_df.drop().reset_index.event_label.value_counts", "desed_dataset.initialize_and_get_df.filename.drop_duplicates", "desed_dataset.initialize_and_get_df.filename.isin", "desed_dataset.initialize_and_get_df.drop", "desed_dataset.initialize_and_get_df.head", "inspect.currentframe"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Logger.create_logger", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df"], ["", "def", "get_dfs", "(", "desed_dataset", ",", "nb_files", "=", "None", ",", "separated_sources", "=", "False", ")", ":", "\n", "    ", "log", "=", "create_logger", "(", "__name__", "+", "\"/\"", "+", "inspect", ".", "currentframe", "(", ")", ".", "f_code", ".", "co_name", ",", "terminal_level", "=", "cfg", ".", "terminal_level", ")", "\n", "audio_weak_ss", "=", "None", "\n", "audio_unlabel_ss", "=", "None", "\n", "audio_validation_ss", "=", "None", "\n", "audio_synthetic_ss", "=", "None", "\n", "if", "separated_sources", ":", "\n", "        ", "audio_weak_ss", "=", "cfg", ".", "weak_ss", "\n", "audio_unlabel_ss", "=", "cfg", ".", "unlabel_ss", "\n", "audio_validation_ss", "=", "cfg", ".", "validation_ss", "\n", "audio_synthetic_ss", "=", "cfg", ".", "synthetic_ss", "\n", "\n", "", "weak_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "weak", ",", "audio_dir_ss", "=", "audio_weak_ss", ",", "nb_files", "=", "nb_files", ")", "\n", "unlabel_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "unlabel", ",", "audio_dir_ss", "=", "audio_unlabel_ss", ",", "nb_files", "=", "nb_files", ")", "\n", "# Event if synthetic not used for training, used on validation purpose", "\n", "synthetic_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "synthetic", ",", "audio_dir_ss", "=", "audio_synthetic_ss", ",", "\n", "nb_files", "=", "nb_files", ",", "download", "=", "False", ")", "\n", "log", ".", "debug", "(", "f\"synthetic: {synthetic_df.head()}\"", ")", "\n", "validation_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "validation", ",", "audio_dir", "=", "cfg", ".", "audio_validation_dir", ",", "\n", "audio_dir_ss", "=", "audio_validation_ss", ",", "nb_files", "=", "nb_files", ")", "\n", "# Divide synthetic in train and valid", "\n", "filenames_train", "=", "synthetic_df", ".", "filename", ".", "drop_duplicates", "(", ")", ".", "sample", "(", "frac", "=", "0.8", ",", "random_state", "=", "26", ")", "\n", "train_synth_df", "=", "synthetic_df", "[", "synthetic_df", ".", "filename", ".", "isin", "(", "filenames_train", ")", "]", "\n", "valid_synth_df", "=", "synthetic_df", ".", "drop", "(", "train_synth_df", ".", "index", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "# Put train_synth in frames so many_hot_encoder can work.", "\n", "#  Not doing it for valid, because not using labels (when prediction) and event based metric expect sec.", "\n", "train_synth_df", ".", "onset", "=", "train_synth_df", ".", "onset", "*", "cfg", ".", "sample_rate", "//", "cfg", ".", "hop_size", "//", "pooling_time_ratio", "\n", "train_synth_df", ".", "offset", "=", "train_synth_df", ".", "offset", "*", "cfg", ".", "sample_rate", "//", "cfg", ".", "hop_size", "//", "pooling_time_ratio", "\n", "log", ".", "debug", "(", "valid_synth_df", ".", "event_label", ".", "value_counts", "(", ")", ")", "\n", "\n", "data_dfs", "=", "{", "\"weak\"", ":", "weak_df", ",", "\n", "\"unlabel\"", ":", "unlabel_df", ",", "\n", "\"synthetic\"", ":", "synthetic_df", ",", "\n", "\"train_synthetic\"", ":", "train_synth_df", ",", "\n", "\"valid_synthetic\"", ":", "valid_synth_df", ",", "\n", "\"validation\"", ":", "validation_df", ",", "\n", "}", "\n", "\n", "return", "data_dfs", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model.adjust_learning_rate": [[31, 49], ["None"], "function", ["None"], ["def", "adjust_learning_rate", "(", "optimizer", ",", "rampup_value", ",", "rampdown_value", "=", "1", ")", ":", "\n", "    ", "\"\"\" adjust the learning rate\n    Args:\n        optimizer: torch.Module, the optimizer to be updated\n        rampup_value: float, the float value between 0 and 1 that should increases linearly\n        rampdown_value: float, the float between 1 and 0 that should decrease linearly\n    Returns:\n\n    \"\"\"", "\n", "#LR warm-up to handle large minibatch sizes from https://arxiv.org/abs/1706.02677", "\n", "#We commented parts on betas and weight decay to match 2nd system of last year from Orange", "\n", "lr", "=", "rampup_value", "*", "rampdown_value", "*", "cfg", ".", "max_learning_rate", "\n", "# beta1 = rampdown_value * cfg.beta1_before_rampdown + (1. - rampdown_value) * cfg.beta1_after_rampdown", "\n", "# beta2 = (1. - rampup_value) * cfg.beta2_during_rampdup + rampup_value * cfg.beta2_after_rampup", "\n", "# weight_decay = (1 - rampup_value) * cfg.weight_decay_during_rampup + cfg.weight_decay_after_rampup * rampup_value", "\n", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "# param_group['betas'] = (beta1, beta2)", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model.update_ema_variables": [[53, 58], ["min", "zip", "ema_model.parameters", "model.parameters", "ema_params.data.mul_().add_", "ema_params.data.mul_"], "function", ["None"], ["", "", "def", "update_ema_variables", "(", "model", ",", "ema_model", ",", "alpha", ",", "global_step", ")", ":", "\n", "# Use the true average until the exponential average is more correct", "\n", "    ", "alpha", "=", "min", "(", "1", "-", "1", "/", "(", "global_step", "+", "1", ")", ",", "alpha", ")", "\n", "for", "ema_params", ",", "params", "in", "zip", "(", "ema_model", ".", "parameters", "(", ")", ",", "model", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "ema_params", ".", "data", ".", "mul_", "(", "alpha", ")", ".", "add_", "(", "1", "-", "alpha", ",", "params", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model.train": [[60, 244], ["utilities.Logger.create_logger", "torch.nn.BCELoss", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss", "utilities.utils.JSD", "torch.nn.Softmax", "torch.tensor().cuda", "utilities.utils.to_cuda_if_available", "utilities.utils.AverageMeterSet", "utilities.Logger.create_logger.debug", "time.time", "enumerate", "utilities.Logger.create_logger.info", "utilities.ramps.exp_rampup", "utilities.utils.AverageMeterSet.update", "utilities.utils.to_cuda_if_available", "model1", "ema_model1", "strong_predict1.detach.detach", "weak_predict1.detach.detach", "model2", "ema_model2", "strong_predict2.detach.detach", "weak_predict2.detach.detach", "int", "torch.zeros().cuda", "torch.zeros().cuda", "range", "torch.zeros().cuda.mean", "torch.zeros().cuda.mean", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "nn.MSELoss.mean", "nn.MSELoss.mean", "nn.MSELoss.mean", "nn.MSELoss.mean", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "time.time", "torch.tensor", "len", "main_CRST_model.adjust_learning_rate", "main_CRST_model.adjust_learning_rate", "target.max", "nn.BCELoss.mean", "nn.BCELoss.mean", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "nn.BCELoss.mean", "nn.BCELoss.mean", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "torch.clamp", "torch.log", "torch.log", "torch.clamp", "torch.log", "torch.log", "torch.cat", "torch.cat", "torch.cat.sum", "range", "torch.cat", "torch.cat", "nn.Softmax.", "torch.sort", "prob_v.sum", "torch.mul().sum", "torch.squeeze", "torch.squeeze", "strong_reliability1.item", "strong_reliability2.item", "expect_loss1.item", "expect_loss2.item", "loss1.item", "loss2.item", "numpy.isnan", "print", "print", "optimizer1.zero_grad", "loss1.backward", "optimizer1.step", "optimizer2.zero_grad", "loss2.backward", "optimizer2.step", "len", "len", "utilities.Logger.create_logger.debug", "class_criterion().mean.item", "class_criterion().mean.item", "class_criterion().mean.item", "class_criterion().mean.item", "torch.zeros", "torch.zeros", "torch.cat.append", "utilities.utils.JSD.apply().mean", "utilities.utils.JSD.apply().mean", "utilities.utils.JSD.apply().mean", "utilities.utils.JSD.apply().mean", "nn.MSELoss.", "nn.MSELoss.", "nn.MSELoss.", "nn.MSELoss.", "mse_criterion().mean.mean", "mse_criterion().mean.mean", "mse_criterion().mean.mean", "mse_criterion().mean.mean", "loss1.item", "loss1.item", "main_CRST_model.update_ema_variables", "main_CRST_model.update_ema_variables", "inspect.currentframe", "nn.BCELoss.", "nn.BCELoss.", "nn.BCELoss.", "nn.BCELoss.", "p_h0.sum.reshape", "torch.mul", "prob_i.tolist", "utilities.utils.JSD.apply", "utilities.utils.JSD.apply", "utilities.utils.JSD.apply", "utilities.utils.JSD.apply", "target.mean", "target[].sum", "batch_input.mean"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Logger.create_logger", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.ramps.exp_rampup", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.adjust_learning_rate", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.adjust_learning_rate", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.update_ema_variables", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.update_ema_variables", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.EarlyStopping.apply", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.EarlyStopping.apply", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.EarlyStopping.apply", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.EarlyStopping.apply", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["", "", "def", "train", "(", "train_loader", ",", "model1", ",", "model2", ",", "optimizer1", ",", "optimizer2", ",", "c_epoch", ",", "ema_model1", "=", "None", ",", "ema_model2", "=", "None", ",", "mask_weak", "=", "None", ",", "mask_strong", "=", "None", ",", "adjust_lr", "=", "False", ")", ":", "\n", "    ", "\"\"\" One epoch of a Mean Teacher model\n    Args:\n        train_loader: torch.utils.data.DataLoader, iterator of training batches for an epoch.\n            Should return a tuple: ((teacher input, student input), labels)\n        model: torch.Module, model to be trained, should return a weak and strong prediction\n        optimizer: torch.Module, optimizer used to train the model\n        c_epoch: int, the current epoch of training\n        ema_model: torch.Module, student model, should return a weak and strong prediction\n        mask_weak: slice or list, mask the batch to get only the weak labeled data (used to calculate the loss)\n        mask_strong: slice or list, mask the batch to get only the strong labeled data (used to calcultate the loss)\n        adjust_lr: bool, Whether or not to adjust the learning rate during training (params in config)\n    \"\"\"", "\n", "\n", "log", "=", "create_logger", "(", "__name__", "+", "\"/\"", "+", "inspect", ".", "currentframe", "(", ")", ".", "f_code", ".", "co_name", ",", "terminal_level", "=", "cfg", ".", "terminal_level", ")", "\n", "class_criterion", "=", "nn", ".", "BCELoss", "(", "reduction", "=", "'none'", ")", "\n", "mse_criterion", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "'none'", ")", "\n", "reliability_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "jsd", "=", "JSD", "(", ")", "\n", "\n", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "\n", "class_label", "=", "torch", ".", "tensor", "(", "cfg", ".", "class_label", ")", ".", "cuda", "(", ")", "\n", "class_criterion", ",", "mse_criterion", ",", "softmax", "=", "to_cuda_if_available", "(", "class_criterion", ",", "mse_criterion", ",", "softmax", ")", "\n", "\n", "meters", "=", "AverageMeterSet", "(", ")", "\n", "log", ".", "debug", "(", "\"Nb batches: {}\"", ".", "format", "(", "len", "(", "train_loader", ")", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "#plabel = []", "\n", "for", "i", ",", "(", "(", "batch_input", ",", "batch_input_ema", ")", ",", "target", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "        ", "global_step", "=", "c_epoch", "*", "len", "(", "train_loader", ")", "+", "i", "\n", "rampup_value", "=", "ramps", ".", "exp_rampup", "(", "global_step", ",", "cfg", ".", "n_epoch_rampup2", "*", "len", "(", "train_loader", ")", ")", "\n", "\n", "if", "adjust_lr", ":", "\n", "            ", "adjust_learning_rate", "(", "optimizer1", ",", "rampup_value", ",", "rampdown_value", "=", "1.0", ")", "\n", "adjust_learning_rate", "(", "optimizer2", ",", "rampup_value", ",", "rampdown_value", "=", "0.9", ")", "\n", "", "meters", ".", "update", "(", "'lr'", ",", "optimizer1", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", "\n", "batch_input", ",", "batch_input_ema", ",", "target", "=", "to_cuda_if_available", "(", "batch_input", ",", "batch_input_ema", ",", "target", ")", "\n", "\n", "# Outputs", "\n", "strong_pred1", ",", "weak_pred1", "=", "model1", "(", "batch_input", ")", "\n", "strong_predict1", ",", "weak_predict1", "=", "ema_model1", "(", "batch_input_ema", ")", "\n", "strong_predict1", "=", "strong_predict1", ".", "detach", "(", ")", "\n", "weak_predict1", "=", "weak_predict1", ".", "detach", "(", ")", "\n", "\n", "# data augmentation    ", "\n", "strong_pred2", ",", "weak_pred2", "=", "model2", "(", "batch_input_ema", ")", "\n", "strong_predict2", ",", "weak_predict2", "=", "ema_model2", "(", "batch_input", ")", "\n", "strong_predict2", "=", "strong_predict2", ".", "detach", "(", ")", "\n", "weak_predict2", "=", "weak_predict2", ".", "detach", "(", ")", "\n", "\n", "# Weak BCE Loss", "\n", "target_weak", "=", "target", ".", "max", "(", "-", "2", ")", "[", "0", "]", "# Take the max in the time axis", "\n", "if", "mask_weak", "is", "not", "None", ":", "\n", "            ", "weak_class_loss1", "=", "class_criterion", "(", "weak_pred1", "[", "mask_weak", "]", ",", "target_weak", "[", "mask_weak", "]", ")", ".", "mean", "(", ")", "\n", "weak_class_loss2", "=", "class_criterion", "(", "weak_pred2", "[", "mask_weak", "]", ",", "target_weak", "[", "mask_weak", "]", ")", ".", "mean", "(", ")", "\n", "\n", "if", "i", "==", "0", ":", "\n", "                ", "log", ".", "debug", "(", "f\"target: {target.mean(-2)} \\n Target_weak: {target_weak} \\n \"", "\n", "f\"Target weak mask: {target_weak[mask_weak]} \\n \"", "\n", "f\"Target strong mask: {target[mask_strong].sum(-2)}\\n\"", "\n", "f\"weak loss1: {weak_class_loss1} \\t rampup_value: {rampup_value}\"", "\n", "f\"weak loss2: {weak_class_loss2} \\t rampup_value: {rampup_value}\"", "\n", "f\"tensor mean: {batch_input.mean()}\"", ")", "\n", "", "meters", ".", "update", "(", "'weak_class_loss1'", ",", "weak_class_loss1", ".", "item", "(", ")", ")", "\n", "meters", ".", "update", "(", "'weak_class_loss2'", ",", "weak_class_loss2", ".", "item", "(", ")", ")", "\n", "\n", "# Strong BCE loss", "\n", "", "if", "mask_strong", "is", "not", "None", ":", "\n", "            ", "strong_class_loss1", "=", "class_criterion", "(", "strong_pred1", "[", "mask_strong", "]", ",", "target", "[", "mask_strong", "]", ")", ".", "mean", "(", ")", "\n", "strong_class_loss2", "=", "class_criterion", "(", "strong_pred2", "[", "mask_strong", "]", ",", "target", "[", "mask_strong", "]", ")", ".", "mean", "(", ")", "\n", "meters", ".", "update", "(", "'Strong loss1'", ",", "strong_class_loss1", ".", "item", "(", ")", ")", "\n", "meters", ".", "update", "(", "'Strong loss2'", ",", "strong_class_loss2", ".", "item", "(", ")", ")", "\n", "\n", "# Teacher-student consistency cost", "\n", "", "if", "ema_model1", "is", "not", "None", ":", "\n", "            ", "rampup_weight", "=", "cfg", ".", "max_rampup_weight", "*", "rampup_value", "\n", "meters", ".", "update", "(", "'Rampup weight'", ",", "rampup_weight", ")", "\n", "\n", "\n", "# Self-labeling", "\n", "", "n_unlabeled", "=", "int", "(", "3", "*", "cfg", ".", "batch_size", "/", "4", ")", "\n", "est_strong_target1", "=", "torch", ".", "zeros", "(", "cfg", ".", "batch_size", ",", "157", ",", "cfg", ".", "nClass", ")", ".", "cuda", "(", ")", "\n", "est_strong_target2", "=", "torch", ".", "zeros", "(", "cfg", ".", "batch_size", ",", "157", ",", "cfg", ".", "nClass", ")", ".", "cuda", "(", ")", "\n", "for", "bter", "in", "range", "(", "cfg", ".", "batch_size", ")", ":", "\n", "            ", "sp1", "=", "strong_predict1", "[", "bter", "]", "\n", "sp1", "=", "torch", ".", "clamp", "(", "sp1", ",", "1.0e-4", ",", "1", "-", "1.0e-4", ")", "\n", "p1_h1", "=", "torch", ".", "log", "(", "sp1", ")", "\n", "p1_h0", "=", "torch", ".", "log", "(", "1", "-", "sp1", ")", "\n", "\n", "sp2", "=", "strong_predict2", "[", "bter", "]", "\n", "sp2", "=", "torch", ".", "clamp", "(", "sp2", ",", "1.0e-4", ",", "1", "-", "1.0e-4", ")", "\n", "p2_h1", "=", "torch", ".", "log", "(", "sp2", ")", "\n", "p2_h0", "=", "torch", ".", "log", "(", "1", "-", "sp2", ")", "\n", "\n", "p_h0", "=", "torch", ".", "cat", "(", "(", "p1_h0", ",", "p2_h0", ")", ",", "0", ")", "\n", "p_h1", "=", "torch", ".", "cat", "(", "(", "p1_h1", ",", "p2_h1", ")", ",", "0", ")", "\n", "\n", "# K = 0", "\n", "P0", "=", "p_h0", ".", "sum", "(", "1", ")", "\n", "\n", "# K = 1", "\n", "P1", "=", "P0", "[", ":", ",", "None", "]", "+", "p_h1", "-", "p_h0", "\n", "#P  = torch.cat([P0.reshape(157,1), P1], 1)", "\n", "\n", "# K = 2", "\n", "P2", "=", "[", "]", "\n", "for", "cter", "in", "range", "(", "1", ",", "cfg", ".", "nClass", ")", ":", "\n", "                ", "P2", ".", "append", "(", "P1", "[", ":", ",", ":", "-", "cter", "]", "+", "P1", "[", ":", ",", "cter", ":", "]", ")", "\n", "", "P2", "=", "torch", ".", "cat", "(", "P2", ",", "1", ")", "\n", "P2", "=", "P2", "-", "P0", "[", ":", ",", "None", "]", "\n", "P", "=", "torch", ".", "cat", "(", "[", "P0", ".", "reshape", "(", "157", "*", "2", ",", "1", ")", ",", "P1", ",", "P2", "]", ",", "1", ")", "\n", "\n", "# K: up to 3", "\n", "#P3 = []", "\n", "#for cter1 in range(1,cfg.nClass):", "\n", "#    for cter2 in range(1, cfg.nClass-cter1):", "\n", "#        P3.append(P1[:,:-(cter1+cter2)]+P1[:,cter1:-cter2]+P1[:,(cter1+cter2):])", "\n", "#P3 = torch.cat(P3,1)", "\n", "#P3 = P3 - 2*P0[:,None]", "\n", "#P  = torch.cat([P0.reshape(157,1), P1, P2, P3], 1)", "\n", "\n", "P", "=", "softmax", "(", "P", ")", "\n", "prob_v", ",", "prob_i", "=", "torch", ".", "sort", "(", "P", ",", "dim", "=", "1", ",", "descending", "=", "True", ")", "\n", "\n", "norm_p", "=", "prob_v", ".", "sum", "(", "1", ")", "\n", "prob_v", "=", "prob_v", "/", "norm_p", "[", ":", ",", "None", "]", "\n", "\n", "cl", "=", "class_label", "[", "prob_i", ".", "tolist", "(", ")", ",", ":", "]", "\n", "cl", "=", "torch", ".", "mul", "(", "cl", ",", "prob_v", "[", ":", ",", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", "\n", "\n", "est_strong_target1", "[", "bter", ",", ":", ",", ":", "]", "=", "torch", ".", "squeeze", "(", "cl", "[", ":", "157", ",", ":", "]", ")", "\n", "est_strong_target2", "[", "bter", ",", ":", ",", ":", "]", "=", "torch", ".", "squeeze", "(", "cl", "[", "157", ":", ",", ":", "]", ")", "\n", "\n", "", "est_weak_target1", "=", "est_strong_target1", ".", "mean", "(", "1", ")", "\n", "est_weak_target2", "=", "est_strong_target2", ".", "mean", "(", "1", ")", "\n", "\n", "strong_reliability1", "=", "rampup_weight", "*", "(", "1", "-", "jsd", ".", "apply", "(", "est_strong_target1", "[", "mask_strong", "]", ",", "target", "[", "mask_strong", "]", ")", ".", "mean", "(", ")", ")", "\n", "strong_reliability2", "=", "rampup_weight", "*", "(", "1", "-", "jsd", ".", "apply", "(", "est_strong_target2", "[", "mask_strong", "]", ",", "target", "[", "mask_strong", "]", ")", ".", "mean", "(", ")", ")", "\n", "weak_reliability1", "=", "rampup_weight", "*", "(", "1", "-", "jsd", ".", "apply", "(", "est_weak_target1", "[", "mask_weak", "]", ",", "target_weak", "[", "mask_weak", "]", ")", ".", "mean", "(", ")", ")", "\n", "weak_reliability2", "=", "rampup_weight", "*", "(", "1", "-", "jsd", ".", "apply", "(", "est_weak_target2", "[", "mask_weak", "]", ",", "target_weak", "[", "mask_weak", "]", ")", ".", "mean", "(", ")", ")", "\n", "\n", "meters", ".", "update", "(", "'Reliability of pseudo label1'", ",", "strong_reliability1", ".", "item", "(", ")", ")", "\n", "meters", ".", "update", "(", "'Reliability of pseudo label2'", ",", "strong_reliability2", ".", "item", "(", ")", ")", "\n", "\n", "# classification error with pseudo label", "\n", "pred_strong_loss1", "=", "mse_criterion", "(", "strong_pred1", "[", "6", ":", "n_unlabeled", "]", ",", "est_strong_target2", "[", "6", ":", "n_unlabeled", "]", ")", ".", "mean", "(", "[", "1", ",", "2", "]", ")", "\n", "pred_weak_loss1", "=", "mse_criterion", "(", "strong_pred1", "[", "mask_weak", "]", ",", "est_strong_target2", "[", "mask_weak", "]", ")", ".", "mean", "(", "[", "1", ",", "2", "]", ")", "\n", "pred_strong_loss2", "=", "mse_criterion", "(", "strong_pred2", "[", "6", ":", "n_unlabeled", "]", ",", "est_strong_target1", "[", "6", ":", "n_unlabeled", "]", ")", ".", "mean", "(", "[", "1", ",", "2", "]", ")", "\n", "pred_weak_loss2", "=", "mse_criterion", "(", "strong_pred2", "[", "mask_weak", "]", ",", "est_strong_target1", "[", "mask_weak", "]", ")", ".", "mean", "(", "[", "1", ",", "2", "]", ")", "\n", "\n", "expect_loss1", "=", "strong_reliability2", "*", "pred_strong_loss1", ".", "mean", "(", ")", "+", "weak_reliability2", "*", "pred_weak_loss1", ".", "mean", "(", ")", "\n", "expect_loss2", "=", "strong_reliability1", "*", "pred_strong_loss2", ".", "mean", "(", ")", "+", "weak_reliability1", "*", "pred_weak_loss2", ".", "mean", "(", ")", "\n", "meters", ".", "update", "(", "'Expectation of predict loss1'", ",", "expect_loss1", ".", "item", "(", ")", ")", "\n", "meters", ".", "update", "(", "'Expectation of predict loss2'", ",", "expect_loss2", ".", "item", "(", ")", ")", "\n", "\n", "loss1", "=", "weak_class_loss1", "+", "strong_class_loss1", "+", "expect_loss1", "\n", "loss2", "=", "weak_class_loss2", "+", "strong_class_loss2", "+", "expect_loss2", "\n", "meters", ".", "update", "(", "'Loss1'", ",", "loss1", ".", "item", "(", ")", ")", "\n", "meters", ".", "update", "(", "'Loss2'", ",", "loss2", ".", "item", "(", ")", ")", "\n", "\n", "if", "(", "np", ".", "isnan", "(", "loss1", ".", "item", "(", ")", ")", "or", "loss1", ".", "item", "(", ")", ">", "1e5", ")", ":", "\n", "            ", "print", "(", "loss1", ")", "\n", "print", "(", "loss2", ")", "\n", "", "else", ":", "\n", "# compute gradient and do optimizer step", "\n", "            ", "optimizer1", ".", "zero_grad", "(", ")", "\n", "loss1", ".", "backward", "(", ")", "\n", "optimizer1", ".", "step", "(", ")", "\n", "\n", "optimizer2", ".", "zero_grad", "(", ")", "\n", "loss2", ".", "backward", "(", ")", "\n", "optimizer2", ".", "step", "(", ")", "\n", "\n", "global_step", "+=", "1", "\n", "if", "ema_model1", "is", "not", "None", ":", "\n", "                ", "update_ema_variables", "(", "model1", ",", "ema_model1", ",", "0.999", ",", "global_step", ")", "\n", "", "if", "ema_model2", "is", "not", "None", ":", "\n", "                ", "update_ema_variables", "(", "model2", ",", "ema_model2", ",", "0.999", ",", "global_step", ")", "\n", "\n", "", "", "", "epoch_time", "=", "time", ".", "time", "(", ")", "-", "start", "\n", "log", ".", "info", "(", "f\"Epoch: {c_epoch}\\t Time {epoch_time:.2f}\\t {meters}\"", ")", "\n", "return", "loss1", ",", "loss2", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model.get_dfs": [[245, 284], ["utilities.Logger.create_logger", "desed_dataset.initialize_and_get_df", "desed_dataset.initialize_and_get_df", "desed_dataset.initialize_and_get_df", "utilities.Logger.create_logger.debug", "desed_dataset.initialize_and_get_df", "desed_dataset.initialize_and_get_df.filename.drop_duplicates().sample", "desed_dataset.initialize_and_get_df.drop().reset_index", "utilities.Logger.create_logger.debug", "synthetic_df.drop().reset_index.event_label.value_counts", "desed_dataset.initialize_and_get_df.filename.drop_duplicates", "desed_dataset.initialize_and_get_df.filename.isin", "desed_dataset.initialize_and_get_df.drop", "desed_dataset.initialize_and_get_df.head", "inspect.currentframe"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Logger.create_logger", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df"], ["", "def", "get_dfs", "(", "desed_dataset", ",", "nb_files", "=", "None", ",", "separated_sources", "=", "False", ")", ":", "\n", "    ", "log", "=", "create_logger", "(", "__name__", "+", "\"/\"", "+", "inspect", ".", "currentframe", "(", ")", ".", "f_code", ".", "co_name", ",", "terminal_level", "=", "cfg", ".", "terminal_level", ")", "\n", "audio_weak_ss", "=", "None", "\n", "audio_unlabel_ss", "=", "None", "\n", "audio_validation_ss", "=", "None", "\n", "audio_synthetic_ss", "=", "None", "\n", "if", "separated_sources", ":", "\n", "        ", "audio_weak_ss", "=", "cfg", ".", "weak_ss", "\n", "audio_unlabel_ss", "=", "cfg", ".", "unlabel_ss", "\n", "audio_validation_ss", "=", "cfg", ".", "validation_ss", "\n", "audio_synthetic_ss", "=", "cfg", ".", "synthetic_ss", "\n", "\n", "", "weak_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "weak", ",", "audio_dir_ss", "=", "audio_weak_ss", ",", "nb_files", "=", "nb_files", ")", "\n", "unlabel_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "unlabel", ",", "audio_dir_ss", "=", "audio_unlabel_ss", ",", "nb_files", "=", "nb_files", ")", "\n", "# Event if synthetic not used for training, used on validation purpose", "\n", "synthetic_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "synthetic", ",", "audio_dir_ss", "=", "audio_synthetic_ss", ",", "\n", "nb_files", "=", "nb_files", ",", "download", "=", "False", ")", "\n", "log", ".", "debug", "(", "f\"synthetic: {synthetic_df.head()}\"", ")", "\n", "validation_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "validation", ",", "audio_dir", "=", "cfg", ".", "audio_validation_dir", ",", "\n", "audio_dir_ss", "=", "audio_validation_ss", ",", "nb_files", "=", "nb_files", ")", "\n", "# Divide synthetic in train and valid", "\n", "filenames_train", "=", "synthetic_df", ".", "filename", ".", "drop_duplicates", "(", ")", ".", "sample", "(", "frac", "=", "0.8", ",", "random_state", "=", "26", ")", "\n", "train_synth_df", "=", "synthetic_df", "[", "synthetic_df", ".", "filename", ".", "isin", "(", "filenames_train", ")", "]", "\n", "valid_synth_df", "=", "synthetic_df", ".", "drop", "(", "train_synth_df", ".", "index", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "# Put train_synth in frames so many_hot_encoder can work.", "\n", "#  Not doing it for valid, because not using labels (when prediction) and event based metric expect sec.", "\n", "train_synth_df", ".", "onset", "=", "train_synth_df", ".", "onset", "*", "cfg", ".", "sample_rate", "//", "cfg", ".", "hop_size", "//", "pooling_time_ratio", "\n", "train_synth_df", ".", "offset", "=", "train_synth_df", ".", "offset", "*", "cfg", ".", "sample_rate", "//", "cfg", ".", "hop_size", "//", "pooling_time_ratio", "\n", "log", ".", "debug", "(", "valid_synth_df", ".", "event_label", ".", "value_counts", "(", ")", ")", "\n", "\n", "data_dfs", "=", "{", "\"weak\"", ":", "weak_df", ",", "\n", "\"unlabel\"", ":", "unlabel_df", ",", "\n", "\"synthetic\"", ":", "synthetic_df", ",", "\n", "\"train_synthetic\"", ":", "train_synth_df", ",", "\n", "\"valid_synthetic\"", ":", "valid_synth_df", ",", "\n", "\"validation\"", ":", "validation_df", ",", "\n", "}", "\n", "\n", "return", "data_dfs", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_MT_model.adjust_learning_rate": [[31, 49], ["None"], "function", ["None"], ["def", "adjust_learning_rate", "(", "optimizer", ",", "rampup_value", ",", "rampdown_value", "=", "1", ")", ":", "\n", "    ", "\"\"\" adjust the learning rate\n    Args:\n        optimizer: torch.Module, the optimizer to be updated\n        rampup_value: float, the float value between 0 and 1 that should increases linearly\n        rampdown_value: float, the float between 1 and 0 that should decrease linearly\n    Returns:\n\n    \"\"\"", "\n", "# LR warm-up to handle large minibatch sizes from https://arxiv.org/abs/1706.02677", "\n", "# We commented parts on betas and weight decay to match 2nd system of last year from Orange", "\n", "lr", "=", "rampup_value", "*", "rampdown_value", "*", "cfg", ".", "max_learning_rate", "\n", "# beta1 = rampdown_value * cfg.beta1_before_rampdown + (1. - rampdown_value) * cfg.beta1_after_rampdown", "\n", "# beta2 = (1. - rampup_value) * cfg.beta2_during_rampdup + rampup_value * cfg.beta2_after_rampup", "\n", "# weight_decay = (1 - rampup_value) * cfg.weight_decay_during_rampup + cfg.weight_decay_after_rampup * rampup_value", "\n", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "# param_group['betas'] = (beta1, beta2)", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_MT_model.update_ema_variables": [[53, 58], ["min", "zip", "ema_model.parameters", "model.parameters", "ema_params.data.mul_().add_", "ema_params.data.mul_"], "function", ["None"], ["", "", "def", "update_ema_variables", "(", "model", ",", "ema_model", ",", "alpha", ",", "global_step", ")", ":", "\n", "# Use the true average until the exponential average is more correct", "\n", "    ", "alpha", "=", "min", "(", "1", "-", "1", "/", "(", "global_step", "+", "1", ")", ",", "alpha", ")", "\n", "for", "ema_params", ",", "params", "in", "zip", "(", "ema_model", ".", "parameters", "(", ")", ",", "model", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "ema_params", ".", "data", ".", "mul_", "(", "alpha", ")", ".", "add_", "(", "1", "-", "alpha", ",", "params", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_MT_model.train": [[60, 170], ["utilities.Logger.create_logger", "torch.nn.BCELoss", "torch.nn.MSELoss", "utilities.utils.to_cuda_if_available", "utilities.utils.AverageMeterSet", "utilities.Logger.create_logger.debug", "time.time", "enumerate", "utilities.Logger.create_logger.info", "utilities.ramps.exp_rampup", "utilities.utils.AverageMeterSet.update", "utilities.utils.to_cuda_if_available", "ema_model", "strong_pred_ema.detach.detach", "weak_pred_ema.detach.detach", "model", "utilities.utils.AverageMeterSet.update", "optimizer.zero_grad", "loss.backward", "optimizer.step", "time.time", "len", "main_MT_model.adjust_learning_rate", "target.max", "nn.BCELoss.", "nn.BCELoss.", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "nn.BCELoss.", "utilities.utils.AverageMeterSet.update", "nn.BCELoss.", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "loss.item", "loss.item", "main_MT_model.update_ema_variables", "len", "len", "utilities.Logger.create_logger.debug", "class_criterion.item", "class_criterion.item", "class_criterion.item", "class_criterion.item", "nn.BCELoss.", "consistency_loss_strong.item", "nn.BCELoss.", "consistency_loss_weak.item", "numpy.isnan", "loss.item", "inspect.currentframe", "loss.item", "loss.item", "target.mean", "target[].sum", "batch_input.mean"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Logger.create_logger", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.ramps.exp_rampup", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.adjust_learning_rate", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.update_ema_variables", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["", "", "def", "train", "(", "train_loader", ",", "model", ",", "optimizer", ",", "c_epoch", ",", "ema_model", "=", "None", ",", "mask_weak", "=", "None", ",", "mask_strong", "=", "None", ",", "adjust_lr", "=", "False", ")", ":", "\n", "    ", "\"\"\" One epoch of a Mean Teacher model\n    Args:\n        train_loader: torch.utils.data.DataLoader, iterator of training batches for an epoch.\n            Should return a tuple: ((teacher input, student input), labels)\n        model: torch.Module, model to be trained, should return a weak and strong prediction\n        optimizer: torch.Module, optimizer used to train the model\n        c_epoch: int, the current epoch of training\n        ema_model: torch.Module, student model, should return a weak and strong prediction\n        mask_weak: slice or list, mask the batch to get only the weak labeled data (used to calculate the loss)\n        mask_strong: slice or list, mask the batch to get only the strong labeled data (used to calcultate the loss)\n        adjust_lr: bool, Whether or not to adjust the learning rate during training (params in config)\n    \"\"\"", "\n", "log", "=", "create_logger", "(", "__name__", "+", "\"/\"", "+", "inspect", ".", "currentframe", "(", ")", ".", "f_code", ".", "co_name", ",", "terminal_level", "=", "cfg", ".", "terminal_level", ")", "\n", "class_criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "consistency_criterion", "=", "nn", ".", "MSELoss", "(", ")", "\n", "class_criterion", ",", "consistency_criterion", "=", "to_cuda_if_available", "(", "class_criterion", ",", "consistency_criterion", ")", "\n", "\n", "meters", "=", "AverageMeterSet", "(", ")", "\n", "log", ".", "debug", "(", "\"Nb batches: {}\"", ".", "format", "(", "len", "(", "train_loader", ")", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "(", "batch_input", ",", "ema_batch_input", ")", ",", "target", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "        ", "global_step", "=", "c_epoch", "*", "len", "(", "train_loader", ")", "+", "i", "\n", "rampup_value", "=", "ramps", ".", "exp_rampup", "(", "global_step", ",", "cfg", ".", "n_epoch_rampup", "*", "len", "(", "train_loader", ")", ")", "\n", "\n", "if", "adjust_lr", ":", "\n", "            ", "adjust_learning_rate", "(", "optimizer", ",", "rampup_value", ")", "\n", "", "meters", ".", "update", "(", "'lr'", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", "\n", "batch_input", ",", "ema_batch_input", ",", "target", "=", "to_cuda_if_available", "(", "batch_input", ",", "ema_batch_input", ",", "target", ")", "\n", "# Outputs", "\n", "strong_pred_ema", ",", "weak_pred_ema", "=", "ema_model", "(", "ema_batch_input", ")", "\n", "strong_pred_ema", "=", "strong_pred_ema", ".", "detach", "(", ")", "\n", "weak_pred_ema", "=", "weak_pred_ema", ".", "detach", "(", ")", "\n", "strong_pred", ",", "weak_pred", "=", "model", "(", "batch_input", ")", "\n", "\n", "#sample = target[mask_strong].sum(2)", "\n", "#sample = sample.cpu().numpy()", "\n", "#print(np.where(sample[-1,:]>1))", "\n", "\n", "loss", "=", "None", "\n", "# Weak BCE Loss", "\n", "target_weak", "=", "target", ".", "max", "(", "-", "2", ")", "[", "0", "]", "# Take the max in the time axis", "\n", "\n", "if", "mask_weak", "is", "not", "None", ":", "\n", "            ", "weak_class_loss", "=", "class_criterion", "(", "weak_pred", "[", "mask_weak", "]", ",", "target_weak", "[", "mask_weak", "]", ")", "\n", "ema_class_loss", "=", "class_criterion", "(", "weak_pred_ema", "[", "mask_weak", "]", ",", "target_weak", "[", "mask_weak", "]", ")", "\n", "loss", "=", "weak_class_loss", "\n", "\n", "if", "i", "==", "0", ":", "\n", "                ", "log", ".", "debug", "(", "f\"target: {target.mean(-2)} \\n Target_weak: {target_weak} \\n \"", "\n", "f\"Target weak mask: {target_weak[mask_weak]} \\n \"", "\n", "f\"Target strong mask: {target[mask_strong].sum(-2)}\\n\"", "\n", "f\"weak loss: {weak_class_loss} \\t rampup_value: {rampup_value}\"", "\n", "f\"tensor mean: {batch_input.mean()}\"", ")", "\n", "", "meters", ".", "update", "(", "'weak_class_loss'", ",", "weak_class_loss", ".", "item", "(", ")", ")", "\n", "meters", ".", "update", "(", "'Weak EMA loss'", ",", "ema_class_loss", ".", "item", "(", ")", ")", "\n", "\n", "# Strong BCE loss", "\n", "", "if", "mask_strong", "is", "not", "None", ":", "\n", "            ", "strong_class_loss", "=", "class_criterion", "(", "strong_pred", "[", "mask_strong", "]", ",", "target", "[", "mask_strong", "]", ")", "\n", "meters", ".", "update", "(", "'Strong loss'", ",", "strong_class_loss", ".", "item", "(", ")", ")", "\n", "\n", "strong_ema_class_loss", "=", "class_criterion", "(", "strong_pred_ema", "[", "mask_strong", "]", ",", "target", "[", "mask_strong", "]", ")", "\n", "meters", ".", "update", "(", "'Strong EMA loss'", ",", "strong_ema_class_loss", ".", "item", "(", ")", ")", "\n", "\n", "if", "loss", "is", "not", "None", ":", "\n", "                ", "loss", "+=", "strong_class_loss", "\n", "", "else", ":", "\n", "                ", "loss", "=", "strong_class_loss", "\n", "\n", "# Teacher-student consistency cost", "\n", "\n", "", "", "if", "ema_model", "is", "not", "None", ":", "\n", "            ", "consistency_cost", "=", "cfg", ".", "max_consistency_cost", "*", "rampup_value", "\n", "meters", ".", "update", "(", "'Consistency weight'", ",", "consistency_cost", ")", "\n", "# Take consistency about strong predictions (all data)", "\n", "#consistency_loss_strong = consistency_cost * consistency_criterion(strong_pred, strong_pred_ema)", "\n", "consistency_loss_strong", "=", "consistency_cost", "*", "class_criterion", "(", "strong_pred", ",", "strong_pred_ema", ")", "\n", "\n", "meters", ".", "update", "(", "'Consistency strong'", ",", "consistency_loss_strong", ".", "item", "(", ")", ")", "\n", "if", "loss", "is", "not", "None", ":", "\n", "                ", "loss", "+=", "consistency_loss_strong", "\n", "", "else", ":", "\n", "                ", "loss", "=", "consistency_loss_strong", "\n", "", "meters", ".", "update", "(", "'Consistency weight'", ",", "consistency_cost", ")", "\n", "# Take consistency about weak predictions (all data)", "\n", "#consistency_loss_weak = consistency_cost * consistency_criterion(weak_pred, weak_pred_ema)", "\n", "consistency_loss_weak", "=", "consistency_cost", "*", "class_criterion", "(", "weak_pred", ",", "weak_pred_ema", ")", "\n", "\n", "meters", ".", "update", "(", "'Consistency weak'", ",", "consistency_loss_weak", ".", "item", "(", ")", ")", "\n", "if", "loss", "is", "not", "None", ":", "\n", "                ", "loss", "+=", "consistency_loss_weak", "\n", "", "else", ":", "\n", "                ", "loss", "=", "consistency_loss_weak", "\n", "\n", "", "", "assert", "not", "(", "np", ".", "isnan", "(", "loss", ".", "item", "(", ")", ")", "or", "loss", ".", "item", "(", ")", ">", "1e5", ")", ",", "'Loss explosion: {}'", ".", "format", "(", "loss", ".", "item", "(", ")", ")", "\n", "assert", "not", "loss", ".", "item", "(", ")", "<", "0", ",", "'Loss problem, cannot be negative'", "\n", "meters", ".", "update", "(", "'Loss'", ",", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# compute gradient and do optimizer step", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "global_step", "+=", "1", "\n", "if", "ema_model", "is", "not", "None", ":", "\n", "            ", "update_ema_variables", "(", "model", ",", "ema_model", ",", "0.999", ",", "global_step", ")", "\n", "\n", "", "", "epoch_time", "=", "time", ".", "time", "(", ")", "-", "start", "\n", "log", ".", "info", "(", "f\"Epoch: {c_epoch}\\t Time {epoch_time:.2f}\\t {meters}\"", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_MT_model.get_dfs": [[172, 211], ["utilities.Logger.create_logger", "desed_dataset.initialize_and_get_df", "desed_dataset.initialize_and_get_df", "desed_dataset.initialize_and_get_df", "utilities.Logger.create_logger.debug", "desed_dataset.initialize_and_get_df", "desed_dataset.initialize_and_get_df.filename.drop_duplicates().sample", "desed_dataset.initialize_and_get_df.drop().reset_index", "utilities.Logger.create_logger.debug", "synthetic_df.drop().reset_index.event_label.value_counts", "desed_dataset.initialize_and_get_df.filename.drop_duplicates", "desed_dataset.initialize_and_get_df.filename.isin", "desed_dataset.initialize_and_get_df.drop", "desed_dataset.initialize_and_get_df.head", "inspect.currentframe"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Logger.create_logger", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df"], ["", "def", "get_dfs", "(", "desed_dataset", ",", "nb_files", "=", "None", ",", "separated_sources", "=", "False", ")", ":", "\n", "    ", "log", "=", "create_logger", "(", "__name__", "+", "\"/\"", "+", "inspect", ".", "currentframe", "(", ")", ".", "f_code", ".", "co_name", ",", "terminal_level", "=", "cfg", ".", "terminal_level", ")", "\n", "audio_weak_ss", "=", "None", "\n", "audio_unlabel_ss", "=", "None", "\n", "audio_validation_ss", "=", "None", "\n", "audio_synthetic_ss", "=", "None", "\n", "if", "separated_sources", ":", "\n", "        ", "audio_weak_ss", "=", "cfg", ".", "weak_ss", "\n", "audio_unlabel_ss", "=", "cfg", ".", "unlabel_ss", "\n", "audio_validation_ss", "=", "cfg", ".", "validation_ss", "\n", "audio_synthetic_ss", "=", "cfg", ".", "synthetic_ss", "\n", "\n", "", "weak_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "weak", ",", "audio_dir_ss", "=", "audio_weak_ss", ",", "nb_files", "=", "nb_files", ")", "\n", "unlabel_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "unlabel", ",", "audio_dir_ss", "=", "audio_unlabel_ss", ",", "nb_files", "=", "nb_files", ")", "\n", "# Event if synthetic not used for training, used on validation purpose", "\n", "synthetic_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "synthetic", ",", "audio_dir_ss", "=", "audio_synthetic_ss", ",", "\n", "nb_files", "=", "nb_files", ",", "download", "=", "False", ")", "\n", "log", ".", "debug", "(", "f\"synthetic: {synthetic_df.head()}\"", ")", "\n", "validation_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "validation", ",", "audio_dir", "=", "cfg", ".", "audio_validation_dir", ",", "\n", "audio_dir_ss", "=", "audio_validation_ss", ",", "nb_files", "=", "nb_files", ")", "\n", "# Divide synthetic in train and valid", "\n", "filenames_train", "=", "synthetic_df", ".", "filename", ".", "drop_duplicates", "(", ")", ".", "sample", "(", "frac", "=", "0.8", ",", "random_state", "=", "26", ")", "\n", "train_synth_df", "=", "synthetic_df", "[", "synthetic_df", ".", "filename", ".", "isin", "(", "filenames_train", ")", "]", "\n", "valid_synth_df", "=", "synthetic_df", ".", "drop", "(", "train_synth_df", ".", "index", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "# Put train_synth in frames so many_hot_encoder can work.", "\n", "#  Not doing it for valid, because not using labels (when prediction) and event based metric expect sec.", "\n", "train_synth_df", ".", "onset", "=", "train_synth_df", ".", "onset", "*", "cfg", ".", "sample_rate", "//", "cfg", ".", "hop_size", "//", "pooling_time_ratio", "\n", "train_synth_df", ".", "offset", "=", "train_synth_df", ".", "offset", "*", "cfg", ".", "sample_rate", "//", "cfg", ".", "hop_size", "//", "pooling_time_ratio", "\n", "log", ".", "debug", "(", "valid_synth_df", ".", "event_label", ".", "value_counts", "(", ")", ")", "\n", "\n", "data_dfs", "=", "{", "\"weak\"", ":", "weak_df", ",", "\n", "\"unlabel\"", ":", "unlabel_df", ",", "\n", "\"synthetic\"", ":", "synthetic_df", ",", "\n", "\"train_synthetic\"", ":", "train_synth_df", ",", "\n", "\"valid_synthetic\"", ":", "valid_synth_df", ",", "\n", "\"validation\"", ":", "validation_df", ",", "\n", "}", "\n", "\n", "return", "data_dfs", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel._load_model": [[28, 45], ["models.Conformer_bk.Conformer.load_state_dict", "models.Conformer_bk.Conformer.eval", "utilities.utils.to_cuda_if_available", "logger.info", "logger.info", "models.CRNN.CRNN", "models.Transformer.Transformer", "models.Conformer_bk.Conformer"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available"], ["def", "_load_model", "(", "state", ",", "model_type", ",", "model_name", "=", "\"model\"", ")", ":", "\n", "    ", "model_args", "=", "state", "[", "model_name", "]", "[", "\"args\"", "]", "\n", "model_kwargs", "=", "state", "[", "model_name", "]", "[", "\"kwargs\"", "]", "\n", "\n", "if", "model_type", "is", "'crnn'", ":", "\n", "        ", "model", "=", "CRNN", "(", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "", "elif", "model_type", "is", "'transformer'", ":", "\n", "        ", "model", "=", "Transformer", "(", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "", "elif", "model_type", "is", "'conformer'", ":", "\n", "        ", "model", "=", "Conformer", "(", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "\n", "", "model", ".", "load_state_dict", "(", "state", "[", "model_name", "]", "[", "\"state_dict\"", "]", ")", "\n", "model", ".", "eval", "(", ")", "\n", "model", "=", "to_cuda_if_available", "(", "model", ")", "\n", "logger", ".", "info", "(", "\"Model loaded at epoch: {}\"", ".", "format", "(", "state", "[", "\"epoch\"", "]", ")", ")", "\n", "logger", ".", "info", "(", "model", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel._load_model_v2": [[47, 67], ["models.Conformer_bk.Conformer.eval", "utilities.utils.to_cuda_if_available", "logger.info", "logger.info", "models.CRNN.CRNN", "models.Conformer_bk.Conformer.load_state_dict", "models.Transformer.Transformer", "models.Conformer_bk.Conformer.load_state_dict", "models.Conformer_bk.Conformer"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict"], ["", "def", "_load_model_v2", "(", "state", ",", "model_id", ",", "model_type", ",", "model_name", "=", "\"model\"", ")", ":", "\n", "    ", "model_args", "=", "state", "[", "model_name", "]", "[", "\"args\"", "]", "\n", "model_kwargs", "=", "state", "[", "model_name", "]", "[", "\"kwargs\"", "]", "\n", "\n", "if", "model_type", "is", "'crnn'", ":", "\n", "        ", "model", "=", "CRNN", "(", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "", "elif", "model_type", "is", "'transformer'", ":", "\n", "        ", "model", "=", "Transformer", "(", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "", "elif", "model_type", "is", "'conformer'", ":", "\n", "        ", "model", "=", "Conformer", "(", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "\n", "", "if", "model_id", "==", "1", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "state", "[", "model_name", "]", "[", "\"state_dict1\"", "]", ")", "\n", "", "elif", "model_id", "==", "2", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "state", "[", "model_name", "]", "[", "\"state_dict2\"", "]", ")", "\n", "", "model", ".", "eval", "(", ")", "\n", "model", "=", "to_cuda_if_available", "(", "model", ")", "\n", "logger", ".", "info", "(", "\"Model loaded at epoch: {}\"", ".", "format", "(", "state", "[", "\"epoch\"", "]", ")", ")", "\n", "logger", ".", "info", "(", "model", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel._load_scaler": [[69, 80], ["utilities.Scaler.Scaler.load_state_dict", "utilities.Scaler.ScalerPerAudio", "utilities.Scaler.Scaler", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict"], ["", "def", "_load_scaler", "(", "state", ")", ":", "\n", "    ", "scaler_state", "=", "state", "[", "\"scaler\"", "]", "\n", "type_sc", "=", "scaler_state", "[", "\"type\"", "]", "\n", "if", "type_sc", "==", "\"ScalerPerAudio\"", ":", "\n", "        ", "scaler", "=", "ScalerPerAudio", "(", "*", "scaler_state", "[", "\"args\"", "]", ")", "\n", "", "elif", "type_sc", "==", "\"Scaler\"", ":", "\n", "        ", "scaler", "=", "Scaler", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Not the right type of Scaler has been saved in state\"", ")", "\n", "", "scaler", ".", "load_state_dict", "(", "state", "[", "\"scaler\"", "]", "[", "\"state_dict\"", "]", ")", "\n", "return", "scaler", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel._load_state_vars": [[82, 103], ["gtruth_df.copy", "utilities.ManyHotEncoder.ManyHotEncoder.load_state_dict", "TestModel._load_scaler", "TestModel._load_model", "utilities.Transforms.get_transforms", "data_utils.DataLoad.DataLoadDf", "torch.utils.data.DataLoader", "utilities.ManyHotEncoder.ManyHotEncoder.load_state_dict"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_dual._load_scaler", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_dual._load_model", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.get_transforms", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict"], ["", "def", "_load_state_vars", "(", "state", ",", "gtruth_df", ",", "median_win", "=", "None", ")", ":", "\n", "    ", "pred_df", "=", "gtruth_df", ".", "copy", "(", ")", "\n", "# Define dataloader", "\n", "many_hot_encoder", "=", "ManyHotEncoder", ".", "load_state_dict", "(", "state", "[", "\"many_hot_encoder\"", "]", ")", "\n", "scaler", "=", "_load_scaler", "(", "state", ")", "\n", "model", "=", "_load_model", "(", "state", ",", "'crnn'", ")", "\n", "transforms_valid", "=", "get_transforms", "(", "cfg", ".", "max_frames", ",", "scaler", "=", "scaler", ",", "add_axis", "=", "0", ")", "\n", "\n", "strong_dataload", "=", "DataLoadDf", "(", "pred_df", ",", "many_hot_encoder", ".", "encode_strong_df", ",", "transforms_valid", ",", "return_indexes", "=", "True", ")", "\n", "strong_dataloader_ind", "=", "DataLoader", "(", "strong_dataload", ",", "batch_size", "=", "cfg", ".", "batch_size", ",", "drop_last", "=", "False", ")", "\n", "\n", "pooling_time_ratio", "=", "state", "[", "\"pooling_time_ratio\"", "]", "\n", "many_hot_encoder", "=", "ManyHotEncoder", ".", "load_state_dict", "(", "state", "[", "\"many_hot_encoder\"", "]", ")", "\n", "if", "median_win", "is", "None", ":", "\n", "        ", "median_win", "=", "state", "[", "\"median_window\"", "]", "\n", "", "return", "{", "\n", "\"model\"", ":", "model", ",", "\n", "\"dataloader\"", ":", "strong_dataloader_ind", ",", "\n", "\"pooling_time_ratio\"", ":", "pooling_time_ratio", ",", "\n", "\"many_hot_encoder\"", ":", "many_hot_encoder", ",", "\n", "\"median_window\"", ":", "median_win", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel.get_variables": [[106, 131], ["os.splitext", "pandas.read_csv", "os.exists", "utilities.utils.meta_path_to_audio_dir", "pandas.read_csv", "utilities.utils.generate_tsv_wav_durations", "os.dirname", "len", "utilities.utils.generate_tsv_wav_durations"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.meta_path_to_audio_dir", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.generate_tsv_wav_durations", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.generate_tsv_wav_durations"], ["", "def", "get_variables", "(", "args", ")", ":", "\n", "    ", "model_pth", "=", "args", ".", "model_path", "\n", "gt_fname", ",", "ext", "=", "osp", ".", "splitext", "(", "args", ".", "groundtruth_tsv", ")", "\n", "median_win", "=", "args", ".", "median_window", "\n", "meta_gt", "=", "args", ".", "meta_gt", "\n", "gt_audio_pth", "=", "args", ".", "groundtruth_audio_dir", "\n", "\n", "if", "meta_gt", "is", "None", ":", "\n", "        ", "meta_gt", "=", "gt_fname", "+", "\"_durations\"", "+", "ext", "\n", "\n", "", "if", "gt_audio_pth", "is", "None", ":", "\n", "        ", "gt_audio_pth", "=", "meta_path_to_audio_dir", "(", "gt_fname", ")", "\n", "# Useful because of the data format", "\n", "if", "\"validation\"", "in", "gt_audio_pth", ":", "\n", "            ", "gt_audio_pth", "=", "osp", ".", "dirname", "(", "gt_audio_pth", ")", "\n", "\n", "", "", "groundtruth", "=", "pd", ".", "read_csv", "(", "args", ".", "groundtruth_tsv", ",", "sep", "=", "\"\\t\"", ")", "\n", "if", "osp", ".", "exists", "(", "meta_gt", ")", ":", "\n", "        ", "meta_dur_df", "=", "pd", ".", "read_csv", "(", "meta_gt", ",", "sep", "=", "'\\t'", ")", "\n", "if", "len", "(", "meta_dur_df", ")", "==", "0", ":", "\n", "            ", "meta_dur_df", "=", "generate_tsv_wav_durations", "(", "gt_audio_pth", ",", "meta_gt", ")", "\n", "", "", "else", ":", "\n", "        ", "meta_dur_df", "=", "generate_tsv_wav_durations", "(", "gt_audio_pth", ",", "meta_gt", ")", "\n", "\n", "", "return", "model_pth", ",", "median_win", ",", "gt_audio_pth", ",", "groundtruth", ",", "meta_dur_df", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.adjust_learning_rate": [[31, 49], ["None"], "function", ["None"], ["def", "adjust_learning_rate", "(", "optimizer", ",", "rampup_value", ",", "rampdown_value", "=", "1", ")", ":", "\n", "    ", "\"\"\" adjust the learning rate\n    Args:\n        optimizer: torch.Module, the optimizer to be updated\n        rampup_value: float, the float value between 0 and 1 that should increases linearly\n        rampdown_value: float, the float between 1 and 0 that should decrease linearly\n    Returns:\n\n    \"\"\"", "\n", "#LR warm-up to handle large minibatch sizes from https://arxiv.org/abs/1706.02677", "\n", "#We commented parts on betas and weight decay to match 2nd system of last year from Orange", "\n", "lr", "=", "rampup_value", "*", "rampdown_value", "*", "cfg", ".", "max_learning_rate", "\n", "# beta1 = rampdown_value * cfg.beta1_before_rampdown + (1. - rampdown_value) * cfg.beta1_after_rampdown", "\n", "# beta2 = (1. - rampup_value) * cfg.beta2_during_rampdup + rampup_value * cfg.beta2_after_rampup", "\n", "# weight_decay = (1 - rampup_value) * cfg.weight_decay_during_rampup + cfg.weight_decay_after_rampup * rampup_value", "\n", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "# param_group['betas'] = (beta1, beta2)", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.update_ema_variables": [[53, 58], ["min", "zip", "ema_model.parameters", "model.parameters", "ema_params.data.mul_().add_", "ema_params.data.mul_"], "function", ["None"], ["", "", "def", "update_ema_variables", "(", "model", ",", "ema_model", ",", "alpha", ",", "global_step", ")", ":", "\n", "# Use the true average until the exponential average is more correct", "\n", "    ", "alpha", "=", "min", "(", "1", "-", "1", "/", "(", "global_step", "+", "1", ")", ",", "alpha", ")", "\n", "for", "ema_params", ",", "params", "in", "zip", "(", "ema_model", ".", "parameters", "(", ")", ",", "model", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "ema_params", ".", "data", ".", "mul_", "(", "alpha", ")", ".", "add_", "(", "1", "-", "alpha", ",", "params", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.train": [[60, 246], ["utilities.Logger.create_logger", "torch.nn.BCELoss", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss", "utilities.utils.JSD", "torch.nn.Softmax", "torch.tensor().cuda", "utilities.utils.to_cuda_if_available", "utilities.utils.AverageMeterSet", "utilities.Logger.create_logger.debug", "time.time", "enumerate", "utilities.Logger.create_logger.info", "utilities.ramps.exp_rampup", "utilities.utils.AverageMeterSet.update", "target2.type.type", "utilities.utils.to_cuda_if_available", "model1", "ema_model1", "strong_predict1.detach.detach", "weak_predict1.detach.detach", "model2", "ema_model2", "strong_predict2.detach.detach", "weak_predict2.detach.detach", "int", "torch.zeros().cuda", "torch.zeros().cuda", "range", "torch.zeros().cuda.mean", "torch.zeros().cuda.mean", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "nn.MSELoss.mean", "nn.MSELoss.mean", "nn.MSELoss.mean", "nn.MSELoss.mean", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "time.time", "torch.tensor", "len", "main_CRST_model_v2.adjust_learning_rate", "main_CRST_model_v2.adjust_learning_rate", "target.max", "target2.type.max", "nn.BCELoss.mean", "nn.BCELoss.mean", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "nn.BCELoss.mean", "nn.BCELoss.mean", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "utilities.utils.AverageMeterSet.update", "torch.clamp", "torch.log", "torch.log", "torch.clamp", "torch.log", "torch.log", "torch.cat", "torch.cat", "torch.cat.sum", "range", "torch.cat", "torch.cat", "nn.Softmax.", "torch.sort", "prob_v.sum", "torch.mul().sum", "torch.squeeze", "torch.squeeze", "strong_reliability1.item", "strong_reliability2.item", "expect_loss1.item", "expect_loss2.item", "loss1.item", "loss2.item", "numpy.isnan", "print", "print", "optimizer1.zero_grad", "loss1.backward", "optimizer1.step", "optimizer2.zero_grad", "loss2.backward", "optimizer2.step", "len", "len", "utilities.Logger.create_logger.debug", "class_criterion().mean.item", "class_criterion().mean.item", "class_criterion().mean.item", "class_criterion().mean.item", "torch.zeros", "torch.zeros", "torch.cat.append", "utilities.utils.JSD.apply().mean", "utilities.utils.JSD.apply().mean", "utilities.utils.JSD.apply().mean", "utilities.utils.JSD.apply().mean", "nn.MSELoss.", "nn.MSELoss.", "nn.MSELoss.", "nn.MSELoss.", "mse_criterion().mean.mean", "mse_criterion().mean.mean", "mse_criterion().mean.mean", "mse_criterion().mean.mean", "loss1.item", "loss1.item", "main_CRST_model_v2.update_ema_variables", "main_CRST_model_v2.update_ema_variables", "inspect.currentframe", "nn.BCELoss.", "nn.BCELoss.", "nn.BCELoss.", "nn.BCELoss.", "p_h0.sum.reshape", "torch.mul", "prob_i.tolist", "utilities.utils.JSD.apply", "utilities.utils.JSD.apply", "utilities.utils.JSD.apply", "utilities.utils.JSD.apply", "target.mean", "target[].sum", "batch_input.mean"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Logger.create_logger", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.ramps.exp_rampup", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.adjust_learning_rate", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.adjust_learning_rate", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.update_ema_variables", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.update_ema_variables", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.EarlyStopping.apply", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.EarlyStopping.apply", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.EarlyStopping.apply", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.EarlyStopping.apply", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["", "", "def", "train", "(", "train_loader", ",", "model1", ",", "model2", ",", "optimizer1", ",", "optimizer2", ",", "c_epoch", ",", "ema_model1", "=", "None", ",", "ema_model2", "=", "None", ",", "mask_weak", "=", "None", ",", "mask_strong", "=", "None", ",", "adjust_lr", "=", "False", ")", ":", "\n", "    ", "\"\"\" One epoch of a Mean Teacher model\n    Args:\n        train_loader: torch.utils.data.DataLoader, iterator of training batches for an epoch.\n            Should return a tuple: ((teacher input, student input), labels)\n        model: torch.Module, model to be trained, should return a weak and strong prediction\n        optimizer: torch.Module, optimizer used to train the model\n        c_epoch: int, the current epoch of training\n        ema_model: torch.Module, student model, should return a weak and strong prediction\n        mask_weak: slice or list, mask the batch to get only the weak labeled data (used to calculate the loss)\n        mask_strong: slice or list, mask the batch to get only the strong labeled data (used to calcultate the loss)\n        adjust_lr: bool, Whether or not to adjust the learning rate during training (params in config)\n    \"\"\"", "\n", "\n", "log", "=", "create_logger", "(", "__name__", "+", "\"/\"", "+", "inspect", ".", "currentframe", "(", ")", ".", "f_code", ".", "co_name", ",", "terminal_level", "=", "cfg", ".", "terminal_level", ")", "\n", "class_criterion", "=", "nn", ".", "BCELoss", "(", "reduction", "=", "'none'", ")", "\n", "mse_criterion", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "'none'", ")", "\n", "reliability_criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "jsd", "=", "JSD", "(", ")", "\n", "\n", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "\n", "class_label", "=", "torch", ".", "tensor", "(", "cfg", ".", "class_label", ")", ".", "cuda", "(", ")", "\n", "class_criterion", ",", "mse_criterion", ",", "softmax", "=", "to_cuda_if_available", "(", "class_criterion", ",", "mse_criterion", ",", "softmax", ")", "\n", "\n", "meters", "=", "AverageMeterSet", "(", ")", "\n", "log", ".", "debug", "(", "\"Nb batches: {}\"", ".", "format", "(", "len", "(", "train_loader", ")", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "#plabel = []", "\n", "for", "i", ",", "(", "(", "(", "batch_input", ",", "batch_input_ema", ")", ",", "target2", ")", ",", "target", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "        ", "global_step", "=", "c_epoch", "*", "len", "(", "train_loader", ")", "+", "i", "\n", "rampup_value", "=", "ramps", ".", "exp_rampup", "(", "global_step", ",", "cfg", ".", "n_epoch_rampup2", "*", "len", "(", "train_loader", ")", ")", "\n", "\n", "if", "adjust_lr", ":", "\n", "            ", "adjust_learning_rate", "(", "optimizer1", ",", "rampup_value", ",", "rampdown_value", "=", "1.0", ")", "\n", "adjust_learning_rate", "(", "optimizer2", ",", "rampup_value", ",", "rampdown_value", "=", "0.9", ")", "\n", "", "meters", ".", "update", "(", "'lr'", ",", "optimizer1", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", "\n", "target2", "=", "target2", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "batch_input", ",", "batch_input_ema", ",", "target", ",", "target2", "=", "to_cuda_if_available", "(", "batch_input", ",", "batch_input_ema", ",", "target", ",", "target2", ")", "\n", "\n", "# Outputs", "\n", "strong_pred1", ",", "weak_pred1", "=", "model1", "(", "batch_input", ")", "\n", "strong_predict1", ",", "weak_predict1", "=", "ema_model1", "(", "batch_input_ema", ")", "\n", "strong_predict1", "=", "strong_predict1", ".", "detach", "(", ")", "\n", "weak_predict1", "=", "weak_predict1", ".", "detach", "(", ")", "\n", "\n", "# data augmentation    ", "\n", "strong_pred2", ",", "weak_pred2", "=", "model2", "(", "batch_input_ema", ")", "\n", "strong_predict2", ",", "weak_predict2", "=", "ema_model2", "(", "batch_input", ")", "\n", "strong_predict2", "=", "strong_predict2", ".", "detach", "(", ")", "\n", "weak_predict2", "=", "weak_predict2", ".", "detach", "(", ")", "\n", "\n", "# Weak BCE Loss", "\n", "target_weak", "=", "target", ".", "max", "(", "-", "2", ")", "[", "0", "]", "# Take the max in the time axis", "\n", "target2_weak", "=", "target2", ".", "max", "(", "-", "2", ")", "[", "0", "]", "\n", "if", "mask_weak", "is", "not", "None", ":", "\n", "            ", "weak_class_loss1", "=", "class_criterion", "(", "weak_pred1", "[", "mask_weak", "]", ",", "target_weak", "[", "mask_weak", "]", ")", ".", "mean", "(", ")", "\n", "weak_class_loss2", "=", "class_criterion", "(", "weak_pred2", "[", "mask_weak", "]", ",", "target2_weak", "[", "mask_weak", "]", ")", ".", "mean", "(", ")", "\n", "\n", "if", "i", "==", "0", ":", "\n", "                ", "log", ".", "debug", "(", "f\"target: {target.mean(-2)} \\n Target_weak: {target_weak} \\n \"", "\n", "f\"Target weak mask: {target_weak[mask_weak]} \\n \"", "\n", "f\"Target strong mask: {target[mask_strong].sum(-2)}\\n\"", "\n", "f\"weak loss1: {weak_class_loss1} \\t rampup_value: {rampup_value}\"", "\n", "f\"weak loss2: {weak_class_loss2} \\t rampup_value: {rampup_value}\"", "\n", "f\"tensor mean: {batch_input.mean()}\"", ")", "\n", "", "meters", ".", "update", "(", "'weak_class_loss1'", ",", "weak_class_loss1", ".", "item", "(", ")", ")", "\n", "meters", ".", "update", "(", "'weak_class_loss2'", ",", "weak_class_loss2", ".", "item", "(", ")", ")", "\n", "\n", "# Strong BCE loss", "\n", "", "if", "mask_strong", "is", "not", "None", ":", "\n", "            ", "strong_class_loss1", "=", "class_criterion", "(", "strong_pred1", "[", "mask_strong", "]", ",", "target", "[", "mask_strong", "]", ")", ".", "mean", "(", ")", "\n", "strong_class_loss2", "=", "class_criterion", "(", "strong_pred2", "[", "mask_strong", "]", ",", "target2", "[", "mask_strong", "]", ")", ".", "mean", "(", ")", "\n", "meters", ".", "update", "(", "'Strong loss1'", ",", "strong_class_loss1", ".", "item", "(", ")", ")", "\n", "meters", ".", "update", "(", "'Strong loss2'", ",", "strong_class_loss2", ".", "item", "(", ")", ")", "\n", "\n", "# Teacher-student consistency cost", "\n", "", "if", "ema_model1", "is", "not", "None", ":", "\n", "            ", "rampup_weight", "=", "cfg", ".", "max_rampup_weight", "*", "rampup_value", "\n", "meters", ".", "update", "(", "'Rampup weight'", ",", "rampup_weight", ")", "\n", "\n", "\n", "# Self-labeling", "\n", "", "n_unlabeled", "=", "int", "(", "3", "*", "cfg", ".", "batch_size", "/", "4", ")", "\n", "est_strong_target1", "=", "torch", ".", "zeros", "(", "cfg", ".", "batch_size", ",", "157", ",", "cfg", ".", "nClass", ")", ".", "cuda", "(", ")", "\n", "est_strong_target2", "=", "torch", ".", "zeros", "(", "cfg", ".", "batch_size", ",", "157", ",", "cfg", ".", "nClass", ")", ".", "cuda", "(", ")", "\n", "for", "bter", "in", "range", "(", "cfg", ".", "batch_size", ")", ":", "\n", "            ", "sp1", "=", "strong_predict1", "[", "bter", "]", "\n", "sp1", "=", "torch", ".", "clamp", "(", "sp1", ",", "1.0e-4", ",", "1", "-", "1.0e-4", ")", "\n", "p1_h1", "=", "torch", ".", "log", "(", "sp1", ")", "\n", "p1_h0", "=", "torch", ".", "log", "(", "1", "-", "sp1", ")", "\n", "\n", "sp2", "=", "strong_predict2", "[", "bter", "]", "\n", "sp2", "=", "torch", ".", "clamp", "(", "sp2", ",", "1.0e-4", ",", "1", "-", "1.0e-4", ")", "\n", "p2_h1", "=", "torch", ".", "log", "(", "sp2", ")", "\n", "p2_h0", "=", "torch", ".", "log", "(", "1", "-", "sp2", ")", "\n", "\n", "p_h0", "=", "torch", ".", "cat", "(", "(", "p1_h0", ",", "p2_h0", ")", ",", "0", ")", "\n", "p_h1", "=", "torch", ".", "cat", "(", "(", "p1_h1", ",", "p2_h1", ")", ",", "0", ")", "\n", "\n", "# K = 0", "\n", "P0", "=", "p_h0", ".", "sum", "(", "1", ")", "\n", "\n", "# K = 1", "\n", "P1", "=", "P0", "[", ":", ",", "None", "]", "+", "p_h1", "-", "p_h0", "\n", "#P  = torch.cat([P0.reshape(157,1), P1], 1)", "\n", "\n", "# K = 2", "\n", "P2", "=", "[", "]", "\n", "for", "cter", "in", "range", "(", "1", ",", "cfg", ".", "nClass", ")", ":", "\n", "                ", "P2", ".", "append", "(", "P1", "[", ":", ",", ":", "-", "cter", "]", "+", "P1", "[", ":", ",", "cter", ":", "]", ")", "\n", "", "P2", "=", "torch", ".", "cat", "(", "P2", ",", "1", ")", "\n", "P2", "=", "P2", "-", "P0", "[", ":", ",", "None", "]", "\n", "P", "=", "torch", ".", "cat", "(", "[", "P0", ".", "reshape", "(", "157", "*", "2", ",", "1", ")", ",", "P1", ",", "P2", "]", ",", "1", ")", "\n", "\n", "# K: up to 3", "\n", "#P3 = []", "\n", "#for cter1 in range(1,cfg.nClass):", "\n", "#    for cter2 in range(1, cfg.nClass-cter1):", "\n", "#        P3.append(P1[:,:-(cter1+cter2)]+P1[:,cter1:-cter2]+P1[:,(cter1+cter2):])", "\n", "#P3 = torch.cat(P3,1)", "\n", "#P3 = P3 - 2*P0[:,None]", "\n", "#P  = torch.cat([P0.reshape(157,1), P1, P2, P3], 1)", "\n", "\n", "P", "=", "softmax", "(", "P", ")", "\n", "prob_v", ",", "prob_i", "=", "torch", ".", "sort", "(", "P", ",", "dim", "=", "1", ",", "descending", "=", "True", ")", "\n", "\n", "norm_p", "=", "prob_v", ".", "sum", "(", "1", ")", "\n", "prob_v", "=", "prob_v", "/", "norm_p", "[", ":", ",", "None", "]", "\n", "\n", "cl", "=", "class_label", "[", "prob_i", ".", "tolist", "(", ")", ",", ":", "]", "\n", "cl", "=", "torch", ".", "mul", "(", "cl", ",", "prob_v", "[", ":", ",", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", "\n", "\n", "est_strong_target1", "[", "bter", ",", ":", ",", ":", "]", "=", "torch", ".", "squeeze", "(", "cl", "[", ":", "157", ",", ":", "]", ")", "\n", "est_strong_target2", "[", "bter", ",", ":", ",", ":", "]", "=", "torch", ".", "squeeze", "(", "cl", "[", "157", ":", ",", ":", "]", ")", "\n", "\n", "", "est_weak_target1", "=", "est_strong_target1", ".", "mean", "(", "1", ")", "\n", "est_weak_target2", "=", "est_strong_target2", ".", "mean", "(", "1", ")", "\n", "\n", "strong_reliability1", "=", "rampup_weight", "*", "(", "1", "-", "jsd", ".", "apply", "(", "est_strong_target1", "[", "mask_strong", "]", ",", "target2", "[", "mask_strong", "]", ")", ".", "mean", "(", ")", ")", "\n", "strong_reliability2", "=", "rampup_weight", "*", "(", "1", "-", "jsd", ".", "apply", "(", "est_strong_target2", "[", "mask_strong", "]", ",", "target", "[", "mask_strong", "]", ")", ".", "mean", "(", ")", ")", "\n", "weak_reliability1", "=", "rampup_weight", "*", "(", "1", "-", "jsd", ".", "apply", "(", "est_weak_target1", "[", "mask_weak", "]", ",", "target2_weak", "[", "mask_weak", "]", ")", ".", "mean", "(", ")", ")", "\n", "weak_reliability2", "=", "rampup_weight", "*", "(", "1", "-", "jsd", ".", "apply", "(", "est_weak_target2", "[", "mask_weak", "]", ",", "target_weak", "[", "mask_weak", "]", ")", ".", "mean", "(", ")", ")", "\n", "\n", "meters", ".", "update", "(", "'Reliability of pseudo label1'", ",", "strong_reliability1", ".", "item", "(", ")", ")", "\n", "meters", ".", "update", "(", "'Reliability of pseudo label2'", ",", "strong_reliability2", ".", "item", "(", ")", ")", "\n", "\n", "# classification error with pseudo label", "\n", "pred_strong_loss1", "=", "mse_criterion", "(", "strong_pred1", "[", "6", ":", "n_unlabeled", "]", ",", "est_strong_target2", "[", "6", ":", "n_unlabeled", "]", ")", ".", "mean", "(", "[", "1", ",", "2", "]", ")", "\n", "pred_weak_loss1", "=", "mse_criterion", "(", "strong_pred1", "[", "mask_weak", "]", ",", "est_strong_target2", "[", "mask_weak", "]", ")", ".", "mean", "(", "[", "1", ",", "2", "]", ")", "\n", "pred_strong_loss2", "=", "mse_criterion", "(", "strong_pred2", "[", "6", ":", "n_unlabeled", "]", ",", "est_strong_target1", "[", "6", ":", "n_unlabeled", "]", ")", ".", "mean", "(", "[", "1", ",", "2", "]", ")", "\n", "pred_weak_loss2", "=", "mse_criterion", "(", "strong_pred2", "[", "mask_weak", "]", ",", "est_strong_target1", "[", "mask_weak", "]", ")", ".", "mean", "(", "[", "1", ",", "2", "]", ")", "\n", "\n", "expect_loss1", "=", "strong_reliability2", "*", "pred_strong_loss1", ".", "mean", "(", ")", "+", "weak_reliability2", "*", "pred_weak_loss1", ".", "mean", "(", ")", "\n", "expect_loss2", "=", "strong_reliability1", "*", "pred_strong_loss2", ".", "mean", "(", ")", "+", "weak_reliability1", "*", "pred_weak_loss2", ".", "mean", "(", ")", "\n", "meters", ".", "update", "(", "'Expectation of predict loss1'", ",", "expect_loss1", ".", "item", "(", ")", ")", "\n", "meters", ".", "update", "(", "'Expectation of predict loss2'", ",", "expect_loss2", ".", "item", "(", ")", ")", "\n", "\n", "loss1", "=", "weak_class_loss1", "+", "strong_class_loss1", "+", "expect_loss1", "\n", "loss2", "=", "weak_class_loss2", "+", "strong_class_loss2", "+", "expect_loss2", "\n", "meters", ".", "update", "(", "'Loss1'", ",", "loss1", ".", "item", "(", ")", ")", "\n", "meters", ".", "update", "(", "'Loss2'", ",", "loss2", ".", "item", "(", ")", ")", "\n", "\n", "if", "(", "np", ".", "isnan", "(", "loss1", ".", "item", "(", ")", ")", "or", "loss1", ".", "item", "(", ")", ">", "1e5", ")", ":", "\n", "            ", "print", "(", "loss1", ")", "\n", "print", "(", "loss2", ")", "\n", "", "else", ":", "\n", "# compute gradient and do optimizer step", "\n", "            ", "optimizer1", ".", "zero_grad", "(", ")", "\n", "loss1", ".", "backward", "(", ")", "\n", "optimizer1", ".", "step", "(", ")", "\n", "\n", "optimizer2", ".", "zero_grad", "(", ")", "\n", "loss2", ".", "backward", "(", ")", "\n", "optimizer2", ".", "step", "(", ")", "\n", "\n", "global_step", "+=", "1", "\n", "if", "ema_model1", "is", "not", "None", ":", "\n", "                ", "update_ema_variables", "(", "model1", ",", "ema_model1", ",", "0.999", ",", "global_step", ")", "\n", "", "if", "ema_model2", "is", "not", "None", ":", "\n", "                ", "update_ema_variables", "(", "model2", ",", "ema_model2", ",", "0.999", ",", "global_step", ")", "\n", "\n", "", "", "", "epoch_time", "=", "time", ".", "time", "(", ")", "-", "start", "\n", "log", ".", "info", "(", "f\"Epoch: {c_epoch}\\t Time {epoch_time:.2f}\\t {meters}\"", ")", "\n", "return", "loss1", ",", "loss2", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.main_CRST_model_v2.get_dfs": [[247, 286], ["utilities.Logger.create_logger", "desed_dataset.initialize_and_get_df", "desed_dataset.initialize_and_get_df", "desed_dataset.initialize_and_get_df", "utilities.Logger.create_logger.debug", "desed_dataset.initialize_and_get_df", "desed_dataset.initialize_and_get_df.filename.drop_duplicates().sample", "desed_dataset.initialize_and_get_df.drop().reset_index", "utilities.Logger.create_logger.debug", "synthetic_df.drop().reset_index.event_label.value_counts", "desed_dataset.initialize_and_get_df.filename.drop_duplicates", "desed_dataset.initialize_and_get_df.filename.isin", "desed_dataset.initialize_and_get_df.drop", "desed_dataset.initialize_and_get_df.head", "inspect.currentframe"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Logger.create_logger", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df"], ["", "def", "get_dfs", "(", "desed_dataset", ",", "nb_files", "=", "None", ",", "separated_sources", "=", "False", ")", ":", "\n", "    ", "log", "=", "create_logger", "(", "__name__", "+", "\"/\"", "+", "inspect", ".", "currentframe", "(", ")", ".", "f_code", ".", "co_name", ",", "terminal_level", "=", "cfg", ".", "terminal_level", ")", "\n", "audio_weak_ss", "=", "None", "\n", "audio_unlabel_ss", "=", "None", "\n", "audio_validation_ss", "=", "None", "\n", "audio_synthetic_ss", "=", "None", "\n", "if", "separated_sources", ":", "\n", "        ", "audio_weak_ss", "=", "cfg", ".", "weak_ss", "\n", "audio_unlabel_ss", "=", "cfg", ".", "unlabel_ss", "\n", "audio_validation_ss", "=", "cfg", ".", "validation_ss", "\n", "audio_synthetic_ss", "=", "cfg", ".", "synthetic_ss", "\n", "\n", "", "weak_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "weak", ",", "audio_dir_ss", "=", "audio_weak_ss", ",", "nb_files", "=", "nb_files", ")", "\n", "unlabel_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "unlabel", ",", "audio_dir_ss", "=", "audio_unlabel_ss", ",", "nb_files", "=", "nb_files", ")", "\n", "# Event if synthetic not used for training, used on validation purpose", "\n", "synthetic_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "synthetic", ",", "audio_dir_ss", "=", "audio_synthetic_ss", ",", "\n", "nb_files", "=", "nb_files", ",", "download", "=", "False", ")", "\n", "log", ".", "debug", "(", "f\"synthetic: {synthetic_df.head()}\"", ")", "\n", "validation_df", "=", "desed_dataset", ".", "initialize_and_get_df", "(", "cfg", ".", "validation", ",", "audio_dir", "=", "cfg", ".", "audio_validation_dir", ",", "\n", "audio_dir_ss", "=", "audio_validation_ss", ",", "nb_files", "=", "nb_files", ")", "\n", "# Divide synthetic in train and valid", "\n", "filenames_train", "=", "synthetic_df", ".", "filename", ".", "drop_duplicates", "(", ")", ".", "sample", "(", "frac", "=", "0.8", ",", "random_state", "=", "26", ")", "\n", "train_synth_df", "=", "synthetic_df", "[", "synthetic_df", ".", "filename", ".", "isin", "(", "filenames_train", ")", "]", "\n", "valid_synth_df", "=", "synthetic_df", ".", "drop", "(", "train_synth_df", ".", "index", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "# Put train_synth in frames so many_hot_encoder can work.", "\n", "#  Not doing it for valid, because not using labels (when prediction) and event based metric expect sec.", "\n", "train_synth_df", ".", "onset", "=", "train_synth_df", ".", "onset", "*", "cfg", ".", "sample_rate", "//", "cfg", ".", "hop_size", "//", "pooling_time_ratio", "\n", "train_synth_df", ".", "offset", "=", "train_synth_df", ".", "offset", "*", "cfg", ".", "sample_rate", "//", "cfg", ".", "hop_size", "//", "pooling_time_ratio", "\n", "log", ".", "debug", "(", "valid_synth_df", ".", "event_label", ".", "value_counts", "(", ")", ")", "\n", "\n", "data_dfs", "=", "{", "\"weak\"", ":", "weak_df", ",", "\n", "\"unlabel\"", ":", "unlabel_df", ",", "\n", "\"synthetic\"", ":", "synthetic_df", ",", "\n", "\"train_synthetic\"", ":", "train_synth_df", ",", "\n", "\"valid_synthetic\"", ":", "valid_synth_df", ",", "\n", "\"validation\"", ":", "validation_df", ",", "\n", "}", "\n", "\n", "return", "data_dfs", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.get_event_list_current_file": [[22, 39], ["len", "pandas.isna", "event_file.to_dict", "event_file.to_dict"], "function", ["None"], ["def", "get_event_list_current_file", "(", "df", ",", "fname", ")", ":", "\n", "    ", "\"\"\"\n    Get list of events for a given filename\n    :param df: pd.DataFrame, the dataframe to search on\n    :param fname: the filename to extract the value from the dataframe\n    :return: list of events (dictionaries) for the given filename\n    \"\"\"", "\n", "event_file", "=", "df", "[", "df", "[", "\"filename\"", "]", "==", "fname", "]", "\n", "if", "len", "(", "event_file", ")", "==", "1", ":", "\n", "        ", "if", "pd", ".", "isna", "(", "event_file", "[", "\"event_label\"", "]", ".", "iloc", "[", "0", "]", ")", ":", "\n", "            ", "event_list_for_current_file", "=", "[", "{", "\"filename\"", ":", "fname", "}", "]", "\n", "", "else", ":", "\n", "            ", "event_list_for_current_file", "=", "event_file", ".", "to_dict", "(", "'records'", ")", "\n", "", "", "else", ":", "\n", "        ", "event_list_for_current_file", "=", "event_file", ".", "to_dict", "(", "'records'", ")", "\n", "\n", "", "return", "event_list_for_current_file", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.event_based_evaluation_df": [[41, 79], ["reference[].unique", "list.extend", "list.extend", "list", "sed_eval.sound_event.EventBasedMetrics", "reference.event_label.dropna().unique", "estimated.event_label.dropna().unique", "set", "evaluation_measures.get_event_list_current_file", "evaluation_measures.get_event_list_current_file", "sed_eval.sound_event.EventBasedMetrics.evaluate", "reference.event_label.dropna", "estimated.event_label.dropna"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.get_event_list_current_file", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.get_event_list_current_file"], ["", "def", "event_based_evaluation_df", "(", "reference", ",", "estimated", ",", "t_collar", "=", "0.200", ",", "percentage_of_length", "=", "0.2", ")", ":", "\n", "    ", "\"\"\" Calculate EventBasedMetric given a reference and estimated dataframe\n\n    Args:\n        reference: pd.DataFrame containing \"filename\" \"onset\" \"offset\" and \"event_label\" columns which describe the\n            reference events\n        estimated: pd.DataFrame containing \"filename\" \"onset\" \"offset\" and \"event_label\" columns which describe the\n            estimated events to be compared with reference\n        t_collar: float, in seconds, the number of time allowed on onsets and offsets\n        percentage_of_length: float, between 0 and 1, the percentage of length of the file allowed on the offset\n    Returns:\n         sed_eval.sound_event.EventBasedMetrics with the scores\n    \"\"\"", "\n", "\n", "evaluated_files", "=", "reference", "[", "\"filename\"", "]", ".", "unique", "(", ")", "\n", "\n", "classes", "=", "[", "]", "\n", "classes", ".", "extend", "(", "reference", ".", "event_label", ".", "dropna", "(", ")", ".", "unique", "(", ")", ")", "\n", "classes", ".", "extend", "(", "estimated", ".", "event_label", ".", "dropna", "(", ")", ".", "unique", "(", ")", ")", "\n", "classes", "=", "list", "(", "set", "(", "classes", ")", ")", "\n", "\n", "event_based_metric", "=", "sed_eval", ".", "sound_event", ".", "EventBasedMetrics", "(", "\n", "event_label_list", "=", "classes", ",", "\n", "t_collar", "=", "t_collar", ",", "\n", "percentage_of_length", "=", "percentage_of_length", ",", "\n", "empty_system_output_handling", "=", "'zero_score'", "\n", ")", "\n", "\n", "for", "fname", "in", "evaluated_files", ":", "\n", "        ", "reference_event_list_for_current_file", "=", "get_event_list_current_file", "(", "reference", ",", "fname", ")", "\n", "estimated_event_list_for_current_file", "=", "get_event_list_current_file", "(", "estimated", ",", "fname", ")", "\n", "\n", "event_based_metric", ".", "evaluate", "(", "\n", "reference_event_list", "=", "reference_event_list_for_current_file", ",", "\n", "estimated_event_list", "=", "estimated_event_list_for_current_file", ",", "\n", ")", "\n", "\n", "", "return", "event_based_metric", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.segment_based_evaluation_df": [[81, 115], ["reference[].unique", "list.extend", "list.extend", "list", "sed_eval.sound_event.SegmentBasedMetrics", "reference.event_label.dropna().unique", "estimated.event_label.dropna().unique", "set", "evaluation_measures.get_event_list_current_file", "evaluation_measures.get_event_list_current_file", "sed_eval.sound_event.SegmentBasedMetrics.evaluate", "reference.event_label.dropna", "estimated.event_label.dropna"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.get_event_list_current_file", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.get_event_list_current_file"], ["", "def", "segment_based_evaluation_df", "(", "reference", ",", "estimated", ",", "time_resolution", "=", "1.", ")", ":", "\n", "    ", "\"\"\" Calculate SegmentBasedMetrics given a reference and estimated dataframe\n\n        Args:\n            reference: pd.DataFrame containing \"filename\" \"onset\" \"offset\" and \"event_label\" columns which describe the\n                reference events\n            estimated: pd.DataFrame containing \"filename\" \"onset\" \"offset\" and \"event_label\" columns which describe the\n                estimated events to be compared with reference\n            time_resolution: float, the time resolution of the segment based metric\n        Returns:\n             sed_eval.sound_event.SegmentBasedMetrics with the scores\n        \"\"\"", "\n", "evaluated_files", "=", "reference", "[", "\"filename\"", "]", ".", "unique", "(", ")", "\n", "\n", "classes", "=", "[", "]", "\n", "classes", ".", "extend", "(", "reference", ".", "event_label", ".", "dropna", "(", ")", ".", "unique", "(", ")", ")", "\n", "classes", ".", "extend", "(", "estimated", ".", "event_label", ".", "dropna", "(", ")", ".", "unique", "(", ")", ")", "\n", "classes", "=", "list", "(", "set", "(", "classes", ")", ")", "\n", "\n", "segment_based_metric", "=", "sed_eval", ".", "sound_event", ".", "SegmentBasedMetrics", "(", "\n", "event_label_list", "=", "classes", ",", "\n", "time_resolution", "=", "time_resolution", "\n", ")", "\n", "\n", "for", "fname", "in", "evaluated_files", ":", "\n", "        ", "reference_event_list_for_current_file", "=", "get_event_list_current_file", "(", "reference", ",", "fname", ")", "\n", "estimated_event_list_for_current_file", "=", "get_event_list_current_file", "(", "estimated", ",", "fname", ")", "\n", "\n", "segment_based_metric", ".", "evaluate", "(", "\n", "reference_event_list", "=", "reference_event_list_for_current_file", ",", "\n", "estimated_event_list", "=", "estimated_event_list_for_current_file", "\n", ")", "\n", "\n", "", "return", "segment_based_metric", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.get_predictions": [[117, 207], ["enumerate", "pandas.DataFrame", "indexes.numpy.numpy", "utilities.utils.to_cuda_if_available", "pred_strong.detach().numpy.cpu", "pred_strong.detach().numpy.detach().numpy", "enumerate", "isinstance", "enumerate", "list_predictions.append", "len", "torch.no_grad", "model", "logger.debug", "os.path.dirname", "pred_strong.detach().numpy.detach", "dcase_util.data.ProbabilityEncoder().binarization", "scipy.ndimage.filters.median_filter", "decoder", "pandas.DataFrame", "pred[].clip", "prediction_dfs[].append", "len", "os.path.splitext", "len", "len", "os.makedirs", "prediction_dfs[].to_csv", "logger.debug", "logger.debug", "os.path.join", "len", "len", "logger.info", "dcase_util.data.ProbabilityEncoder", "len"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available"], ["", "def", "get_predictions", "(", "model", ",", "dataloader", ",", "decoder", ",", "pooling_time_ratio", "=", "1", ",", "thresholds", "=", "[", "0.5", "]", ",", "\n", "median_window", "=", "1", ",", "save_predictions", "=", "None", ")", ":", "\n", "    ", "\"\"\" Get the predictions of a trained model on a specific set\n    Args:\n        model: torch.Module, a trained pytorch model (you usually want it to be in .eval() mode).\n        dataloader: torch.utils.data.DataLoader, giving ((input_data, label), indexes) but label is not used here\n        decoder: function, takes a numpy.array of shape (time_steps, n_labels) as input and return a list of lists\n            of (\"event_label\", \"onset\", \"offset\") for each label predicted.\n        pooling_time_ratio: the division to make between timesteps as input and timesteps as output\n        median_window: int, the median window (in number of time steps) to be applied\n        save_predictions: str or list, the path of the base_filename to save the predictions or a list of names\n            corresponding for each thresholds\n        thresholds: list, list of threshold to be applied\n\n    Returns:\n        dict of the different predictions with associated threshold\n    \"\"\"", "\n", "\n", "# Init a dataframe per threshold", "\n", "prediction_dfs", "=", "{", "}", "\n", "for", "threshold", "in", "thresholds", ":", "\n", "        ", "prediction_dfs", "[", "threshold", "]", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "# Get predictions", "\n", "", "for", "i", ",", "(", "(", "input_data", ",", "_", ")", ",", "indexes", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "indexes", "=", "indexes", ".", "numpy", "(", ")", "\n", "\n", "input_data", "=", "to_cuda_if_available", "(", "input_data", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pred_strong", ",", "_", "=", "model", "(", "input_data", ")", "\n", "", "pred_strong", "=", "pred_strong", ".", "cpu", "(", ")", "\n", "pred_strong", "=", "pred_strong", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "if", "i", "==", "0", ":", "\n", "            ", "logger", ".", "debug", "(", "pred_strong", ")", "\n", "\n", "# Post processing and put predictions in a dataframe", "\n", "", "for", "j", ",", "pred_strong_it", "in", "enumerate", "(", "pred_strong", ")", ":", "\n", "\n", "#savePath = \"./Posterior/\" + dataloader.dataset.filenames.iloc[indexes[j]]", "\n", "#savePath.replace(\"wav\", \"npy\")", "\n", "#np.save(savePath, pred_strong_it)", "\n", "\n", "            ", "for", "threshold", "in", "thresholds", ":", "\n", "                ", "pred_strong_bin", "=", "ProbabilityEncoder", "(", ")", ".", "binarization", "(", "pred_strong_it", ",", "\n", "binarization_type", "=", "\"global_threshold\"", ",", "\n", "threshold", "=", "threshold", ")", "\n", "pred_strong_m", "=", "scipy", ".", "ndimage", ".", "filters", ".", "median_filter", "(", "pred_strong_bin", ",", "(", "median_window", ",", "1", ")", ")", "\n", "pred", "=", "decoder", "(", "pred_strong_m", ")", "\n", "pred", "=", "pd", ".", "DataFrame", "(", "pred", ",", "columns", "=", "[", "\"event_label\"", ",", "\"onset\"", ",", "\"offset\"", "]", ")", "\n", "# Put them in seconds", "\n", "pred", ".", "loc", "[", ":", ",", "[", "\"onset\"", ",", "\"offset\"", "]", "]", "*=", "pooling_time_ratio", "/", "(", "cfg", ".", "sample_rate", "/", "cfg", ".", "hop_size", ")", "\n", "pred", ".", "loc", "[", ":", ",", "[", "\"onset\"", ",", "\"offset\"", "]", "]", "=", "pred", "[", "[", "\"onset\"", ",", "\"offset\"", "]", "]", ".", "clip", "(", "0", ",", "cfg", ".", "max_len_seconds", ")", "\n", "\n", "pred", "[", "\"filename\"", "]", "=", "dataloader", ".", "dataset", ".", "filenames", ".", "iloc", "[", "indexes", "[", "j", "]", "]", "\n", "prediction_dfs", "[", "threshold", "]", "=", "prediction_dfs", "[", "threshold", "]", ".", "append", "(", "pred", ",", "ignore_index", "=", "True", ")", "\n", "\n", "if", "i", "==", "0", "and", "j", "==", "0", ":", "\n", "                    ", "logger", ".", "debug", "(", "\"predictions: \\n{}\"", ".", "format", "(", "pred", ")", ")", "\n", "logger", ".", "debug", "(", "\"predictions strong: \\n{}\"", ".", "format", "(", "pred_strong_it", ")", ")", "\n", "\n", "# Save predictions", "\n", "", "", "", "", "if", "save_predictions", "is", "not", "None", ":", "\n", "        ", "if", "isinstance", "(", "save_predictions", ",", "str", ")", ":", "\n", "            ", "if", "len", "(", "thresholds", ")", "==", "1", ":", "\n", "                ", "save_predictions", "=", "[", "save_predictions", "]", "\n", "", "else", ":", "\n", "                ", "base", ",", "ext", "=", "osp", ".", "splitext", "(", "save_predictions", ")", "\n", "save_predictions", "=", "[", "osp", ".", "join", "(", "base", ",", "f\"{threshold:.3f}{ext}\"", ")", "for", "threshold", "in", "thresholds", "]", "\n", "", "", "else", ":", "\n", "            ", "assert", "len", "(", "save_predictions", ")", "==", "len", "(", "thresholds", ")", ",", "f\"There should be a prediction file per threshold: len predictions: {len(save_predictions)}\\n\"", "f\"len thresholds: {len(thresholds)}\"", "\n", "save_predictions", "=", "save_predictions", "\n", "\n", "", "for", "ind", ",", "threshold", "in", "enumerate", "(", "thresholds", ")", ":", "\n", "            ", "dir_to_create", "=", "osp", ".", "dirname", "(", "save_predictions", "[", "ind", "]", ")", "\n", "if", "dir_to_create", "!=", "\"\"", ":", "\n", "                ", "os", ".", "makedirs", "(", "dir_to_create", ",", "exist_ok", "=", "True", ")", "\n", "if", "ind", "%", "10", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"Saving predictions at: {save_predictions[ind]}. {ind + 1} / {len(thresholds)}\"", ")", "\n", "", "prediction_dfs", "[", "threshold", "]", ".", "to_csv", "(", "save_predictions", "[", "ind", "]", ",", "index", "=", "False", ",", "sep", "=", "\"\\t\"", ",", "float_format", "=", "\"%.3f\"", ")", "\n", "\n", "", "", "", "list_predictions", "=", "[", "]", "\n", "for", "key", "in", "prediction_dfs", ":", "\n", "        ", "list_predictions", ".", "append", "(", "prediction_dfs", "[", "key", "]", ")", "\n", "\n", "", "if", "len", "(", "list_predictions", ")", "==", "1", ":", "\n", "        ", "list_predictions", "=", "list_predictions", "[", "0", "]", "\n", "\n", "", "return", "list_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.get_predictions_v2": [[209, 303], ["enumerate", "pandas.DataFrame", "os.makedirs", "indexes.numpy.numpy", "utilities.utils.to_cuda_if_available", "pred_strong.detach().numpy.cpu", "pred_strong.detach().numpy.detach().numpy", "enumerate", "isinstance", "enumerate", "list_predictions.append", "len", "torch.no_grad", "model", "logger.debug", "os.path.dirname", "pred_strong.detach().numpy.detach", "savePath.replace", "numpy.save", "dcase_util.data.ProbabilityEncoder().binarization", "scipy.ndimage.filters.median_filter", "decoder", "pandas.DataFrame", "pred[].clip", "prediction_dfs[].append", "len", "os.path.splitext", "len", "len", "os.makedirs", "prediction_dfs[].to_csv", "logger.debug", "logger.debug", "os.path.join", "len", "len", "logger.info", "dcase_util.data.ProbabilityEncoder", "len"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save"], ["", "def", "get_predictions_v2", "(", "model", ",", "dataloader", ",", "decoder", ",", "pooling_time_ratio", "=", "1", ",", "thresholds", "=", "[", "0.5", "]", ",", "\n", "median_window", "=", "1", ",", "save_dir", "=", "None", ",", "save_predictions", "=", "None", ")", ":", "\n", "    ", "\"\"\" Get the predictions of a trained model on a specific set\n    Args:\n        model: torch.Module, a trained pytorch model (you usually want it to be in .eval() mode).\n        dataloader: torch.utils.data.DataLoader, giving ((input_data, label), indexes) but label is not used here\n        decoder: function, takes a numpy.array of shape (time_steps, n_labels) as input and return a list of lists\n            of (\"event_label\", \"onset\", \"offset\") for each label predicted.\n        pooling_time_ratio: the division to make between timesteps as input and timesteps as output\n        median_window: int, the median window (in number of time steps) to be applied\n        save_predictions: str or list, the path of the base_filename to save the predictions or a list of names\n            corresponding for each thresholds\n        thresholds: list, list of threshold to be applied\n\n    Returns:\n        dict of the different predictions with associated threshold\n    \"\"\"", "\n", "\n", "# Init a dataframe per threshold", "\n", "prediction_dfs", "=", "{", "}", "\n", "for", "threshold", "in", "thresholds", ":", "\n", "        ", "prediction_dfs", "[", "threshold", "]", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "", "if", "save_dir", "is", "not", "None", ":", "\n", "        ", "os", ".", "makedirs", "(", "save_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Get predictions", "\n", "", "for", "i", ",", "(", "(", "input_data", ",", "_", ")", ",", "indexes", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "indexes", "=", "indexes", ".", "numpy", "(", ")", "\n", "\n", "input_data", "=", "to_cuda_if_available", "(", "input_data", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pred_strong", ",", "_", "=", "model", "(", "input_data", ")", "\n", "", "pred_strong", "=", "pred_strong", ".", "cpu", "(", ")", "\n", "pred_strong", "=", "pred_strong", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "if", "i", "==", "0", ":", "\n", "            ", "logger", ".", "debug", "(", "pred_strong", ")", "\n", "\n", "# Post processing and put predictions in a dataframe", "\n", "", "for", "j", ",", "pred_strong_it", "in", "enumerate", "(", "pred_strong", ")", ":", "\n", "\n", "            ", "if", "save_dir", "is", "not", "None", ":", "\n", "                ", "savePath", "=", "save_dir", "+", "dataloader", ".", "dataset", ".", "filenames", ".", "iloc", "[", "indexes", "[", "j", "]", "]", "\n", "savePath", ".", "replace", "(", "\"wav\"", ",", "\"npy\"", ")", "\n", "np", ".", "save", "(", "savePath", ",", "pred_strong_it", ")", "\n", "\n", "", "for", "threshold", "in", "thresholds", ":", "\n", "                ", "pred_strong_bin", "=", "ProbabilityEncoder", "(", ")", ".", "binarization", "(", "pred_strong_it", ",", "\n", "binarization_type", "=", "\"global_threshold\"", ",", "\n", "threshold", "=", "threshold", ")", "\n", "pred_strong_m", "=", "scipy", ".", "ndimage", ".", "filters", ".", "median_filter", "(", "pred_strong_bin", ",", "(", "median_window", ",", "1", ")", ")", "\n", "pred", "=", "decoder", "(", "pred_strong_m", ")", "\n", "pred", "=", "pd", ".", "DataFrame", "(", "pred", ",", "columns", "=", "[", "\"event_label\"", ",", "\"onset\"", ",", "\"offset\"", "]", ")", "\n", "# Put them in seconds", "\n", "pred", ".", "loc", "[", ":", ",", "[", "\"onset\"", ",", "\"offset\"", "]", "]", "*=", "pooling_time_ratio", "/", "(", "cfg", ".", "sample_rate", "/", "cfg", ".", "hop_size", ")", "\n", "pred", ".", "loc", "[", ":", ",", "[", "\"onset\"", ",", "\"offset\"", "]", "]", "=", "pred", "[", "[", "\"onset\"", ",", "\"offset\"", "]", "]", ".", "clip", "(", "0", ",", "cfg", ".", "max_len_seconds", ")", "\n", "\n", "pred", "[", "\"filename\"", "]", "=", "dataloader", ".", "dataset", ".", "filenames", ".", "iloc", "[", "indexes", "[", "j", "]", "]", "\n", "prediction_dfs", "[", "threshold", "]", "=", "prediction_dfs", "[", "threshold", "]", ".", "append", "(", "pred", ",", "ignore_index", "=", "True", ")", "\n", "\n", "if", "i", "==", "0", "and", "j", "==", "0", ":", "\n", "                    ", "logger", ".", "debug", "(", "\"predictions: \\n{}\"", ".", "format", "(", "pred", ")", ")", "\n", "logger", ".", "debug", "(", "\"predictions strong: \\n{}\"", ".", "format", "(", "pred_strong_it", ")", ")", "\n", "\n", "# Save predictions", "\n", "", "", "", "", "if", "save_predictions", "is", "not", "None", ":", "\n", "        ", "if", "isinstance", "(", "save_predictions", ",", "str", ")", ":", "\n", "            ", "if", "len", "(", "thresholds", ")", "==", "1", ":", "\n", "                ", "save_predictions", "=", "[", "save_predictions", "]", "\n", "", "else", ":", "\n", "                ", "base", ",", "ext", "=", "osp", ".", "splitext", "(", "save_predictions", ")", "\n", "save_predictions", "=", "[", "osp", ".", "join", "(", "base", ",", "f\"{threshold:.3f}{ext}\"", ")", "for", "threshold", "in", "thresholds", "]", "\n", "", "", "else", ":", "\n", "            ", "assert", "len", "(", "save_predictions", ")", "==", "len", "(", "thresholds", ")", ",", "f\"There should be a prediction file per threshold: len predictions: {len(save_predictions)}\\n\"", "f\"len thresholds: {len(thresholds)}\"", "\n", "save_predictions", "=", "save_predictions", "\n", "\n", "", "for", "ind", ",", "threshold", "in", "enumerate", "(", "thresholds", ")", ":", "\n", "            ", "dir_to_create", "=", "osp", ".", "dirname", "(", "save_predictions", "[", "ind", "]", ")", "\n", "if", "dir_to_create", "!=", "\"\"", ":", "\n", "                ", "os", ".", "makedirs", "(", "dir_to_create", ",", "exist_ok", "=", "True", ")", "\n", "if", "ind", "%", "10", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"Saving predictions at: {save_predictions[ind]}. {ind + 1} / {len(thresholds)}\"", ")", "\n", "", "prediction_dfs", "[", "threshold", "]", ".", "to_csv", "(", "save_predictions", "[", "ind", "]", ",", "index", "=", "False", ",", "sep", "=", "\"\\t\"", ",", "float_format", "=", "\"%.3f\"", ")", "\n", "\n", "", "", "", "list_predictions", "=", "[", "]", "\n", "for", "key", "in", "prediction_dfs", ":", "\n", "        ", "list_predictions", ".", "append", "(", "prediction_dfs", "[", "key", "]", ")", "\n", "\n", "", "if", "len", "(", "list_predictions", ")", "==", "1", ":", "\n", "        ", "list_predictions", "=", "list_predictions", "[", "0", "]", "\n", "\n", "", "return", "list_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.psds_score": [[305, 330], ["psds.psds", "logger.info", "psds.psds", "logger.info", "psds.psds", "logger.info", "os.path.splitext", "psds_eval.plot_psd_roc", "psds_eval.plot_psd_roc", "psds_eval.plot_psd_roc", "logger.error", "logger.error", "os.path.dirname", "os.makedirs", "os.path.dirname"], "function", ["None"], ["", "def", "psds_score", "(", "psds", ",", "filename_roc_curves", "=", "None", ")", ":", "\n", "    ", "\"\"\" add operating points to PSDSEval object and compute metrics\n\n    Args:\n        psds: psds.PSDSEval object initialized with the groundtruth corresponding to the predictions\n        filename_roc_curves: str, the base filename of the roc curve to be computed\n    \"\"\"", "\n", "try", ":", "\n", "        ", "psds_score", "=", "psds", ".", "psds", "(", "alpha_ct", "=", "0", ",", "alpha_st", "=", "0", ",", "max_efpr", "=", "100", ")", "\n", "logger", ".", "info", "(", "f\"\\nPSD-Score (0, 0, 100): {psds_score.value:.5f}\"", ")", "\n", "psds_ct_score", "=", "psds", ".", "psds", "(", "alpha_ct", "=", "1", ",", "alpha_st", "=", "0", ",", "max_efpr", "=", "100", ")", "\n", "logger", ".", "info", "(", "f\"\\nPSD-Score (1, 0, 100): {psds_ct_score.value:.5f}\"", ")", "\n", "psds_macro_score", "=", "psds", ".", "psds", "(", "alpha_ct", "=", "0", ",", "alpha_st", "=", "1", ",", "max_efpr", "=", "100", ")", "\n", "logger", ".", "info", "(", "f\"\\nPSD-Score (0, 1, 100): {psds_macro_score.value:.5f}\"", ")", "\n", "if", "filename_roc_curves", "is", "not", "None", ":", "\n", "            ", "if", "osp", ".", "dirname", "(", "filename_roc_curves", ")", "!=", "\"\"", ":", "\n", "                ", "os", ".", "makedirs", "(", "osp", ".", "dirname", "(", "filename_roc_curves", ")", ",", "exist_ok", "=", "True", ")", "\n", "", "base", ",", "ext", "=", "osp", ".", "splitext", "(", "filename_roc_curves", ")", "\n", "plot_psd_roc", "(", "psds_score", ",", "filename", "=", "f\"{base}_0_0_100{ext}\"", ")", "\n", "plot_psd_roc", "(", "psds_ct_score", ",", "filename", "=", "f\"{base}_1_0_100{ext}\"", ")", "\n", "plot_psd_roc", "(", "psds_score", ",", "filename", "=", "f\"{base}_0_1_100{ext}\"", ")", "\n", "\n", "", "", "except", "psds_eval", ".", "psds", ".", "PSDSEvalError", "as", "e", ":", "\n", "        ", "logger", ".", "error", "(", "\"psds score did not work ....\"", ")", "\n", "logger", ".", "error", "(", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.compute_sed_eval_metrics": [[332, 340], ["evaluation_measures.event_based_evaluation_df", "evaluation_measures.segment_based_evaluation_df", "logger.info", "logger.info"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.event_based_evaluation_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.segment_based_evaluation_df"], ["", "", "def", "compute_sed_eval_metrics", "(", "predictions", ",", "groundtruth", ")", ":", "\n", "    ", "metric_event", "=", "event_based_evaluation_df", "(", "groundtruth", ",", "predictions", ",", "t_collar", "=", "0.200", ",", "\n", "percentage_of_length", "=", "0.2", ")", "\n", "metric_segment", "=", "segment_based_evaluation_df", "(", "groundtruth", ",", "predictions", ",", "time_resolution", "=", "1.", ")", "\n", "logger", ".", "info", "(", "metric_event", ")", "\n", "logger", ".", "info", "(", "metric_segment", ")", "\n", "\n", "return", "metric_event", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.format_df": [[342, 358], ["pandas.Series", "df.groupby().apply.groupby().apply", "dict", "df.groupby().apply.groupby", "mhe.encode_weak", "x[].drop_duplicates().dropna().tolist", "x[].drop_duplicates().dropna", "x[].drop_duplicates"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.EarlyStopping.apply", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.encode_weak"], ["", "def", "format_df", "(", "df", ",", "mhe", ")", ":", "\n", "    ", "\"\"\" Make a weak labels dataframe from strongly labeled (join labels)\n    Args:\n        df: pd.DataFrame, the dataframe strongly labeled with onset and offset columns (+ event_label)\n        mhe: ManyHotEncoder object, the many hot encoder object that can encode the weak labels\n\n    Returns:\n        weakly labeled dataframe\n    \"\"\"", "\n", "def", "join_labels", "(", "x", ")", ":", "\n", "        ", "return", "pd", ".", "Series", "(", "dict", "(", "filename", "=", "x", "[", "'filename'", "]", ".", "iloc", "[", "0", "]", ",", "\n", "event_label", "=", "mhe", ".", "encode_weak", "(", "x", "[", "\"event_label\"", "]", ".", "drop_duplicates", "(", ")", ".", "dropna", "(", ")", ".", "tolist", "(", ")", ")", ")", ")", "\n", "\n", "", "if", "\"onset\"", "in", "df", ".", "columns", "or", "\"offset\"", "in", "df", ".", "columns", ":", "\n", "        ", "df", "=", "df", ".", "groupby", "(", "\"filename\"", ",", "as_index", "=", "False", ")", ".", "apply", "(", "join_labels", ")", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.get_f_measure_by_class": [[360, 425], ["torch.cuda.is_available", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.zeros", "torch_model.cuda.cuda", "torch.cuda.is_available", "torch_model.cuda.", "np.max.cpu().data.numpy", "y.numpy", "dcase_util.data.ProbabilityEncoder().binarization", "evaluation_measures.intermediate_at_measures", "batch_x.cuda.cuda", "len", "numpy.max", "len", "numpy.max", "dcase_util.data.ProbabilityEncoder().binarization", "type", "dcase_util.data.ProbabilityEncoder", "np.max.cpu", "dcase_util.data.ProbabilityEncoder"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.intermediate_at_measures"], ["", "def", "get_f_measure_by_class", "(", "torch_model", ",", "nb_tags", ",", "dataloader_", ",", "thresholds_", "=", "None", ")", ":", "\n", "    ", "\"\"\" get f measure for each class given a model and a generator of data (batch_x, y)\n\n    Args:\n        torch_model : Model, model to get predictions, forward should return weak and strong predictions\n        nb_tags : int, number of classes which are represented\n        dataloader_ : generator, data generator used to get f_measure\n        thresholds_ : int or list, thresholds to apply to each class to binarize probabilities\n\n    Returns:\n        macro_f_measure : list, f measure for each class\n\n    \"\"\"", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch_model", "=", "torch_model", ".", "cuda", "(", ")", "\n", "\n", "# Calculate external metrics", "\n", "", "tp", "=", "np", ".", "zeros", "(", "nb_tags", ")", "\n", "tn", "=", "np", ".", "zeros", "(", "nb_tags", ")", "\n", "fp", "=", "np", ".", "zeros", "(", "nb_tags", ")", "\n", "fn", "=", "np", ".", "zeros", "(", "nb_tags", ")", "\n", "for", "counter", ",", "(", "batch_x", ",", "y", ")", "in", "enumerate", "(", "dataloader_", ")", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "batch_x", "=", "batch_x", ".", "cuda", "(", ")", "\n", "\n", "", "pred_strong", ",", "pred_weak", "=", "torch_model", "(", "batch_x", ")", "\n", "pred_weak", "=", "pred_weak", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "labels", "=", "y", ".", "numpy", "(", ")", "\n", "\n", "# Used only with a model predicting only strong outputs", "\n", "if", "len", "(", "pred_weak", ".", "shape", ")", "==", "3", ":", "\n", "# average data to have weak labels", "\n", "            ", "pred_weak", "=", "np", ".", "max", "(", "pred_weak", ",", "axis", "=", "1", ")", "\n", "\n", "", "if", "len", "(", "labels", ".", "shape", ")", "==", "3", ":", "\n", "            ", "labels", "=", "np", ".", "max", "(", "labels", ",", "axis", "=", "1", ")", "\n", "labels", "=", "ProbabilityEncoder", "(", ")", ".", "binarization", "(", "labels", ",", "\n", "binarization_type", "=", "\"global_threshold\"", ",", "\n", "threshold", "=", "0.5", ")", "\n", "\n", "", "if", "thresholds_", "is", "None", ":", "\n", "            ", "binarization_type", "=", "'global_threshold'", "\n", "thresh", "=", "0.5", "\n", "", "else", ":", "\n", "            ", "binarization_type", "=", "\"class_threshold\"", "\n", "assert", "type", "(", "thresholds_", ")", "is", "list", "\n", "thresh", "=", "thresholds_", "\n", "\n", "", "batch_predictions", "=", "ProbabilityEncoder", "(", ")", ".", "binarization", "(", "pred_weak", ",", "\n", "binarization_type", "=", "binarization_type", ",", "\n", "threshold", "=", "thresh", ",", "\n", "time_axis", "=", "0", "\n", ")", "\n", "\n", "tp_", ",", "fp_", ",", "fn_", ",", "tn_", "=", "intermediate_at_measures", "(", "labels", ",", "batch_predictions", ")", "\n", "tp", "+=", "tp_", "\n", "fp", "+=", "fp_", "\n", "fn", "+=", "fn_", "\n", "tn", "+=", "tn_", "\n", "\n", "", "macro_f_score", "=", "np", ".", "zeros", "(", "nb_tags", ")", "\n", "mask_f_score", "=", "2", "*", "tp", "+", "fp", "+", "fn", "!=", "0", "\n", "macro_f_score", "[", "mask_f_score", "]", "=", "2", "*", "tp", "[", "mask_f_score", "]", "/", "(", "2", "*", "tp", "+", "fp", "+", "fn", ")", "[", "mask_f_score", "]", "\n", "\n", "return", "macro_f_score", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.intermediate_at_measures": [[427, 444], ["None"], "function", ["None"], ["", "def", "intermediate_at_measures", "(", "encoded_ref", ",", "encoded_est", ")", ":", "\n", "    ", "\"\"\" Calculate true/false - positives/negatives.\n\n    Args:\n        encoded_ref: np.array, the reference array where a 1 means the label is present, 0 otherwise\n        encoded_est: np.array, the estimated array, where a 1 means the label is present, 0 otherwise\n\n    Returns:\n        tuple\n        number of (true positives, false positives, false negatives, true negatives)\n\n    \"\"\"", "\n", "tp", "=", "(", "encoded_est", "+", "encoded_ref", "==", "2", ")", ".", "sum", "(", "axis", "=", "0", ")", "\n", "fp", "=", "(", "encoded_est", "-", "encoded_ref", "==", "1", ")", ".", "sum", "(", "axis", "=", "0", ")", "\n", "fn", "=", "(", "encoded_ref", "-", "encoded_est", "==", "1", ")", ".", "sum", "(", "axis", "=", "0", ")", "\n", "tn", "=", "(", "encoded_est", "+", "encoded_ref", "==", "0", ")", ".", "sum", "(", "axis", "=", "0", ")", "\n", "return", "tp", ",", "fp", ",", "fn", ",", "tn", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.macro_f_measure": [[446, 462], ["numpy.zeros"], "function", ["None"], ["", "def", "macro_f_measure", "(", "tp", ",", "fp", ",", "fn", ")", ":", "\n", "    ", "\"\"\" From intermediates measures, give the macro F-measure\n\n    Args:\n        tp: int, number of true positives\n        fp: int, number of false positives\n        fn: int, number of true negatives\n\n    Returns:\n        float\n        The macro F-measure\n    \"\"\"", "\n", "macro_f_score", "=", "np", ".", "zeros", "(", "tp", ".", "shape", "[", "-", "1", "]", ")", "\n", "mask_f_score", "=", "2", "*", "tp", "+", "fp", "+", "fn", "!=", "0", "\n", "macro_f_score", "[", "mask_f_score", "]", "=", "2", "*", "tp", "[", "mask_f_score", "]", "/", "(", "2", "*", "tp", "+", "fp", "+", "fn", ")", "[", "mask_f_score", "]", "\n", "return", "macro_f_score", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.audio_tagging_results": [[464, 500], ["format_df.merge", "pandas.DataFrame", "list.extend", "list.extend", "list", "utilities.ManyHotEncoder.ManyHotEncoder", "evaluation_measures.format_df", "evaluation_measures.format_df", "list.extend", "list.extend", "list", "utilities.ManyHotEncoder.ManyHotEncoder", "pandas.isna", "reference.merge.event_label_pred.apply", "reference.merge.event_label_ref.apply", "evaluation_measures.intermediate_at_measures", "evaluation_measures.macro_f_measure", "numpy.zeros", "format_df.event_label.dropna().unique", "format_df.event_label.dropna().unique", "set", "format_df.event_labels.str.split().unstack().dropna().unique", "format_df.event_labels.str.split().unstack().dropna().unique", "set", "type", "numpy.zeros", "numpy.array", "numpy.array", "len", "len", "reference.merge.event_label_ref.tolist", "reference.merge.event_label_pred.tolist", "format_df.event_label.dropna", "format_df.event_label.dropna", "format_df.event_labels.str.split().unstack().dropna", "format_df.event_labels.str.split().unstack().dropna", "format_df.event_labels.str.split().unstack", "format_df.event_labels.str.split().unstack", "format_df.event_labels.str.split", "format_df.event_labels.str.split"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.format_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.format_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.EarlyStopping.apply", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.EarlyStopping.apply", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.intermediate_at_measures", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.macro_f_measure"], ["", "def", "audio_tagging_results", "(", "reference", ",", "estimated", ")", ":", "\n", "    ", "classes", "=", "[", "]", "\n", "if", "\"event_label\"", "in", "reference", ".", "columns", ":", "\n", "        ", "classes", ".", "extend", "(", "reference", ".", "event_label", ".", "dropna", "(", ")", ".", "unique", "(", ")", ")", "\n", "classes", ".", "extend", "(", "estimated", ".", "event_label", ".", "dropna", "(", ")", ".", "unique", "(", ")", ")", "\n", "classes", "=", "list", "(", "set", "(", "classes", ")", ")", "\n", "mhe", "=", "ManyHotEncoder", "(", "classes", ")", "\n", "reference", "=", "format_df", "(", "reference", ",", "mhe", ")", "\n", "estimated", "=", "format_df", "(", "estimated", ",", "mhe", ")", "\n", "", "else", ":", "\n", "        ", "classes", ".", "extend", "(", "reference", ".", "event_labels", ".", "str", ".", "split", "(", "','", ",", "expand", "=", "True", ")", ".", "unstack", "(", ")", ".", "dropna", "(", ")", ".", "unique", "(", ")", ")", "\n", "classes", ".", "extend", "(", "estimated", ".", "event_labels", ".", "str", ".", "split", "(", "','", ",", "expand", "=", "True", ")", ".", "unstack", "(", ")", ".", "dropna", "(", ")", ".", "unique", "(", ")", ")", "\n", "classes", "=", "list", "(", "set", "(", "classes", ")", ")", "\n", "mhe", "=", "ManyHotEncoder", "(", "classes", ")", "\n", "\n", "", "matching", "=", "reference", ".", "merge", "(", "estimated", ",", "how", "=", "'outer'", ",", "on", "=", "\"filename\"", ",", "suffixes", "=", "[", "\"_ref\"", ",", "\"_pred\"", "]", ")", "\n", "\n", "def", "na_values", "(", "val", ")", ":", "\n", "        ", "if", "type", "(", "val", ")", "is", "np", ".", "ndarray", ":", "\n", "            ", "return", "val", "\n", "", "if", "pd", ".", "isna", "(", "val", ")", ":", "\n", "            ", "return", "np", ".", "zeros", "(", "len", "(", "classes", ")", ")", "\n", "", "return", "val", "\n", "\n", "", "if", "not", "estimated", ".", "empty", ":", "\n", "        ", "matching", ".", "event_label_pred", "=", "matching", ".", "event_label_pred", ".", "apply", "(", "na_values", ")", "\n", "matching", ".", "event_label_ref", "=", "matching", ".", "event_label_ref", ".", "apply", "(", "na_values", ")", "\n", "\n", "tp", ",", "fp", ",", "fn", ",", "tn", "=", "intermediate_at_measures", "(", "np", ".", "array", "(", "matching", ".", "event_label_ref", ".", "tolist", "(", ")", ")", ",", "\n", "np", ".", "array", "(", "matching", ".", "event_label_pred", ".", "tolist", "(", ")", ")", ")", "\n", "macro_res", "=", "macro_f_measure", "(", "tp", ",", "fp", ",", "fn", ")", "\n", "", "else", ":", "\n", "        ", "macro_res", "=", "np", ".", "zeros", "(", "len", "(", "classes", ")", ")", "\n", "\n", "", "results_serie", "=", "pd", ".", "DataFrame", "(", "macro_res", ",", "index", "=", "mhe", ".", "labels", ")", "\n", "return", "results_serie", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.compute_psds_from_operating_points": [[502, 508], ["psds_eval.PSDSEval", "psds_eval.PSDSEval.add_operating_point"], "function", ["None"], ["", "def", "compute_psds_from_operating_points", "(", "list_predictions", ",", "groundtruth_df", ",", "meta_df", ",", "dtc_threshold", "=", "0.5", ",", "gtc_threshold", "=", "0.5", ",", "\n", "cttc_threshold", "=", "0.3", ")", ":", "\n", "    ", "psds", "=", "PSDSEval", "(", "dtc_threshold", ",", "gtc_threshold", ",", "cttc_threshold", ",", "ground_truth", "=", "groundtruth_df", ",", "metadata", "=", "meta_df", ")", "\n", "for", "prediction_df", "in", "list_predictions", ":", "\n", "        ", "psds", ".", "add_operating_point", "(", "prediction_df", ")", "\n", "", "return", "psds", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.evaluation_measures.compute_metrics": [[510, 518], ["evaluation_measures.compute_sed_eval_metrics", "psds_eval.PSDSEval", "psds_eval.PSDSEval.compute_macro_f_score", "logger.info", "compute_sed_eval_metrics.results_class_wise_average_metrics"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_sed_eval_metrics"], ["", "def", "compute_metrics", "(", "predictions", ",", "gtruth_df", ",", "meta_df", ")", ":", "\n", "    ", "events_metric", "=", "compute_sed_eval_metrics", "(", "predictions", ",", "gtruth_df", ")", "\n", "macro_f1_event", "=", "events_metric", ".", "results_class_wise_average_metrics", "(", ")", "[", "'f_measure'", "]", "[", "'f_measure'", "]", "\n", "dtc_threshold", ",", "gtc_threshold", ",", "cttc_threshold", "=", "0.5", ",", "0.5", ",", "0.3", "\n", "psds", "=", "PSDSEval", "(", "dtc_threshold", ",", "gtc_threshold", ",", "cttc_threshold", ",", "ground_truth", "=", "gtruth_df", ",", "metadata", "=", "meta_df", ")", "\n", "psds_macro_f1", ",", "psds_f1_classes", "=", "psds", ".", "compute_macro_f_score", "(", "predictions", ")", "\n", "logger", ".", "info", "(", "f\"F1_score (psds_eval) accounting cross triggers: {psds_macro_f1}\"", ")", "\n", "return", "macro_f1_event", ",", "psds_macro_f1", "\n", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_dual._load_model": [[28, 45], ["models.Conformer_bk.Conformer.load_state_dict", "models.Conformer_bk.Conformer.eval", "utilities.utils.to_cuda_if_available", "logger.info", "logger.info", "models.CRNN.CRNN", "models.Transformer.Transformer", "models.Conformer_bk.Conformer"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available"], ["def", "_load_model", "(", "state", ",", "model_type", ",", "model_name", "=", "\"model\"", ")", ":", "\n", "    ", "model_args", "=", "state", "[", "model_name", "]", "[", "\"args\"", "]", "\n", "model_kwargs", "=", "state", "[", "model_name", "]", "[", "\"kwargs\"", "]", "\n", "\n", "if", "model_type", "is", "'crnn'", ":", "\n", "        ", "model", "=", "CRNN", "(", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "", "elif", "model_type", "is", "'transformer'", ":", "\n", "        ", "model", "=", "Transformer", "(", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "", "elif", "model_type", "is", "'conformer'", ":", "\n", "        ", "model", "=", "Conformer", "(", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "\n", "", "model", ".", "load_state_dict", "(", "state", "[", "model_name", "]", "[", "\"state_dict\"", "]", ")", "\n", "model", ".", "eval", "(", ")", "\n", "model", "=", "to_cuda_if_available", "(", "model", ")", "\n", "logger", ".", "info", "(", "\"Model loaded at epoch: {}\"", ".", "format", "(", "state", "[", "\"epoch\"", "]", ")", ")", "\n", "logger", ".", "info", "(", "model", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_dual._load_model_v2": [[47, 67], ["models.Conformer_bk.Conformer.eval", "utilities.utils.to_cuda_if_available", "logger.info", "logger.info", "models.CRNN.CRNN", "models.Conformer_bk.Conformer.load_state_dict", "models.Transformer.Transformer", "models.Conformer_bk.Conformer.load_state_dict", "models.Conformer_bk.Conformer"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict"], ["", "def", "_load_model_v2", "(", "state", ",", "model_id", ",", "model_type", ",", "model_name", "=", "\"model\"", ")", ":", "\n", "    ", "model_args", "=", "state", "[", "model_name", "]", "[", "\"args\"", "]", "\n", "model_kwargs", "=", "state", "[", "model_name", "]", "[", "\"kwargs\"", "]", "\n", "\n", "if", "model_type", "is", "'crnn'", ":", "\n", "        ", "model", "=", "CRNN", "(", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "", "elif", "model_type", "is", "'transformer'", ":", "\n", "        ", "model", "=", "Transformer", "(", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "", "elif", "model_type", "is", "'conformer'", ":", "\n", "        ", "model", "=", "Conformer", "(", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "\n", "", "if", "model_id", "==", "1", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "state", "[", "model_name", "]", "[", "\"state_dict1\"", "]", ")", "\n", "", "elif", "model_id", "==", "2", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "state", "[", "model_name", "]", "[", "\"state_dict2\"", "]", ")", "\n", "", "model", ".", "eval", "(", ")", "\n", "model", "=", "to_cuda_if_available", "(", "model", ")", "\n", "logger", ".", "info", "(", "\"Model loaded at epoch: {}\"", ".", "format", "(", "state", "[", "\"epoch\"", "]", ")", ")", "\n", "logger", ".", "info", "(", "model", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_dual._load_scaler": [[69, 80], ["utilities.Scaler.Scaler.load_state_dict", "utilities.Scaler.ScalerPerAudio", "utilities.Scaler.Scaler", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict"], ["", "def", "_load_scaler", "(", "state", ")", ":", "\n", "    ", "scaler_state", "=", "state", "[", "\"scaler\"", "]", "\n", "type_sc", "=", "scaler_state", "[", "\"type\"", "]", "\n", "if", "type_sc", "==", "\"ScalerPerAudio\"", ":", "\n", "        ", "scaler", "=", "ScalerPerAudio", "(", "*", "scaler_state", "[", "\"args\"", "]", ")", "\n", "", "elif", "type_sc", "==", "\"Scaler\"", ":", "\n", "        ", "scaler", "=", "Scaler", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Not the right type of Scaler has been saved in state\"", ")", "\n", "", "scaler", ".", "load_state_dict", "(", "state", "[", "\"scaler\"", "]", "[", "\"state_dict\"", "]", ")", "\n", "return", "scaler", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_dual._load_state_vars": [[82, 105], ["gtruth_df.copy", "utilities.ManyHotEncoder.ManyHotEncoder.load_state_dict", "TestModel_dual._load_scaler", "TestModel_dual._load_model_v2", "utilities.Transforms.get_transforms", "utilities.Transforms.get_transforms", "data_utils.DataLoad.DataLoadDf", "torch.utils.data.DataLoader", "utilities.ManyHotEncoder.ManyHotEncoder.load_state_dict"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_dual._load_scaler", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_dual._load_model_v2", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.get_transforms", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.get_transforms", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict"], ["", "def", "_load_state_vars", "(", "state", ",", "gtruth_df", ",", "median_win", "=", "None", ")", ":", "\n", "    ", "pred_df", "=", "gtruth_df", ".", "copy", "(", ")", "\n", "# Define dataloader", "\n", "many_hot_encoder", "=", "ManyHotEncoder", ".", "load_state_dict", "(", "state", "[", "\"many_hot_encoder\"", "]", ")", "\n", "scaler", "=", "_load_scaler", "(", "state", ")", "\n", "model", "=", "_load_model_v2", "(", "state", ",", "1", ",", "'crnn'", ")", "\n", "\n", "transforms", "=", "get_transforms", "(", "cfg", ".", "max_frames", ",", "scaler", ",", "0", ",", "noise_dict_params", "=", "{", "\"mean\"", ":", "0", ",", "\"snr\"", ":", "cfg", ".", "noise_snr", "}", ")", "\n", "transforms_valid", "=", "get_transforms", "(", "cfg", ".", "max_frames", ",", "scaler", "=", "scaler", ",", "add_axis", "=", "0", ")", "\n", "\n", "strong_dataload", "=", "DataLoadDf", "(", "pred_df", ",", "many_hot_encoder", ".", "encode_strong_df", ",", "transforms_valid", ",", "return_indexes", "=", "True", ")", "\n", "strong_dataloader_ind", "=", "DataLoader", "(", "strong_dataload", ",", "batch_size", "=", "cfg", ".", "batch_size", ",", "drop_last", "=", "False", ")", "\n", "\n", "pooling_time_ratio", "=", "state", "[", "\"pooling_time_ratio\"", "]", "\n", "many_hot_encoder", "=", "ManyHotEncoder", ".", "load_state_dict", "(", "state", "[", "\"many_hot_encoder\"", "]", ")", "\n", "if", "median_win", "is", "None", ":", "\n", "        ", "median_win", "=", "state", "[", "\"median_window\"", "]", "\n", "", "return", "{", "\n", "\"model\"", ":", "model", ",", "\n", "\"dataloader\"", ":", "strong_dataloader_ind", ",", "\n", "\"pooling_time_ratio\"", ":", "pooling_time_ratio", ",", "\n", "\"many_hot_encoder\"", ":", "many_hot_encoder", ",", "\n", "\"median_window\"", ":", "median_win", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_dual.get_variables": [[108, 133], ["os.splitext", "pandas.read_csv", "os.exists", "utilities.utils.meta_path_to_audio_dir", "pandas.read_csv", "utilities.utils.generate_tsv_wav_durations", "os.dirname", "len", "utilities.utils.generate_tsv_wav_durations"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.meta_path_to_audio_dir", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.generate_tsv_wav_durations", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.generate_tsv_wav_durations"], ["", "def", "get_variables", "(", "args", ")", ":", "\n", "    ", "model_pth", "=", "args", ".", "model_path", "\n", "gt_fname", ",", "ext", "=", "osp", ".", "splitext", "(", "args", ".", "groundtruth_tsv", ")", "\n", "median_win", "=", "args", ".", "median_window", "\n", "meta_gt", "=", "args", ".", "meta_gt", "\n", "gt_audio_pth", "=", "args", ".", "groundtruth_audio_dir", "\n", "\n", "if", "meta_gt", "is", "None", ":", "\n", "        ", "meta_gt", "=", "gt_fname", "+", "\"_durations\"", "+", "ext", "\n", "\n", "", "if", "gt_audio_pth", "is", "None", ":", "\n", "        ", "gt_audio_pth", "=", "meta_path_to_audio_dir", "(", "gt_fname", ")", "\n", "# Useful because of the data format", "\n", "if", "\"validation\"", "in", "gt_audio_pth", ":", "\n", "            ", "gt_audio_pth", "=", "osp", ".", "dirname", "(", "gt_audio_pth", ")", "\n", "\n", "", "", "groundtruth", "=", "pd", ".", "read_csv", "(", "args", ".", "groundtruth_tsv", ",", "sep", "=", "\"\\t\"", ")", "\n", "if", "osp", ".", "exists", "(", "meta_gt", ")", ":", "\n", "        ", "meta_dur_df", "=", "pd", ".", "read_csv", "(", "meta_gt", ",", "sep", "=", "'\\t'", ")", "\n", "if", "len", "(", "meta_dur_df", ")", "==", "0", ":", "\n", "            ", "meta_dur_df", "=", "generate_tsv_wav_durations", "(", "gt_audio_pth", ",", "meta_gt", ")", "\n", "", "", "else", ":", "\n", "        ", "meta_dur_df", "=", "generate_tsv_wav_durations", "(", "gt_audio_pth", ",", "meta_gt", ")", "\n", "\n", "", "return", "model_pth", ",", "median_win", ",", "gt_audio_pth", ",", "groundtruth", ",", "meta_dur_df", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_ss_late_integration.norm_alpha": [[25, 27], ["None"], "function", ["None"], ["def", "norm_alpha", "(", "x", ",", "alpha_val", ")", ":", "\n", "    ", "return", "(", "(", "1", "/", "x", ".", "shape", "[", "0", "]", ")", "*", "(", "x", "**", "alpha_val", ")", ".", "sum", "(", "0", ")", ")", "**", "(", "1", "/", "alpha_val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_ss_late_integration.get_predictions_ss_late_integration": [[29, 118], ["enumerate", "pandas.DataFrame", "utilities.utils.to_cuda_if_available", "pred_strong.detach().numpy.cpu", "pred_strong.detach().numpy.detach().numpy", "TestModel_ss_late_integration.norm_alpha", "TestModel_ss_late_integration.norm_alpha", "isinstance", "enumerate", "list_predictions.append", "len", "torch.no_grad", "model", "logger.debug", "numpy.stack", "dcase_util.data.ProbabilityEncoder().binarization", "scipy.ndimage.filters.median_filter", "decoder", "pandas.DataFrame", "pred[].clip", "prediction_dfs[].append", "os.dirname", "pred_strong.detach().numpy.detach", "logger.debug", "logger.debug", "len", "os.splitext", "len", "len", "os.makedirs", "os.makedirs", "prediction_dfs[].to_csv", "dcase_util.data.ProbabilityEncoder", "os.join", "len", "len", "logger.info", "len"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_ss_late_integration.norm_alpha", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_ss_late_integration.norm_alpha"], ["", "def", "get_predictions_ss_late_integration", "(", "model", ",", "valid_dataload", ",", "decoder", ",", "pooling_time_ratio", "=", "1", ",", "thresholds", "=", "[", "0.5", "]", ",", "\n", "median_window", "=", "1", ",", "save_predictions", "=", "None", ",", "alpha", "=", "1", ")", ":", "\n", "    ", "\"\"\" Get the predictions of a trained model on a specific set\n    Args:\n        model: torch.Module, a trained pytorch model (you usually want it to be in .eval() mode).\n        valid_dataload: DataLoadDf, giving ((input_data, label), index) but label is not used here, the multiple\n            data are the multiple sources (the mixture should always be the first one to appear, and then the sources)\n            example: if the input data is (3, 1, timesteps, freq) there is the mixture and 2 sources.\n        decoder: function, takes a numpy.array of shape (time_steps, n_labels) as input and return a list of lists\n            of (\"event_label\", \"onset\", \"offset\") for each label predicted.\n        pooling_time_ratio: the division to make between timesteps as input and timesteps as output\n        median_window: int, the median window (in number of time steps) to be applied\n        save_predictions: str or list, the path of the base_filename to save the predictions or a list of names\n            corresponding for each thresholds\n        thresholds: list, list of threshold to be applied\n        alpha: float, the value of the norm to combine the predictions\n\n    Returns:\n        dict of the different predictions with associated threshold\n    \"\"\"", "\n", "\n", "# Init a dataframe per threshold", "\n", "prediction_dfs", "=", "{", "}", "\n", "for", "threshold", "in", "thresholds", ":", "\n", "        ", "prediction_dfs", "[", "threshold", "]", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "# Get predictions", "\n", "", "for", "i", ",", "(", "(", "input_data", ",", "_", ")", ",", "index", ")", "in", "enumerate", "(", "valid_dataload", ")", ":", "\n", "        ", "input_data", "=", "to_cuda_if_available", "(", "input_data", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pred_strong", ",", "_", "=", "model", "(", "input_data", ")", "\n", "", "pred_strong", "=", "pred_strong", ".", "cpu", "(", ")", "\n", "pred_strong", "=", "pred_strong", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "if", "i", "==", "0", ":", "\n", "            ", "logger", ".", "debug", "(", "pred_strong", ")", "\n", "\n", "", "pred_strong_sources", "=", "pred_strong", "[", "1", ":", "]", "\n", "pred_strong_sources", "=", "norm_alpha", "(", "pred_strong_sources", ",", "alpha", ")", "\n", "pred_strong_comb", "=", "norm_alpha", "(", "np", ".", "stack", "(", "(", "pred_strong", "[", "0", "]", ",", "pred_strong_sources", ")", ",", "0", ")", ",", "alpha", ")", "\n", "\n", "# Get different post processing per threshold", "\n", "for", "threshold", "in", "thresholds", ":", "\n", "            ", "pred_strong_bin", "=", "ProbabilityEncoder", "(", ")", ".", "binarization", "(", "pred_strong_comb", ",", "\n", "binarization_type", "=", "\"global_threshold\"", ",", "\n", "threshold", "=", "threshold", ")", "\n", "pred_strong_m", "=", "scipy", ".", "ndimage", ".", "filters", ".", "median_filter", "(", "pred_strong_bin", ",", "(", "median_window", ",", "1", ")", ")", "\n", "pred", "=", "decoder", "(", "pred_strong_m", ")", "\n", "pred", "=", "pd", ".", "DataFrame", "(", "pred", ",", "columns", "=", "[", "\"event_label\"", ",", "\"onset\"", ",", "\"offset\"", "]", ")", "\n", "# Put them in seconds", "\n", "pred", ".", "loc", "[", ":", ",", "[", "\"onset\"", ",", "\"offset\"", "]", "]", "*=", "pooling_time_ratio", "/", "(", "cfg", ".", "sample_rate", "/", "cfg", ".", "hop_size", ")", "\n", "pred", ".", "loc", "[", ":", ",", "[", "\"onset\"", ",", "\"offset\"", "]", "]", "=", "pred", "[", "[", "\"onset\"", ",", "\"offset\"", "]", "]", ".", "clip", "(", "0", ",", "cfg", ".", "max_len_seconds", ")", "\n", "\n", "pred", "[", "\"filename\"", "]", "=", "valid_dataload", ".", "filenames", ".", "iloc", "[", "index", "]", "\n", "prediction_dfs", "[", "threshold", "]", "=", "prediction_dfs", "[", "threshold", "]", ".", "append", "(", "pred", ",", "ignore_index", "=", "True", ")", "\n", "\n", "if", "i", "==", "0", ":", "\n", "                ", "logger", ".", "debug", "(", "\"predictions: \\n{}\"", ".", "format", "(", "pred", ")", ")", "\n", "logger", ".", "debug", "(", "\"predictions strong: \\n{}\"", ".", "format", "(", "pred_strong_comb", ")", ")", "\n", "\n", "# Save predictions", "\n", "", "", "", "if", "save_predictions", "is", "not", "None", ":", "\n", "        ", "if", "isinstance", "(", "save_predictions", ",", "str", ")", ":", "\n", "            ", "if", "len", "(", "thresholds", ")", "==", "1", ":", "\n", "                ", "save_predictions", "=", "[", "save_predictions", "]", "\n", "", "else", ":", "\n", "                ", "base", ",", "ext", "=", "osp", ".", "splitext", "(", "save_predictions", ")", "\n", "save_predictions", "=", "[", "osp", ".", "join", "(", "base", ",", "f\"{threshold:.3f}{ext}\"", ")", "for", "threshold", "in", "thresholds", "]", "\n", "", "", "else", ":", "\n", "            ", "assert", "len", "(", "save_predictions", ")", "==", "len", "(", "thresholds", ")", ",", "f\"There should be a prediction file per threshold: len predictions: {len(save_predictions)}\\n\"", "f\"len thresholds: {len(thresholds)}\"", "\n", "save_predictions", "=", "save_predictions", "\n", "\n", "", "for", "ind", ",", "threshold", "in", "enumerate", "(", "thresholds", ")", ":", "\n", "            ", "dir_to_create", "=", "osp", ".", "dirname", "(", "save_predictions", "[", "ind", "]", ")", "\n", "if", "dir_to_create", "!=", "\"\"", ":", "\n", "                ", "os", ".", "makedirs", "(", "dir_to_create", ",", "exist_ok", "=", "True", ")", "\n", "if", "ind", "%", "10", "==", "0", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"Saving predictions at: {save_predictions[ind]}. {ind + 1} / {len(thresholds)}\"", ")", "\n", "", "prediction_dfs", "[", "threshold", "]", ".", "to_csv", "(", "save_predictions", "[", "ind", "]", ",", "index", "=", "False", ",", "sep", "=", "\"\\t\"", ",", "float_format", "=", "\"%.3f\"", ")", "\n", "\n", "", "", "", "list_predictions", "=", "[", "]", "\n", "for", "key", "in", "prediction_dfs", ":", "\n", "        ", "list_predictions", ".", "append", "(", "prediction_dfs", "[", "key", "]", ")", "\n", "\n", "", "if", "len", "(", "list_predictions", ")", "==", "1", ":", "\n", "        ", "list_predictions", "=", "list_predictions", "[", "0", "]", "\n", "\n", "", "return", "list_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_ss_late_integration._load_state_vars": [[120, 142], ["gtruth_df.copy", "utilities.ManyHotEncoder.ManyHotEncoder.load_state_dict", "TestModel._load_scaler", "TestModel._load_crnn", "utilities.Transforms.get_transforms", "data_utils.DataLoad.DataLoadDf", "utilities.ManyHotEncoder.ManyHotEncoder.load_state_dict"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_dual._load_scaler", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.get_transforms", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict"], ["", "def", "_load_state_vars", "(", "state", ",", "gtruth_df", ",", "median_win", "=", "None", ")", ":", "\n", "    ", "pred_df", "=", "gtruth_df", ".", "copy", "(", ")", "\n", "# Define dataloader", "\n", "many_hot_encoder", "=", "ManyHotEncoder", ".", "load_state_dict", "(", "state", "[", "\"many_hot_encoder\"", "]", ")", "\n", "scaler", "=", "_load_scaler", "(", "state", ")", "\n", "crnn", "=", "_load_crnn", "(", "state", ")", "\n", "# Note, need to unsqueeze axis 1", "\n", "transforms_valid", "=", "get_transforms", "(", "cfg", ".", "max_frames", ",", "scaler", "=", "scaler", ",", "add_axis", "=", "1", ")", "\n", "\n", "# Note, no dataloader here", "\n", "strong_dataload", "=", "DataLoadDf", "(", "pred_df", ",", "many_hot_encoder", ".", "encode_strong_df", ",", "transforms_valid", ",", "return_indexes", "=", "True", ")", "\n", "\n", "pooling_time_ratio", "=", "state", "[", "\"pooling_time_ratio\"", "]", "\n", "many_hot_encoder", "=", "ManyHotEncoder", ".", "load_state_dict", "(", "state", "[", "\"many_hot_encoder\"", "]", ")", "\n", "if", "median_win", "is", "None", ":", "\n", "        ", "median_win", "=", "state", "[", "\"median_window\"", "]", "\n", "", "return", "{", "\n", "\"model\"", ":", "crnn", ",", "\n", "\"dataload\"", ":", "strong_dataload", ",", "\n", "\"pooling_time_ratio\"", ":", "pooling_time_ratio", ",", "\n", "\"many_hot_encoder\"", ":", "many_hot_encoder", ",", "\n", "\"median_window\"", ":", "median_win", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.DCASE2020_baseline_platform.TestModel_ss_late_integration.get_variables": [[145, 172], ["os.splitext", "os.exists", "utilities.utils.meta_path_to_audio_dir", "pandas.read_csv", "utilities.utils.generate_tsv_wav_durations", "keep_sources.split.split", "os.dirname", "len", "utilities.utils.generate_tsv_wav_durations"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.meta_path_to_audio_dir", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.generate_tsv_wav_durations", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.generate_tsv_wav_durations"], ["", "def", "get_variables", "(", "args", ")", ":", "\n", "    ", "model_pth", "=", "args", ".", "model_path", "\n", "gt_fname", ",", "ext", "=", "osp", ".", "splitext", "(", "args", ".", "groundtruth_tsv", ")", "\n", "median_win", "=", "args", ".", "median_window", "\n", "meta_gt", "=", "args", ".", "meta_gt", "\n", "gt_audio_pth", "=", "args", ".", "groundtruth_audio_dir", "\n", "\n", "if", "meta_gt", "is", "None", ":", "\n", "        ", "meta_gt", "=", "gt_fname", "+", "\"_durations\"", "+", "ext", "\n", "\n", "", "if", "gt_audio_pth", "is", "None", ":", "\n", "        ", "gt_audio_pth", "=", "meta_path_to_audio_dir", "(", "gt_fname", ")", "\n", "# Useful because of the data format", "\n", "if", "\"validation\"", "in", "gt_audio_pth", ":", "\n", "            ", "gt_audio_pth", "=", "osp", ".", "dirname", "(", "gt_audio_pth", ")", "\n", "\n", "", "", "if", "osp", ".", "exists", "(", "meta_gt", ")", ":", "\n", "        ", "meta_dur_df", "=", "pd", ".", "read_csv", "(", "meta_gt", ",", "sep", "=", "'\\t'", ")", "\n", "if", "len", "(", "meta_dur_df", ")", "==", "0", ":", "\n", "            ", "meta_dur_df", "=", "generate_tsv_wav_durations", "(", "gt_audio_pth", ",", "meta_gt", ")", "\n", "", "", "else", ":", "\n", "        ", "meta_dur_df", "=", "generate_tsv_wav_durations", "(", "gt_audio_pth", ",", "meta_gt", ")", "\n", "", "keep_sources", "=", "args", ".", "keep_sources", "\n", "if", "keep_sources", "is", "not", "None", ":", "\n", "        ", "keep_sources", "=", "keep_sources", ".", "split", "(", "\",\"", ")", "\n", "\n", "", "return", "model_pth", ",", "median_win", ",", "gt_audio_pth", ",", "meta_dur_df", ",", "keep_sources", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.__init__": [[80, 106], ["os.join", "os.join", "os.join", "os.join", "os.join", "os.join", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "base_feature_dir", "=", "\"features\"", ",", "recompute_features", "=", "False", ",", "compute_log", "=", "True", ")", ":", "\n", "# Parameters, they're kept if we need to reproduce the dataset", "\n", "        ", "self", ".", "sample_rate", "=", "cfg", ".", "sample_rate", "\n", "self", ".", "n_window", "=", "cfg", ".", "n_window", "\n", "self", ".", "hop_size", "=", "cfg", ".", "hop_size", "\n", "self", ".", "n_mels", "=", "cfg", ".", "n_mels", "\n", "self", ".", "mel_min_max_freq", "=", "(", "cfg", ".", "mel_f_min", ",", "cfg", ".", "mel_f_max", ")", "\n", "\n", "# Defined parameters", "\n", "self", ".", "recompute_features", "=", "recompute_features", "\n", "self", ".", "compute_log", "=", "compute_log", "\n", "\n", "# Feature dir to not have the same name with different parameters", "\n", "ext_freq", "=", "''", "\n", "if", "self", ".", "mel_min_max_freq", "!=", "(", "0", ",", "self", ".", "sample_rate", "/", "2", ")", ":", "\n", "            ", "ext_freq", "=", "f\"_{'_'.join(self.mel_min_max_freq)}\"", "\n", "", "feature_dir", "=", "osp", ".", "join", "(", "base_feature_dir", ",", "f\"sr{self.sample_rate}_win{self.n_window}_hop{self.hop_size}\"", "\n", "f\"_mels{self.n_mels}{ext_freq}\"", ")", "\n", "if", "not", "self", ".", "compute_log", ":", "\n", "            ", "feature_dir", "+=", "\"_nolog\"", "\n", "\n", "", "self", ".", "feature_dir", "=", "osp", ".", "join", "(", "feature_dir", ",", "\"features\"", ")", "\n", "self", ".", "meta_feat_dir", "=", "osp", ".", "join", "(", "feature_dir", ",", "\"metadata\"", ")", "\n", "# create folder if not exist", "\n", "os", ".", "makedirs", "(", "self", ".", "feature_dir", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "meta_feat_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.state_dict": [[107, 123], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\" get the important parameters to save for the class\n        Returns:\n            dict\n        \"\"\"", "\n", "parameters", "=", "{", "\n", "\"feature_dir\"", ":", "self", ".", "feature_dir", ",", "\n", "\"meta_feat_dir\"", ":", "self", ".", "meta_feat_dir", ",", "\n", "\"compute_log\"", ":", "self", ".", "compute_log", ",", "\n", "\"sample_rate\"", ":", "self", ".", "sample_rate", ",", "\n", "\"n_window\"", ":", "self", ".", "n_window", ",", "\n", "\"hop_size\"", ":", "self", ".", "hop_size", ",", "\n", "\"n_mels\"", ":", "self", ".", "n_mels", ",", "\n", "\"mel_min_max_freq\"", ":", "self", ".", "mel_min_max_freq", "\n", "}", "\n", "return", "parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.load_state_dict": [[124, 142], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "load_state_dict", "(", "cls", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\" load the dataset from previously saved parameters\n        Args:\n            state_dict: dict, parameter saved with state_dict function\n        Returns:\n            DESED class object with the right parameters\n        \"\"\"", "\n", "desed_obj", "=", "cls", "(", ")", "\n", "desed_obj", ".", "feature_dir", "=", "state_dict", "[", "\"feature_dir\"", "]", "\n", "desed_obj", ".", "meta_feat_dir", "=", "state_dict", "[", "\"meta_feat_dir\"", "]", "\n", "desed_obj", ".", "compute_log", "=", "state_dict", "[", "\"compute_log\"", "]", "\n", "desed_obj", ".", "sample_rate", "=", "state_dict", "[", "\"sample_rate\"", "]", "\n", "desed_obj", ".", "n_window", "=", "state_dict", "[", "\"n_window\"", "]", "\n", "desed_obj", ".", "hop_size", "=", "state_dict", "[", "\"hop_size\"", "]", "\n", "desed_obj", ".", "n_mels", "=", "state_dict", "[", "\"n_mels\"", "]", "\n", "desed_obj", ".", "mel_min_max_freq", "=", "state_dict", "[", "\"mel_min_max_freq\"", "]", "\n", "return", "desed_obj", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.initialize_and_get_df": [[143, 210], ["os.exists", "os.exists", "os.sep.join", "os.sep.join", "os.join", "os.join", "os.join", "os.join", "logger.debug", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "Desed.DESED.get_df_from_meta", "logger.info", "os.splitext", "os.splitext", "os.join", "os.join", "time.time", "logger.info", "Desed.DESED.extract_features_from_df", "os.exists", "os.exists", "utilities.utils.meta_path_to_audio_dir", "fdir.endswith", "Desed.DESED.filename.drop_duplicates", "Desed.DESED.download", "os.basename", "os.basename", "len", "logger.info", "IndexError", "fdir.split", "len", "Desed.DESED.filename.unique", "time.time"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.get_df_from_meta", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.extract_features_from_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.meta_path_to_audio_dir", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.download"], ["", "def", "initialize_and_get_df", "(", "self", ",", "tsv_path", ",", "audio_dir", "=", "None", ",", "audio_dir_ss", "=", "None", ",", "pattern_ss", "=", "None", ",", "\n", "ext_ss_feature_file", "=", "\"_ss\"", ",", "nb_files", "=", "None", ",", "download", "=", "False", ",", "keep_sources", "=", "None", ")", ":", "\n", "        ", "\"\"\" Initialize the dataset, extract the features dataframes\n        Args:\n            tsv_path: str, tsv path in the initial dataset\n            audio_dir: str, the path where to search the filename of the df\n            audio_dir_ss: str, the path where to search the separated_sources\n            pattern_ss: str, only when audio_dir_ss is not None, this should be defined. The pattern that's added\n                after normal filenames to get associated separated sources (have been done during source separation)\n            ext_ss_feature_file: str, only when audio_dir_ss is not None, what to add at the end of the feature files\n            nb_files: int, optional, the number of file to take in the dataframe if taking a small part of the dataset.\n            download: bool, optional, whether or not to download the data from the internet (youtube).\n            keep_sources: list, if sound_separation is used, it indicates which source is kept to create the features\n\n        Returns:\n            pd.DataFrame\n            The dataframe containing the right features and labels\n        \"\"\"", "\n", "# Check parameters", "\n", "if", "audio_dir_ss", "is", "not", "None", ":", "\n", "            ", "assert", "osp", ".", "exists", "(", "audio_dir_ss", ")", ",", "f\"the directory of separated sources: {audio_dir_ss} does not exist, \"", "f\"cannot extract features from it\"", "\n", "if", "pattern_ss", "is", "None", ":", "\n", "               ", "pattern_ss", "=", "\"_events\"", "\n", "", "", "if", "audio_dir", "is", "None", ":", "\n", "            ", "audio_dir", "=", "meta_path_to_audio_dir", "(", "tsv_path", ")", "\n", "", "assert", "osp", ".", "exists", "(", "audio_dir", ")", ",", "f\"the directory {audio_dir} does not exist\"", "\n", "\n", "# Path to save features, subdir, otherwise could have duplicate paths for synthetic data", "\n", "fdir", "=", "audio_dir", "if", "audio_dir_ss", "is", "None", "else", "audio_dir_ss", "\n", "fdir", "=", "fdir", "[", ":", "-", "1", "]", "if", "fdir", ".", "endswith", "(", "osp", ".", "sep", ")", "else", "fdir", "\n", "subdir", "=", "osp", ".", "sep", ".", "join", "(", "fdir", ".", "split", "(", "osp", ".", "sep", ")", "[", "-", "2", ":", "]", ")", "\n", "meta_feat_dir", "=", "osp", ".", "join", "(", "self", ".", "meta_feat_dir", ",", "subdir", ")", "\n", "feature_dir", "=", "osp", ".", "join", "(", "self", ".", "feature_dir", ",", "subdir", ")", "\n", "logger", ".", "debug", "(", "feature_dir", ")", "\n", "os", ".", "makedirs", "(", "meta_feat_dir", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "feature_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "df_meta", "=", "self", ".", "get_df_from_meta", "(", "tsv_path", ",", "nb_files", ",", "pattern_ss", "=", "pattern_ss", ")", "\n", "logger", ".", "info", "(", "f\"{tsv_path} Total file number: {len(df_meta.filename.unique())}\"", ")", "\n", "# Download real data", "\n", "if", "download", ":", "# Get only one filename once", "\n", "            ", "filenames", "=", "df_meta", ".", "filename", ".", "drop_duplicates", "(", ")", "\n", "self", ".", "download", "(", "filenames", ",", "audio_dir", ")", "\n", "\n", "# Meta filename", "\n", "", "ext_tsv_feature", "=", "\"\"", "\n", "if", "audio_dir_ss", "is", "not", "None", ":", "\n", "            ", "ext_tsv_feature", "=", "ext_ss_feature_file", "\n", "", "fname", ",", "ext", "=", "osp", ".", "splitext", "(", "osp", ".", "basename", "(", "tsv_path", ")", ")", "\n", "feat_fname", "=", "fname", "+", "ext_tsv_feature", "+", "ext", "\n", "if", "nb_files", "is", "not", "None", ":", "\n", "            ", "feat_fname", "=", "f\"{nb_files}_{feat_fname}\"", "\n", "", "features_tsv", "=", "osp", ".", "join", "(", "meta_feat_dir", ",", "feat_fname", ")", "\n", "\n", "# if not osp.exists(features_tsv):", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "logger", ".", "info", "(", "f\"Getting features ...\"", ")", "\n", "df_features", "=", "self", ".", "extract_features_from_df", "(", "df_meta", ",", "audio_dir", ",", "feature_dir", ",", "\n", "audio_dir_ss", ",", "pattern_ss", ",", "\n", "ext_ss_feature_file", ",", "keep_sources", ")", "\n", "if", "len", "(", "df_features", ")", "!=", "0", ":", "\n", "#df_features.to_csv(features_tsv, sep=\"\\t\", index=False)", "\n", "            ", "logger", ".", "info", "(", "f\"features created/retrieved in {time.time() - t:.2f}s, metadata: {features_tsv}\"", ")", "\n", "", "else", ":", "\n", "            ", "raise", "IndexError", "(", "f\"Empty features DataFrames {features_tsv}\"", ")", "\n", "", "return", "df_features", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.calculate_mel_spec": [[212, 251], ["numpy.hamming", "scipy.lfilter", "librosa.stft", "librosa.feature.melspectrogram", "librosa.amplitude_to_db.astype", "librosa.amplitude_to_db", "numpy.abs"], "methods", ["None"], ["", "def", "calculate_mel_spec", "(", "self", ",", "audio", ",", "compute_log", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Calculate a mal spectrogram from raw audio waveform\n        Note: The parameters of the spectrograms are in the config.py file.\n        Args:\n            audio : numpy.array, raw waveform to compute the spectrogram\n            compute_log: bool, whether to get the output in dB (log scale) or not\n\n        Returns:\n            numpy.array\n            containing the mel spectrogram\n        \"\"\"", "\n", "# Compute spectrogram", "\n", "ham_win", "=", "np", ".", "hamming", "(", "self", ".", "n_window", ")", "\n", "\n", "# preemphasis", "\n", "audio", "=", "sp", ".", "lfilter", "(", "[", "1", ",", "-", "0.97", "]", ",", "[", "1", "]", ",", "audio", ")", "\n", "\n", "spec", "=", "librosa", ".", "stft", "(", "\n", "audio", ",", "\n", "n_fft", "=", "self", ".", "n_window", ",", "\n", "hop_length", "=", "self", ".", "hop_size", ",", "\n", "window", "=", "ham_win", ",", "\n", "center", "=", "True", ",", "\n", "pad_mode", "=", "'reflect'", "\n", ")", "\n", "\n", "mel_spec", "=", "librosa", ".", "feature", ".", "melspectrogram", "(", "\n", "S", "=", "np", ".", "abs", "(", "spec", ")", ",", "# amplitude, for energy: spec**2 but don't forget to change amplitude_to_db.", "\n", "sr", "=", "self", ".", "sample_rate", ",", "\n", "n_mels", "=", "self", ".", "n_mels", ",", "\n", "fmin", "=", "self", ".", "mel_min_max_freq", "[", "0", "]", ",", "fmax", "=", "self", ".", "mel_min_max_freq", "[", "1", "]", ",", "\n", "htk", "=", "False", ",", "norm", "=", "None", ")", "\n", "\n", "if", "compute_log", ":", "\n", "            ", "mel_spec", "=", "librosa", ".", "amplitude_to_db", "(", "mel_spec", ")", "# 10 * log10(S**2 / ref), ref default is 1", "\n", "", "mel_spec", "=", "mel_spec", ".", "T", "\n", "mel_spec", "=", "mel_spec", ".", "astype", "(", "np", ".", "float32", ")", "\n", "return", "mel_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.load_and_compute_mel_spec": [[252, 261], ["utilities.utils.read_audio", "IOError", "time.time", "Desed.DESED.calculate_mel_spec", "logger.debug", "time.time"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.read_audio", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.calculate_mel_spec"], ["", "def", "load_and_compute_mel_spec", "(", "self", ",", "wav_path", ")", ":", "\n", "        ", "(", "audio", ",", "_", ")", "=", "read_audio", "(", "wav_path", ",", "self", ".", "sample_rate", ")", "\n", "if", "audio", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "            ", "raise", "IOError", "(", "\"File {wav_path} is corrupted!\"", ")", "\n", "", "else", ":", "\n", "            ", "t1", "=", "time", ".", "time", "(", ")", "\n", "mel_spec", "=", "self", ".", "calculate_mel_spec", "(", "audio", ",", "self", ".", "compute_log", ")", "\n", "logger", ".", "debug", "(", "f\"compute features time: {time.time() - t1}\"", ")", "\n", "", "return", "mel_spec", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED._extract_features": [[262, 270], ["os.exists", "os.exists", "Desed.DESED.load_and_compute_mel_spec", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "numpy.save", "os.dirname", "os.dirname", "logger.error"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.load_and_compute_mel_spec", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save"], ["", "def", "_extract_features", "(", "self", ",", "wav_path", ",", "out_path", ")", ":", "\n", "        ", "if", "not", "osp", ".", "exists", "(", "out_path", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "mel_spec", "=", "self", ".", "load_and_compute_mel_spec", "(", "wav_path", ")", "\n", "os", ".", "makedirs", "(", "osp", ".", "dirname", "(", "out_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "np", ".", "save", "(", "out_path", ",", "mel_spec", ")", "\n", "", "except", "IOError", "as", "e", ":", "\n", "                ", "logger", ".", "error", "(", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED._extract_features_ss": [[271, 281], ["numpy.expand_dims", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "numpy.save", "Desed.DESED.load_and_compute_mel_spec", "numpy.expand_dims", "numpy.concatenate", "os.dirname", "os.dirname", "logger.error", "Desed.DESED.load_and_compute_mel_spec"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.load_and_compute_mel_spec", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.load_and_compute_mel_spec"], ["", "", "", "def", "_extract_features_ss", "(", "self", ",", "wav_path", ",", "wav_paths_ss", ",", "out_path", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "features", "=", "np", ".", "expand_dims", "(", "self", ".", "load_and_compute_mel_spec", "(", "wav_path", ")", ",", "axis", "=", "0", ")", "\n", "for", "wav_path_ss", "in", "wav_paths_ss", ":", "\n", "                ", "sep_features", "=", "np", ".", "expand_dims", "(", "self", ".", "load_and_compute_mel_spec", "(", "wav_path_ss", ")", ",", "axis", "=", "0", ")", "\n", "features", "=", "np", ".", "concatenate", "(", "(", "features", ",", "sep_features", ")", ")", "\n", "", "os", ".", "makedirs", "(", "osp", ".", "dirname", "(", "out_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "np", ".", "save", "(", "out_path", ",", "features", ")", "\n", "", "except", "IOError", "as", "e", ":", "\n", "            ", "logger", ".", "error", "(", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED._extract_features_file": [[282, 312], ["os.join", "os.join", "os.isfile", "os.isfile", "logger.error", "os.join", "os.join", "os.join", "os.join", "Desed.DESED._extract_features", "os.join", "os.join", "os.join", "os.join", "os.splitext", "os.splitext", "glob.glob", "os.exists", "os.exists", "Desed.DESED._extract_features_ss", "os.join", "os.join", "os.join", "os.join", "os.exists", "os.exists", "glob.glob.append", "os.splitext", "os.splitext", "os.splitext", "os.splitext"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED._extract_features", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED._extract_features_ss"], ["", "", "def", "_extract_features_file", "(", "self", ",", "filename", ",", "audio_dir", ",", "feature_dir", ",", "audio_dir_ss", "=", "None", ",", "pattern_ss", "=", "None", ",", "\n", "ext_ss_feature_file", "=", "\"_ss\"", ",", "keep_sources", "=", "None", ")", ":", "\n", "        ", "wav_path", "=", "osp", ".", "join", "(", "audio_dir", ",", "filename", ")", "\n", "if", "not", "osp", ".", "isfile", "(", "wav_path", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"File %s is in the tsv file but the feature is not extracted because \"", "\n", "\"file do not exist!\"", "%", "wav_path", ")", "\n", "out_path", "=", "None", "\n", "# df_meta = df_meta.drop(df_meta[df_meta.filename == filename].index)", "\n", "", "else", ":", "\n", "            ", "if", "audio_dir_ss", "is", "None", ":", "\n", "                ", "out_filename", "=", "osp", ".", "join", "(", "osp", ".", "splitext", "(", "filename", ")", "[", "0", "]", "+", "\".npy\"", ")", "\n", "out_path", "=", "osp", ".", "join", "(", "feature_dir", ",", "out_filename", ")", "\n", "self", ".", "_extract_features", "(", "wav_path", ",", "out_path", ")", "\n", "", "else", ":", "\n", "# To be changed if you have new separated sounds from the same mixture", "\n", "                ", "out_filename", "=", "osp", ".", "join", "(", "osp", ".", "splitext", "(", "filename", ")", "[", "0", "]", "+", "ext_ss_feature_file", "+", "\".npy\"", ")", "\n", "out_path", "=", "osp", ".", "join", "(", "feature_dir", ",", "out_filename", ")", "\n", "bname", ",", "ext", "=", "osp", ".", "splitext", "(", "filename", ")", "\n", "if", "keep_sources", "is", "None", ":", "\n", "                    ", "wav_paths_ss", "=", "glob", ".", "glob", "(", "osp", ".", "join", "(", "audio_dir_ss", ",", "bname", "+", "pattern_ss", ",", "\"*\"", "+", "ext", ")", ")", "\n", "", "else", ":", "\n", "                    ", "wav_paths_ss", "=", "[", "]", "\n", "for", "s_ind", "in", "keep_sources", ":", "\n", "                        ", "audio_file", "=", "osp", ".", "join", "(", "audio_dir_ss", ",", "bname", "+", "pattern_ss", ",", "s_ind", "+", "ext", ")", "\n", "assert", "osp", ".", "exists", "(", "audio_file", ")", ",", "f\"Audio file does not exists: {audio_file}\"", "\n", "wav_paths_ss", ".", "append", "(", "audio_file", ")", "\n", "", "", "if", "not", "osp", ".", "exists", "(", "out_path", ")", ":", "\n", "                    ", "self", ".", "_extract_features_ss", "(", "wav_path", ",", "wav_paths_ss", ",", "out_path", ")", "\n", "\n", "", "", "", "return", "filename", ",", "out_path", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.extract_features_from_df": [[313, 353], ["pandas.DataFrame", "fpaths.drop_duplicates().to_list", "functools.partial", "logger.info", "df_features.append.append.reset_index", "bool", "bool", "NotImplementedError", "multiprocessing.cpu_count", "contextlib.closing", "tqdm.tqdm.tqdm", "fpaths.drop_duplicates", "multiprocessing.Pool", "p.imap_unordered", "df_features.append.append.append", "len"], "methods", ["None"], ["", "def", "extract_features_from_df", "(", "self", ",", "df_meta", ",", "audio_dir", ",", "feature_dir", ",", "audio_dir_ss", "=", "None", ",", "pattern_ss", "=", "None", ",", "\n", "ext_ss_feature_file", "=", "\"_ss\"", ",", "keep_sources", "=", "None", ")", ":", "\n", "        ", "\"\"\"Extract log mel spectrogram features.\n\n        Args:\n            df_meta : pd.DataFrame, containing at least column \"filename\" with name of the wav to compute features\n            audio_dir: str, the path where to find the wav files specified by the dataframe\n            feature_dir: str, the path where to search and save the features.\n            audio_dir_ss: str, the path where to find the separated files (associated to the mixture)\n            pattern_ss: str, the pattern following the normal filename to match the folder to find separated sources\n            ext_ss_feature_file: str, only when audio_dir_ss is not None\n            keep_sources: list, the index of the sources to be kept if sound separation is used\n\n        Returns:\n            pd.DataFrame containing the initial meta + column with the \"feature_filename\"\n        \"\"\"", "\n", "if", "bool", "(", "audio_dir_ss", ")", "!=", "bool", "(", "pattern_ss", ")", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"if audio_dir_ss is not None, you must specify a pattern_ss\"", ")", "\n", "\n", "", "df_features", "=", "pd", ".", "DataFrame", "(", ")", "\n", "fpaths", "=", "df_meta", "[", "\"filename\"", "]", "\n", "uniq_fpaths", "=", "fpaths", ".", "drop_duplicates", "(", ")", ".", "to_list", "(", ")", "\n", "\n", "extract_file_func", "=", "functools", ".", "partial", "(", "self", ".", "_extract_features_file", ",", "\n", "audio_dir", "=", "audio_dir", ",", "\n", "feature_dir", "=", "feature_dir", ",", "\n", "audio_dir_ss", "=", "audio_dir_ss", ",", "\n", "pattern_ss", "=", "pattern_ss", ",", "\n", "ext_ss_feature_file", "=", "ext_ss_feature_file", ",", "\n", "keep_sources", "=", "keep_sources", ")", "\n", "\n", "n_jobs", "=", "multiprocessing", ".", "cpu_count", "(", ")", "-", "1", "\n", "logger", ".", "info", "(", "f\"Using {n_jobs} cpus\"", ")", "\n", "with", "closing", "(", "multiprocessing", ".", "Pool", "(", "n_jobs", ")", ")", "as", "p", ":", "\n", "            ", "for", "filename", ",", "out_path", "in", "tqdm", "(", "p", ".", "imap_unordered", "(", "extract_file_func", ",", "uniq_fpaths", ",", "200", ")", ",", "total", "=", "len", "(", "uniq_fpaths", ")", ")", ":", "\n", "                ", "row_features", "=", "df_meta", "[", "df_meta", ".", "filename", "==", "filename", "]", "\n", "row_features", ".", "loc", "[", ":", ",", "\"feature_filename\"", "]", "=", "out_path", "\n", "df_features", "=", "df_features", ".", "append", "(", "row_features", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "", "return", "df_features", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.get_classes": [[354, 367], ["list", "set", "classes.extend", "df[].dropna().unique", "classes.extend", "df.event_labels.str.split().unstack().dropna().unique", "df[].dropna", "df.event_labels.str.split().unstack().dropna", "df.event_labels.str.split().unstack", "df.event_labels.str.split"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_classes", "(", "list_dfs", ")", ":", "\n", "        ", "\"\"\" Get the different classes of the dataset\n        Returns:\n            A list containing the classes\n        \"\"\"", "\n", "classes", "=", "[", "]", "\n", "for", "df", "in", "list_dfs", ":", "\n", "            ", "if", "\"event_label\"", "in", "df", ".", "columns", ":", "\n", "                ", "classes", ".", "extend", "(", "df", "[", "\"event_label\"", "]", ".", "dropna", "(", ")", ".", "unique", "(", ")", ")", "# dropna avoid the issue between string and float", "\n", "", "elif", "\"event_labels\"", "in", "df", ".", "columns", ":", "\n", "                ", "classes", ".", "extend", "(", "df", ".", "event_labels", ".", "str", ".", "split", "(", "','", ",", "expand", "=", "True", ")", ".", "unstack", "(", ")", ".", "dropna", "(", ")", ".", "unique", "(", ")", ")", "\n", "", "", "return", "list", "(", "set", "(", "classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.get_subpart_data": [[368, 397], ["logger.debug", "len", "df[].apply", "df[].drop_duplicates.drop_duplicates", "df[].drop_duplicates.sort_values().sample", "df[].reset_index", "df[].drop_duplicates", "df[].drop_duplicates.sort_values().sample", "df[].reset_index", "df[].unique", "df[].drop_duplicates.sort_values", "df[].drop_duplicates.sort_values", "len", "x.split", "df[].apply().isin", "df[].isin", "df[].apply", "x.split"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.EarlyStopping.apply", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.EarlyStopping.apply"], ["", "@", "staticmethod", "\n", "def", "get_subpart_data", "(", "df", ",", "nb_files", ",", "pattern_ss", "=", "None", ")", ":", "\n", "        ", "\"\"\"Get a subpart of a dataframe (only the number of files specified)\n        Args:\n            df : pd.DataFrame, the dataframe to extract a subpart of it (nb of filenames)\n            nb_files: int, the number of file to take in the dataframe if taking a small part of the dataset.\n            pattern_ss: str, if nb_files is not None, the pattern is needed to get same ss than soundscapes\n        Returns:\n            pd.DataFrame containing the only the number of files specified\n        \"\"\"", "\n", "column", "=", "\"filename\"", "\n", "if", "not", "nb_files", ">", "len", "(", "df", "[", "column", "]", ".", "unique", "(", ")", ")", ":", "\n", "            ", "if", "pattern_ss", "is", "not", "None", ":", "\n", "                ", "filenames", "=", "df", "[", "column", "]", ".", "apply", "(", "lambda", "x", ":", "x", ".", "split", "(", "pattern_ss", ")", "[", "0", "]", ")", "\n", "filenames", "=", "filenames", ".", "drop_duplicates", "(", ")", "\n", "# sort_values and random_state are used to have the same filenames each time (also for normal and ss)", "\n", "filenames_kept", "=", "filenames", ".", "sort_values", "(", ")", ".", "sample", "(", "nb_files", ",", "random_state", "=", "10", ")", "\n", "df_kept", "=", "df", "[", "df", "[", "column", "]", ".", "apply", "(", "lambda", "x", ":", "x", ".", "split", "(", "pattern_ss", ")", "[", "0", "]", ")", ".", "isin", "(", "filenames_kept", ")", "]", ".", "reset_index", "(", "\n", "drop", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "filenames", "=", "df", "[", "column", "]", ".", "drop_duplicates", "(", ")", "\n", "# sort_values and random_state are used to have the same filenames each time (also for normal and ss)", "\n", "filenames_kept", "=", "filenames", ".", "sort_values", "(", ")", ".", "sample", "(", "nb_files", ",", "random_state", "=", "10", ")", "\n", "df_kept", "=", "df", "[", "df", "[", "column", "]", ".", "isin", "(", "filenames_kept", ")", "]", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "", "logger", ".", "debug", "(", "f\"Taking subpart of the data, len : {nb_files}, df_len: {len(df)}\"", ")", "\n", "", "else", ":", "\n", "            ", "df_kept", "=", "df", "\n", "", "return", "df_kept", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.get_df_from_meta": [[398, 414], ["pandas.read_csv", "Desed.DESED.get_subpart_data"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.get_subpart_data"], ["", "@", "staticmethod", "\n", "def", "get_df_from_meta", "(", "meta_name", ",", "nb_files", "=", "None", ",", "pattern_ss", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Extract a pandas dataframe from a tsv file\n\n        Args:\n            meta_name : str, path of the tsv file to extract the df\n            nb_files: int, the number of file to take in the dataframe if taking a small part of the dataset.\n            pattern_ss: str, if nb_files is not None, the pattern is needed to get same ss than soundscapes\n        Returns:\n            dataframe\n        \"\"\"", "\n", "df", "=", "pd", ".", "read_csv", "(", "meta_name", ",", "header", "=", "0", ",", "sep", "=", "\"\\t\"", ")", "\n", "if", "nb_files", "is", "not", "None", ":", "\n", "            ", "df", "=", "DESED", ".", "get_subpart_data", "(", "df", ",", "nb_files", ",", "pattern_ss", "=", "pattern_ss", ")", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.download": [[415, 427], ["desed.download_real.download"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.Desed.DESED.download"], ["", "@", "staticmethod", "\n", "def", "download", "(", "filenames", ",", "audio_dir", ",", "n_jobs", "=", "3", ",", "chunk_size", "=", "10", ")", ":", "\n", "        ", "\"\"\"\n        Download files contained in a list of filenames\n\n        Args:\n            filenames: list or pd.Series, filenames of files to be downloaded ()\n            audio_dir: str, the directory where the wav file should be downloaded (if not exist)\n            chunk_size: int, (Default value = 10) number of files to download in a chunk\n            n_jobs : int, (Default value = 3) number of parallel jobs\n        \"\"\"", "\n", "desed", ".", "download_real", ".", "download", "(", "filenames", ",", "audio_dir", ",", "n_jobs", "=", "n_jobs", ",", "chunk_size", "=", "chunk_size", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.DataLoadDf.__init__": [[39, 49], ["df.feature_filename.drop_duplicates", "df.filename.drop_duplicates"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "df", ",", "encode_function", "=", "None", ",", "transform", "=", "None", ",", "return_indexes", "=", "False", ",", "in_memory", "=", "False", ")", ":", "\n", "        ", "self", ".", "df", "=", "df", "\n", "self", ".", "encode_function", "=", "encode_function", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "return_indexes", "=", "return_indexes", "\n", "self", ".", "feat_filenames", "=", "df", ".", "feature_filename", ".", "drop_duplicates", "(", ")", "\n", "self", ".", "filenames", "=", "df", ".", "filename", ".", "drop_duplicates", "(", ")", "\n", "self", ".", "in_memory", "=", "in_memory", "\n", "if", "self", ".", "in_memory", ":", "\n", "            ", "self", ".", "features", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.DataLoadDf.set_return_indexes": [[50, 56], ["None"], "methods", ["None"], ["", "", "def", "set_return_indexes", "(", "self", ",", "val", ")", ":", "\n", "        ", "\"\"\" Set the value of self.return_indexes\n        Args:\n            val : bool, whether or not to return indexes when use __getitem__\n        \"\"\"", "\n", "self", ".", "return_indexes", "=", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.DataLoadDf.get_feature_file_func": [[57, 75], ["numpy.load().astype", "DataLoad.DataLoadDf.features.get", "numpy.load().astype", "numpy.load", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.load", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.load"], ["", "def", "get_feature_file_func", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"\"\"Get a feature file from a filename\n        Args:\n            filename:  str, name of the file to get the feature\n\n        Returns:\n            numpy.array\n            containing the features computed previously\n        \"\"\"", "\n", "if", "not", "self", ".", "in_memory", ":", "\n", "            ", "data", "=", "np", ".", "load", "(", "filename", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "features", ".", "get", "(", "filename", ")", "is", "None", ":", "\n", "                ", "data", "=", "np", ".", "load", "(", "filename", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "self", ".", "features", "[", "filename", "]", "=", "data", "\n", "", "else", ":", "\n", "                ", "data", "=", "self", ".", "features", "[", "filename", "]", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.DataLoadDf.__len__": [[76, 84], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns:\n            int\n                Length of the object\n        \"\"\"", "\n", "length", "=", "len", "(", "self", ".", "feat_filenames", ")", "\n", "return", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.DataLoadDf.get_sample": [[85, 132], ["DataLoad.DataLoadDf.get_feature_file_func", "len", "logger.debug", "DataLoad.DataLoadDf.encode_function", "pandas.isna", "NotImplementedError", "type", "label.split.split.split"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.DataLoadDf.get_feature_file_func"], ["", "def", "get_sample", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"From an index, get the features and the labels to create a sample\n\n        Args:\n            index: int, Index of the sample desired\n\n        Returns:\n            tuple\n            Tuple containing the features and the labels (numpy.array, numpy.array)\n\n        \"\"\"", "\n", "features", "=", "self", ".", "get_feature_file_func", "(", "self", ".", "feat_filenames", ".", "iloc", "[", "index", "]", ")", "\n", "if", "len", "(", "features", ")", "==", "1", ":", "\n", "            ", "features", "=", "features", "[", "0", "]", "\n", "\n", "# event_labels means weak labels, event_label means strong labels", "\n", "", "if", "\"event_labels\"", "in", "self", ".", "df", ".", "columns", "or", "{", "\"onset\"", ",", "\"offset\"", ",", "\"event_label\"", "}", ".", "issubset", "(", "self", ".", "df", ".", "columns", ")", ":", "\n", "            ", "if", "\"event_labels\"", "in", "self", ".", "df", ".", "columns", ":", "\n", "                ", "label", "=", "self", ".", "df", ".", "iloc", "[", "index", "]", "[", "\"event_labels\"", "]", "\n", "if", "pd", ".", "isna", "(", "label", ")", ":", "\n", "                    ", "label", "=", "[", "]", "\n", "", "if", "type", "(", "label", ")", "is", "str", ":", "\n", "                    ", "if", "label", "==", "\"\"", ":", "\n", "                        ", "label", "=", "[", "]", "\n", "", "else", ":", "\n", "                        ", "label", "=", "label", ".", "split", "(", "\",\"", ")", "\n", "", "", "", "else", ":", "\n", "                ", "cols", "=", "[", "\"onset\"", ",", "\"offset\"", ",", "\"event_label\"", "]", "\n", "label", "=", "self", ".", "df", "[", "self", ".", "df", ".", "filename", "==", "self", ".", "filenames", ".", "iloc", "[", "index", "]", "]", "[", "cols", "]", "\n", "if", "label", ".", "empty", ":", "\n", "                    ", "label", "=", "[", "]", "\n", "", "", "", "else", ":", "\n", "            ", "label", "=", "\"empty\"", "# trick to have -1 for unlabeled data and concat them with labeled", "\n", "if", "\"filename\"", "not", "in", "self", ".", "df", ".", "columns", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\n", "\"Dataframe to be encoded doesn't have specified columns: columns allowed: 'filename' for unlabeled;\"", "\n", "\"'filename', 'event_labels' for weak labels; 'filename' 'onset' 'offset' 'event_label' \"", "\n", "\"for strong labels, yours: {}\"", ".", "format", "(", "self", ".", "df", ".", "columns", ")", ")", "\n", "", "", "if", "index", "==", "0", ":", "\n", "            ", "logger", ".", "debug", "(", "\"label to encode: {}\"", ".", "format", "(", "label", ")", ")", "\n", "", "if", "self", ".", "encode_function", "is", "not", "None", ":", "\n", "# labels are a list of string or list of list [[label, onset, offset]]", "\n", "            ", "y", "=", "self", ".", "encode_function", "(", "label", ")", "\n", "", "else", ":", "\n", "            ", "y", "=", "label", "\n", "", "sample", "=", "features", ",", "y", "\n", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.DataLoadDf.__getitem__": [[133, 154], ["DataLoad.DataLoadDf.get_sample", "DataLoad.DataLoadDf.transform"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.DataLoadDf.get_sample"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\" Get a sample and transform it to be used in a ss_model, use the transformations\n\n        Args:\n            index : int, index of the sample desired\n\n        Returns:\n            tuple\n            Tuple containing the features and the labels (numpy.array, numpy.array) or\n            Tuple containing the features, the labels and the index (numpy.array, numpy.array, int)\n\n        \"\"\"", "\n", "sample", "=", "self", ".", "get_sample", "(", "index", ")", "\n", "\n", "if", "self", ".", "transform", ":", "\n", "            ", "sample", "=", "self", ".", "transform", "(", "sample", ")", "\n", "\n", "", "if", "self", ".", "return_indexes", ":", "\n", "            ", "sample", "=", "(", "sample", ",", "index", ")", "\n", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.DataLoadDf.set_transform": [[155, 162], ["None"], "methods", ["None"], ["", "def", "set_transform", "(", "self", ",", "transform", ")", ":", "\n", "        ", "\"\"\"Set the transformations used on a sample\n\n        Args:\n            transform: function(), the new transformations\n        \"\"\"", "\n", "self", ".", "transform", "=", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.DataLoadDf.add_transform": [[163, 168], ["DataLoad.DataLoadDf.transform.add_transform", "DataLoad.DataLoadDf", "type", "TypeError"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.Compose.add_transform"], ["", "def", "add_transform", "(", "self", ",", "transform", ")", ":", "\n", "        ", "if", "type", "(", "self", ".", "transform", ")", "is", "not", "Compose", ":", "\n", "            ", "raise", "TypeError", "(", "\"To add transform, the transform should already be a compose of transforms\"", ")", "\n", "", "transforms", "=", "self", ".", "transform", ".", "add_transform", "(", "transform", ")", "\n", "return", "DataLoadDf", "(", "self", ".", "df", ",", "self", ".", "encode_function", ",", "transforms", ",", "self", ".", "return_indexes", ",", "self", ".", "in_memory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.ConcatDataset.cumsum": [[181, 189], ["len", "r.append"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "cumsum", "(", "sequence", ")", ":", "\n", "        ", "r", ",", "s", "=", "[", "]", ",", "0", "\n", "for", "e", "in", "sequence", ":", "\n", "            ", "l", "=", "len", "(", "e", ")", "\n", "r", ".", "append", "(", "l", "+", "s", ")", "\n", "s", "+=", "l", "\n", "", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.ConcatDataset.cluster_indices": [[190, 198], ["cluster_ind.append", "range"], "methods", ["None"], ["", "@", "property", "\n", "def", "cluster_indices", "(", "self", ")", ":", "\n", "        ", "cluster_ind", "=", "[", "]", "\n", "prec", "=", "0", "\n", "for", "size", "in", "self", ".", "cumulative_sizes", ":", "\n", "            ", "cluster_ind", ".", "append", "(", "range", "(", "prec", ",", "size", ")", ")", "\n", "prec", "=", "size", "\n", "", "return", "cluster_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.ConcatDataset.__init__": [[199, 203], ["list", "DataLoad.ConcatDataset.cumsum", "len"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.ConcatDataset.cumsum"], ["", "def", "__init__", "(", "self", ",", "datasets", ")", ":", "\n", "        ", "assert", "len", "(", "datasets", ")", ">", "0", ",", "'datasets should not be an empty iterable'", "\n", "self", ".", "datasets", "=", "list", "(", "datasets", ")", "\n", "self", ".", "cumulative_sizes", "=", "self", ".", "cumsum", "(", "self", ".", "datasets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.ConcatDataset.__len__": [[204, 206], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cumulative_sizes", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.ConcatDataset.__getitem__": [[207, 214], ["bisect.bisect_right"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "dataset_idx", "=", "bisect", ".", "bisect_right", "(", "self", ".", "cumulative_sizes", ",", "idx", ")", "\n", "if", "dataset_idx", "==", "0", ":", "\n", "            ", "sample_idx", "=", "idx", "\n", "", "else", ":", "\n", "            ", "sample_idx", "=", "idx", "-", "self", ".", "cumulative_sizes", "[", "dataset_idx", "-", "1", "]", "\n", "", "return", "self", ".", "datasets", "[", "dataset_idx", "]", "[", "sample_idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.ConcatDataset.cummulative_sizes": [[215, 220], ["warnings.warn"], "methods", ["None"], ["", "@", "property", "\n", "def", "cummulative_sizes", "(", "self", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"cummulative_sizes attribute is renamed to \"", "\n", "\"cumulative_sizes\"", ",", "DeprecationWarning", ",", "stacklevel", "=", "2", ")", "\n", "return", "self", ".", "cumulative_sizes", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.ConcatDataset.df": [[221, 227], ["pandas.concat"], "methods", ["None"], ["", "@", "property", "\n", "def", "df", "(", "self", ")", ":", "\n", "        ", "df", "=", "self", ".", "datasets", "[", "0", "]", ".", "df", "\n", "for", "dataset", "in", "self", ".", "datasets", "[", "1", ":", "]", ":", "\n", "            ", "df", "=", "pd", ".", "concat", "(", "[", "df", ",", "dataset", ".", "df", "]", ",", "axis", "=", "0", ",", "ignore_index", "=", "True", ",", "sort", "=", "False", ")", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.MultiStreamBatchSampler.__init__": [[242, 251], ["torch.utils.data.sampler.Sampler.__init__", "len", "len"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["def", "__init__", "(", "self", ",", "data_source", ",", "batch_sizes", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "super", "(", "MultiStreamBatchSampler", ",", "self", ")", ".", "__init__", "(", "data_source", ")", "\n", "self", ".", "data_source", "=", "data_source", "\n", "self", ".", "batch_sizes", "=", "batch_sizes", "\n", "l_bs", "=", "len", "(", "batch_sizes", ")", "\n", "nb_dataset", "=", "len", "(", "self", ".", "data_source", ".", "cluster_indices", ")", "\n", "assert", "l_bs", "==", "nb_dataset", ",", "\"batch_sizes must be the same length as the number of datasets in \"", "\"the source {} != {}\"", ".", "format", "(", "l_bs", ",", "nb_dataset", ")", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.MultiStreamBatchSampler.__iter__": [[252, 262], ["range", "range", "len", "iterators.append", "sum", "len", "numpy.random.permutation", "DataLoad.grouper", "zip"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.grouper"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "indices", "=", "self", ".", "data_source", ".", "cluster_indices", "\n", "if", "self", ".", "shuffle", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "batch_sizes", ")", ")", ":", "\n", "                ", "indices", "[", "i", "]", "=", "np", ".", "random", ".", "permutation", "(", "indices", "[", "i", "]", ")", "\n", "", "", "iterators", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "batch_sizes", ")", ")", ":", "\n", "            ", "iterators", ".", "append", "(", "grouper", "(", "indices", "[", "i", "]", ",", "self", ".", "batch_sizes", "[", "i", "]", ")", ")", "\n", "\n", "", "return", "(", "sum", "(", "subbatch_ind", ",", "(", ")", ")", "for", "subbatch_ind", "in", "zip", "(", "*", "iterators", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.MultiStreamBatchSampler.__len__": [[263, 268], ["range", "len", "min", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "val", "=", "np", ".", "inf", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "batch_sizes", ")", ")", ":", "\n", "            ", "val", "=", "min", "(", "val", ",", "len", "(", "self", ".", "data_source", ".", "cluster_indices", "[", "i", "]", ")", "//", "self", ".", "batch_sizes", "[", "i", "]", ")", "\n", "", "return", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.grouper": [[270, 275], ["zip", "iter"], "function", ["None"], ["", "", "def", "grouper", "(", "iterable", ",", "n", ")", ":", "\n", "    ", "\"Collect data into fixed-length chunks or blocks\"", "\n", "# grouper('ABCDEFG', 3) --> ABC DEF\"", "\n", "args", "=", "[", "iter", "(", "iterable", ")", "]", "*", "n", "\n", "return", "zip", "(", "*", "args", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.CNN.GLU.__init__": [[6, 10], ["torch.Module.__init__", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_num", ")", ":", "\n", "        ", "super", "(", "GLU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_num", ",", "input_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.CNN.GLU.forward": [[11, 17], ["CNN.GLU.linear", "lin.permute.permute.permute", "CNN.GLU.sigmoid", "x.permute"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "lin", "=", "self", ".", "linear", "(", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "lin", "=", "lin", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "sig", "=", "self", ".", "sigmoid", "(", "x", ")", "\n", "res", "=", "lin", "*", "sig", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.CNN.ContextGating.__init__": [[20, 24], ["torch.Module.__init__", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_num", ")", ":", "\n", "        ", "super", "(", "ContextGating", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_num", ",", "input_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.CNN.ContextGating.forward": [[25, 31], ["CNN.ContextGating.linear", "lin.permute.permute.permute", "CNN.ContextGating.sigmoid", "x.permute"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "lin", "=", "self", ".", "linear", "(", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n", "lin", "=", "lin", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "sig", "=", "self", ".", "sigmoid", "(", "lin", ")", "\n", "res", "=", "x", "*", "sig", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.CNN.CNN.__init__": [[35, 88], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "range", "torch.Sequential.add_module", "len", "CNN.CNN.__init__.conv"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_in_channel", ",", "activation", "=", "\"Relu\"", ",", "conv_dropout", "=", "0", ",", "\n", "kernel_size", "=", "[", "3", ",", "3", ",", "3", "]", ",", "padding", "=", "[", "1", ",", "1", ",", "1", "]", ",", "stride", "=", "[", "1", ",", "1", ",", "1", "]", ",", "nb_filters", "=", "[", "64", ",", "64", ",", "64", "]", ",", "\n", "pooling", "=", "[", "(", "1", ",", "4", ")", ",", "(", "1", ",", "4", ")", ",", "(", "1", ",", "4", ")", "]", "\n", ")", ":", "\n", "        ", "super", "(", "CNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nb_filters", "=", "nb_filters", "\n", "cnn", "=", "nn", ".", "Sequential", "(", ")", "\n", "\n", "def", "conv", "(", "i", ",", "batchNormalization", "=", "False", ",", "dropout", "=", "None", ",", "activ", "=", "\"relu\"", ")", ":", "\n", "            ", "nIn", "=", "n_in_channel", "if", "i", "==", "0", "else", "nb_filters", "[", "i", "-", "1", "]", "\n", "nOut", "=", "nb_filters", "[", "i", "]", "\n", "cnn", ".", "add_module", "(", "'conv{0}'", ".", "format", "(", "i", ")", ",", "\n", "nn", ".", "Conv2d", "(", "nIn", ",", "nOut", ",", "kernel_size", "[", "i", "]", ",", "stride", "[", "i", "]", ",", "padding", "[", "i", "]", ")", ")", "\n", "if", "batchNormalization", ":", "\n", "                ", "cnn", ".", "add_module", "(", "'batchnorm{0}'", ".", "format", "(", "i", ")", ",", "nn", ".", "BatchNorm2d", "(", "nOut", ",", "eps", "=", "0.001", ",", "momentum", "=", "0.99", ")", ")", "\n", "", "if", "activ", ".", "lower", "(", ")", "==", "\"leakyrelu\"", ":", "\n", "                ", "cnn", ".", "add_module", "(", "'relu{0}'", ".", "format", "(", "i", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ")", "\n", "", "elif", "activ", ".", "lower", "(", ")", "==", "\"relu\"", ":", "\n", "                ", "cnn", ".", "add_module", "(", "'relu{0}'", ".", "format", "(", "i", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "", "elif", "activ", ".", "lower", "(", ")", "==", "\"glu\"", ":", "\n", "                ", "cnn", ".", "add_module", "(", "'glu{0}'", ".", "format", "(", "i", ")", ",", "GLU", "(", "nOut", ")", ")", "\n", "", "elif", "activ", ".", "lower", "(", ")", "==", "\"cg\"", ":", "\n", "                ", "cnn", ".", "add_module", "(", "'cg{0}'", ".", "format", "(", "i", ")", ",", "ContextGating", "(", "nOut", ")", ")", "\n", "", "if", "dropout", "is", "not", "None", ":", "\n", "                ", "cnn", ".", "add_module", "(", "'dropout{0}'", ".", "format", "(", "i", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ")", "\n", "\n", "", "", "batch_norm", "=", "True", "\n", "# 128x862x64", "\n", "for", "i", "in", "range", "(", "len", "(", "nb_filters", ")", ")", ":", "\n", "#nIn = n_in_channel if i == 0 else nb_filters[i-1]", "\n", "#nOut = nb_filters[i]", "\n", "            ", "conv", "(", "i", ",", "batch_norm", ",", "conv_dropout", ",", "activ", "=", "activation", ")", "\n", "cnn", ".", "add_module", "(", "'pooling{0}'", ".", "format", "(", "i", ")", ",", "nn", ".", "AvgPool2d", "(", "pooling", "[", "i", "]", ")", ")", "# bs x tframe x mels", "\n", "#cnn.add_module('pooling{0}'.format(i), nn.MaxPool2d(pooling[i]))  # bs x tframe x mels", "\n", "\n", "#if batch_norm:", "\n", "#    cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut, eps=0.001, momentum=0.99))", "\n", "#if activation.lower() == \"leakyrelu\":", "\n", "#    cnn.add_module('relu{0}'.format(i),", "\n", "#                   nn.LeakyReLU(0.2))", "\n", "#elif activation.lower() == \"relu\":", "\n", "#    cnn.add_module('relu{0}'.format(i), nn.ReLU())", "\n", "#elif activation.lower() == \"glu\":", "\n", "#    cnn.add_module('glu{0}'.format(i), GLU(nOut))", "\n", "#elif activation.lower() == \"cg\":", "\n", "#    cnn.add_module('cg{0}'.format(i), ContextGating(nOut))", "\n", "#if conv_dropout is not None:", "\n", "#    cnn.add_module('dropout{0}'.format(i),", "\n", "#                   nn.Dropout(conv_dropout))", "\n", "\n", "", "self", ".", "cnn", "=", "cnn", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.CNN.CNN.load_state_dict": [[89, 91], ["CNN.CNN.cnn.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "strict", "=", "True", ")", ":", "\n", "        ", "self", ".", "cnn", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.CNN.CNN.state_dict": [[92, 94], ["CNN.CNN.cnn.state_dict"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict"], ["", "def", "state_dict", "(", "self", ",", "destination", "=", "None", ",", "prefix", "=", "''", ",", "keep_vars", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "cnn", ".", "state_dict", "(", "destination", "=", "destination", ",", "prefix", "=", "prefix", ",", "keep_vars", "=", "keep_vars", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.CNN.CNN.save": [[95, 97], ["torch.save", "torch.save", "torch.save", "torch.save", "CNN.CNN.cnn.state_dict"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict"], ["", "def", "save", "(", "self", ",", "filename", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "cnn", ".", "state_dict", "(", ")", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.CNN.CNN.forward": [[98, 103], ["CNN.CNN.cnn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# input size : (batch_size, n_channels, n_frames, n_freq)", "\n", "# conv features", "\n", "        ", "x", "=", "self", ".", "cnn", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.CRNN.CRNN.__init__": [[12, 42], ["torch.Module.__init__", "models.CNN.CNN", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "CRNN.CRNN.cnn.parameters", "models.RNN.BidirectionalGRU", "NotImplementedError", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_in_channel", ",", "nclass", ",", "attention", "=", "False", ",", "activation", "=", "\"Relu\"", ",", "dropout", "=", "0", ",", "\n", "train_cnn", "=", "True", ",", "rnn_type", "=", "'BGRU'", ",", "n_RNN_cell", "=", "64", ",", "n_layers_RNN", "=", "1", ",", "dropout_recurrent", "=", "0", ",", "\n", "cnn_integration", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_in_channel", "=", "n_in_channel", "\n", "self", ".", "attention", "=", "attention", "\n", "self", ".", "cnn_integration", "=", "cnn_integration", "\n", "n_in_cnn", "=", "n_in_channel", "\n", "if", "cnn_integration", ":", "\n", "            ", "n_in_cnn", "=", "1", "\n", "", "self", ".", "cnn", "=", "CNN", "(", "n_in_cnn", ",", "activation", ",", "dropout", ",", "**", "kwargs", ")", "\n", "if", "not", "train_cnn", ":", "\n", "            ", "for", "param", "in", "self", ".", "cnn", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "self", ".", "train_cnn", "=", "train_cnn", "\n", "if", "rnn_type", "==", "'BGRU'", ":", "\n", "            ", "nb_in", "=", "self", ".", "cnn", ".", "nb_filters", "[", "-", "1", "]", "\n", "if", "self", ".", "cnn_integration", ":", "\n", "# self.fc = nn.Linear(nb_in * n_in_channel, nb_in)", "\n", "                ", "nb_in", "=", "nb_in", "*", "n_in_channel", "\n", "", "self", ".", "rnn", "=", "BidirectionalGRU", "(", "nb_in", ",", "\n", "n_RNN_cell", ",", "dropout", "=", "dropout_recurrent", ",", "num_layers", "=", "n_layers_RNN", ")", "\n", "", "else", ":", "\n", "            ", "NotImplementedError", "(", "\"Only BGRU supported for CRNN for now\"", ")", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "n_RNN_cell", "*", "2", ",", "nclass", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "if", "self", ".", "attention", ":", "\n", "            ", "self", ".", "dense_softmax", "=", "nn", ".", "Linear", "(", "n_RNN_cell", "*", "2", ",", "nclass", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.CRNN.CRNN.load_cnn": [[43, 48], ["CRNN.CRNN.cnn.load_state_dict", "CRNN.CRNN.cnn.parameters"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict"], ["", "", "def", "load_cnn", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "cnn", ".", "load_state_dict", "(", "state_dict", ")", "\n", "if", "not", "self", ".", "train_cnn", ":", "\n", "            ", "for", "param", "in", "self", ".", "cnn", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.CRNN.CRNN.load_state_dict": [[49, 53], ["CRNN.CRNN.cnn.load_state_dict", "CRNN.CRNN.rnn.load_state_dict", "CRNN.CRNN.dense.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict"], ["", "", "", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "strict", "=", "True", ")", ":", "\n", "        ", "self", ".", "cnn", ".", "load_state_dict", "(", "state_dict", "[", "\"cnn\"", "]", ")", "\n", "self", ".", "rnn", ".", "load_state_dict", "(", "state_dict", "[", "\"rnn\"", "]", ")", "\n", "self", ".", "dense", ".", "load_state_dict", "(", "state_dict", "[", "\"dense\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.CRNN.CRNN.state_dict": [[54, 59], ["CRNN.CRNN.cnn.state_dict", "CRNN.CRNN.rnn.state_dict", "CRNN.CRNN.dense.state_dict"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict"], ["", "def", "state_dict", "(", "self", ",", "destination", "=", "None", ",", "prefix", "=", "''", ",", "keep_vars", "=", "False", ")", ":", "\n", "        ", "state_dict", "=", "{", "\"cnn\"", ":", "self", ".", "cnn", ".", "state_dict", "(", "destination", "=", "destination", ",", "prefix", "=", "prefix", ",", "keep_vars", "=", "keep_vars", ")", ",", "\n", "\"rnn\"", ":", "self", ".", "rnn", ".", "state_dict", "(", "destination", "=", "destination", ",", "prefix", "=", "prefix", ",", "keep_vars", "=", "keep_vars", ")", ",", "\n", "'dense'", ":", "self", ".", "dense", ".", "state_dict", "(", "destination", "=", "destination", ",", "prefix", "=", "prefix", ",", "keep_vars", "=", "keep_vars", ")", "}", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.CRNN.CRNN.save": [[60, 63], ["torch.save", "torch.save", "torch.save", "torch.save", "CRNN.CRNN.cnn.state_dict", "CRNN.CRNN.rnn.state_dict", "CRNN.CRNN.dense.state_dict"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict"], ["", "def", "save", "(", "self", ",", "filename", ")", ":", "\n", "        ", "parameters", "=", "{", "'cnn'", ":", "self", ".", "cnn", ".", "state_dict", "(", ")", ",", "'rnn'", ":", "self", ".", "rnn", ".", "state_dict", "(", ")", ",", "'dense'", ":", "self", ".", "dense", ".", "state_dict", "(", ")", "}", "\n", "torch", ".", "save", "(", "parameters", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.CRNN.CRNN.forward": [[64, 97], ["CRNN.CRNN.cnn", "x.permute.permute.size", "CRNN.CRNN.rnn", "CRNN.CRNN.dropout", "CRNN.CRNN.dense", "CRNN.CRNN.sigmoid", "x.permute.permute.view", "x.permute.permute.reshape", "warnings.warn", "x.permute.permute.permute", "x.permute.permute.contiguous().view", "x.permute.permute.squeeze", "x.permute.permute.permute", "CRNN.CRNN.dense_softmax", "CRNN.CRNN.softmax", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "CRNN.CRNN.mean", "x.permute.permute.size", "x.permute.permute.size", "torch.clamp.sum", "torch.clamp.sum", "x.permute.permute.contiguous"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# input size : (batch_size, n_channels, n_frames, n_freq)", "\n", "        ", "if", "self", ".", "cnn_integration", ":", "\n", "            ", "bs_in", ",", "nc_in", "=", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", "\n", "x", "=", "x", ".", "view", "(", "bs_in", "*", "nc_in", ",", "1", ",", "*", "x", ".", "shape", "[", "2", ":", "]", ")", "\n", "\n", "# conv features", "\n", "", "x", "=", "self", ".", "cnn", "(", "x", ")", "\n", "bs", ",", "chan", ",", "frames", ",", "freq", "=", "x", ".", "size", "(", ")", "\n", "if", "self", ".", "cnn_integration", ":", "\n", "            ", "x", "=", "x", ".", "reshape", "(", "bs_in", ",", "chan", "*", "nc_in", ",", "frames", ",", "freq", ")", "\n", "\n", "", "if", "freq", "!=", "1", ":", "\n", "            ", "warnings", ".", "warn", "(", "f\"Output shape is: {(bs, frames, chan * freq)}, from {freq} staying freq\"", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "x", "=", "x", ".", "contiguous", "(", ")", ".", "view", "(", "bs", ",", "frames", ",", "chan", "*", "freq", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", ".", "squeeze", "(", "-", "1", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# [bs, frames, chan]", "\n", "\n", "# rnn features", "\n", "", "x", "=", "self", ".", "rnn", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "strong", "=", "self", ".", "dense", "(", "x", ")", "# [bs, frames, nclass]", "\n", "strong", "=", "self", ".", "sigmoid", "(", "strong", ")", "\n", "if", "self", ".", "attention", ":", "\n", "            ", "sof", "=", "self", ".", "dense_softmax", "(", "x", ")", "# [bs, frames, nclass]", "\n", "sof", "=", "self", ".", "softmax", "(", "sof", ")", "\n", "sof", "=", "torch", ".", "clamp", "(", "sof", ",", "min", "=", "1e-7", ",", "max", "=", "1", ")", "\n", "weak", "=", "(", "strong", "*", "sof", ")", ".", "sum", "(", "1", ")", "/", "sof", ".", "sum", "(", "1", ")", "# [bs, nclass]", "\n", "", "else", ":", "\n", "            ", "weak", "=", "strong", ".", "mean", "(", "1", ")", "\n", "", "return", "strong", ",", "weak", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.RNN.BidirectionalGRU.__init__": [[9, 13], ["torch.nn.Module.__init__", "torch.nn.GRU"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_hidden", ",", "dropout", "=", "0", ",", "num_layers", "=", "1", ")", ":", "\n", "        ", "super", "(", "BidirectionalGRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "rnn", "=", "nn", ".", "GRU", "(", "n_in", ",", "n_hidden", ",", "bidirectional", "=", "True", ",", "dropout", "=", "dropout", ",", "batch_first", "=", "True", ",", "num_layers", "=", "num_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.RNN.BidirectionalGRU.forward": [[14, 17], ["RNN.BidirectionalGRU.rnn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_feat", ")", ":", "\n", "        ", "recurrent", ",", "_", "=", "self", ".", "rnn", "(", "input_feat", ")", "\n", "return", "recurrent", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.RNN.BidirectionalLSTM.__init__": [[21, 26], ["torch.nn.Module.__init__", "torch.nn.LSTM", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nIn", ",", "nHidden", ",", "nOut", ",", "dropout", "=", "0", ",", "num_layers", "=", "1", ")", ":", "\n", "        ", "super", "(", "BidirectionalLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "nIn", ",", "nHidden", "//", "2", ",", "bidirectional", "=", "True", ",", "batch_first", "=", "True", ",", "\n", "dropout", "=", "dropout", ",", "num_layers", "=", "num_layers", ")", "\n", "self", ".", "embedding", "=", "nn", ".", "Linear", "(", "nHidden", "*", "2", ",", "nOut", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.RNN.BidirectionalLSTM.save": [[27, 29], ["torch.save", "RNN.BidirectionalLSTM.state_dict"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict"], ["", "def", "save", "(", "self", ",", "filename", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "state_dict", "(", ")", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.RNN.BidirectionalLSTM.load": [[30, 37], ["RNN.BidirectionalLSTM.load_state_dict", "torch.load", "RNN.BidirectionalLSTM.load_state_dict", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.load", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict"], ["", "def", "load", "(", "self", ",", "filename", "=", "None", ",", "parameters", "=", "None", ")", ":", "\n", "        ", "if", "filename", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "torch", ".", "load", "(", "filename", ")", ")", "\n", "", "elif", "parameters", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "parameters", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"load is a filename or a list of parameters (state_dict)\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.models.RNN.BidirectionalLSTM.forward": [[38, 46], ["RNN.BidirectionalLSTM.rnn", "recurrent.size", "recurrent.contiguous().view", "RNN.BidirectionalLSTM.embedding", "output.view.view.view", "recurrent.contiguous"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_feat", ")", ":", "\n", "        ", "recurrent", ",", "_", "=", "self", ".", "rnn", "(", "input_feat", ")", "\n", "b", ",", "T", ",", "h", "=", "recurrent", ".", "size", "(", ")", "\n", "t_rec", "=", "recurrent", ".", "contiguous", "(", ")", ".", "view", "(", "b", "*", "T", ",", "h", ")", "\n", "\n", "output", "=", "self", ".", "embedding", "(", "t_rec", ")", "# [T * b, nOut]", "\n", "output", "=", "output", ".", "view", "(", "b", ",", "T", ",", "-", "1", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Logger.create_logger": [[6, 44], ["logging.config.dictConfig", "logging.config.dictConfig", "logging.getLogger", "logging.getLogger", "logging.Formatter", "logging.Formatter", "logging.getLogger.setLevel", "type", "len", "logging.StreamHandler", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.set_name", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "terminal_level.lower", "terminal_level.lower", "terminal_level.lower", "terminal_level.lower", "terminal_level.lower"], "function", ["None"], ["def", "create_logger", "(", "logger_name", ",", "terminal_level", "=", "logging", ".", "INFO", ")", ":", "\n", "    ", "\"\"\" Create a logger.\n    Args:\n        logger_name: str, name of the logger\n        terminal_level: int, logging level in the terminal\n    \"\"\"", "\n", "logging", ".", "config", ".", "dictConfig", "(", "{", "\n", "'version'", ":", "1", ",", "\n", "'disable_existing_loggers'", ":", "False", ",", "\n", "}", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", "logger_name", ")", "\n", "tool_formatter", "=", "logging", ".", "Formatter", "(", "'%(levelname)s - %(name)s - %(message)s'", ")", "\n", "\n", "if", "type", "(", "terminal_level", ")", "is", "str", ":", "\n", "        ", "if", "terminal_level", ".", "lower", "(", ")", "==", "\"debug\"", ":", "\n", "            ", "res_terminal_level", "=", "logging", ".", "DEBUG", "\n", "", "elif", "terminal_level", ".", "lower", "(", ")", "==", "\"info\"", ":", "\n", "            ", "res_terminal_level", "=", "logging", ".", "INFO", "\n", "", "elif", "\"warn\"", "in", "terminal_level", ".", "lower", "(", ")", ":", "\n", "            ", "res_terminal_level", "=", "logging", ".", "WARNING", "\n", "", "elif", "terminal_level", ".", "lower", "(", ")", "==", "\"error\"", ":", "\n", "            ", "res_terminal_level", "=", "logging", ".", "ERROR", "\n", "", "elif", "terminal_level", ".", "lower", "(", ")", "==", "\"critical\"", ":", "\n", "            ", "res_terminal_level", "=", "logging", ".", "CRITICAL", "\n", "", "else", ":", "\n", "            ", "res_terminal_level", "=", "logging", ".", "NOTSET", "\n", "", "", "else", ":", "\n", "        ", "res_terminal_level", "=", "terminal_level", "\n", "", "logger", ".", "setLevel", "(", "res_terminal_level", ")", "\n", "# Remove the stdout handler", "\n", "logger_handlers", "=", "logger", ".", "handlers", "[", ":", "]", "\n", "if", "not", "len", "(", "logger_handlers", ")", ":", "\n", "        ", "terminal_h", "=", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "\n", "terminal_h", ".", "setLevel", "(", "res_terminal_level", ")", "\n", "terminal_h", ".", "set_name", "(", "'stdout'", ")", "\n", "terminal_h", ".", "setFormatter", "(", "tool_formatter", ")", "\n", "logger", ".", "addHandler", "(", "terminal_h", ")", "\n", "", "return", "logger", "\n", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.__init__": [[18, 22], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "mean_", "=", "None", "\n", "self", ".", "mean_of_square_", "=", "None", "\n", "self", ".", "std_", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean": [[24, 33], ["numpy.mean", "len", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["", "def", "mean", "(", "self", ",", "data", ",", "axis", "=", "-", "1", ")", ":", "\n", "# -1 means have at the end a mean vector of the last dimension", "\n", "        ", "if", "axis", "==", "-", "1", ":", "\n", "            ", "mean", "=", "data", "\n", "while", "len", "(", "mean", ".", "shape", ")", "!=", "1", ":", "\n", "                ", "mean", "=", "np", ".", "mean", "(", "mean", ",", "axis", "=", "0", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "", "", "else", ":", "\n", "            ", "mean", "=", "np", ".", "mean", "(", "data", ",", "axis", "=", "axis", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "", "return", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.variance": [[35, 37], ["None"], "methods", ["None"], ["", "def", "variance", "(", "self", ",", "mean", ",", "mean_of_square", ")", ":", "\n", "        ", "return", "mean_of_square", "-", "mean", "**", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.means": [[38, 91], ["logger.info", "time.time", "logger.debug", "type", "batch_x.numpy", "Scaler.Scaler.mean", "Scaler.Scaler.mean", "Scaler.Scaler.mean", "Scaler.Scaler.mean", "str", "type", "len", "NotImplementedError", "time.time"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["", "def", "means", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "\"\"\"\n       Splits a dataset in to train test validation.\n       :param dataset: dataset, from DataLoad class, each sample is an (X, y) tuple.\n       \"\"\"", "\n", "logger", ".", "info", "(", "'computing mean'", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "shape", "=", "None", "\n", "counter", "=", "0", "\n", "for", "sample", "in", "dataset", ":", "\n", "            ", "if", "type", "(", "sample", ")", "in", "[", "tuple", ",", "list", "]", "and", "len", "(", "sample", ")", "==", "2", ":", "\n", "                ", "batch_x", ",", "_", "=", "sample", "\n", "", "else", ":", "\n", "                ", "batch_x", "=", "sample", "\n", "", "if", "type", "(", "batch_x", ")", "is", "torch", ".", "Tensor", ":", "\n", "                ", "batch_x_arr", "=", "batch_x", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "batch_x_arr", "=", "batch_x", "\n", "", "data_square", "=", "batch_x_arr", "**", "2", "\n", "counter", "+=", "1", "\n", "\n", "if", "shape", "is", "None", ":", "\n", "                ", "shape", "=", "batch_x_arr", ".", "shape", "\n", "", "else", ":", "\n", "                ", "if", "not", "batch_x_arr", ".", "shape", "==", "shape", ":", "\n", "                    ", "raise", "NotImplementedError", "(", "\"Not possible to add data with different shape in mean calculation yet\"", ")", "\n", "\n", "# assume first item will have shape info", "\n", "", "", "if", "self", ".", "mean_", "is", "None", ":", "\n", "                ", "self", ".", "mean_", "=", "self", ".", "mean", "(", "batch_x_arr", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "mean_", "+=", "self", ".", "mean", "(", "batch_x_arr", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "if", "self", ".", "mean_of_square_", "is", "None", ":", "\n", "                ", "self", ".", "mean_of_square_", "=", "self", ".", "mean", "(", "data_square", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "mean_of_square_", "+=", "self", ".", "mean", "(", "data_square", ",", "axis", "=", "-", "1", ")", "\n", "\n", "", "", "self", ".", "mean_", "/=", "counter", "\n", "self", ".", "mean_of_square_", "/=", "counter", "\n", "\n", "# ### To be used if data different shape, but need to stop the iteration before.", "\n", "# rest = len(dataset) - i", "\n", "# if rest != 0:", "\n", "#     weight = rest / float(i + rest)", "\n", "#     X, y = dataset[-1]", "\n", "#     data_square = X ** 2", "\n", "#     mean = mean * (1 - weight) + self.mean(X, axis=-1) * weight", "\n", "#     mean_of_square = mean_of_square * (1 - weight) + self.mean(data_square, axis=-1) * weight", "\n", "\n", "logger", ".", "debug", "(", "'time to compute means: '", "+", "str", "(", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.std": [[92, 94], ["numpy.sqrt"], "methods", ["None"], ["", "def", "std", "(", "self", ",", "variance", ")", ":", "\n", "        ", "return", "np", ".", "sqrt", "(", "variance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.calculate_scaler": [[95, 101], ["Scaler.Scaler.means", "Scaler.Scaler.variance", "Scaler.Scaler.std"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.means", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.variance", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.std"], ["", "def", "calculate_scaler", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "self", ".", "means", "(", "dataset", ")", "\n", "variance", "=", "self", ".", "variance", "(", "self", ".", "mean_", ",", "self", ".", "mean_of_square_", ")", "\n", "self", ".", "std_", "=", "self", ".", "std", "(", "variance", ")", "\n", "\n", "return", "self", ".", "mean_", ",", "self", ".", "std_", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.normalize": [[102, 109], ["type", "batch.numpy", "torch.Tensor"], "methods", ["None"], ["", "def", "normalize", "(", "self", ",", "batch", ")", ":", "\n", "        ", "if", "type", "(", "batch", ")", "is", "torch", ".", "Tensor", ":", "\n", "            ", "batch_", "=", "batch", ".", "numpy", "(", ")", "\n", "batch_", "=", "(", "batch_", "-", "self", ".", "mean_", ")", "/", "self", ".", "std_", "\n", "return", "torch", ".", "Tensor", "(", "batch_", ")", "\n", "", "else", ":", "\n", "            ", "return", "(", "batch", "-", "self", ".", "mean_", ")", "/", "self", ".", "std_", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.state_dict": [[110, 117], ["type", "NotImplementedError", "Scaler.Scaler.mean_.tolist", "Scaler.Scaler.mean_of_square_.tolist"], "methods", ["None"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "if", "type", "(", "self", ".", "mean_", ")", "is", "not", "np", ".", "ndarray", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Save scaler only implemented for numpy array means_\"", ")", "\n", "\n", "", "dict_save", "=", "{", "\"mean_\"", ":", "self", ".", "mean_", ".", "tolist", "(", ")", ",", "\n", "\"mean_of_square_\"", ":", "self", ".", "mean_of_square_", ".", "tolist", "(", ")", "}", "\n", "return", "dict_save", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.save": [[118, 122], ["Scaler.Scaler.state_dict", "open", "json.dump"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict"], ["", "def", "save", "(", "self", ",", "path", ")", ":", "\n", "        ", "dict_save", "=", "self", ".", "state_dict", "(", ")", "\n", "with", "open", "(", "path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "dict_save", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.load": [[123, 128], ["Scaler.Scaler.load_state_dict", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.load"], ["", "", "def", "load", "(", "self", ",", "path", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "dict_save", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "", "self", ".", "load_state_dict", "(", "dict_save", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.load_state_dict": [[129, 134], ["numpy.array", "numpy.array", "Scaler.Scaler.variance", "Scaler.Scaler.std"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.variance", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.std"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "mean_", "=", "np", ".", "array", "(", "state_dict", "[", "\"mean_\"", "]", ")", "\n", "self", ".", "mean_of_square_", "=", "np", ".", "array", "(", "state_dict", "[", "\"mean_of_square_\"", "]", ")", "\n", "variance", "=", "self", ".", "variance", "(", "self", ".", "mean_", ",", "self", ".", "mean_of_square_", ")", "\n", "self", ".", "std_", "=", "self", ".", "std", "(", "variance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.__init__": [[143, 146], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "normalization", "=", "\"global\"", ",", "type_norm", "=", "\"mean\"", ")", ":", "\n", "        ", "self", ".", "normalization", "=", "normalization", "\n", "self", ".", "type_norm", "=", "type_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.normalize": [[147, 185], ["numpy.isnan().any", "type", "spectrogram.numpy.numpy.numpy", "numpy.nan_to_num", "warnings.warn", "torch.Tensor", "NotImplementedError", "numpy.isnan", "spectrogram[].mean", "spectrogram[].std", "NotImplementedError", "numpy.finfo", "numpy.abs", "spectrogram[].max", "numpy.finfo", "spectrogram[].min", "spectrogram[].max", "spectrogram[].min", "numpy.finfo"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.std"], ["", "def", "normalize", "(", "self", ",", "spectrogram", ")", ":", "\n", "        ", "\"\"\" Apply the transformation on data\n            Args:\n                spectrogram: np.array, the data to be modified, assume to have 3 dimensions\n\n            Returns:\n                np.array\n                The transformed data\n        \"\"\"", "\n", "if", "type", "(", "spectrogram", ")", "is", "torch", ".", "Tensor", ":", "\n", "            ", "tensor", "=", "True", "\n", "spectrogram", "=", "spectrogram", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "tensor", "=", "False", "\n", "\n", "", "if", "self", ".", "normalization", "==", "\"global\"", ":", "\n", "            ", "axis", "=", "None", "\n", "", "elif", "self", ".", "normalization", "==", "\"per_band\"", ":", "\n", "            ", "axis", "=", "0", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"normalization is 'global' or 'per_band'\"", ")", "\n", "\n", "", "if", "self", ".", "type_norm", "==", "\"standard\"", ":", "\n", "            ", "res_data", "=", "(", "spectrogram", "-", "spectrogram", "[", "0", "]", ".", "mean", "(", "axis", ")", ")", "/", "(", "spectrogram", "[", "0", "]", ".", "std", "(", "axis", ")", "+", "np", ".", "finfo", "(", "float", ")", ".", "eps", ")", "\n", "", "elif", "self", ".", "type_norm", "==", "\"max\"", ":", "\n", "            ", "res_data", "=", "spectrogram", "[", "0", "]", "/", "(", "np", ".", "abs", "(", "spectrogram", "[", "0", "]", ".", "max", "(", "axis", ")", ")", "+", "np", ".", "finfo", "(", "float", ")", ".", "eps", ")", "\n", "", "elif", "self", ".", "type_norm", "==", "\"min-max\"", ":", "\n", "            ", "res_data", "=", "(", "spectrogram", "-", "spectrogram", "[", "0", "]", ".", "min", "(", "axis", ")", ")", "/", "(", "spectrogram", "[", "0", "]", ".", "max", "(", "axis", ")", "-", "spectrogram", "[", "0", "]", ".", "min", "(", "axis", ")", "\n", "+", "np", ".", "finfo", "(", "float", ")", ".", "eps", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"No other type_norm implemented except {'standard', 'max', 'min-max'}\"", ")", "\n", "", "if", "np", ".", "isnan", "(", "res_data", ")", ".", "any", "(", ")", ":", "\n", "            ", "res_data", "=", "np", ".", "nan_to_num", "(", "res_data", ",", "posinf", "=", "0", ",", "neginf", "=", "0", ")", "\n", "warnings", ".", "warn", "(", "\"Trying to divide by zeros while normalizing spectrogram, replacing nan by 0\"", ")", "\n", "\n", "", "if", "tensor", ":", "\n", "            ", "res_data", "=", "torch", ".", "Tensor", "(", "res_data", ")", "\n", "", "return", "res_data", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.state_dict": [[186, 188], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save": [[189, 191], ["None"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "path", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.load": [[192, 194], ["None"], "methods", ["None"], ["", "def", "load", "(", "self", ",", "path", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.load_state_dict": [[195, 197], ["None"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.ManyHotEncoder.ManyHotEncoder.__init__": [[20, 25], ["type", "labels.tolist.tolist.tolist"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "labels", ",", "n_frames", "=", "None", ")", ":", "\n", "        ", "if", "type", "(", "labels", ")", "in", "[", "np", ".", "ndarray", ",", "np", ".", "array", "]", ":", "\n", "            ", "labels", "=", "labels", ".", "tolist", "(", ")", "\n", "", "self", ".", "labels", "=", "labels", "\n", "self", ".", "n_frames", "=", "n_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.ManyHotEncoder.ManyHotEncoder.encode_weak": [[26, 52], ["numpy.zeros", "type", "type", "len", "pandas.isna", "ManyHotEncoder.ManyHotEncoder.labels.index", "numpy.zeros", "len"], "methods", ["None"], ["", "def", "encode_weak", "(", "self", ",", "labels", ")", ":", "\n", "        ", "\"\"\" Encode a list of weak labels into a numpy array\n\n        Args:\n            labels: list, list of labels to encode (to a vector of 0 and 1)\n\n        Returns:\n            numpy.array\n            A vector containing 1 for each label, and 0 everywhere else\n        \"\"\"", "\n", "# useful for tensor empty labels", "\n", "if", "type", "(", "labels", ")", "is", "str", ":", "\n", "            ", "if", "labels", "==", "\"empty\"", ":", "\n", "                ", "y", "=", "np", ".", "zeros", "(", "len", "(", "self", ".", "labels", ")", ")", "-", "1", "\n", "return", "y", "\n", "", "", "if", "type", "(", "labels", ")", "is", "pd", ".", "DataFrame", ":", "\n", "            ", "if", "labels", ".", "empty", ":", "\n", "                ", "labels", "=", "[", "]", "\n", "", "elif", "\"event_label\"", "in", "labels", ".", "columns", ":", "\n", "                ", "labels", "=", "labels", "[", "\"event_label\"", "]", "\n", "", "", "y", "=", "np", ".", "zeros", "(", "len", "(", "self", ".", "labels", ")", ")", "\n", "for", "label", "in", "labels", ":", "\n", "            ", "if", "not", "pd", ".", "isna", "(", "label", ")", ":", "\n", "                ", "i", "=", "self", ".", "labels", ".", "index", "(", "label", ")", "\n", "y", "[", "i", "]", "=", "1", "\n", "", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.ManyHotEncoder.ManyHotEncoder.encode_strong_df": [[53, 113], ["numpy.zeros", "type", "type", "len", "label_df.iterrows", "type", "NotImplementedError", "numpy.zeros", "type", "pandas.isna", "ManyHotEncoder.ManyHotEncoder.labels.index", "int", "int", "type", "type", "len", "pandas.isna", "ManyHotEncoder.ManyHotEncoder.labels.index", "int", "int", "ManyHotEncoder.ManyHotEncoder.labels.index", "len", "NotImplementedError", "ManyHotEncoder.ManyHotEncoder.labels.index", "int", "int", "type"], "methods", ["None"], ["", "def", "encode_strong_df", "(", "self", ",", "label_df", ")", ":", "\n", "        ", "\"\"\"Encode a list (or pandas Dataframe or Serie) of strong labels, they correspond to a given filename\n\n        Args:\n            label_df: pandas DataFrame or Series, contains filename, onset (in frames) and offset (in frames)\n                If only filename (no onset offset) is specified, it will return the event on all the frames\n                onset and offset should be in frames\n        Returns:\n            numpy.array\n            Encoded labels, 1 where the label is present, 0 otherwise\n        \"\"\"", "\n", "\n", "assert", "self", ".", "n_frames", "is", "not", "None", ",", "\"n_frames need to be specified when using strong encoder\"", "\n", "if", "type", "(", "label_df", ")", "is", "str", ":", "\n", "            ", "if", "label_df", "==", "'empty'", ":", "\n", "                ", "y", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_frames", ",", "len", "(", "self", ".", "labels", ")", ")", ")", "-", "1", "\n", "return", "y", "\n", "", "", "y", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_frames", ",", "len", "(", "self", ".", "labels", ")", ")", ")", "\n", "if", "type", "(", "label_df", ")", "is", "pd", ".", "DataFrame", ":", "\n", "            ", "if", "{", "\"onset\"", ",", "\"offset\"", ",", "\"event_label\"", "}", ".", "issubset", "(", "label_df", ".", "columns", ")", ":", "\n", "                ", "for", "_", ",", "row", "in", "label_df", ".", "iterrows", "(", ")", ":", "\n", "                    ", "if", "not", "pd", ".", "isna", "(", "row", "[", "\"event_label\"", "]", ")", ":", "\n", "                        ", "i", "=", "self", ".", "labels", ".", "index", "(", "row", "[", "\"event_label\"", "]", ")", "\n", "onset", "=", "int", "(", "row", "[", "\"onset\"", "]", ")", "\n", "offset", "=", "int", "(", "row", "[", "\"offset\"", "]", ")", "\n", "y", "[", "onset", ":", "offset", ",", "i", "]", "=", "1", "# means offset not included (hypothesis of overlapping frames, so ok)", "\n", "\n", "", "", "", "", "elif", "type", "(", "label_df", ")", "in", "[", "pd", ".", "Series", ",", "list", ",", "np", ".", "ndarray", "]", ":", "# list of list or list of strings", "\n", "            ", "if", "type", "(", "label_df", ")", "is", "pd", ".", "Series", ":", "\n", "                ", "if", "{", "\"onset\"", ",", "\"offset\"", ",", "\"event_label\"", "}", ".", "issubset", "(", "label_df", ".", "index", ")", ":", "# means only one value", "\n", "                    ", "if", "not", "pd", ".", "isna", "(", "label_df", "[", "\"event_label\"", "]", ")", ":", "\n", "                        ", "i", "=", "self", ".", "labels", ".", "index", "(", "label_df", "[", "\"event_label\"", "]", ")", "\n", "onset", "=", "int", "(", "label_df", "[", "\"onset\"", "]", ")", "\n", "offset", "=", "int", "(", "label_df", "[", "\"offset\"", "]", ")", "\n", "y", "[", "onset", ":", "offset", ",", "i", "]", "=", "1", "\n", "", "return", "y", "\n", "\n", "", "", "for", "event_label", "in", "label_df", ":", "\n", "# List of string, so weak labels to be encoded in strong", "\n", "                ", "if", "type", "(", "event_label", ")", "is", "str", ":", "\n", "                    ", "if", "event_label", "is", "not", "\"\"", ":", "\n", "                        ", "i", "=", "self", ".", "labels", ".", "index", "(", "event_label", ")", "\n", "y", "[", ":", ",", "i", "]", "=", "1", "\n", "\n", "# List of list, with [label, onset, offset]", "\n", "", "", "elif", "len", "(", "event_label", ")", "==", "3", ":", "\n", "                    ", "if", "event_label", "[", "0", "]", "is", "not", "\"\"", ":", "\n", "                        ", "i", "=", "self", ".", "labels", ".", "index", "(", "event_label", "[", "0", "]", ")", "\n", "onset", "=", "int", "(", "event_label", "[", "1", "]", ")", "\n", "offset", "=", "int", "(", "event_label", "[", "2", "]", ")", "\n", "y", "[", "onset", ":", "offset", ",", "i", "]", "=", "1", "\n", "\n", "", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "(", "\"cannot encode strong, type mismatch: {}\"", ".", "format", "(", "type", "(", "event_label", ")", ")", ")", "\n", "\n", "", "", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"To encode_strong, type is pandas.Dataframe with onset, offset and event_label\"", "\n", "\"columns, or it is a list or pandas Series of event labels, \"", "\n", "\"type given: {}\"", ".", "format", "(", "type", "(", "label_df", ")", ")", ")", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.ManyHotEncoder.ManyHotEncoder.decode_weak": [[114, 129], ["enumerate", "result_labels.append"], "methods", ["None"], ["", "def", "decode_weak", "(", "self", ",", "labels", ")", ":", "\n", "        ", "\"\"\" Decode the encoded weak labels\n        Args:\n            labels: numpy.array, the encoded labels to be decoded\n\n        Returns:\n            list\n            Decoded labels, list of string\n\n        \"\"\"", "\n", "result_labels", "=", "[", "]", "\n", "for", "i", ",", "value", "in", "enumerate", "(", "labels", ")", ":", "\n", "            ", "if", "value", "==", "1", ":", "\n", "                ", "result_labels", ".", "append", "(", "self", ".", "labels", "[", "i", "]", ")", "\n", "", "", "return", "result_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.ManyHotEncoder.ManyHotEncoder.decode_strong": [[130, 147], ["enumerate", "dcase_util.data.DecisionEncoder().find_contiguous_regions", "result_labels.append", "dcase_util.data.DecisionEncoder"], "methods", ["None"], ["", "def", "decode_strong", "(", "self", ",", "labels", ")", ":", "\n", "        ", "\"\"\" Decode the encoded strong labels\n        Args:\n            labels: numpy.array, the encoded labels to be decoded\n        Returns:\n            list\n            Decoded labels, list of list: [[label, onset offset], ...]\n\n        \"\"\"", "\n", "result_labels", "=", "[", "]", "\n", "for", "i", ",", "label_column", "in", "enumerate", "(", "labels", ".", "T", ")", ":", "\n", "            ", "change_indices", "=", "DecisionEncoder", "(", ")", ".", "find_contiguous_regions", "(", "label_column", ")", "\n", "\n", "# append [label, onset, offset] in the result list", "\n", "for", "row", "in", "change_indices", ":", "\n", "                ", "result_labels", ".", "append", "(", "[", "self", ".", "labels", "[", "i", "]", ",", "row", "[", "0", "]", ",", "row", "[", "1", "]", "]", ")", "\n", "", "", "return", "result_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.ManyHotEncoder.ManyHotEncoder.state_dict": [[148, 151], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"labels\"", ":", "self", ".", "labels", ",", "\n", "\"n_frames\"", ":", "self", ".", "n_frames", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.ManyHotEncoder.ManyHotEncoder.load_state_dict": [[152, 157], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "load_state_dict", "(", "cls", ",", "state_dict", ")", ":", "\n", "        ", "labels", "=", "state_dict", "[", "\"labels\"", "]", "\n", "n_frames", "=", "state_dict", "[", "\"n_frames\"", "]", "\n", "return", "cls", "(", "labels", ",", "n_frames", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.ramps.exp_rampup": [[4, 17], ["numpy.clip", "float", "numpy.exp"], "function", ["None"], ["def", "exp_rampup", "(", "current", ",", "rampup_length", ")", ":", "\n", "    ", "\"\"\"Exponential rampup inspired by https://arxiv.org/abs/1610.02242\n        Args:\n            current: float, current step of the rampup\n            rampup_length: float: length of the rampup\n\n    \"\"\"", "\n", "if", "rampup_length", "==", "0", ":", "\n", "        ", "return", "1.0", "\n", "", "else", ":", "\n", "        ", "current", "=", "np", ".", "clip", "(", "current", ",", "0.0", ",", "rampup_length", ")", "\n", "phase", "=", "1.0", "-", "current", "/", "rampup_length", "\n", "return", "float", "(", "np", ".", "exp", "(", "-", "5.0", "*", "phase", "*", "phase", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.Transform.transform_data": [[10, 13], ["NotImplementedError"], "methods", ["None"], ["    ", "def", "transform_data", "(", "self", ",", "data", ")", ":", "\n", "# Mandatory to be defined by subclasses", "\n", "        ", "raise", "NotImplementedError", "(", "\"Abstract object\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.Transform.transform_label": [[14, 17], ["None"], "methods", ["None"], ["", "def", "transform_label", "(", "self", ",", "label", ")", ":", "\n", "# Do nothing, to be changed in subclasses if needed", "\n", "        ", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.Transform._apply_transform": [[18, 41], ["Transforms.Transform.transform_label", "type", "list", "type", "list", "range", "tuple", "range", "tuple", "Transforms.Transform.transform_data", "Transforms.Transform.transform_data", "len", "Transforms.Transform.transform_data", "len", "Transforms.Transform.transform_data"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.ToTensor.transform_label", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.CombineChannels.transform_data", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.CombineChannels.transform_data", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.CombineChannels.transform_data", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.CombineChannels.transform_data"], ["", "def", "_apply_transform", "(", "self", ",", "sample_no_index", ")", ":", "\n", "        ", "data", ",", "label", "=", "sample_no_index", "\n", "\n", "if", "type", "(", "data", ")", "is", "tuple", ":", "# meaning there is more than one data_input (could be duet, triplet...)", "\n", "            ", "data", "=", "list", "(", "data", ")", "\n", "if", "type", "(", "data", "[", "0", "]", ")", "is", "tuple", ":", "\n", "                ", "data2", ",", "label2", "=", "data", "\n", "data2", "=", "list", "(", "data2", ")", "\n", "for", "k", "in", "range", "(", "len", "(", "data2", ")", ")", ":", "\n", "                    ", "data2", "[", "k", "]", "=", "self", ".", "transform_data", "(", "data2", "[", "k", "]", ")", "\n", "", "data2", "=", "tuple", "(", "data2", ")", "\n", "data", "=", "data2", ",", "label2", "\n", "", "else", ":", "\n", "                ", "for", "k", "in", "range", "(", "len", "(", "data", ")", ")", ":", "\n", "                    ", "data", "[", "k", "]", "=", "self", ".", "transform_data", "(", "data", "[", "k", "]", ")", "\n", "", "data", "=", "tuple", "(", "data", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "flag", ":", "\n", "                ", "data", "=", "self", ".", "transform_data", "(", "data", ",", "target", "=", "label", ")", "\n", "", "else", ":", "\n", "                ", "data", "=", "self", ".", "transform_data", "(", "data", ")", "\n", "", "", "label", "=", "self", ".", "transform_label", "(", "label", ")", "\n", "return", "data", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.Transform.__call__": [[42, 58], ["type", "Transforms.Transform._apply_transform", "Transforms.Transform._apply_transform"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.Transform._apply_transform", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.Transform._apply_transform"], ["", "def", "__call__", "(", "self", ",", "sample", ")", ":", "\n", "        ", "\"\"\" Apply the transformation\n        Args:\n            sample: tuple, a sample defined by a DataLoad class\n\n        Returns:\n            tuple\n            The transformed tuple\n        \"\"\"", "\n", "if", "type", "(", "sample", "[", "1", "]", ")", "is", "int", ":", "# Means there is an index, may be another way to make it cleaner", "\n", "            ", "sample_data", ",", "index", "=", "sample", "\n", "sample_data", "=", "self", ".", "_apply_transform", "(", "sample_data", ")", "\n", "sample", "=", "sample_data", ",", "index", "\n", "", "else", ":", "\n", "            ", "sample", "=", "self", ".", "_apply_transform", "(", "sample", ")", "\n", "", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.GaussianNoise.__init__": [[70, 73], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mean", "=", "0", ",", "std", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.GaussianNoise.transform_data": [[74, 84], ["numpy.abs", "numpy.random.normal"], "methods", ["None"], ["", "def", "transform_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\" Apply the transformation on data\n        Args:\n            data: np.array, the data to be modified\n\n        Returns:\n            np.array\n            The transformed data\n        \"\"\"", "\n", "return", "data", "+", "np", ".", "abs", "(", "np", ".", "random", ".", "normal", "(", "0", ",", "0.5", "**", "2", ",", "data", ".", "shape", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.ApplyLog.__init__": [[88, 90], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "flag", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.ApplyLog.transform_data": [[91, 101], ["librosa.amplitude_to_db"], "methods", ["None"], ["", "def", "transform_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\" Apply the transformation on data\n        Args:\n            data: np.array, the data to be modified\n\n        Returns:\n            np.array\n            The transformed data\n        \"\"\"", "\n", "return", "librosa", ".", "amplitude_to_db", "(", "data", ".", "T", ")", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.PadOrTrunc.__init__": [[132, 136], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "nb_frames", ",", "apply_to_label", "=", "False", ")", ":", "\n", "        ", "self", ".", "flag", "=", "False", "\n", "self", ".", "nb_frames", "=", "nb_frames", "\n", "self", ".", "apply_to_label", "=", "apply_to_label", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.PadOrTrunc.transform_label": [[137, 142], ["Transforms.pad_trunc_seq"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.pad_trunc_seq"], ["", "def", "transform_label", "(", "self", ",", "label", ")", ":", "\n", "        ", "if", "self", ".", "apply_to_label", ":", "\n", "            ", "return", "pad_trunc_seq", "(", "label", ",", "self", ".", "nb_frames", ")", "\n", "", "else", ":", "\n", "            ", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.PadOrTrunc.transform_data": [[143, 153], ["Transforms.pad_trunc_seq"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.pad_trunc_seq"], ["", "", "def", "transform_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\" Apply the transformation on data\n        Args:\n            data: np.array, the data to be modified\n\n        Returns:\n            np.array\n            The transformed data\n        \"\"\"", "\n", "return", "pad_trunc_seq", "(", "data", ",", "self", ".", "nb_frames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.AugmentGaussianNoise.__init__": [[163, 168], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mean", "=", "0.", ",", "std", "=", "None", ",", "snr", "=", "None", ")", ":", "\n", "        ", "self", ".", "flag", "=", "False", "\n", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "self", ".", "snr", "=", "snr", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.AugmentGaussianNoise.gaussian_noise": [[169, 194], ["numpy.sqrt", "len", "numpy.mean", "numpy.random.normal", "warnings.warn", "numpy.random.normal"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["", "@", "staticmethod", "\n", "def", "gaussian_noise", "(", "features", ",", "snr", ")", ":", "\n", "        ", "\"\"\"Apply gaussian noise on each point of the data\n\n            Args:\n                features: numpy.array, features to be modified\n                snr: float, average snr to be used for data augmentation\n            Returns:\n                numpy.ndarray\n                Modified features\n                \"\"\"", "\n", "# If using source separation, using only the first audio (the mixture) to compute the gaussian noise,", "\n", "# Otherwise it just removes the first axis if it was an extended one", "\n", "if", "len", "(", "features", ".", "shape", ")", "==", "3", ":", "\n", "            ", "feat_used", "=", "features", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "feat_used", "=", "features", "\n", "", "std", "=", "np", ".", "sqrt", "(", "np", ".", "mean", "(", "(", "feat_used", "**", "2", ")", "*", "(", "10", "**", "(", "-", "snr", "/", "10", ")", ")", ",", "axis", "=", "-", "2", ")", ")", "\n", "try", ":", "\n", "            ", "noise", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "std", ",", "features", ".", "shape", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "warnings", ".", "warn", "(", "f\"the computed noise did not work std: {std}, using 0.5 for std instead\"", ")", "\n", "noise", "=", "np", ".", "random", ".", "normal", "(", "0", ",", "0.5", ",", "features", ".", "shape", ")", "\n", "\n", "", "return", "features", "+", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.AugmentGaussianNoise.transform_data": [[195, 211], ["numpy.abs", "Transforms.AugmentGaussianNoise.gaussian_noise", "NotImplementedError", "numpy.random.normal"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.AugmentGaussianNoise.gaussian_noise"], ["", "def", "transform_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\" Apply the transformation on data\n            Args:\n                data: np.array, the data to be modified\n\n            Returns:\n                (np.array, np.array)\n                (original data, noisy_data (data + noise))\n        \"\"\"", "\n", "if", "self", ".", "std", "is", "not", "None", ":", "\n", "            ", "noisy_data", "=", "data", "+", "np", ".", "abs", "(", "np", ".", "random", ".", "normal", "(", "0", ",", "0.5", "**", "2", ",", "data", ".", "shape", ")", ")", "\n", "", "elif", "self", ".", "snr", "is", "not", "None", ":", "\n", "            ", "noisy_data", "=", "self", ".", "gaussian_noise", "(", "data", ",", "self", ".", "snr", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Only (mean, std) or snr can be given\"", ")", "\n", "", "return", "data", ",", "noisy_data", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.ToTensor.__init__": [[222, 225], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "unsqueeze_axis", "=", "None", ")", ":", "\n", "        ", "self", ".", "flag", "=", "False", "\n", "self", ".", "unsqueeze_axis", "=", "unsqueeze_axis", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.ToTensor.transform_data": [[226, 239], ["torch.from_numpy().float", "res_data.unsqueeze.unsqueeze.unsqueeze", "torch.from_numpy"], "methods", ["None"], ["", "def", "transform_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\" Apply the transformation on data\n            Args:\n                data: np.array, the data to be modified\n\n            Returns:\n                np.array\n                The transformed data\n        \"\"\"", "\n", "res_data", "=", "torch", ".", "from_numpy", "(", "data", ")", ".", "float", "(", ")", "\n", "if", "self", ".", "unsqueeze_axis", "is", "not", "None", ":", "\n", "            ", "res_data", "=", "res_data", ".", "unsqueeze", "(", "self", ".", "unsqueeze_axis", ")", "\n", "", "return", "res_data", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.ToTensor.transform_label": [[240, 242], ["torch.from_numpy().float", "torch.from_numpy"], "methods", ["None"], ["", "def", "transform_label", "(", "self", ",", "label", ")", ":", "\n", "        ", "return", "torch", ".", "from_numpy", "(", "label", ")", ".", "float", "(", ")", "# float otherwise error", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.Normalize.__init__": [[252, 255], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "scaler", ")", ":", "\n", "        ", "self", ".", "flag", "=", "False", "\n", "self", ".", "scaler", "=", "scaler", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.Normalize.transform_data": [[256, 266], ["Transforms.Normalize.scaler.normalize"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.normalize"], ["", "def", "transform_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\" Apply the transformation on data\n            Args:\n                data: np.array, the data to be modified\n\n            Returns:\n                np.array\n                The transformed data\n        \"\"\"", "\n", "return", "self", ".", "scaler", ".", "normalize", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.Mixup.__init__": [[269, 274], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "alpha", "=", "0.2", ",", "beta", "=", "0.2", ",", "mixup_label_type", "=", "\"soft\"", ")", ":", "\n", "        ", "self", ".", "flag", "=", "True", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "mixup_label_type", "=", "mixup_label_type", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.Mixup.transform_data": [[275, 295], ["numpy.random.beta", "torch.randperm", "numpy.clip", "numpy.clip", "NotImplementedError"], "methods", ["None"], ["", "def", "transform_data", "(", "self", ",", "data", ",", "target", "=", "None", ")", ":", "\n", "        ", "batch_size", "=", "data", ".", "shape", "[", "0", "]", "\n", "c", "=", "np", ".", "random", ".", "beta", "(", "self", ".", "alpha", ",", "self", ".", "beta", ")", "\n", "perm", "=", "torch", ".", "randperm", "(", "batch_size", ")", "\n", "\n", "mixed_data", "=", "c", "*", "data", "+", "(", "1", "-", "c", ")", "*", "data", "[", "perm", ",", ":", "]", "\n", "if", "target", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "mixup_label_type", "==", "\"soft\"", ":", "\n", "                ", "mixed_target", "=", "np", ".", "clip", "(", "\n", "c", "*", "target", "+", "(", "1", "-", "c", ")", "*", "target", "[", "perm", ",", ":", "]", ",", "a_min", "=", "0", ",", "a_max", "=", "1", ")", "\n", "", "elif", "self", ".", "mixup_label_type", "==", "\"hard\"", ":", "\n", "                ", "mixed_target", "=", "np", ".", "clip", "(", "target", "+", "target", "[", "perm", ",", ":", "]", ",", "a_min", "=", "0", ",", "a_max", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\n", "f\"mixup_label_type: {mixup_label_type} not implemented. choise in \"", "\n", "f\"{'soft', 'hard'}\"", "\n", ")", "\n", "", "return", "(", "data", ",", "mixed_data", ")", ",", "mixed_target", "\n", "", "else", ":", "\n", "            ", "return", "data", ",", "mixed_data", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.TemporalShifting.__init__": [[298, 301], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "net_pooling", "=", "4", ")", ":", "\n", "        ", "self", ".", "flag", "=", "True", "\n", "self", ".", "net_pooling", "=", "net_pooling", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.TemporalShifting.transform_data": [[302, 315], ["int", "numpy.roll", "random.gauss", "numpy.roll", "abs"], "methods", ["None"], ["", "def", "transform_data", "(", "self", ",", "data", ",", "target", "=", "None", ")", ":", "\n", "        ", "frames", ",", "n_bands", "=", "data", ".", "shape", "\n", "\n", "shift", "=", "int", "(", "random", ".", "gauss", "(", "0", ",", "40", ")", ")", "\n", "shifted", "=", "np", ".", "roll", "(", "data", ",", "shift", ",", "axis", "=", "0", ")", "\n", "\n", "if", "target", "is", "not", "None", ":", "\n", "            ", "shift", "=", "-", "abs", "(", "shift", ")", "//", "self", ".", "net_pooling", "if", "shift", "<", "0", "else", "shift", "//", "self", ".", "net_pooling", "\n", "new_labels", "=", "np", ".", "roll", "(", "target", ",", "shift", ",", "axis", "=", "0", ")", "\n", "\n", "return", "(", "data", ",", "shifted", ")", ",", "new_labels", "\n", "", "else", ":", "\n", "            ", "return", "data", ",", "shifted", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.CombineChannels.__init__": [[325, 329], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "combine_on", "=", "\"max\"", ",", "n_channel_mix", "=", "2", ")", ":", "\n", "        ", "self", ".", "flag", "=", "False", "\n", "self", ".", "combine_on", "=", "combine_on", "\n", "self", ".", "n_channel_mix", "=", "n_channel_mix", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.CombineChannels.transform_data": [[330, 350], ["channels_en.argsort", "sources[].sum", "numpy.concatenate"], "methods", ["None"], ["", "def", "transform_data", "(", "self", ",", "data", ")", ":", "\n", "        ", "\"\"\" Apply the transformation on data\n            Args:\n                data: np.array, the data to be modified, assuming the first values are the mixture,\n                    and the other channels the sources\n\n            Returns:\n                np.array\n                The transformed data\n        \"\"\"", "\n", "mix", "=", "data", "[", ":", "1", "]", "# :1 is just to keep the first axis", "\n", "sources", "=", "data", "[", "1", ":", "]", "\n", "channels_en", "=", "(", "sources", "**", "2", ")", ".", "sum", "(", "-", "1", ")", ".", "sum", "(", "-", "1", ")", "# Get the energy per channel", "\n", "indexes_sorted", "=", "channels_en", ".", "argsort", "(", ")", "\n", "sources_to_add", "=", "sources", "[", "indexes_sorted", "[", ":", "2", "]", "]", ".", "sum", "(", "0", ")", "\n", "if", "self", ".", "combine_on", "==", "\"min\"", ":", "\n", "            ", "sources", "[", "indexes_sorted", "[", "2", "]", "]", "+=", "sources_to_add", "\n", "", "elif", "self", ".", "combine_on", "==", "\"max\"", ":", "\n", "            ", "sources", "[", "indexes_sorted", "[", "-", "1", "]", "]", "+=", "sources_to_add", "\n", "", "return", "np", ".", "concatenate", "(", "(", "mix", ",", "sources", "[", "indexes_sorted", "[", "2", ":", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.Compose.__init__": [[408, 410], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "transforms", ")", ":", "\n", "        ", "self", ".", "transforms", "=", "transforms", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.Compose.add_transform": [[411, 415], ["Transforms.Compose.transforms.copy", "Transforms.Compose.append", "Transforms.Compose"], "methods", ["None"], ["", "def", "add_transform", "(", "self", ",", "transform", ")", ":", "\n", "        ", "t", "=", "self", ".", "transforms", ".", "copy", "(", ")", "\n", "t", ".", "append", "(", "transform", ")", "\n", "return", "Compose", "(", "t", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.Compose.__call__": [[416, 420], ["t"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "audio", ")", ":", "\n", "        ", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "audio", "=", "t", "(", "audio", ")", "\n", "", "return", "audio", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.Compose.__repr__": [[421, 429], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "format_string", "=", "self", ".", "__class__", ".", "__name__", "+", "'('", "\n", "for", "t", "in", "self", ".", "transforms", ":", "\n", "            ", "format_string", "+=", "'\\n'", "\n", "format_string", "+=", "'    {0}'", ".", "format", "(", "t", ")", "\n", "", "format_string", "+=", "'\\n)'", "\n", "\n", "return", "format_string", "\n", "", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.pad_trunc_seq": [[103, 122], ["numpy.pad", "len"], "function", ["None"], ["", "", "def", "pad_trunc_seq", "(", "x", ",", "max_len", ")", ":", "\n", "    ", "\"\"\"Pad or truncate a sequence data to a fixed length.\n    The sequence should be on axis -2.\n\n    Args:\n      x: ndarray, input sequence data.\n      max_len: integer, length of sequence to be padded or truncated.\n\n    Returns:\n      ndarray, Padded or truncated input sequence data.\n    \"\"\"", "\n", "shape", "=", "x", ".", "shape", "\n", "if", "shape", "[", "-", "2", "]", "<=", "max_len", ":", "\n", "        ", "padded", "=", "max_len", "-", "shape", "[", "-", "2", "]", "\n", "padded_shape", "=", "(", "(", "0", ",", "0", ")", ",", ")", "*", "len", "(", "shape", "[", ":", "-", "2", "]", ")", "+", "(", "(", "0", ",", "padded", ")", ",", "(", "0", ",", "0", ")", ")", "\n", "x", "=", "np", ".", "pad", "(", "x", ",", "padded_shape", ",", "mode", "=", "\"constant\"", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "x", "[", "...", ",", ":", "max_len", ",", ":", "]", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.get_transforms": [[352, 369], ["transf.extend", "Transforms.Compose", "transf.append", "transf.append", "transf.append", "Transforms.CombineChannels", "Transforms.AugmentGaussianNoise", "Transforms.ApplyLog", "Transforms.PadOrTrunc", "Transforms.ToTensor", "Transforms.Normalize"], "function", ["None"], ["", "", "def", "get_transforms", "(", "frames", ",", "scaler", "=", "None", ",", "add_axis", "=", "0", ",", "noise_dict_params", "=", "None", ",", "combine_channels_args", "=", "None", ")", ":", "\n", "    ", "transf", "=", "[", "]", "\n", "unsqueeze_axis", "=", "None", "\n", "if", "add_axis", "is", "not", "None", ":", "\n", "        ", "unsqueeze_axis", "=", "add_axis", "\n", "\n", "", "if", "combine_channels_args", "is", "not", "None", ":", "\n", "        ", "transf", ".", "append", "(", "CombineChannels", "(", "*", "combine_channels_args", ")", ")", "\n", "\n", "", "if", "noise_dict_params", "is", "not", "None", ":", "\n", "        ", "transf", ".", "append", "(", "AugmentGaussianNoise", "(", "**", "noise_dict_params", ")", ")", "\n", "\n", "", "transf", ".", "extend", "(", "[", "ApplyLog", "(", ")", ",", "PadOrTrunc", "(", "nb_frames", "=", "frames", ")", ",", "ToTensor", "(", "unsqueeze_axis", "=", "unsqueeze_axis", ")", "]", ")", "\n", "if", "scaler", "is", "not", "None", ":", "\n", "        ", "transf", ".", "append", "(", "Normalize", "(", "scaler", "=", "scaler", ")", ")", "\n", "\n", "", "return", "Compose", "(", "transf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Transforms.get_transforms_v2": [[372, 396], ["transf.extend", "Transforms.Compose", "transf.append", "transf.append", "transf.append", "transf.append", "transf.append", "Transforms.CombineChannels", "Transforms.AugmentGaussianNoise", "Transforms.Mixup", "Transforms.TemporalShifting", "Transforms.ApplyLog", "Transforms.PadOrTrunc", "Transforms.ToTensor", "Transforms.Normalize"], "function", ["None"], ["", "def", "get_transforms_v2", "(", "frames", ",", "scaler", "=", "None", ",", "add_axis", "=", "0", ",", "noise_dict_params", "=", "None", ",", "mixup_dict_params", "=", "None", ",", "shift_dict_params", "=", "None", ",", "combine_channels_args", "=", "None", ")", ":", "\n", "    ", "transf", "=", "[", "]", "\n", "unsqueeze_axis", "=", "None", "\n", "if", "add_axis", "is", "not", "None", ":", "\n", "        ", "unsqueeze_axis", "=", "add_axis", "\n", "\n", "", "if", "combine_channels_args", "is", "not", "None", ":", "\n", "        ", "transf", ".", "append", "(", "CombineChannels", "(", "*", "combine_channels_args", ")", ")", "\n", "\n", "", "if", "noise_dict_params", "is", "not", "None", ":", "\n", "        ", "transf", ".", "append", "(", "AugmentGaussianNoise", "(", "**", "noise_dict_params", ")", ")", "\n", "\n", "", "if", "mixup_dict_params", "is", "not", "None", ":", "\n", "        ", "transf", ".", "append", "(", "Mixup", "(", "**", "mixup_dict_params", ")", ")", "\n", "\n", "", "if", "shift_dict_params", "is", "not", "None", ":", "\n", "        ", "transf", ".", "append", "(", "TemporalShifting", "(", "**", "shift_dict_params", ")", ")", "\n", "\n", "\n", "", "transf", ".", "extend", "(", "[", "ApplyLog", "(", ")", ",", "PadOrTrunc", "(", "nb_frames", "=", "frames", ")", ",", "ToTensor", "(", "unsqueeze_axis", "=", "unsqueeze_axis", ")", "]", ")", "\n", "if", "scaler", "is", "not", "None", ":", "\n", "        ", "transf", ".", "append", "(", "Normalize", "(", "scaler", "=", "scaler", ")", ")", "\n", "\n", "", "return", "Compose", "(", "transf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.SaveBest.__init__": [[108, 118], ["NotImplementedError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "val_comp", "=", "\"inf\"", ")", ":", "\n", "        ", "self", ".", "comp", "=", "val_comp", "\n", "if", "val_comp", "in", "[", "\"inf\"", ",", "\"lt\"", ",", "\"desc\"", "]", ":", "\n", "            ", "self", ".", "best_val", "=", "np", ".", "inf", "\n", "", "elif", "val_comp", "in", "[", "\"sup\"", ",", "\"gt\"", ",", "\"asc\"", "]", ":", "\n", "            ", "self", ".", "best_val", "=", "0", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"value comparison is only 'inf' or 'sup'\"", ")", "\n", "", "self", ".", "best_epoch", "=", "0", "\n", "self", ".", "current_epoch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.SaveBest.apply": [[119, 133], ["None"], "methods", ["None"], ["", "def", "apply", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\" Apply the callback\n        Args:\n            value: float, the value of the metric followed\n        \"\"\"", "\n", "decision", "=", "False", "\n", "if", "self", ".", "current_epoch", "==", "0", ":", "\n", "            ", "decision", "=", "True", "\n", "", "if", "(", "self", ".", "comp", "==", "\"inf\"", "and", "value", "<", "self", ".", "best_val", ")", "or", "(", "self", ".", "comp", "==", "\"sup\"", "and", "value", ">", "self", ".", "best_val", ")", ":", "\n", "            ", "self", ".", "best_epoch", "=", "self", ".", "current_epoch", "\n", "self", ".", "best_val", "=", "value", "\n", "decision", "=", "True", "\n", "", "self", ".", "current_epoch", "+=", "1", "\n", "return", "decision", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.JSD.__init__": [[136, 139], ["torch.nn.Module.__init__", "torch.nn.KLDivLoss().cuda", "torch.nn.KLDivLoss"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "JSD", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "kld", "=", "nn", ".", "KLDivLoss", "(", ")", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.JSD.apply": [[140, 143], ["utils.JSD.kld", "utils.JSD.kld"], "methods", ["None"], ["", "def", "apply", "(", "self", ",", "p", ",", "q", ")", ":", "\n", "        ", "m", "=", "0.5", "*", "(", "p", "+", "q", ")", "\n", "return", "-", "0.5", "*", "(", "self", ".", "kld", "(", "p", ",", "m", ")", "+", "self", ".", "kld", "(", "q", ",", "m", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.Entropy.__init__": [[145, 147], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Entropy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.Entropy.forward": [[148, 152], ["torch.log", "b.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "dim", ")", ":", "\n", "        ", "b", "=", "x", "*", "torch", ".", "log", "(", "x", ")", "\n", "b", "=", "-", "1.0", "*", "b", ".", "sum", "(", "dim", ")", "\n", "return", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.EarlyStopping.__init__": [[167, 179], ["NotImplementedError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "patience", ",", "val_comp", "=", "\"inf\"", ",", "init_patience", "=", "0", ")", ":", "\n", "        ", "self", ".", "patience", "=", "patience", "\n", "self", ".", "first_early_wait", "=", "init_patience", "\n", "self", ".", "val_comp", "=", "val_comp", "\n", "if", "val_comp", "==", "\"inf\"", ":", "\n", "            ", "self", ".", "best_val", "=", "np", ".", "inf", "\n", "", "elif", "val_comp", "==", "\"sup\"", ":", "\n", "            ", "self", ".", "best_val", "=", "0", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"value comparison is only 'inf' or 'sup'\"", ")", "\n", "", "self", ".", "current_epoch", "=", "0", "\n", "self", ".", "best_epoch", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.EarlyStopping.apply": [[180, 201], ["None"], "methods", ["None"], ["", "def", "apply", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\" Apply the callback\n\n        Args:\n            value: the value of the metric followed\n        \"\"\"", "\n", "current", "=", "False", "\n", "if", "self", ".", "val_comp", "==", "\"inf\"", ":", "\n", "            ", "if", "value", "<", "self", ".", "best_val", ":", "\n", "                ", "current", "=", "True", "\n", "", "", "if", "self", ".", "val_comp", "==", "\"sup\"", ":", "\n", "            ", "if", "value", ">", "self", ".", "best_val", ":", "\n", "                ", "current", "=", "True", "\n", "", "", "if", "current", ":", "\n", "            ", "self", ".", "best_val", "=", "value", "\n", "self", ".", "best_epoch", "=", "self", ".", "current_epoch", "\n", "", "elif", "self", ".", "current_epoch", "-", "self", ".", "best_epoch", ">", "self", ".", "patience", "and", "self", ".", "current_epoch", ">", "self", ".", "first_early_wait", ":", "\n", "            ", "self", ".", "current_epoch", "=", "0", "\n", "return", "True", "\n", "", "self", ".", "current_epoch", "+=", "1", "\n", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeterSet.__init__": [[204, 206], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "meters", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeterSet.__getitem__": [[207, 209], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "self", ".", "meters", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeterSet.update": [[210, 214], ["utils.AverageMeterSet.meters[].update", "utils.AverageMeter"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update"], ["", "def", "update", "(", "self", ",", "name", ",", "value", ",", "n", "=", "1", ")", ":", "\n", "        ", "if", "name", "not", "in", "self", ".", "meters", ":", "\n", "            ", "self", ".", "meters", "[", "name", "]", "=", "AverageMeter", "(", ")", "\n", "", "self", ".", "meters", "[", "name", "]", ".", "update", "(", "value", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeterSet.reset": [[215, 218], ["utils.AverageMeterSet.meters.values", "meter.reset"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeterSet.values", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "for", "meter", "in", "self", ".", "meters", ".", "values", "(", ")", ":", "\n", "            ", "meter", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeterSet.values": [[219, 221], ["utils.AverageMeterSet.meters.items"], "methods", ["None"], ["", "", "def", "values", "(", "self", ",", "postfix", "=", "''", ")", ":", "\n", "        ", "return", "{", "name", "+", "postfix", ":", "meter", ".", "val", "for", "name", ",", "meter", "in", "self", ".", "meters", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeterSet.averages": [[222, 224], ["utils.AverageMeterSet.meters.items"], "methods", ["None"], ["", "def", "averages", "(", "self", ",", "postfix", "=", "'/avg'", ")", ":", "\n", "        ", "return", "{", "name", "+", "postfix", ":", "meter", ".", "avg", "for", "name", ",", "meter", "in", "self", ".", "meters", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeterSet.sums": [[225, 227], ["utils.AverageMeterSet.meters.items"], "methods", ["None"], ["", "def", "sums", "(", "self", ",", "postfix", "=", "'/sum'", ")", ":", "\n", "        ", "return", "{", "name", "+", "postfix", ":", "meter", ".", "sum", "for", "name", ",", "meter", "in", "self", ".", "meters", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeterSet.counts": [[228, 230], ["utils.AverageMeterSet.meters.items"], "methods", ["None"], ["", "def", "counts", "(", "self", ",", "postfix", "=", "'/count'", ")", ":", "\n", "        ", "return", "{", "name", "+", "postfix", ":", "meter", ".", "count", "for", "name", ",", "meter", "in", "self", ".", "meters", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeterSet.__str__": [[231, 239], ["utils.AverageMeterSet.meters.items"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "string", "=", "\"\"", "\n", "for", "name", ",", "meter", "in", "self", ".", "meters", ".", "items", "(", ")", ":", "\n", "            ", "fmat", "=", "\".4f\"", "\n", "if", "meter", ".", "val", "<", "0.01", ":", "\n", "                ", "fmat", "=", "\".2E\"", "\n", "", "string", "+=", "\"{} {:{format}} \\t\"", ".", "format", "(", "name", ",", "meter", ".", "val", ",", "format", "=", "fmat", ")", "\n", "", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.__init__": [[244, 246], ["utils.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.reset": [[247, 252], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update": [[253, 258], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.__format__": [[259, 261], ["None"], "methods", ["None"], ["", "def", "__format__", "(", "self", ",", "format", ")", ":", "\n", "        ", "return", "\"{self.avg:{format}}\"", ".", "format", "(", "self", "=", "self", ",", "format", "=", "format", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.median_smoothing": [[19, 34], ["torch.zeros().cuda", "range", "torch.nn.functional.pad", "torch.nn.functional.pad", "torch.cat", "torch.nn.functional.pad.unfold", "torch.median", "torch.zeros", "indices[].unsqueeze"], "function", ["None"], ["def", "median_smoothing", "(", "input_tensor", ",", "win_length", ")", ":", "\n", "    ", "nFrms", ",", "nClass", "=", "input_tensor", ".", "shape", "[", "0", "]", ",", "input_tensor", ".", "shape", "[", "1", "]", "\n", "\n", "pad_length", "=", "(", "win_length", "-", "1", ")", "//", "2", "\n", "output_tensor", "=", "torch", ".", "zeros", "(", "nFrms", ",", "nClass", ")", ".", "cuda", "(", ")", "\n", "for", "cter", "in", "range", "(", "nClass", ")", ":", "\n", "        ", "tensor1D", "=", "input_tensor", "[", ":", ",", "cter", "]", "\n", "indices", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "tensor1D", ",", "(", "pad_length", ",", "0", ")", ",", "mode", "=", "\"constant\"", ",", "value", "=", "0.", ")", "\n", "indices", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "indices", ",", "(", "0", ",", "pad_length", ")", ",", "mode", "=", "\"constant\"", ",", "value", "=", "0.", ")", "\n", "indices", "[", "...", ",", ":", "pad_length", "]", "=", "torch", ".", "cat", "(", "pad_length", "*", "[", "indices", "[", "...", ",", "pad_length", "]", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "roll", "=", "indices", ".", "unfold", "(", "-", "1", ",", "win_length", ",", "1", ")", "\n", "values", ",", "_", "=", "torch", ".", "median", "(", "roll", ",", "-", "1", ")", "\n", "output_tensor", "[", ":", ",", "cter", "]", "=", "values", "[", ":", "nFrms", "]", "\n", "\n", "", "return", "output_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.read_audio": [[36, 55], ["soundfile.read", "numpy.mean", "librosa.resample"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.resample_folder.resample"], ["", "def", "read_audio", "(", "path", ",", "target_fs", "=", "None", ")", ":", "\n", "    ", "\"\"\" Read a wav file\n    Args:\n        path: str, path of the audio file\n        target_fs: int, (Default value = None) sampling rate of the returned audio file, if not specified, the sampling\n            rate of the audio file is taken\n\n    Returns:\n        tuple\n        (numpy.array, sampling rate), array containing the audio at the sampling rate given\n\n    \"\"\"", "\n", "(", "audio", ",", "fs", ")", "=", "soundfile", ".", "read", "(", "path", ")", "\n", "if", "audio", ".", "ndim", ">", "1", ":", "\n", "        ", "audio", "=", "np", ".", "mean", "(", "audio", ",", "axis", "=", "1", ")", "\n", "", "if", "target_fs", "is", "not", "None", "and", "fs", "!=", "target_fs", ":", "\n", "        ", "audio", "=", "librosa", ".", "resample", "(", "audio", ",", "orig_sr", "=", "fs", ",", "target_sr", "=", "target_fs", ")", "\n", "fs", "=", "target_fs", "\n", "", "return", "audio", ",", "fs", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.weights_init": [[57, 77], ["classname.find", "torch.nn.init.xavier_uniform_", "m.bias.data.fill_", "classname.find", "m.weight.data.normal_", "m.bias.data.fill_", "numpy.sqrt", "classname.find", "m.parameters", "classname.find", "m.weight.data.normal_", "m.bias.data.zero_", "len", "torch.nn.init.orthogonal_", "weight.size"], "function", ["None"], ["", "def", "weights_init", "(", "m", ")", ":", "\n", "    ", "\"\"\" Initialize the weights of some layers of neural networks, here Conv2D, BatchNorm, GRU, Linear\n        Based on the work of Xavier Glorot\n    Args:\n        m: the model to initialize\n    \"\"\"", "\n", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Conv2d'", ")", "!=", "-", "1", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ",", "gain", "=", "np", ".", "sqrt", "(", "2", ")", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "elif", "classname", ".", "find", "(", "'BatchNorm'", ")", "!=", "-", "1", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "1.0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "elif", "classname", ".", "find", "(", "'GRU'", ")", "!=", "-", "1", ":", "\n", "        ", "for", "weight", "in", "m", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "len", "(", "weight", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "nn", ".", "init", ".", "orthogonal_", "(", "weight", ".", "data", ")", "\n", "", "", "", "elif", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.01", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.to_cuda_if_available": [[79, 94], ["list", "torch.cuda.is_available", "enumerate", "len", "torch_obj.cuda"], "function", ["None"], ["", "", "def", "to_cuda_if_available", "(", "*", "args", ")", ":", "\n", "    ", "\"\"\" Transfer object (Module, Tensor) to GPU if GPU available\n    Args:\n        args: torch object to put on cuda if available (needs to have object.cuda() defined)\n\n    Returns:\n        Objects on GPU if GPUs available\n    \"\"\"", "\n", "res", "=", "list", "(", "args", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "for", "i", ",", "torch_obj", "in", "enumerate", "(", "args", ")", ":", "\n", "            ", "res", "[", "i", "]", "=", "torch_obj", ".", "cuda", "(", ")", "\n", "", "", "if", "len", "(", "res", ")", "==", "1", ":", "\n", "        ", "return", "res", "[", "0", "]", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.generate_tsv_wav_durations": [[263, 280], ["glob.glob", "pandas.DataFrame", "os.path.join", "os.path.join", "meta_list.append", "pd.DataFrame.to_csv", "soundfile.info", "os.path.basename", "os.path.basename"], "function", ["None"], ["", "", "def", "generate_tsv_wav_durations", "(", "audio_dir", ",", "out_tsv", ")", ":", "\n", "    ", "\"\"\" Generate a dataframe with filename and duration of the file\n    Args:\n        audio_dir: str, the path of the folder where audio files are (used by glob.glob)\n        out_tsv: str, the path of the output tsv file\n\n    Returns:\n        pd.DataFrame, the dataframe containing filenames and durations\n    \"\"\"", "\n", "meta_list", "=", "[", "]", "\n", "for", "file", "in", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "audio_dir", ",", "\"*.wav\"", ")", ")", ":", "\n", "        ", "d", "=", "soundfile", ".", "info", "(", "file", ")", ".", "duration", "\n", "meta_list", ".", "append", "(", "[", "os", ".", "path", ".", "basename", "(", "file", ")", ",", "d", "]", ")", "\n", "", "meta_df", "=", "pd", ".", "DataFrame", "(", "meta_list", ",", "columns", "=", "[", "\"filename\"", ",", "\"duration\"", "]", ")", "\n", "if", "out_tsv", "is", "not", "None", ":", "\n", "        ", "meta_df", ".", "to_csv", "(", "out_tsv", ",", "sep", "=", "\"\\t\"", ",", "index", "=", "False", ",", "float_format", "=", "\"%.1f\"", ")", "\n", "", "return", "meta_df", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.generate_tsv_from_isolated_events": [[282, 317], ["os.path.exists", "os.path.exists", "pandas.read_csv", "pandas.DataFrame", "os.walk", "os.walk", "source_sep_df.append.append", "desed.utils.create_folder", "source_sep_df.append.to_csv", "os.listdir", "os.listdir", "os.isdir", "os.join", "pandas.DataFrame", "os.path.dirname", "os.path.dirname", "os.join", "list_isolated_files.append", "warnings.warn", "os.splitext", "directory.split", "len", "os.join", "os.join"], "function", ["None"], ["", "def", "generate_tsv_from_isolated_events", "(", "wav_folder", ",", "out_tsv", "=", "None", ")", ":", "\n", "    ", "\"\"\" Generate list of separated wav files in a folder and export them in a tsv file\n    Separated audio files considered are all wav files in 'subdirectories' of the 'wav_folder'\n    Args:\n        wav_folder: str, path of the folder containing subdirectories (one for each mixture separated)\n        out_tsv: str, path of the csv in which to save the list of files\n    Returns:\n        pd.DataFrame, having only one column with the filename considered\n    \"\"\"", "\n", "if", "out_tsv", "is", "not", "None", "and", "os", ".", "path", ".", "exists", "(", "out_tsv", ")", ":", "\n", "        ", "source_sep_df", "=", "pd", ".", "read_csv", "(", "out_tsv", ",", "sep", "=", "\"\\t\"", ")", "\n", "", "else", ":", "\n", "        ", "source_sep_df", "=", "pd", ".", "DataFrame", "(", ")", "\n", "list_dirs", "=", "[", "d", "for", "d", "in", "os", ".", "listdir", "(", "wav_folder", ")", "if", "osp", ".", "isdir", "(", "osp", ".", "join", "(", "wav_folder", ",", "d", ")", ")", "]", "\n", "for", "dirname", "in", "list_dirs", ":", "\n", "            ", "list_isolated_files", "=", "[", "]", "\n", "for", "directory", ",", "subdir", ",", "fnames", "in", "os", ".", "walk", "(", "osp", ".", "join", "(", "wav_folder", ",", "dirname", ")", ")", ":", "\n", "                ", "for", "fname", "in", "fnames", ":", "\n", "                    ", "if", "osp", ".", "splitext", "(", "fname", ")", "[", "1", "]", "in", "[", "\".wav\"", "]", ":", "\n", "# Get the level folders and keep it in the tsv", "\n", "                        ", "subfolder", "=", "directory", ".", "split", "(", "dirname", "+", "os", ".", "sep", ")", "[", "1", ":", "]", "\n", "if", "len", "(", "subfolder", ")", ">", "0", ":", "\n", "                            ", "subdirs", "=", "osp", ".", "join", "(", "*", "subfolder", ")", "\n", "", "else", ":", "\n", "                            ", "subdirs", "=", "\"\"", "\n", "# Append the subfolders and name in the list of files", "\n", "", "list_isolated_files", ".", "append", "(", "osp", ".", "join", "(", "dirname", ",", "subdirs", ",", "fname", ")", ")", "\n", "", "else", ":", "\n", "                        ", "warnings", ".", "warn", "(", "f\"Not only wav audio files in the separated source folder,\"", "\n", "f\"{fname} not added to the .tsv file\"", ")", "\n", "", "", "", "source_sep_df", "=", "source_sep_df", ".", "append", "(", "pd", ".", "DataFrame", "(", "list_isolated_files", ",", "columns", "=", "[", "\"filename\"", "]", ")", ")", "\n", "", "if", "out_tsv", "is", "not", "None", ":", "\n", "            ", "create_folder", "(", "os", ".", "path", ".", "dirname", "(", "out_tsv", ")", ")", "\n", "source_sep_df", ".", "to_csv", "(", "out_tsv", ",", "sep", "=", "\"\\t\"", ",", "index", "=", "False", ",", "float_format", "=", "\"%.3f\"", ")", "\n", "", "", "return", "source_sep_df", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.meta_path_to_audio_dir": [[319, 321], ["os.path.splitext", "os.path.splitext", "tsv_path.replace", "config.cfg.synthetic"], "function", ["None"], ["", "def", "meta_path_to_audio_dir", "(", "tsv_path", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "splitext", "(", "tsv_path", ".", "replace", "(", "\"metadata\"", ",", "\"audio\"", ")", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.audio_dir_to_meta_path": [[323, 325], ["audio_dir.replace"], "function", ["None"], ["", "def", "audio_dir_to_meta_path", "(", "audio_dir", ")", ":", "\n", "    ", "return", "audio_dir", ".", "replace", "(", "\"audio\"", ",", "\"metadata\"", ")", "+", "\".tsv\"", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.get_durations_df": [[327, 337], ["os.path.splitext", "os.path.splitext", "utils.meta_path_to_audio_dir", "os.path.exists", "os.path.exists", "utils.generate_tsv_wav_durations", "pandas.read_csv"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.meta_path_to_audio_dir", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.generate_tsv_wav_durations"], ["", "def", "get_durations_df", "(", "gtruth_path", ",", "audio_dir", "=", "None", ")", ":", "\n", "    ", "if", "audio_dir", "is", "None", ":", "\n", "        ", "audio_dir", "=", "meta_path_to_audio_dir", "(", "cfg", ".", "synthetic", ")", "\n", "", "path", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "gtruth_path", ")", "\n", "path_durations_synth", "=", "\"./validation_durations\"", "+", "ext", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path_durations_synth", ")", ":", "\n", "        ", "durations_df", "=", "generate_tsv_wav_durations", "(", "audio_dir", ",", "path_durations_synth", ")", "\n", "", "else", ":", "\n", "        ", "durations_df", "=", "pd", ".", "read_csv", "(", "path_durations_synth", ",", "sep", "=", "\"\\t\"", ")", "\n", "", "return", "durations_df", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.schedulers.ExponentialWarmup.__init__": [[14, 20], ["BaseScheduler.__init__"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "max_lr", ",", "rampup_length", ",", "exponent", "=", "-", "5.0", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "optimizer", ")", "\n", "self", ".", "rampup_len", "=", "rampup_length", "\n", "self", ".", "max_lr", "=", "max_lr", "\n", "self", ".", "step_num", "=", "1", "\n", "self", ".", "exponent", "=", "exponent", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.schedulers.ExponentialWarmup._get_scaling_factor": [[21, 30], ["numpy.clip", "float", "numpy.exp"], "methods", ["None"], ["", "def", "_get_scaling_factor", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "rampup_len", "==", "0", ":", "\n", "            ", "return", "1.0", "\n", "", "else", ":", "\n", "\n", "            ", "current", "=", "np", ".", "clip", "(", "self", ".", "step_num", ",", "0.0", ",", "self", ".", "rampup_len", ")", "\n", "phase", "=", "1.0", "-", "current", "/", "self", ".", "rampup_len", "\n", "return", "float", "(", "np", ".", "exp", "(", "self", ".", "exponent", "*", "phase", "*", "phase", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.schedulers.ExponentialWarmup._get_lr": [[31, 33], ["schedulers.ExponentialWarmup._get_scaling_factor"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.schedulers.ExponentialWarmup._get_scaling_factor"], ["", "", "def", "_get_lr", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "max_lr", "*", "self", ".", "_get_scaling_factor", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.__init__": [[21, 37], ["int", "type", "labels.tolist.tolist.tolist", "int"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "labels", ",", "audio_len", ",", "frame_len", ",", "frame_hop", ",", "net_pooling", "=", "1", ",", "fs", "=", "16000", "\n", ")", ":", "\n", "        ", "if", "type", "(", "labels", ")", "in", "[", "np", ".", "ndarray", ",", "np", ".", "array", "]", ":", "\n", "            ", "labels", "=", "labels", ".", "tolist", "(", ")", "\n", "", "self", ".", "labels", "=", "labels", "\n", "self", ".", "audio_len", "=", "audio_len", "\n", "self", ".", "frame_len", "=", "frame_len", "\n", "self", ".", "frame_hop", "=", "frame_hop", "\n", "self", ".", "fs", "=", "fs", "\n", "self", ".", "net_pooling", "=", "net_pooling", "\n", "n_frames", "=", "self", ".", "audio_len", "*", "self", ".", "fs", "\n", "# self.n_frames = int(", "\n", "#     int(((n_frames - self.frame_len) / self.frame_hop)) / self.net_pooling", "\n", "# )", "\n", "self", ".", "n_frames", "=", "int", "(", "int", "(", "(", "n_frames", "/", "self", ".", "frame_hop", ")", ")", "/", "self", ".", "net_pooling", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.encode_weak": [[38, 66], ["numpy.zeros", "type", "type", "len", "labels.split.split.split", "pandas.isna", "encoder.ManyHotEncoder.labels.index", "numpy.zeros", "len"], "methods", ["None"], ["", "def", "encode_weak", "(", "self", ",", "labels", ")", ":", "\n", "        ", "\"\"\" Encode a list of weak labels into a numpy array\n\n        Args:\n            labels: list, list of labels to encode (to a vector of 0 and 1)\n\n        Returns:\n            numpy.array\n            A vector containing 1 for each label, and 0 everywhere else\n        \"\"\"", "\n", "# useful for tensor empty labels", "\n", "if", "type", "(", "labels", ")", "is", "str", ":", "\n", "            ", "if", "labels", "==", "\"empty\"", ":", "\n", "                ", "y", "=", "np", ".", "zeros", "(", "len", "(", "self", ".", "labels", ")", ")", "-", "1", "\n", "return", "y", "\n", "", "else", ":", "\n", "                ", "labels", "=", "labels", ".", "split", "(", "\",\"", ")", "\n", "", "", "if", "type", "(", "labels", ")", "is", "pd", ".", "DataFrame", ":", "\n", "            ", "if", "labels", ".", "empty", ":", "\n", "                ", "labels", "=", "[", "]", "\n", "", "elif", "\"event_label\"", "in", "labels", ".", "columns", ":", "\n", "                ", "labels", "=", "labels", "[", "\"event_label\"", "]", "\n", "", "", "y", "=", "np", ".", "zeros", "(", "len", "(", "self", ".", "labels", ")", ")", "\n", "for", "label", "in", "labels", ":", "\n", "            ", "if", "not", "pd", ".", "isna", "(", "label", ")", ":", "\n", "                ", "i", "=", "self", ".", "labels", ".", "index", "(", "label", ")", "\n", "y", "[", "i", "]", "=", "1", "\n", "", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder._time_to_frame": [[67, 71], ["numpy.clip"], "methods", ["None"], ["", "def", "_time_to_frame", "(", "self", ",", "time", ")", ":", "\n", "        ", "samples", "=", "time", "*", "self", ".", "fs", "\n", "frame", "=", "(", "samples", ")", "/", "self", ".", "frame_hop", "\n", "return", "np", ".", "clip", "(", "frame", "/", "self", ".", "net_pooling", ",", "a_min", "=", "0", ",", "a_max", "=", "self", ".", "n_frames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder._frame_to_time": [[72, 75], ["numpy.clip"], "methods", ["None"], ["", "def", "_frame_to_time", "(", "self", ",", "frame", ")", ":", "\n", "        ", "frame", "=", "frame", "*", "self", ".", "net_pooling", "/", "(", "self", ".", "fs", "/", "self", ".", "frame_hop", ")", "\n", "return", "np", ".", "clip", "(", "frame", ",", "a_min", "=", "0", ",", "a_max", "=", "self", ".", "audio_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.encode_strong_df": [[76, 154], ["any", "numpy.zeros", "type", "type", "len", "label_df.iterrows", "type", "NotImplementedError", "numpy.zeros", "type", "pandas.isna", "encoder.ManyHotEncoder.labels.index", "int", "int", "type", "type", "len", "encoder.ManyHotEncoder._time_to_frame", "numpy.ceil", "pandas.isna", "encoder.ManyHotEncoder.labels.index", "int", "int", "encoder.ManyHotEncoder.labels.index", "len", "NotImplementedError", "encoder.ManyHotEncoder._time_to_frame", "encoder.ManyHotEncoder._time_to_frame", "numpy.ceil", "encoder.ManyHotEncoder.labels.index", "int", "int", "encoder.ManyHotEncoder._time_to_frame", "encoder.ManyHotEncoder._time_to_frame", "numpy.ceil", "type", "encoder.ManyHotEncoder._time_to_frame"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder._time_to_frame", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder._time_to_frame", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder._time_to_frame", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder._time_to_frame", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder._time_to_frame", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder._time_to_frame"], ["", "def", "encode_strong_df", "(", "self", ",", "label_df", ")", ":", "\n", "        ", "\"\"\"Encode a list (or pandas Dataframe or Serie) of strong labels, they correspond to a given filename\n\n        Args:\n            label_df: pandas DataFrame or Series, contains filename, onset (in frames) and offset (in frames)\n                If only filename (no onset offset) is specified, it will return the event on all the frames\n                onset and offset should be in frames\n        Returns:\n            numpy.array\n            Encoded labels, 1 where the label is present, 0 otherwise\n        \"\"\"", "\n", "\n", "assert", "any", "(", "\n", "[", "x", "is", "not", "None", "for", "x", "in", "[", "self", ".", "audio_len", ",", "self", ".", "frame_len", ",", "self", ".", "frame_hop", "]", "]", "\n", ")", "\n", "\n", "samples_len", "=", "self", ".", "n_frames", "\n", "if", "type", "(", "label_df", ")", "is", "str", ":", "\n", "            ", "if", "label_df", "==", "\"empty\"", ":", "\n", "                ", "y", "=", "np", ".", "zeros", "(", "(", "samples_len", ",", "len", "(", "self", ".", "labels", ")", ")", ")", "-", "1", "\n", "return", "y", "\n", "", "", "y", "=", "np", ".", "zeros", "(", "(", "samples_len", ",", "len", "(", "self", ".", "labels", ")", ")", ")", "\n", "if", "type", "(", "label_df", ")", "is", "pd", ".", "DataFrame", ":", "\n", "            ", "if", "{", "\"onset\"", ",", "\"offset\"", ",", "\"event_label\"", "}", ".", "issubset", "(", "label_df", ".", "columns", ")", ":", "\n", "                ", "for", "_", ",", "row", "in", "label_df", ".", "iterrows", "(", ")", ":", "\n", "                    ", "if", "not", "pd", ".", "isna", "(", "row", "[", "\"event_label\"", "]", ")", ":", "\n", "                        ", "i", "=", "self", ".", "labels", ".", "index", "(", "row", "[", "\"event_label\"", "]", ")", "\n", "onset", "=", "int", "(", "self", ".", "_time_to_frame", "(", "row", "[", "\"onset\"", "]", ")", ")", "\n", "offset", "=", "int", "(", "np", ".", "ceil", "(", "self", ".", "_time_to_frame", "(", "row", "[", "\"offset\"", "]", ")", ")", ")", "\n", "y", "[", "\n", "onset", ":", "offset", ",", "i", "\n", "]", "=", "1", "# means offset not included (hypothesis of overlapping frames, so ok)", "\n", "\n", "", "", "", "", "elif", "type", "(", "label_df", ")", "in", "[", "\n", "pd", ".", "Series", ",", "\n", "list", ",", "\n", "np", ".", "ndarray", ",", "\n", "]", ":", "# list of list or list of strings", "\n", "            ", "if", "type", "(", "label_df", ")", "is", "pd", ".", "Series", ":", "\n", "                ", "if", "{", "\"onset\"", ",", "\"offset\"", ",", "\"event_label\"", "}", ".", "issubset", "(", "\n", "label_df", ".", "index", "\n", ")", ":", "# means only one value", "\n", "                    ", "if", "not", "pd", ".", "isna", "(", "label_df", "[", "\"event_label\"", "]", ")", ":", "\n", "                        ", "i", "=", "self", ".", "labels", ".", "index", "(", "label_df", "[", "\"event_label\"", "]", ")", "\n", "onset", "=", "int", "(", "self", ".", "_time_to_frame", "(", "label_df", "[", "\"onset\"", "]", ")", ")", "\n", "offset", "=", "int", "(", "np", ".", "ceil", "(", "self", ".", "_time_to_frame", "(", "label_df", "[", "\"offset\"", "]", ")", ")", ")", "\n", "y", "[", "onset", ":", "offset", ",", "i", "]", "=", "1", "\n", "", "return", "y", "\n", "\n", "", "", "for", "event_label", "in", "label_df", ":", "\n", "# List of string, so weak labels to be encoded in strong", "\n", "                ", "if", "type", "(", "event_label", ")", "is", "str", ":", "\n", "                    ", "if", "event_label", "!=", "\"\"", ":", "\n", "                        ", "i", "=", "self", ".", "labels", ".", "index", "(", "event_label", ")", "\n", "y", "[", ":", ",", "i", "]", "=", "1", "\n", "\n", "# List of list, with [label, onset, offset]", "\n", "", "", "elif", "len", "(", "event_label", ")", "==", "3", ":", "\n", "                    ", "if", "event_label", "[", "0", "]", "!=", "\"\"", ":", "\n", "                        ", "i", "=", "self", ".", "labels", ".", "index", "(", "event_label", "[", "0", "]", ")", "\n", "onset", "=", "int", "(", "self", ".", "_time_to_frame", "(", "event_label", "[", "1", "]", ")", ")", "\n", "offset", "=", "int", "(", "np", ".", "ceil", "(", "self", ".", "_time_to_frame", "(", "event_label", "[", "2", "]", ")", ")", ")", "\n", "y", "[", "onset", ":", "offset", ",", "i", "]", "=", "1", "\n", "\n", "", "", "else", ":", "\n", "                    ", "raise", "NotImplementedError", "(", "\n", "\"cannot encode strong, type mismatch: {}\"", ".", "format", "(", "\n", "type", "(", "event_label", ")", "\n", ")", "\n", ")", "\n", "\n", "", "", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"To encode_strong, type is pandas.Dataframe with onset, offset and event_label\"", "\n", "\"columns, or it is a list or pandas Series of event labels, \"", "\n", "\"type given: {}\"", ".", "format", "(", "type", "(", "label_df", ")", ")", "\n", ")", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.decode_weak": [[155, 170], ["enumerate", "result_labels.append"], "methods", ["None"], ["", "def", "decode_weak", "(", "self", ",", "labels", ")", ":", "\n", "        ", "\"\"\" Decode the encoded weak labels\n        Args:\n            labels: numpy.array, the encoded labels to be decoded\n\n        Returns:\n            list\n            Decoded labels, list of string\n\n        \"\"\"", "\n", "result_labels", "=", "[", "]", "\n", "for", "i", ",", "value", "in", "enumerate", "(", "labels", ")", ":", "\n", "            ", "if", "value", "==", "1", ":", "\n", "                ", "result_labels", ".", "append", "(", "self", ".", "labels", "[", "i", "]", ")", "\n", "", "", "return", "result_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.decode_strong": [[171, 194], ["enumerate", "dcase_util.data.DecisionEncoder().find_contiguous_regions", "result_labels.append", "dcase_util.data.DecisionEncoder", "encoder.ManyHotEncoder._frame_to_time", "encoder.ManyHotEncoder._frame_to_time"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder._frame_to_time", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder._frame_to_time"], ["", "def", "decode_strong", "(", "self", ",", "labels", ")", ":", "\n", "        ", "\"\"\" Decode the encoded strong labels\n        Args:\n            labels: numpy.array, the encoded labels to be decoded\n        Returns:\n            list\n            Decoded labels, list of list: [[label, onset offset], ...]\n\n        \"\"\"", "\n", "result_labels", "=", "[", "]", "\n", "for", "i", ",", "label_column", "in", "enumerate", "(", "labels", ".", "T", ")", ":", "\n", "            ", "change_indices", "=", "DecisionEncoder", "(", ")", ".", "find_contiguous_regions", "(", "label_column", ")", "\n", "\n", "# append [label, onset, offset] in the result list", "\n", "for", "row", "in", "change_indices", ":", "\n", "                ", "result_labels", ".", "append", "(", "\n", "[", "\n", "self", ".", "labels", "[", "i", "]", ",", "\n", "self", ".", "_frame_to_time", "(", "row", "[", "0", "]", ")", ",", "\n", "self", ".", "_frame_to_time", "(", "row", "[", "1", "]", ")", ",", "\n", "]", "\n", ")", "\n", "", "", "return", "result_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict": [[195, 203], ["None"], "methods", ["None"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"labels\"", ":", "self", ".", "labels", ",", "\n", "\"audio_len\"", ":", "self", ".", "audio_len", ",", "\n", "\"frame_len\"", ":", "self", ".", "frame_len", ",", "\n", "\"frame_hop\"", ":", "self", ".", "frame_hop", ",", "\n", "\"net_pooling\"", ":", "self", ".", "net_pooling", ",", "\n", "\"fs\"", ":", "self", ".", "fs", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.load_state_dict": [[205, 214], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "load_state_dict", "(", "cls", ",", "state_dict", ")", ":", "\n", "        ", "labels", "=", "state_dict", "[", "\"labels\"", "]", "\n", "audio_len", "=", "state_dict", "[", "\"audio_len\"", "]", "\n", "frame_len", "=", "state_dict", "[", "\"frame_len\"", "]", "\n", "frame_hop", "=", "state_dict", "[", "\"frame_hop\"", "]", "\n", "net_pooling", "=", "state_dict", "[", "\"net_pooling\"", "]", "\n", "fs", "=", "state_dict", "[", "\"fs\"", "]", "\n", "return", "cls", "(", "labels", ",", "audio_len", ",", "frame_len", ",", "frame_hop", ",", "net_pooling", ",", "fs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.__init__": [[22, 34], ["super().__init__", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["def", "__init__", "(", "self", ",", "statistic", "=", "\"dataset\"", ",", "normtype", "=", "\"standard\"", ",", "dims", "=", "(", "1", ",", "2", ")", ",", "eps", "=", "1e-8", ")", ":", "\n", "        ", "super", "(", "TorchScaler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "statistic", "in", "[", "\"dataset\"", ",", "\"instance\"", "]", "\n", "assert", "normtype", "in", "[", "\"standard\"", ",", "\"mean\"", ",", "\"minmax\"", "]", "\n", "if", "statistic", "==", "\"dataset\"", "and", "normtype", "==", "\"minmax\"", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"statistic==dataset and normtype==minmax is not currently implemented.\"", "\n", ")", "\n", "", "self", ".", "statistic", "=", "statistic", "\n", "self", ".", "normtype", "=", "normtype", "\n", "self", ".", "dims", "=", "dims", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict": [[35, 38], ["super().load_state_dict"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "strict", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "statistic", "==", "\"dataset\"", ":", "\n", "            ", "super", "(", "TorchScaler", ",", "self", ")", ".", "load_state_dict", "(", "state_dict", ",", "strict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler._load_from_state_dict": [[39, 58], ["super()._load_from_state_dict"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler._load_from_state_dict"], ["", "", "def", "_load_from_state_dict", "(", "\n", "self", ",", "\n", "state_dict", ",", "\n", "prefix", ",", "\n", "local_metadata", ",", "\n", "strict", ",", "\n", "missing_keys", ",", "\n", "unexpected_keys", ",", "\n", "error_msgs", ",", "\n", ")", ":", "\n", "        ", "if", "self", ".", "statistic", "==", "\"dataset\"", ":", "\n", "            ", "super", "(", "TorchScaler", ",", "self", ")", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "\n", "prefix", ",", "\n", "local_metadata", ",", "\n", "strict", ",", "\n", "missing_keys", ",", "\n", "unexpected_keys", ",", "\n", "error_msgs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.fit": [[60, 90], ["tqdm.tqdm", "scaler.TorchScaler.register_buffer", "scaler.TorchScaler.register_buffer", "transform_func", "torch.mean().mean().unsqueeze", "torch.mean().mean().unsqueeze", "torch.mean().mean().unsqueeze", "torch.mean().mean().unsqueeze", "torch.mean().mean", "torch.mean().mean", "torch.mean().mean", "torch.mean().mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["", "", "def", "fit", "(", "self", ",", "dataloader", ",", "transform_func", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", ":", "\n", "        ", "\"\"\"\n        Scaler fitting\n\n        Args:\n            dataloader (DataLoader): training data DataLoader\n            transform_func (lambda function, optional): Transforms applied to the data.\n                Defaults to lambdax:x[0].\n        \"\"\"", "\n", "indx", "=", "0", "\n", "for", "batch", "in", "tqdm", ".", "tqdm", "(", "dataloader", ")", ":", "\n", "\n", "            ", "feats", "=", "transform_func", "(", "batch", ")", "\n", "if", "indx", "==", "0", ":", "\n", "                ", "mean", "=", "torch", ".", "mean", "(", "feats", ",", "self", ".", "dims", ",", "keepdim", "=", "True", ")", ".", "mean", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "mean_squared", "=", "(", "\n", "torch", ".", "mean", "(", "feats", "**", "2", ",", "self", ".", "dims", ",", "keepdim", "=", "True", ")", ".", "mean", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "mean", "+=", "torch", ".", "mean", "(", "feats", ",", "self", ".", "dims", ",", "keepdim", "=", "True", ")", ".", "mean", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "mean_squared", "+=", "(", "\n", "torch", ".", "mean", "(", "feats", "**", "2", ",", "self", ".", "dims", ",", "keepdim", "=", "True", ")", ".", "mean", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", ")", "\n", "", "indx", "+=", "1", "\n", "\n", "", "mean", "/=", "indx", "\n", "mean_squared", "/=", "indx", "\n", "\n", "self", ".", "register_buffer", "(", "\"mean\"", ",", "mean", ")", "\n", "self", ".", "register_buffer", "(", "\"mean_squared\"", ",", "mean_squared", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.forward": [[91, 117], ["hasattr", "hasattr", "torch.sqrt", "torch.mean", "torch.mean", "torch.std", "torch.amin", "torch.amax", "torch.amin"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.std"], ["", "def", "forward", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "if", "self", ".", "statistic", "==", "\"dataset\"", ":", "\n", "            ", "assert", "hasattr", "(", "self", ",", "\"mean\"", ")", "and", "hasattr", "(", "\n", "self", ",", "\"mean_squared\"", "\n", ")", ",", "\"TorchScaler should be fit before used if statistics=dataset\"", "\n", "assert", "tensor", ".", "ndim", "==", "self", ".", "mean", ".", "ndim", ",", "\"Pre-computed statistics \"", "\n", "if", "self", ".", "normtype", "==", "\"mean\"", ":", "\n", "                ", "return", "tensor", "-", "self", ".", "mean", "\n", "", "elif", "self", ".", "normtype", "==", "\"standard\"", ":", "\n", "                ", "std", "=", "torch", ".", "sqrt", "(", "self", ".", "mean_squared", "-", "self", ".", "mean", "**", "2", ")", "\n", "return", "(", "tensor", "-", "self", ".", "mean", ")", "/", "(", "std", "+", "self", ".", "eps", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "normtype", "==", "\"mean\"", ":", "\n", "                ", "return", "tensor", "-", "torch", ".", "mean", "(", "tensor", ",", "self", ".", "dims", ",", "keepdim", "=", "True", ")", "\n", "", "elif", "self", ".", "normtype", "==", "\"standard\"", ":", "\n", "                ", "return", "(", "tensor", "-", "torch", ".", "mean", "(", "tensor", ",", "self", ".", "dims", ",", "keepdim", "=", "True", ")", ")", "/", "(", "\n", "torch", ".", "std", "(", "tensor", ",", "self", ".", "dims", ",", "keepdim", "=", "True", ")", "+", "self", ".", "eps", "\n", ")", "\n", "", "elif", "self", ".", "normtype", "==", "\"minmax\"", ":", "\n", "                ", "return", "(", "tensor", "-", "torch", ".", "amin", "(", "tensor", ",", "dim", "=", "self", ".", "dims", ",", "keepdim", "=", "True", ")", ")", "/", "(", "\n", "torch", ".", "amax", "(", "tensor", ",", "dim", "=", "self", ".", "dims", ",", "keepdim", "=", "True", ")", "\n", "-", "torch", ".", "amin", "(", "tensor", ",", "dim", "=", "self", ".", "dims", ",", "keepdim", "=", "True", ")", "\n", "+", "self", ".", "eps", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.torch_utils.nantensor": [[5, 7], ["torch.ones"], "function", ["None"], ["def", "nantensor", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "torch", ".", "ones", "(", "*", "args", ",", "**", "kwargs", ")", "*", "np", ".", "nan", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.torch_utils.nanmean": [[9, 15], ["torch.isnan", "v.clone.clone", "v.clone.sum"], "function", ["None"], ["", "def", "nanmean", "(", "v", ",", "*", "args", ",", "inplace", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "not", "inplace", ":", "\n", "        ", "v", "=", "v", ".", "clone", "(", ")", "\n", "", "is_nan", "=", "torch", ".", "isnan", "(", "v", ")", "\n", "v", "[", "is_nan", "]", "=", "0", "\n", "return", "v", ".", "sum", "(", "*", "args", ",", "**", "kwargs", ")", "/", "(", "~", "is_nan", ")", ".", "float", "(", ")", ".", "sum", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.desed_task.data_augm.frame_shift": [[6, 17], ["range", "int", "shifted.append", "new_labels.append", "torch.stack", "torch.stack", "random.gauss", "torch.roll", "torch.roll", "abs"], "function", ["None"], ["def", "frame_shift", "(", "mels", ",", "labels", ",", "net_pooling", "=", "4", ")", ":", "\n", "    ", "bsz", ",", "n_bands", ",", "frames", "=", "mels", ".", "shape", "\n", "\n", "shifted", "=", "[", "]", "\n", "new_labels", "=", "[", "]", "\n", "for", "bindx", "in", "range", "(", "bsz", ")", ":", "\n", "        ", "shift", "=", "int", "(", "random", ".", "gauss", "(", "0", ",", "90", ")", ")", "\n", "shifted", ".", "append", "(", "torch", ".", "roll", "(", "mels", "[", "bindx", "]", ",", "shift", ",", "dims", "=", "-", "1", ")", ")", "\n", "shift", "=", "-", "abs", "(", "shift", ")", "//", "net_pooling", "if", "shift", "<", "0", "else", "shift", "//", "net_pooling", "\n", "new_labels", ".", "append", "(", "torch", ".", "roll", "(", "labels", "[", "bindx", "]", ",", "shift", ",", "dims", "=", "-", "1", ")", ")", "\n", "", "return", "torch", ".", "stack", "(", "shifted", ")", ",", "torch", ".", "stack", "(", "new_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.desed_task.data_augm.frame_shift2": [[18, 38], ["range", "torch.stack", "range", "torch.stack", "torch.stack().permute", "int", "torch.stack.append", "new_labels.append", "int", "torch.stack.append", "torch.stack", "random.gauss", "torch.roll", "torch.roll", "random.gauss", "torch.roll", "torch.stack", "abs"], "function", ["None"], ["", "def", "frame_shift2", "(", "mels", ",", "labels", ",", "net_pooling", "=", "4", ")", ":", "\n", "    ", "bsz", ",", "n_ch", ",", "n_bands", ",", "frames", "=", "mels", ".", "shape", "\n", "\n", "shifted1", "=", "[", "]", "\n", "new_labels", "=", "[", "]", "\n", "for", "bindx", "in", "range", "(", "bsz", ")", ":", "\n", "        ", "shift", "=", "int", "(", "random", ".", "gauss", "(", "0", ",", "90", ")", ")", "\n", "shifted1", ".", "append", "(", "torch", ".", "roll", "(", "mels", "[", "bindx", ",", "0", "]", ",", "shift", ",", "dims", "=", "-", "1", ")", ")", "\n", "shift", "=", "-", "abs", "(", "shift", ")", "//", "net_pooling", "if", "shift", "<", "0", "else", "shift", "//", "net_pooling", "\n", "new_labels", ".", "append", "(", "torch", ".", "roll", "(", "labels", "[", "bindx", "]", ",", "shift", ",", "dims", "=", "-", "1", ")", ")", "\n", "", "shifted1", "=", "torch", ".", "stack", "(", "shifted1", ")", "\n", "\n", "shifted2", "=", "[", "]", "\n", "for", "bindx", "in", "range", "(", "bsz", ")", ":", "\n", "        ", "shift", "=", "int", "(", "random", ".", "gauss", "(", "0", ",", "90", ")", ")", "\n", "shifted2", ".", "append", "(", "torch", ".", "roll", "(", "mels", "[", "bindx", ",", "1", "]", ",", "shift", ",", "dims", "=", "-", "1", ")", ")", "\n", "", "shifted2", "=", "torch", ".", "stack", "(", "shifted2", ")", "\n", "\n", "shifted", "=", "torch", ".", "stack", "(", "[", "shifted1", ",", "shifted2", "]", ",", "3", ")", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "return", "shifted", ",", "torch", ".", "stack", "(", "new_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.desed_task.data_augm.temporal_reverse": [[40, 48], ["range", "reverse.append", "new_labels.append", "torch.stack", "torch.stack", "torch.fliplr", "torch.fliplr"], "function", ["None"], ["", "def", "temporal_reverse", "(", "mels", ",", "labels", ",", "net_pooling", "=", "4", ")", ":", "\n", "    ", "bsz", ",", "n_bands", ",", "frames", "=", "mels", ".", "shape", "\n", "reverse", "=", "[", "]", "\n", "new_labels", "=", "[", "]", "\n", "for", "bindx", "in", "range", "(", "bsz", ")", ":", "\n", "        ", "reverse", ".", "append", "(", "torch", ".", "fliplr", "(", "mels", "[", "bindx", "]", ")", ")", "\n", "new_labels", ".", "append", "(", "torch", ".", "fliplr", "(", "labels", "[", "bindx", "]", ")", ")", "\n", "", "return", "torch", ".", "stack", "(", "reverse", ")", ",", "torch", ".", "stack", "(", "new_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.desed_task.data_augm.mixup": [[50, 85], ["torch.no_grad", "data.size", "numpy.random.beta", "torch.randperm", "torch.clamp", "torch.clamp", "NotImplementedError"], "function", ["None"], ["", "def", "mixup", "(", "data", ",", "target", "=", "None", ",", "alpha", "=", "0.2", ",", "beta", "=", "0.2", ",", "mixup_label_type", "=", "\"soft\"", ")", ":", "\n", "    ", "\"\"\"Mixup data augmentation by permuting the data\n\n    Args:\n        data: input tensor, must be a batch so data can be permuted and mixed.\n        target: tensor of the target to be mixed, if None, do not return targets.\n        alpha: float, the parameter to the np.random.beta distribution\n        beta: float, the parameter to the np.random.beta distribution\n        mixup_label_type: str, the type of mixup to be used choice between {'soft', 'hard'}.\n    Returns:\n        torch.Tensor of mixed data and labels if given\n    \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "batch_size", "=", "data", ".", "size", "(", "0", ")", "\n", "c", "=", "np", ".", "random", ".", "beta", "(", "alpha", ",", "beta", ")", "\n", "\n", "perm", "=", "torch", ".", "randperm", "(", "batch_size", ")", "\n", "\n", "mixed_data", "=", "c", "*", "data", "+", "(", "1", "-", "c", ")", "*", "data", "[", "perm", ",", ":", "]", "\n", "if", "target", "is", "not", "None", ":", "\n", "            ", "if", "mixup_label_type", "==", "\"soft\"", ":", "\n", "                ", "mixed_target", "=", "torch", ".", "clamp", "(", "\n", "c", "*", "target", "+", "(", "1", "-", "c", ")", "*", "target", "[", "perm", ",", ":", "]", ",", "min", "=", "0", ",", "max", "=", "1", "\n", ")", "\n", "", "elif", "mixup_label_type", "==", "\"hard\"", ":", "\n", "                ", "mixed_target", "=", "torch", ".", "clamp", "(", "target", "+", "target", "[", "perm", ",", ":", "]", ",", "min", "=", "0", ",", "max", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\n", "f\"mixup_label_type: {mixup_label_type} not implemented. choice in \"", "\n", "f\"{'soft', 'hard'}\"", "\n", ")", "\n", "\n", "", "return", "mixed_data", ",", "mixed_target", "\n", "", "else", ":", "\n", "            ", "return", "mixed_data", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.desed_task.data_augm.add_noise": [[87, 109], ["isinstance", "torch.std", "torch.randn", "torch.rand().reshape", "torch.rand"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.std"], ["", "", "", "def", "add_noise", "(", "mels", ",", "snrs", "=", "(", "6", ",", "30", ")", ",", "dims", "=", "(", "1", ",", "2", ")", ")", ":", "\n", "    ", "\"\"\" Add white noise to mels spectrograms\n    Args:\n        mels: torch.tensor, mels spectrograms to apply the white noise to.\n        snrs: int or tuple, the range of snrs to choose from if tuple (uniform)\n        dims: tuple, the dimensions for which to compute the standard deviation (default to (1,2) because assume\n            an input of a batch of mel spectrograms.\n    Returns:\n        torch.Tensor of mels with noise applied\n    \"\"\"", "\n", "if", "isinstance", "(", "snrs", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "snr", "=", "(", "snrs", "[", "0", "]", "-", "snrs", "[", "1", "]", ")", "*", "torch", ".", "rand", "(", "\n", "(", "mels", ".", "shape", "[", "0", "]", ",", ")", ",", "device", "=", "mels", ".", "device", "\n", ")", ".", "reshape", "(", "-", "1", ",", "1", ",", "1", ")", "+", "snrs", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "snr", "=", "snrs", "\n", "\n", "", "snr", "=", "10", "**", "(", "snr", "/", "20", ")", "# linear domain", "\n", "sigma", "=", "torch", ".", "std", "(", "mels", ",", "dim", "=", "dims", ",", "keepdim", "=", "True", ")", "/", "snr", "\n", "mels", "=", "mels", "+", "torch", ".", "randn", "(", "mels", ".", "shape", ",", "device", "=", "mels", ".", "device", ")", "*", "sigma", "\n", "\n", "return", "mels", "\n", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.sampler.ConcatDatasetBatchSampler.__init__": [[34, 57], ["sampler.ConcatDatasetBatchSampler.set_epoch", "isinstance", "ValueError", "isinstance", "ValueError", "ValueError", "len", "len", "numpy.cumsum().tolist", "numpy.cumsum", "len"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.sampler.ConcatDatasetBatchSampler.set_epoch", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.data_utils.DataLoad.ConcatDataset.cumsum"], ["def", "__init__", "(", "self", ",", "samplers", ",", "batch_sizes", ":", "(", "tuple", ",", "list", ")", ",", "epoch", "=", "0", ")", "->", "None", ":", "\n", "\n", "        ", "if", "not", "isinstance", "(", "samplers", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"samplers should be a list or tuple of Pytorch Samplers, \"", "\n", "\"but got samplers={}\"", ".", "format", "(", "batch_sizes", ")", "\n", ")", "\n", "\n", "", "if", "not", "isinstance", "(", "batch_sizes", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"batch_sizes should be a list or tuple of integers, \"", "\n", "\"but got batch_sizes={}\"", ".", "format", "(", "batch_sizes", ")", "\n", ")", "\n", "\n", "", "if", "not", "len", "(", "batch_sizes", ")", "==", "len", "(", "samplers", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"batch_sizes and samplers should be have same length\"", ")", "\n", "\n", "", "self", ".", "batch_sizes", "=", "batch_sizes", "\n", "self", ".", "samplers", "=", "samplers", "\n", "self", ".", "offsets", "=", "[", "0", "]", "+", "np", ".", "cumsum", "(", "[", "len", "(", "x", ")", "for", "x", "in", "self", ".", "samplers", "]", ")", ".", "tolist", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "self", ".", "epoch", "=", "epoch", "\n", "self", ".", "set_epoch", "(", "self", ".", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.sampler.ConcatDatasetBatchSampler._iter_one_dataset": [[58, 64], ["batch.append", "len"], "methods", ["None"], ["", "def", "_iter_one_dataset", "(", "self", ",", "c_batch_size", ",", "c_sampler", ",", "c_offset", ")", ":", "\n", "        ", "batch", "=", "[", "]", "\n", "for", "idx", "in", "c_sampler", ":", "\n", "            ", "batch", ".", "append", "(", "c_offset", "+", "idx", ")", "\n", "if", "len", "(", "batch", ")", "==", "c_batch_size", ":", "\n", "                ", "yield", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.sampler.ConcatDatasetBatchSampler.set_epoch": [[65, 69], ["hasattr", "s.set_epoch"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.sampler.ConcatDatasetBatchSampler.set_epoch"], ["", "", "", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "samplers", "[", "0", "]", ",", "\"epoch\"", ")", ":", "\n", "            ", "for", "s", "in", "self", ".", "samplers", ":", "\n", "                ", "s", ".", "set_epoch", "(", "epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.sampler.ConcatDatasetBatchSampler.__iter__": [[70, 83], ["range", "iter", "len", "range", "len", "tot_batch.extend", "len", "c_batch.append", "next"], "methods", ["None"], ["", "", "", "def", "__iter__", "(", "self", ")", ":", "\n", "\n", "        ", "iterators", "=", "[", "iter", "(", "i", ")", "for", "i", "in", "self", ".", "samplers", "]", "\n", "tot_batch", "=", "[", "]", "\n", "\n", "for", "b_num", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "            ", "for", "samp_idx", "in", "range", "(", "len", "(", "self", ".", "samplers", ")", ")", ":", "\n", "                ", "c_batch", "=", "[", "]", "\n", "while", "len", "(", "c_batch", ")", "<", "self", ".", "batch_sizes", "[", "samp_idx", "]", ":", "\n", "                    ", "c_batch", ".", "append", "(", "self", ".", "offsets", "[", "samp_idx", "]", "+", "next", "(", "iterators", "[", "samp_idx", "]", ")", ")", "\n", "", "tot_batch", ".", "extend", "(", "c_batch", ")", "\n", "", "yield", "tot_batch", "\n", "tot_batch", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.sampler.ConcatDatasetBatchSampler.__len__": [[84, 92], ["float", "enumerate", "min", "len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "\n", "        ", "min_len", "=", "float", "(", "\"inf\"", ")", "\n", "for", "idx", ",", "sampler", "in", "enumerate", "(", "self", ".", "samplers", ")", ":", "\n", "            ", "c_len", "=", "(", "len", "(", "sampler", ")", ")", "//", "self", ".", "batch_sizes", "[", "idx", "]", "\n", "\n", "min_len", "=", "min", "(", "c_len", ",", "min_len", ")", "\n", "", "return", "min_len", "\n", "", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.StronglyAnnotatedSet.__init__": [[49, 98], ["tsv_entries.iterrows", "list", "examples.keys", "examples.keys", "os.path.join", "numpy.isnan", "[].append", "numpy.isnan", "[].append"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "audio_folder", ",", "\n", "tsv_entries", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "10", ",", "\n", "fs", "=", "16000", ",", "\n", "return_filename", "=", "False", ",", "\n", "random_channel", "=", "False", ",", "\n", "multisrc", "=", "False", ",", "\n", "evaluation", "=", "False", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "fs", "=", "fs", "\n", "self", ".", "pad_to", "=", "pad_to", "*", "fs", "\n", "self", ".", "return_filename", "=", "return_filename", "\n", "self", ".", "random_channel", "=", "random_channel", "\n", "self", ".", "multisrc", "=", "multisrc", "\n", "\n", "# annotation = pd.read_csv(tsv_file, sep=\"\\t\")", "\n", "examples", "=", "{", "}", "\n", "for", "i", ",", "r", "in", "tsv_entries", ".", "iterrows", "(", ")", ":", "\n", "            ", "if", "r", "[", "\"filename\"", "]", "not", "in", "examples", ".", "keys", "(", ")", ":", "\n", "                ", "examples", "[", "r", "[", "\"filename\"", "]", "]", "=", "{", "\n", "\"mixture\"", ":", "os", ".", "path", ".", "join", "(", "audio_folder", ",", "r", "[", "\"filename\"", "]", ")", ",", "\n", "\"events\"", ":", "[", "]", ",", "\n", "}", "\n", "if", "not", "np", ".", "isnan", "(", "r", "[", "\"onset\"", "]", ")", ":", "\n", "                    ", "examples", "[", "r", "[", "\"filename\"", "]", "]", "[", "\"events\"", "]", ".", "append", "(", "\n", "{", "\n", "\"event_label\"", ":", "r", "[", "\"event_label\"", "]", ",", "\n", "\"onset\"", ":", "r", "[", "\"onset\"", "]", ",", "\n", "\"offset\"", ":", "r", "[", "\"offset\"", "]", ",", "\n", "}", "\n", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "not", "np", ".", "isnan", "(", "r", "[", "\"onset\"", "]", ")", ":", "\n", "                    ", "examples", "[", "r", "[", "\"filename\"", "]", "]", "[", "\"events\"", "]", ".", "append", "(", "\n", "{", "\n", "\"event_label\"", ":", "r", "[", "\"event_label\"", "]", ",", "\n", "\"onset\"", ":", "r", "[", "\"onset\"", "]", ",", "\n", "\"offset\"", ":", "r", "[", "\"offset\"", "]", ",", "\n", "}", "\n", ")", "\n", "\n", "# we construct a dictionary for each example", "\n", "", "", "", "self", ".", "examples", "=", "examples", "\n", "self", ".", "examples_list", "=", "list", "(", "examples", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.StronglyAnnotatedSet.__len__": [[99, 101], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.StronglyAnnotatedSet.__getitem__": [[102, 125], ["datasets.read_audio", "len", "torch.zeros().float", "datasets.StronglyAnnotatedSet.encoder.encode_strong_df", "torch.from_numpy().float", "pandas.DataFrame", "torch.from_numpy().float.transpose", "torch.from_numpy().float.transpose", "torch.zeros", "torch.from_numpy", "len"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.read_audio", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.encode_strong_df"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "c_ex", "=", "self", ".", "examples", "[", "self", ".", "examples_list", "[", "item", "]", "]", "\n", "\n", "mixture", ",", "padded_indx", "=", "read_audio", "(", "\n", "c_ex", "[", "\"mixture\"", "]", ",", "self", ".", "multisrc", ",", "self", ".", "random_channel", ",", "self", ".", "pad_to", "\n", ")", "\n", "\n", "# labels", "\n", "labels", "=", "c_ex", "[", "\"events\"", "]", "\n", "# check if labels exists:", "\n", "if", "not", "len", "(", "labels", ")", ":", "\n", "            ", "max_len_targets", "=", "self", ".", "encoder", ".", "n_frames", "\n", "strong", "=", "torch", ".", "zeros", "(", "max_len_targets", ",", "len", "(", "self", ".", "encoder", ".", "labels", ")", ")", ".", "float", "(", ")", "\n", "\n", "", "else", ":", "\n", "# to steps", "\n", "            ", "strong", "=", "self", ".", "encoder", ".", "encode_strong_df", "(", "pd", ".", "DataFrame", "(", "labels", ")", ")", "\n", "strong", "=", "torch", ".", "from_numpy", "(", "strong", ")", ".", "float", "(", ")", "\n", "\n", "", "if", "self", ".", "return_filename", ":", "\n", "            ", "return", "mixture", ",", "strong", ".", "transpose", "(", "0", ",", "1", ")", ",", "padded_indx", ",", "c_ex", "[", "\"mixture\"", "]", "\n", "", "else", ":", "\n", "            ", "return", "mixture", ",", "strong", ".", "transpose", "(", "0", ",", "1", ")", ",", "padded_indx", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.WeakSet.__init__": [[128, 158], ["tsv_entries.iterrows", "list", "examples.keys", "examples.keys", "os.path.join", "r[].split"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "audio_folder", ",", "\n", "tsv_entries", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "10", ",", "\n", "fs", "=", "16000", ",", "\n", "return_filename", "=", "False", ",", "\n", "random_channel", "=", "False", ",", "\n", "multisrc", "=", "False", ",", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "fs", "=", "fs", "\n", "self", ".", "pad_to", "=", "pad_to", "*", "fs", "\n", "self", ".", "return_filename", "=", "return_filename", "\n", "self", ".", "random_channel", "=", "random_channel", "\n", "self", ".", "multisrc", "=", "multisrc", "\n", "\n", "examples", "=", "{", "}", "\n", "for", "i", ",", "r", "in", "tsv_entries", ".", "iterrows", "(", ")", ":", "\n", "\n", "            ", "if", "r", "[", "\"filename\"", "]", "not", "in", "examples", ".", "keys", "(", ")", ":", "\n", "                ", "examples", "[", "r", "[", "\"filename\"", "]", "]", "=", "{", "\n", "\"mixture\"", ":", "os", ".", "path", ".", "join", "(", "audio_folder", ",", "r", "[", "\"filename\"", "]", ")", ",", "\n", "\"events\"", ":", "r", "[", "\"event_labels\"", "]", ".", "split", "(", "\",\"", ")", ",", "\n", "}", "\n", "\n", "", "", "self", ".", "examples", "=", "examples", "\n", "self", ".", "examples_list", "=", "list", "(", "examples", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.WeakSet.__len__": [[159, 161], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.WeakSet.__getitem__": [[162, 184], ["datasets.read_audio", "torch.zeros", "len", "len", "datasets.WeakSet.encoder.encode_weak", "torch.from_numpy().float", "torch.zeros.transpose", "out_args.append", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.read_audio", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.encode_weak"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "file", "=", "self", ".", "examples_list", "[", "item", "]", "\n", "c_ex", "=", "self", ".", "examples", "[", "file", "]", "\n", "mixture", ",", "padded_indx", "=", "read_audio", "(", "\n", "c_ex", "[", "\"mixture\"", "]", ",", "self", ".", "multisrc", ",", "self", ".", "random_channel", ",", "self", ".", "pad_to", "\n", ")", "\n", "\n", "# labels", "\n", "labels", "=", "c_ex", "[", "\"events\"", "]", "\n", "# check if labels exists:", "\n", "max_len_targets", "=", "self", ".", "encoder", ".", "n_frames", "\n", "weak", "=", "torch", ".", "zeros", "(", "max_len_targets", ",", "len", "(", "self", ".", "encoder", ".", "labels", ")", ")", "\n", "if", "len", "(", "labels", ")", ":", "\n", "            ", "weak_labels", "=", "self", ".", "encoder", ".", "encode_weak", "(", "labels", ")", "\n", "weak", "[", "0", ",", ":", "]", "=", "torch", ".", "from_numpy", "(", "weak_labels", ")", ".", "float", "(", ")", "\n", "\n", "", "out_args", "=", "[", "mixture", ",", "weak", ".", "transpose", "(", "0", ",", "1", ")", ",", "padded_indx", "]", "\n", "\n", "if", "self", ".", "return_filename", ":", "\n", "            ", "out_args", ".", "append", "(", "c_ex", "[", "\"mixture\"", "]", ")", "\n", "\n", "", "return", "out_args", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.UnlabeledSet.__init__": [[187, 205], ["glob.glob", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "unlabeled_folder", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "10", ",", "\n", "fs", "=", "16000", ",", "\n", "return_filename", "=", "False", ",", "\n", "random_channel", "=", "False", ",", "\n", "multisrc", "=", "False", ",", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "fs", "=", "fs", "\n", "self", ".", "pad_to", "=", "pad_to", "*", "fs", "if", "pad_to", "is", "not", "None", "else", "None", "\n", "self", ".", "examples", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "unlabeled_folder", ",", "\"*.wav\"", ")", ")", "\n", "self", ".", "return_filename", "=", "return_filename", "\n", "self", ".", "random_channel", "=", "random_channel", "\n", "self", ".", "multisrc", "=", "multisrc", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.UnlabeledSet.__len__": [[206, 208], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "examples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.UnlabeledSet.__getitem__": [[209, 223], ["datasets.read_audio", "torch.zeros().float", "torch.zeros().float.transpose", "out_args.append", "torch.zeros", "len"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.read_audio"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "c_ex", "=", "self", ".", "examples", "[", "item", "]", "\n", "mixture", ",", "padded_indx", "=", "read_audio", "(", "\n", "c_ex", ",", "self", ".", "multisrc", ",", "self", ".", "random_channel", ",", "self", ".", "pad_to", "\n", ")", "\n", "\n", "max_len_targets", "=", "self", ".", "encoder", ".", "n_frames", "\n", "strong", "=", "torch", ".", "zeros", "(", "max_len_targets", ",", "len", "(", "self", ".", "encoder", ".", "labels", ")", ")", ".", "float", "(", ")", "\n", "out_args", "=", "[", "mixture", ",", "strong", ".", "transpose", "(", "0", ",", "1", ")", ",", "padded_indx", "]", "\n", "\n", "if", "self", ".", "return_filename", ":", "\n", "            ", "out_args", ".", "append", "(", "c_ex", ")", "\n", "\n", "", "return", "out_args", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.to_mono": [[11, 20], ["torch.mean", "numpy.random.randint"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["def", "to_mono", "(", "mixture", ",", "random_ch", "=", "False", ")", ":", "\n", "\n", "    ", "if", "mixture", ".", "ndim", ">", "1", ":", "# multi channel", "\n", "        ", "if", "not", "random_ch", ":", "\n", "            ", "mixture", "=", "torch", ".", "mean", "(", "mixture", ",", "0", ")", "\n", "", "else", ":", "# randomly select one channel", "\n", "            ", "indx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "mixture", ".", "shape", "[", "0", "]", "-", "1", ")", "\n", "mixture", "=", "mixture", "[", "indx", "]", "\n", "", "", "return", "mixture", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.pad_audio": [[22, 32], ["torch.nn.functional.pad", "len"], "function", ["None"], ["", "def", "pad_audio", "(", "audio", ",", "target_len", ")", ":", "\n", "    ", "if", "audio", ".", "shape", "[", "-", "1", "]", "<", "target_len", ":", "\n", "        ", "audio", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "\n", "audio", ",", "(", "0", ",", "target_len", "-", "audio", ".", "shape", "[", "-", "1", "]", ")", ",", "mode", "=", "\"constant\"", "\n", ")", "\n", "padded_indx", "=", "[", "target_len", "/", "len", "(", "audio", ")", "]", "\n", "", "else", ":", "\n", "        ", "padded_indx", "=", "[", "1.0", "]", "\n", "\n", "", "return", "audio", ",", "padded_indx", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.read_audio": [[34, 46], ["torchaudio.load", "to_mono.float", "datasets.to_mono", "datasets.pad_audio"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.load", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.to_mono", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dataio.datasets.pad_audio"], ["", "def", "read_audio", "(", "file", ",", "multisrc", ",", "random_channel", ",", "pad_to", ")", ":", "\n", "    ", "mixture", ",", "fs", "=", "torchaudio", ".", "load", "(", "file", ")", "\n", "if", "not", "multisrc", ":", "\n", "        ", "mixture", "=", "to_mono", "(", "mixture", ",", "random_channel", ")", "\n", "\n", "", "if", "pad_to", "is", "not", "None", ":", "\n", "        ", "mixture", ",", "padded_indx", "=", "pad_audio", "(", "mixture", ",", "pad_to", ")", "\n", "", "else", ":", "\n", "        ", "padded_indx", "=", "[", "1.0", "]", "\n", "\n", "", "mixture", "=", "mixture", ".", "float", "(", ")", "\n", "return", "mixture", ",", "padded_indx", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.GLU.__init__": [[8, 12], ["torch.Module.__init__", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_num", ",", "input_num", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "lin", "=", "self", ".", "linear", "(", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.GLU.forward": [[13, 19], ["CNN.GLU.linear", "lin.permute.permute.permute", "CNN.GLU.sigmoid", "x.permute"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid"], ["lin", "=", "lin", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "sig", "=", "self", ".", "sigmoid", "(", "x", ")", "\n", "res", "=", "lin", "*", "sig", "\n", "return", "res", "\n", "\n", "\n", "", "", "class", "ContextGating", "(", "nn", ".", "Module", ")", ":", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.ContextGating.__init__": [[22, 26], ["torch.Module.__init__", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "input_num", ",", "input_num", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "lin", "=", "self", ".", "linear", "(", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.ContextGating.forward": [[27, 33], ["CNN.ContextGating.linear", "lin.permute.permute.permute", "CNN.ContextGating.sigmoid", "x.permute"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid"], ["lin", "=", "lin", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "sig", "=", "self", ".", "sigmoid", "(", "lin", ")", "\n", "res", "=", "x", "*", "sig", "\n", "return", "res", "\n", "\n", "\n", "", "", "class", "CNN", "(", "nn", ".", "Module", ")", ":", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.BasicConv.__init__": [[35, 41], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_in_channel", ",", "activation", "=", "\"Relu\"", ",", "conv_dropout", "=", "0", ",", "\n", "kernel_size", "=", "[", "3", ",", "3", ",", "3", "]", ",", "padding", "=", "[", "1", ",", "1", ",", "1", "]", ",", "stride", "=", "[", "1", ",", "1", ",", "1", "]", ",", "nb_filters", "=", "[", "64", ",", "64", ",", "64", "]", ",", "\n", "pooling", "=", "[", "(", "1", ",", "4", ")", ",", "(", "1", ",", "4", ")", ",", "(", "1", ",", "4", ")", "]", "\n", ")", ":", "\n", "        ", "super", "(", "CNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nb_filters", "=", "nb_filters", "\n", "cnn", "=", "nn", ".", "Sequential", "(", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.BasicConv.forward": [[42, 49], ["CNN.BasicConv.conv", "CNN.BasicConv.bn", "CNN.BasicConv.relu"], "methods", ["None"], ["\n", "def", "conv", "(", "i", ",", "batchNormalization", "=", "False", ",", "dropout", "=", "None", ",", "activ", "=", "\"relu\"", ")", ":", "\n", "            ", "nIn", "=", "n_in_channel", "if", "i", "==", "0", "else", "nb_filters", "[", "i", "-", "1", "]", "\n", "nOut", "=", "nb_filters", "[", "i", "]", "\n", "cnn", ".", "add_module", "(", "'conv{0}'", ".", "format", "(", "i", ")", ",", "\n", "nn", ".", "Conv2d", "(", "nIn", ",", "nOut", ",", "kernel_size", "[", "i", "]", ",", "stride", "[", "i", "]", ",", "padding", "[", "i", "]", ")", ")", "\n", "if", "batchNormalization", ":", "\n", "                ", "cnn", ".", "add_module", "(", "'batchnorm{0}'", ".", "format", "(", "i", ")", ",", "nn", ".", "BatchNorm2d", "(", "nOut", ",", "eps", "=", "0.001", ",", "momentum", "=", "0.99", ")", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.Flatten.forward": [[51, 53], ["x.view", "x.size"], "methods", ["None"], ["                ", "cnn", ".", "add_module", "(", "'relu{0}'", ".", "format", "(", "i", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ")", ")", "\n", "", "elif", "activ", ".", "lower", "(", ")", "==", "\"relu\"", ":", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.ChannelGate.__init__": [[55, 65], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "CNN.Flatten", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["", "elif", "activ", ".", "lower", "(", ")", "==", "\"glu\"", ":", "\n", "                ", "cnn", ".", "add_module", "(", "'glu{0}'", ".", "format", "(", "i", ")", ",", "GLU", "(", "nOut", ")", ")", "\n", "", "elif", "activ", ".", "lower", "(", ")", "==", "\"cg\"", ":", "\n", "                ", "cnn", ".", "add_module", "(", "'cg{0}'", ".", "format", "(", "i", ")", ",", "ContextGating", "(", "nOut", ")", ")", "\n", "", "if", "dropout", "is", "not", "None", ":", "\n", "                ", "cnn", ".", "add_module", "(", "'dropout{0}'", ".", "format", "(", "i", ")", ",", "\n", "nn", ".", "Dropout", "(", "dropout", ")", ")", "\n", "\n", "", "", "batch_norm", "=", "True", "\n", "# 128x862x64", "\n", "for", "i", "in", "range", "(", "len", "(", "nb_filters", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.ChannelGate.forward": [[66, 90], ["torch.sigmoid().unsqueeze().unsqueeze().expand_as", "torch.sigmoid().unsqueeze().unsqueeze().expand_as", "torch.sigmoid().unsqueeze().unsqueeze().expand_as", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "CNN.ChannelGate.mlp", "torch.sigmoid().unsqueeze().unsqueeze", "torch.sigmoid().unsqueeze().unsqueeze", "torch.sigmoid().unsqueeze().unsqueeze", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "CNN.ChannelGate.mlp", "x.size", "x.size", "torch.lp_pool2d", "torch.lp_pool2d", "torch.lp_pool2d", "CNN.ChannelGate.mlp", "torch.sigmoid().unsqueeze", "torch.sigmoid().unsqueeze", "torch.sigmoid().unsqueeze", "x.size", "x.size", "x.size", "x.size", "CNN.logsumexp_2d", "CNN.ChannelGate.mlp", "x.size", "x.size", "x.size", "x.size", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "x.size", "x.size"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.logsumexp_2d", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid"], ["#nIn = n_in_channel if i == 0 else nb_filters[i-1]", "\n", "#nOut = nb_filters[i]", "\n", "            ", "conv", "(", "i", ",", "batch_norm", ",", "conv_dropout", ",", "activ", "=", "activation", ")", "\n", "cnn", ".", "add_module", "(", "'pooling{0}'", ".", "format", "(", "i", ")", ",", "nn", ".", "AvgPool2d", "(", "pooling", "[", "i", "]", ")", ")", "# bs x tframe x mels", "\n", "#cnn.add_module('pooling{0}'.format(i), nn.MaxPool2d(pooling[i]))  # bs x tframe x mels", "\n", "\n", "#if batch_norm:", "\n", "#    cnn.add_module('batchnorm{0}'.format(i), nn.BatchNorm2d(nOut, eps=0.001, momentum=0.99))", "\n", "#if activation.lower() == \"leakyrelu\":", "\n", "#    cnn.add_module('relu{0}'.format(i),", "\n", "#                   nn.LeakyReLU(0.2))", "\n", "#elif activation.lower() == \"relu\":", "\n", "#    cnn.add_module('relu{0}'.format(i), nn.ReLU())", "\n", "#elif activation.lower() == \"glu\":", "\n", "#    cnn.add_module('glu{0}'.format(i), GLU(nOut))", "\n", "#elif activation.lower() == \"cg\":", "\n", "#    cnn.add_module('cg{0}'.format(i), ContextGating(nOut))", "\n", "#if conv_dropout is not None:", "\n", "#    cnn.add_module('dropout{0}'.format(i),", "\n", "#                   nn.Dropout(conv_dropout))", "\n", "\n", "", "self", ".", "cnn", "=", "cnn", "\n", "\n", "", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "strict", "=", "True", ")", ":", "\n", "        ", "self", ".", "cnn", ".", "load_state_dict", "(", "state_dict", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.ChannelPool.forward": [[100, 102], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "[].unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean().unsqueeze", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["# conv features", "\n", "        ", "x", "=", "self", ".", "cnn", "(", "x", ")", "\n", "return", "x", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.SpatialGate.__init__": [[105, 110], ["torch.Module.__init__", "CNN.ChannelPool", "CNN.BasicConv"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.SpatialGate.forward": [[111, 116], ["CNN.SpatialGate.compress", "CNN.SpatialGate.spatial", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid"], []], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.CBAM.__init__": [[119, 124], ["torch.Module.__init__", "CNN.ChannelGate", "CNN.SpatialGate"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], []], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.CBAM.forward": [[125, 130], ["CNN.CBAM.ChannelGate", "CNN.CBAM.SpatialGate"], "methods", ["None"], []], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.ResidualConv.__init__": [[132, 137], ["torch.Module.__init__", "CNN.BasicConv", "CNN.BasicConv", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], []], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.ResidualConv.forward": [[138, 143], ["CNN.ResidualConv.conv1", "CNN.ResidualConv.conv2", "CNN.ResidualConv.skip"], "methods", ["None"], []], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.ResidualCNN.__init__": [[146, 223], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Sequential.add_module", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "CNN.GLU", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "CNN.GLU", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "CNN.ResidualConv", "CNN.CBAM", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "CNN.ResidualConv", "CNN.CBAM", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "CNN.ResidualConv", "CNN.CBAM", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "CNN.ResidualConv", "CNN.CBAM", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "CNN.ResidualConv", "CNN.CBAM", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], []], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.ResidualCNN.forward": [[224, 237], ["CNN.ResidualCNN.cnn"], "methods", ["None"], []], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.CNN.__init__": [[240, 307], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "range", "torch.Sequential.add_module", "len", "CNN.CNN.__init__.conv"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], []], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.CNN.forward": [[308, 321], ["CNN.CNN.cnn"], "methods", ["None"], []], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CNN.logsumexp_2d": [[92, 97], ["tensor.view", "torch.max", "torch.max", "torch.max", "tensor.size", "tensor.size"], "function", ["None"], ["", "def", "state_dict", "(", "self", ",", "destination", "=", "None", ",", "prefix", "=", "''", ",", "keep_vars", "=", "False", ")", ":", "\n", "        ", "return", "self", ".", "cnn", ".", "state_dict", "(", "destination", "=", "destination", ",", "prefix", "=", "prefix", ",", "keep_vars", "=", "keep_vars", ")", "\n", "\n", "", "def", "save", "(", "self", ",", "filename", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "cnn", ".", "state_dict", "(", ")", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CRNN.RCRNN.__init__": [[10, 92], ["torch.Module.__init__", "CNN.CNN.ResidualCNN", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "CRNN.RCRNN.cnn.parameters", "RNN.BidirectionalGRU", "NotImplementedError", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["class", "CRNN", "(", "nn", ".", "Module", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "n_in_channel", ",", "nclass", ",", "attention", "=", "False", ",", "activation", "=", "\"Relu\"", ",", "dropout", "=", "0", ",", "\n", "train_cnn", "=", "True", ",", "rnn_type", "=", "'BGRU'", ",", "n_RNN_cell", "=", "64", ",", "n_layers_RNN", "=", "1", ",", "dropout_recurrent", "=", "0", ",", "\n", "cnn_integration", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "CRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_in_channel", "=", "n_in_channel", "\n", "self", ".", "attention", "=", "attention", "\n", "self", ".", "cnn_integration", "=", "cnn_integration", "\n", "n_in_cnn", "=", "n_in_channel", "\n", "if", "cnn_integration", ":", "\n", "            ", "n_in_cnn", "=", "1", "\n", "", "self", ".", "cnn", "=", "CNN", "(", "n_in_cnn", ",", "activation", ",", "dropout", ",", "**", "kwargs", ")", "\n", "if", "not", "train_cnn", ":", "\n", "            ", "for", "param", "in", "self", ".", "cnn", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "self", ".", "train_cnn", "=", "train_cnn", "\n", "if", "rnn_type", "==", "'BGRU'", ":", "\n", "            ", "nb_in", "=", "self", ".", "cnn", ".", "nb_filters", "[", "-", "1", "]", "\n", "if", "self", ".", "cnn_integration", ":", "\n", "# self.fc = nn.Linear(nb_in * n_in_channel, nb_in)", "\n", "                ", "nb_in", "=", "nb_in", "*", "n_in_channel", "\n", "", "self", ".", "rnn", "=", "BidirectionalGRU", "(", "nb_in", ",", "\n", "n_RNN_cell", ",", "dropout", "=", "dropout_recurrent", ",", "num_layers", "=", "n_layers_RNN", ")", "\n", "", "else", ":", "\n", "            ", "NotImplementedError", "(", "\"Only BGRU supported for CRNN for now\"", ")", "\n", "", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "n_RNN_cell", "*", "2", ",", "nclass", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "if", "self", ".", "attention", ":", "\n", "            ", "self", ".", "dense_softmax", "=", "nn", ".", "Linear", "(", "n_RNN_cell", "*", "2", ",", "nclass", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "", "", "def", "load_cnn", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "cnn", ".", "load_state_dict", "(", "state_dict", ")", "\n", "if", "not", "self", ".", "train_cnn", ":", "\n", "            ", "for", "param", "in", "self", ".", "cnn", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "", "def", "load_state_dict", "(", "self", ",", "state_dict", ",", "strict", "=", "True", ")", ":", "\n", "        ", "self", ".", "cnn", ".", "load_state_dict", "(", "state_dict", "[", "\"cnn\"", "]", ")", "\n", "self", ".", "rnn", ".", "load_state_dict", "(", "state_dict", "[", "\"rnn\"", "]", ")", "\n", "self", ".", "dense", ".", "load_state_dict", "(", "state_dict", "[", "\"dense\"", "]", ")", "\n", "\n", "", "def", "state_dict", "(", "self", ",", "destination", "=", "None", ",", "prefix", "=", "''", ",", "keep_vars", "=", "False", ")", ":", "\n", "        ", "state_dict", "=", "{", "\"cnn\"", ":", "self", ".", "cnn", ".", "state_dict", "(", "destination", "=", "destination", ",", "prefix", "=", "prefix", ",", "keep_vars", "=", "keep_vars", ")", ",", "\n", "\"rnn\"", ":", "self", ".", "rnn", ".", "state_dict", "(", "destination", "=", "destination", ",", "prefix", "=", "prefix", ",", "keep_vars", "=", "keep_vars", ")", ",", "\n", "'dense'", ":", "self", ".", "dense", ".", "state_dict", "(", "destination", "=", "destination", ",", "prefix", "=", "prefix", ",", "keep_vars", "=", "keep_vars", ")", "}", "\n", "return", "state_dict", "\n", "\n", "", "def", "save", "(", "self", ",", "filename", ")", ":", "\n", "        ", "parameters", "=", "{", "'cnn'", ":", "self", ".", "cnn", ".", "state_dict", "(", ")", ",", "'rnn'", ":", "self", ".", "rnn", ".", "state_dict", "(", ")", ",", "'dense'", ":", "self", ".", "dense", ".", "state_dict", "(", ")", "}", "\n", "torch", ".", "save", "(", "parameters", ",", "filename", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# input size : (batch_size, n_channels, n_frames, n_freq)", "\n", "        ", "if", "self", ".", "cnn_integration", ":", "\n", "            ", "bs_in", ",", "nc_in", "=", "x", ".", "size", "(", "0", ")", ",", "x", ".", "size", "(", "1", ")", "\n", "x", "=", "x", ".", "view", "(", "bs_in", "*", "nc_in", ",", "1", ",", "*", "x", ".", "shape", "[", "2", ":", "]", ")", "\n", "\n", "# conv features", "\n", "", "x", "=", "self", ".", "cnn", "(", "x", ")", "\n", "bs", ",", "chan", ",", "frames", ",", "freq", "=", "x", ".", "size", "(", ")", "\n", "if", "self", ".", "cnn_integration", ":", "\n", "            ", "x", "=", "x", ".", "reshape", "(", "bs_in", ",", "chan", "*", "nc_in", ",", "frames", ",", "freq", ")", "\n", "\n", "", "if", "freq", "!=", "1", ":", "\n", "            ", "warnings", ".", "warn", "(", "f\"Output shape is: {(bs, frames, chan * freq)}, from {freq} staying freq\"", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "x", "=", "x", ".", "contiguous", "(", ")", ".", "view", "(", "bs", ",", "frames", ",", "chan", "*", "freq", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", ".", "squeeze", "(", "-", "1", ")", "\n", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "# [bs, frames, chan]", "\n", "\n", "# rnn features", "\n", "", "x", "=", "self", ".", "rnn", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "strong", "=", "self", ".", "dense", "(", "x", ")", "# [bs, frames, nclass]", "\n", "strong", "=", "self", ".", "sigmoid", "(", "strong", ")", "\n", "if", "self", ".", "attention", ":", "\n", "            ", "sof", "=", "self", ".", "dense_softmax", "(", "x", ")", "# [bs, frames, nclass]", "\n", "sof", "=", "self", ".", "softmax", "(", "sof", ")", "\n", "sof", "=", "torch", ".", "clamp", "(", "sof", ",", "min", "=", "1e-7", ",", "max", "=", "1", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CRNN.RCRNN.forward": [[93, 139], ["CRNN.RCRNN.cnn", "x.permute.permute.size", "CRNN.RCRNN.rnn", "CRNN.RCRNN.dropout", "CRNN.RCRNN.dense", "CRNN.RCRNN.sigmoid", "len", "x.permute.permute.transpose().unsqueeze", "x.permute.permute.permute", "x.permute.permute.view", "x.permute.permute.reshape", "warnings.warn", "x.permute.permute.permute", "x.permute.permute.contiguous().view", "x.permute.permute.squeeze", "x.permute.permute.permute", "CRNN.RCRNN.dense_softmax", "CRNN.RCRNN.softmax", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "CRNN.RCRNN.mean", "CRNN.RCRNN.transpose", "x.permute.permute.size", "x.permute.permute.size", "sof.masked_fill.masked_fill.masked_fill", "sof.masked_fill.masked_fill.sum", "x.permute.permute.transpose", "x.permute.permute.contiguous", "pad_mask.transpose"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["weak", "=", "(", "strong", "*", "sof", ")", ".", "sum", "(", "1", ")", "/", "sof", ".", "sum", "(", "1", ")", "# [bs, nclass]", "\n", "", "else", ":", "\n", "            ", "weak", "=", "strong", ".", "mean", "(", "1", ")", "\n", "", "return", "strong", ",", "weak", "\n", "\n", "\n", "", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "CRNN", "(", "64", ",", "10", ",", "kernel_size", "=", "[", "3", ",", "3", ",", "3", "]", ",", "padding", "=", "[", "1", ",", "1", ",", "1", "]", ",", "stride", "=", "[", "1", ",", "1", ",", "1", "]", ",", "nb_filters", "=", "[", "64", ",", "64", ",", "64", "]", ",", "\n", "pooling", "=", "[", "(", "1", ",", "4", ")", ",", "(", "1", ",", "4", ")", ",", "(", "1", ",", "4", ")", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CRNN.RCRNN.train": [[140, 156], ["super().train", "print", "CRNN.RCRNN.modules", "print", "isinstance", "m.eval"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CRNN.CRNN.train"], []], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CRNN.CRNN.__init__": [[159, 234], ["torch.Module.__init__", "CNN.CNN.CNN", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "CRNN.CRNN.cnn.parameters", "RNN.BidirectionalGRU", "NotImplementedError", "torch.Linear", "torch.Linear", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], []], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CRNN.CRNN.forward": [[235, 275], ["x.permute.permute.transpose().unsqueeze", "CRNN.CRNN.cnn", "x.permute.permute.size", "CRNN.CRNN.rnn", "CRNN.CRNN.dropout", "CRNN.CRNN.dense", "CRNN.CRNN.sigmoid", "x.permute.permute.view", "x.permute.permute.reshape", "warnings.warn", "x.permute.permute.permute", "x.permute.permute.contiguous().view", "x.permute.permute.squeeze", "x.permute.permute.permute", "CRNN.CRNN.dense_softmax", "CRNN.CRNN.softmax", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "CRNN.CRNN.mean", "CRNN.CRNN.transpose", "x.permute.permute.transpose", "x.permute.permute.size", "x.permute.permute.size", "sof.masked_fill.masked_fill.masked_fill", "sof.masked_fill.masked_fill.sum", "x.permute.permute.contiguous", "pad_mask.transpose"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], []], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CRNN.CRNN.train": [[276, 292], ["super().train", "print", "CRNN.CRNN.modules", "print", "isinstance", "m.eval"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.CRNN.CRNN.train"], []], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.RNN.BidirectionalGRU.__init__": [[8, 27], ["torch.nn.Module.__init__", "torch.nn.GRU"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["\n", "    ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_hidden", ",", "dropout", "=", "0", ",", "num_layers", "=", "1", ")", ":", "\n", "        ", "super", "(", "BidirectionalGRU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "rnn", "=", "nn", ".", "GRU", "(", "n_in", ",", "n_hidden", ",", "bidirectional", "=", "True", ",", "dropout", "=", "dropout", ",", "batch_first", "=", "True", ",", "num_layers", "=", "num_layers", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "input_feat", ")", ":", "\n", "        ", "recurrent", ",", "_", "=", "self", ".", "rnn", "(", "input_feat", ")", "\n", "return", "recurrent", "\n", "\n", "\n", "", "", "class", "BidirectionalLSTM", "(", "nn", ".", "Module", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "nIn", ",", "nHidden", ",", "nOut", ",", "dropout", "=", "0", ",", "num_layers", "=", "1", ")", ":", "\n", "        ", "super", "(", "BidirectionalLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "nIn", ",", "nHidden", "//", "2", ",", "bidirectional", "=", "True", ",", "batch_first", "=", "True", ",", "\n", "dropout", "=", "dropout", ",", "num_layers", "=", "num_layers", ")", "\n", "self", ".", "embedding", "=", "nn", ".", "Linear", "(", "nHidden", "*", "2", ",", "nOut", ")", "\n", "\n", "", "def", "save", "(", "self", ",", "filename", ")", ":", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.RNN.BidirectionalGRU.forward": [[29, 32], ["RNN.BidirectionalGRU.rnn"], "methods", ["None"], ["\n", "", "def", "load", "(", "self", ",", "filename", "=", "None", ",", "parameters", "=", "None", ")", ":", "\n", "        ", "if", "filename", "is", "not", "None", ":", "\n", "            ", "self", ".", "load_state_dict", "(", "torch", ".", "load", "(", "filename", ")", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.RNN.BidirectionalLSTM.__init__": [[35, 46], ["torch.nn.Module.__init__", "torch.nn.LSTM", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"load is a filename or a list of parameters (state_dict)\"", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "input_feat", ")", ":", "\n", "        ", "recurrent", ",", "_", "=", "self", ".", "rnn", "(", "input_feat", ")", "\n", "b", ",", "T", ",", "h", "=", "recurrent", ".", "size", "(", ")", "\n", "t_rec", "=", "recurrent", ".", "contiguous", "(", ")", ".", "view", "(", "b", "*", "T", ",", "h", ")", "\n", "\n", "output", "=", "self", ".", "embedding", "(", "t_rec", ")", "# [T * b, nOut]", "\n", "output", "=", "output", ".", "view", "(", "b", ",", "T", ",", "-", "1", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.nnet.RNN.BidirectionalLSTM.forward": [[47, 55], ["RNN.BidirectionalLSTM.rnn", "recurrent.size", "recurrent.contiguous().view", "RNN.BidirectionalLSTM.embedding", "output.view.view.view", "recurrent.contiguous"], "methods", ["None"], []], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dcase2021_task4_baseline.train_sed_CRST.resample_data_generate_durations": [[27, 51], ["local.resample_folder.resample_folder", "local.utils.generate_tsv_wav_durations", "os.path.exists"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.resample_folder.resample_folder", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.generate_tsv_wav_durations"], ["def", "resample_data_generate_durations", "(", "config_data", ",", "test_only", "=", "False", ",", "evaluation", "=", "False", ")", ":", "\n", "    ", "if", "not", "test_only", ":", "\n", "        ", "dsets", "=", "[", "\n", "\"synth_folder\"", ",", "\n", "\"synth_val_folder\"", ",", "\n", "\"weak_folder\"", ",", "\n", "\"unlabeled_folder\"", ",", "\n", "\"test_folder\"", ",", "\n", "]", "\n", "", "elif", "test_only", ":", "\n", "        ", "dsets", "=", "[", "\"test_folder\"", "]", "\n", "", "else", ":", "\n", "        ", "dsets", "=", "[", "\"eval_folder\"", "]", "\n", "\n", "", "for", "dset", "in", "dsets", ":", "\n", "        ", "computed", "=", "resample_folder", "(", "\n", "config_data", "[", "dset", "+", "\"_44k\"", "]", ",", "config_data", "[", "dset", "]", ",", "target_fs", "=", "config_data", "[", "\"fs\"", "]", "\n", ")", "\n", "\n", "", "if", "not", "evaluation", ":", "\n", "        ", "for", "base_set", "in", "[", "\"synth_val\"", ",", "\"test\"", "]", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "config_data", "[", "base_set", "+", "\"_dur\"", "]", ")", "or", "computed", ":", "\n", "                ", "generate_tsv_wav_durations", "(", "\n", "config_data", "[", "base_set", "+", "\"_folder\"", "]", ",", "config_data", "[", "base_set", "+", "\"_dur\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dcase2021_task4_baseline.train_sed_CRST.single_run": [[54, 274], ["config.update", "desed_task.utils.encoder.ManyHotEncoder", "desed_task.nnet.CRNN.RCRNN", "desed_task.nnet.CRNN.RCRNN", "local.sed_trainer_CRST.SEDTask4_2021", "pytorch_lightning.Trainer", "local.sed_trainer_CRST.SEDTask4_2021.load_state_dict", "pl.Trainer.test", "list", "pandas.read_csv", "desed_task.dataio.datasets.StronglyAnnotatedSet", "desed_task.dataio.datasets.UnlabeledSet", "pandas.read_csv", "desed_task.dataio.datasets.StronglyAnnotatedSet", "pandas.read_csv", "pd.read_csv.sample", "pd.read_csv.drop().reset_index", "train_weak_df.reset_index.reset_index", "desed_task.dataio.datasets.WeakSet", "desed_task.dataio.datasets.UnlabeledSet", "pandas.read_csv", "desed_task.dataio.datasets.StronglyAnnotatedSet", "desed_task.dataio.datasets.WeakSet", "torch.utils.data.ConcatDataset", "desed_task.dataio.ConcatDatasetBatchSampler", "torch.utils.data.ConcatDataset", "min", "torch.optim.Adam", "torch.optim.Adam", "pytorch_lightning.loggers.TensorBoardLogger", "print", "pl.Trainer.fit", "print", "local.classes_dict.classes_labels.keys", "torch.utils.data.RandomSampler", "desed_task.nnet.CRNN.RCRNN.parameters", "desed_task.nnet.CRNN.RCRNN.parameters", "desed_task.utils.schedulers.ExponentialWarmup", "desed_task.utils.schedulers.ExponentialWarmup", "os.path.dirname", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint", "config[].get", "torch.load", "pd.read_csv.drop", "config[].split", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.fit", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.load"], ["", "", "", "", "def", "single_run", "(", "\n", "config", ",", "\n", "log_dir", ",", "\n", "gpus", ",", "\n", "checkpoint_resume", "=", "None", ",", "\n", "test_state_dict", "=", "None", ",", "\n", "fast_dev_run", "=", "False", ",", "\n", "evaluation", "=", "False", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Running sound event detection baselin\n\n    Args:\n        config (dict): the dictionary of configuration params\n        log_dir (str): path to log directory\n        gpus (int): number of gpus to use\n        checkpoint_resume (str, optional): path to checkpoint to resume from. Defaults to \"\".\n        test_state_dict (dict, optional): if not None, no training is involved. This dictionary is the state_dict\n            to be loaded to test the model.\n        fast_dev_run (bool, optional): whether to use a run with only one batch at train and validation, useful\n            for development purposes.\n    \"\"\"", "\n", "config", ".", "update", "(", "{", "\"log_dir\"", ":", "log_dir", "}", ")", "\n", "\n", "##### data prep test ##########", "\n", "encoder", "=", "ManyHotEncoder", "(", "\n", "list", "(", "classes_labels", ".", "keys", "(", ")", ")", ",", "\n", "audio_len", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", "frame_len", "=", "config", "[", "\"feats\"", "]", "[", "\"n_filters\"", "]", ",", "\n", "frame_hop", "=", "config", "[", "\"feats\"", "]", "[", "\"hop_length\"", "]", ",", "\n", "net_pooling", "=", "config", "[", "\"data\"", "]", "[", "\"net_subsample\"", "]", ",", "\n", "fs", "=", "config", "[", "\"data\"", "]", "[", "\"fs\"", "]", ",", "\n", ")", "\n", "\n", "if", "not", "evaluation", ":", "\n", "        ", "devtest_df", "=", "pd", ".", "read_csv", "(", "config", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "sep", "=", "\"\\t\"", ")", "\n", "devtest_dataset", "=", "StronglyAnnotatedSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"test_folder\"", "]", ",", "\n", "devtest_df", ",", "\n", "encoder", ",", "\n", "return_filename", "=", "True", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "devtest_dataset", "=", "UnlabeledSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"test_folder\"", "]", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "11", ",", "\n", "return_filename", "=", "True", "\n", ")", "\n", "\n", "", "test_dataset", "=", "devtest_dataset", "\n", "\n", "##### model definition  ############", "\n", "sed_student1", "=", "RCRNN", "(", "**", "config", "[", "\"net1\"", "]", ")", "\n", "sed_student2", "=", "RCRNN", "(", "**", "config", "[", "\"net1\"", "]", ")", "\n", "\n", "if", "test_state_dict", "is", "None", ":", "\n", "##### data prep train valid ##########", "\n", "        ", "synth_df", "=", "pd", ".", "read_csv", "(", "config", "[", "\"data\"", "]", "[", "\"synth_tsv\"", "]", ",", "sep", "=", "\"\\t\"", ")", "\n", "synth_set", "=", "StronglyAnnotatedSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"synth_folder\"", "]", ",", "\n", "synth_df", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", ")", "\n", "\n", "weak_df", "=", "pd", ".", "read_csv", "(", "config", "[", "\"data\"", "]", "[", "\"weak_tsv\"", "]", ",", "sep", "=", "\"\\t\"", ")", "\n", "train_weak_df", "=", "weak_df", ".", "sample", "(", "\n", "frac", "=", "config", "[", "\"training\"", "]", "[", "\"weak_split\"", "]", ",", "random_state", "=", "config", "[", "\"training\"", "]", "[", "\"seed\"", "]", "\n", ")", "\n", "valid_weak_df", "=", "weak_df", ".", "drop", "(", "train_weak_df", ".", "index", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "train_weak_df", "=", "train_weak_df", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "weak_set", "=", "WeakSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"weak_folder\"", "]", ",", "\n", "train_weak_df", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", ")", "\n", "\n", "unlabeled_set", "=", "UnlabeledSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"unlabeled_folder\"", "]", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", ")", "\n", "\n", "synth_df_val", "=", "pd", ".", "read_csv", "(", "config", "[", "\"data\"", "]", "[", "\"synth_val_tsv\"", "]", ",", "sep", "=", "\"\\t\"", ")", "\n", "synth_val", "=", "StronglyAnnotatedSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"synth_val_folder\"", "]", ",", "\n", "synth_df_val", ",", "\n", "encoder", ",", "\n", "return_filename", "=", "True", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", ")", "\n", "\n", "weak_val", "=", "WeakSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"weak_folder\"", "]", ",", "\n", "valid_weak_df", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", "return_filename", "=", "True", ",", "\n", ")", "\n", "\n", "tot_train_data", "=", "[", "synth_set", ",", "weak_set", ",", "unlabeled_set", "]", "\n", "train_dataset", "=", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "tot_train_data", ")", "\n", "\n", "batch_sizes", "=", "config", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", "\n", "samplers", "=", "[", "torch", ".", "utils", ".", "data", ".", "RandomSampler", "(", "x", ")", "for", "x", "in", "tot_train_data", "]", "\n", "batch_sampler", "=", "ConcatDatasetBatchSampler", "(", "samplers", ",", "batch_sizes", ")", "\n", "\n", "valid_dataset", "=", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "\n", "[", "synth_val", ",", "weak_val", "]", "\n", ")", "\n", "\n", "##### training params and optimizers ############", "\n", "epoch_len", "=", "min", "(", "\n", "[", "\n", "len", "(", "tot_train_data", "[", "indx", "]", ")", "\n", "//", "(", "\n", "config", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", "[", "indx", "]", "\n", "*", "config", "[", "\"training\"", "]", "[", "\"accumulate_batches\"", "]", "\n", ")", "\n", "for", "indx", "in", "range", "(", "len", "(", "tot_train_data", ")", ")", "\n", "]", "\n", ")", "\n", "\n", "opt1", "=", "torch", ".", "optim", ".", "Adam", "(", "sed_student1", ".", "parameters", "(", ")", ",", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ")", "\n", "opt2", "=", "torch", ".", "optim", ".", "Adam", "(", "sed_student2", ".", "parameters", "(", ")", ",", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ")", "\n", "exp_steps", "=", "config", "[", "\"training\"", "]", "[", "\"n_epochs_warmup\"", "]", "*", "epoch_len", "\n", "exp_scheduler1", "=", "{", "\n", "\"scheduler\"", ":", "ExponentialWarmup", "(", "opt1", ",", "config", "[", "\"opt\"", "]", "[", "\"lr\"", "]", ",", "exp_steps", ")", ",", "\n", "\"interval\"", ":", "\"step\"", ",", "\n", "}", "\n", "exp_scheduler2", "=", "{", "\n", "\"scheduler\"", ":", "ExponentialWarmup", "(", "opt2", ",", "config", "[", "\"opt\"", "]", "[", "\"lr\"", "]", ",", "exp_steps", ")", ",", "\n", "\"interval\"", ":", "\"step\"", ",", "\n", "}", "\n", "\n", "logger", "=", "TensorBoardLogger", "(", "\n", "os", ".", "path", ".", "dirname", "(", "config", "[", "\"log_dir\"", "]", ")", ",", "config", "[", "\"log_dir\"", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ",", "\n", ")", "\n", "print", "(", "f\"experiment dir: {logger.log_dir}\"", ")", "\n", "\n", "callbacks", "=", "[", "\n", "EarlyStopping", "(", "\n", "monitor", "=", "\"val/obj_metric\"", ",", "\n", "patience", "=", "config", "[", "\"training\"", "]", "[", "\"early_stop_patience\"", "]", ",", "\n", "verbose", "=", "True", ",", "\n", "mode", "=", "\"max\"", "\n", ")", ",", "\n", "ModelCheckpoint", "(", "logger", ".", "log_dir", ",", "monitor", "=", "\"val/obj_metric\"", ",", "save_top_k", "=", "1", ",", "mode", "=", "\"max\"", ",", "\n", "save_last", "=", "True", ")", ",", "\n", "]", "\n", "", "else", ":", "\n", "        ", "train_dataset", "=", "None", "\n", "valid_dataset", "=", "None", "\n", "batch_sampler", "=", "None", "\n", "opt1", "=", "None", "\n", "opt2", "=", "None", "\n", "exp_scheduler1", "=", "None", "\n", "exp_scheduler2", "=", "None", "\n", "logger", "=", "True", "\n", "callbacks", "=", "None", "\n", "\n", "", "desed_training", "=", "SEDTask4_2021", "(", "\n", "config", ",", "\n", "encoder", "=", "encoder", ",", "\n", "sed_student", "=", "[", "sed_student1", ",", "sed_student2", "]", ",", "\n", "opt", "=", "[", "opt1", ",", "opt2", "]", ",", "\n", "train_data", "=", "train_dataset", ",", "\n", "valid_data", "=", "valid_dataset", ",", "\n", "test_data", "=", "test_dataset", ",", "\n", "train_sampler", "=", "batch_sampler", ",", "\n", "scheduler", "=", "[", "exp_scheduler1", ",", "exp_scheduler2", "]", ",", "\n", "fast_dev_run", "=", "fast_dev_run", ",", "\n", "evaluation", "=", "evaluation", "\n", ")", "\n", "\n", "# Not using the fast_dev_run of Trainer because creates a DummyLogger so cannot check problems with the Logger", "\n", "if", "fast_dev_run", ":", "\n", "        ", "flush_logs_every_n_steps", "=", "1", "\n", "log_every_n_steps", "=", "1", "\n", "limit_train_batches", "=", "2", "\n", "limit_val_batches", "=", "2", "\n", "limit_test_batches", "=", "2", "\n", "n_epochs", "=", "3", "\n", "", "else", ":", "\n", "        ", "flush_logs_every_n_steps", "=", "100", "\n", "log_every_n_steps", "=", "40", "\n", "limit_train_batches", "=", "1.", "\n", "limit_val_batches", "=", "1.", "\n", "limit_test_batches", "=", "1.", "\n", "n_epochs", "=", "config", "[", "\"training\"", "]", "[", "\"n_epochs\"", "]", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "n_epochs", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "gpus", "=", "gpus", ",", "\n", "distributed_backend", "=", "config", "[", "\"training\"", "]", ".", "get", "(", "\"backend\"", ")", ",", "\n", "accumulate_grad_batches", "=", "config", "[", "\"training\"", "]", "[", "\"accumulate_batches\"", "]", ",", "\n", "logger", "=", "logger", ",", "\n", "resume_from_checkpoint", "=", "checkpoint_resume", ",", "\n", "gradient_clip_val", "=", "config", "[", "\"training\"", "]", "[", "\"gradient_clip\"", "]", ",", "\n", "check_val_every_n_epoch", "=", "config", "[", "\"training\"", "]", "[", "\"validation_interval\"", "]", ",", "\n", "num_sanity_val_steps", "=", "0", ",", "\n", "log_every_n_steps", "=", "log_every_n_steps", ",", "\n", "flush_logs_every_n_steps", "=", "flush_logs_every_n_steps", ",", "\n", "limit_train_batches", "=", "limit_train_batches", ",", "\n", "limit_val_batches", "=", "limit_val_batches", ",", "\n", "limit_test_batches", "=", "limit_test_batches", ",", "\n", ")", "\n", "\n", "if", "test_state_dict", "is", "None", ":", "\n", "        ", "trainer", ".", "fit", "(", "desed_training", ")", "\n", "best_path", "=", "trainer", ".", "checkpoint_callback", ".", "best_model_path", "\n", "print", "(", "f\"best model: {best_path}\"", ")", "\n", "test_state_dict", "=", "torch", ".", "load", "(", "best_path", ")", "[", "\"state_dict\"", "]", "\n", "\n", "", "desed_training", ".", "load_state_dict", "(", "test_state_dict", ")", "\n", "trainer", ".", "test", "(", "desed_training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dcase2021_task4_baseline.train_sed.resample_data_generate_durations": [[26, 50], ["local.resample_folder.resample_folder", "local.utils.generate_tsv_wav_durations", "os.path.exists"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.resample_folder.resample_folder", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.generate_tsv_wav_durations"], ["def", "resample_data_generate_durations", "(", "config_data", ",", "test_only", "=", "False", ",", "evaluation", "=", "False", ")", ":", "\n", "    ", "if", "not", "test_only", ":", "\n", "        ", "dsets", "=", "[", "\n", "\"synth_folder\"", ",", "\n", "\"synth_val_folder\"", ",", "\n", "\"weak_folder\"", ",", "\n", "\"unlabeled_folder\"", ",", "\n", "\"test_folder\"", ",", "\n", "]", "\n", "", "elif", "test_only", ":", "\n", "        ", "dsets", "=", "[", "\"test_folder\"", "]", "\n", "", "else", ":", "\n", "        ", "dsets", "=", "[", "\"eval_folder\"", "]", "\n", "\n", "", "for", "dset", "in", "dsets", ":", "\n", "        ", "computed", "=", "resample_folder", "(", "\n", "config_data", "[", "dset", "+", "\"_44k\"", "]", ",", "config_data", "[", "dset", "]", ",", "target_fs", "=", "config_data", "[", "\"fs\"", "]", "\n", ")", "\n", "\n", "", "if", "not", "evaluation", ":", "\n", "        ", "for", "base_set", "in", "[", "\"synth_val\"", ",", "\"test\"", "]", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "config_data", "[", "base_set", "+", "\"_dur\"", "]", ")", "or", "computed", ":", "\n", "                ", "generate_tsv_wav_durations", "(", "\n", "config_data", "[", "base_set", "+", "\"_folder\"", "]", ",", "config_data", "[", "base_set", "+", "\"_dur\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dcase2021_task4_baseline.train_sed.single_run": [[53, 265], ["config.update", "desed_task.utils.encoder.ManyHotEncoder", "desed_task.nnet.CRNN.CRNN", "local.sed_trainer.SEDTask4_2021", "pytorch_lightning.Trainer", "local.sed_trainer.SEDTask4_2021.load_state_dict", "pl.Trainer.test", "list", "pandas.read_csv", "desed_task.dataio.datasets.StronglyAnnotatedSet", "desed_task.dataio.datasets.UnlabeledSet", "pandas.read_csv", "desed_task.dataio.datasets.StronglyAnnotatedSet", "pandas.read_csv", "pd.read_csv.sample", "pd.read_csv.drop().reset_index", "train_weak_df.reset_index.reset_index", "desed_task.dataio.datasets.WeakSet", "desed_task.dataio.datasets.UnlabeledSet", "pandas.read_csv", "desed_task.dataio.datasets.StronglyAnnotatedSet", "desed_task.dataio.datasets.WeakSet", "torch.utils.data.ConcatDataset", "desed_task.dataio.ConcatDatasetBatchSampler", "torch.utils.data.ConcatDataset", "min", "torch.optim.Adam", "pytorch_lightning.loggers.TensorBoardLogger", "print", "pl.Trainer.fit", "print", "local.classes_dict.classes_labels.keys", "torch.utils.data.RandomSampler", "desed_task.nnet.CRNN.CRNN.parameters", "desed_task.utils.schedulers.ExponentialWarmup", "os.path.dirname", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint", "config[].get", "torch.load", "pd.read_csv.drop", "config[].split", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.fit", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.load"], ["", "", "", "", "def", "single_run", "(", "\n", "config", ",", "\n", "log_dir", ",", "\n", "gpus", ",", "\n", "checkpoint_resume", "=", "None", ",", "\n", "test_state_dict", "=", "None", ",", "\n", "fast_dev_run", "=", "False", ",", "\n", "evaluation", "=", "False", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Running sound event detection baselin\n\n    Args:\n        config (dict): the dictionary of configuration params\n        log_dir (str): path to log directory\n        gpus (int): number of gpus to use\n        checkpoint_resume (str, optional): path to checkpoint to resume from. Defaults to \"\".\n        test_state_dict (dict, optional): if not None, no training is involved. This dictionary is the state_dict\n            to be loaded to test the model.\n        fast_dev_run (bool, optional): whether to use a run with only one batch at train and validation, useful\n            for development purposes.\n    \"\"\"", "\n", "config", ".", "update", "(", "{", "\"log_dir\"", ":", "log_dir", "}", ")", "\n", "\n", "##### data prep test ##########", "\n", "encoder", "=", "ManyHotEncoder", "(", "\n", "list", "(", "classes_labels", ".", "keys", "(", ")", ")", ",", "\n", "audio_len", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", "frame_len", "=", "config", "[", "\"feats\"", "]", "[", "\"n_filters\"", "]", ",", "\n", "frame_hop", "=", "config", "[", "\"feats\"", "]", "[", "\"hop_length\"", "]", ",", "\n", "net_pooling", "=", "config", "[", "\"data\"", "]", "[", "\"net_subsample\"", "]", ",", "\n", "fs", "=", "config", "[", "\"data\"", "]", "[", "\"fs\"", "]", ",", "\n", ")", "\n", "\n", "if", "not", "evaluation", ":", "\n", "        ", "devtest_df", "=", "pd", ".", "read_csv", "(", "config", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "sep", "=", "\"\\t\"", ")", "\n", "devtest_dataset", "=", "StronglyAnnotatedSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"test_folder\"", "]", ",", "\n", "devtest_df", ",", "\n", "encoder", ",", "\n", "return_filename", "=", "True", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "devtest_dataset", "=", "UnlabeledSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"eval_folder\"", "]", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "10", ",", "\n", "return_filename", "=", "True", "\n", ")", "\n", "\n", "", "test_dataset", "=", "devtest_dataset", "\n", "\n", "##### model definition  ############", "\n", "sed_student", "=", "CRNN", "(", "**", "config", "[", "\"net\"", "]", ")", "\n", "\n", "if", "test_state_dict", "is", "None", ":", "\n", "##### data prep train valid ##########", "\n", "        ", "synth_df", "=", "pd", ".", "read_csv", "(", "config", "[", "\"data\"", "]", "[", "\"synth_tsv\"", "]", ",", "sep", "=", "\"\\t\"", ")", "\n", "synth_set", "=", "StronglyAnnotatedSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"synth_folder\"", "]", ",", "\n", "synth_df", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", ")", "\n", "\n", "weak_df", "=", "pd", ".", "read_csv", "(", "config", "[", "\"data\"", "]", "[", "\"weak_tsv\"", "]", ",", "sep", "=", "\"\\t\"", ")", "\n", "train_weak_df", "=", "weak_df", ".", "sample", "(", "\n", "frac", "=", "config", "[", "\"training\"", "]", "[", "\"weak_split\"", "]", ",", "random_state", "=", "config", "[", "\"training\"", "]", "[", "\"seed\"", "]", "\n", ")", "\n", "valid_weak_df", "=", "weak_df", ".", "drop", "(", "train_weak_df", ".", "index", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "train_weak_df", "=", "train_weak_df", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "weak_set", "=", "WeakSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"weak_folder\"", "]", ",", "\n", "train_weak_df", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", ")", "\n", "\n", "unlabeled_set", "=", "UnlabeledSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"unlabeled_folder\"", "]", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", ")", "\n", "\n", "synth_df_val", "=", "pd", ".", "read_csv", "(", "config", "[", "\"data\"", "]", "[", "\"synth_val_tsv\"", "]", ",", "sep", "=", "\"\\t\"", ")", "\n", "synth_val", "=", "StronglyAnnotatedSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"synth_val_folder\"", "]", ",", "\n", "synth_df_val", ",", "\n", "encoder", ",", "\n", "return_filename", "=", "True", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", ")", "\n", "\n", "weak_val", "=", "WeakSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"weak_folder\"", "]", ",", "\n", "valid_weak_df", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", "return_filename", "=", "True", ",", "\n", ")", "\n", "\n", "tot_train_data", "=", "[", "synth_set", ",", "weak_set", ",", "unlabeled_set", "]", "\n", "train_dataset", "=", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "tot_train_data", ")", "\n", "\n", "batch_sizes", "=", "config", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", "\n", "samplers", "=", "[", "torch", ".", "utils", ".", "data", ".", "RandomSampler", "(", "x", ")", "for", "x", "in", "tot_train_data", "]", "\n", "batch_sampler", "=", "ConcatDatasetBatchSampler", "(", "samplers", ",", "batch_sizes", ")", "\n", "\n", "valid_dataset", "=", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "\n", "[", "synth_val", ",", "weak_val", "]", "\n", ")", "\n", "\n", "##### training params and optimizers ############", "\n", "epoch_len", "=", "min", "(", "\n", "[", "\n", "len", "(", "tot_train_data", "[", "indx", "]", ")", "\n", "//", "(", "\n", "config", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", "[", "indx", "]", "\n", "*", "config", "[", "\"training\"", "]", "[", "\"accumulate_batches\"", "]", "\n", ")", "\n", "for", "indx", "in", "range", "(", "len", "(", "tot_train_data", ")", ")", "\n", "]", "\n", ")", "\n", "# print(epoch_len) => 118", "\n", "\n", "opt", "=", "torch", ".", "optim", ".", "Adam", "(", "sed_student", ".", "parameters", "(", ")", ",", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ")", "\n", "exp_steps", "=", "config", "[", "\"training\"", "]", "[", "\"n_epochs_warmup\"", "]", "*", "epoch_len", "\n", "exp_scheduler", "=", "{", "\n", "\"scheduler\"", ":", "ExponentialWarmup", "(", "opt", ",", "config", "[", "\"opt\"", "]", "[", "\"lr\"", "]", ",", "exp_steps", ")", ",", "\n", "\"interval\"", ":", "\"step\"", ",", "\n", "}", "\n", "logger", "=", "TensorBoardLogger", "(", "\n", "os", ".", "path", ".", "dirname", "(", "config", "[", "\"log_dir\"", "]", ")", ",", "config", "[", "\"log_dir\"", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ",", "\n", ")", "\n", "print", "(", "f\"experiment dir: {logger.log_dir}\"", ")", "\n", "\n", "callbacks", "=", "[", "\n", "EarlyStopping", "(", "\n", "monitor", "=", "\"val/obj_metric\"", ",", "\n", "patience", "=", "config", "[", "\"training\"", "]", "[", "\"early_stop_patience\"", "]", ",", "\n", "verbose", "=", "True", ",", "\n", "mode", "=", "\"max\"", "\n", ")", ",", "\n", "ModelCheckpoint", "(", "logger", ".", "log_dir", ",", "monitor", "=", "\"val/obj_metric\"", ",", "save_top_k", "=", "1", ",", "mode", "=", "\"max\"", ",", "\n", "save_last", "=", "True", ")", ",", "\n", "]", "\n", "", "else", ":", "\n", "        ", "train_dataset", "=", "None", "\n", "valid_dataset", "=", "None", "\n", "batch_sampler", "=", "None", "\n", "opt", "=", "None", "\n", "exp_scheduler", "=", "None", "\n", "logger", "=", "True", "\n", "callbacks", "=", "None", "\n", "\n", "", "desed_training", "=", "SEDTask4_2021", "(", "\n", "config", ",", "\n", "encoder", "=", "encoder", ",", "\n", "sed_student", "=", "sed_student", ",", "\n", "opt", "=", "opt", ",", "\n", "train_data", "=", "train_dataset", ",", "\n", "valid_data", "=", "valid_dataset", ",", "\n", "test_data", "=", "test_dataset", ",", "\n", "train_sampler", "=", "batch_sampler", ",", "\n", "scheduler", "=", "exp_scheduler", ",", "\n", "fast_dev_run", "=", "fast_dev_run", ",", "\n", "evaluation", "=", "evaluation", "\n", ")", "\n", "\n", "# Not using the fast_dev_run of Trainer because creates a DummyLogger so cannot check problems with the Logger", "\n", "if", "fast_dev_run", ":", "\n", "        ", "flush_logs_every_n_steps", "=", "1", "\n", "log_every_n_steps", "=", "1", "\n", "limit_train_batches", "=", "2", "\n", "limit_val_batches", "=", "2", "\n", "limit_test_batches", "=", "2", "\n", "n_epochs", "=", "3", "\n", "", "else", ":", "\n", "        ", "flush_logs_every_n_steps", "=", "100", "\n", "log_every_n_steps", "=", "40", "\n", "limit_train_batches", "=", "1.", "\n", "limit_val_batches", "=", "1.", "\n", "limit_test_batches", "=", "1.", "\n", "n_epochs", "=", "config", "[", "\"training\"", "]", "[", "\"n_epochs\"", "]", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "n_epochs", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "gpus", "=", "gpus", ",", "\n", "distributed_backend", "=", "config", "[", "\"training\"", "]", ".", "get", "(", "\"backend\"", ")", ",", "\n", "accumulate_grad_batches", "=", "config", "[", "\"training\"", "]", "[", "\"accumulate_batches\"", "]", ",", "\n", "logger", "=", "logger", ",", "\n", "resume_from_checkpoint", "=", "checkpoint_resume", ",", "\n", "gradient_clip_val", "=", "config", "[", "\"training\"", "]", "[", "\"gradient_clip\"", "]", ",", "\n", "check_val_every_n_epoch", "=", "config", "[", "\"training\"", "]", "[", "\"validation_interval\"", "]", ",", "\n", "num_sanity_val_steps", "=", "0", ",", "\n", "log_every_n_steps", "=", "log_every_n_steps", ",", "\n", "flush_logs_every_n_steps", "=", "flush_logs_every_n_steps", ",", "\n", "limit_train_batches", "=", "limit_train_batches", ",", "\n", "limit_val_batches", "=", "limit_val_batches", ",", "\n", "limit_test_batches", "=", "limit_test_batches", ",", "\n", ")", "\n", "\n", "if", "test_state_dict", "is", "None", ":", "\n", "        ", "trainer", ".", "fit", "(", "desed_training", ")", "\n", "best_path", "=", "trainer", ".", "checkpoint_callback", ".", "best_model_path", "\n", "print", "(", "f\"best model: {best_path}\"", ")", "\n", "test_state_dict", "=", "torch", ".", "load", "(", "best_path", ")", "[", "\"state_dict\"", "]", "\n", "\n", "", "desed_training", ".", "load_state_dict", "(", "test_state_dict", ")", "\n", "trainer", ".", "test", "(", "desed_training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dcase2021_task4_baseline.train_sed_SRST.resample_data_generate_durations": [[26, 47], ["local.resample_folder.resample_folder", "local.utils.generate_tsv_wav_durations", "os.path.exists"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.resample_folder.resample_folder", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.generate_tsv_wav_durations"], ["def", "resample_data_generate_durations", "(", "config_data", ",", "test_only", "=", "False", ")", ":", "\n", "    ", "if", "not", "test_only", ":", "\n", "        ", "dsets", "=", "[", "\n", "\"synth_folder\"", ",", "\n", "\"synth_val_folder\"", ",", "\n", "\"weak_folder\"", ",", "\n", "\"unlabeled_folder\"", ",", "\n", "\"test_folder\"", ",", "\n", "]", "\n", "", "else", ":", "\n", "        ", "dsets", "=", "[", "\"test_folder\"", "]", "\n", "\n", "", "for", "dset", "in", "dsets", ":", "\n", "        ", "computed", "=", "resample_folder", "(", "\n", "config_data", "[", "dset", "+", "\"_44k\"", "]", ",", "config_data", "[", "dset", "]", ",", "target_fs", "=", "config_data", "[", "\"fs\"", "]", "\n", ")", "\n", "\n", "", "for", "base_set", "in", "[", "\"synth_val\"", ",", "\"test\"", "]", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "config_data", "[", "base_set", "+", "\"_dur\"", "]", ")", "or", "computed", ":", "\n", "            ", "generate_tsv_wav_durations", "(", "\n", "config_data", "[", "base_set", "+", "\"_folder\"", "]", ",", "config_data", "[", "base_set", "+", "\"_dur\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.dcase2021_task4_baseline.train_sed_SRST.single_run": [[50, 251], ["config.update", "desed_task.utils.encoder.ManyHotEncoder", "pandas.read_csv", "desed_task.dataio.datasets.StronglyAnnotatedSet", "desed_task.nnet.CRNN.CRNN", "local.sed_trainer_SRST.SEDTask4_2021", "pytorch_lightning.Trainer", "local.sed_trainer_SRST.SEDTask4_2021.load_state_dict", "pl.Trainer.test", "list", "pandas.read_csv", "desed_task.dataio.datasets.StronglyAnnotatedSet", "pandas.read_csv", "pd.read_csv.sample", "pd.read_csv.drop().reset_index", "train_weak_df.reset_index.reset_index", "desed_task.dataio.datasets.WeakSet", "desed_task.dataio.datasets.UnlabelledSet", "pandas.read_csv", "desed_task.dataio.datasets.StronglyAnnotatedSet", "desed_task.dataio.datasets.WeakSet", "torch.utils.data.ConcatDataset", "desed_task.dataio.ConcatDatasetBatchSampler", "torch.utils.data.ConcatDataset", "min", "torch.optim.Adam", "pytorch_lightning.loggers.TensorBoardLogger", "print", "pl.Trainer.fit", "print", "local.classes_dict.classes_labels.keys", "torch.utils.data.RandomSampler", "desed_task.nnet.CRNN.CRNN.parameters", "desed_task.utils.schedulers.ExponentialWarmup", "os.path.dirname", "pytorch_lightning.callbacks.EarlyStopping", "pytorch_lightning.callbacks.ModelCheckpoint", "config[].get", "torch.load", "pd.read_csv.drop", "config[].split", "len", "range", "len"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.update", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.load_state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.fit", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.load"], ["", "", "", "def", "single_run", "(", "\n", "config", ",", "\n", "log_dir", ",", "\n", "gpus", ",", "\n", "checkpoint_resume", "=", "None", ",", "\n", "test_state_dict", "=", "None", ",", "\n", "fast_dev_run", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Running sound event detection baselin\n\n    Args:\n        config (dict): the dictionary of configuration params\n        log_dir (str): path to log directory\n        gpus (int): number of gpus to use\n        checkpoint_resume (str, optional): path to checkpoint to resume from. Defaults to \"\".\n        test_state_dict (dict, optional): if not None, no training is involved. This dictionary is the state_dict\n            to be loaded to test the model.\n        fast_dev_run (bool, optional): whether to use a run with only one batch at train and validation, useful\n            for development purposes.\n    \"\"\"", "\n", "config", ".", "update", "(", "{", "\"log_dir\"", ":", "log_dir", "}", ")", "\n", "\n", "##### data prep test ##########", "\n", "encoder", "=", "ManyHotEncoder", "(", "\n", "list", "(", "classes_labels", ".", "keys", "(", ")", ")", ",", "\n", "audio_len", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", "frame_len", "=", "config", "[", "\"feats\"", "]", "[", "\"n_filters\"", "]", ",", "\n", "frame_hop", "=", "config", "[", "\"feats\"", "]", "[", "\"hop_length\"", "]", ",", "\n", "net_pooling", "=", "config", "[", "\"data\"", "]", "[", "\"net_subsample\"", "]", ",", "\n", "fs", "=", "config", "[", "\"data\"", "]", "[", "\"fs\"", "]", ",", "\n", ")", "\n", "\n", "devtest_df", "=", "pd", ".", "read_csv", "(", "config", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "sep", "=", "\"\\t\"", ")", "\n", "devtest_dataset", "=", "StronglyAnnotatedSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"test_folder\"", "]", ",", "\n", "devtest_df", ",", "\n", "encoder", ",", "\n", "return_filename", "=", "True", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", ")", "\n", "\n", "test_dataset", "=", "devtest_dataset", "\n", "\n", "##### model definition  ############", "\n", "sed_student", "=", "CRNN", "(", "**", "config", "[", "\"net\"", "]", ")", "\n", "\n", "if", "test_state_dict", "is", "None", ":", "\n", "##### data prep train valid ##########", "\n", "        ", "synth_df", "=", "pd", ".", "read_csv", "(", "config", "[", "\"data\"", "]", "[", "\"synth_tsv\"", "]", ",", "sep", "=", "\"\\t\"", ")", "\n", "synth_set", "=", "StronglyAnnotatedSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"synth_folder\"", "]", ",", "\n", "synth_df", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", ")", "\n", "\n", "weak_df", "=", "pd", ".", "read_csv", "(", "config", "[", "\"data\"", "]", "[", "\"weak_tsv\"", "]", ",", "sep", "=", "\"\\t\"", ")", "\n", "train_weak_df", "=", "weak_df", ".", "sample", "(", "\n", "frac", "=", "config", "[", "\"training\"", "]", "[", "\"weak_split\"", "]", ",", "random_state", "=", "config", "[", "\"training\"", "]", "[", "\"seed\"", "]", "\n", ")", "\n", "valid_weak_df", "=", "weak_df", ".", "drop", "(", "train_weak_df", ".", "index", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "train_weak_df", "=", "train_weak_df", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "weak_set", "=", "WeakSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"weak_folder\"", "]", ",", "\n", "train_weak_df", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", ")", "\n", "\n", "unlabeled_set", "=", "UnlabelledSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"unlabeled_folder\"", "]", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", ")", "\n", "\n", "synth_df_val", "=", "pd", ".", "read_csv", "(", "config", "[", "\"data\"", "]", "[", "\"synth_val_tsv\"", "]", ",", "sep", "=", "\"\\t\"", ")", "\n", "synth_val", "=", "StronglyAnnotatedSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"synth_val_folder\"", "]", ",", "\n", "synth_df_val", ",", "\n", "encoder", ",", "\n", "return_filename", "=", "True", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", ")", "\n", "\n", "weak_val", "=", "WeakSet", "(", "\n", "config", "[", "\"data\"", "]", "[", "\"weak_folder\"", "]", ",", "\n", "valid_weak_df", ",", "\n", "encoder", ",", "\n", "pad_to", "=", "config", "[", "\"data\"", "]", "[", "\"audio_max_len\"", "]", ",", "\n", "return_filename", "=", "True", ",", "\n", ")", "\n", "\n", "tot_train_data", "=", "[", "synth_set", ",", "weak_set", ",", "unlabeled_set", "]", "\n", "train_dataset", "=", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "tot_train_data", ")", "\n", "\n", "batch_sizes", "=", "config", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", "\n", "samplers", "=", "[", "torch", ".", "utils", ".", "data", ".", "RandomSampler", "(", "x", ")", "for", "x", "in", "tot_train_data", "]", "\n", "batch_sampler", "=", "ConcatDatasetBatchSampler", "(", "samplers", ",", "batch_sizes", ")", "\n", "\n", "valid_dataset", "=", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "\n", "[", "synth_val", ",", "weak_val", "]", "\n", ")", "\n", "\n", "##### training params and optimizers ############", "\n", "epoch_len", "=", "min", "(", "\n", "[", "\n", "len", "(", "tot_train_data", "[", "indx", "]", ")", "\n", "//", "(", "\n", "config", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", "[", "indx", "]", "\n", "*", "config", "[", "\"training\"", "]", "[", "\"accumulate_batches\"", "]", "\n", ")", "\n", "for", "indx", "in", "range", "(", "len", "(", "tot_train_data", ")", ")", "\n", "]", "\n", ")", "\n", "\n", "opt", "=", "torch", ".", "optim", ".", "Adam", "(", "sed_student", ".", "parameters", "(", ")", ",", "1e-3", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ")", "\n", "exp_steps", "=", "config", "[", "\"training\"", "]", "[", "\"n_epochs_warmup\"", "]", "*", "epoch_len", "\n", "exp_scheduler", "=", "{", "\n", "\"scheduler\"", ":", "ExponentialWarmup", "(", "opt", ",", "config", "[", "\"opt\"", "]", "[", "\"lr\"", "]", ",", "exp_steps", ")", ",", "\n", "\"interval\"", ":", "\"step\"", ",", "\n", "}", "\n", "logger", "=", "TensorBoardLogger", "(", "\n", "os", ".", "path", ".", "dirname", "(", "config", "[", "\"log_dir\"", "]", ")", ",", "config", "[", "\"log_dir\"", "]", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ",", "\n", ")", "\n", "print", "(", "f\"experiment dir: {logger.log_dir}\"", ")", "\n", "\n", "callbacks", "=", "[", "\n", "EarlyStopping", "(", "\n", "monitor", "=", "\"val/obj_metric\"", ",", "\n", "patience", "=", "config", "[", "\"training\"", "]", "[", "\"early_stop_patience\"", "]", ",", "\n", "verbose", "=", "True", ",", "\n", "mode", "=", "\"max\"", "\n", ")", ",", "\n", "ModelCheckpoint", "(", "logger", ".", "log_dir", ",", "monitor", "=", "\"val/obj_metric\"", ",", "save_top_k", "=", "1", ",", "mode", "=", "\"max\"", ",", "\n", "save_last", "=", "True", ")", ",", "\n", "]", "\n", "", "else", ":", "\n", "        ", "train_dataset", "=", "None", "\n", "valid_dataset", "=", "None", "\n", "batch_sampler", "=", "None", "\n", "opt", "=", "None", "\n", "exp_scheduler", "=", "None", "\n", "logger", "=", "True", "\n", "callbacks", "=", "None", "\n", "\n", "", "desed_training", "=", "SEDTask4_2021", "(", "\n", "config", ",", "\n", "encoder", "=", "encoder", ",", "\n", "sed_student", "=", "sed_student", ",", "\n", "opt", "=", "opt", ",", "\n", "train_data", "=", "train_dataset", ",", "\n", "valid_data", "=", "valid_dataset", ",", "\n", "test_data", "=", "test_dataset", ",", "\n", "train_sampler", "=", "batch_sampler", ",", "\n", "scheduler", "=", "exp_scheduler", ",", "\n", "fast_dev_run", "=", "fast_dev_run", ",", "\n", ")", "\n", "\n", "# Not using the fast_dev_run of Trainer because creates a DummyLogger so cannot check problems with the Logger", "\n", "if", "fast_dev_run", ":", "\n", "        ", "flush_logs_every_n_steps", "=", "1", "\n", "log_every_n_steps", "=", "1", "\n", "limit_train_batches", "=", "2", "\n", "limit_val_batches", "=", "2", "\n", "limit_test_batches", "=", "2", "\n", "n_epochs", "=", "3", "\n", "", "else", ":", "\n", "        ", "flush_logs_every_n_steps", "=", "100", "\n", "log_every_n_steps", "=", "40", "\n", "limit_train_batches", "=", "1.", "\n", "limit_val_batches", "=", "1.", "\n", "limit_test_batches", "=", "1.", "\n", "n_epochs", "=", "config", "[", "\"training\"", "]", "[", "\"n_epochs\"", "]", "\n", "\n", "", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "n_epochs", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "gpus", "=", "gpus", ",", "\n", "distributed_backend", "=", "config", "[", "\"training\"", "]", ".", "get", "(", "\"backend\"", ")", ",", "\n", "accumulate_grad_batches", "=", "config", "[", "\"training\"", "]", "[", "\"accumulate_batches\"", "]", ",", "\n", "logger", "=", "logger", ",", "\n", "resume_from_checkpoint", "=", "checkpoint_resume", ",", "\n", "gradient_clip_val", "=", "config", "[", "\"training\"", "]", "[", "\"gradient_clip\"", "]", ",", "\n", "check_val_every_n_epoch", "=", "config", "[", "\"training\"", "]", "[", "\"validation_interval\"", "]", ",", "\n", "num_sanity_val_steps", "=", "0", ",", "\n", "log_every_n_steps", "=", "log_every_n_steps", ",", "\n", "flush_logs_every_n_steps", "=", "flush_logs_every_n_steps", ",", "\n", "limit_train_batches", "=", "limit_train_batches", ",", "\n", "limit_val_batches", "=", "limit_val_batches", ",", "\n", "limit_test_batches", "=", "limit_test_batches", ",", "\n", ")", "\n", "\n", "if", "test_state_dict", "is", "None", ":", "\n", "        ", "trainer", ".", "fit", "(", "desed_training", ")", "\n", "best_path", "=", "trainer", ".", "checkpoint_callback", ".", "best_model_path", "\n", "print", "(", "f\"best model: {best_path}\"", ")", "\n", "test_state_dict", "=", "torch", ".", "load", "(", "best_path", ")", "[", "\"state_dict\"", "]", "\n", "\n", "", "desed_training", ".", "load_state_dict", "(", "test_state_dict", ")", "\n", "trainer", ".", "test", "(", "desed_training", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_CRST.SEDTask4_2021.__init__": [[43, 169], ["pytorch_lightning.LightningModule.__init__", "copy.deepcopy", "copy.deepcopy", "torch.nn.Softmax", "utils.JSD", "torch.tensor().cuda", "torchaudio.transforms.MelSpectrogram", "sed_trainer_CRST.SEDTask4_2021.sed_teacher1.parameters", "sed_trainer_CRST.SEDTask4_2021.sed_teacher2.parameters", "torch.nn.BCELoss", "pytorch_lightning.metrics.classification.F1", "pytorch_lightning.metrics.classification.F1", "sed_trainer_CRST.SEDTask4_2021._init_scaler", "numpy.arange", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "param.detach_", "param.detach_", "torch.nn.MSELoss", "len", "len", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "torch.tensor", "torch.nn.BCELoss"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021._init_scaler"], ["def", "__init__", "(", "\n", "self", ",", "\n", "hparams", ",", "\n", "encoder", ",", "\n", "sed_student", ",", "\n", "opt", "=", "None", ",", "\n", "train_data", "=", "None", ",", "\n", "valid_data", "=", "None", ",", "\n", "test_data", "=", "None", ",", "\n", "train_sampler", "=", "None", ",", "\n", "scheduler", "=", "None", ",", "\n", "fast_dev_run", "=", "False", ",", "\n", "evaluation", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", "SEDTask4_2021", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hparams", "=", "hparams", "\n", "\n", "# manual optimization", "\n", "self", ".", "automatic_optimization", "=", "False", "\n", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "sed_student1", "=", "sed_student", "[", "0", "]", "\n", "self", ".", "sed_teacher1", "=", "deepcopy", "(", "sed_student", "[", "0", "]", ")", "\n", "self", ".", "sed_student2", "=", "sed_student", "[", "1", "]", "\n", "self", ".", "sed_teacher2", "=", "deepcopy", "(", "sed_student", "[", "1", "]", ")", "\n", "self", ".", "opt1", "=", "opt", "[", "0", "]", "\n", "self", ".", "opt2", "=", "opt", "[", "1", "]", "\n", "self", ".", "train_data", "=", "train_data", "\n", "self", ".", "valid_data", "=", "valid_data", "\n", "self", ".", "test_data", "=", "test_data", "\n", "self", ".", "train_sampler", "=", "train_sampler", "\n", "self", ".", "scheduler1", "=", "scheduler", "[", "0", "]", "\n", "self", ".", "scheduler2", "=", "scheduler", "[", "1", "]", "\n", "self", ".", "fast_dev_run", "=", "fast_dev_run", "\n", "self", ".", "evaluation", "=", "evaluation", "\n", "\n", "if", "self", ".", "fast_dev_run", ":", "\n", "            ", "self", ".", "num_workers", "=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_workers", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", "\n", "\n", "\n", "# add class_label", "\n", "", "self", ".", "softmax", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "2", ")", "\n", "self", ".", "jsd", "=", "JSD", "(", ")", "\n", "self", ".", "class_label", "=", "torch", ".", "tensor", "(", "cfg", ".", "class_label", ")", ".", "cuda", "(", ")", "\n", "\n", "feat_params", "=", "self", ".", "hparams", "[", "\"feats\"", "]", "\n", "#self.lin_spec = LinearSpectrogram(nCh=128, n_fft=2048, hop_length=256, win_fn = torch.hamming_window)", "\n", "self", ".", "mel_spec", "=", "MelSpectrogram", "(", "\n", "sample_rate", "=", "feat_params", "[", "\"sample_rate\"", "]", ",", "\n", "n_fft", "=", "feat_params", "[", "\"n_window\"", "]", ",", "\n", "win_length", "=", "feat_params", "[", "\"n_window\"", "]", ",", "\n", "hop_length", "=", "feat_params", "[", "\"hop_length\"", "]", ",", "\n", "f_min", "=", "feat_params", "[", "\"f_min\"", "]", ",", "\n", "f_max", "=", "feat_params", "[", "\"f_max\"", "]", ",", "\n", "n_mels", "=", "feat_params", "[", "\"n_mels\"", "]", ",", "\n", "window_fn", "=", "torch", ".", "hamming_window", ",", "\n", "wkwargs", "=", "{", "\"periodic\"", ":", "False", "}", ",", "\n", "power", "=", "1", ",", "\n", ")", "\n", "\n", "for", "param", "in", "self", ".", "sed_teacher1", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "detach_", "(", ")", "\n", "\n", "", "for", "param", "in", "self", ".", "sed_teacher2", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "detach_", "(", ")", "\n", "\n", "# instantiating losses", "\n", "", "self", ".", "supervised_loss", "=", "torch", ".", "nn", ".", "BCELoss", "(", ")", "\n", "if", "hparams", "[", "\"training\"", "]", "[", "\"self_sup_loss\"", "]", "==", "\"mse\"", ":", "\n", "            ", "self", ".", "selfsup_loss", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "\n", "", "elif", "hparams", "[", "\"training\"", "]", "[", "\"self_sup_loss\"", "]", "==", "\"bce\"", ":", "\n", "            ", "self", ".", "selfsup_loss", "=", "torch", ".", "nn", ".", "BCELoss", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "# for weak labels we simply compute f1 score", "\n", "", "self", ".", "get_weak_student_f1_seg_macro", "=", "pl", ".", "metrics", ".", "classification", ".", "F1", "(", "\n", "len", "(", "self", ".", "encoder", ".", "labels", ")", ",", "\n", "average", "=", "\"macro\"", ",", "\n", "multilabel", "=", "True", ",", "\n", "compute_on_step", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "get_weak_teacher_f1_seg_macro", "=", "pl", ".", "metrics", ".", "classification", ".", "F1", "(", "\n", "len", "(", "self", ".", "encoder", ".", "labels", ")", ",", "\n", "average", "=", "\"macro\"", ",", "\n", "multilabel", "=", "True", ",", "\n", "compute_on_step", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "scaler", "=", "self", ".", "_init_scaler", "(", ")", "\n", "\n", "# buffer for event based scores which we compute using sed-eval", "\n", "self", ".", "val_buffer_student_synth", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "self", ".", "val_buffer_teacher_synth", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "\n", "self", ".", "val_buffer_student_test", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "self", ".", "val_buffer_teacher_test", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "\n", "test_n_thresholds", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"n_test_thresholds\"", "]", "\n", "test_thresholds", "=", "np", ".", "arange", "(", "\n", "1", "/", "(", "test_n_thresholds", "*", "2", ")", ",", "1", ",", "1", "/", "test_n_thresholds", "\n", ")", "\n", "self", ".", "test_psds_buffer_student1", "=", "{", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "test_thresholds", "}", "\n", "self", ".", "test_psds_buffer_teacher1", "=", "{", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "test_thresholds", "}", "\n", "self", ".", "test_psds_buffer_student2", "=", "{", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "test_thresholds", "}", "\n", "self", ".", "test_psds_buffer_teacher2", "=", "{", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "test_thresholds", "}", "\n", "self", ".", "test_psds_buffer_student", "=", "{", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "test_thresholds", "}", "\n", "self", ".", "test_psds_buffer_teacher", "=", "{", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "test_thresholds", "}", "\n", "\n", "self", ".", "decoded_student1_05_buffer", "=", "pd", ".", "DataFrame", "(", ")", "\n", "self", ".", "decoded_teacher1_05_buffer", "=", "pd", ".", "DataFrame", "(", ")", "\n", "self", ".", "decoded_student2_05_buffer", "=", "pd", ".", "DataFrame", "(", ")", "\n", "self", ".", "decoded_teacher2_05_buffer", "=", "pd", ".", "DataFrame", "(", ")", "\n", "self", ".", "decoded_student_05_buffer", "=", "pd", ".", "DataFrame", "(", ")", "\n", "self", ".", "decoded_teacher_05_buffer", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_CRST.SEDTask4_2021.update_ema": [[171, 184], ["min", "zip", "ema_model.parameters", "model.parameters", "ema_params.data.mul_().add_", "ema_params.data.mul_"], "methods", ["None"], ["", "def", "update_ema", "(", "self", ",", "alpha", ",", "global_step", ",", "model", ",", "ema_model", ")", ":", "\n", "        ", "\"\"\" Update teacher model parameters\n\n        Args:\n            alpha: float, the factor to be used between each updated step.\n            global_step: int, the current global step to be used.\n            model: torch.Module, student model to use\n            ema_model: torch.Module, teacher model to use\n        \"\"\"", "\n", "# Use the true average until the exponential average is more correct", "\n", "alpha", "=", "min", "(", "1", "-", "1", "/", "(", "global_step", "+", "1", ")", ",", "alpha", ")", "\n", "for", "ema_params", ",", "params", "in", "zip", "(", "ema_model", ".", "parameters", "(", ")", ",", "model", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "ema_params", ".", "data", ".", "mul_", "(", "alpha", ")", ".", "add_", "(", "params", ".", "data", ",", "alpha", "=", "1", "-", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_CRST.SEDTask4_2021._init_scaler": [[185, 232], ["sed_trainer_CRST.SEDTask4_2021.train_dataloader", "torch.load.fit", "desed_task.utils.scaler.TorchScaler", "os.path.exists", "torch.save", "print", "desed_task.utils.scaler.TorchScaler", "torch.load", "print", "sed_trainer_CRST.SEDTask4_2021.take_log", "sed_trainer_CRST.SEDTask4_2021.mel_spec"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.train_dataloader", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.fit", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.load", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.take_log"], ["", "", "def", "_init_scaler", "(", "self", ")", ":", "\n", "        ", "\"\"\"Scaler inizialization\n\n        Raises:\n            NotImplementedError: in case of not Implemented scaler\n\n        Returns:\n            TorchScaler: returns the scaler\n        \"\"\"", "\n", "\n", "if", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"statistic\"", "]", "==", "\"instance\"", ":", "\n", "            ", "scaler", "=", "TorchScaler", "(", "\"instance\"", ",", "\"minmax\"", ",", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"dims\"", "]", ")", "\n", "\n", "return", "scaler", "\n", "", "elif", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"statistic\"", "]", "==", "\"dataset\"", ":", "\n", "# we fit the scaler", "\n", "            ", "scaler", "=", "TorchScaler", "(", "\n", "\"dataset\"", ",", "\n", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"normtype\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"dims\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "if", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", "is", "not", "None", ":", "\n", "            ", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", ")", ":", "\n", "                ", "scaler", "=", "torch", ".", "load", "(", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", ")", "\n", "print", "(", "\n", "\"Loaded Scaler from previous checkpoint from {}\"", ".", "format", "(", "\n", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", "\n", ")", "\n", ")", "\n", "return", "scaler", "\n", "\n", "", "", "self", ".", "train_loader", "=", "self", ".", "train_dataloader", "(", ")", "\n", "scaler", ".", "fit", "(", "\n", "self", ".", "train_loader", ",", "\n", "transform_func", "=", "lambda", "x", ":", "self", ".", "take_log", "(", "self", ".", "mel_spec", "(", "x", "[", "0", "]", ")", ")", ",", "\n", ")", "\n", "\n", "if", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", "is", "not", "None", ":", "\n", "            ", "torch", ".", "save", "(", "scaler", ",", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", ")", "\n", "print", "(", "\n", "\"Saving Scaler from previous checkpoint at {}\"", ".", "format", "(", "\n", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", "\n", ")", "\n", ")", "\n", "return", "scaler", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_CRST.SEDTask4_2021.take_log": [[233, 245], ["torchaudio.transforms.AmplitudeToDB", "torchaudio.transforms.AmplitudeToDB.clamp", "torchaudio.transforms.AmplitudeToDB."], "methods", ["None"], ["", "", "def", "take_log", "(", "self", ",", "mels", ")", ":", "\n", "        ", "\"\"\" Apply the log transformation to mel spectrograms.\n        Args:\n            mels: torch.Tensor, mel spectrograms for which to apply log.\n\n        Returns:\n            Tensor: logarithmic mel spectrogram of the mel spectrogram given as input\n        \"\"\"", "\n", "\n", "amp_to_db", "=", "AmplitudeToDB", "(", "stype", "=", "\"amplitude\"", ")", "\n", "amp_to_db", ".", "amin", "=", "1e-5", "# amin= 1e-5 as in librosa", "\n", "return", "amp_to_db", "(", "mels", ")", ".", "clamp", "(", "min", "=", "-", "50", ",", "max", "=", "80", ")", "# clamp to reproduce old code", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_CRST.SEDTask4_2021.training_step": [[247, 468], ["sed_trainer_CRST.SEDTask4_2021.mel_spec", "torch.zeros().to().bool", "torch.zeros().to().bool", "sed_trainer_CRST.SEDTask4_2021.hparams[].get", "sed_trainer_CRST.SEDTask4_2021.scaler", "sed_trainer_CRST.SEDTask4_2021.clone().detach", "labels.clone().detach", "desed_task.data_augm.frame_shift", "sed_trainer_CRST.SEDTask4_2021.sed_student1", "sed_trainer_CRST.SEDTask4_2021.sed_student2", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.selfsup_loss", "sed_trainer_CRST.SEDTask4_2021.selfsup_loss", "sed_trainer_CRST.SEDTask4_2021.selfsup_loss", "sed_trainer_CRST.SEDTask4_2021.selfsup_loss", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.update_ema", "sed_trainer_CRST.SEDTask4_2021.update_ema", "sed_trainer_CRST.SEDTask4_2021.opt1.zero_grad", "sed_trainer_CRST.SEDTask4_2021.manual_backward", "sed_trainer_CRST.SEDTask4_2021.opt1.step", "sed_trainer_CRST.SEDTask4_2021.opt2.zero_grad", "sed_trainer_CRST.SEDTask4_2021.manual_backward", "sed_trainer_CRST.SEDTask4_2021.opt2.step", "desed_task.data_augm.mixup", "desed_task.data_augm.mixup", "sed_trainer_CRST.SEDTask4_2021.take_log", "torch.no_grad", "sed_trainer_CRST.SEDTask4_2021.sed_teacher1", "sed_trainer_CRST.SEDTask4_2021.sed_teacher2", "torch.clamp", "torch.log", "torch.log", "torch.clamp", "torch.log", "torch.log", "torch.cat", "torch.cat", "torch.cat.sum", "range", "torch.cat", "range", "torch.cat", "torch.cat", "sed_trainer_CRST.SEDTask4_2021.softmax", "torch.sort", "prob_v[].sum", "torch.mul().sum", "torch.squeeze().float", "torch.squeeze().float", "est_strong_target1.permute.permute.permute", "est_strong_target2.permute.permute.permute", "est_strong_target1.permute.permute.mean", "est_strong_target2.permute.permute.mean", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.scheduler1[]._get_scaling_factor", "sed_trainer_CRST.SEDTask4_2021.scheduler2[]._get_scaling_factor", "torch.zeros().to", "torch.zeros().to", "random.random", "sed_trainer_CRST.SEDTask4_2021.clone", "labels.clone", "torch.clamp.permute", "torch.clamp.permute", "torch.cat.append", "range", "sed_trainer_CRST.SEDTask4_2021.jsd", "sed_trainer_CRST.SEDTask4_2021.jsd", "sed_trainer_CRST.SEDTask4_2021.jsd", "sed_trainer_CRST.SEDTask4_2021.jsd", "torch.sum", "torch.sum", "torch.clamp.permute", "torch.clamp.permute", "torch.cat.append", "torch.cat.sum.reshape", "torch.mul", "torch.squeeze", "torch.squeeze", "torch.zeros", "torch.zeros", "prob_i[].tolist"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.desed_task.data_augm.frame_shift", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.update_ema", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.update_ema", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.desed_task.data_augm.mixup", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.desed_task.data_augm.mixup", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.take_log", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.schedulers.ExponentialWarmup._get_scaling_factor", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.schedulers.ExponentialWarmup._get_scaling_factor"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_indx", ",", "optimizer_idx", ")", ":", "\n", "        ", "\"\"\" Applying the training for one batch (a step). Used during trainer.fit\n\n        Args:\n            batch: torch.Tensor, batch input tensor\n            batch_indx: torch.Tensor, 1D tensor of indexes to know which data are present in each batch.\n\n        Returns:\n           torch.Tensor, the loss to take into account.\n        \"\"\"", "\n", "\n", "audio", ",", "labels", ",", "padded_indxs", "=", "batch", "\n", "indx_synth", ",", "indx_weak", ",", "indx_unlabelled", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", "\n", "features", "=", "self", ".", "mel_spec", "(", "audio", ")", "\n", "\n", "batch_num", "=", "features", ".", "shape", "[", "0", "]", "\n", "# deriving masks for each dataset", "\n", "strong_mask", "=", "torch", ".", "zeros", "(", "batch_num", ")", ".", "to", "(", "features", ")", ".", "bool", "(", ")", "\n", "weak_mask", "=", "torch", ".", "zeros", "(", "batch_num", ")", ".", "to", "(", "features", ")", ".", "bool", "(", ")", "\n", "strong_mask", "[", ":", "indx_synth", "]", "=", "1", "\n", "weak_mask", "[", "indx_synth", ":", "indx_weak", "+", "indx_synth", "]", "=", "1", "\n", "\n", "# deriving weak labels", "\n", "labels_weak", "=", "(", "torch", ".", "sum", "(", "labels", "[", "weak_mask", "]", ",", "-", "1", ")", ">", "0", ")", ".", "float", "(", ")", "\n", "\n", "mixup_type", "=", "self", ".", "hparams", "[", "\"training\"", "]", ".", "get", "(", "\"mixup\"", ")", "\n", "if", "mixup_type", "is", "not", "None", "and", "0.5", ">", "random", ".", "random", "(", ")", ":", "\n", "            ", "features", "[", "weak_mask", "]", ",", "labels_weak", "=", "mixup", "(", "\n", "features", "[", "weak_mask", "]", ",", "labels_weak", ",", "mixup_label_type", "=", "mixup_type", "\n", ")", "\n", "features", "[", "strong_mask", "]", ",", "labels", "[", "strong_mask", "]", "=", "mixup", "(", "\n", "features", "[", "strong_mask", "]", ",", "labels", "[", "strong_mask", "]", ",", "mixup_label_type", "=", "mixup_type", "\n", ")", "\n", "\n", "# perturbation", "\n", "", "ori_features", "=", "self", ".", "scaler", "(", "self", ".", "take_log", "(", "features", ")", ")", "\n", "ema_features", "=", "ori_features", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "ema_labels", "=", "labels", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "ema_features", ",", "ema_labels", "=", "frame_shift", "(", "ema_features", ",", "ema_labels", ")", "\n", "ema_labels_weak", "=", "(", "torch", ".", "sum", "(", "ema_labels", "[", "weak_mask", "]", ",", "-", "1", ")", ">", "0", ")", ".", "float", "(", ")", "\n", "\n", "# sed students forward", "\n", "strong_preds_student1", ",", "weak_preds_student1", "=", "self", ".", "sed_student1", "(", "ori_features", ")", "\n", "strong_preds_student2", ",", "weak_preds_student2", "=", "self", ".", "sed_student2", "(", "ema_features", ")", "\n", "\n", "# supervised loss on strong labels", "\n", "loss_strong1", "=", "self", ".", "supervised_loss", "(", "\n", "strong_preds_student1", "[", "strong_mask", "]", ",", "labels", "[", "strong_mask", "]", "\n", ")", "\n", "loss_strong2", "=", "self", ".", "supervised_loss", "(", "\n", "strong_preds_student2", "[", "strong_mask", "]", ",", "ema_labels", "[", "strong_mask", "]", "\n", ")", "\n", "\n", "# supervised loss on weakly labelled", "\n", "loss_weak1", "=", "self", ".", "supervised_loss", "(", "weak_preds_student1", "[", "weak_mask", "]", ",", "labels_weak", ")", "\n", "loss_weak2", "=", "self", ".", "supervised_loss", "(", "weak_preds_student2", "[", "weak_mask", "]", ",", "ema_labels_weak", ")", "\n", "\n", "# total supervised loss", "\n", "tot_loss_supervised1", "=", "loss_strong1", "+", "loss_weak1", "\n", "tot_loss_supervised2", "=", "loss_strong2", "+", "loss_weak2", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "strong_preds_teacher1", ",", "weak_preds_teacher1", "=", "self", ".", "sed_teacher1", "(", "ema_features", ")", "\n", "strong_preds_teacher2", ",", "weak_preds_teacher2", "=", "self", ".", "sed_teacher2", "(", "ori_features", ")", "\n", "\n", "nClass", "=", "self", ".", "hparams", "[", "'net'", "]", "[", "'nclass'", "]", "\n", "\n", "sp1", "=", "torch", ".", "clamp", "(", "strong_preds_teacher1", ",", "1.0e-4", ",", "1", "-", "1.0e-4", ")", "\n", "p1_h1", "=", "torch", ".", "log", "(", "sp1", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "p1_h0", "=", "torch", ".", "log", "(", "1", "-", "sp1", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "\n", "sp2", "=", "torch", ".", "clamp", "(", "strong_preds_teacher2", ",", "1.0e-4", ",", "1", "-", "1.0e-4", ")", "\n", "p2_h1", "=", "torch", ".", "log", "(", "sp2", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "p2_h0", "=", "torch", ".", "log", "(", "1", "-", "sp2", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "\n", "p_h0", "=", "torch", ".", "cat", "(", "(", "p1_h0", ",", "p2_h0", ")", ",", "1", ")", "\n", "p_h1", "=", "torch", ".", "cat", "(", "(", "p1_h1", ",", "p2_h1", ")", ",", "1", ")", "\n", "\n", "# K = 0", "\n", "P0", "=", "p_h0", ".", "sum", "(", "2", ")", "\n", "\n", "# K = 1", "\n", "P1", "=", "P0", "[", ":", ",", ":", ",", "None", "]", "+", "p_h1", "-", "p_h0", "\n", "#P  = torch.cat([P0.reshape(157,1), P1], 1)", "\n", "\n", "# K = 2", "\n", "P2", "=", "[", "]", "\n", "for", "cter", "in", "range", "(", "1", ",", "nClass", ")", ":", "\n", "                ", "P2", ".", "append", "(", "P1", "[", ":", ",", ":", ",", ":", "-", "cter", "]", "+", "P1", "[", ":", ",", ":", ",", "cter", ":", "]", ")", "\n", "", "P2", "=", "torch", ".", "cat", "(", "P2", ",", "2", ")", "\n", "P2", "=", "P2", "-", "P0", "[", ":", ",", ":", ",", "None", "]", "\n", "#P = torch.cat([P0.reshape(156*2,1), P1, P2], 1)", "\n", "\n", "# K: up to 3", "\n", "P3", "=", "[", "]", "\n", "for", "cter1", "in", "range", "(", "1", ",", "nClass", ")", ":", "\n", "                ", "for", "cter2", "in", "range", "(", "1", ",", "nClass", "-", "cter1", ")", ":", "\n", "                    ", "P3", ".", "append", "(", "P1", "[", ":", ",", ":", ",", ":", "-", "(", "cter1", "+", "cter2", ")", "]", "+", "P1", "[", ":", ",", ":", ",", "cter1", ":", "-", "cter2", "]", "+", "P1", "[", ":", ",", ":", ",", "(", "cter1", "+", "cter2", ")", ":", "]", ")", "\n", "", "", "P3", "=", "torch", ".", "cat", "(", "P3", ",", "2", ")", "\n", "P3", "=", "P3", "-", "2", "*", "P0", "[", ":", ",", ":", ",", "None", "]", "\n", "P", "=", "torch", ".", "cat", "(", "[", "P0", ".", "reshape", "(", "batch_num", ",", "156", "*", "2", ",", "1", ")", ",", "P1", ",", "P2", ",", "P3", "]", ",", "2", ")", "\n", "\n", "P", "=", "self", ".", "softmax", "(", "P", ")", "\n", "prob_v", ",", "prob_i", "=", "torch", ".", "sort", "(", "P", ",", "dim", "=", "2", ",", "descending", "=", "True", ")", "\n", "\n", "# 5 best potential labels", "\n", "norm_p", "=", "prob_v", "[", ":", ",", ":", ",", ":", "]", ".", "sum", "(", "2", ")", "\n", "prob_v", "=", "prob_v", "[", ":", ",", ":", ",", ":", "]", "/", "norm_p", "[", ":", ",", ":", ",", "None", "]", "\n", "\n", "cl", "=", "self", ".", "class_label", "[", "prob_i", "[", ":", ",", ":", ",", ":", "]", ".", "tolist", "(", ")", ",", ":", "]", "\n", "# picking up the best label", "\n", "cl", "=", "torch", ".", "mul", "(", "cl", ",", "prob_v", "[", ":", ",", ":", ",", ":", ",", "None", "]", ")", ".", "sum", "(", "2", ")", "\n", "\n", "est_strong_target1", "=", "torch", ".", "squeeze", "(", "cl", "[", ":", ",", ":", "156", ",", ":", "]", ")", ".", "float", "(", ")", "\n", "est_strong_target2", "=", "torch", ".", "squeeze", "(", "cl", "[", ":", ",", "156", ":", ",", ":", "]", ")", ".", "float", "(", ")", "\n", "\n", "est_strong_target1", "=", "est_strong_target1", ".", "permute", "(", "(", "0", ",", "2", ",", "1", ")", ")", "# for ema_feature", "\n", "est_strong_target2", "=", "est_strong_target2", ".", "permute", "(", "(", "0", ",", "2", ",", "1", ")", ")", "# for ori_feature", "\n", "\n", "est_weak_target1", "=", "est_strong_target1", ".", "mean", "(", "2", ")", "\n", "est_weak_target2", "=", "est_strong_target2", ".", "mean", "(", "2", ")", "\n", "\n", "loss_strong_teacher1", "=", "self", ".", "supervised_loss", "(", "\n", "strong_preds_teacher1", "[", "strong_mask", "]", ",", "ema_labels", "[", "strong_mask", "]", "\n", ")", "\n", "loss_strong_teacher2", "=", "self", ".", "supervised_loss", "(", "\n", "strong_preds_teacher2", "[", "strong_mask", "]", ",", "labels", "[", "strong_mask", "]", "\n", ")", "\n", "\n", "loss_weak_teacher1", "=", "self", ".", "supervised_loss", "(", "\n", "weak_preds_teacher1", "[", "weak_mask", "]", ",", "ema_labels_weak", "\n", ")", "\n", "loss_weak_teacher2", "=", "self", ".", "supervised_loss", "(", "\n", "weak_preds_teacher2", "[", "weak_mask", "]", ",", "labels_weak", "\n", ")", "\n", "\n", "# we apply consistency between the predictions, use the scheduler for learning rate (to be changed ?)", "\n", "", "weight1", "=", "(", "\n", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"const_max\"", "]", "\n", "*", "self", ".", "scheduler1", "[", "\"scheduler\"", "]", ".", "_get_scaling_factor", "(", ")", "\n", ")", "\n", "weight2", "=", "(", "\n", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"const_max\"", "]", "\n", "*", "self", ".", "scheduler2", "[", "\"scheduler\"", "]", ".", "_get_scaling_factor", "(", ")", "\n", ")", "\n", "\n", "strong_reliability1", "=", "weight1", "*", "(", "1", "-", "self", ".", "jsd", "(", "est_strong_target1", "[", "strong_mask", "]", ",", "ema_labels", "[", "strong_mask", "]", ")", ")", "\n", "strong_reliability2", "=", "weight2", "*", "(", "1", "-", "self", ".", "jsd", "(", "est_strong_target2", "[", "strong_mask", "]", ",", "labels", "[", "strong_mask", "]", ")", ")", "\n", "weak_reliability1", "=", "weight1", "*", "(", "1", "-", "self", ".", "jsd", "(", "est_weak_target1", "[", "weak_mask", "]", ",", "ema_labels_weak", ")", ")", "\n", "weak_reliability2", "=", "weight2", "*", "(", "1", "-", "self", ".", "jsd", "(", "est_weak_target2", "[", "weak_mask", "]", ",", "labels_weak", ")", ")", "\n", "\n", "strong_self_sup_loss1", "=", "self", ".", "selfsup_loss", "(", "\n", "strong_preds_student1", "[", "24", ":", "]", ",", "est_strong_target2", "[", "24", ":", "]", "# for ori_feature", "\n", ")", "\n", "strong_self_sup_loss2", "=", "self", ".", "selfsup_loss", "(", "\n", "strong_preds_student2", "[", "24", ":", "]", ",", "est_strong_target1", "[", "24", ":", "]", "# for ema_feature", "\n", ")", "\n", "\n", "weak_self_sup_loss1", "=", "self", ".", "selfsup_loss", "(", "\n", "weak_preds_student1", "[", "weak_mask", "]", ",", "est_weak_target2", "[", "weak_mask", "]", "\n", ")", "\n", "weak_self_sup_loss2", "=", "self", ".", "selfsup_loss", "(", "\n", "weak_preds_student2", "[", "weak_mask", "]", ",", "est_weak_target1", "[", "weak_mask", "]", "\n", ")", "\n", "\n", "tot_self_loss1", "=", "strong_reliability2", "*", "strong_self_sup_loss1", "+", "weak_reliability2", "*", "weak_self_sup_loss1", "\n", "tot_self_loss2", "=", "strong_reliability1", "*", "strong_self_sup_loss2", "+", "weak_reliability1", "*", "weak_self_sup_loss2", "\n", "\n", "tot_loss1", "=", "tot_loss_supervised1", "+", "tot_self_loss1", "\n", "tot_loss2", "=", "tot_loss_supervised2", "+", "tot_self_loss2", "\n", "\n", "#self.log(\"train/student/loss_strong1\", loss_strong1)", "\n", "#self.log(\"train/student/loss_weak1\", loss_weak1)", "\n", "#self.log(\"train/student/loss_strong2\", loss_strong2)", "\n", "#self.log(\"train/student/loss_weak2\", loss_weak2)", "\n", "#self.log(\"train/teacher/loss_strong1\", loss_strong_teacher1)", "\n", "#self.log(\"train/teacher/loss_weak1\", loss_weak_teacher1)", "\n", "#self.log(\"train/teacher/loss_strong2\", loss_strong_teacher2)", "\n", "#self.log(\"train/teacher/loss_weak2\", loss_weak_teacher2)", "\n", "self", ".", "log", "(", "\"train/step1\"", ",", "self", ".", "scheduler1", "[", "\"scheduler\"", "]", ".", "step_num", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"train/step2\"", ",", "self", ".", "scheduler2", "[", "\"scheduler\"", "]", ".", "step_num", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"train/student/tot_loss1\"", ",", "tot_loss1", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"train/student/tot_loss2\"", ",", "tot_loss2", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"train/strong_reliability1\"", ",", "strong_reliability1", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"train/strong_reliability2\"", ",", "strong_reliability2", ",", "prog_bar", "=", "True", ")", "\n", "#self.log(\"train/student/tot_self_loss1\", tot_self_loss1, prog_bar=True)", "\n", "#self.log(\"train/student/weak_self_sup_loss1\", weak_self_sup_loss1)", "\n", "#self.log(\"train/student/strong_self_sup_loss1\", strong_self_sup_loss1)", "\n", "#self.log(\"train/student/tot_self_loss2\", tot_self_loss2, prog_bar=True)", "\n", "#self.log(\"train/student/weak_self_sup_loss2\", weak_self_sup_loss2)", "\n", "#self.log(\"train/student/strong_self_sup_loss2\", strong_self_sup_loss2)", "\n", "self", ".", "log", "(", "\"train/lr1\"", ",", "self", ".", "opt1", ".", "param_groups", "[", "-", "1", "]", "[", "\"lr\"", "]", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"train/lr2\"", ",", "self", ".", "opt2", ".", "param_groups", "[", "-", "1", "]", "[", "\"lr\"", "]", ",", "prog_bar", "=", "True", ")", "\n", "\n", "\n", "# update EMA teacher", "\n", "self", ".", "update_ema", "(", "\n", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"ema_factor\"", "]", ",", "\n", "self", ".", "scheduler1", "[", "\"scheduler\"", "]", ".", "step_num", ",", "\n", "self", ".", "sed_student1", ",", "\n", "self", ".", "sed_teacher1", ",", "\n", ")", "\n", "\n", "self", ".", "update_ema", "(", "\n", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"ema_factor\"", "]", ",", "\n", "self", ".", "scheduler2", "[", "\"scheduler\"", "]", ".", "step_num", ",", "\n", "self", ".", "sed_student2", ",", "\n", "self", ".", "sed_teacher2", ",", "\n", ")", "\n", "\n", "# training Model I", "\n", "self", ".", "opt1", ".", "zero_grad", "(", ")", "\n", "self", ".", "manual_backward", "(", "tot_loss1", ",", "self", ".", "opt1", ")", "\n", "self", ".", "opt1", ".", "step", "(", ")", "\n", "\n", "# training Model II", "\n", "self", ".", "opt2", ".", "zero_grad", "(", ")", "\n", "self", ".", "manual_backward", "(", "tot_loss2", ",", "self", ".", "opt2", ")", "\n", "self", ".", "opt2", ".", "step", "(", ")", "\n", "\n", "return", "{", "'tot_loss1'", ":", "tot_loss1", ",", "'tot_loss2'", ":", "tot_loss2", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_CRST.SEDTask4_2021.validation_step": [[471, 584], ["sed_trainer_CRST.SEDTask4_2021.mel_spec", "sed_trainer_CRST.SEDTask4_2021.scaler", "sed_trainer_CRST.SEDTask4_2021.sed_student1", "sed_trainer_CRST.SEDTask4_2021.sed_student2", "sed_trainer_CRST.SEDTask4_2021.sed_teacher1", "sed_trainer_CRST.SEDTask4_2021.sed_teacher2", "torch.tensor().to().bool", "torch.tensor().to().bool", "torch.any", "torch.any", "sed_trainer_CRST.SEDTask4_2021.take_log", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.get_weak_student_f1_seg_macro", "sed_trainer_CRST.SEDTask4_2021.get_weak_teacher_f1_seg_macro", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "utils.batched_decode_preds", "sed_trainer_CRST.SEDTask4_2021.val_buffer_student_synth.keys", "utils.batched_decode_preds", "sed_trainer_CRST.SEDTask4_2021.val_buffer_teacher_synth.keys", "torch.tensor().to", "torch.tensor().to", "sed_trainer_CRST.SEDTask4_2021.val_buffer_student_synth[].append", "sed_trainer_CRST.SEDTask4_2021.val_buffer_teacher_synth[].append", "list", "list", "torch.tensor", "torch.tensor", "torch.sum", "pathlib.Path", "sed_trainer_CRST.SEDTask4_2021.val_buffer_student_synth.keys", "sed_trainer_CRST.SEDTask4_2021.val_buffer_teacher_synth.keys", "pathlib.Path", "str", "str", "str", "str", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.take_log", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_indx", ")", ":", "\n", "        ", "\"\"\" Apply validation to a batch (step). Used during trainer.fit\n\n        Args:\n            batch: torch.Tensor, input batch tensor\n            batch_indx: torch.Tensor, 1D tensor of indexes to know which data are present in each batch.\n        Returns:\n        \"\"\"", "\n", "\n", "audio", ",", "labels", ",", "padded_indxs", ",", "filenames", "=", "batch", "\n", "features", "=", "self", ".", "mel_spec", "(", "audio", ")", "\n", "#features2 = self.lin_spec(audio)", "\n", "#features  = torch.cat([features1, features2], 1)", "\n", "\n", "logmels", "=", "self", ".", "scaler", "(", "self", ".", "take_log", "(", "features", ")", ")", "\n", "\n", "# prediction for strudent", "\n", "strong_preds_student1", ",", "weak_preds_student1", "=", "self", ".", "sed_student1", "(", "logmels", ")", "\n", "strong_preds_student2", ",", "weak_preds_student2", "=", "self", ".", "sed_student2", "(", "logmels", ")", "\n", "strong_preds_student", "=", "(", "strong_preds_student1", "+", "strong_preds_student2", ")", "/", "2", "\n", "weak_preds_student", "=", "(", "weak_preds_student1", "+", "weak_preds_student2", ")", "/", "2", "\n", "# prediction for teacher", "\n", "strong_preds_teacher1", ",", "weak_preds_teacher1", "=", "self", ".", "sed_teacher1", "(", "logmels", ")", "\n", "strong_preds_teacher2", ",", "weak_preds_teacher2", "=", "self", ".", "sed_teacher2", "(", "logmels", ")", "\n", "strong_preds_teacher", "=", "(", "strong_preds_teacher1", "+", "strong_preds_teacher2", ")", "/", "2", "\n", "weak_preds_teacher", "=", "(", "weak_preds_teacher1", "+", "weak_preds_teacher2", ")", "/", "2", "\n", "\n", "# we derive masks for each dataset based on folders of filenames", "\n", "mask_weak", "=", "(", "\n", "torch", ".", "tensor", "(", "\n", "[", "\n", "str", "(", "Path", "(", "x", ")", ".", "parent", ")", "\n", "==", "str", "(", "Path", "(", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"weak_folder\"", "]", ")", ")", "\n", "for", "x", "in", "filenames", "\n", "]", "\n", ")", "\n", ".", "to", "(", "audio", ")", "\n", ".", "bool", "(", ")", "\n", ")", "\n", "mask_synth", "=", "(", "\n", "torch", ".", "tensor", "(", "\n", "[", "\n", "str", "(", "Path", "(", "x", ")", ".", "parent", ")", "\n", "==", "str", "(", "Path", "(", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_folder\"", "]", ")", ")", "\n", "for", "x", "in", "filenames", "\n", "]", "\n", ")", "\n", ".", "to", "(", "audio", ")", "\n", ".", "bool", "(", ")", "\n", ")", "\n", "\n", "if", "torch", ".", "any", "(", "mask_weak", ")", ":", "\n", "            ", "labels_weak", "=", "(", "torch", ".", "sum", "(", "labels", "[", "mask_weak", "]", ",", "-", "1", ")", ">=", "1", ")", ".", "float", "(", ")", "\n", "loss_weak_student", "=", "self", ".", "supervised_loss", "(", "\n", "weak_preds_student", "[", "mask_weak", "]", ",", "labels_weak", "\n", ")", "\n", "loss_weak_teacher", "=", "self", ".", "supervised_loss", "(", "\n", "weak_preds_teacher", "[", "mask_weak", "]", ",", "labels_weak", "\n", ")", "\n", "self", ".", "log", "(", "\"val/weak/student/loss_weak\"", ",", "loss_weak_student", ")", "\n", "self", ".", "log", "(", "\"val/weak/teacher/loss_weak\"", ",", "loss_weak_teacher", ")", "\n", "\n", "# accumulate f1 score for weak labels", "\n", "self", ".", "get_weak_student_f1_seg_macro", "(", "\n", "weak_preds_student", "[", "mask_weak", "]", ",", "labels_weak", "\n", ")", "\n", "self", ".", "get_weak_teacher_f1_seg_macro", "(", "\n", "weak_preds_teacher", "[", "mask_weak", "]", ",", "labels_weak", "\n", ")", "\n", "\n", "", "if", "torch", ".", "any", "(", "mask_synth", ")", ":", "\n", "            ", "loss_strong_student", "=", "self", ".", "supervised_loss", "(", "\n", "strong_preds_student", "[", "mask_synth", "]", ",", "labels", "[", "mask_synth", "]", "\n", ")", "\n", "loss_strong_teacher", "=", "self", ".", "supervised_loss", "(", "\n", "strong_preds_teacher", "[", "mask_synth", "]", ",", "labels", "[", "mask_synth", "]", "\n", ")", "\n", "\n", "self", ".", "log", "(", "\"val/synth/student/loss_strong\"", ",", "loss_strong_student", ")", "\n", "self", ".", "log", "(", "\"val/synth/teacher/loss_strong\"", ",", "loss_strong_teacher", ")", "\n", "\n", "filenames_synth", "=", "[", "\n", "x", "\n", "for", "x", "in", "filenames", "\n", "if", "Path", "(", "x", ")", ".", "parent", "==", "Path", "(", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_folder\"", "]", ")", "\n", "]", "\n", "\n", "decoded_student_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_student", "[", "mask_synth", "]", ",", "\n", "filenames_synth", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "val_buffer_student_synth", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "\n", "for", "th", "in", "self", ".", "val_buffer_student_synth", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "val_buffer_student_synth", "[", "th", "]", "=", "self", ".", "val_buffer_student_synth", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_student_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "decoded_teacher_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_teacher", "[", "mask_synth", "]", ",", "\n", "filenames_synth", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "val_buffer_teacher_synth", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "for", "th", "in", "self", ".", "val_buffer_teacher_synth", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "val_buffer_teacher_synth", "[", "th", "]", "=", "self", ".", "val_buffer_teacher_synth", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_teacher_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_CRST.SEDTask4_2021.validation_epoch_end": [[585, 657], ["sed_trainer_CRST.SEDTask4_2021.get_weak_student_f1_seg_macro.compute", "sed_trainer_CRST.SEDTask4_2021.get_weak_teacher_f1_seg_macro.compute", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "sed_trainer_CRST.SEDTask4_2021.hparams[].get", "torch.tensor", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.get_weak_student_f1_seg_macro.reset", "sed_trainer_CRST.SEDTask4_2021.get_weak_teacher_f1_seg_macro.reset", "utils.log_sedeval_metrics", "utils.log_sedeval_metrics", "pandas.DataFrame", "pandas.DataFrame", "sed_trainer_CRST.SEDTask4_2021.item", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.reset", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.reset", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "\"\"\" Fonction applied at the end of all the validation steps of the epoch.\n\n        Args:\n            outputs: torch.Tensor, the concatenation of everything returned by validation_step.\n\n        Returns:\n            torch.Tensor, the objective metric to be used to choose the best model from for example.\n        \"\"\"", "\n", "\n", "weak_student_f1_macro", "=", "self", ".", "get_weak_student_f1_seg_macro", ".", "compute", "(", ")", "\n", "weak_teacher_f1_macro", "=", "self", ".", "get_weak_teacher_f1_seg_macro", ".", "compute", "(", ")", "\n", "\n", "# synth dataset", "\n", "intersection_f1_macro_student", "=", "compute_per_intersection_macro_f1", "(", "\n", "self", ".", "val_buffer_student_synth", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_dur\"", "]", ",", "\n", ")", "\n", "\n", "synth_student_event_macro", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "val_buffer_student_synth", "[", "0.5", "]", ",", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_tsv\"", "]", ",", "\n", ")", "[", "0", "]", "\n", "\n", "intersection_f1_macro_teacher", "=", "compute_per_intersection_macro_f1", "(", "\n", "self", ".", "val_buffer_teacher_synth", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_dur\"", "]", ",", "\n", ")", "\n", "\n", "synth_teacher_event_macro", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "val_buffer_teacher_synth", "[", "0.5", "]", ",", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_tsv\"", "]", ",", "\n", ")", "[", "0", "]", "\n", "\n", "obj_metric_synth_type", "=", "self", ".", "hparams", "[", "\"training\"", "]", ".", "get", "(", "\"obj_metric_synth_type\"", ")", "\n", "if", "obj_metric_synth_type", "is", "None", ":", "\n", "            ", "synth_metric", "=", "intersection_f1_macro_student", "\n", "", "elif", "obj_metric_synth_type", "==", "\"event\"", ":", "\n", "            ", "synth_metric", "=", "synth_student_event_macro", "\n", "", "elif", "obj_metric_synth_type", "==", "\"intersection\"", ":", "\n", "            ", "synth_metric", "=", "intersection_f1_macro_student", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "f\"obj_metric_synth_type: {obj_metric_synth_type} not implemented.\"", "\n", ")", "\n", "\n", "", "obj_metric", "=", "torch", ".", "tensor", "(", "weak_student_f1_macro", ".", "item", "(", ")", "+", "synth_metric", ")", "\n", "\n", "self", ".", "log", "(", "\"val/obj_metric\"", ",", "obj_metric", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"val/weak/student/macro_F1\"", ",", "weak_student_f1_macro", ")", "\n", "self", ".", "log", "(", "\"val/weak/teacher/macro_F1\"", ",", "weak_teacher_f1_macro", ")", "\n", "self", ".", "log", "(", "\n", "\"val/synth/student/intersection_f1_macro\"", ",", "intersection_f1_macro_student", "\n", ")", "\n", "self", ".", "log", "(", "\n", "\"val/synth/teacher/intersection_f1_macro\"", ",", "intersection_f1_macro_teacher", "\n", ")", "\n", "self", ".", "log", "(", "\"val/synth/student/event_f1_macro\"", ",", "synth_student_event_macro", ")", "\n", "self", ".", "log", "(", "\"val/synth/teacher/event_f1_macro\"", ",", "synth_teacher_event_macro", ")", "\n", "\n", "# free the buffers", "\n", "self", ".", "val_buffer_student_synth", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "self", ".", "val_buffer_teacher_synth", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "\n", "self", ".", "get_weak_student_f1_seg_macro", ".", "reset", "(", ")", "\n", "self", ".", "get_weak_teacher_f1_seg_macro", ".", "reset", "(", ")", "\n", "\n", "return", "obj_metric", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_CRST.SEDTask4_2021.on_save_checkpoint": [[658, 664], ["sed_trainer_CRST.SEDTask4_2021.sed_student1.state_dict", "sed_trainer_CRST.SEDTask4_2021.sed_teacher1.state_dict", "sed_trainer_CRST.SEDTask4_2021.sed_student2.state_dict", "sed_trainer_CRST.SEDTask4_2021.sed_teacher2.state_dict"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict"], ["", "def", "on_save_checkpoint", "(", "self", ",", "checkpoint", ")", ":", "\n", "        ", "checkpoint", "[", "\"sed_student1\"", "]", "=", "self", ".", "sed_student1", ".", "state_dict", "(", ")", "\n", "checkpoint", "[", "\"sed_teacher1\"", "]", "=", "self", ".", "sed_teacher1", ".", "state_dict", "(", ")", "\n", "checkpoint", "[", "\"sed_student2\"", "]", "=", "self", ".", "sed_student2", ".", "state_dict", "(", ")", "\n", "checkpoint", "[", "\"sed_teacher2\"", "]", "=", "self", ".", "sed_teacher2", ".", "state_dict", "(", ")", "\n", "return", "checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_CRST.SEDTask4_2021.test_step": [[665, 861], ["sed_trainer_CRST.SEDTask4_2021.mel_spec", "sed_trainer_CRST.SEDTask4_2021.scaler", "sed_trainer_CRST.SEDTask4_2021.sed_student1", "sed_trainer_CRST.SEDTask4_2021.sed_student2", "sed_trainer_CRST.SEDTask4_2021.sed_teacher1", "sed_trainer_CRST.SEDTask4_2021.sed_teacher2", "len", "range", "utils.batched_decode_preds", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_student1.keys", "utils.batched_decode_preds", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_student2.keys", "utils.batched_decode_preds", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_student.keys", "utils.batched_decode_preds", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_teacher1.keys", "utils.batched_decode_preds", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_teacher2.keys", "utils.batched_decode_preds", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_teacher.keys", "utils.batched_decode_preds", "sed_trainer_CRST.SEDTask4_2021.decoded_student1_05_buffer.append", "utils.batched_decode_preds", "sed_trainer_CRST.SEDTask4_2021.decoded_student2_05_buffer.append", "utils.batched_decode_preds", "sed_trainer_CRST.SEDTask4_2021.decoded_student_05_buffer.append", "utils.batched_decode_preds", "sed_trainer_CRST.SEDTask4_2021.decoded_teacher1_05_buffer.append", "utils.batched_decode_preds", "sed_trainer_CRST.SEDTask4_2021.decoded_teacher2_05_buffer.append", "utils.batched_decode_preds", "sed_trainer_CRST.SEDTask4_2021.decoded_teacher_05_buffer.append", "sed_trainer_CRST.SEDTask4_2021.take_log", "os.path.split", "strong_preds_student[].cpu().numpy", "strong_preds_teacher[].cpu().numpy", "numpy.save", "numpy.save", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.supervised_loss", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.log", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_student1[].append", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_student2[].append", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_student[].append", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_teacher1[].append", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_teacher2[].append", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_teacher[].append", "list", "list", "list", "list", "list", "list", "strong_preds_student[].cpu", "strong_preds_teacher[].cpu", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_student1.keys", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_student2.keys", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_student.keys", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_teacher1.keys", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_teacher2.keys", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_teacher.keys"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.take_log", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_indx", ")", ":", "\n", "        ", "\"\"\" Apply Test to a batch (step), used only when (trainer.test is called)\n\n        Args:\n            batch: torch.Tensor, input batch tensor\n            batch_indx: torch.Tensor, 1D tensor of indexes to know which data are present in each batch.\n        Returns:\n        \"\"\"", "\n", "\n", "audio", ",", "labels", ",", "padded_indxs", ",", "filenames", "=", "batch", "\n", "features", "=", "self", ".", "mel_spec", "(", "audio", ")", "\n", "#features2 = self.lin_spec(audio)", "\n", "#features  = torch.cat([features1, features2], 1)", "\n", "\n", "# prediction for student", "\n", "logmels", "=", "self", ".", "scaler", "(", "self", ".", "take_log", "(", "features", ")", ")", "\n", "strong_preds_student1", ",", "weak_preds_student1", "=", "self", ".", "sed_student1", "(", "logmels", ")", "\n", "strong_preds_student2", ",", "weak_preds_student2", "=", "self", ".", "sed_student2", "(", "logmels", ")", "\n", "strong_preds_student", "=", "(", "strong_preds_student1", "+", "strong_preds_student2", ")", "/", "2", "\n", "weak_preds_student", "=", "(", "weak_preds_student1", "+", "weak_preds_student2", ")", "/", "2", "\n", "\n", "# prediction for teacher", "\n", "strong_preds_teacher1", ",", "weak_preds_teacher1", "=", "self", ".", "sed_teacher1", "(", "logmels", ")", "\n", "strong_preds_teacher2", ",", "weak_preds_teacher2", "=", "self", ".", "sed_teacher2", "(", "logmels", ")", "\n", "strong_preds_teacher", "=", "(", "strong_preds_teacher1", "+", "strong_preds_teacher2", ")", "/", "2", "\n", "weak_preds_teacher", "=", "(", "weak_preds_teacher1", "+", "weak_preds_teacher2", ")", "/", "2", "\n", "\n", "\n", "bsz", "=", "len", "(", "filenames", ")", "\n", "for", "bter", "in", "range", "(", "bsz", ")", ":", "\n", "            ", "path", ",", "filename", "=", "os", ".", "path", ".", "split", "(", "filenames", "[", "bter", "]", ")", "\n", "\n", "pred_student", "=", "strong_preds_student", "[", "bter", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "pred_teacher", "=", "strong_preds_teacher", "[", "bter", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "np", ".", "save", "(", "'./Posterior/student/{}.npy'", ".", "format", "(", "filename", ")", ",", "pred_student", ")", "\n", "np", ".", "save", "(", "'./Posterior/teacher/{}.npy'", ".", "format", "(", "filename", ")", ",", "pred_teacher", ")", "\n", "\n", "\n", "", "if", "not", "self", ".", "evaluation", ":", "\n", "            ", "loss_strong_student1", "=", "self", ".", "supervised_loss", "(", "strong_preds_student1", ",", "labels", ")", "\n", "loss_strong_student2", "=", "self", ".", "supervised_loss", "(", "strong_preds_student2", ",", "labels", ")", "\n", "loss_strong_student", "=", "self", ".", "supervised_loss", "(", "strong_preds_student", ",", "labels", ")", "\n", "loss_strong_teacher1", "=", "self", ".", "supervised_loss", "(", "strong_preds_teacher1", ",", "labels", ")", "\n", "loss_strong_teacher2", "=", "self", ".", "supervised_loss", "(", "strong_preds_teacher2", ",", "labels", ")", "\n", "loss_strong_teacher", "=", "self", ".", "supervised_loss", "(", "strong_preds_teacher", ",", "labels", ")", "\n", "\n", "#            self.log(\"test/student1/loss_strong\", loss_strong_student1)", "\n", "#            self.log(\"test/student2/loss_strong\", loss_strong_student2)", "\n", "self", ".", "log", "(", "\"test/student/loss_strong\"", ",", "loss_strong_student", ")", "\n", "#            self.log(\"test/teacher1/loss_strong\", loss_strong_teacher1)", "\n", "#            self.log(\"test/teacher2/loss_strong\", loss_strong_teacher2)", "\n", "self", ".", "log", "(", "\"test/teacher/loss_strong\"", ",", "loss_strong_teacher", ")", "\n", "\n", "# compute psds", "\n", "", "decoded_student1_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_student1", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "test_psds_buffer_student1", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "for", "th", "in", "self", ".", "test_psds_buffer_student1", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "test_psds_buffer_student1", "[", "th", "]", "=", "self", ".", "test_psds_buffer_student1", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_student1_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "\n", "", "decoded_student2_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_student2", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "test_psds_buffer_student2", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "for", "th", "in", "self", ".", "test_psds_buffer_student2", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "test_psds_buffer_student2", "[", "th", "]", "=", "self", ".", "test_psds_buffer_student2", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_student2_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "decoded_student_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_student", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "test_psds_buffer_student", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "for", "th", "in", "self", ".", "test_psds_buffer_student", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "test_psds_buffer_student", "[", "th", "]", "=", "self", ".", "test_psds_buffer_student", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_student_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "\n", "", "decoded_teacher1_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_teacher1", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "test_psds_buffer_teacher1", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "for", "th", "in", "self", ".", "test_psds_buffer_teacher1", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "test_psds_buffer_teacher1", "[", "th", "]", "=", "self", ".", "test_psds_buffer_teacher1", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_teacher1_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "\n", "", "decoded_teacher2_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_teacher2", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "test_psds_buffer_teacher2", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "for", "th", "in", "self", ".", "test_psds_buffer_teacher2", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "test_psds_buffer_teacher2", "[", "th", "]", "=", "self", ".", "test_psds_buffer_teacher2", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_teacher2_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "decoded_teacher_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_teacher", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "test_psds_buffer_teacher", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "for", "th", "in", "self", ".", "test_psds_buffer_teacher", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "test_psds_buffer_teacher", "[", "th", "]", "=", "self", ".", "test_psds_buffer_teacher", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_teacher_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "\n", "# compute f1 score", "\n", "", "decoded_student1_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_student1", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "[", "0.5", "]", ",", "\n", ")", "\n", "self", ".", "decoded_student1_05_buffer", "=", "self", ".", "decoded_student1_05_buffer", ".", "append", "(", "\n", "decoded_student1_strong", "[", "0.5", "]", "\n", ")", "\n", "\n", "decoded_student2_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_student2", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "[", "0.5", "]", ",", "\n", ")", "\n", "self", ".", "decoded_student2_05_buffer", "=", "self", ".", "decoded_student2_05_buffer", ".", "append", "(", "\n", "decoded_student2_strong", "[", "0.5", "]", "\n", ")", "\n", "\n", "decoded_student_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_student", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "[", "0.5", "]", ",", "\n", ")", "\n", "self", ".", "decoded_student_05_buffer", "=", "self", ".", "decoded_student_05_buffer", ".", "append", "(", "\n", "decoded_student_strong", "[", "0.5", "]", "\n", ")", "\n", "\n", "\n", "decoded_teacher1_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_teacher1", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "[", "0.5", "]", ",", "\n", ")", "\n", "self", ".", "decoded_teacher1_05_buffer", "=", "self", ".", "decoded_teacher1_05_buffer", ".", "append", "(", "\n", "decoded_teacher1_strong", "[", "0.5", "]", "\n", ")", "\n", "\n", "decoded_teacher2_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_teacher2", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "[", "0.5", "]", ",", "\n", ")", "\n", "self", ".", "decoded_teacher2_05_buffer", "=", "self", ".", "decoded_teacher2_05_buffer", ".", "append", "(", "\n", "decoded_teacher2_strong", "[", "0.5", "]", "\n", ")", "\n", "\n", "decoded_teacher_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_teacher", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "[", "0.5", "]", ",", "\n", ")", "\n", "self", ".", "decoded_teacher_05_buffer", "=", "self", ".", "decoded_teacher_05_buffer", ".", "append", "(", "\n", "decoded_teacher_strong", "[", "0.5", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_CRST.SEDTask4_2021.on_test_epoch_end": [[865, 1169], ["os.path.join", "os.path.join", "os.makedirs", "sed_trainer_CRST.SEDTask4_2021.decoded_student_05_buffer.to_csv", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_student.keys", "print", "os.path.join", "os.makedirs", "sed_trainer_CRST.SEDTask4_2021.decoded_teacher_05_buffer.to_csv", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_student.keys", "print", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "torch.tensor", "torch.tensor", "torch.tensor", "results.keys", "os.path.join", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_student[].to_csv", "os.path.join", "sed_trainer_CRST.SEDTask4_2021.test_psds_buffer_student[].to_csv", "utils.log_sedeval_metrics", "utils.log_sedeval_metrics", "utils.log_sedeval_metrics", "utils.log_sedeval_metrics", "utils.log_sedeval_metrics", "utils.log_sedeval_metrics", "max", "max", "max", "sed_trainer_CRST.SEDTask4_2021.logger.log_metrics", "sed_trainer_CRST.SEDTask4_2021.logger.log_hyperparams", "sed_trainer_CRST.SEDTask4_2021.log", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics"], ["", "def", "on_test_epoch_end", "(", "self", ")", ":", "\n", "# pub eval dataset", "\n", "        ", "try", ":", "\n", "            ", "log_dir", "=", "self", ".", "logger", ".", "log_dir", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "log_dir", "=", "self", ".", "hparams", "[", "\"log_dir\"", "]", "\n", "", "save_dir", "=", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"metrics_test\"", ")", "\n", "\n", "if", "self", ".", "evaluation", ":", "\n", "# only save the predictions", "\n", "            ", "save_dir_student", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student\"", ")", "\n", "os", ".", "makedirs", "(", "save_dir_student", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "decoded_student_05_buffer", ".", "to_csv", "(", "\n", "os", ".", "path", ".", "join", "(", "save_dir_student", ",", "f\"predictions_05_student.tsv\"", ")", ",", "\n", "sep", "=", "\"\\t\"", ",", "\n", "index", "=", "False", "\n", ")", "\n", "for", "k", "in", "self", ".", "test_psds_buffer_student", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "test_psds_buffer_student", "[", "k", "]", ".", "to_csv", "(", "\n", "os", ".", "path", ".", "join", "(", "save_dir_student", ",", "f\"predictions_th_{k:.2f}.tsv\"", ")", ",", "\n", "sep", "=", "\"\\t\"", ",", "\n", "index", "=", "False", ",", "\n", ")", "\n", "", "print", "(", "f\"\\nPredictions for student saved in: {save_dir_student}\"", ")", "\n", "\n", "save_dir_teacher", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher\"", ")", "\n", "os", ".", "makedirs", "(", "save_dir_teacher", ",", "exist_ok", "=", "True", ")", "\n", "\n", "self", ".", "decoded_teacher_05_buffer", ".", "to_csv", "(", "\n", "os", ".", "path", ".", "join", "(", "save_dir_teacher", ",", "f\"predictions_05_teacher.tsv\"", ")", ",", "\n", "sep", "=", "\"\\t\"", ",", "\n", "index", "=", "False", "\n", ")", "\n", "for", "k", "in", "self", ".", "test_psds_buffer_student", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "test_psds_buffer_student", "[", "k", "]", ".", "to_csv", "(", "\n", "os", ".", "path", ".", "join", "(", "save_dir_teacher", ",", "f\"predictions_th_{k:.2f}.tsv\"", ")", ",", "\n", "sep", "=", "\"\\t\"", ",", "\n", "index", "=", "False", ",", "\n", ")", "\n", "", "print", "(", "f\"\\nPredictions for teacher saved in: {save_dir_teacher}\"", ")", "\n", "\n", "", "else", ":", "\n", "# calculate the metrics", "\n", "            ", "psds_score_student1_scenario1", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_student1", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.7", ",", "\n", "gtc_threshold", "=", "0.7", ",", "\n", "alpha_ct", "=", "0", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student1\"", ",", "\"scenario1\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_student1_scenario2", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_student1", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.1", ",", "\n", "gtc_threshold", "=", "0.1", ",", "\n", "cttc_threshold", "=", "0.3", ",", "\n", "alpha_ct", "=", "0.5", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student1\"", ",", "\"scenario2\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_student2_scenario1", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_student2", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.7", ",", "\n", "gtc_threshold", "=", "0.7", ",", "\n", "alpha_ct", "=", "0", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student2\"", ",", "\"scenario1\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_student2_scenario2", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_student2", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.1", ",", "\n", "gtc_threshold", "=", "0.1", ",", "\n", "cttc_threshold", "=", "0.3", ",", "\n", "alpha_ct", "=", "0.5", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student2\"", ",", "\"scenario2\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_student_scenario1", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_student", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.7", ",", "\n", "gtc_threshold", "=", "0.7", ",", "\n", "alpha_ct", "=", "0", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student\"", ",", "\"scenario1\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_student_scenario2", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_student", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.1", ",", "\n", "gtc_threshold", "=", "0.1", ",", "\n", "cttc_threshold", "=", "0.3", ",", "\n", "alpha_ct", "=", "0.5", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student\"", ",", "\"scenario2\"", ")", ",", "\n", ")", "\n", "\n", "\n", "psds_score_teacher1_scenario1", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_teacher1", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.7", ",", "\n", "gtc_threshold", "=", "0.7", ",", "\n", "alpha_ct", "=", "0", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher1\"", ",", "\"scenario1\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_teacher1_scenario2", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_teacher1", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.1", ",", "\n", "gtc_threshold", "=", "0.1", ",", "\n", "cttc_threshold", "=", "0.3", ",", "\n", "alpha_ct", "=", "0.5", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher1\"", ",", "\"scenario2\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_teacher2_scenario1", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_teacher2", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.7", ",", "\n", "gtc_threshold", "=", "0.7", ",", "\n", "alpha_ct", "=", "0", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher2\"", ",", "\"scenario1\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_teacher2_scenario2", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_teacher2", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.1", ",", "\n", "gtc_threshold", "=", "0.1", ",", "\n", "cttc_threshold", "=", "0.3", ",", "\n", "alpha_ct", "=", "0.5", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher2\"", ",", "\"scenario2\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_teacher_scenario1", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_teacher", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.7", ",", "\n", "gtc_threshold", "=", "0.7", ",", "\n", "alpha_ct", "=", "0", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher\"", ",", "\"scenario1\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_teacher_scenario2", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_teacher", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.1", ",", "\n", "gtc_threshold", "=", "0.1", ",", "\n", "cttc_threshold", "=", "0.3", ",", "\n", "alpha_ct", "=", "0.5", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher\"", ",", "\"scenario2\"", ")", ",", "\n", ")", "\n", "\n", "\n", "\n", "event_macro_student1", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "decoded_student1_05_buffer", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student1\"", ")", ",", "\n", ")", "[", "0", "]", "\n", "\n", "event_macro_student2", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "decoded_student2_05_buffer", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student2\"", ")", ",", "\n", ")", "[", "0", "]", "\n", "\n", "event_macro_student", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "decoded_student_05_buffer", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student\"", ")", ",", "\n", ")", "[", "0", "]", "\n", "\n", "\n", "event_macro_teacher1", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "decoded_teacher1_05_buffer", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher1\"", ")", ",", "\n", ")", "[", "0", "]", "\n", "\n", "event_macro_teacher2", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "decoded_teacher2_05_buffer", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher2\"", ")", ",", "\n", ")", "[", "0", "]", "\n", "\n", "event_macro_teacher", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "decoded_teacher_05_buffer", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher\"", ")", ",", "\n", ")", "[", "0", "]", "\n", "\n", "\n", "# synth dataset", "\n", "intersection_f1_macro_student1", "=", "compute_per_intersection_macro_f1", "(", "\n", "{", "\"0.5\"", ":", "self", ".", "decoded_student1_05_buffer", "}", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", ")", "\n", "\n", "# synth dataset", "\n", "intersection_f1_macro_teacher1", "=", "compute_per_intersection_macro_f1", "(", "\n", "{", "\"0.5\"", ":", "self", ".", "decoded_teacher1_05_buffer", "}", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", ")", "\n", "\n", "# synth dataset", "\n", "intersection_f1_macro_student2", "=", "compute_per_intersection_macro_f1", "(", "\n", "{", "\"0.5\"", ":", "self", ".", "decoded_student2_05_buffer", "}", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", ")", "\n", "\n", "# synth dataset", "\n", "intersection_f1_macro_teacher2", "=", "compute_per_intersection_macro_f1", "(", "\n", "{", "\"0.5\"", ":", "self", ".", "decoded_teacher2_05_buffer", "}", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", ")", "\n", "\n", "# synth dataset", "\n", "intersection_f1_macro_student", "=", "compute_per_intersection_macro_f1", "(", "\n", "{", "\"0.5\"", ":", "self", ".", "decoded_student_05_buffer", "}", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", ")", "\n", "\n", "# synth dataset", "\n", "intersection_f1_macro_teacher", "=", "compute_per_intersection_macro_f1", "(", "\n", "{", "\"0.5\"", ":", "self", ".", "decoded_teacher_05_buffer", "}", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", ")", "\n", "\n", "\n", "best_test_result1", "=", "torch", ".", "tensor", "(", "max", "(", "psds_score_student1_scenario1", ",", "psds_score_student1_scenario2", ")", ")", "\n", "best_test_result2", "=", "torch", ".", "tensor", "(", "max", "(", "psds_score_student2_scenario1", ",", "psds_score_student2_scenario2", ")", ")", "\n", "best_test_result", "=", "torch", ".", "tensor", "(", "max", "(", "psds_score_student_scenario1", ",", "psds_score_student_scenario2", ")", ")", "\n", "\n", "results", "=", "{", "\n", "\"hp_metric\"", ":", "best_test_result", ",", "\n", "\"test/student/psds_score_scenario1\"", ":", "psds_score_student_scenario1", ",", "\n", "\"test/student/psds_score_scenario2\"", ":", "psds_score_student_scenario2", ",", "\n", "\"test/teacher/psds_score_scenario1\"", ":", "psds_score_teacher_scenario1", ",", "\n", "\"test/teacher/psds_score_scenario2\"", ":", "psds_score_teacher_scenario2", ",", "\n", "\"test/student/event_f1_macro\"", ":", "event_macro_student", ",", "\n", "\"test/student/intersection_f1_macro\"", ":", "intersection_f1_macro_student", ",", "\n", "\"test/teacher/event_f1_macro\"", ":", "event_macro_teacher", ",", "\n", "\"test/teacher/intersection_f1_macro\"", ":", "intersection_f1_macro_teacher", ",", "\n", "#\"hp_metric_I\": best_test_result1,", "\n", "#\"test/student1/psds_score_scenario1\": psds_score_student1_scenario1,", "\n", "#\"test/student1/psds_score_scenario2\": psds_score_student1_scenario2,", "\n", "#\"test/teacher1/psds_score_scenario1\": psds_score_teacher1_scenario1,", "\n", "#\"test/teacher1/psds_score_scenario2\": psds_score_teacher1_scenario2,", "\n", "#\"test/student1/event_f1_macro\": event_macro_student1,", "\n", "#\"test/student1/intersection_f1_macro\": intersection_f1_macro_student1,", "\n", "#\"test/teacher1/event_f1_macro\": event_macro_teacher1,", "\n", "#\"test/teacher1/intersection_f1_macro\": intersection_f1_macro_teacher1,", "\n", "#\"hp_metric_II\": best_test_result2,", "\n", "#\"test/student2/psds_score_scenario1\": psds_score_student2_scenario1,", "\n", "#\"test/student2/psds_score_scenario2\": psds_score_student2_scenario2,", "\n", "#\"test/teacher2/psds_score_scenario1\": psds_score_teacher2_scenario1,", "\n", "#\"test/teacher2/psds_score_scenario2\": psds_score_teacher2_scenario2,", "\n", "#\"test/student2/event_f1_macro\": event_macro_student2,", "\n", "#\"test/student2/intersection_f1_macro\": intersection_f1_macro_student2,", "\n", "#\"test/teacher2/event_f1_macro\": event_macro_teacher2,", "\n", "#\"test/teacher2/intersection_f1_macro\": intersection_f1_macro_teacher2,", "\n", "}", "\n", "if", "self", ".", "logger", "is", "not", "None", ":", "\n", "                ", "self", ".", "logger", ".", "log_metrics", "(", "results", ")", "\n", "self", ".", "logger", ".", "log_hyperparams", "(", "self", ".", "hparams", ",", "results", ")", "\n", "\n", "", "for", "key", "in", "results", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "log", "(", "key", ",", "results", "[", "key", "]", ",", "prog_bar", "=", "True", ",", "logger", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_CRST.SEDTask4_2021.configure_optimizers": [[1170, 1172], ["None"], "methods", ["None"], ["", "", "", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "opt1", ",", "self", ".", "opt2", "]", ",", "[", "self", ".", "scheduler1", ",", "self", ".", "scheduler2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_CRST.SEDTask4_2021.train_dataloader": [[1173, 1182], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "train_data", ",", "\n", "batch_sampler", "=", "self", ".", "train_sampler", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", ")", "\n", "\n", "return", "self", ".", "train_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_CRST.SEDTask4_2021.val_dataloader": [[1183, 1192], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "self", ".", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "valid_data", ",", "\n", "batch_size", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"batch_size_val\"", "]", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "shuffle", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "\n", ")", "\n", "return", "self", ".", "val_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_CRST.SEDTask4_2021.test_dataloader": [[1193, 1202], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "self", ".", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "test_data", ",", "\n", "batch_size", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"batch_size_val\"", "]", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "shuffle", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "\n", ")", "\n", "return", "self", ".", "test_loader", "\n", "", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.LinearSpectrogram.__init__": [[12, 25], ["torch.Module.__init__", "torchaudio.transforms.Spectrogram", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "range", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["\t", "def", "__init__", "(", "self", ",", "nCh", "=", "128", ",", "n_fft", "=", "2048", ",", "hop_length", "=", "256", ",", "win_fn", "=", "torch", ".", "hamming_window", ")", ":", "\n", "\t\t", "super", "(", "LinearSpectrogram", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "spec", "=", "Spectrogram", "(", "n_fft", "=", "n_fft", ",", "hop_length", "=", "hop_length", ",", "window_fn", "=", "win_fn", ")", "\n", "self", ".", "nCh", "=", "nCh", "\n", "\n", "nbin", "=", "n_fft", "//", "2", "\n", "fbin", "=", "nbin", "//", "nCh", "\n", "linfilt", "=", "torch", ".", "zeros", "(", "[", "nbin", ",", "nCh", "]", ")", ".", "cuda", "(", ")", "\n", "for", "ch", "in", "range", "(", "nCh", ")", ":", "\n", "\t\t\t", "stridx", "=", "ch", "*", "fbin", "\n", "endidx", "=", "ch", "*", "fbin", "+", "fbin", "\n", "linfilt", "[", "stridx", ":", "endidx", ",", "ch", "]", "=", "1.0", "\n", "", "self", ".", "lfilter", "=", "linfilt", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.LinearSpectrogram.forward": [[26, 33], ["utilities.LinearSpectrogram.spec", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul.permute", "torch.matmul.permute", "utilities.LinearSpectrogram.size", "utilities.LinearSpectrogram.size", "utilities.LinearSpectrogram.size", "utilities.LinearSpectrogram.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "wavData", ")", ":", "\n", "\t\t", "specData", "=", "self", ".", "spec", "(", "wavData", ")", "\n", "bs", ",", "nfrq", ",", "nfrm", "=", "specData", ".", "size", "(", "0", ")", ",", "specData", ".", "size", "(", "1", ")", ",", "specData", ".", "size", "(", "2", ")", "\n", "specData", "=", "specData", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "\n", "out", "=", "torch", ".", "matmul", "(", "specData", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ",", "self", ".", "lfilter", ")", "\n", "return", "out", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.AuditorySpectrogram.__init__": [[36, 74], ["torch.Module.__init__", "scipy.io.loadmat", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "range", "len", "torch.exp().cuda", "torch.exp().cuda", "torch.exp().cuda", "torch.exp().cuda", "torch.exp().cuda", "torch.exp().cuda", "torch.exp().cuda", "torch.exp().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.real().to", "torch.real().to", "torch.real().to", "torch.real().to", "B.append", "A.append", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.real().to", "torch.real().to", "torch.real().to", "torch.real().to", "torch.imag().to", "torch.imag().to", "torch.imag().to", "torch.imag().to", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.real", "torch.real", "torch.real", "torch.real", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.real", "torch.real", "torch.real", "torch.real", "torch.imag", "torch.imag", "torch.imag", "torch.imag", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["\t", "def", "__init__", "(", "self", ",", "frmRate", "=", "16", ",", "tc", "=", "8", ",", "fac", "=", "1", ",", "shft", "=", "0", ")", ":", "\n", "\t\t", "super", "(", "AuditorySpectrogram", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "frmRate", "=", "frmRate", "\n", "self", ".", "tc", "=", "tc", "\n", "self", ".", "fac", "=", "fac", "\n", "self", ".", "shft", "=", "shft", "\n", "self", ".", "haircell_tc", "=", "0.5", "\n", "\n", "cochlear", "=", "loadmat", "(", "'./aud24.mat'", ")", "\n", "cochba", "=", "torch", ".", "from_numpy", "(", "cochlear", "[", "'COCHBA'", "]", ")", ".", "cuda", "(", ")", "\n", "\n", "L", ",", "M", "=", "cochba", ".", "shape", "\n", "self", ".", "L", "=", "L", "\n", "self", ".", "M", "=", "M", "\n", "\n", "A", "=", "[", "]", "\n", "B", "=", "[", "]", "\n", "for", "ch", "in", "range", "(", "M", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "\t\t\t", "p", "=", "torch", ".", "real", "(", "cochba", "[", "0", ",", "ch", "]", ")", ".", "to", "(", "torch", ".", "long", ")", "\n", "B", ".", "append", "(", "torch", ".", "real", "(", "cochba", "[", "1", ":", "p", "+", "2", ",", "ch", "]", ")", ".", "to", "(", "torch", ".", "float", ")", ")", "\n", "A", ".", "append", "(", "torch", ".", "imag", "(", "cochba", "[", "1", ":", "p", "+", "2", ",", "ch", "]", ")", ".", "to", "(", "torch", ".", "float", ")", ")", "\n", "\n", "", "self", ".", "A", "=", "A", "\n", "self", ".", "B", "=", "B", "\n", "self", ".", "nCh", "=", "len", "(", "A", ")", "\n", "\n", "alpha", "=", "torch", ".", "exp", "(", "torch", ".", "tensor", "(", "-", "1", "/", "(", "tc", "*", "2", "**", "(", "4", "+", "shft", ")", ")", ")", ")", ".", "cuda", "(", ")", "\n", "beta", "=", "torch", ".", "exp", "(", "torch", ".", "tensor", "(", "-", "1", "/", "(", "self", ".", "haircell_tc", "*", "2", "**", "(", "4", "+", "shft", ")", ")", ")", ")", ".", "cuda", "(", ")", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "L_frm", "=", "torch", ".", "tensor", "(", "frmRate", "*", "2", "**", "(", "4", "+", "shft", ")", ")", ".", "cuda", "(", ")", "\n", "\n", "# hair-cell membrane", "\n", "self", ".", "hair_a", "=", "torch", ".", "tensor", "(", "[", "1", ",", "-", "beta", "]", ")", ".", "cuda", "(", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "self", ".", "hair_b", "=", "torch", ".", "tensor", "(", "[", "1", ",", "0", "]", ")", ".", "cuda", "(", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "\n", "# temporal integration", "\n", "self", ".", "temp_a", "=", "torch", ".", "tensor", "(", "[", "1", ",", "-", "alpha", "]", ")", ".", "cuda", "(", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "self", ".", "temp_b", "=", "torch", ".", "tensor", "(", "[", "1", ",", "0", "]", ")", ".", "cuda", "(", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.AuditorySpectrogram.forward": [[76, 128], ["torchaudio.functional.lfilter", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack.permute", "torch.stack.permute", "wavData.size", "wavData.size", "torchaudio.functional.lfilter", "torchaudio.functional.lfilter", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.maximum", "torch.maximum", "torch.maximum", "torch.maximum", "torchaudio.functional.lfilter", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torchaudio.functional.lfilter", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["", "def", "forward", "(", "self", ",", "wavData", ")", ":", "\n", "\t\t", "bs", ",", "wavLeng", "=", "wavData", ".", "size", "(", "0", ")", ",", "wavData", ".", "size", "(", "1", ")", "\n", "\n", "y1", "=", "lfilter", "(", "wavData", ",", "self", ".", "A", "[", "0", "]", ",", "self", ".", "B", "[", "0", "]", ")", "\n", "y2", "=", "torch", ".", "sigmoid", "(", "y1", "*", "self", ".", "fac", ")", "\n", "\n", "# hair cell membrane (low-pass <= 4kHz)", "\n", "if", "not", "self", ".", "fac", "==", "-", "2", ":", "\n", "\t\t\t", "y2", "=", "lfilter", "(", "y2", ",", "self", ".", "hair_a", ",", "self", ".", "hair_b", ")", "\n", "\n", "", "y2_h", "=", "y2", "\n", "y3_h", "=", "0", "\n", "\n", "#####################################################", "\n", "# All other channels", "\n", "#####################################################", "\n", "audData", "=", "[", "]", "\n", "for", "ch", "in", "range", "(", "self", ".", "nCh", ")", ":", "\n", "\t\t\t", "y1", "=", "lfilter", "(", "wavData", ",", "self", ".", "A", "[", "ch", "]", ",", "self", ".", "B", "[", "ch", "]", ")", "\n", "\n", "########################################", "\n", "# TRANSDUCTION: hair cells", "\n", "########################################", "\n", "# Fluid cillia coupling (preemphasis) (ignored)", "\n", "# ionic channels (sigmoid function)", "\n", "y2", "=", "torch", ".", "sigmoid", "(", "y1", "*", "self", ".", "fac", ")", "\n", "\n", "# hair cell membrane (low-pass <= 4 kHz) ---> y2 (ignored for linear)", "\n", "if", "not", "self", ".", "fac", "==", "-", "2", ":", "\n", "\t\t\t\t", "y2", "=", "lfilter", "(", "y2", ",", "self", ".", "hair_a", ",", "self", ".", "hair_b", ")", "\n", "\n", "########################################", "\n", "# REDUCTION: lateral inhibitory network", "\n", "########################################", "\n", "# masked by higher (frequency) spatial response", "\n", "", "y3", "=", "y2", "-", "y2_h", "\n", "y2_h", "=", "y2", "\n", "\n", "# half-wave rectifier ---> y4", "\n", "y4", "=", "torch", ".", "maximum", "(", "torch", ".", "tensor", "(", "0", ")", ".", "cuda", "(", ")", ",", "y3", ")", "\n", "\n", "# temporal integration window ---> y5", "\n", "if", "self", ".", "alpha", ":", "# leaky integration", "\n", "\t\t\t\t", "y5", "=", "lfilter", "(", "y4", ",", "self", ".", "temp_a", ",", "self", ".", "temp_b", ")", "\n", "audData", ".", "append", "(", "y5", "[", ":", ",", "0", ":", "-", "1", ":", "self", ".", "L_frm", "]", ")", "\n", "", "else", ":", "# short-term average", "\n", "\t\t\t\t", "if", "L_frm", "==", "1", ":", "\n", "\t\t\t\t\t", "audData", ".", "append", "(", "y4", ")", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "audData", ".", "append", "(", "torch", ".", "mean", "(", "torch", ".", "reshape", "(", "y4", ",", "[", "self", ".", "L_frm", ",", "self", ".", "N", "]", ")", ",", "0", ")", ")", "\n", "", "", "", "audData", "=", "torch", ".", "stack", "(", "audData", ",", "2", ")", "\n", "return", "audData", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.audioread": [[130, 135], ["scipy.io.wavfile.read", "numpy.amax", "abs"], "function", ["None"], ["", "", "def", "audioread", "(", "audioPath", ")", ":", "\n", "\t", "FS", ",", "wavData", "=", "wavfile", ".", "read", "(", "audioPath", ")", "\n", "maxV", "=", "np", ".", "amax", "(", "abs", "(", "wavData", ")", ")", "\n", "wavData", "=", "wavData", "/", "maxV", "\n", "return", "wavData", ",", "FS", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.wav2aud": [[136, 234], ["scipy.io.loadmat", "torch.from_numpy().cuda", "torch.from_numpy().cuda", "torch.exp().cuda", "torch.exp().cuda", "torch.exp().cuda", "torch.exp().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "range", "torch.cat().permute", "torch.cat().permute", "len", "torch.ceil().to().cuda", "torch.ceil().to().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.real().to", "torch.real().to", "torch.real().to", "torch.real().to", "torch.imag().to", "torch.imag().to", "torchaudio.functional.lfilter", "torch.sigmoid", "torch.sigmoid", "range", "torch.from_numpy", "torch.from_numpy", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.tensor", "torch.tensor", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torchaudio.functional.lfilter", "torch.real().to", "torch.real().to", "torch.real().to", "torch.real().to", "torch.imag().to", "torch.imag().to", "torchaudio.functional.lfilter", "torch.sigmoid", "torch.sigmoid", "torch.maximum", "torch.maximum", "torch.cat().permute.append", "torch.cat", "torch.cat", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.ceil().to", "torch.ceil().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.real", "torch.real", "torch.real", "torch.real", "torch.imag", "torch.imag", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torchaudio.functional.lfilter", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torch.tensor().cuda().to", "torchaudio.functional.lfilter", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.real", "torch.real", "torch.real", "torch.real", "torch.imag", "torch.imag", "torch.mean", "torch.mean", "torch.ceil", "torch.ceil", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor", "torch.tensor", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.reshape", "torch.reshape", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["", "def", "wav2aud", "(", "batchWave", ",", "frmLeng", ",", "tc", ",", "fac", ",", "shft", ")", ":", "\n", "\t", "nbatch", "=", "batchWave", ".", "shape", "[", "0", "]", "\n", "\n", "# define parameters and load cochlear filter", "\n", "cochlear", "=", "loadmat", "(", "'./aud24.mat'", ")", "\n", "COCHBA", "=", "torch", ".", "from_numpy", "(", "cochlear", "[", "'COCHBA'", "]", ")", ".", "cuda", "(", ")", "\n", "L", ",", "M", "=", "COCHBA", ".", "shape", "\n", "haircell_tc", "=", "0.5", "\n", "\n", "alpha", "=", "torch", ".", "exp", "(", "torch", ".", "tensor", "(", "-", "1", "/", "(", "tc", "*", "2", "**", "(", "4", "+", "shft", ")", ")", ")", ")", ".", "cuda", "(", ")", "\n", "beta", "=", "torch", ".", "exp", "(", "torch", ".", "tensor", "(", "-", "1", "/", "(", "haircell_tc", "*", "2", "**", "(", "4", "+", "shft", ")", ")", ")", ")", ".", "cuda", "(", ")", "\n", "L_frm", "=", "torch", ".", "tensor", "(", "frmLeng", "*", "2", "**", "(", "4", "+", "shft", ")", ")", ".", "cuda", "(", ")", "\n", "\n", "batchAud", "=", "[", "]", "\n", "for", "bter", "in", "range", "(", "nbatch", ")", ":", "\n", "\t\t", "wavData", "=", "batchWave", "[", "bter", "]", "\n", "\n", "L_x", "=", "len", "(", "wavData", ")", "\n", "N", "=", "torch", ".", "ceil", "(", "L_x", "/", "L_frm", ")", ".", "to", "(", "torch", ".", "long", ")", ".", "cuda", "(", ")", "\n", "buff", "=", "torch", ".", "zeros", "(", "[", "N", "*", "L_frm", "]", ")", ".", "cuda", "(", ")", "\n", "buff", "[", ":", "L_x", "]", "=", "wavData", "\n", "wavData", "=", "buff", "\n", "\n", "# initialize output", "\n", "audData", "=", "torch", ".", "zeros", "(", "[", "N", ",", "M", "-", "1", "]", ")", ".", "cuda", "(", ")", "\n", "\n", "#####################################################", "\n", "# Last channel (highest frequency)", "\n", "#####################################################", "\n", "p", "=", "torch", ".", "real", "(", "COCHBA", "[", "0", ",", "M", "-", "1", "]", ")", ".", "to", "(", "torch", ".", "long", ")", "\n", "B", "=", "torch", ".", "real", "(", "COCHBA", "[", "1", ":", "p", "+", "2", ",", "M", "-", "1", "]", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "A", "=", "torch", ".", "imag", "(", "COCHBA", "[", "1", ":", "p", "+", "2", ",", "M", "-", "1", "]", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "y1", "=", "lfilter", "(", "wavData", ",", "A", ",", "B", ")", "\n", "y2", "=", "torch", ".", "sigmoid", "(", "y1", "*", "fac", ")", "\n", "\n", "# hair cell membrane (low-pass <= 4kHz)", "\n", "if", "not", "fac", "==", "-", "2", ":", "\n", "\t\t\t", "b", "=", "torch", ".", "tensor", "(", "[", "1", ",", "0", "]", ")", ".", "cuda", "(", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "a", "=", "torch", ".", "tensor", "(", "[", "1", ",", "-", "beta", "]", ")", ".", "cuda", "(", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "y2", "=", "lfilter", "(", "y2", ",", "a", ",", "b", ")", "\n", "\n", "", "y2_h", "=", "y2", "\n", "y3_h", "=", "0", "\n", "\n", "#####################################################", "\n", "# All other channels", "\n", "#####################################################", "\n", "for", "ch", "in", "range", "(", "M", "-", "2", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "########################################", "\n", "# ANALYSIS: cochlear filterbank", "\n", "########################################", "\n", "# (IIR) filter bank convolution ---> y1", "\n", "\t\t\t", "p", "=", "torch", ".", "real", "(", "COCHBA", "[", "0", ",", "ch", "]", ")", ".", "to", "(", "torch", ".", "long", ")", "\n", "B", "=", "torch", ".", "real", "(", "COCHBA", "[", "1", ":", "p", "+", "2", ",", "ch", "]", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "A", "=", "torch", ".", "imag", "(", "COCHBA", "[", "1", ":", "p", "+", "2", ",", "ch", "]", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "y1", "=", "lfilter", "(", "wavData", ",", "A", ",", "B", ")", "\n", "\n", "########################################", "\n", "# TRANSDUCTION: hair cells", "\n", "########################################", "\n", "# Fluid cillia coupling (preemphasis) (ignored)", "\n", "# ionic channels (sigmoid function)", "\n", "y2", "=", "torch", ".", "sigmoid", "(", "y1", "*", "fac", ")", "\n", "\n", "# hair cell membrane (low-pass <= 4 kHz) ---> y2 (ignored for linear)", "\n", "if", "not", "fac", "==", "-", "2", ":", "\n", "\t\t\t\t", "b", "=", "torch", ".", "tensor", "(", "[", "1", ",", "0", "]", ")", ".", "cuda", "(", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "a", "=", "torch", ".", "tensor", "(", "[", "1", ",", "-", "beta", "]", ")", ".", "cuda", "(", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "y2", "=", "lfilter", "(", "y2", ",", "a", ",", "b", ")", "\n", "\n", "########################################", "\n", "# REDUCTION: lateral inhibitory network", "\n", "########################################", "\n", "# masked by higher (frequency) spatial response", "\n", "", "y3", "=", "y2", "-", "y2_h", "\n", "y2_h", "=", "y2", "\n", "\n", "# half-wave rectifier ---> y4", "\n", "y4", "=", "torch", ".", "maximum", "(", "torch", ".", "tensor", "(", "0", ")", ".", "cuda", "(", ")", ",", "y3", ")", "\n", "\n", "# temporal integration window ---> y5", "\n", "if", "alpha", ":", "# leaky integration", "\n", "\t\t\t\t", "b", "=", "torch", ".", "tensor", "(", "[", "1", ",", "0", "]", ")", ".", "cuda", "(", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "a", "=", "torch", ".", "tensor", "(", "[", "1", ",", "-", "alpha", "]", ")", ".", "cuda", "(", ")", ".", "to", "(", "torch", ".", "float", ")", "\n", "\n", "y5", "=", "lfilter", "(", "y4", ",", "a", ",", "b", ")", "\n", "audData", "[", ":", ",", "ch", "]", "=", "y5", "[", "0", ":", "-", "1", ":", "L_frm", "]", "\n", "", "else", ":", "# short-term average", "\n", "\t\t\t\t", "if", "L_frm", "==", "1", ":", "\n", "\t\t\t\t\t", "audData", "[", ":", ",", "ch", "]", "=", "y4", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "audData", "[", ":", ",", "ch", "]", "=", "torch", ".", "mean", "(", "torch", ".", "reshape", "(", "y4", ",", "[", "L_frm", ",", "N", "]", ")", ",", "0", ")", "\n", "\n", "", "", "batchAud", ".", "append", "(", "audData", ")", "\n", "\n", "", "", "batchAud", "=", "torch", ".", "cat", "(", "batchAud", ",", "0", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "\n", "return", "batchAud", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.sigmoid": [[235, 238], ["numpy.exp"], "function", ["None"], ["", "def", "sigmoid", "(", "x", ",", "a", ")", ":", "\n", "\t", "x", "=", "np", ".", "exp", "(", "-", "x", "/", "a", ")", "\n", "return", "1", "/", "(", "1", "+", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.DataNormalization": [[240, 254], ["numpy.zeros", "numpy.mean", "numpy.std", "range", "range"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.std"], ["", "def", "DataNormalization", "(", "target", ",", "meanV", "=", "None", ",", "stdV", "=", "None", ")", ":", "\n", "\t", "nData", ",", "nDim", "=", "target", ".", "shape", "[", "0", "]", ",", "target", ".", "shape", "[", "1", "]", "\n", "\n", "output", "=", "np", ".", "zeros", "(", "shape", "=", "[", "nData", ",", "nDim", "]", ",", "dtype", "=", "float", ")", "\n", "if", "meanV", "is", "None", ":", "\n", "\t\t", "meanV", "=", "np", ".", "mean", "(", "target", ",", "axis", "=", "0", ")", "\n", "stdV", "=", "np", ".", "std", "(", "target", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "for", "dter", "in", "range", "(", "nData", ")", ":", "\n", "\t\t\t", "output", "[", "dter", ",", ":", "nDim", "]", "=", "(", "target", "[", "dter", ",", ":", "nDim", "]", "-", "meanV", ")", "/", "stdV", "\n", "", "", "else", ":", "\n", "\t\t", "for", "dter", "in", "range", "(", "nData", ")", ":", "\n", "\t\t\t", "output", "[", "dter", ",", ":", "nDim", "]", "=", "(", "target", "[", "dter", ",", ":", "nDim", "]", "-", "meanV", ")", "/", "stdV", "\n", "\n", "", "", "return", "output", ",", "meanV", ",", "stdV", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.DataRegularization": [[256, 267], ["range", "range", "numpy.amax", "numpy.amin", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["", "def", "DataRegularization", "(", "target", ")", ":", "\n", "\t", "nData", ",", "nSeq", "=", "target", ".", "shape", "[", "0", "]", ",", "target", ".", "shape", "[", "1", "]", "\n", "for", "dter", "in", "range", "(", "nData", ")", ":", "\n", "\t\t", "for", "ster", "in", "range", "(", "nSeq", ")", ":", "\n", "\t\t\t", "temp", "=", "target", "[", "dter", ",", "ster", "]", "\n", "maxV", "=", "np", ".", "amax", "(", "temp", ")", "\n", "minV", "=", "np", ".", "amin", "(", "temp", ")", "\n", "reg_temp", "=", "2", "*", "(", "temp", "-", "minV", ")", "/", "(", "maxV", "-", "minV", ")", "\n", "target", "[", "dter", ",", "ster", "]", "=", "reg_temp", "-", "np", ".", "mean", "(", "reg_temp", ")", "\n", "\n", "", "", "return", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.weights_init": [[269, 289], ["classname.find", "torch.init.xavier_uniform_", "m.bias.data.fill_", "classname.find", "m.weight.data.normal_", "m.bias.data.fill_", "numpy.sqrt", "classname.find", "m.parameters", "classname.find", "m.weight.data.normal_", "m.bias.data.zero_", "len", "torch.init.orthogonal_", "weight.size"], "function", ["None"], ["", "def", "weights_init", "(", "m", ")", ":", "\n", "    ", "\"\"\" Initialize the weights of some layers of neural networks, here Conv2D, BatchNorm, GRU, Linear\n        Based on the work of Xavier Glorot\n    Args:\n        m: the model to initialize\n    \"\"\"", "\n", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Conv2d'", ")", "!=", "-", "1", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ",", "gain", "=", "np", ".", "sqrt", "(", "2", ")", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "elif", "classname", ".", "find", "(", "'BatchNorm'", ")", "!=", "-", "1", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "1.0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "elif", "classname", ".", "find", "(", "'GRU'", ")", "!=", "-", "1", ":", "\n", "        ", "for", "weight", "in", "m", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "len", "(", "weight", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "nn", ".", "init", ".", "orthogonal_", "(", "weight", ".", "data", ")", "\n", "", "", "", "elif", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.01", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utilities.calc_error": [[290, 340], ["list", "list", "samples.permute.permute", "labels.permute().cpu().numpy.permute().cpu().numpy", "numpy.arange", "numpy.delete", "list", "range", "samples.permute.size", "labels.permute().cpu().numpy.size", "numpy.where", "v.size", "numpy.arange", "numpy.roll", "torch.mul().sum", "torch.mul().sum", "torch.mul().sum", "torch.mul().sum", "torch.div", "torch.div", "torch.div", "torch.div", "torch.norm().mean", "torch.norm().mean", "range", "labels.permute().cpu().numpy.permute().cpu", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.mul", "torch.mul", "numpy.arange", "numpy.delete", "torch.norm", "torch.norm", "torch.div", "torch.div", "vecs[].permute", "inners.mean", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.norm", "torch.norm", "numpy.where", "torch.matmul", "torch.matmul", "labels.permute().cpu().numpy.permute"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["", "", "def", "calc_error", "(", "samples", ",", "labels", ")", ":", "\n", "\t", "batch_size", ",", "nSnaps", ",", "nDim", "=", "list", "(", "samples", ".", "size", "(", ")", ")", "\n", "_", ",", "_", ",", "nClass", "=", "list", "(", "labels", ".", "size", "(", ")", ")", "\n", "samples", "=", "samples", ".", "permute", "(", "1", ",", "0", ",", "2", ")", "\n", "labels", "=", "labels", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "cidx", "=", "np", ".", "where", "(", "labels", "[", "0", "]", ")", "[", "1", "]", "\n", "\n", "idx", "=", "np", ".", "arange", "(", "nSnaps", ")", "\n", "idx", "=", "np", ".", "delete", "(", "idx", ",", "0", ")", "\n", "v0", "=", "samples", "[", "0", "]", "\n", "v1", "=", "samples", "[", "idx", "]", "\n", "v", "=", "v1", "-", "v0", "\n", "\n", "nVec", ",", "batch_size", ",", "nDim", "=", "list", "(", "v", ".", "size", "(", ")", ")", "\n", "error", "=", "None", "\n", "for", "iter", "in", "range", "(", "nVec", ")", ":", "\n", "\t\t", "idx", "=", "np", ".", "arange", "(", "nVec", ")", "\n", "idx", "=", "np", ".", "roll", "(", "idx", ",", "iter", ")", "\n", "\n", "v1_norm", "=", "torch", ".", "norm", "(", "v", "[", "idx", "[", "1", "]", "]", ",", "dim", "=", "1", ")", "**", "2", "\n", "v2_norm", "=", "torch", ".", "norm", "(", "v", "[", "idx", "[", "2", "]", "]", ",", "dim", "=", "1", ")", "**", "2", "\n", "v01_dot", "=", "torch", ".", "mul", "(", "v", "[", "idx", "[", "0", "]", "]", ",", "v", "[", "idx", "[", "1", "]", "]", ")", ".", "sum", "(", "1", ")", "\n", "v02_dot", "=", "torch", ".", "mul", "(", "v", "[", "idx", "[", "0", "]", "]", ",", "v", "[", "idx", "[", "2", "]", "]", ")", ".", "sum", "(", "1", ")", "\n", "alpha", "=", "torch", ".", "div", "(", "v01_dot", ",", "v1_norm", ")", "\n", "beta", "=", "torch", ".", "div", "(", "v02_dot", ",", "v2_norm", ")", "\n", "n_vec", "=", "v", "[", "idx", "[", "0", "]", "]", "-", "torch", ".", "mul", "(", "alpha", "[", ":", ",", "None", "]", ",", "v", "[", "idx", "[", "1", "]", "]", ")", "-", "torch", ".", "mul", "(", "beta", "[", ":", ",", "None", "]", ",", "v", "[", "idx", "[", "2", "]", "]", ")", "\n", "n_vec_norm", "=", "torch", ".", "norm", "(", "n_vec", ",", "dim", "=", "1", ")", ".", "mean", "(", ")", "\n", "\n", "orthogonality", "=", "0", "\n", "for", "cter", "in", "range", "(", "nClass", ")", ":", "\n", "\t\t\t", "tidx", "=", "np", ".", "where", "(", "cidx", "==", "cter", ")", "[", "0", "]", "\n", "ntidx", "=", "np", ".", "arange", "(", "batch_size", ")", "\n", "ntidx", "=", "np", ".", "delete", "(", "ntidx", ",", "tidx", ")", "\n", "\n", "vecs", "=", "v", "[", "idx", "[", "0", "]", "]", "\n", "nvec", "=", "torch", ".", "norm", "(", "vecs", ",", "dim", "=", "1", ")", "\n", "vecs", "=", "torch", ".", "div", "(", "vecs", ",", "nvec", "[", ":", ",", "None", "]", ")", "\n", "\n", "tvec", "=", "vecs", "[", "tidx", "]", "\n", "ntvec", "=", "vecs", "[", "ntidx", "]", ".", "permute", "(", "1", ",", "0", ")", "\n", "\n", "inners", "=", "torch", ".", "matmul", "(", "tvec", ",", "ntvec", ")", "**", "2", "\n", "orthogonality", "+=", "inners", ".", "mean", "(", ")", "\n", "\n", "", "if", "error", "is", "None", ":", "\n", "\t\t\t", "error", "=", "(", "n_vec_norm", "+", "orthogonality", "/", "nClass", ")", "\n", "", "else", ":", "\n", "\t\t\t", "error", "+=", "(", "n_vec_norm", "+", "orthogonality", "/", "nClass", ")", "\n", "\n", "", "", "return", "error", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.resample_folder.resample": [[22, 43], ["range", "torch.stack", "audio[].detach().cpu().numpy", "torch.stack.append", "librosa.resample", "torch.from_numpy", "audio[].detach().cpu", "audio[].detach"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.resample_folder.resample"], ["def", "resample", "(", "audio", ",", "orig_fs", ",", "target_fs", ")", ":", "\n", "    ", "\"\"\"\n    Resamples the audio given as input at the target_fs sample rate, if the target sample rate and the\n    original sample rate are different.\n\n    Args:\n        audio (Tensor): audio to resample\n        orig_fs (int): original sample rate\n        target_fs (int): target sample rate\n\n    Returns:\n        Tensor: audio resampled\n    \"\"\"", "\n", "out", "=", "[", "]", "\n", "for", "c", "in", "range", "(", "audio", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "tmp", "=", "audio", "[", "c", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "target_fs", "!=", "orig_fs", ":", "\n", "            ", "tmp", "=", "librosa", ".", "resample", "(", "tmp", ",", "orig_fs", ",", "target_fs", ")", "\n", "", "out", ".", "append", "(", "torch", ".", "from_numpy", "(", "tmp", ")", ")", "\n", "", "out", "=", "torch", ".", "stack", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.resample_folder.resample_folder": [[45, 78], ["glob.glob", "os.path.exists", "os.path.join", "glob.glob", "tqdm.tqdm", "os.path.join", "len", "len", "torchaudio.load", "resample_folder.resample", "os.makedirs", "torchaudio.set_audio_backend", "torchaudio.save", "os.path.join", "pathlib.Path", "pathlib.Path().relative_to", "os.path.join", "pathlib.Path", "pathlib.Path().relative_to", "pathlib.Path", "pathlib.Path", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.load", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.resample_folder.resample", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save"], ["", "def", "resample_folder", "(", "in_dir", ",", "out_dir", ",", "target_fs", "=", "16000", ",", "regex", "=", "\"*.wav\"", ")", ":", "\n", "    ", "\"\"\"\n    Resamples the audio files contained in the in_dir folder and saves them in out_dir folder\n\n    Args:\n        in_dir (str): path to audio directory (audio to be resampled)\n        out_dir (str): path to audio resampled directory\n        target_fs (int, optional): target sample rate. Defaults to 16000.\n        regex (str, optional): regular expression for extension of file. Defaults to \"*.wav\".\n    \"\"\"", "\n", "compute", "=", "True", "\n", "files", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "in_dir", ",", "regex", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "out_files", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "regex", ")", ")", "\n", "if", "len", "(", "files", ")", "==", "len", "(", "out_files", ")", ":", "\n", "            ", "compute", "=", "False", "\n", "\n", "", "", "if", "compute", ":", "\n", "        ", "for", "f", "in", "tqdm", ".", "tqdm", "(", "files", ")", ":", "\n", "            ", "audio", ",", "orig_fs", "=", "torchaudio", ".", "load", "(", "f", ")", "\n", "audio", "=", "resample", "(", "audio", ",", "orig_fs", ",", "target_fs", ")", "\n", "\n", "os", ".", "makedirs", "(", "\n", "Path", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "Path", "(", "f", ")", ".", "relative_to", "(", "Path", "(", "in_dir", ")", ")", ")", ")", ".", "parent", ",", "\n", "exist_ok", "=", "True", ",", "\n", ")", "\n", "torchaudio", ".", "set_audio_backend", "(", "\"sox_io\"", ")", "\n", "torchaudio", ".", "save", "(", "\n", "os", ".", "path", ".", "join", "(", "out_dir", ",", "Path", "(", "f", ")", ".", "relative_to", "(", "Path", "(", "in_dir", ")", ")", ")", ",", "\n", "audio", ",", "\n", "target_fs", ",", "\n", ")", "\n", "", "", "return", "compute", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer.SEDTask4_2021.__init__": [[42, 144], ["pytorch_lightning.LightningModule.__init__", "copy.deepcopy", "torchaudio.transforms.MelSpectrogram", "sed_trainer.SEDTask4_2021.sed_teacher.parameters", "torch.nn.BCELoss", "pytorch_lightning.metrics.classification.F1", "pytorch_lightning.metrics.classification.F1", "sed_trainer.SEDTask4_2021._init_scaler", "numpy.arange", "pandas.DataFrame", "pandas.DataFrame", "param.detach_", "torch.nn.MSELoss", "len", "len", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "torch.nn.BCELoss"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021._init_scaler"], ["def", "__init__", "(", "\n", "self", ",", "\n", "hparams", ",", "\n", "encoder", ",", "\n", "sed_student", ",", "\n", "opt", "=", "None", ",", "\n", "train_data", "=", "None", ",", "\n", "valid_data", "=", "None", ",", "\n", "test_data", "=", "None", ",", "\n", "train_sampler", "=", "None", ",", "\n", "scheduler", "=", "None", ",", "\n", "fast_dev_run", "=", "False", ",", "\n", "evaluation", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", "SEDTask4_2021", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hparams", "=", "hparams", "\n", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "sed_student", "=", "sed_student", "\n", "self", ".", "sed_teacher", "=", "deepcopy", "(", "sed_student", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "train_data", "=", "train_data", "\n", "self", ".", "valid_data", "=", "valid_data", "\n", "self", ".", "test_data", "=", "test_data", "\n", "self", ".", "train_sampler", "=", "train_sampler", "\n", "self", ".", "scheduler", "=", "scheduler", "\n", "self", ".", "fast_dev_run", "=", "fast_dev_run", "\n", "self", ".", "evaluation", "=", "evaluation", "\n", "\n", "if", "self", ".", "fast_dev_run", ":", "\n", "            ", "self", ".", "num_workers", "=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_workers", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", "\n", "\n", "", "feat_params", "=", "self", ".", "hparams", "[", "\"feats\"", "]", "\n", "self", ".", "mel_spec", "=", "MelSpectrogram", "(", "\n", "sample_rate", "=", "feat_params", "[", "\"sample_rate\"", "]", ",", "\n", "n_fft", "=", "feat_params", "[", "\"n_window\"", "]", ",", "\n", "win_length", "=", "feat_params", "[", "\"n_window\"", "]", ",", "\n", "hop_length", "=", "feat_params", "[", "\"hop_length\"", "]", ",", "\n", "f_min", "=", "feat_params", "[", "\"f_min\"", "]", ",", "\n", "f_max", "=", "feat_params", "[", "\"f_max\"", "]", ",", "\n", "n_mels", "=", "feat_params", "[", "\"n_mels\"", "]", ",", "\n", "window_fn", "=", "torch", ".", "hamming_window", ",", "\n", "wkwargs", "=", "{", "\"periodic\"", ":", "False", "}", ",", "\n", "power", "=", "1", ",", "\n", ")", "\n", "\n", "for", "param", "in", "self", ".", "sed_teacher", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "detach_", "(", ")", "\n", "\n", "# instantiating losses", "\n", "", "self", ".", "supervised_loss", "=", "torch", ".", "nn", ".", "BCELoss", "(", ")", "\n", "if", "hparams", "[", "\"training\"", "]", "[", "\"self_sup_loss\"", "]", "==", "\"mse\"", ":", "\n", "            ", "self", ".", "selfsup_loss", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "\n", "", "elif", "hparams", "[", "\"training\"", "]", "[", "\"self_sup_loss\"", "]", "==", "\"bce\"", ":", "\n", "            ", "self", ".", "selfsup_loss", "=", "torch", ".", "nn", ".", "BCELoss", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "# for weak labels we simply compute f1 score", "\n", "", "self", ".", "get_weak_student_f1_seg_macro", "=", "pl", ".", "metrics", ".", "classification", ".", "F1", "(", "\n", "len", "(", "self", ".", "encoder", ".", "labels", ")", ",", "\n", "average", "=", "\"macro\"", ",", "\n", "multilabel", "=", "True", ",", "\n", "compute_on_step", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "get_weak_teacher_f1_seg_macro", "=", "pl", ".", "metrics", ".", "classification", ".", "F1", "(", "\n", "len", "(", "self", ".", "encoder", ".", "labels", ")", ",", "\n", "average", "=", "\"macro\"", ",", "\n", "multilabel", "=", "True", ",", "\n", "compute_on_step", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "scaler", "=", "self", ".", "_init_scaler", "(", ")", "\n", "\n", "# buffer for event based scores which we compute using sed-eval", "\n", "\n", "self", ".", "val_buffer_student_synth", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "self", ".", "val_buffer_teacher_synth", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "\n", "self", ".", "val_buffer_student_test", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "self", ".", "val_buffer_teacher_test", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "\n", "test_n_thresholds", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"n_test_thresholds\"", "]", "\n", "test_thresholds", "=", "np", ".", "arange", "(", "\n", "1", "/", "(", "test_n_thresholds", "*", "2", ")", ",", "1", ",", "1", "/", "test_n_thresholds", "\n", ")", "\n", "self", ".", "test_psds_buffer_student", "=", "{", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "test_thresholds", "}", "\n", "self", ".", "test_psds_buffer_teacher", "=", "{", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "test_thresholds", "}", "\n", "\n", "self", ".", "decoded_student_05_buffer", "=", "pd", ".", "DataFrame", "(", ")", "\n", "self", ".", "decoded_teacher_05_buffer", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer.SEDTask4_2021.update_ema": [[145, 158], ["min", "zip", "ema_model.parameters", "model.parameters", "ema_params.data.mul_().add_", "ema_params.data.mul_"], "methods", ["None"], ["", "def", "update_ema", "(", "self", ",", "alpha", ",", "global_step", ",", "model", ",", "ema_model", ")", ":", "\n", "        ", "\"\"\" Update teacher model parameters\n\n        Args:\n            alpha: float, the factor to be used between each updated step.\n            global_step: int, the current global step to be used.\n            model: torch.Module, student model to use\n            ema_model: torch.Module, teacher model to use\n        \"\"\"", "\n", "# Use the true average until the exponential average is more correct", "\n", "alpha", "=", "min", "(", "1", "-", "1", "/", "(", "global_step", "+", "1", ")", ",", "alpha", ")", "\n", "for", "ema_params", ",", "params", "in", "zip", "(", "ema_model", ".", "parameters", "(", ")", ",", "model", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "ema_params", ".", "data", ".", "mul_", "(", "alpha", ")", ".", "add_", "(", "params", ".", "data", ",", "alpha", "=", "1", "-", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer.SEDTask4_2021._init_scaler": [[159, 206], ["sed_trainer.SEDTask4_2021.train_dataloader", "torch.load.fit", "desed_task.utils.scaler.TorchScaler", "os.path.exists", "torch.save", "print", "desed_task.utils.scaler.TorchScaler", "torch.load", "print", "sed_trainer.SEDTask4_2021.take_log", "sed_trainer.SEDTask4_2021.mel_spec"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.train_dataloader", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.fit", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.load", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.take_log"], ["", "", "def", "_init_scaler", "(", "self", ")", ":", "\n", "        ", "\"\"\"Scaler inizialization\n\n        Raises:\n            NotImplementedError: in case of not Implemented scaler\n\n        Returns:\n            TorchScaler: returns the scaler\n        \"\"\"", "\n", "\n", "if", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"statistic\"", "]", "==", "\"instance\"", ":", "\n", "            ", "scaler", "=", "TorchScaler", "(", "\"instance\"", ",", "\"minmax\"", ",", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"dims\"", "]", ")", "\n", "\n", "return", "scaler", "\n", "", "elif", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"statistic\"", "]", "==", "\"dataset\"", ":", "\n", "# we fit the scaler", "\n", "            ", "scaler", "=", "TorchScaler", "(", "\n", "\"dataset\"", ",", "\n", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"normtype\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"dims\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "if", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", "is", "not", "None", ":", "\n", "            ", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", ")", ":", "\n", "                ", "scaler", "=", "torch", ".", "load", "(", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", ")", "\n", "print", "(", "\n", "\"Loaded Scaler from previous checkpoint from {}\"", ".", "format", "(", "\n", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", "\n", ")", "\n", ")", "\n", "return", "scaler", "\n", "\n", "", "", "self", ".", "train_loader", "=", "self", ".", "train_dataloader", "(", ")", "\n", "scaler", ".", "fit", "(", "\n", "self", ".", "train_loader", ",", "\n", "transform_func", "=", "lambda", "x", ":", "self", ".", "take_log", "(", "self", ".", "mel_spec", "(", "x", "[", "0", "]", ")", ")", ",", "\n", ")", "\n", "\n", "if", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", "is", "not", "None", ":", "\n", "            ", "torch", ".", "save", "(", "scaler", ",", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", ")", "\n", "print", "(", "\n", "\"Saving Scaler from previous checkpoint at {}\"", ".", "format", "(", "\n", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", "\n", ")", "\n", ")", "\n", "return", "scaler", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer.SEDTask4_2021.take_log": [[207, 219], ["torchaudio.transforms.AmplitudeToDB", "torchaudio.transforms.AmplitudeToDB.clamp", "torchaudio.transforms.AmplitudeToDB."], "methods", ["None"], ["", "", "def", "take_log", "(", "self", ",", "mels", ")", ":", "\n", "        ", "\"\"\" Apply the log transformation to mel spectrograms.\n        Args:\n            mels: torch.Tensor, mel spectrograms for which to apply log.\n\n        Returns:\n            Tensor: logarithmic mel spectrogram of the mel spectrogram given as input\n        \"\"\"", "\n", "\n", "amp_to_db", "=", "AmplitudeToDB", "(", "stype", "=", "\"amplitude\"", ")", "\n", "amp_to_db", ".", "amin", "=", "1e-5", "# amin= 1e-5 as in librosa", "\n", "return", "amp_to_db", "(", "mels", ")", ".", "clamp", "(", "min", "=", "-", "50", ",", "max", "=", "80", ")", "# clamp to reproduce old code", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer.SEDTask4_2021.training_step": [[220, 307], ["sed_trainer.SEDTask4_2021.mel_spec", "torch.zeros().to().bool", "torch.zeros().to().bool", "sed_trainer.SEDTask4_2021.hparams[].get", "sed_trainer.SEDTask4_2021.sed_student", "sed_trainer.SEDTask4_2021.supervised_loss", "sed_trainer.SEDTask4_2021.supervised_loss", "sed_trainer.SEDTask4_2021.selfsup_loss", "sed_trainer.SEDTask4_2021.selfsup_loss", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "desed_task.data_augm.mixup", "desed_task.data_augm.mixup", "sed_trainer.SEDTask4_2021.scaler", "torch.no_grad", "sed_trainer.SEDTask4_2021.scaler", "sed_trainer.SEDTask4_2021.sed_teacher", "sed_trainer.SEDTask4_2021.supervised_loss", "sed_trainer.SEDTask4_2021.supervised_loss", "sed_trainer.SEDTask4_2021.scheduler[]._get_scaling_factor", "strong_preds_teacher.detach", "weak_preds_teacher.detach", "torch.zeros().to", "torch.zeros().to", "random.random", "sed_trainer.SEDTask4_2021.take_log", "sed_trainer.SEDTask4_2021.take_log", "torch.sum", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.desed_task.data_augm.mixup", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.desed_task.data_augm.mixup", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.schedulers.ExponentialWarmup._get_scaling_factor", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.take_log", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.take_log"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_indx", ")", ":", "\n", "        ", "\"\"\" Applying the training for one batch (a step). Used during trainer.fit\n\n        Args:\n            batch: torch.Tensor, batch input tensor\n            batch_indx: torch.Tensor, 1D tensor of indexes to know which data are present in each batch.\n\n        Returns:\n           torch.Tensor, the loss to take into account.\n        \"\"\"", "\n", "\n", "audio", ",", "labels", ",", "padded_indxs", "=", "batch", "\n", "indx_synth", ",", "indx_weak", ",", "indx_unlabelled", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", "\n", "features", "=", "self", ".", "mel_spec", "(", "audio", ")", "\n", "\n", "batch_num", "=", "features", ".", "shape", "[", "0", "]", "\n", "# deriving masks for each dataset", "\n", "strong_mask", "=", "torch", ".", "zeros", "(", "batch_num", ")", ".", "to", "(", "features", ")", ".", "bool", "(", ")", "\n", "weak_mask", "=", "torch", ".", "zeros", "(", "batch_num", ")", ".", "to", "(", "features", ")", ".", "bool", "(", ")", "\n", "strong_mask", "[", ":", "indx_synth", "]", "=", "1", "\n", "weak_mask", "[", "indx_synth", ":", "indx_weak", "+", "indx_synth", "]", "=", "1", "\n", "\n", "# deriving weak labels", "\n", "labels_weak", "=", "(", "torch", ".", "sum", "(", "labels", "[", "weak_mask", "]", ",", "-", "1", ")", ">", "0", ")", ".", "float", "(", ")", "\n", "\n", "mixup_type", "=", "self", ".", "hparams", "[", "\"training\"", "]", ".", "get", "(", "\"mixup\"", ")", "\n", "if", "mixup_type", "is", "not", "None", "and", "0.5", ">", "random", ".", "random", "(", ")", ":", "\n", "            ", "features", "[", "weak_mask", "]", ",", "labels_weak", "=", "mixup", "(", "\n", "features", "[", "weak_mask", "]", ",", "labels_weak", ",", "mixup_label_type", "=", "mixup_type", "\n", ")", "\n", "features", "[", "strong_mask", "]", ",", "labels", "[", "strong_mask", "]", "=", "mixup", "(", "\n", "features", "[", "strong_mask", "]", ",", "labels", "[", "strong_mask", "]", ",", "mixup_label_type", "=", "mixup_type", "\n", ")", "\n", "\n", "# sed student forward", "\n", "", "strong_preds_student", ",", "weak_preds_student", "=", "self", ".", "sed_student", "(", "\n", "self", ".", "scaler", "(", "self", ".", "take_log", "(", "features", ")", ")", "\n", ")", "\n", "\n", "# supervised loss on strong labels", "\n", "loss_strong", "=", "self", ".", "supervised_loss", "(", "\n", "strong_preds_student", "[", "strong_mask", "]", ",", "labels", "[", "strong_mask", "]", "\n", ")", "\n", "# supervised loss on weakly labelled", "\n", "loss_weak", "=", "self", ".", "supervised_loss", "(", "weak_preds_student", "[", "weak_mask", "]", ",", "labels_weak", ")", "\n", "# total supervised loss", "\n", "tot_loss_supervised", "=", "loss_strong", "+", "loss_weak", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "ema_features", "=", "self", ".", "scaler", "(", "self", ".", "take_log", "(", "features", ")", ")", "\n", "strong_preds_teacher", ",", "weak_preds_teacher", "=", "self", ".", "sed_teacher", "(", "ema_features", ")", "\n", "loss_strong_teacher", "=", "self", ".", "supervised_loss", "(", "\n", "strong_preds_teacher", "[", "strong_mask", "]", ",", "labels", "[", "strong_mask", "]", "\n", ")", "\n", "\n", "loss_weak_teacher", "=", "self", ".", "supervised_loss", "(", "\n", "weak_preds_teacher", "[", "weak_mask", "]", ",", "labels_weak", "\n", ")", "\n", "# we apply consistency between the predictions, use the scheduler for learning rate (to be changed ?)", "\n", "", "weight", "=", "(", "\n", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"const_max\"", "]", "\n", "*", "self", ".", "scheduler", "[", "\"scheduler\"", "]", ".", "_get_scaling_factor", "(", ")", "\n", ")", "\n", "\n", "strong_self_sup_loss", "=", "self", ".", "selfsup_loss", "(", "\n", "strong_preds_student", ",", "strong_preds_teacher", ".", "detach", "(", ")", "\n", ")", "\n", "weak_self_sup_loss", "=", "self", ".", "selfsup_loss", "(", "\n", "weak_preds_student", ",", "weak_preds_teacher", ".", "detach", "(", ")", "\n", ")", "\n", "tot_self_loss", "=", "(", "strong_self_sup_loss", "+", "weak_self_sup_loss", ")", "*", "weight", "\n", "\n", "tot_loss", "=", "tot_loss_supervised", "+", "tot_self_loss", "\n", "\n", "self", ".", "log", "(", "\"train/student/loss_strong\"", ",", "loss_strong", ")", "\n", "self", ".", "log", "(", "\"train/student/loss_weak\"", ",", "loss_weak", ")", "\n", "self", ".", "log", "(", "\"train/teacher/loss_strong\"", ",", "loss_strong_teacher", ")", "\n", "self", ".", "log", "(", "\"train/teacher/loss_weak\"", ",", "loss_weak_teacher", ")", "\n", "self", ".", "log", "(", "\"train/step\"", ",", "self", ".", "scheduler", "[", "\"scheduler\"", "]", ".", "step_num", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"train/student/tot_self_loss\"", ",", "tot_self_loss", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"train/weight\"", ",", "weight", ")", "\n", "self", ".", "log", "(", "\"train/student/tot_supervised\"", ",", "strong_self_sup_loss", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"train/student/weak_self_sup_loss\"", ",", "weak_self_sup_loss", ")", "\n", "self", ".", "log", "(", "\"train/student/strong_self_sup_loss\"", ",", "strong_self_sup_loss", ")", "\n", "self", ".", "log", "(", "\"train/lr\"", ",", "self", ".", "opt", ".", "param_groups", "[", "-", "1", "]", "[", "\"lr\"", "]", ",", "prog_bar", "=", "True", ")", "\n", "\n", "return", "tot_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer.SEDTask4_2021.on_before_zero_grad": [[308, 315], ["sed_trainer.SEDTask4_2021.update_ema"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.update_ema"], ["", "def", "on_before_zero_grad", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# update EMA teacher", "\n", "        ", "self", ".", "update_ema", "(", "\n", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"ema_factor\"", "]", ",", "\n", "self", ".", "scheduler", "[", "\"scheduler\"", "]", ".", "step_num", ",", "\n", "self", ".", "sed_student", ",", "\n", "self", ".", "sed_teacher", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer.SEDTask4_2021.validation_step": [[317, 420], ["sed_trainer.SEDTask4_2021.scaler", "sed_trainer.SEDTask4_2021.sed_student", "sed_trainer.SEDTask4_2021.sed_teacher", "torch.tensor().to().bool", "torch.tensor().to().bool", "torch.any", "torch.any", "sed_trainer.SEDTask4_2021.take_log", "sed_trainer.SEDTask4_2021.supervised_loss", "sed_trainer.SEDTask4_2021.supervised_loss", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.get_weak_student_f1_seg_macro", "sed_trainer.SEDTask4_2021.get_weak_teacher_f1_seg_macro", "sed_trainer.SEDTask4_2021.supervised_loss", "sed_trainer.SEDTask4_2021.supervised_loss", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "utils.batched_decode_preds", "sed_trainer.SEDTask4_2021.val_buffer_student_synth.keys", "utils.batched_decode_preds", "sed_trainer.SEDTask4_2021.val_buffer_teacher_synth.keys", "sed_trainer.SEDTask4_2021.mel_spec", "torch.tensor().to", "torch.tensor().to", "sed_trainer.SEDTask4_2021.val_buffer_student_synth[].append", "sed_trainer.SEDTask4_2021.val_buffer_teacher_synth[].append", "list", "list", "torch.tensor", "torch.tensor", "torch.sum", "pathlib.Path", "sed_trainer.SEDTask4_2021.val_buffer_student_synth.keys", "sed_trainer.SEDTask4_2021.val_buffer_teacher_synth.keys", "pathlib.Path", "str", "str", "str", "str", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.take_log", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_indx", ")", ":", "\n", "        ", "\"\"\" Apply validation to a batch (step). Used during trainer.fit\n\n        Args:\n            batch: torch.Tensor, input batch tensor\n            batch_indx: torch.Tensor, 1D tensor of indexes to know which data are present in each batch.\n        Returns:\n        \"\"\"", "\n", "\n", "audio", ",", "labels", ",", "padded_indxs", ",", "filenames", "=", "batch", "\n", "\n", "# prediction for student", "\n", "logmels", "=", "self", ".", "scaler", "(", "self", ".", "take_log", "(", "self", ".", "mel_spec", "(", "audio", ")", ")", ")", "\n", "strong_preds_student", ",", "weak_preds_student", "=", "self", ".", "sed_student", "(", "logmels", ")", "\n", "# prediction for teacher", "\n", "strong_preds_teacher", ",", "weak_preds_teacher", "=", "self", ".", "sed_teacher", "(", "logmels", ")", "\n", "\n", "# we derive masks for each dataset based on folders of filenames", "\n", "mask_weak", "=", "(", "\n", "torch", ".", "tensor", "(", "\n", "[", "\n", "str", "(", "Path", "(", "x", ")", ".", "parent", ")", "\n", "==", "str", "(", "Path", "(", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"weak_folder\"", "]", ")", ")", "\n", "for", "x", "in", "filenames", "\n", "]", "\n", ")", "\n", ".", "to", "(", "audio", ")", "\n", ".", "bool", "(", ")", "\n", ")", "\n", "mask_synth", "=", "(", "\n", "torch", ".", "tensor", "(", "\n", "[", "\n", "str", "(", "Path", "(", "x", ")", ".", "parent", ")", "\n", "==", "str", "(", "Path", "(", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_folder\"", "]", ")", ")", "\n", "for", "x", "in", "filenames", "\n", "]", "\n", ")", "\n", ".", "to", "(", "audio", ")", "\n", ".", "bool", "(", ")", "\n", ")", "\n", "\n", "if", "torch", ".", "any", "(", "mask_weak", ")", ":", "\n", "            ", "labels_weak", "=", "(", "torch", ".", "sum", "(", "labels", "[", "mask_weak", "]", ",", "-", "1", ")", ">=", "1", ")", ".", "float", "(", ")", "\n", "loss_weak_student", "=", "self", ".", "supervised_loss", "(", "\n", "weak_preds_student", "[", "mask_weak", "]", ",", "labels_weak", "\n", ")", "\n", "loss_weak_teacher", "=", "self", ".", "supervised_loss", "(", "\n", "weak_preds_teacher", "[", "mask_weak", "]", ",", "labels_weak", "\n", ")", "\n", "self", ".", "log", "(", "\"val/weak/student/loss_weak\"", ",", "loss_weak_student", ")", "\n", "self", ".", "log", "(", "\"val/weak/teacher/loss_weak\"", ",", "loss_weak_teacher", ")", "\n", "\n", "# accumulate f1 score for weak labels", "\n", "self", ".", "get_weak_student_f1_seg_macro", "(", "\n", "weak_preds_student", "[", "mask_weak", "]", ",", "labels_weak", "\n", ")", "\n", "self", ".", "get_weak_teacher_f1_seg_macro", "(", "\n", "weak_preds_teacher", "[", "mask_weak", "]", ",", "labels_weak", "\n", ")", "\n", "\n", "", "if", "torch", ".", "any", "(", "mask_synth", ")", ":", "\n", "            ", "loss_strong_student", "=", "self", ".", "supervised_loss", "(", "\n", "strong_preds_student", "[", "mask_synth", "]", ",", "labels", "[", "mask_synth", "]", "\n", ")", "\n", "loss_strong_teacher", "=", "self", ".", "supervised_loss", "(", "\n", "strong_preds_teacher", "[", "mask_synth", "]", ",", "labels", "[", "mask_synth", "]", "\n", ")", "\n", "\n", "self", ".", "log", "(", "\"val/synth/student/loss_strong\"", ",", "loss_strong_student", ")", "\n", "self", ".", "log", "(", "\"val/synth/teacher/loss_strong\"", ",", "loss_strong_teacher", ")", "\n", "\n", "filenames_synth", "=", "[", "\n", "x", "\n", "for", "x", "in", "filenames", "\n", "if", "Path", "(", "x", ")", ".", "parent", "==", "Path", "(", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_folder\"", "]", ")", "\n", "]", "\n", "\n", "decoded_student_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_student", "[", "mask_synth", "]", ",", "\n", "filenames_synth", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "val_buffer_student_synth", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "\n", "for", "th", "in", "self", ".", "val_buffer_student_synth", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "val_buffer_student_synth", "[", "th", "]", "=", "self", ".", "val_buffer_student_synth", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_student_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "decoded_teacher_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_teacher", "[", "mask_synth", "]", ",", "\n", "filenames_synth", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "val_buffer_teacher_synth", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "for", "th", "in", "self", ".", "val_buffer_teacher_synth", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "val_buffer_teacher_synth", "[", "th", "]", "=", "self", ".", "val_buffer_teacher_synth", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_teacher_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer.SEDTask4_2021.validation_epoch_end": [[421, 493], ["sed_trainer.SEDTask4_2021.get_weak_student_f1_seg_macro.compute", "sed_trainer.SEDTask4_2021.get_weak_teacher_f1_seg_macro.compute", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "sed_trainer.SEDTask4_2021.hparams[].get", "torch.tensor", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.get_weak_student_f1_seg_macro.reset", "sed_trainer.SEDTask4_2021.get_weak_teacher_f1_seg_macro.reset", "utils.log_sedeval_metrics", "utils.log_sedeval_metrics", "pandas.DataFrame", "pandas.DataFrame", "sed_trainer.SEDTask4_2021.item", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.reset", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.reset", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "\"\"\" Fonction applied at the end of all the validation steps of the epoch.\n\n        Args:\n            outputs: torch.Tensor, the concatenation of everything returned by validation_step.\n\n        Returns:\n            torch.Tensor, the objective metric to be used to choose the best model from for example.\n        \"\"\"", "\n", "\n", "weak_student_f1_macro", "=", "self", ".", "get_weak_student_f1_seg_macro", ".", "compute", "(", ")", "\n", "weak_teacher_f1_macro", "=", "self", ".", "get_weak_teacher_f1_seg_macro", ".", "compute", "(", ")", "\n", "\n", "# synth dataset", "\n", "intersection_f1_macro_student", "=", "compute_per_intersection_macro_f1", "(", "\n", "self", ".", "val_buffer_student_synth", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_dur\"", "]", ",", "\n", ")", "\n", "\n", "synth_student_event_macro", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "val_buffer_student_synth", "[", "0.5", "]", ",", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_tsv\"", "]", ",", "\n", ")", "[", "0", "]", "\n", "\n", "intersection_f1_macro_teacher", "=", "compute_per_intersection_macro_f1", "(", "\n", "self", ".", "val_buffer_teacher_synth", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_dur\"", "]", ",", "\n", ")", "\n", "\n", "synth_teacher_event_macro", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "val_buffer_teacher_synth", "[", "0.5", "]", ",", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_tsv\"", "]", ",", "\n", ")", "[", "0", "]", "\n", "\n", "obj_metric_synth_type", "=", "self", ".", "hparams", "[", "\"training\"", "]", ".", "get", "(", "\"obj_metric_synth_type\"", ")", "\n", "if", "obj_metric_synth_type", "is", "None", ":", "\n", "            ", "synth_metric", "=", "intersection_f1_macro_student", "\n", "", "elif", "obj_metric_synth_type", "==", "\"event\"", ":", "\n", "            ", "synth_metric", "=", "synth_student_event_macro", "\n", "", "elif", "obj_metric_synth_type", "==", "\"intersection\"", ":", "\n", "            ", "synth_metric", "=", "intersection_f1_macro_student", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "f\"obj_metric_synth_type: {obj_metric_synth_type} not implemented.\"", "\n", ")", "\n", "\n", "", "obj_metric", "=", "torch", ".", "tensor", "(", "weak_student_f1_macro", ".", "item", "(", ")", "+", "synth_metric", ")", "\n", "\n", "self", ".", "log", "(", "\"val/obj_metric\"", ",", "obj_metric", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"val/weak/student/macro_F1\"", ",", "weak_student_f1_macro", ")", "\n", "self", ".", "log", "(", "\"val/weak/teacher/macro_F1\"", ",", "weak_teacher_f1_macro", ")", "\n", "self", ".", "log", "(", "\n", "\"val/synth/student/intersection_f1_macro\"", ",", "intersection_f1_macro_student", "\n", ")", "\n", "self", ".", "log", "(", "\n", "\"val/synth/teacher/intersection_f1_macro\"", ",", "intersection_f1_macro_teacher", "\n", ")", "\n", "self", ".", "log", "(", "\"val/synth/student/event_f1_macro\"", ",", "synth_student_event_macro", ")", "\n", "self", ".", "log", "(", "\"val/synth/teacher/event_f1_macro\"", ",", "synth_teacher_event_macro", ")", "\n", "\n", "# free the buffers", "\n", "self", ".", "val_buffer_student_synth", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "self", ".", "val_buffer_teacher_synth", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "\n", "self", ".", "get_weak_student_f1_seg_macro", ".", "reset", "(", ")", "\n", "self", ".", "get_weak_teacher_f1_seg_macro", ".", "reset", "(", ")", "\n", "\n", "return", "obj_metric", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer.SEDTask4_2021.on_save_checkpoint": [[494, 498], ["sed_trainer.SEDTask4_2021.sed_student.state_dict", "sed_trainer.SEDTask4_2021.sed_teacher.state_dict"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict"], ["", "def", "on_save_checkpoint", "(", "self", ",", "checkpoint", ")", ":", "\n", "        ", "checkpoint", "[", "\"sed_student\"", "]", "=", "self", ".", "sed_student", ".", "state_dict", "(", ")", "\n", "checkpoint", "[", "\"sed_teacher\"", "]", "=", "self", ".", "sed_teacher", ".", "state_dict", "(", ")", "\n", "return", "checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer.SEDTask4_2021.test_step": [[499, 584], ["sed_trainer.SEDTask4_2021.scaler", "sed_trainer.SEDTask4_2021.sed_student", "sed_trainer.SEDTask4_2021.sed_teacher", "utils.batched_decode_preds", "sed_trainer.SEDTask4_2021.test_psds_buffer_student.keys", "utils.batched_decode_preds", "sed_trainer.SEDTask4_2021.test_psds_buffer_teacher.keys", "utils.batched_decode_preds", "sed_trainer.SEDTask4_2021.decoded_student_05_buffer.append", "utils.batched_decode_preds", "sed_trainer.SEDTask4_2021.decoded_teacher_05_buffer.append", "sed_trainer.SEDTask4_2021.take_log", "sed_trainer.SEDTask4_2021.supervised_loss", "sed_trainer.SEDTask4_2021.supervised_loss", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.log", "sed_trainer.SEDTask4_2021.test_psds_buffer_student[].append", "sed_trainer.SEDTask4_2021.test_psds_buffer_teacher[].append", "sed_trainer.SEDTask4_2021.mel_spec", "list", "list", "sed_trainer.SEDTask4_2021.test_psds_buffer_student.keys", "sed_trainer.SEDTask4_2021.test_psds_buffer_teacher.keys"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.take_log"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_indx", ")", ":", "\n", "        ", "\"\"\" Apply Test to a batch (step), used only when (trainer.test is called)\n\n        Args:\n            batch: torch.Tensor, input batch tensor\n            batch_indx: torch.Tensor, 1D tensor of indexes to know which data are present in each batch.\n        Returns:\n        \"\"\"", "\n", "\n", "audio", ",", "labels", ",", "padded_indxs", ",", "filenames", "=", "batch", "\n", "\n", "# prediction for student", "\n", "logmels", "=", "self", ".", "scaler", "(", "self", ".", "take_log", "(", "self", ".", "mel_spec", "(", "audio", ")", ")", ")", "\n", "strong_preds_student", ",", "weak_preds_student", "=", "self", ".", "sed_student", "(", "logmels", ")", "\n", "# prediction for teacher", "\n", "strong_preds_teacher", ",", "weak_preds_teacher", "=", "self", ".", "sed_teacher", "(", "logmels", ")", "\n", "\n", "\"\"\"\n        bsz = len(filenames)\n        for bter in range(bsz):\n            pred_student = strong_preds_student[bter].cpu().numpy()\n            pred_teacher = strong_preds_teacher[bter].cpu().numpy()\n\n            path, filename = os.path.split(filenames[bter])            \n            np.save('./Posterior/student/{}.npy'.format(filename), pred_student)\n            np.save('./Posterior/teacher/{}.npy'.format(filename), pred_teacher)\n        \"\"\"", "\n", "\n", "if", "not", "self", ".", "evaluation", ":", "\n", "            ", "loss_strong_student", "=", "self", ".", "supervised_loss", "(", "strong_preds_student", ",", "labels", ")", "\n", "loss_strong_teacher", "=", "self", ".", "supervised_loss", "(", "strong_preds_teacher", ",", "labels", ")", "\n", "\n", "self", ".", "log", "(", "\"test/student/loss_strong\"", ",", "loss_strong_student", ")", "\n", "self", ".", "log", "(", "\"test/teacher/loss_strong\"", ",", "loss_strong_teacher", ")", "\n", "\n", "# compute psds", "\n", "", "decoded_student_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_student", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "test_psds_buffer_student", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "\n", "for", "th", "in", "self", ".", "test_psds_buffer_student", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "test_psds_buffer_student", "[", "th", "]", "=", "self", ".", "test_psds_buffer_student", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_student_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "decoded_teacher_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_teacher", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "test_psds_buffer_teacher", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "\n", "for", "th", "in", "self", ".", "test_psds_buffer_teacher", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "test_psds_buffer_teacher", "[", "th", "]", "=", "self", ".", "test_psds_buffer_teacher", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_teacher_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "# compute f1 score", "\n", "", "decoded_student_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_student", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "[", "0.5", "]", ",", "\n", ")", "\n", "\n", "self", ".", "decoded_student_05_buffer", "=", "self", ".", "decoded_student_05_buffer", ".", "append", "(", "\n", "decoded_student_strong", "[", "0.5", "]", "\n", ")", "\n", "\n", "decoded_teacher_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_teacher", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "[", "0.5", "]", ",", "\n", ")", "\n", "\n", "self", ".", "decoded_teacher_05_buffer", "=", "self", ".", "decoded_teacher_05_buffer", ".", "append", "(", "\n", "decoded_teacher_strong", "[", "0.5", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer.SEDTask4_2021.on_test_epoch_end": [[586, 719], ["os.path.join", "os.path.join", "os.makedirs", "sed_trainer.SEDTask4_2021.decoded_student_05_buffer.to_csv", "sed_trainer.SEDTask4_2021.test_psds_buffer_student.keys", "print", "os.path.join", "os.makedirs", "sed_trainer.SEDTask4_2021.decoded_teacher_05_buffer.to_csv", "sed_trainer.SEDTask4_2021.test_psds_buffer_student.keys", "print", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "torch.tensor", "results.keys", "os.path.join", "sed_trainer.SEDTask4_2021.test_psds_buffer_student[].to_csv", "os.path.join", "sed_trainer.SEDTask4_2021.test_psds_buffer_student[].to_csv", "utils.log_sedeval_metrics", "utils.log_sedeval_metrics", "max", "sed_trainer.SEDTask4_2021.logger.log_metrics", "sed_trainer.SEDTask4_2021.logger.log_hyperparams", "sed_trainer.SEDTask4_2021.log", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics"], ["", "def", "on_test_epoch_end", "(", "self", ")", ":", "\n", "# pub eval dataset", "\n", "        ", "try", ":", "\n", "            ", "log_dir", "=", "self", ".", "logger", ".", "log_dir", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "log_dir", "=", "self", ".", "hparams", "[", "\"log_dir\"", "]", "\n", "", "save_dir", "=", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"metrics_test\"", ")", "\n", "\n", "if", "self", ".", "evaluation", ":", "\n", "# only save the predictions", "\n", "            ", "save_dir_student", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student\"", ")", "\n", "os", ".", "makedirs", "(", "save_dir_student", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "decoded_student_05_buffer", ".", "to_csv", "(", "\n", "os", ".", "path", ".", "join", "(", "save_dir_student", ",", "f\"predictions_05_student.tsv\"", ")", ",", "\n", "sep", "=", "\"\\t\"", ",", "\n", "index", "=", "False", "\n", ")", "\n", "for", "k", "in", "self", ".", "test_psds_buffer_student", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "test_psds_buffer_student", "[", "k", "]", ".", "to_csv", "(", "\n", "os", ".", "path", ".", "join", "(", "save_dir_student", ",", "f\"predictions_th_{k:.2f}.tsv\"", ")", ",", "\n", "sep", "=", "\"\\t\"", ",", "\n", "index", "=", "False", ",", "\n", ")", "\n", "", "print", "(", "f\"\\nPredictions for student saved in: {save_dir_student}\"", ")", "\n", "\n", "save_dir_teacher", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher\"", ")", "\n", "os", ".", "makedirs", "(", "save_dir_teacher", ",", "exist_ok", "=", "True", ")", "\n", "\n", "self", ".", "decoded_teacher_05_buffer", ".", "to_csv", "(", "\n", "os", ".", "path", ".", "join", "(", "save_dir_teacher", ",", "f\"predictions_05_teacher.tsv\"", ")", ",", "\n", "sep", "=", "\"\\t\"", ",", "\n", "index", "=", "False", "\n", ")", "\n", "for", "k", "in", "self", ".", "test_psds_buffer_student", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "test_psds_buffer_student", "[", "k", "]", ".", "to_csv", "(", "\n", "os", ".", "path", ".", "join", "(", "save_dir_teacher", ",", "f\"predictions_th_{k:.2f}.tsv\"", ")", ",", "\n", "sep", "=", "\"\\t\"", ",", "\n", "index", "=", "False", ",", "\n", ")", "\n", "", "print", "(", "f\"\\nPredictions for teacher saved in: {save_dir_teacher}\"", ")", "\n", "\n", "", "else", ":", "\n", "            ", "psds_score_scenario1", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_student", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.7", ",", "\n", "gtc_threshold", "=", "0.7", ",", "\n", "alpha_ct", "=", "0", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student\"", ",", "\"scenario1\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_scenario2", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_student", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.1", ",", "\n", "gtc_threshold", "=", "0.1", ",", "\n", "cttc_threshold", "=", "0.3", ",", "\n", "alpha_ct", "=", "0.5", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student\"", ",", "\"scenario2\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_teacher_scenario1", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_teacher", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.7", ",", "\n", "gtc_threshold", "=", "0.7", ",", "\n", "alpha_ct", "=", "0", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher\"", ",", "\"scenario1\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_teacher_scenario2", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_teacher", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.1", ",", "\n", "gtc_threshold", "=", "0.1", ",", "\n", "cttc_threshold", "=", "0.3", ",", "\n", "alpha_ct", "=", "0.5", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher\"", ",", "\"scenario2\"", ")", ",", "\n", ")", "\n", "\n", "event_macro_student", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "decoded_student_05_buffer", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student\"", ")", ",", "\n", ")", "[", "0", "]", "\n", "\n", "event_macro_teacher", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "decoded_teacher_05_buffer", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher\"", ")", ",", "\n", ")", "[", "0", "]", "\n", "\n", "# synth dataset", "\n", "intersection_f1_macro_student", "=", "compute_per_intersection_macro_f1", "(", "\n", "{", "\"0.5\"", ":", "self", ".", "decoded_student_05_buffer", "}", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", ")", "\n", "\n", "# synth dataset", "\n", "intersection_f1_macro_teacher", "=", "compute_per_intersection_macro_f1", "(", "\n", "{", "\"0.5\"", ":", "self", ".", "decoded_teacher_05_buffer", "}", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", ")", "\n", "\n", "best_test_result", "=", "torch", ".", "tensor", "(", "max", "(", "psds_score_scenario1", ",", "psds_score_scenario2", ")", ")", "\n", "\n", "results", "=", "{", "\n", "\"hp_metric\"", ":", "best_test_result", ",", "\n", "\"test/student/psds_score_scenario1\"", ":", "psds_score_scenario1", ",", "\n", "\"test/student/psds_score_scenario2\"", ":", "psds_score_scenario2", ",", "\n", "\"test/teacher/psds_score_scenario1\"", ":", "psds_score_teacher_scenario1", ",", "\n", "\"test/teacher/psds_score_scenario2\"", ":", "psds_score_teacher_scenario2", ",", "\n", "\"test/student/event_f1_macro\"", ":", "event_macro_student", ",", "\n", "\"test/student/intersection_f1_macro\"", ":", "intersection_f1_macro_student", ",", "\n", "\"test/teacher/event_f1_macro\"", ":", "event_macro_teacher", ",", "\n", "\"test/teacher/intersection_f1_macro\"", ":", "intersection_f1_macro_teacher", "\n", "}", "\n", "if", "self", ".", "logger", "is", "not", "None", ":", "\n", "                ", "self", ".", "logger", ".", "log_metrics", "(", "results", ")", "\n", "self", ".", "logger", ".", "log_hyperparams", "(", "self", ".", "hparams", ",", "results", ")", "\n", "\n", "", "for", "key", "in", "results", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "log", "(", "key", ",", "results", "[", "key", "]", ",", "prog_bar", "=", "True", ",", "logger", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer.SEDTask4_2021.configure_optimizers": [[720, 722], ["None"], "methods", ["None"], ["", "", "", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "opt", "]", ",", "[", "self", ".", "scheduler", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer.SEDTask4_2021.train_dataloader": [[723, 732], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "train_data", ",", "\n", "batch_sampler", "=", "self", ".", "train_sampler", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", ")", "\n", "\n", "return", "self", ".", "train_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer.SEDTask4_2021.val_dataloader": [[733, 742], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "self", ".", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "valid_data", ",", "\n", "batch_size", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"batch_size_val\"", "]", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "shuffle", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "\n", ")", "\n", "return", "self", ".", "val_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer.SEDTask4_2021.test_dataloader": [[743, 752], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "self", ".", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "test_data", ",", "\n", "batch_size", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"batch_size_val\"", "]", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "shuffle", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "\n", ")", "\n", "return", "self", ".", "test_loader", "\n", "", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.JSD.__init__": [[13, 16], ["torch.nn.Module.__init__", "torch.nn.KLDivLoss().cuda", "torch.nn.KLDivLoss"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__"], ["from", "desed", ".", "utils", "import", "create_folder", "\n", "from", "torch", "import", "nn", "\n", "\n", "import", "config", "as", "cfg", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.JSD.forward": [[17, 20], ["utils.JSD.kld", "utils.JSD.kld"], "methods", ["None"], ["\n", "\n", "def", "median_smoothing", "(", "input_tensor", ",", "win_length", ")", ":", "\n", "    ", "nFrms", ",", "nClass", "=", "input_tensor", ".", "shape", "[", "0", "]", ",", "input_tensor", ".", "shape", "[", "1", "]", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds": [[21, 58], ["range", "pandas.DataFrame", "c_preds.transpose().detach().cpu().numpy", "scipy.ndimage.filters.median_filter", "encoder.decode_strong", "pandas.DataFrame", "prediction_dfs[].append", "int", "c_preds.transpose().detach().cpu", "pathlib.Path", "pad_indx[].item", "c_preds.transpose().detach", "c_preds.transpose"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.decode_strong"], ["\n", "pad_length", "=", "(", "win_length", "-", "1", ")", "//", "2", "\n", "output_tensor", "=", "torch", ".", "zeros", "(", "nFrms", ",", "nClass", ")", ".", "cuda", "(", ")", "\n", "for", "cter", "in", "range", "(", "nClass", ")", ":", "\n", "        ", "tensor1D", "=", "input_tensor", "[", ":", ",", "cter", "]", "\n", "indices", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "tensor1D", ",", "(", "pad_length", ",", "0", ")", ",", "mode", "=", "\"constant\"", ",", "value", "=", "0.", ")", "\n", "indices", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "indices", ",", "(", "0", ",", "pad_length", ")", ",", "mode", "=", "\"constant\"", ",", "value", "=", "0.", ")", "\n", "indices", "[", "...", ",", ":", "pad_length", "]", "=", "torch", ".", "cat", "(", "pad_length", "*", "[", "indices", "[", "...", ",", "pad_length", "]", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "roll", "=", "indices", ".", "unfold", "(", "-", "1", ",", "win_length", ",", "1", ")", "\n", "values", ",", "_", "=", "torch", ".", "median", "(", "roll", ",", "-", "1", ")", "\n", "output_tensor", "[", ":", ",", "cter", "]", "=", "values", "[", ":", "nFrms", "]", "\n", "\n", "", "return", "output_tensor", "\n", "\n", "\n", "", "def", "read_audio", "(", "path", ",", "target_fs", "=", "None", ")", ":", "\n", "    ", "\"\"\" Read a wav file\n    Args:\n        path: str, path of the audio file\n        target_fs: int, (Default value = None) sampling rate of the returned audio file, if not specified, the sampling\n            rate of the audio file is taken\n\n    Returns:\n        tuple\n        (numpy.array, sampling rate), array containing the audio at the sampling rate given\n\n    \"\"\"", "\n", "(", "audio", ",", "fs", ")", "=", "soundfile", ".", "read", "(", "path", ")", "\n", "if", "audio", ".", "ndim", ">", "1", ":", "\n", "        ", "audio", "=", "np", ".", "mean", "(", "audio", ",", "axis", "=", "1", ")", "\n", "", "if", "target_fs", "is", "not", "None", "and", "fs", "!=", "target_fs", ":", "\n", "        ", "audio", "=", "librosa", ".", "resample", "(", "audio", ",", "orig_sr", "=", "fs", ",", "target_sr", "=", "target_fs", ")", "\n", "fs", "=", "target_fs", "\n", "", "return", "audio", ",", "fs", "\n", "\n", "\n", "", "def", "weights_init", "(", "m", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.convert_to_event_based": [[60, 80], ["weak_dataframe.iterrows", "pandas.DataFrame", "r[].split", "new.append"], "function", ["None"], ["\n", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Conv2d'", ")", "!=", "-", "1", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ",", "gain", "=", "np", ".", "sqrt", "(", "2", ")", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "elif", "classname", ".", "find", "(", "'BatchNorm'", ")", "!=", "-", "1", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "1.0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "elif", "classname", ".", "find", "(", "'GRU'", ")", "!=", "-", "1", ":", "\n", "        ", "for", "weight", "in", "m", ".", "parameters", "(", ")", ":", "\n", "            ", "if", "len", "(", "weight", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "nn", ".", "init", ".", "orthogonal_", "(", "weight", ".", "data", ")", "\n", "", "", "", "elif", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "0.01", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n", "\n", "", "", "def", "to_cuda_if_available", "(", "*", "args", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics": [[82, 112], ["pandas.read_csv", "desed_task.evaluation.evaluation_measures.compute_sed_eval_metrics", "os.makedirs", "open", "f.write", "open", "f.write", "os.path.join", "str", "os.path.join", "str", "event_res.results", "event_res.results", "segment_res.results", "segment_res.results"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_sed_eval_metrics"], ["\n", "res", "=", "list", "(", "args", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "for", "i", ",", "torch_obj", "in", "enumerate", "(", "args", ")", ":", "\n", "            ", "res", "[", "i", "]", "=", "torch_obj", ".", "cuda", "(", ")", "\n", "", "", "if", "len", "(", "res", ")", "==", "1", ":", "\n", "        ", "return", "res", "[", "0", "]", "\n", "", "return", "res", "\n", "\n", "\n", "", "class", "SaveBest", ":", "\n", "    ", "\"\"\" Callback to get the best value and epoch\n    Args:\n        val_comp: str, (Default value = \"inf\") \"inf\" or \"sup\", inf when we store the lowest model, sup when we\n            store the highest model\n    Attributes:\n        val_comp: str, \"inf\" or \"sup\", inf when we store the lowest model, sup when we\n            store the highest model\n        best_val: float, the best values of the model based on the criterion chosen\n        best_epoch: int, the epoch when the model was the best\n        current_epoch: int, the current epoch of the model\n    \"\"\"", "\n", "def", "__init__", "(", "self", ",", "val_comp", "=", "\"inf\"", ")", ":", "\n", "        ", "self", ".", "comp", "=", "val_comp", "\n", "if", "val_comp", "in", "[", "\"inf\"", ",", "\"lt\"", ",", "\"desc\"", "]", ":", "\n", "            ", "self", ".", "best_val", "=", "np", ".", "inf", "\n", "", "elif", "val_comp", "in", "[", "\"sup\"", ",", "\"gt\"", ",", "\"asc\"", "]", ":", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.parse_jams": [[115, 170], ["os.makedirs", "len", "IndexError", "enumerate", "open", "json.dump", "open", "json.load", "len", "len", "os.path.join", "pathlib.Path", "pathlib.Path", "backgrounds.append", "sources.append", "pathlib.Path", "[].startswith", "pathlib.Path", "[].startswith"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.load"], ["            ", "raise", "NotImplementedError", "(", "\"value comparison is only 'inf' or 'sup'\"", ")", "\n", "", "self", ".", "best_epoch", "=", "0", "\n", "self", ".", "current_epoch", "=", "0", "\n", "\n", "", "def", "apply", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\" Apply the callback\n        Args:\n            value: float, the value of the metric followed\n        \"\"\"", "\n", "decision", "=", "False", "\n", "if", "self", ".", "current_epoch", "==", "0", ":", "\n", "            ", "decision", "=", "True", "\n", "", "if", "(", "self", ".", "comp", "==", "\"inf\"", "and", "value", "<", "self", ".", "best_val", ")", "or", "(", "self", ".", "comp", "==", "\"sup\"", "and", "value", ">", "self", ".", "best_val", ")", ":", "\n", "            ", "self", ".", "best_epoch", "=", "self", ".", "current_epoch", "\n", "self", ".", "best_val", "=", "value", "\n", "decision", "=", "True", "\n", "", "self", ".", "current_epoch", "+=", "1", "\n", "return", "decision", "\n", "\n", "\n", "", "", "class", "JSD", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "JSD", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "kld", "=", "nn", ".", "KLDivLoss", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "", "def", "apply", "(", "self", ",", "p", ",", "q", ")", ":", "\n", "        ", "m", "=", "0.5", "*", "(", "p", "+", "q", ")", "\n", "return", "-", "0.5", "*", "(", "self", ".", "kld", "(", "p", ",", "m", ")", "+", "self", ".", "kld", "(", "q", ",", "m", ")", ")", "\n", "\n", "", "", "class", "Entropy", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Entropy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "dim", ")", ":", "\n", "        ", "b", "=", "x", "*", "torch", ".", "log", "(", "x", ")", "\n", "b", "=", "-", "1.0", "*", "b", ".", "sum", "(", "dim", ")", "\n", "return", "b", "\n", "\n", "", "", "class", "EarlyStopping", ":", "\n", "    ", "\"\"\" Callback to stop training if the metric have not improved during multiple epochs.\n    Args:\n        patience: int, number of epochs with no improvement before stopping the model\n        val_comp: str, (Default value = \"inf\") \"inf\" or \"sup\", inf when we store the lowest model, sup when we\n            store the highest model\n    Attributes:\n        patience: int, number of epochs with no improvement before stopping the model\n        val_comp: str, \"inf\" or \"sup\", inf when we store the lowest model, sup when we\n            store the highest model\n        best_val: float, the best values of the model based on the criterion chosen\n        best_epoch: int, the epoch when the model was the best\n        current_epoch: int, the current epoch of the model\n    \"\"\"", "\n", "def", "__init__", "(", "self", ",", "patience", ",", "val_comp", "=", "\"inf\"", ",", "init_patience", "=", "0", ")", ":", "\n", "        ", "self", ".", "patience", "=", "patience", "\n", "self", ".", "first_early_wait", "=", "init_patience", "\n", "self", ".", "val_comp", "=", "val_comp", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.generate_tsv_wav_durations": [[172, 192], ["glob.glob", "pandas.DataFrame", "os.path.join", "meta_list.append", "pd.DataFrame.to_csv", "soundfile.info", "os.path.basename"], "function", ["None"], ["            ", "self", ".", "best_val", "=", "np", ".", "inf", "\n", "", "elif", "val_comp", "==", "\"sup\"", ":", "\n", "            ", "self", ".", "best_val", "=", "0", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"value comparison is only 'inf' or 'sup'\"", ")", "\n", "", "self", ".", "current_epoch", "=", "0", "\n", "self", ".", "best_epoch", "=", "0", "\n", "\n", "", "def", "apply", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\" Apply the callback\n\n        Args:\n            value: the value of the metric followed\n        \"\"\"", "\n", "current", "=", "False", "\n", "if", "self", ".", "val_comp", "==", "\"inf\"", ":", "\n", "            ", "if", "value", "<", "self", ".", "best_val", ":", "\n", "                ", "current", "=", "True", "\n", "", "", "if", "self", ".", "val_comp", "==", "\"sup\"", ":", "\n", "            ", "if", "value", ">", "self", ".", "best_val", ":", "\n", "                ", "current", "=", "True", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__": [[44, 148], ["pytorch_lightning.LightningModule.__init__", "copy.deepcopy", "torch.nn.Softmax", "utils.JSD", "torch.tensor().cuda", "torchaudio.transforms.MelSpectrogram", "sed_trainer_SRST.SEDTask4_2021.sed_teacher.parameters", "torch.nn.BCELoss", "pytorch_lightning.metrics.classification.F1", "pytorch_lightning.metrics.classification.F1", "sed_trainer_SRST.SEDTask4_2021._init_scaler", "numpy.arange", "pandas.DataFrame", "pandas.DataFrame", "param.detach_", "torch.nn.MSELoss", "len", "len", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame", "torch.tensor", "torch.nn.BCELoss"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.__init__", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021._init_scaler"], ["def", "__init__", "(", "\n", "self", ",", "\n", "hparams", ",", "\n", "encoder", ",", "\n", "sed_student", ",", "\n", "opt", "=", "None", ",", "\n", "train_data", "=", "None", ",", "\n", "valid_data", "=", "None", ",", "\n", "test_data", "=", "None", ",", "\n", "train_sampler", "=", "None", ",", "\n", "scheduler", "=", "None", ",", "\n", "fast_dev_run", "=", "False", ",", "\n", ")", ":", "\n", "        ", "super", "(", "SEDTask4_2021", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hparams", "=", "hparams", "\n", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "sed_student", "=", "sed_student", "\n", "self", ".", "sed_teacher", "=", "deepcopy", "(", "sed_student", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "train_data", "=", "train_data", "\n", "self", ".", "valid_data", "=", "valid_data", "\n", "self", ".", "test_data", "=", "test_data", "\n", "self", ".", "train_sampler", "=", "train_sampler", "\n", "self", ".", "scheduler", "=", "scheduler", "\n", "self", ".", "fast_dev_run", "=", "fast_dev_run", "\n", "if", "self", ".", "fast_dev_run", ":", "\n", "            ", "self", ".", "num_workers", "=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_workers", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"num_workers\"", "]", "\n", "\n", "# add class_label", "\n", "", "self", ".", "softmax", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "self", ".", "jsd", "=", "JSD", "(", ")", "\n", "self", ".", "class_label", "=", "torch", ".", "tensor", "(", "cfg", ".", "class_label", ")", ".", "cuda", "(", ")", "\n", "\n", "feat_params", "=", "self", ".", "hparams", "[", "\"feats\"", "]", "\n", "self", ".", "mel_spec", "=", "MelSpectrogram", "(", "\n", "sample_rate", "=", "feat_params", "[", "\"sample_rate\"", "]", ",", "\n", "n_fft", "=", "feat_params", "[", "\"n_window\"", "]", ",", "\n", "win_length", "=", "feat_params", "[", "\"n_window\"", "]", ",", "\n", "hop_length", "=", "feat_params", "[", "\"hop_length\"", "]", ",", "\n", "f_min", "=", "feat_params", "[", "\"f_min\"", "]", ",", "\n", "f_max", "=", "feat_params", "[", "\"f_max\"", "]", ",", "\n", "n_mels", "=", "feat_params", "[", "\"n_mels\"", "]", ",", "\n", "window_fn", "=", "torch", ".", "hamming_window", ",", "\n", "wkwargs", "=", "{", "\"periodic\"", ":", "False", "}", ",", "\n", "power", "=", "1", ",", "\n", ")", "\n", "\n", "for", "param", "in", "self", ".", "sed_teacher", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "detach_", "(", ")", "\n", "\n", "# instantiating losses", "\n", "", "self", ".", "supervised_loss", "=", "torch", ".", "nn", ".", "BCELoss", "(", ")", "\n", "if", "hparams", "[", "\"training\"", "]", "[", "\"self_sup_loss\"", "]", "==", "\"mse\"", ":", "\n", "            ", "self", ".", "selfsup_loss", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "\n", "", "elif", "hparams", "[", "\"training\"", "]", "[", "\"self_sup_loss\"", "]", "==", "\"bce\"", ":", "\n", "            ", "self", ".", "selfsup_loss", "=", "torch", ".", "nn", ".", "BCELoss", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "# for weak labels we simply compute f1 score", "\n", "", "self", ".", "get_weak_student_f1_seg_macro", "=", "pl", ".", "metrics", ".", "classification", ".", "F1", "(", "\n", "len", "(", "self", ".", "encoder", ".", "labels", ")", ",", "\n", "average", "=", "\"macro\"", ",", "\n", "multilabel", "=", "True", ",", "\n", "compute_on_step", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "get_weak_teacher_f1_seg_macro", "=", "pl", ".", "metrics", ".", "classification", ".", "F1", "(", "\n", "len", "(", "self", ".", "encoder", ".", "labels", ")", ",", "\n", "average", "=", "\"macro\"", ",", "\n", "multilabel", "=", "True", ",", "\n", "compute_on_step", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "scaler", "=", "self", ".", "_init_scaler", "(", ")", "\n", "\n", "# buffer for event based scores which we compute using sed-eval", "\n", "\n", "self", ".", "val_buffer_student_synth", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "self", ".", "val_buffer_teacher_synth", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "\n", "self", ".", "val_buffer_student_test", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "self", ".", "val_buffer_teacher_test", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "\n", "test_n_thresholds", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"n_test_thresholds\"", "]", "\n", "test_thresholds", "=", "np", ".", "arange", "(", "\n", "1", "/", "(", "test_n_thresholds", "*", "2", ")", ",", "1", ",", "1", "/", "test_n_thresholds", "\n", ")", "\n", "self", ".", "test_psds_buffer_student", "=", "{", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "test_thresholds", "}", "\n", "self", ".", "test_psds_buffer_teacher", "=", "{", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "test_thresholds", "}", "\n", "\n", "self", ".", "decoded_student_05_buffer", "=", "pd", ".", "DataFrame", "(", ")", "\n", "self", ".", "decoded_teacher_05_buffer", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.update_ema": [[149, 162], ["min", "zip", "ema_model.parameters", "model.parameters", "ema_params.data.mul_().add_", "ema_params.data.mul_"], "methods", ["None"], ["", "def", "update_ema", "(", "self", ",", "alpha", ",", "global_step", ",", "model", ",", "ema_model", ")", ":", "\n", "        ", "\"\"\" Update teacher model parameters\n\n        Args:\n            alpha: float, the factor to be used between each updated step.\n            global_step: int, the current global step to be used.\n            model: torch.Module, student model to use\n            ema_model: torch.Module, teacher model to use\n        \"\"\"", "\n", "# Use the true average until the exponential average is more correct", "\n", "alpha", "=", "min", "(", "1", "-", "1", "/", "(", "global_step", "+", "1", ")", ",", "alpha", ")", "\n", "for", "ema_params", ",", "params", "in", "zip", "(", "ema_model", ".", "parameters", "(", ")", ",", "model", ".", "parameters", "(", ")", ")", ":", "\n", "            ", "ema_params", ".", "data", ".", "mul_", "(", "alpha", ")", ".", "add_", "(", "params", ".", "data", ",", "alpha", "=", "1", "-", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021._init_scaler": [[163, 210], ["sed_trainer_SRST.SEDTask4_2021.train_dataloader", "torch.load.fit", "desed_task.utils.scaler.TorchScaler", "os.path.exists", "torch.save", "print", "desed_task.utils.scaler.TorchScaler", "torch.load", "print", "sed_trainer_SRST.SEDTask4_2021.take_log", "sed_trainer_SRST.SEDTask4_2021.mel_spec"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.train_dataloader", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.scaler.TorchScaler.fit", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.save", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.ScalerPerAudio.load", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.take_log"], ["", "", "def", "_init_scaler", "(", "self", ")", ":", "\n", "        ", "\"\"\"Scaler inizialization\n\n        Raises:\n            NotImplementedError: in case of not Implemented scaler\n\n        Returns:\n            TorchScaler: returns the scaler\n        \"\"\"", "\n", "\n", "if", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"statistic\"", "]", "==", "\"instance\"", ":", "\n", "            ", "scaler", "=", "TorchScaler", "(", "\"instance\"", ",", "\"minmax\"", ",", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"dims\"", "]", ")", "\n", "\n", "return", "scaler", "\n", "", "elif", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"statistic\"", "]", "==", "\"dataset\"", ":", "\n", "# we fit the scaler", "\n", "            ", "scaler", "=", "TorchScaler", "(", "\n", "\"dataset\"", ",", "\n", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"normtype\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"dims\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "if", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", "is", "not", "None", ":", "\n", "            ", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", ")", ":", "\n", "                ", "scaler", "=", "torch", ".", "load", "(", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", ")", "\n", "print", "(", "\n", "\"Loaded Scaler from previous checkpoint from {}\"", ".", "format", "(", "\n", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", "\n", ")", "\n", ")", "\n", "return", "scaler", "\n", "\n", "", "", "self", ".", "train_loader", "=", "self", ".", "train_dataloader", "(", ")", "\n", "scaler", ".", "fit", "(", "\n", "self", ".", "train_loader", ",", "\n", "transform_func", "=", "lambda", "x", ":", "self", ".", "take_log", "(", "self", ".", "mel_spec", "(", "x", "[", "0", "]", ")", ")", ",", "\n", ")", "\n", "\n", "if", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", "is", "not", "None", ":", "\n", "            ", "torch", ".", "save", "(", "scaler", ",", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", ")", "\n", "print", "(", "\n", "\"Saving Scaler from previous checkpoint at {}\"", ".", "format", "(", "\n", "self", ".", "hparams", "[", "\"scaler\"", "]", "[", "\"savepath\"", "]", "\n", ")", "\n", ")", "\n", "return", "scaler", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.take_log": [[211, 223], ["torchaudio.transforms.AmplitudeToDB", "torchaudio.transforms.AmplitudeToDB.clamp", "torchaudio.transforms.AmplitudeToDB."], "methods", ["None"], ["", "", "def", "take_log", "(", "self", ",", "mels", ")", ":", "\n", "        ", "\"\"\" Apply the log transformation to mel spectrograms.\n        Args:\n            mels: torch.Tensor, mel spectrograms for which to apply log.\n\n        Returns:\n            Tensor: logarithmic mel spectrogram of the mel spectrogram given as input\n        \"\"\"", "\n", "\n", "amp_to_db", "=", "AmplitudeToDB", "(", "stype", "=", "\"amplitude\"", ")", "\n", "amp_to_db", ".", "amin", "=", "1e-5", "# amin= 1e-5 as in librosa", "\n", "return", "amp_to_db", "(", "mels", ")", ".", "clamp", "(", "min", "=", "-", "50", ",", "max", "=", "80", ")", "# clamp to reproduce old code", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.training_step": [[224, 363], ["sed_trainer_SRST.SEDTask4_2021.mel_spec", "torch.zeros().to().bool", "torch.zeros().to().bool", "sed_trainer_SRST.SEDTask4_2021.hparams[].get", "sed_trainer_SRST.SEDTask4_2021.sed_student", "sed_trainer_SRST.SEDTask4_2021.supervised_loss", "sed_trainer_SRST.SEDTask4_2021.supervised_loss", "sed_trainer_SRST.SEDTask4_2021.selfsup_loss", "sed_trainer_SRST.SEDTask4_2021.selfsup_loss", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "desed_task.data_augm.mixup", "desed_task.data_augm.mixup", "sed_trainer_SRST.SEDTask4_2021.scaler", "torch.no_grad", "sed_trainer_SRST.SEDTask4_2021.scaler", "sed_trainer_SRST.SEDTask4_2021.sed_teacher", "torch.zeros().cuda", "range", "est_strong_target.permute.permute.permute", "est_strong_target.permute.permute.mean", "sed_trainer_SRST.SEDTask4_2021.supervised_loss", "sed_trainer_SRST.SEDTask4_2021.supervised_loss", "sed_trainer_SRST.SEDTask4_2021.scheduler[]._get_scaling_factor", "torch.zeros().to", "torch.zeros().to", "random.random", "sed_trainer_SRST.SEDTask4_2021.take_log", "sed_trainer_SRST.SEDTask4_2021.take_log", "torch.clamp", "torch.log", "torch.log", "torch.log.sum", "range", "torch.cat", "range", "torch.cat", "torch.cat", "sed_trainer_SRST.SEDTask4_2021.softmax", "torch.sort", "prob_v.sum", "torch.mul().sum", "torch.squeeze", "sed_trainer_SRST.SEDTask4_2021.jsd().mean", "sed_trainer_SRST.SEDTask4_2021.jsd().mean", "torch.sum", "desed_task.data_augm.add_noise", "torch.zeros", "torch.clamp.permute", "torch.cat.append", "range", "torch.zeros", "torch.zeros", "torch.clamp.permute", "torch.cat.append", "torch.log.sum.reshape", "torch.mul", "sed_trainer_SRST.SEDTask4_2021.jsd", "sed_trainer_SRST.SEDTask4_2021.jsd", "prob_i.tolist"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.desed_task.data_augm.mixup", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.desed_task.data_augm.mixup", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.schedulers.ExponentialWarmup._get_scaling_factor", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.take_log", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.take_log", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.desed_task.data_augm.add_noise"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_indx", ")", ":", "\n", "        ", "\"\"\" Applying the training for one batch (a step). Used during trainer.fit\n\n        Args:\n            batch: torch.Tensor, batch input tensor\n            batch_indx: torch.Tensor, 1D tensor of indexes to know which data are present in each batch.\n\n        Returns:\n           torch.Tensor, the loss to take into account.\n        \"\"\"", "\n", "\n", "audio", ",", "labels", ",", "padded_indxs", "=", "batch", "\n", "indx_synth", ",", "indx_weak", ",", "indx_unlabelled", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"batch_size\"", "]", "\n", "features", "=", "self", ".", "mel_spec", "(", "audio", ")", "\n", "\n", "batch_num", "=", "features", ".", "shape", "[", "0", "]", "\n", "# deriving masks for each dataset", "\n", "strong_mask", "=", "torch", ".", "zeros", "(", "batch_num", ")", ".", "to", "(", "features", ")", ".", "bool", "(", ")", "\n", "weak_mask", "=", "torch", ".", "zeros", "(", "batch_num", ")", ".", "to", "(", "features", ")", ".", "bool", "(", ")", "\n", "strong_mask", "[", ":", "indx_synth", "]", "=", "1", "\n", "weak_mask", "[", "indx_synth", ":", "indx_weak", "+", "indx_synth", "]", "=", "1", "\n", "\n", "# deriving weak labels", "\n", "labels_weak", "=", "(", "torch", ".", "sum", "(", "labels", "[", "weak_mask", "]", ",", "-", "1", ")", ">", "0", ")", ".", "float", "(", ")", "\n", "\n", "mixup_type", "=", "self", ".", "hparams", "[", "\"training\"", "]", ".", "get", "(", "\"mixup\"", ")", "\n", "if", "mixup_type", "is", "not", "None", "and", "0.5", ">", "random", ".", "random", "(", ")", ":", "\n", "            ", "features", "[", "weak_mask", "]", ",", "labels_weak", "=", "mixup", "(", "\n", "features", "[", "weak_mask", "]", ",", "labels_weak", ",", "mixup_label_type", "=", "mixup_type", "\n", ")", "\n", "features", "[", "strong_mask", "]", ",", "labels", "[", "strong_mask", "]", "=", "mixup", "(", "\n", "features", "[", "strong_mask", "]", ",", "labels", "[", "strong_mask", "]", ",", "mixup_label_type", "=", "mixup_type", "\n", ")", "\n", "\n", "# sed students forward", "\n", "", "strong_preds_student", ",", "weak_preds_student", "=", "self", ".", "sed_student", "(", "\n", "self", ".", "scaler", "(", "self", ".", "take_log", "(", "features", ")", ")", "\n", ")", "\n", "\n", "# supervised loss on strong labels", "\n", "loss_strong", "=", "self", ".", "supervised_loss", "(", "\n", "strong_preds_student", "[", "strong_mask", "]", ",", "labels", "[", "strong_mask", "]", "\n", ")", "\n", "# supervised loss on weakly labelled", "\n", "loss_weak", "=", "self", ".", "supervised_loss", "(", "weak_preds_student", "[", "weak_mask", "]", ",", "labels_weak", ")", "\n", "# total supervised loss", "\n", "tot_loss_supervised", "=", "loss_strong", "+", "loss_weak", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# perturbation", "\n", "            ", "ema_features", "=", "self", ".", "scaler", "(", "self", ".", "take_log", "(", "add_noise", "(", "features", ")", ")", ")", "\n", "strong_preds_teacher", ",", "weak_preds_teacher", "=", "self", ".", "sed_teacher", "(", "ema_features", ")", "\n", "\n", "nClass", "=", "self", ".", "hparams", "[", "'net'", "]", "[", "'nclass'", "]", "\n", "est_strong_target", "=", "torch", ".", "zeros", "(", "batch_num", ",", "156", ",", "nClass", ")", ".", "cuda", "(", ")", "\n", "for", "bter", "in", "range", "(", "batch_num", ")", ":", "\n", "                ", "sp", "=", "strong_preds_teacher", "[", "bter", "]", "\n", "sp", "=", "torch", ".", "clamp", "(", "sp", ",", "1.0e-4", ",", "1", "-", "1.0e-4", ")", "\n", "p_h1", "=", "torch", ".", "log", "(", "sp", ".", "permute", "(", "(", "1", ",", "0", ")", ")", ")", "\n", "p_h0", "=", "torch", ".", "log", "(", "1", "-", "sp", ".", "permute", "(", "1", ",", "0", ")", ")", "\n", "\n", "# K = 0", "\n", "P0", "=", "p_h0", ".", "sum", "(", "1", ")", "\n", "\n", "# K = 1", "\n", "P1", "=", "P0", "[", ":", ",", "None", "]", "+", "p_h1", "-", "p_h0", "\n", "#P  = torch.cat([P0.reshape(157,1), P1], 1)", "\n", "\n", "# K = 2", "\n", "P2", "=", "[", "]", "\n", "for", "cter", "in", "range", "(", "1", ",", "nClass", ")", ":", "\n", "                    ", "P2", ".", "append", "(", "P1", "[", ":", ",", ":", "-", "cter", "]", "+", "P1", "[", ":", ",", "cter", ":", "]", ")", "\n", "", "P2", "=", "torch", ".", "cat", "(", "P2", ",", "1", ")", "\n", "P2", "=", "P2", "-", "P0", "[", ":", ",", "None", "]", "\n", "#P = torch.cat([P0.reshape(156,1), P1, P2], 1)", "\n", "\n", "# K: up to 3", "\n", "P3", "=", "[", "]", "\n", "for", "cter1", "in", "range", "(", "1", ",", "nClass", ")", ":", "\n", "                    ", "for", "cter2", "in", "range", "(", "1", ",", "nClass", "-", "cter1", ")", ":", "\n", "                        ", "P3", ".", "append", "(", "P1", "[", ":", ",", ":", "-", "(", "cter1", "+", "cter2", ")", "]", "+", "P1", "[", ":", ",", "cter1", ":", "-", "cter2", "]", "+", "P1", "[", ":", ",", "(", "cter1", "+", "cter2", ")", ":", "]", ")", "\n", "", "", "P3", "=", "torch", ".", "cat", "(", "P3", ",", "1", ")", "\n", "P3", "=", "P3", "-", "2", "*", "P0", "[", ":", ",", "None", "]", "\n", "P", "=", "torch", ".", "cat", "(", "[", "P0", ".", "reshape", "(", "156", ",", "1", ")", ",", "P1", ",", "P2", ",", "P3", "]", ",", "1", ")", "\n", "\n", "P", "=", "self", ".", "softmax", "(", "P", ")", "\n", "prob_v", ",", "prob_i", "=", "torch", ".", "sort", "(", "P", ",", "dim", "=", "1", ",", "descending", "=", "True", ")", "\n", "\n", "norm_p", "=", "prob_v", ".", "sum", "(", "1", ")", "\n", "prob_v", "=", "prob_v", "/", "norm_p", "[", ":", ",", "None", "]", "\n", "\n", "cl", "=", "self", ".", "class_label", "[", "prob_i", ".", "tolist", "(", ")", ",", ":", "]", "\n", "cl", "=", "torch", ".", "mul", "(", "cl", ",", "prob_v", "[", ":", ",", ":", ",", "None", "]", ")", ".", "sum", "(", "1", ")", "\n", "\n", "est_strong_target", "[", "bter", ",", ":", ",", ":", "]", "=", "torch", ".", "squeeze", "(", "cl", "[", ":", "156", ",", ":", "]", ")", "\n", "\n", "", "est_strong_target", "=", "est_strong_target", ".", "permute", "(", "(", "0", ",", "2", ",", "1", ")", ")", "\n", "est_weak_target", "=", "est_strong_target", ".", "mean", "(", "2", ")", "\n", "\n", "loss_strong_teacher", "=", "self", ".", "supervised_loss", "(", "\n", "strong_preds_teacher", "[", "strong_mask", "]", ",", "labels", "[", "strong_mask", "]", "\n", ")", "\n", "\n", "loss_weak_teacher", "=", "self", ".", "supervised_loss", "(", "\n", "weak_preds_teacher", "[", "weak_mask", "]", ",", "labels_weak", "\n", ")", "\n", "# we apply consistency between the predictions, use the scheduler for learning rate (to be changed ?)", "\n", "", "weight", "=", "(", "\n", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"const_max\"", "]", "\n", "*", "self", ".", "scheduler", "[", "\"scheduler\"", "]", ".", "_get_scaling_factor", "(", ")", "\n", ")", "\n", "\n", "strong_reliability", "=", "weight", "*", "(", "1", "-", "self", ".", "jsd", "(", "est_strong_target", "[", "strong_mask", "]", ",", "labels", "[", "strong_mask", "]", ")", ".", "mean", "(", ")", ")", "\n", "weak_reliability", "=", "weight", "*", "(", "1", "-", "self", ".", "jsd", "(", "est_weak_target", "[", "weak_mask", "]", ",", "labels_weak", ")", ".", "mean", "(", ")", ")", "\n", "\n", "strong_self_sup_loss", "=", "self", ".", "selfsup_loss", "(", "\n", "strong_preds_student", "[", "24", ":", "]", ",", "est_strong_target", "[", "24", ":", "]", "\n", ")", "\n", "weak_self_sup_loss", "=", "self", ".", "selfsup_loss", "(", "\n", "weak_preds_student", "[", "weak_mask", "]", ",", "est_weak_target", "[", "weak_mask", "]", "\n", ")", "\n", "tot_self_loss", "=", "strong_reliability", "*", "strong_self_sup_loss", "+", "weak_reliability", "*", "weak_self_sup_loss", "\n", "\n", "tot_loss", "=", "tot_loss_supervised", "+", "tot_self_loss", "\n", "\n", "\n", "self", ".", "log", "(", "\"train/student/loss_strong\"", ",", "loss_strong", ")", "\n", "self", ".", "log", "(", "\"train/student/loss_weak\"", ",", "loss_weak", ")", "\n", "self", ".", "log", "(", "\"train/teacher/loss_strong\"", ",", "loss_strong_teacher", ")", "\n", "self", ".", "log", "(", "\"train/teacher/loss_weak\"", ",", "loss_weak_teacher", ")", "\n", "self", ".", "log", "(", "\"train/step\"", ",", "self", ".", "scheduler", "[", "\"scheduler\"", "]", ".", "step_num", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"train/student/tot_loss\"", ",", "tot_loss", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"train/weight\"", ",", "weight", ")", "\n", "self", ".", "log", "(", "\"train/student/tot_supervised\"", ",", "strong_self_sup_loss", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"train/student/weak_self_sup_loss\"", ",", "weak_self_sup_loss", ")", "\n", "self", ".", "log", "(", "\"train/student/strong_self_sup_loss\"", ",", "strong_self_sup_loss", ")", "\n", "self", ".", "log", "(", "\"train/lr\"", ",", "self", ".", "opt", ".", "param_groups", "[", "-", "1", "]", "[", "\"lr\"", "]", ",", "prog_bar", "=", "True", ")", "\n", "\n", "return", "{", "'loss'", ":", "tot_loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.on_before_zero_grad": [[364, 371], ["sed_trainer_SRST.SEDTask4_2021.update_ema"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.update_ema"], ["", "def", "on_before_zero_grad", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# update EMA teacher", "\n", "        ", "self", ".", "update_ema", "(", "\n", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"ema_factor\"", "]", ",", "\n", "self", ".", "scheduler", "[", "\"scheduler\"", "]", ".", "step_num", ",", "\n", "self", ".", "sed_student", ",", "\n", "self", ".", "sed_teacher", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.validation_step": [[373, 476], ["sed_trainer_SRST.SEDTask4_2021.scaler", "sed_trainer_SRST.SEDTask4_2021.sed_student", "sed_trainer_SRST.SEDTask4_2021.sed_teacher", "torch.tensor().to().bool", "torch.tensor().to().bool", "torch.any", "torch.any", "sed_trainer_SRST.SEDTask4_2021.take_log", "sed_trainer_SRST.SEDTask4_2021.supervised_loss", "sed_trainer_SRST.SEDTask4_2021.supervised_loss", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.get_weak_student_f1_seg_macro", "sed_trainer_SRST.SEDTask4_2021.get_weak_teacher_f1_seg_macro", "sed_trainer_SRST.SEDTask4_2021.supervised_loss", "sed_trainer_SRST.SEDTask4_2021.supervised_loss", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "utils.batched_decode_preds", "sed_trainer_SRST.SEDTask4_2021.val_buffer_student_synth.keys", "utils.batched_decode_preds", "sed_trainer_SRST.SEDTask4_2021.val_buffer_teacher_synth.keys", "sed_trainer_SRST.SEDTask4_2021.mel_spec", "torch.tensor().to", "torch.tensor().to", "sed_trainer_SRST.SEDTask4_2021.val_buffer_student_synth[].append", "sed_trainer_SRST.SEDTask4_2021.val_buffer_teacher_synth[].append", "list", "list", "torch.tensor", "torch.tensor", "torch.sum", "pathlib.Path", "sed_trainer_SRST.SEDTask4_2021.val_buffer_student_synth.keys", "sed_trainer_SRST.SEDTask4_2021.val_buffer_teacher_synth.keys", "pathlib.Path", "str", "str", "str", "str", "pathlib.Path", "pathlib.Path", "pathlib.Path", "pathlib.Path"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.take_log", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_indx", ")", ":", "\n", "        ", "\"\"\" Apply validation to a batch (step). Used during trainer.fit\n\n        Args:\n            batch: torch.Tensor, input batch tensor\n            batch_indx: torch.Tensor, 1D tensor of indexes to know which data are present in each batch.\n        Returns:\n        \"\"\"", "\n", "\n", "audio", ",", "labels", ",", "padded_indxs", ",", "filenames", "=", "batch", "\n", "\n", "# prediction for student", "\n", "logmels", "=", "self", ".", "scaler", "(", "self", ".", "take_log", "(", "self", ".", "mel_spec", "(", "audio", ")", ")", ")", "\n", "strong_preds_student", ",", "weak_preds_student", "=", "self", ".", "sed_student", "(", "logmels", ")", "\n", "# prediction for teacher", "\n", "strong_preds_teacher", ",", "weak_preds_teacher", "=", "self", ".", "sed_teacher", "(", "logmels", ")", "\n", "\n", "# we derive masks for each dataset based on folders of filenames", "\n", "mask_weak", "=", "(", "\n", "torch", ".", "tensor", "(", "\n", "[", "\n", "str", "(", "Path", "(", "x", ")", ".", "parent", ")", "\n", "==", "str", "(", "Path", "(", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"weak_folder\"", "]", ")", ")", "\n", "for", "x", "in", "filenames", "\n", "]", "\n", ")", "\n", ".", "to", "(", "audio", ")", "\n", ".", "bool", "(", ")", "\n", ")", "\n", "mask_synth", "=", "(", "\n", "torch", ".", "tensor", "(", "\n", "[", "\n", "str", "(", "Path", "(", "x", ")", ".", "parent", ")", "\n", "==", "str", "(", "Path", "(", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_folder\"", "]", ")", ")", "\n", "for", "x", "in", "filenames", "\n", "]", "\n", ")", "\n", ".", "to", "(", "audio", ")", "\n", ".", "bool", "(", ")", "\n", ")", "\n", "\n", "if", "torch", ".", "any", "(", "mask_weak", ")", ":", "\n", "            ", "labels_weak", "=", "(", "torch", ".", "sum", "(", "labels", "[", "mask_weak", "]", ",", "-", "1", ")", ">=", "1", ")", ".", "float", "(", ")", "\n", "loss_weak_student", "=", "self", ".", "supervised_loss", "(", "\n", "weak_preds_student", "[", "mask_weak", "]", ",", "labels_weak", "\n", ")", "\n", "loss_weak_teacher", "=", "self", ".", "supervised_loss", "(", "\n", "weak_preds_teacher", "[", "mask_weak", "]", ",", "labels_weak", "\n", ")", "\n", "self", ".", "log", "(", "\"val/weak/student/loss_weak\"", ",", "loss_weak_student", ")", "\n", "self", ".", "log", "(", "\"val/weak/teacher/loss_weak\"", ",", "loss_weak_teacher", ")", "\n", "\n", "# accumulate f1 score for weak labels", "\n", "self", ".", "get_weak_student_f1_seg_macro", "(", "\n", "weak_preds_student", "[", "mask_weak", "]", ",", "labels_weak", "\n", ")", "\n", "self", ".", "get_weak_teacher_f1_seg_macro", "(", "\n", "weak_preds_teacher", "[", "mask_weak", "]", ",", "labels_weak", "\n", ")", "\n", "\n", "", "if", "torch", ".", "any", "(", "mask_synth", ")", ":", "\n", "            ", "loss_strong_student", "=", "self", ".", "supervised_loss", "(", "\n", "strong_preds_student", "[", "mask_synth", "]", ",", "labels", "[", "mask_synth", "]", "\n", ")", "\n", "loss_strong_teacher", "=", "self", ".", "supervised_loss", "(", "\n", "strong_preds_teacher", "[", "mask_synth", "]", ",", "labels", "[", "mask_synth", "]", "\n", ")", "\n", "\n", "self", ".", "log", "(", "\"val/synth/student/loss_strong\"", ",", "loss_strong_student", ")", "\n", "self", ".", "log", "(", "\"val/synth/teacher/loss_strong\"", ",", "loss_strong_teacher", ")", "\n", "\n", "filenames_synth", "=", "[", "\n", "x", "\n", "for", "x", "in", "filenames", "\n", "if", "Path", "(", "x", ")", ".", "parent", "==", "Path", "(", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_folder\"", "]", ")", "\n", "]", "\n", "\n", "decoded_student_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_student", "[", "mask_synth", "]", ",", "\n", "filenames_synth", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "val_buffer_student_synth", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "\n", "for", "th", "in", "self", ".", "val_buffer_student_synth", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "val_buffer_student_synth", "[", "th", "]", "=", "self", ".", "val_buffer_student_synth", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_student_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "decoded_teacher_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_teacher", "[", "mask_synth", "]", ",", "\n", "filenames_synth", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "val_buffer_teacher_synth", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "for", "th", "in", "self", ".", "val_buffer_teacher_synth", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "val_buffer_teacher_synth", "[", "th", "]", "=", "self", ".", "val_buffer_teacher_synth", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_teacher_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.validation_epoch_end": [[477, 549], ["sed_trainer_SRST.SEDTask4_2021.get_weak_student_f1_seg_macro.compute", "sed_trainer_SRST.SEDTask4_2021.get_weak_teacher_f1_seg_macro.compute", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "sed_trainer_SRST.SEDTask4_2021.hparams[].get", "torch.tensor", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.get_weak_student_f1_seg_macro.reset", "sed_trainer_SRST.SEDTask4_2021.get_weak_teacher_f1_seg_macro.reset", "utils.log_sedeval_metrics", "utils.log_sedeval_metrics", "pandas.DataFrame", "pandas.DataFrame", "sed_trainer_SRST.SEDTask4_2021.item", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.reset", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.utils.AverageMeter.reset", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "\"\"\" Fonction applied at the end of all the validation steps of the epoch.\n\n        Args:\n            outputs: torch.Tensor, the concatenation of everything returned by validation_step.\n\n        Returns:\n            torch.Tensor, the objective metric to be used to choose the best model from for example.\n        \"\"\"", "\n", "\n", "weak_student_f1_macro", "=", "self", ".", "get_weak_student_f1_seg_macro", ".", "compute", "(", ")", "\n", "weak_teacher_f1_macro", "=", "self", ".", "get_weak_teacher_f1_seg_macro", ".", "compute", "(", ")", "\n", "\n", "# synth dataset", "\n", "intersection_f1_macro_student", "=", "compute_per_intersection_macro_f1", "(", "\n", "self", ".", "val_buffer_student_synth", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_dur\"", "]", ",", "\n", ")", "\n", "\n", "synth_student_event_macro", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "val_buffer_student_synth", "[", "0.5", "]", ",", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_tsv\"", "]", ",", "\n", ")", "[", "0", "]", "\n", "\n", "intersection_f1_macro_teacher", "=", "compute_per_intersection_macro_f1", "(", "\n", "self", ".", "val_buffer_teacher_synth", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_dur\"", "]", ",", "\n", ")", "\n", "\n", "synth_teacher_event_macro", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "val_buffer_teacher_synth", "[", "0.5", "]", ",", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"synth_val_tsv\"", "]", ",", "\n", ")", "[", "0", "]", "\n", "\n", "obj_metric_synth_type", "=", "self", ".", "hparams", "[", "\"training\"", "]", ".", "get", "(", "\"obj_metric_synth_type\"", ")", "\n", "if", "obj_metric_synth_type", "is", "None", ":", "\n", "            ", "synth_metric", "=", "intersection_f1_macro_student", "\n", "", "elif", "obj_metric_synth_type", "==", "\"event\"", ":", "\n", "            ", "synth_metric", "=", "synth_student_event_macro", "\n", "", "elif", "obj_metric_synth_type", "==", "\"intersection\"", ":", "\n", "            ", "synth_metric", "=", "intersection_f1_macro_student", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "f\"obj_metric_synth_type: {obj_metric_synth_type} not implemented.\"", "\n", ")", "\n", "\n", "", "obj_metric", "=", "torch", ".", "tensor", "(", "weak_student_f1_macro", ".", "item", "(", ")", "+", "synth_metric", ")", "\n", "\n", "self", ".", "log", "(", "\"val/obj_metric\"", ",", "obj_metric", ",", "prog_bar", "=", "True", ")", "\n", "self", ".", "log", "(", "\"val/weak/student/macro_F1\"", ",", "weak_student_f1_macro", ")", "\n", "self", ".", "log", "(", "\"val/weak/teacher/macro_F1\"", ",", "weak_teacher_f1_macro", ")", "\n", "self", ".", "log", "(", "\n", "\"val/synth/student/intersection_f1_macro\"", ",", "intersection_f1_macro_student", "\n", ")", "\n", "self", ".", "log", "(", "\n", "\"val/synth/teacher/intersection_f1_macro\"", ",", "intersection_f1_macro_teacher", "\n", ")", "\n", "self", ".", "log", "(", "\"val/synth/student/event_f1_macro\"", ",", "synth_student_event_macro", ")", "\n", "self", ".", "log", "(", "\"val/synth/teacher/event_f1_macro\"", ",", "synth_teacher_event_macro", ")", "\n", "\n", "# free the buffers", "\n", "self", ".", "val_buffer_student_synth", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "self", ".", "val_buffer_teacher_synth", "=", "{", "\n", "k", ":", "pd", ".", "DataFrame", "(", ")", "for", "k", "in", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"val_thresholds\"", "]", "\n", "}", "\n", "\n", "self", ".", "get_weak_student_f1_seg_macro", ".", "reset", "(", ")", "\n", "self", ".", "get_weak_teacher_f1_seg_macro", ".", "reset", "(", ")", "\n", "\n", "return", "obj_metric", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.on_save_checkpoint": [[550, 554], ["sed_trainer_SRST.SEDTask4_2021.sed_student.state_dict", "sed_trainer_SRST.SEDTask4_2021.sed_teacher.state_dict"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utils.encoder.ManyHotEncoder.state_dict"], ["", "def", "on_save_checkpoint", "(", "self", ",", "checkpoint", ")", ":", "\n", "        ", "checkpoint", "[", "\"sed_student\"", "]", "=", "self", ".", "sed_student", ".", "state_dict", "(", ")", "\n", "checkpoint", "[", "\"sed_teacher\"", "]", "=", "self", ".", "sed_teacher", ".", "state_dict", "(", ")", "\n", "return", "checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.test_step": [[555, 628], ["sed_trainer_SRST.SEDTask4_2021.scaler", "sed_trainer_SRST.SEDTask4_2021.sed_student", "sed_trainer_SRST.SEDTask4_2021.sed_teacher", "sed_trainer_SRST.SEDTask4_2021.supervised_loss", "sed_trainer_SRST.SEDTask4_2021.supervised_loss", "sed_trainer_SRST.SEDTask4_2021.log", "sed_trainer_SRST.SEDTask4_2021.log", "utils.batched_decode_preds", "sed_trainer_SRST.SEDTask4_2021.test_psds_buffer_student.keys", "utils.batched_decode_preds", "sed_trainer_SRST.SEDTask4_2021.test_psds_buffer_teacher.keys", "utils.batched_decode_preds", "sed_trainer_SRST.SEDTask4_2021.decoded_student_05_buffer.append", "utils.batched_decode_preds", "sed_trainer_SRST.SEDTask4_2021.decoded_teacher_05_buffer.append", "sed_trainer_SRST.SEDTask4_2021.take_log", "sed_trainer_SRST.SEDTask4_2021.test_psds_buffer_student[].append", "sed_trainer_SRST.SEDTask4_2021.test_psds_buffer_teacher[].append", "sed_trainer_SRST.SEDTask4_2021.mel_spec", "list", "list", "sed_trainer_SRST.SEDTask4_2021.test_psds_buffer_student.keys", "sed_trainer_SRST.SEDTask4_2021.test_psds_buffer_teacher.keys"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.batched_decode_preds", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.take_log"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_indx", ")", ":", "\n", "        ", "\"\"\" Apply Test to a batch (step), used only when (trainer.test is called)\n\n        Args:\n            batch: torch.Tensor, input batch tensor\n            batch_indx: torch.Tensor, 1D tensor of indexes to know which data are present in each batch.\n        Returns:\n        \"\"\"", "\n", "\n", "audio", ",", "labels", ",", "padded_indxs", ",", "filenames", "=", "batch", "\n", "\n", "# prediction for student", "\n", "logmels", "=", "self", ".", "scaler", "(", "self", ".", "take_log", "(", "self", ".", "mel_spec", "(", "audio", ")", ")", ")", "\n", "strong_preds_student", ",", "weak_preds_student", "=", "self", ".", "sed_student", "(", "logmels", ")", "\n", "# prediction for teacher", "\n", "strong_preds_teacher", ",", "weak_preds_teacher", "=", "self", ".", "sed_teacher", "(", "logmels", ")", "\n", "\n", "loss_strong_student", "=", "self", ".", "supervised_loss", "(", "strong_preds_student", ",", "labels", ")", "\n", "loss_strong_teacher", "=", "self", ".", "supervised_loss", "(", "strong_preds_teacher", ",", "labels", ")", "\n", "\n", "self", ".", "log", "(", "\"test/student/loss_strong\"", ",", "loss_strong_student", ")", "\n", "self", ".", "log", "(", "\"test/teacher/loss_strong\"", ",", "loss_strong_teacher", ")", "\n", "\n", "# compute psds", "\n", "decoded_student_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_student", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "test_psds_buffer_student", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "\n", "for", "th", "in", "self", ".", "test_psds_buffer_student", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "test_psds_buffer_student", "[", "th", "]", "=", "self", ".", "test_psds_buffer_student", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_student_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "decoded_teacher_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_teacher", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "list", "(", "self", ".", "test_psds_buffer_teacher", ".", "keys", "(", ")", ")", ",", "\n", ")", "\n", "\n", "for", "th", "in", "self", ".", "test_psds_buffer_teacher", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "test_psds_buffer_teacher", "[", "th", "]", "=", "self", ".", "test_psds_buffer_teacher", "[", "\n", "th", "\n", "]", ".", "append", "(", "decoded_teacher_strong", "[", "th", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "# compute f1 score", "\n", "", "decoded_student_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_student", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "[", "0.5", "]", ",", "\n", ")", "\n", "\n", "self", ".", "decoded_student_05_buffer", "=", "self", ".", "decoded_student_05_buffer", ".", "append", "(", "\n", "decoded_student_strong", "[", "0.5", "]", "\n", ")", "\n", "\n", "decoded_teacher_strong", "=", "batched_decode_preds", "(", "\n", "strong_preds_teacher", ",", "\n", "filenames", ",", "\n", "self", ".", "encoder", ",", "\n", "median_filter", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"median_window\"", "]", ",", "\n", "thresholds", "=", "[", "0.5", "]", ",", "\n", ")", "\n", "\n", "self", ".", "decoded_teacher_05_buffer", "=", "self", ".", "decoded_teacher_05_buffer", ".", "append", "(", "\n", "decoded_teacher_strong", "[", "0.5", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.on_test_epoch_end": [[630, 729], ["os.path.join", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_psds_from_operating_points", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "desed_task.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "torch.tensor", "results.keys", "utils.log_sedeval_metrics", "utils.log_sedeval_metrics", "max", "sed_trainer_SRST.SEDTask4_2021.logger.log_metrics", "sed_trainer_SRST.SEDTask4_2021.logger.log_hyperparams", "sed_trainer_SRST.SEDTask4_2021.log", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.utils.log_sedeval_metrics"], ["", "def", "on_test_epoch_end", "(", "self", ")", ":", "\n", "# pub eval dataset", "\n", "        ", "try", ":", "\n", "            ", "log_dir", "=", "self", ".", "logger", ".", "log_dir", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "log_dir", "=", "self", ".", "hparams", "[", "\"log_dir\"", "]", "\n", "", "save_dir", "=", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"metrics_test\"", ")", "\n", "\n", "psds_score_scenario1", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_student", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.7", ",", "\n", "gtc_threshold", "=", "0.7", ",", "\n", "alpha_ct", "=", "0", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student\"", ",", "\"scenario1\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_scenario2", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_student", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.1", ",", "\n", "gtc_threshold", "=", "0.1", ",", "\n", "cttc_threshold", "=", "0.3", ",", "\n", "alpha_ct", "=", "0.5", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student\"", ",", "\"scenario2\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_teacher_scenario1", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_teacher", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.7", ",", "\n", "gtc_threshold", "=", "0.7", ",", "\n", "alpha_ct", "=", "0", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher\"", ",", "\"scenario1\"", ")", ",", "\n", ")", "\n", "\n", "psds_score_teacher_scenario2", "=", "compute_psds_from_operating_points", "(", "\n", "self", ".", "test_psds_buffer_teacher", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", "dtc_threshold", "=", "0.1", ",", "\n", "gtc_threshold", "=", "0.1", ",", "\n", "cttc_threshold", "=", "0.3", ",", "\n", "alpha_ct", "=", "0.5", ",", "\n", "alpha_st", "=", "1", ",", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher\"", ",", "\"scenario2\"", ")", ",", "\n", ")", "\n", "\n", "event_macro_student", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "decoded_student_05_buffer", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"student\"", ")", ",", "\n", ")", "[", "0", "]", "\n", "\n", "event_macro_teacher", "=", "log_sedeval_metrics", "(", "\n", "self", ".", "decoded_teacher_05_buffer", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"teacher\"", ")", ",", "\n", ")", "[", "0", "]", "\n", "\n", "# synth dataset", "\n", "intersection_f1_macro_student", "=", "compute_per_intersection_macro_f1", "(", "\n", "{", "\"0.5\"", ":", "self", ".", "decoded_student_05_buffer", "}", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", ")", "\n", "\n", "# synth dataset", "\n", "intersection_f1_macro_teacher", "=", "compute_per_intersection_macro_f1", "(", "\n", "{", "\"0.5\"", ":", "self", ".", "decoded_teacher_05_buffer", "}", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_tsv\"", "]", ",", "\n", "self", ".", "hparams", "[", "\"data\"", "]", "[", "\"test_dur\"", "]", ",", "\n", ")", "\n", "\n", "best_test_result", "=", "torch", ".", "tensor", "(", "max", "(", "psds_score_scenario1", ",", "psds_score_scenario2", ")", ")", "\n", "\n", "results", "=", "{", "\n", "\"hp_metric\"", ":", "best_test_result", ",", "\n", "\"test/student/psds_score_scenario1\"", ":", "psds_score_scenario1", ",", "\n", "\"test/student/psds_score_scenario2\"", ":", "psds_score_scenario2", ",", "\n", "\"test/teacher/psds_score_scenario1\"", ":", "psds_score_teacher_scenario1", ",", "\n", "\"test/teacher/psds_score_scenario2\"", ":", "psds_score_teacher_scenario2", ",", "\n", "\"test/student/event_f1_macro\"", ":", "event_macro_student", ",", "\n", "\"test/student/intersection_f1_macro\"", ":", "intersection_f1_macro_student", ",", "\n", "\"test/teacher/event_f1_macro\"", ":", "event_macro_teacher", ",", "\n", "\"test/teacher/intersection_f1_macro\"", ":", "intersection_f1_macro_teacher", "\n", "}", "\n", "if", "self", ".", "logger", "is", "not", "None", ":", "\n", "            ", "self", ".", "logger", ".", "log_metrics", "(", "results", ")", "\n", "self", ".", "logger", ".", "log_hyperparams", "(", "self", ".", "hparams", ",", "results", ")", "\n", "\n", "", "for", "key", "in", "results", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "log", "(", "key", ",", "results", "[", "key", "]", ",", "prog_bar", "=", "True", ",", "logger", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.configure_optimizers": [[730, 732], ["None"], "methods", ["None"], ["", "", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "opt", "]", ",", "[", "self", ".", "scheduler", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.train_dataloader": [[733, 742], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "train_data", ",", "\n", "batch_sampler", "=", "self", ".", "train_sampler", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", ")", "\n", "\n", "return", "self", ".", "train_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.val_dataloader": [[743, 752], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "self", ".", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "valid_data", ",", "\n", "batch_size", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"batch_size_val\"", "]", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "shuffle", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "\n", ")", "\n", "return", "self", ".", "val_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.local.sed_trainer_SRST.SEDTask4_2021.test_dataloader": [[753, 762], ["torch.utils.data.DataLoader"], "methods", ["None"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "self", ".", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "self", ".", "test_data", ",", "\n", "batch_size", "=", "self", ".", "hparams", "[", "\"training\"", "]", "[", "\"batch_size_val\"", "]", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "shuffle", "=", "False", ",", "\n", "drop_last", "=", "False", ",", "\n", ")", "\n", "return", "self", ".", "test_loader", "\n", "", "", ""]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.get_event_list_current_file": [[10, 29], ["len", "pandas.isna", "event_file.to_dict", "event_file.to_dict"], "function", ["None"], ["import", "pandas", "as", "pd", "\n", "import", "torch", "\n", "from", "psds_eval", "import", "plot_psd_roc", ",", "PSDSEval", "\n", "\n", "import", "config", "as", "cfg", "\n", "from", "utilities", ".", "Logger", "import", "create_logger", "\n", "from", "utilities", ".", "utils", "import", "to_cuda_if_available", "\n", "from", "utilities", ".", "ManyHotEncoder", "import", "ManyHotEncoder", "\n", "\n", "logger", "=", "create_logger", "(", "__name__", ",", "terminal_level", "=", "cfg", ".", "terminal_level", ")", "\n", "\n", "\n", "def", "get_event_list_current_file", "(", "df", ",", "fname", ")", ":", "\n", "    ", "\"\"\"\n    Get list of events for a given filename\n    :param df: pd.DataFrame, the dataframe to search on\n    :param fname: the filename to extract the value from the dataframe\n    :return: list of events (dictionaries) for the given filename\n    \"\"\"", "\n", "event_file", "=", "df", "[", "df", "[", "\"filename\"", "]", "==", "fname", "]", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.psds_results": [[31, 47], ["psds_obj.psds", "print", "psds_obj.psds", "print", "psds_obj.psds", "print", "print"], "function", ["None"], ["        ", "if", "pd", ".", "isna", "(", "event_file", "[", "\"event_label\"", "]", ".", "iloc", "[", "0", "]", ")", ":", "\n", "            ", "event_list_for_current_file", "=", "[", "{", "\"filename\"", ":", "fname", "}", "]", "\n", "", "else", ":", "\n", "            ", "event_list_for_current_file", "=", "event_file", ".", "to_dict", "(", "'records'", ")", "\n", "", "", "else", ":", "\n", "        ", "event_list_for_current_file", "=", "event_file", ".", "to_dict", "(", "'records'", ")", "\n", "\n", "", "return", "event_list_for_current_file", "\n", "\n", "\n", "", "def", "event_based_evaluation_df", "(", "reference", ",", "estimated", ",", "t_collar", "=", "0.200", ",", "percentage_of_length", "=", "0.2", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.event_based_evaluation_df": [[49, 93], ["reference[].unique", "list.extend", "list.extend", "list", "sed_eval.sound_event.EventBasedMetrics", "reference.event_label.dropna().unique", "estimated.event_label.dropna().unique", "set", "evaluation_measures.get_event_list_current_file", "evaluation_measures.get_event_list_current_file", "sed_eval.sound_event.EventBasedMetrics.evaluate", "reference.event_label.dropna", "estimated.event_label.dropna"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.get_event_list_current_file", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.get_event_list_current_file"], ["\n", "\n", "evaluated_files", "=", "reference", "[", "\"filename\"", "]", ".", "unique", "(", ")", "\n", "\n", "classes", "=", "[", "]", "\n", "classes", ".", "extend", "(", "reference", ".", "event_label", ".", "dropna", "(", ")", ".", "unique", "(", ")", ")", "\n", "classes", ".", "extend", "(", "estimated", ".", "event_label", ".", "dropna", "(", ")", ".", "unique", "(", ")", ")", "\n", "classes", "=", "list", "(", "set", "(", "classes", ")", ")", "\n", "\n", "event_based_metric", "=", "sed_eval", ".", "sound_event", ".", "EventBasedMetrics", "(", "\n", "event_label_list", "=", "classes", ",", "\n", "t_collar", "=", "t_collar", ",", "\n", "percentage_of_length", "=", "percentage_of_length", ",", "\n", "empty_system_output_handling", "=", "'zero_score'", "\n", ")", "\n", "\n", "for", "fname", "in", "evaluated_files", ":", "\n", "        ", "reference_event_list_for_current_file", "=", "get_event_list_current_file", "(", "reference", ",", "fname", ")", "\n", "estimated_event_list_for_current_file", "=", "get_event_list_current_file", "(", "estimated", ",", "fname", ")", "\n", "\n", "event_based_metric", ".", "evaluate", "(", "\n", "reference_event_list", "=", "reference_event_list_for_current_file", ",", "\n", "estimated_event_list", "=", "estimated_event_list_for_current_file", ",", "\n", ")", "\n", "\n", "", "return", "event_based_metric", "\n", "\n", "\n", "", "def", "segment_based_evaluation_df", "(", "reference", ",", "estimated", ",", "time_resolution", "=", "1.", ")", ":", "\n", "    ", "\"\"\" Calculate SegmentBasedMetrics given a reference and estimated dataframe\n\n        Args:\n            reference: pd.DataFrame containing \"filename\" \"onset\" \"offset\" and \"event_label\" columns which describe the\n                reference events\n            estimated: pd.DataFrame containing \"filename\" \"onset\" \"offset\" and \"event_label\" columns which describe the\n                estimated events to be compared with reference\n            time_resolution: float, the time resolution of the segment based metric\n        Returns:\n             sed_eval.sound_event.SegmentBasedMetrics with the scores\n        \"\"\"", "\n", "evaluated_files", "=", "reference", "[", "\"filename\"", "]", ".", "unique", "(", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.segment_based_evaluation_df": [[95, 132], ["reference[].unique", "list.extend", "list.extend", "list", "sed_eval.sound_event.SegmentBasedMetrics", "reference.event_label.dropna().unique", "estimated.event_label.dropna().unique", "set", "evaluation_measures.get_event_list_current_file", "evaluation_measures.get_event_list_current_file", "sed_eval.sound_event.SegmentBasedMetrics.evaluate", "reference.event_label.dropna", "estimated.event_label.dropna"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.get_event_list_current_file", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.get_event_list_current_file"], ["classes", "=", "[", "]", "\n", "classes", ".", "extend", "(", "reference", ".", "event_label", ".", "dropna", "(", ")", ".", "unique", "(", ")", ")", "\n", "classes", ".", "extend", "(", "estimated", ".", "event_label", ".", "dropna", "(", ")", ".", "unique", "(", ")", ")", "\n", "classes", "=", "list", "(", "set", "(", "classes", ")", ")", "\n", "\n", "segment_based_metric", "=", "sed_eval", ".", "sound_event", ".", "SegmentBasedMetrics", "(", "\n", "event_label_list", "=", "classes", ",", "\n", "time_resolution", "=", "time_resolution", "\n", ")", "\n", "\n", "for", "fname", "in", "evaluated_files", ":", "\n", "        ", "reference_event_list_for_current_file", "=", "get_event_list_current_file", "(", "reference", ",", "fname", ")", "\n", "estimated_event_list_for_current_file", "=", "get_event_list_current_file", "(", "estimated", ",", "fname", ")", "\n", "\n", "segment_based_metric", ".", "evaluate", "(", "\n", "reference_event_list", "=", "reference_event_list_for_current_file", ",", "\n", "estimated_event_list", "=", "estimated_event_list_for_current_file", "\n", ")", "\n", "\n", "", "return", "segment_based_metric", "\n", "\n", "\n", "", "def", "get_predictions", "(", "model", ",", "dataloader", ",", "decoder", ",", "pooling_time_ratio", "=", "1", ",", "thresholds", "=", "[", "0.5", "]", ",", "\n", "median_window", "=", "1", ",", "save_predictions", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_sed_eval_metrics": [[134, 150], ["evaluation_measures.event_based_evaluation_df", "evaluation_measures.segment_based_evaluation_df"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.event_based_evaluation_df", "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.segment_based_evaluation_df"], ["\n", "# Init a dataframe per threshold", "\n", "prediction_dfs", "=", "{", "}", "\n", "for", "threshold", "in", "thresholds", ":", "\n", "        ", "prediction_dfs", "[", "threshold", "]", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "# Get predictions", "\n", "", "for", "i", ",", "(", "(", "input_data", ",", "_", ")", ",", "indexes", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "indexes", "=", "indexes", ".", "numpy", "(", ")", "\n", "\n", "input_data", "=", "to_cuda_if_available", "(", "input_data", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pred_strong", ",", "_", "=", "model", "(", "input_data", ")", "\n", "", "pred_strong", "=", "pred_strong", ".", "cpu", "(", ")", "\n", "pred_strong", "=", "pred_strong", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "if", "i", "==", "0", ":", "\n", "            ", "logger", ".", "debug", "(", "pred_strong", ")", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_per_intersection_macro_f1": [[152, 195], ["pandas.read_csv", "pandas.read_csv", "psds_eval.PSDSEval", "prediction_dfs.keys", "numpy.mean", "numpy.isnan", "np.mean.append", "psds_eval.PSDSEval.compute_macro_f_score"], "function", ["home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.utilities.Scaler.Scaler.mean"], ["# Post processing and put predictions in a dataframe", "\n", "", "for", "j", ",", "pred_strong_it", "in", "enumerate", "(", "pred_strong", ")", ":", "\n", "\n", "#savePath = \"./Posterior/\" + dataloader.dataset.filenames.iloc[indexes[j]]", "\n", "#savePath.replace(\"wav\", \"npy\")", "\n", "#np.save(savePath, pred_strong_it)", "\n", "\n", "            ", "for", "threshold", "in", "thresholds", ":", "\n", "                ", "pred_strong_bin", "=", "ProbabilityEncoder", "(", ")", ".", "binarization", "(", "pred_strong_it", ",", "\n", "binarization_type", "=", "\"global_threshold\"", ",", "\n", "threshold", "=", "threshold", ")", "\n", "pred_strong_m", "=", "scipy", ".", "ndimage", ".", "filters", ".", "median_filter", "(", "pred_strong_bin", ",", "(", "median_window", ",", "1", ")", ")", "\n", "pred", "=", "decoder", "(", "pred_strong_m", ")", "\n", "pred", "=", "pd", ".", "DataFrame", "(", "pred", ",", "columns", "=", "[", "\"event_label\"", ",", "\"onset\"", ",", "\"offset\"", "]", ")", "\n", "# Put them in seconds", "\n", "pred", ".", "loc", "[", ":", ",", "[", "\"onset\"", ",", "\"offset\"", "]", "]", "*=", "pooling_time_ratio", "/", "(", "cfg", ".", "sample_rate", "/", "cfg", ".", "hop_size", ")", "\n", "pred", ".", "loc", "[", ":", ",", "[", "\"onset\"", ",", "\"offset\"", "]", "]", "=", "pred", "[", "[", "\"onset\"", ",", "\"offset\"", "]", "]", ".", "clip", "(", "0", ",", "cfg", ".", "max_len_seconds", ")", "\n", "\n", "pred", "[", "\"filename\"", "]", "=", "dataloader", ".", "dataset", ".", "filenames", ".", "iloc", "[", "indexes", "[", "j", "]", "]", "\n", "prediction_dfs", "[", "threshold", "]", "=", "prediction_dfs", "[", "threshold", "]", ".", "append", "(", "pred", ",", "ignore_index", "=", "True", ")", "\n", "\n", "if", "i", "==", "0", "and", "j", "==", "0", ":", "\n", "                    ", "logger", ".", "debug", "(", "\"predictions: \\n{}\"", ".", "format", "(", "pred", ")", ")", "\n", "logger", ".", "debug", "(", "\"predictions strong: \\n{}\"", ".", "format", "(", "pred_strong_it", ")", ")", "\n", "\n", "# Save predictions", "\n", "", "", "", "", "if", "save_predictions", "is", "not", "None", ":", "\n", "        ", "if", "isinstance", "(", "save_predictions", ",", "str", ")", ":", "\n", "            ", "if", "len", "(", "thresholds", ")", "==", "1", ":", "\n", "                ", "save_predictions", "=", "[", "save_predictions", "]", "\n", "", "else", ":", "\n", "                ", "base", ",", "ext", "=", "osp", ".", "splitext", "(", "save_predictions", ")", "\n", "save_predictions", "=", "[", "osp", ".", "join", "(", "base", ",", "f\"{threshold:.3f}{ext}\"", ")", "for", "threshold", "in", "thresholds", "]", "\n", "", "", "else", ":", "\n", "            ", "assert", "len", "(", "save_predictions", ")", "==", "len", "(", "thresholds", ")", ",", "f\"There should be a prediction file per threshold: len predictions: {len(save_predictions)}\\n\"", "f\"len thresholds: {len(thresholds)}\"", "\n", "save_predictions", "=", "save_predictions", "\n", "\n", "", "for", "ind", ",", "threshold", "in", "enumerate", "(", "thresholds", ")", ":", "\n", "            ", "dir_to_create", "=", "osp", ".", "dirname", "(", "save_predictions", "[", "ind", "]", ")", "\n", "if", "dir_to_create", "!=", "\"\"", ":", "\n", "                ", "os", ".", "makedirs", "(", "dir_to_create", ",", "exist_ok", "=", "True", ")", "\n", "if", "ind", "%", "10", "==", "0", ":", "\n"]], "home.repos.pwc.inspect_result.JHU-LCAP_CRSTmodel.evaluation.evaluation_measures.compute_psds_from_operating_points": [[197, 252], ["pandas.read_csv", "pandas.read_csv", "psds_eval.PSDSEval", "enumerate", "psds_eval.PSDSEval.psds", "prediction_dfs.keys", "range", "det.set_index.set_index", "psds_eval.PSDSEval.add_operating_point", "os.makedirs", "os.path.join", "os.makedirs", "prediction_dfs.keys", "psds_eval.plot_psd_roc", "prediction_dfs[].to_csv", "len", "os.path.join", "os.path.join"], "function", ["None"], ["", "prediction_dfs", "[", "threshold", "]", ".", "to_csv", "(", "save_predictions", "[", "ind", "]", ",", "index", "=", "False", ",", "sep", "=", "\"\\t\"", ",", "float_format", "=", "\"%.3f\"", ")", "\n", "\n", "", "", "", "list_predictions", "=", "[", "]", "\n", "for", "key", "in", "prediction_dfs", ":", "\n", "        ", "list_predictions", ".", "append", "(", "prediction_dfs", "[", "key", "]", ")", "\n", "\n", "", "if", "len", "(", "list_predictions", ")", "==", "1", ":", "\n", "        ", "list_predictions", "=", "list_predictions", "[", "0", "]", "\n", "\n", "", "return", "list_predictions", "\n", "\n", "\n", "", "def", "get_predictions_v2", "(", "model", ",", "dataloader", ",", "decoder", ",", "pooling_time_ratio", "=", "1", ",", "thresholds", "=", "[", "0.5", "]", ",", "\n", "median_window", "=", "1", ",", "save_dir", "=", "None", ",", "save_predictions", "=", "None", ")", ":", "\n", "    ", "\"\"\" Get the predictions of a trained model on a specific set\n    Args:\n        model: torch.Module, a trained pytorch model (you usually want it to be in .eval() mode).\n        dataloader: torch.utils.data.DataLoader, giving ((input_data, label), indexes) but label is not used here\n        decoder: function, takes a numpy.array of shape (time_steps, n_labels) as input and return a list of lists\n            of (\"event_label\", \"onset\", \"offset\") for each label predicted.\n        pooling_time_ratio: the division to make between timesteps as input and timesteps as output\n        median_window: int, the median window (in number of time steps) to be applied\n        save_predictions: str or list, the path of the base_filename to save the predictions or a list of names\n            corresponding for each thresholds\n        thresholds: list, list of threshold to be applied\n\n    Returns:\n        dict of the different predictions with associated threshold\n    \"\"\"", "\n", "\n", "# Init a dataframe per threshold", "\n", "prediction_dfs", "=", "{", "}", "\n", "for", "threshold", "in", "thresholds", ":", "\n", "        ", "prediction_dfs", "[", "threshold", "]", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "", "if", "save_dir", "is", "not", "None", ":", "\n", "        ", "os", ".", "makedirs", "(", "save_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Get predictions", "\n", "", "for", "i", ",", "(", "(", "input_data", ",", "_", ")", ",", "indexes", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "indexes", "=", "indexes", ".", "numpy", "(", ")", "\n", "\n", "input_data", "=", "to_cuda_if_available", "(", "input_data", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "pred_strong", ",", "_", "=", "model", "(", "input_data", ")", "\n", "", "pred_strong", "=", "pred_strong", ".", "cpu", "(", ")", "\n", "pred_strong", "=", "pred_strong", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "if", "i", "==", "0", ":", "\n", "            ", "logger", ".", "debug", "(", "pred_strong", ")", "\n", "\n", "# Post processing and put predictions in a dataframe", "\n", "", "for", "j", ",", "pred_strong_it", "in", "enumerate", "(", "pred_strong", ")", ":", "\n", "\n", "            ", "if", "save_dir", "is", "not", "None", ":", "\n", "                ", "savePath", "=", "save_dir", "+", "dataloader", ".", "dataset", ".", "filenames", ".", "iloc", "[", "indexes", "[", "j", "]", "]", "\n", "savePath", ".", "replace", "(", "\"wav\"", ",", "\"npy\"", ")", "\n"]]}