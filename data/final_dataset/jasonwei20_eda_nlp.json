{"home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.e_2_cnn_baselines.run_model": [[10, 47], ["methods.build_model", "methods.get_x_y", "methods.get_x_y", "methods.build_model.fit", "methods.build_model.predict", "methods.one_hot_to_categorical", "methods.one_hot_to_categorical", "accuracy_score", "gc.collect", "EarlyStopping"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.build_model", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical"], ["def", "run_model", "(", "train_file", ",", "test_file", ",", "num_classes", ",", "input_size", ",", "percent_dataset", ",", "word2vec", ")", ":", "\n", "\n", "#initialize model", "\n", "\t", "model", "=", "build_model", "(", "input_size", ",", "word2vec_len", ",", "num_classes", ")", "\n", "\n", "#load data", "\n", "train_x", ",", "train_y", "=", "get_x_y", "(", "train_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "percent_dataset", ")", "\n", "test_x", ",", "test_y", "=", "get_x_y", "(", "test_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "1", ")", "\n", "\n", "#implement early stopping", "\n", "callbacks", "=", "[", "EarlyStopping", "(", "monitor", "=", "'val_loss'", ",", "patience", "=", "3", ")", "]", "\n", "\n", "#train model", "\n", "model", ".", "fit", "(", "train_x", ",", "\n", "train_y", ",", "\n", "epochs", "=", "100000", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "validation_split", "=", "0.1", ",", "\n", "batch_size", "=", "1024", ",", "\n", "shuffle", "=", "True", ",", "\n", "verbose", "=", "0", ")", "\n", "#model.save('checkpoints/lol')", "\n", "#model = load_model('checkpoints/lol')", "\n", "\n", "#evaluate model", "\n", "y_pred", "=", "model", ".", "predict", "(", "test_x", ")", "\n", "test_y_cat", "=", "one_hot_to_categorical", "(", "test_y", ")", "\n", "y_pred_cat", "=", "one_hot_to_categorical", "(", "y_pred", ")", "\n", "acc", "=", "accuracy_score", "(", "test_y_cat", ",", "y_pred_cat", ")", "\n", "\n", "#clean memory???", "\n", "train_x", ",", "train_y", "=", "None", ",", "None", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "#return the accuracy", "\n", "#print(\"data with shape:\", train_x.shape, train_y.shape, 'train=', train_file, 'test=', test_file, 'with fraction', percent_dataset, 'had acc', acc)", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.e_2_cnn_baselines.compute_baselines": [[52, 80], ["range", "print", "writer.write", "len", "methods.load_pickle", "e_2_cnn_baselines.run_model", "performances.append", "str"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.load_pickle", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.b_2_train_eval.run_model"], ["", "def", "compute_baselines", "(", "writer", ")", ":", "\n", "\n", "#baseline computation", "\n", "\t", "for", "size_folder", "in", "size_folders", ":", "\n", "\n", "#get all six datasets", "\n", "\t\t", "dataset_folders", "=", "[", "size_folder", "+", "'/'", "+", "s", "for", "s", "in", "datasets", "]", "\n", "performances", "=", "[", "]", "\n", "\n", "#for each dataset", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset_folders", ")", ")", ":", "\n", "\n", "#initialize all the variables", "\n", "\t\t\t", "dataset_folder", "=", "dataset_folders", "[", "i", "]", "\n", "dataset", "=", "datasets", "[", "i", "]", "\n", "num_classes", "=", "num_classes_list", "[", "i", "]", "\n", "input_size", "=", "input_size_list", "[", "i", "]", "\n", "word2vec_pickle", "=", "dataset_folder", "+", "'/word2vec.p'", "\n", "word2vec", "=", "load_pickle", "(", "word2vec_pickle", ")", "\n", "\n", "train_path", "=", "dataset_folder", "+", "'/train_orig.txt'", "\n", "test_path", "=", "'size_data_t1/test/'", "+", "dataset", "+", "'/test.txt'", "\n", "acc", "=", "run_model", "(", "train_path", ",", "test_path", ",", "num_classes", ",", "input_size", ",", "1", ",", "word2vec", ")", "\n", "performances", ".", "append", "(", "str", "(", "acc", ")", ")", "\n", "\n", "", "line", "=", "','", ".", "join", "(", "performances", ")", "\n", "print", "(", "line", ")", "\n", "writer", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.c_2_train_eval.run_cnn": [[10, 47], ["methods.build_cnn", "methods.get_x_y", "methods.get_x_y", "methods.build_cnn.fit", "methods.build_cnn.predict", "methods.one_hot_to_categorical", "methods.one_hot_to_categorical", "accuracy_score", "gc.collect", "EarlyStopping"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.build_cnn", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical"], ["def", "run_cnn", "(", "train_file", ",", "test_file", ",", "num_classes", ",", "percent_dataset", ")", ":", "\n", "\n", "#initialize model", "\n", "\t", "model", "=", "build_cnn", "(", "input_size", ",", "word2vec_len", ",", "num_classes", ")", "\n", "\n", "#load data", "\n", "train_x", ",", "train_y", "=", "get_x_y", "(", "train_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "percent_dataset", ")", "\n", "test_x", ",", "test_y", "=", "get_x_y", "(", "test_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "1", ")", "\n", "\n", "#implement early stopping", "\n", "callbacks", "=", "[", "EarlyStopping", "(", "monitor", "=", "'val_loss'", ",", "patience", "=", "3", ")", "]", "\n", "\n", "#train model", "\n", "model", ".", "fit", "(", "train_x", ",", "\n", "train_y", ",", "\n", "epochs", "=", "100000", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "validation_split", "=", "0.1", ",", "\n", "batch_size", "=", "1024", ",", "\n", "shuffle", "=", "True", ",", "\n", "verbose", "=", "0", ")", "\n", "#model.save('checkpoints/lol')", "\n", "#model = load_model('checkpoints/lol')", "\n", "\n", "#evaluate model", "\n", "y_pred", "=", "model", ".", "predict", "(", "test_x", ")", "\n", "test_y_cat", "=", "one_hot_to_categorical", "(", "test_y", ")", "\n", "y_pred_cat", "=", "one_hot_to_categorical", "(", "y_pred", ")", "\n", "acc", "=", "accuracy_score", "(", "test_y_cat", ",", "y_pred_cat", ")", "\n", "\n", "#clean memory???", "\n", "train_x", ",", "train_y", "=", "None", ",", "None", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "#return the accuracy", "\n", "#print(\"data with shape:\", train_x.shape, train_y.shape, 'train=', train_file, 'test=', test_file, 'with fraction', percent_dataset, 'had acc', acc)", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.load_pickle": [[37, 39], ["pickle.load", "open"], "function", ["None"], ["def", "load_pickle", "(", "file", ")", ":", "\n", "\t", "return", "pickle", ".", "load", "(", "open", "(", "file", ",", "'rb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.confirm_output_folder": [[41, 44], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "def", "confirm_output_folder", "(", "output_folder", ")", ":", "\n", "\t", "if", "not", "os", ".", "path", ".", "exists", "(", "output_folder", ")", ":", "\n", "\t    ", "os", ".", "makedirs", "(", "output_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_txt_paths": [[46, 52], ["sorted", "os.path.join", "os.path.join", "sorted.remove", "os.listdir", "os.path.join", "os.path.isfile", "os.path.join"], "function", ["None"], ["", "", "def", "get_txt_paths", "(", "folder", ")", ":", "\n", "    ", "txt_paths", "=", "[", "join", "(", "folder", ",", "f", ")", "for", "f", "in", "listdir", "(", "folder", ")", "if", "isfile", "(", "join", "(", "folder", ",", "f", ")", ")", "and", "'.txt'", "in", "f", "]", "\n", "if", "join", "(", "folder", ",", "'.DS_Store'", ")", "in", "txt_paths", ":", "\n", "        ", "txt_paths", ".", "remove", "(", "join", "(", "folder", ",", "'.DS_Store'", ")", ")", "\n", "", "txt_paths", "=", "sorted", "(", "txt_paths", ")", "\n", "return", "txt_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_subfolder_paths": [[54, 60], ["sorted", "os.path.join", "os.path.join", "sorted.remove", "os.listdir", "os.path.join", "os.path.isdir", "os.path.join"], "function", ["None"], ["", "def", "get_subfolder_paths", "(", "folder", ")", ":", "\n", "    ", "subfolder_paths", "=", "[", "join", "(", "folder", ",", "f", ")", "for", "f", "in", "listdir", "(", "folder", ")", "if", "(", "isdir", "(", "join", "(", "folder", ",", "f", ")", ")", "and", "'.DS_Store'", "not", "in", "f", ")", "]", "\n", "if", "join", "(", "folder", ",", "'.DS_Store'", ")", "in", "subfolder_paths", ":", "\n", "        ", "subfolder_paths", ".", "remove", "(", "join", "(", "folder", ",", "'.DS_Store'", ")", ")", "\n", "", "subfolder_paths", "=", "sorted", "(", "subfolder_paths", ")", "\n", "return", "subfolder_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_all_txt_paths": [[62, 72], ["methods.get_subfolder_paths", "len", "methods.get_txt_paths", "methods.get_txt_paths"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_subfolder_paths", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_txt_paths", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_txt_paths"], ["", "def", "get_all_txt_paths", "(", "master_folder", ")", ":", "\n", "\n", "    ", "all_paths", "=", "[", "]", "\n", "subfolders", "=", "get_subfolder_paths", "(", "master_folder", ")", "\n", "if", "len", "(", "subfolders", ")", ">", "1", ":", "\n", "        ", "for", "subfolder", "in", "subfolders", ":", "\n", "            ", "all_paths", "+=", "get_txt_paths", "(", "subfolder", ")", "\n", "", "", "else", ":", "\n", "        ", "all_paths", "=", "get_txt_paths", "(", "master_folder", ")", "\n", "", "return", "all_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.gen_vocab_dicts": [[78, 114], ["set", "open().readlines", "methods.get_all_txt_paths", "print", "print", "print", "pickle.dump", "print", "len", "line.split", "len", "open", "open", "open().readlines", "numpy.asarray", "line[].split", "print", "open", "set.add"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_all_txt_paths"], ["", "def", "gen_vocab_dicts", "(", "folder", ",", "output_pickle_path", ",", "huge_word2vec", ")", ":", "\n", "\n", "    ", "vocab", "=", "set", "(", ")", "\n", "text_embeddings", "=", "open", "(", "huge_word2vec", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "word2vec", "=", "{", "}", "\n", "\n", "#get all the vocab", "\n", "all_txt_paths", "=", "get_all_txt_paths", "(", "folder", ")", "\n", "print", "(", "all_txt_paths", ")", "\n", "\n", "#loop through each text file", "\n", "for", "txt_path", "in", "all_txt_paths", ":", "\n", "\n", "# get all the words", "\n", "    \t", "try", ":", "\n", "    \t\t", "all_lines", "=", "open", "(", "txt_path", ",", "\"r\"", ")", ".", "readlines", "(", ")", "\n", "for", "line", "in", "all_lines", ":", "\n", "    \t\t\t", "words", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "' '", ")", "\n", "for", "word", "in", "words", ":", "\n", "    \t\t\t    ", "vocab", ".", "add", "(", "word", ")", "\n", "", "", "", "except", ":", "\n", "    \t\t", "print", "(", "txt_path", ",", "\"has an error\"", ")", "\n", "\n", "", "", "print", "(", "len", "(", "vocab", ")", ",", "\"unique words found\"", ")", "\n", "\n", "# load the word embeddings, and only add the word to the dictionary if we need it", "\n", "for", "line", "in", "text_embeddings", ":", "\n", "        ", "items", "=", "line", ".", "split", "(", "' '", ")", "\n", "word", "=", "items", "[", "0", "]", "\n", "if", "word", "in", "vocab", ":", "\n", "            ", "vec", "=", "items", "[", "1", ":", "]", "\n", "word2vec", "[", "word", "]", "=", "np", ".", "asarray", "(", "vec", ",", "dtype", "=", "'float32'", ")", "\n", "", "", "print", "(", "len", "(", "word2vec", ")", ",", "\"matches between unique words and word2vec dictionary\"", ")", "\n", "\n", "pickle", ".", "dump", "(", "word2vec", ",", "open", "(", "output_pickle_path", ",", "'wb'", ")", ")", "\n", "print", "(", "\"dictionaries outputted to\"", ",", "output_pickle_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y": [[116, 152], ["open().readlines", "sklearn.utils.shuffle", "len", "numpy.zeros", "enumerate", "numpy.zeros", "line[].split", "int", "sentence.split", "enumerate", "open", "int", "print", "len"], "function", ["None"], ["", "def", "get_x_y", "(", "train_txt", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "percent_dataset", ")", ":", "\n", "\n", "#read in lines", "\n", "\t", "train_lines", "=", "open", "(", "train_txt", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "shuffle", "(", "train_lines", ")", "\n", "train_lines", "=", "train_lines", "[", ":", "int", "(", "percent_dataset", "*", "len", "(", "train_lines", ")", ")", "]", "\n", "num_lines", "=", "len", "(", "train_lines", ")", "\n", "\n", "#initialize x and y matrix", "\n", "x_matrix", "=", "None", "\n", "y_matrix", "=", "None", "\n", "\n", "try", ":", "\n", "\t\t", "x_matrix", "=", "np", ".", "zeros", "(", "(", "num_lines", ",", "input_size", ",", "word2vec_len", ")", ")", "\n", "", "except", ":", "\n", "\t\t", "print", "(", "\"Error!\"", ",", "num_lines", ",", "input_size", ",", "word2vec_len", ")", "\n", "", "y_matrix", "=", "np", ".", "zeros", "(", "(", "num_lines", ",", "num_classes", ")", ")", "\n", "\n", "#insert values", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "train_lines", ")", ":", "\n", "\n", "\t\t", "parts", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "'\\t'", ")", "\n", "label", "=", "int", "(", "parts", "[", "0", "]", ")", "\n", "sentence", "=", "parts", "[", "1", "]", "\n", "\n", "#insert x", "\n", "words", "=", "sentence", ".", "split", "(", "' '", ")", "\n", "words", "=", "words", "[", ":", "x_matrix", ".", "shape", "[", "1", "]", "]", "#cut off if too long", "\n", "for", "j", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "\t\t\t", "if", "word", "in", "word2vec", ":", "\n", "\t\t\t\t", "x_matrix", "[", "i", ",", "j", ",", ":", "]", "=", "word2vec", "[", "word", "]", "\n", "\n", "#insert y", "\n", "", "", "y_matrix", "[", "i", "]", "[", "label", "]", "=", "1.0", "\n", "\n", "", "return", "x_matrix", ",", "y_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.gen_tsne_aug": [[157, 171], ["open", "open().readlines", "enumerate", "open.close", "print", "line[].split", "open.write", "open", "open.write", "nlp_aug.eda_4"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.eda_4"], ["", "def", "gen_tsne_aug", "(", "train_orig", ",", "output_file", ")", ":", "\n", "\n", "    ", "writer", "=", "open", "(", "output_file", ",", "'w'", ")", "\n", "lines", "=", "open", "(", "train_orig", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "    \t", "parts", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "'\\t'", ")", "\n", "label", "=", "parts", "[", "0", "]", "\n", "sentence", "=", "parts", "[", "1", "]", "\n", "writer", ".", "write", "(", "line", ")", "\n", "for", "alpha", "in", "[", "0.1", ",", "0.2", ",", "0.3", ",", "0.4", ",", "0.5", ",", "0.6", ",", "0.7", ",", "0.8", ",", "0.9", "]", ":", "\n", "    \t\t", "aug_sentence", "=", "eda_4", "(", "sentence", ",", "alpha_sr", "=", "alpha", ",", "alpha_ri", "=", "alpha", ",", "alpha_rs", "=", "alpha", ",", "p_rd", "=", "alpha", ",", "num_aug", "=", "2", ")", "[", "0", "]", "\n", "writer", ".", "write", "(", "label", "+", "\"\\t\"", "+", "aug_sentence", "+", "'\\n'", ")", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "print", "(", "\"finished eda for tsne for\"", ",", "train_orig", ",", "\"to\"", ",", "output_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.gen_standard_aug": [[176, 188], ["open", "open().readlines", "enumerate", "open.close", "print", "line[].split", "nlp_aug.eda_4", "open", "open.write"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.eda_4"], ["", "def", "gen_standard_aug", "(", "train_orig", ",", "output_file", ",", "num_aug", "=", "9", ")", ":", "\n", "    ", "writer", "=", "open", "(", "output_file", ",", "'w'", ")", "\n", "lines", "=", "open", "(", "train_orig", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "parts", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "'\\t'", ")", "\n", "label", "=", "parts", "[", "0", "]", "\n", "sentence", "=", "parts", "[", "1", "]", "\n", "aug_sentences", "=", "eda_4", "(", "sentence", ",", "num_aug", "=", "num_aug", ")", "\n", "for", "aug_sentence", "in", "aug_sentences", ":", "\n", "            ", "writer", ".", "write", "(", "label", "+", "\"\\t\"", "+", "aug_sentence", "+", "'\\n'", ")", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "print", "(", "\"finished eda for\"", ",", "train_orig", ",", "\"to\"", ",", "output_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.gen_sr_aug": [[190, 202], ["open", "open().readlines", "enumerate", "open.close", "print", "line[].split", "nlp_aug.SR", "open", "open.write"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.SR"], ["", "def", "gen_sr_aug", "(", "train_orig", ",", "output_file", ",", "alpha_sr", ",", "n_aug", ")", ":", "\n", "    ", "writer", "=", "open", "(", "output_file", ",", "'w'", ")", "\n", "lines", "=", "open", "(", "train_orig", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "parts", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "'\\t'", ")", "\n", "label", "=", "parts", "[", "0", "]", "\n", "sentence", "=", "parts", "[", "1", "]", "\n", "aug_sentences", "=", "SR", "(", "sentence", ",", "alpha_sr", "=", "alpha_sr", ",", "n_aug", "=", "n_aug", ")", "\n", "for", "aug_sentence", "in", "aug_sentences", ":", "\n", "            ", "writer", ".", "write", "(", "label", "+", "\"\\t\"", "+", "aug_sentence", "+", "'\\n'", ")", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "print", "(", "\"finished SR for\"", ",", "train_orig", ",", "\"to\"", ",", "output_file", ",", "\"with alpha\"", ",", "alpha_sr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.gen_ri_aug": [[204, 216], ["open", "open().readlines", "enumerate", "open.close", "print", "line[].split", "nlp_aug.RI", "open", "open.write"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.RI"], ["", "def", "gen_ri_aug", "(", "train_orig", ",", "output_file", ",", "alpha_ri", ",", "n_aug", ")", ":", "\n", "    ", "writer", "=", "open", "(", "output_file", ",", "'w'", ")", "\n", "lines", "=", "open", "(", "train_orig", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "parts", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "'\\t'", ")", "\n", "label", "=", "parts", "[", "0", "]", "\n", "sentence", "=", "parts", "[", "1", "]", "\n", "aug_sentences", "=", "RI", "(", "sentence", ",", "alpha_ri", "=", "alpha_ri", ",", "n_aug", "=", "n_aug", ")", "\n", "for", "aug_sentence", "in", "aug_sentences", ":", "\n", "            ", "writer", ".", "write", "(", "label", "+", "\"\\t\"", "+", "aug_sentence", "+", "'\\n'", ")", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "print", "(", "\"finished RI for\"", ",", "train_orig", ",", "\"to\"", ",", "output_file", ",", "\"with alpha\"", ",", "alpha_ri", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.gen_rs_aug": [[218, 230], ["open", "open().readlines", "enumerate", "open.close", "print", "line[].split", "nlp_aug.RS", "open", "open.write"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.RS"], ["", "def", "gen_rs_aug", "(", "train_orig", ",", "output_file", ",", "alpha_rs", ",", "n_aug", ")", ":", "\n", "    ", "writer", "=", "open", "(", "output_file", ",", "'w'", ")", "\n", "lines", "=", "open", "(", "train_orig", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "parts", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "'\\t'", ")", "\n", "label", "=", "parts", "[", "0", "]", "\n", "sentence", "=", "parts", "[", "1", "]", "\n", "aug_sentences", "=", "RS", "(", "sentence", ",", "alpha_rs", "=", "alpha_rs", ",", "n_aug", "=", "n_aug", ")", "\n", "for", "aug_sentence", "in", "aug_sentences", ":", "\n", "            ", "writer", ".", "write", "(", "label", "+", "\"\\t\"", "+", "aug_sentence", "+", "'\\n'", ")", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "print", "(", "\"finished RS for\"", ",", "train_orig", ",", "\"to\"", ",", "output_file", ",", "\"with alpha\"", ",", "alpha_rs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.gen_rd_aug": [[232, 244], ["open", "open().readlines", "enumerate", "open.close", "print", "line[].split", "nlp_aug.RD", "open", "open.write"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.RD"], ["", "def", "gen_rd_aug", "(", "train_orig", ",", "output_file", ",", "alpha_rd", ",", "n_aug", ")", ":", "\n", "    ", "writer", "=", "open", "(", "output_file", ",", "'w'", ")", "\n", "lines", "=", "open", "(", "train_orig", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "parts", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "'\\t'", ")", "\n", "label", "=", "parts", "[", "0", "]", "\n", "sentence", "=", "parts", "[", "1", "]", "\n", "aug_sentences", "=", "RD", "(", "sentence", ",", "alpha_rd", "=", "alpha_rd", ",", "n_aug", "=", "n_aug", ")", "\n", "for", "aug_sentence", "in", "aug_sentences", ":", "\n", "            ", "writer", ".", "write", "(", "label", "+", "\"\\t\"", "+", "aug_sentence", "+", "'\\n'", ")", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "print", "(", "\"finished RD for\"", ",", "train_orig", ",", "\"to\"", ",", "output_file", ",", "\"with alpha\"", ",", "alpha_rd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.build_model": [[250, 262], ["keras.models.Sequential", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.compile", "keras.layers.Bidirectional", "keras.layers.core.Dropout", "keras.layers.Bidirectional", "keras.layers.core.Dropout", "keras.layers.core.Dense", "keras.layers.core.Dense", "keras.layers.recurrent.LSTM", "keras.layers.recurrent.LSTM"], "function", ["None"], ["", "def", "build_model", "(", "sentence_length", ",", "word2vec_len", ",", "num_classes", ")", ":", "\n", "\t", "model", "=", "None", "\n", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "Bidirectional", "(", "LSTM", "(", "64", ",", "return_sequences", "=", "True", ")", ",", "input_shape", "=", "(", "sentence_length", ",", "word2vec_len", ")", ")", ")", "\n", "model", ".", "add", "(", "Dropout", "(", "0.5", ")", ")", "\n", "model", ".", "add", "(", "Bidirectional", "(", "LSTM", "(", "32", ",", "return_sequences", "=", "False", ")", ")", ")", "\n", "model", ".", "add", "(", "Dropout", "(", "0.5", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "20", ",", "activation", "=", "'relu'", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "num_classes", ",", "kernel_initializer", "=", "'normal'", ",", "activation", "=", "'softmax'", ")", ")", "\n", "model", ".", "compile", "(", "loss", "=", "'categorical_crossentropy'", ",", "optimizer", "=", "'adam'", ",", "metrics", "=", "[", "'accuracy'", "]", ")", "\n", "#print(model.summary())", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.build_cnn": [[264, 273], ["keras.models.Sequential", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.add", "keras.models.Sequential.compile", "keras.Conv1D", "keras.GlobalMaxPooling1D", "keras.layers.core.Dense", "keras.layers.core.Dense"], "function", ["None"], ["", "def", "build_cnn", "(", "sentence_length", ",", "word2vec_len", ",", "num_classes", ")", ":", "\n", "\t", "model", "=", "None", "\n", "model", "=", "Sequential", "(", ")", "\n", "model", ".", "add", "(", "layers", ".", "Conv1D", "(", "128", ",", "5", ",", "activation", "=", "'relu'", ",", "input_shape", "=", "(", "sentence_length", ",", "word2vec_len", ")", ")", ")", "\n", "model", ".", "add", "(", "layers", ".", "GlobalMaxPooling1D", "(", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "20", ",", "activation", "=", "'relu'", ")", ")", "\n", "model", ".", "add", "(", "Dense", "(", "num_classes", ",", "kernel_initializer", "=", "'normal'", ",", "activation", "=", "'softmax'", ")", ")", "\n", "model", ".", "compile", "(", "loss", "=", "'categorical_crossentropy'", ",", "optimizer", "=", "'adam'", ",", "metrics", "=", "[", "'accuracy'", "]", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical": [[275, 278], ["numpy.argmax", "len"], "function", ["None"], ["", "def", "one_hot_to_categorical", "(", "y", ")", ":", "\n", "    ", "assert", "len", "(", "y", ".", "shape", ")", "==", "2", "\n", "return", "np", ".", "argmax", "(", "y", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_now_str": [[279, 281], ["str", "time.strftime", "time.gmtime"], "function", ["None"], ["", "def", "get_now_str", "(", ")", ":", "\n", "    ", "return", "str", "(", "strftime", "(", "\"%Y-%m-%d_%H:%M:%S\"", ",", "gmtime", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.d_1_train_models.run_model": [[9, 47], ["methods.build_model", "methods.get_x_y", "methods.get_x_y", "methods.build_model.fit", "methods.build_model.save", "methods.build_model.predict", "methods.one_hot_to_categorical", "methods.one_hot_to_categorical", "accuracy_score", "EarlyStopping"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.build_model", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical"], ["def", "run_model", "(", "train_file", ",", "test_file", ",", "num_classes", ",", "model_output_path", ")", ":", "\n", "\n", "#initialize model", "\n", "\t", "model", "=", "build_model", "(", "input_size", ",", "word2vec_len", ",", "num_classes", ")", "\n", "\n", "#load data", "\n", "train_x", ",", "train_y", "=", "get_x_y", "(", "train_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "1", ")", "\n", "test_x", ",", "test_y", "=", "get_x_y", "(", "test_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "1", ")", "\n", "\n", "#implement early stopping", "\n", "callbacks", "=", "[", "EarlyStopping", "(", "monitor", "=", "'val_loss'", ",", "patience", "=", "3", ")", "]", "\n", "\n", "#train model", "\n", "model", ".", "fit", "(", "train_x", ",", "\n", "train_y", ",", "\n", "epochs", "=", "100000", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "validation_split", "=", "0.1", ",", "\n", "batch_size", "=", "1024", ",", "\n", "shuffle", "=", "True", ",", "\n", "verbose", "=", "0", ")", "\n", "\n", "#save the model", "\n", "model", ".", "save", "(", "model_output_path", ")", "\n", "#model = load_model('checkpoints/lol')", "\n", "\n", "#evaluate model", "\n", "y_pred", "=", "model", ".", "predict", "(", "test_x", ")", "\n", "test_y_cat", "=", "one_hot_to_categorical", "(", "test_y", ")", "\n", "y_pred_cat", "=", "one_hot_to_categorical", "(", "y_pred", ")", "\n", "acc", "=", "accuracy_score", "(", "test_y_cat", ",", "y_pred_cat", ")", "\n", "\n", "#clean memory???", "\n", "train_x", ",", "train_y", "=", "None", ",", "None", "\n", "\n", "#return the accuracy", "\n", "#print(\"data with shape:\", train_x.shape, train_y.shape, 'train=', train_file, 'test=', test_file, 'with fraction', percent_dataset, 'had acc', acc)", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.e_2_rnn_aug.run_model": [[10, 47], ["methods.build_model", "methods.get_x_y", "methods.get_x_y", "methods.build_model.fit", "methods.build_model.predict", "methods.one_hot_to_categorical", "methods.one_hot_to_categorical", "accuracy_score", "gc.collect", "EarlyStopping"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.build_model", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical"], ["def", "run_model", "(", "train_file", ",", "test_file", ",", "num_classes", ",", "input_size", ",", "percent_dataset", ",", "word2vec", ")", ":", "\n", "\n", "#initialize model", "\n", "\t", "model", "=", "build_model", "(", "input_size", ",", "word2vec_len", ",", "num_classes", ")", "\n", "\n", "#load data", "\n", "train_x", ",", "train_y", "=", "get_x_y", "(", "train_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "percent_dataset", ")", "\n", "test_x", ",", "test_y", "=", "get_x_y", "(", "test_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "1", ")", "\n", "\n", "#implement early stopping", "\n", "callbacks", "=", "[", "EarlyStopping", "(", "monitor", "=", "'val_loss'", ",", "patience", "=", "3", ")", "]", "\n", "\n", "#train model", "\n", "model", ".", "fit", "(", "train_x", ",", "\n", "train_y", ",", "\n", "epochs", "=", "100000", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "validation_split", "=", "0.1", ",", "\n", "batch_size", "=", "1024", ",", "\n", "shuffle", "=", "True", ",", "\n", "verbose", "=", "0", ")", "\n", "#model.save('checkpoints/lol')", "\n", "#model = load_model('checkpoints/lol')", "\n", "\n", "#evaluate model", "\n", "y_pred", "=", "model", ".", "predict", "(", "test_x", ")", "\n", "test_y_cat", "=", "one_hot_to_categorical", "(", "test_y", ")", "\n", "y_pred_cat", "=", "one_hot_to_categorical", "(", "y_pred", ")", "\n", "acc", "=", "accuracy_score", "(", "test_y_cat", ",", "y_pred_cat", ")", "\n", "\n", "#clean memory???", "\n", "train_x", ",", "train_y", ",", "model", "=", "None", ",", "None", ",", "None", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "#return the accuracy", "\n", "#print(\"data with shape:\", train_x.shape, train_y.shape, 'train=', train_file, 'test=', test_file, 'with fraction', percent_dataset, 'had acc', acc)", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.e_2_rnn_aug.compute_baselines": [[52, 80], ["range", "print", "writer.write", "len", "methods.load_pickle", "e_2_rnn_aug.run_model", "performances.append", "str"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.load_pickle", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.b_2_train_eval.run_model"], ["", "def", "compute_baselines", "(", "writer", ")", ":", "\n", "\n", "#baseline computation", "\n", "\t", "for", "size_folder", "in", "size_folders", ":", "\n", "\n", "#get all six datasets", "\n", "\t\t", "dataset_folders", "=", "[", "size_folder", "+", "'/'", "+", "s", "for", "s", "in", "datasets", "]", "\n", "performances", "=", "[", "]", "\n", "\n", "#for each dataset", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset_folders", ")", ")", ":", "\n", "\n", "#initialize all the variables", "\n", "\t\t\t", "dataset_folder", "=", "dataset_folders", "[", "i", "]", "\n", "dataset", "=", "datasets", "[", "i", "]", "\n", "num_classes", "=", "num_classes_list", "[", "i", "]", "\n", "input_size", "=", "input_size_list", "[", "i", "]", "\n", "word2vec_pickle", "=", "dataset_folder", "+", "'/word2vec.p'", "\n", "word2vec", "=", "load_pickle", "(", "word2vec_pickle", ")", "\n", "\n", "train_path", "=", "dataset_folder", "+", "'/train_aug_st.txt'", "\n", "test_path", "=", "'size_data_t1/test/'", "+", "dataset", "+", "'/test.txt'", "\n", "acc", "=", "run_model", "(", "train_path", ",", "test_path", ",", "num_classes", ",", "input_size", ",", "1", ",", "word2vec", ")", "\n", "performances", ".", "append", "(", "str", "(", "acc", ")", ")", "\n", "\n", "", "line", "=", "','", ".", "join", "(", "performances", ")", "\n", "print", "(", "line", ")", "\n", "writer", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.e_2_rnn_baselines.run_model": [[10, 47], ["methods.build_model", "methods.get_x_y", "methods.get_x_y", "methods.build_model.fit", "methods.build_model.predict", "methods.one_hot_to_categorical", "methods.one_hot_to_categorical", "accuracy_score", "gc.collect", "EarlyStopping"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.build_model", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical"], ["def", "run_model", "(", "train_file", ",", "test_file", ",", "num_classes", ",", "input_size", ",", "percent_dataset", ",", "word2vec", ")", ":", "\n", "\n", "#initialize model", "\n", "\t", "model", "=", "build_model", "(", "input_size", ",", "word2vec_len", ",", "num_classes", ")", "\n", "\n", "#load data", "\n", "train_x", ",", "train_y", "=", "get_x_y", "(", "train_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "percent_dataset", ")", "\n", "test_x", ",", "test_y", "=", "get_x_y", "(", "test_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "1", ")", "\n", "\n", "#implement early stopping", "\n", "callbacks", "=", "[", "EarlyStopping", "(", "monitor", "=", "'val_loss'", ",", "patience", "=", "3", ")", "]", "\n", "\n", "#train model", "\n", "model", ".", "fit", "(", "train_x", ",", "\n", "train_y", ",", "\n", "epochs", "=", "100000", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "validation_split", "=", "0.1", ",", "\n", "batch_size", "=", "1024", ",", "\n", "shuffle", "=", "True", ",", "\n", "verbose", "=", "0", ")", "\n", "#model.save('checkpoints/lol')", "\n", "#model = load_model('checkpoints/lol')", "\n", "\n", "#evaluate model", "\n", "y_pred", "=", "model", ".", "predict", "(", "test_x", ")", "\n", "test_y_cat", "=", "one_hot_to_categorical", "(", "test_y", ")", "\n", "y_pred_cat", "=", "one_hot_to_categorical", "(", "y_pred", ")", "\n", "acc", "=", "accuracy_score", "(", "test_y_cat", ",", "y_pred_cat", ")", "\n", "\n", "#clean memory???", "\n", "train_x", ",", "train_y", "=", "None", ",", "None", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "#return the accuracy", "\n", "#print(\"data with shape:\", train_x.shape, train_y.shape, 'train=', train_file, 'test=', test_file, 'with fraction', percent_dataset, 'had acc', acc)", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.e_2_rnn_baselines.compute_baselines": [[52, 80], ["range", "print", "writer.write", "len", "methods.load_pickle", "e_2_rnn_baselines.run_model", "performances.append", "str"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.load_pickle", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.b_2_train_eval.run_model"], ["", "def", "compute_baselines", "(", "writer", ")", ":", "\n", "\n", "#baseline computation", "\n", "\t", "for", "size_folder", "in", "size_folders", ":", "\n", "\n", "#get all six datasets", "\n", "\t\t", "dataset_folders", "=", "[", "size_folder", "+", "'/'", "+", "s", "for", "s", "in", "datasets", "]", "\n", "performances", "=", "[", "]", "\n", "\n", "#for each dataset", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset_folders", ")", ")", ":", "\n", "\n", "#initialize all the variables", "\n", "\t\t\t", "dataset_folder", "=", "dataset_folders", "[", "i", "]", "\n", "dataset", "=", "datasets", "[", "i", "]", "\n", "num_classes", "=", "num_classes_list", "[", "i", "]", "\n", "input_size", "=", "input_size_list", "[", "i", "]", "\n", "word2vec_pickle", "=", "dataset_folder", "+", "'/word2vec.p'", "\n", "word2vec", "=", "load_pickle", "(", "word2vec_pickle", ")", "\n", "\n", "train_path", "=", "dataset_folder", "+", "'/train_orig.txt'", "\n", "test_path", "=", "'size_data_t1/test/'", "+", "dataset", "+", "'/test.txt'", "\n", "acc", "=", "run_model", "(", "train_path", ",", "test_path", ",", "num_classes", ",", "input_size", ",", "1", ",", "word2vec", ")", "\n", "performances", ".", "append", "(", "str", "(", "acc", ")", ")", "\n", "\n", "", "line", "=", "','", ".", "join", "(", "performances", ")", "\n", "print", "(", "line", ")", "\n", "writer", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.b_2_train_eval.run_model": [[10, 47], ["methods.build_model", "methods.get_x_y", "methods.get_x_y", "methods.build_model.fit", "methods.build_model.predict", "methods.one_hot_to_categorical", "methods.one_hot_to_categorical", "accuracy_score", "gc.collect", "EarlyStopping"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.build_model", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical"], ["def", "run_model", "(", "train_file", ",", "test_file", ",", "num_classes", ",", "percent_dataset", ")", ":", "\n", "\n", "#initialize model", "\n", "\t", "model", "=", "build_model", "(", "input_size", ",", "word2vec_len", ",", "num_classes", ")", "\n", "\n", "#load data", "\n", "train_x", ",", "train_y", "=", "get_x_y", "(", "train_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "percent_dataset", ")", "\n", "test_x", ",", "test_y", "=", "get_x_y", "(", "test_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "1", ")", "\n", "\n", "#implement early stopping", "\n", "callbacks", "=", "[", "EarlyStopping", "(", "monitor", "=", "'val_loss'", ",", "patience", "=", "3", ")", "]", "\n", "\n", "#train model", "\n", "model", ".", "fit", "(", "train_x", ",", "\n", "train_y", ",", "\n", "epochs", "=", "100000", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "validation_split", "=", "0.1", ",", "\n", "batch_size", "=", "1024", ",", "\n", "shuffle", "=", "True", ",", "\n", "verbose", "=", "0", ")", "\n", "#model.save('checkpoints/lol')", "\n", "#model = load_model('checkpoints/lol')", "\n", "\n", "#evaluate model", "\n", "y_pred", "=", "model", ".", "predict", "(", "test_x", ")", "\n", "test_y_cat", "=", "one_hot_to_categorical", "(", "test_y", ")", "\n", "y_pred_cat", "=", "one_hot_to_categorical", "(", "y_pred", ")", "\n", "acc", "=", "accuracy_score", "(", "test_y_cat", ",", "y_pred_cat", ")", "\n", "\n", "#clean memory???", "\n", "train_x", ",", "train_y", "=", "None", ",", "None", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "#return the accuracy", "\n", "#print(\"data with shape:\", train_x.shape, train_y.shape, 'train=', train_file, 'test=', test_file, 'with fraction', percent_dataset, 'had acc', acc)", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.e_2_cnn_aug.run_cnn": [[10, 47], ["methods.build_cnn", "methods.get_x_y", "methods.get_x_y", "methods.build_cnn.fit", "methods.build_cnn.predict", "methods.one_hot_to_categorical", "methods.one_hot_to_categorical", "accuracy_score", "gc.collect", "EarlyStopping"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.build_cnn", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical"], ["def", "run_cnn", "(", "train_file", ",", "test_file", ",", "num_classes", ",", "input_size", ",", "percent_dataset", ",", "word2vec", ")", ":", "\n", "\n", "#initialize model", "\n", "\t", "model", "=", "build_cnn", "(", "input_size", ",", "word2vec_len", ",", "num_classes", ")", "\n", "\n", "#load data", "\n", "train_x", ",", "train_y", "=", "get_x_y", "(", "train_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "percent_dataset", ")", "\n", "test_x", ",", "test_y", "=", "get_x_y", "(", "test_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "1", ")", "\n", "\n", "#implement early stopping", "\n", "callbacks", "=", "[", "EarlyStopping", "(", "monitor", "=", "'val_loss'", ",", "patience", "=", "3", ")", "]", "\n", "\n", "#train model", "\n", "model", ".", "fit", "(", "train_x", ",", "\n", "train_y", ",", "\n", "epochs", "=", "100000", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "validation_split", "=", "0.1", ",", "\n", "batch_size", "=", "1024", ",", "\n", "shuffle", "=", "True", ",", "\n", "verbose", "=", "0", ")", "\n", "#model.save('checkpoints/lol')", "\n", "#model = load_model('checkpoints/lol')", "\n", "\n", "#evaluate model", "\n", "y_pred", "=", "model", ".", "predict", "(", "test_x", ")", "\n", "test_y_cat", "=", "one_hot_to_categorical", "(", "test_y", ")", "\n", "y_pred_cat", "=", "one_hot_to_categorical", "(", "y_pred", ")", "\n", "acc", "=", "accuracy_score", "(", "test_y_cat", ",", "y_pred_cat", ")", "\n", "\n", "#clean memory???", "\n", "train_x", ",", "train_y", ",", "model", "=", "None", ",", "None", ",", "None", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "#return the accuracy", "\n", "#print(\"data with shape:\", train_x.shape, train_y.shape, 'train=', train_file, 'test=', test_file, 'with fraction', percent_dataset, 'had acc', acc)", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.e_2_cnn_aug.compute_baselines": [[52, 80], ["range", "print", "writer.write", "len", "methods.load_pickle", "e_2_cnn_aug.run_cnn", "performances.append", "str"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.load_pickle", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.a_2_train_eval.run_cnn"], ["", "def", "compute_baselines", "(", "writer", ")", ":", "\n", "\n", "#baseline computation", "\n", "\t", "for", "size_folder", "in", "size_folders", ":", "\n", "\n", "#get all six datasets", "\n", "\t\t", "dataset_folders", "=", "[", "size_folder", "+", "'/'", "+", "s", "for", "s", "in", "datasets", "]", "\n", "performances", "=", "[", "]", "\n", "\n", "#for each dataset", "\n", "for", "i", "in", "range", "(", "len", "(", "dataset_folders", ")", ")", ":", "\n", "\n", "#initialize all the variables", "\n", "\t\t\t", "dataset_folder", "=", "dataset_folders", "[", "i", "]", "\n", "dataset", "=", "datasets", "[", "i", "]", "\n", "num_classes", "=", "num_classes_list", "[", "i", "]", "\n", "input_size", "=", "input_size_list", "[", "i", "]", "\n", "word2vec_pickle", "=", "dataset_folder", "+", "'/word2vec.p'", "\n", "word2vec", "=", "load_pickle", "(", "word2vec_pickle", ")", "\n", "\n", "train_path", "=", "dataset_folder", "+", "'/train_aug_st.txt'", "\n", "test_path", "=", "'size_data_t1/test/'", "+", "dataset", "+", "'/test.txt'", "\n", "acc", "=", "run_cnn", "(", "train_path", ",", "test_path", ",", "num_classes", ",", "input_size", ",", "1", ",", "word2vec", ")", "\n", "performances", ".", "append", "(", "str", "(", "acc", ")", ")", "\n", "\n", "", "line", "=", "','", ".", "join", "(", "performances", ")", "\n", "print", "(", "line", ")", "\n", "writer", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.d_2_tsne.train_x": [[13, 36], ["open().readlines", "len", "np.zeros", "enumerate", "line[].split", "int", "sentence.split", "enumerate", "open"], "function", ["None"], ["def", "train_x", "(", "train_txt", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ")", ":", "\n", "\n", "#read in lines", "\n", "\t", "train_lines", "=", "open", "(", "train_txt", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "num_lines", "=", "len", "(", "train_lines", ")", "\n", "\n", "x_matrix", "=", "np", ".", "zeros", "(", "(", "num_lines", ",", "input_size", ",", "word2vec_len", ")", ")", "\n", "\n", "#insert values", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "train_lines", ")", ":", "\n", "\n", "\t\t", "parts", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "'\\t'", ")", "\n", "label", "=", "int", "(", "parts", "[", "0", "]", ")", "\n", "sentence", "=", "parts", "[", "1", "]", "\n", "\n", "#insert x", "\n", "words", "=", "sentence", ".", "split", "(", "' '", ")", "\n", "words", "=", "words", "[", ":", "x_matrix", ".", "shape", "[", "1", "]", "]", "#cut off if too long", "\n", "for", "j", ",", "word", "in", "enumerate", "(", "words", ")", ":", "\n", "\t\t\t", "if", "word", "in", "word2vec", ":", "\n", "\t\t\t\t", "x_matrix", "[", "i", ",", "j", ",", ":", "]", "=", "word2vec", "[", "word", "]", "\n", "\n", "", "", "", "return", "x_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.d_2_tsne.get_dense_output": [[37, 47], ["d_2_tsne.train_x", "load_model", "keras.backend.function", "K.function."], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.d_2_tsne.train_x"], ["", "def", "get_dense_output", "(", "model_checkpoint", ",", "file", ",", "num_classes", ")", ":", "\n", "\n", "\t", "x", "=", "train_x", "(", "file", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ")", "\n", "\n", "model", "=", "load_model", "(", "model_checkpoint", ")", "\n", "\n", "get_3rd_layer_output", "=", "K", ".", "function", "(", "[", "model", ".", "layers", "[", "0", "]", ".", "input", "]", ",", "[", "model", ".", "layers", "[", "4", "]", ".", "output", "]", ")", "\n", "layer_output", "=", "get_3rd_layer_output", "(", "[", "x", "]", ")", "[", "0", "]", "\n", "\n", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.d_2_tsne.get_tsne_labels": [[48, 59], ["open().readlines", "enumerate", "line[].split", "int", "labels.append", "alphas.append", "open"], "function", ["None"], ["", "def", "get_tsne_labels", "(", "file", ")", ":", "\n", "\t", "labels", "=", "[", "]", "\n", "alphas", "=", "[", "]", "\n", "lines", "=", "open", "(", "file", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "\t\t", "parts", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "'\\t'", ")", "\n", "_class", "=", "int", "(", "parts", "[", "0", "]", ")", "\n", "alpha", "=", "i", "%", "10", "\n", "labels", ".", "append", "(", "_class", ")", "\n", "alphas", ".", "append", "(", "alpha", ")", "\n", "", "return", "labels", ",", "alphas", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.d_2_tsne.get_plot_vectors": [[60, 64], ["sklearn.manifold.TSNE().fit_transform", "sklearn.manifold.TSNE"], "function", ["None"], ["", "def", "get_plot_vectors", "(", "layer_output", ")", ":", "\n", "\n", "\t", "tsne", "=", "TSNE", "(", "n_components", "=", "2", ")", ".", "fit_transform", "(", "layer_output", ")", "\n", "return", "tsne", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.d_2_tsne.plot_tsne": [[65, 117], ["labels.tolist.tolist", "list", "matplotlib.subplots", "matplotlib.legend", "matplotlib.savefig", "matplotlib.clf", "sorted", "set", "enumerate", "ax.scatter", "matplotlib.axis", "x.append", "y.append", "int"], "function", ["None"], ["", "def", "plot_tsne", "(", "tsne", ",", "labels", ",", "output_path", ")", ":", "\n", "\n", "\t", "label_to_legend_label", "=", "{", "'outputs_f4/pc_tsne.png'", ":", "{", "0", ":", "'Con (augmented)'", ",", "\n", "100", ":", "'Con (original)'", ",", "\n", "1", ":", "'Pro (augmented)'", ",", "\n", "101", ":", "'Pro (original)'", "}", ",", "\n", "'outputs_f4/trec_tsne.png'", ":", "{", "0", ":", "'Description (augmented)'", ",", "\n", "100", ":", "'Description (original)'", ",", "\n", "1", ":", "'Entity (augmented)'", ",", "\n", "101", ":", "'Entity (original)'", ",", "\n", "2", ":", "'Abbreviation (augmented)'", ",", "\n", "102", ":", "'Abbreviation (original)'", ",", "\n", "3", ":", "'Human (augmented)'", ",", "\n", "103", ":", "'Human (original)'", ",", "\n", "4", ":", "'Location (augmented)'", ",", "\n", "104", ":", "'Location (original)'", ",", "\n", "5", ":", "'Number (augmented)'", ",", "\n", "105", ":", "'Number (original)'", "}", "}", "\n", "\n", "plot_to_legend_size", "=", "{", "'outputs_f4/pc_tsne.png'", ":", "11", ",", "'outputs_f4/trec_tsne.png'", ":", "6", "}", "\n", "\n", "labels", "=", "labels", ".", "tolist", "(", ")", "\n", "big_groups", "=", "[", "label", "for", "label", "in", "labels", "if", "label", "<", "100", "]", "\n", "big_groups", "=", "list", "(", "sorted", "(", "set", "(", "big_groups", ")", ")", ")", "\n", "\n", "colors", "=", "[", "'b'", ",", "'g'", ",", "'r'", ",", "'c'", ",", "'m'", ",", "'y'", ",", "'k'", ",", "'#ff1493'", ",", "'#FF4500'", "]", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "\n", "for", "big_group", "in", "big_groups", ":", "\n", "\n", "\t\t", "for", "group", "in", "[", "big_group", ",", "big_group", "+", "100", "]", ":", "\n", "\n", "\t\t\t", "x", ",", "y", "=", "[", "]", ",", "[", "]", "\n", "\n", "for", "j", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "\t\t\t\t", "if", "label", "==", "group", ":", "\n", "\t\t\t\t\t", "x", ".", "append", "(", "tsne", "[", "j", "]", "[", "0", "]", ")", "\n", "y", ".", "append", "(", "tsne", "[", "j", "]", "[", "1", "]", ")", "\n", "\n", "#params", "\n", "", "", "color", "=", "colors", "[", "int", "(", "group", "%", "100", ")", "]", "\n", "marker", "=", "'x'", "if", "group", "<", "100", "else", "'o'", "\n", "size", "=", "1", "if", "group", "<", "100", "else", "27", "\n", "legend_label", "=", "label_to_legend_label", "[", "output_path", "]", "[", "group", "]", "\n", "\n", "ax", ".", "scatter", "(", "x", ",", "y", ",", "color", "=", "color", ",", "marker", "=", "marker", ",", "s", "=", "size", ",", "label", "=", "legend_label", ")", "\n", "plt", ".", "axis", "(", "'off'", ")", "\n", "\n", "", "", "legend_size", "=", "plot_to_legend_size", "[", "output_path", "]", "\n", "plt", ".", "legend", "(", "prop", "=", "{", "'size'", ":", "legend_size", "}", ")", "\n", "plt", ".", "savefig", "(", "output_path", ",", "dpi", "=", "1000", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.get_only_chars": [[33, 54], ["line.lower.replace", "line.lower.replace", "line.lower.replace", "line.lower.replace", "line.lower.replace", "line.lower.lower", "re.sub"], "function", ["None"], ["def", "get_only_chars", "(", "line", ")", ":", "\n", "\n", "    ", "clean_line", "=", "\"\"", "\n", "\n", "line", "=", "line", ".", "replace", "(", "\"\u2019\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"'\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"-\"", ",", "\" \"", ")", "#replace hyphens with spaces", "\n", "line", "=", "line", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "line", "=", "line", ".", "lower", "(", ")", "\n", "\n", "for", "char", "in", "line", ":", "\n", "        ", "if", "char", "in", "'qwertyuiopasdfghjklzxcvbnm '", ":", "\n", "            ", "clean_line", "+=", "char", "\n", "", "else", ":", "\n", "            ", "clean_line", "+=", "' '", "\n", "\n", "", "", "clean_line", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "clean_line", ")", "#delete extra spaces", "\n", "if", "clean_line", "[", "0", "]", "==", "' '", ":", "\n", "        ", "clean_line", "=", "clean_line", "[", "1", ":", "]", "\n", "", "return", "clean_line", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.synonym_replacement": [[65, 85], ["words.copy", "list", "random.shuffle", "sentence.split", "set", "nlp_aug.get_synonyms", "len", "random.choice", "list"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_synonyms"], ["def", "synonym_replacement", "(", "words", ",", "n", ")", ":", "\n", "\t", "new_words", "=", "words", ".", "copy", "(", ")", "\n", "random_word_list", "=", "list", "(", "set", "(", "[", "word", "for", "word", "in", "words", "if", "word", "not", "in", "stop_words", "]", ")", ")", "\n", "random", ".", "shuffle", "(", "random_word_list", ")", "\n", "num_replaced", "=", "0", "\n", "for", "random_word", "in", "random_word_list", ":", "\n", "\t\t", "synonyms", "=", "get_synonyms", "(", "random_word", ")", "\n", "if", "len", "(", "synonyms", ")", ">=", "1", ":", "\n", "\t\t\t", "synonym", "=", "random", ".", "choice", "(", "list", "(", "synonyms", ")", ")", "\n", "new_words", "=", "[", "synonym", "if", "word", "==", "random_word", "else", "word", "for", "word", "in", "new_words", "]", "\n", "#print(\"replaced\", random_word, \"with\", synonym)", "\n", "num_replaced", "+=", "1", "\n", "", "if", "num_replaced", ">=", "n", ":", "#only replace up to n words", "\n", "\t\t\t", "break", "\n", "\n", "#this is stupid but we need it, trust me", "\n", "", "", "sentence", "=", "' '", ".", "join", "(", "new_words", ")", "\n", "new_words", "=", "sentence", ".", "split", "(", "' '", ")", "\n", "\n", "return", "new_words", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.get_synonyms": [[86, 96], ["set", "nltk.corpus.wordnet.synsets", "list", "syn.lemmas", "set.remove", "l.name().replace().replace().lower", "set.add", "l.name().replace().replace", "l.name().replace", "l.name"], "function", ["None"], ["", "def", "get_synonyms", "(", "word", ")", ":", "\n", "\t", "synonyms", "=", "set", "(", ")", "\n", "for", "syn", "in", "wordnet", ".", "synsets", "(", "word", ")", ":", "\n", "\t\t", "for", "l", "in", "syn", ".", "lemmas", "(", ")", ":", "\n", "\t\t\t", "synonym", "=", "l", ".", "name", "(", ")", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", ".", "replace", "(", "\"-\"", ",", "\" \"", ")", ".", "lower", "(", ")", "\n", "synonym", "=", "\"\"", ".", "join", "(", "[", "char", "for", "char", "in", "synonym", "if", "char", "in", "' qwertyuiopasdfghjklzxcvbnm'", "]", ")", "\n", "synonyms", ".", "add", "(", "synonym", ")", "\n", "", "", "if", "word", "in", "synonyms", ":", "\n", "\t\t", "synonyms", ".", "remove", "(", "word", ")", "\n", "", "return", "list", "(", "synonyms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.random_deletion": [[102, 121], ["len", "random.uniform", "len", "random.randint", "new_words.append", "len"], "function", ["None"], ["", "def", "random_deletion", "(", "words", ",", "p", ")", ":", "\n", "\n", "#obviously, if there's only one word, don't delete it", "\n", "\t", "if", "len", "(", "words", ")", "==", "1", ":", "\n", "\t\t", "return", "words", "\n", "\n", "#randomly delete words with probability p", "\n", "", "new_words", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "\t\t", "r", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "r", ">", "p", ":", "\n", "\t\t\t", "new_words", ".", "append", "(", "word", ")", "\n", "\n", "#if you end up deleting all words, just return a random word", "\n", "", "", "if", "len", "(", "new_words", ")", "==", "0", ":", "\n", "\t\t", "rand_int", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "words", ")", "-", "1", ")", "\n", "return", "[", "words", "[", "rand_int", "]", "]", "\n", "\n", "", "return", "new_words", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.random_swap": [[127, 132], ["words.copy", "range", "nlp_aug.swap_word"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.swap_word"], ["", "def", "random_swap", "(", "words", ",", "n", ")", ":", "\n", "\t", "new_words", "=", "words", ".", "copy", "(", ")", "\n", "for", "_", "in", "range", "(", "n", ")", ":", "\n", "\t\t", "new_words", "=", "swap_word", "(", "new_words", ")", "\n", "", "return", "new_words", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.swap_word": [[133, 144], ["random.randint", "random.randint", "len", "len"], "function", ["None"], ["", "def", "swap_word", "(", "new_words", ")", ":", "\n", "\t", "random_idx_1", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "new_words", ")", "-", "1", ")", "\n", "random_idx_2", "=", "random_idx_1", "\n", "counter", "=", "0", "\n", "while", "random_idx_2", "==", "random_idx_1", ":", "\n", "\t\t", "random_idx_2", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "new_words", ")", "-", "1", ")", "\n", "counter", "+=", "1", "\n", "if", "counter", ">", "3", ":", "\n", "\t\t\t", "return", "new_words", "\n", "", "", "new_words", "[", "random_idx_1", "]", ",", "new_words", "[", "random_idx_2", "]", "=", "new_words", "[", "random_idx_2", "]", ",", "new_words", "[", "random_idx_1", "]", "\n", "return", "new_words", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.random_addition": [[150, 155], ["words.copy", "range", "nlp_aug.add_word"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.add_word"], ["", "def", "random_addition", "(", "words", ",", "n", ")", ":", "\n", "\t", "new_words", "=", "words", ".", "copy", "(", ")", "\n", "for", "_", "in", "range", "(", "n", ")", ":", "\n", "\t\t", "add_word", "(", "new_words", ")", "\n", "", "return", "new_words", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.add_word": [[156, 168], ["random.randint", "new_words.insert", "len", "nlp_aug.get_synonyms", "len", "random.randint", "len"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_synonyms"], ["", "def", "add_word", "(", "new_words", ")", ":", "\n", "\t", "synonyms", "=", "[", "]", "\n", "counter", "=", "0", "\n", "while", "len", "(", "synonyms", ")", "<", "1", ":", "\n", "\t\t", "random_word", "=", "new_words", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "new_words", ")", "-", "1", ")", "]", "\n", "synonyms", "=", "get_synonyms", "(", "random_word", ")", "\n", "counter", "+=", "1", "\n", "if", "counter", ">=", "10", ":", "\n", "\t\t\t", "return", "\n", "", "", "random_synonym", "=", "synonyms", "[", "0", "]", "\n", "random_idx", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "new_words", ")", "-", "1", ")", "\n", "new_words", ".", "insert", "(", "random_idx", ",", "random_synonym", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.eda_4": [[173, 220], ["nlp_aug.get_only_chars", "get_only_chars.split", "len", "max", "max", "max", "range", "range", "range", "range", "random.shuffle", "augmented_sentences.append", "int", "int", "int", "int", "nlp_aug.synonym_replacement", "augmented_sentences.append", "nlp_aug.random_addition", "augmented_sentences.append", "nlp_aug.random_swap", "augmented_sentences.append", "nlp_aug.random_deletion", "augmented_sentences.append", "nlp_aug.get_only_chars", "len", "random.uniform"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.synonym_replacement", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.random_addition", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.random_swap", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.random_deletion", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars"], ["", "def", "eda_4", "(", "sentence", ",", "alpha_sr", "=", "0.3", ",", "alpha_ri", "=", "0.2", ",", "alpha_rs", "=", "0.1", ",", "p_rd", "=", "0.15", ",", "num_aug", "=", "9", ")", ":", "\n", "\n", "\t", "sentence", "=", "get_only_chars", "(", "sentence", ")", "\n", "words", "=", "sentence", ".", "split", "(", "' '", ")", "\n", "words", "=", "[", "word", "for", "word", "in", "words", "if", "word", "is", "not", "''", "]", "\n", "num_words", "=", "len", "(", "words", ")", "\n", "\n", "augmented_sentences", "=", "[", "]", "\n", "num_new_per_technique", "=", "int", "(", "num_aug", "/", "4", ")", "+", "1", "\n", "n_sr", "=", "max", "(", "1", ",", "int", "(", "alpha_sr", "*", "num_words", ")", ")", "\n", "n_ri", "=", "max", "(", "1", ",", "int", "(", "alpha_ri", "*", "num_words", ")", ")", "\n", "n_rs", "=", "max", "(", "1", ",", "int", "(", "alpha_rs", "*", "num_words", ")", ")", "\n", "\n", "#sr", "\n", "for", "_", "in", "range", "(", "num_new_per_technique", ")", ":", "\n", "\t\t", "a_words", "=", "synonym_replacement", "(", "words", ",", "n_sr", ")", "\n", "augmented_sentences", ".", "append", "(", "' '", ".", "join", "(", "a_words", ")", ")", "\n", "\n", "#ri", "\n", "", "for", "_", "in", "range", "(", "num_new_per_technique", ")", ":", "\n", "\t\t", "a_words", "=", "random_addition", "(", "words", ",", "n_ri", ")", "\n", "augmented_sentences", ".", "append", "(", "' '", ".", "join", "(", "a_words", ")", ")", "\n", "\n", "#rs", "\n", "", "for", "_", "in", "range", "(", "num_new_per_technique", ")", ":", "\n", "\t\t", "a_words", "=", "random_swap", "(", "words", ",", "n_rs", ")", "\n", "augmented_sentences", ".", "append", "(", "' '", ".", "join", "(", "a_words", ")", ")", "\n", "\n", "#rd", "\n", "", "for", "_", "in", "range", "(", "num_new_per_technique", ")", ":", "\n", "\t\t", "a_words", "=", "random_deletion", "(", "words", ",", "p_rd", ")", "\n", "augmented_sentences", ".", "append", "(", "' '", ".", "join", "(", "a_words", ")", ")", "\n", "\n", "", "augmented_sentences", "=", "[", "get_only_chars", "(", "sentence", ")", "for", "sentence", "in", "augmented_sentences", "]", "\n", "shuffle", "(", "augmented_sentences", ")", "\n", "\n", "#trim so that we have the desired number of augmented sentences", "\n", "if", "num_aug", ">=", "1", ":", "\n", "\t\t", "augmented_sentences", "=", "augmented_sentences", "[", ":", "num_aug", "]", "\n", "", "else", ":", "\n", "\t\t", "keep_prob", "=", "num_aug", "/", "len", "(", "augmented_sentences", ")", "\n", "augmented_sentences", "=", "[", "s", "for", "s", "in", "augmented_sentences", "if", "random", ".", "uniform", "(", "0", ",", "1", ")", "<", "keep_prob", "]", "\n", "\n", "#append the original sentence", "\n", "", "augmented_sentences", ".", "append", "(", "sentence", ")", "\n", "\n", "return", "augmented_sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.SR": [[221, 240], ["nlp_aug.get_only_chars", "get_only_chars.split", "len", "max", "range", "random.shuffle", "augmented_sentences.append", "int", "nlp_aug.synonym_replacement", "augmented_sentences.append", "nlp_aug.get_only_chars"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.synonym_replacement", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars"], ["", "def", "SR", "(", "sentence", ",", "alpha_sr", ",", "n_aug", "=", "9", ")", ":", "\n", "\n", "\t", "sentence", "=", "get_only_chars", "(", "sentence", ")", "\n", "words", "=", "sentence", ".", "split", "(", "' '", ")", "\n", "num_words", "=", "len", "(", "words", ")", "\n", "\n", "augmented_sentences", "=", "[", "]", "\n", "n_sr", "=", "max", "(", "1", ",", "int", "(", "alpha_sr", "*", "num_words", ")", ")", "\n", "\n", "for", "_", "in", "range", "(", "n_aug", ")", ":", "\n", "\t\t", "a_words", "=", "synonym_replacement", "(", "words", ",", "n_sr", ")", "\n", "augmented_sentences", ".", "append", "(", "' '", ".", "join", "(", "a_words", ")", ")", "\n", "\n", "", "augmented_sentences", "=", "[", "get_only_chars", "(", "sentence", ")", "for", "sentence", "in", "augmented_sentences", "]", "\n", "shuffle", "(", "augmented_sentences", ")", "\n", "\n", "augmented_sentences", ".", "append", "(", "sentence", ")", "\n", "\n", "return", "augmented_sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.RI": [[241, 260], ["nlp_aug.get_only_chars", "get_only_chars.split", "len", "max", "range", "random.shuffle", "augmented_sentences.append", "int", "nlp_aug.random_addition", "augmented_sentences.append", "nlp_aug.get_only_chars"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.random_addition", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars"], ["", "def", "RI", "(", "sentence", ",", "alpha_ri", ",", "n_aug", "=", "9", ")", ":", "\n", "\n", "\t", "sentence", "=", "get_only_chars", "(", "sentence", ")", "\n", "words", "=", "sentence", ".", "split", "(", "' '", ")", "\n", "num_words", "=", "len", "(", "words", ")", "\n", "\n", "augmented_sentences", "=", "[", "]", "\n", "n_ri", "=", "max", "(", "1", ",", "int", "(", "alpha_ri", "*", "num_words", ")", ")", "\n", "\n", "for", "_", "in", "range", "(", "n_aug", ")", ":", "\n", "\t\t", "a_words", "=", "random_addition", "(", "words", ",", "n_ri", ")", "\n", "augmented_sentences", ".", "append", "(", "' '", ".", "join", "(", "a_words", ")", ")", "\n", "\n", "", "augmented_sentences", "=", "[", "get_only_chars", "(", "sentence", ")", "for", "sentence", "in", "augmented_sentences", "]", "\n", "shuffle", "(", "augmented_sentences", ")", "\n", "\n", "augmented_sentences", ".", "append", "(", "sentence", ")", "\n", "\n", "return", "augmented_sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.RS": [[261, 280], ["nlp_aug.get_only_chars", "get_only_chars.split", "len", "max", "range", "random.shuffle", "augmented_sentences.append", "int", "nlp_aug.random_swap", "augmented_sentences.append", "nlp_aug.get_only_chars"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.random_swap", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars"], ["", "def", "RS", "(", "sentence", ",", "alpha_rs", ",", "n_aug", "=", "9", ")", ":", "\n", "\n", "\t", "sentence", "=", "get_only_chars", "(", "sentence", ")", "\n", "words", "=", "sentence", ".", "split", "(", "' '", ")", "\n", "num_words", "=", "len", "(", "words", ")", "\n", "\n", "augmented_sentences", "=", "[", "]", "\n", "n_rs", "=", "max", "(", "1", ",", "int", "(", "alpha_rs", "*", "num_words", ")", ")", "\n", "\n", "for", "_", "in", "range", "(", "n_aug", ")", ":", "\n", "\t\t", "a_words", "=", "random_swap", "(", "words", ",", "n_rs", ")", "\n", "augmented_sentences", ".", "append", "(", "' '", ".", "join", "(", "a_words", ")", ")", "\n", "\n", "", "augmented_sentences", "=", "[", "get_only_chars", "(", "sentence", ")", "for", "sentence", "in", "augmented_sentences", "]", "\n", "shuffle", "(", "augmented_sentences", ")", "\n", "\n", "augmented_sentences", ".", "append", "(", "sentence", ")", "\n", "\n", "return", "augmented_sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.nlp_aug.RD": [[281, 300], ["nlp_aug.get_only_chars", "get_only_chars.split", "len", "range", "random.shuffle", "augmented_sentences.append", "nlp_aug.random_deletion", "augmented_sentences.append", "nlp_aug.get_only_chars"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.random_deletion", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars"], ["", "def", "RD", "(", "sentence", ",", "alpha_rd", ",", "n_aug", "=", "9", ")", ":", "\n", "\n", "\t", "sentence", "=", "get_only_chars", "(", "sentence", ")", "\n", "words", "=", "sentence", ".", "split", "(", "' '", ")", "\n", "words", "=", "[", "word", "for", "word", "in", "words", "if", "word", "is", "not", "''", "]", "\n", "num_words", "=", "len", "(", "words", ")", "\n", "\n", "augmented_sentences", "=", "[", "]", "\n", "\n", "for", "_", "in", "range", "(", "n_aug", ")", ":", "\n", "\t\t", "a_words", "=", "random_deletion", "(", "words", ",", "alpha_rd", ")", "\n", "augmented_sentences", ".", "append", "(", "' '", ".", "join", "(", "a_words", ")", ")", "\n", "\n", "", "augmented_sentences", "=", "[", "get_only_chars", "(", "sentence", ")", "for", "sentence", "in", "augmented_sentences", "]", "\n", "shuffle", "(", "augmented_sentences", ")", "\n", "\n", "augmented_sentences", ".", "append", "(", "sentence", ")", "\n", "\n", "return", "augmented_sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.a_2_train_eval.run_cnn": [[10, 47], ["methods.build_cnn", "methods.get_x_y", "methods.get_x_y", "methods.build_cnn.fit", "methods.build_cnn.predict", "methods.one_hot_to_categorical", "methods.one_hot_to_categorical", "accuracy_score", "gc.collect", "EarlyStopping"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.build_cnn", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.get_x_y", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.methods.one_hot_to_categorical"], ["def", "run_cnn", "(", "train_file", ",", "test_file", ",", "num_classes", ",", "percent_dataset", ")", ":", "\n", "\n", "#initialize model", "\n", "\t", "model", "=", "build_cnn", "(", "input_size", ",", "word2vec_len", ",", "num_classes", ")", "\n", "\n", "#load data", "\n", "train_x", ",", "train_y", "=", "get_x_y", "(", "train_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "percent_dataset", ")", "\n", "test_x", ",", "test_y", "=", "get_x_y", "(", "test_file", ",", "num_classes", ",", "word2vec_len", ",", "input_size", ",", "word2vec", ",", "1", ")", "\n", "\n", "#implement early stopping", "\n", "callbacks", "=", "[", "EarlyStopping", "(", "monitor", "=", "'val_loss'", ",", "patience", "=", "3", ")", "]", "\n", "\n", "#train model", "\n", "model", ".", "fit", "(", "train_x", ",", "\n", "train_y", ",", "\n", "epochs", "=", "100000", ",", "\n", "callbacks", "=", "callbacks", ",", "\n", "validation_split", "=", "0.1", ",", "\n", "batch_size", "=", "1024", ",", "\n", "shuffle", "=", "True", ",", "\n", "verbose", "=", "0", ")", "\n", "#model.save('checkpoints/lol')", "\n", "#model = load_model('checkpoints/lol')", "\n", "\n", "#evaluate model", "\n", "y_pred", "=", "model", ".", "predict", "(", "test_x", ")", "\n", "test_y_cat", "=", "one_hot_to_categorical", "(", "test_y", ")", "\n", "y_pred_cat", "=", "one_hot_to_categorical", "(", "y_pred", ")", "\n", "acc", "=", "accuracy_score", "(", "test_y_cat", ",", "y_pred_cat", ")", "\n", "\n", "#clean memory???", "\n", "train_x", ",", "train_y", ",", "test_x", ",", "test_y", ",", "model", "=", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "gc", ".", "collect", "(", ")", "\n", "\n", "#return the accuracy", "\n", "#print(\"data with shape:\", train_x.shape, train_y.shape, 'train=', train_file, 'test=', test_file, 'with fraction', percent_dataset, 'had acc', acc)", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.experiments.d_0_preprocess.generate_short": [[3, 10], ["open().readlines", "int", "open", "open.write", "open", "len"], "function", ["None"], ["def", "generate_short", "(", "input_file", ",", "output_file", ",", "alpha", ")", ":", "\n", "\t", "lines", "=", "open", "(", "input_file", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "increment", "=", "int", "(", "len", "(", "lines", ")", "/", "alpha", ")", "\n", "lines", "=", "lines", "[", ":", ":", "increment", "]", "\n", "writer", "=", "open", "(", "output_file", ",", "'w'", ")", "\n", "for", "line", "in", "lines", ":", "\n", "\t\t", "writer", ".", "write", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.shuffle_lines.shuffle_lines": [[3, 7], ["open().readlines", "random.shuffle", "open().writelines", "open", "open"], "function", ["None"], ["def", "shuffle_lines", "(", "text_file", ")", ":", "\n", "\t", "lines", "=", "open", "(", "text_file", ")", ".", "readlines", "(", ")", "\n", "random", ".", "shuffle", "(", "lines", ")", "\n", "open", "(", "text_file", ",", "'w'", ")", ".", "writelines", "(", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.sst1_clean.get_label": [[3, 16], ["None"], "function", ["None"], ["def", "get_label", "(", "decimal", ")", ":", "\n", "\t", "if", "decimal", ">=", "0", "and", "decimal", "<=", "0.2", ":", "\n", "\t\t", "return", "0", "\n", "", "elif", "decimal", ">", "0.2", "and", "decimal", "<=", "0.4", ":", "\n", "\t\t", "return", "1", "\n", "", "elif", "decimal", ">", "0.4", "and", "decimal", "<=", "0.6", ":", "\n", "\t\t", "return", "2", "\n", "", "elif", "decimal", ">", "0.6", "and", "decimal", "<=", "0.8", ":", "\n", "\t\t", "return", "3", "\n", "", "elif", "decimal", ">", "0.8", "and", "decimal", "<=", "1", ":", "\n", "\t\t", "return", "4", "\n", "", "else", ":", "\n", "\t\t", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.sst1_clean.get_label_binary": [[17, 24], ["None"], "function", ["None"], ["", "", "def", "get_label_binary", "(", "decimal", ")", ":", "\n", "\t", "if", "decimal", ">=", "0", "and", "decimal", "<=", "0.4", ":", "\n", "\t\t", "return", "0", "\n", "", "elif", "decimal", ">", "0.6", "and", "decimal", "<=", "1", ":", "\n", "\t\t", "return", "1", "\n", "", "else", ":", "\n", "\t\t", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.sst1_clean.get_split": [[25, 30], ["None"], "function", ["None"], ["", "", "def", "get_split", "(", "split_num", ")", ":", "\n", "\t", "if", "split_num", "==", "1", "or", "split_num", "==", "3", ":", "\n", "\t\t", "return", "'train'", "\n", "", "elif", "split_num", "==", "2", ":", "\n", "\t\t", "return", "'test'", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.get_stats.get_vocab_size": [[7, 18], ["open().readlines", "set", "len", "line[].split", "open", "set.add"], "function", ["None"], ["def", "get_vocab_size", "(", "filename", ")", ":", "\n", "\t", "lines", "=", "open", "(", "filename", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "\n", "vocab", "=", "set", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "\t\t", "words", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "' '", ")", "\n", "for", "word", "in", "words", ":", "\n", "\t\t\t", "if", "word", "not", "in", "vocab", ":", "\n", "\t\t\t\t", "vocab", ".", "add", "(", "word", ")", "\n", "\n", "", "", "", "return", "len", "(", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.get_stats.get_mean_and_std": [[19, 28], ["open().readlines", "print", "line_lengths.append", "statistics.mean", "statistics.stdev", "max", "open", "len", "line[].split"], "function", ["None"], ["", "def", "get_mean_and_std", "(", "filename", ")", ":", "\n", "\t", "lines", "=", "open", "(", "filename", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "\n", "line_lengths", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "\t\t", "length", "=", "len", "(", "line", "[", ":", "-", "1", "]", ".", "split", "(", "' '", ")", ")", "-", "1", "\n", "line_lengths", ".", "append", "(", "length", ")", "\n", "\n", "", "print", "(", "filename", ",", "statistics", ".", "mean", "(", "line_lengths", ")", ",", "statistics", ".", "stdev", "(", "line_lengths", ")", ",", "max", "(", "line_lengths", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.cr_clean.retrieve_reviews": [[4, 22], ["set", "list", "enumerate", "list", "len", "len", "list.add", "list.add"], "function", ["None"], ["def", "retrieve_reviews", "(", "line", ")", ":", "\n", "\n", "\t", "reviews", "=", "set", "(", ")", "\n", "chars", "=", "list", "(", "line", ")", "\n", "for", "i", ",", "char", "in", "enumerate", "(", "chars", ")", ":", "\n", "\t\t", "if", "char", "==", "'['", ":", "\n", "\t\t\t", "if", "chars", "[", "i", "+", "1", "]", "==", "'-'", ":", "\n", "\t\t\t\t", "reviews", ".", "add", "(", "0", ")", "\n", "", "elif", "chars", "[", "i", "+", "1", "]", "==", "'+'", ":", "\n", "\t\t\t\t", "reviews", ".", "add", "(", "1", ")", "\n", "\n", "", "", "", "reviews", "=", "list", "(", "reviews", ")", "\n", "if", "len", "(", "reviews", ")", "==", "2", ":", "\n", "\t\t", "return", "-", "2", "\n", "", "elif", "len", "(", "reviews", ")", "==", "1", ":", "\n", "\t\t", "return", "reviews", "[", "0", "]", "\n", "", "else", ":", "\n", "\t\t", "return", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.cr_clean.clean_files": [[23, 44], ["open", "open.close", "print", "open().readlines", "print", "cr_clean.retrieve_reviews", "open", "utils.get_only_chars", "open.write", "re.sub", "str"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.cr_clean.retrieve_reviews", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars"], ["", "", "def", "clean_files", "(", "input_files", ",", "output_file", ")", ":", "\n", "\n", "\t", "writer", "=", "open", "(", "output_file", ",", "'w'", ")", "\n", "\n", "for", "input_file", "in", "input_files", ":", "\n", "\t\t", "print", "(", "input_file", ")", "\n", "input_lines", "=", "open", "(", "input_file", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "counter", "=", "0", "\n", "bad_counter", "=", "0", "\n", "for", "line", "in", "input_lines", ":", "\n", "\t\t\t", "review", "=", "retrieve_reviews", "(", "line", ")", "\n", "if", "review", "in", "{", "0", ",", "1", "}", ":", "\n", "\t\t\t\t", "good_line", "=", "get_only_chars", "(", "re", ".", "sub", "(", "\"([\\(\\[]).*?([\\)\\]])\"", ",", "\"\\g<1>\\g<2>\"", ",", "line", ")", ")", "\n", "output_line", "=", "str", "(", "review", ")", "+", "'\\t'", "+", "good_line", "\n", "writer", ".", "write", "(", "output_line", "+", "'\\n'", ")", "\n", "counter", "+=", "1", "\n", "", "elif", "review", "==", "-", "2", ":", "\n", "\t\t\t\t", "bad_counter", "+=", "1", "\n", "", "", "print", "(", "input_file", ",", "counter", ",", "bad_counter", ")", "\n", "\n", "", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.trej_clean.clean": [[6, 18], ["open().readlines", "open", "open.close", "line[].split", "utils.get_only_chars", "print", "open.write", "open", "parts[].split", "str"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars"], ["def", "clean", "(", "input_file", ",", "output_file", ")", ":", "\n", "\t", "lines", "=", "open", "(", "input_file", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "writer", "=", "open", "(", "output_file", ",", "'w'", ")", "\n", "for", "line", "in", "lines", ":", "\n", "\t\t", "parts", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "' '", ")", "\n", "tag", "=", "parts", "[", "0", "]", ".", "split", "(", "':'", ")", "[", "0", "]", "\n", "class_num", "=", "class_name_to_num", "[", "tag", "]", "\n", "sentence", "=", "get_only_chars", "(", "' '", ".", "join", "(", "parts", "[", "1", ":", "]", ")", ")", "\n", "print", "(", "tag", ",", "class_num", ",", "sentence", ")", "\n", "output_line", "=", "str", "(", "class_num", ")", "+", "'\\t'", "+", "sentence", "\n", "writer", ".", "write", "(", "output_line", "+", "'\\n'", ")", "\n", "", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.procon_clean.get_good_stuff": [[4, 9], ["line.find", "utils.get_only_chars"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars"], ["def", "get_good_stuff", "(", "line", ")", ":", "\n", "\t", "idx", "=", "line", ".", "find", "(", "'s>'", ")", "\n", "good", "=", "line", "[", "idx", "+", "2", ":", "-", "8", "]", "\n", "\n", "return", "get_only_chars", "(", "good", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.procon_clean.clean_file": [[10, 33], ["open", "open", "open().readlines", "open().readlines", "procon_clean.get_good_stuff", "procon_clean.get_good_stuff", "procon_clean.get_good_stuff", "procon_clean.get_good_stuff", "open", "int", "len", "open.write", "int", "len", "open.write", "open", "int", "len", "open.write", "int", "len", "open.write", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.procon_clean.get_good_stuff", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.procon_clean.get_good_stuff", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.procon_clean.get_good_stuff", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.procon_clean.get_good_stuff"], ["", "def", "clean_file", "(", "con_file", ",", "pro_file", ",", "output_train", ",", "output_test", ")", ":", "\n", "\n", "\t", "train_writer", "=", "open", "(", "output_train", ",", "'w'", ")", "\n", "test_writer", "=", "open", "(", "output_test", ",", "'w'", ")", "\n", "con_lines", "=", "open", "(", "con_file", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "line", "in", "con_lines", "[", ":", "int", "(", "len", "(", "con_lines", ")", "*", "0.9", ")", "]", ":", "\n", "\t\t", "content", "=", "get_good_stuff", "(", "line", ")", "\n", "if", "len", "(", "content", ")", ">=", "8", ":", "\n", "\t\t\t", "train_writer", ".", "write", "(", "'0\\t'", "+", "content", "+", "'\\n'", ")", "\n", "", "", "for", "line", "in", "con_lines", "[", "int", "(", "len", "(", "con_lines", ")", "*", "0.9", ")", ":", "]", ":", "\n", "\t\t", "content", "=", "get_good_stuff", "(", "line", ")", "\n", "if", "len", "(", "content", ")", ">=", "8", ":", "\n", "\t\t\t", "test_writer", ".", "write", "(", "'0\\t'", "+", "content", "+", "'\\n'", ")", "\n", "\n", "", "", "pro_lines", "=", "open", "(", "pro_file", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "for", "line", "in", "pro_lines", "[", ":", "int", "(", "len", "(", "con_lines", ")", "*", "0.9", ")", "]", ":", "\n", "\t\t", "content", "=", "get_good_stuff", "(", "line", ")", "\n", "if", "len", "(", "content", ")", ">=", "8", ":", "\n", "\t\t\t", "train_writer", ".", "write", "(", "'1\\t'", "+", "content", "+", "'\\n'", ")", "\n", "", "", "for", "line", "in", "pro_lines", "[", "int", "(", "len", "(", "con_lines", ")", "*", "0.9", ")", ":", "]", ":", "\n", "\t\t", "content", "=", "get_good_stuff", "(", "line", ")", "\n", "if", "len", "(", "content", ")", ">=", "8", ":", "\n", "\t\t\t", "test_writer", ".", "write", "(", "'1\\t'", "+", "content", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.bg_clean.clean_csv": [[4, 12], ["open().read", "open().read.split", "print", "len", "print", "open"], "function", ["None"], ["def", "clean_csv", "(", "input_file", ",", "output_file", ")", ":", "\n", "\n", "\t", "input_r", "=", "open", "(", "input_file", ",", "'r'", ")", ".", "read", "(", ")", "\n", "\n", "lines", "=", "input_r", ".", "split", "(", "',,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,'", ")", "\n", "print", "(", "len", "(", "lines", ")", ")", "\n", "for", "line", "in", "lines", "[", ":", "10", "]", ":", "\n", "\t\t", "print", "(", "line", "[", "-", "3", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.preprocess.utils.get_only_chars": [[7, 29], ["line.replace.lower", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "line.replace.replace", "re.sub", "print"], "function", ["None"], ["def", "get_only_chars", "(", "line", ")", ":", "\n", "\n", "    ", "clean_line", "=", "\"\"", "\n", "\n", "line", "=", "line", ".", "lower", "(", ")", "\n", "line", "=", "line", ".", "replace", "(", "\" 's\"", ",", "\" is\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"-\"", ",", "\" \"", ")", "#replace hyphens with spaces", "\n", "line", "=", "line", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"'\"", ",", "\"\"", ")", "\n", "\n", "for", "char", "in", "line", ":", "\n", "        ", "if", "char", "in", "'qwertyuiopasdfghjklzxcvbnm '", ":", "\n", "            ", "clean_line", "+=", "char", "\n", "", "else", ":", "\n", "            ", "clean_line", "+=", "' '", "\n", "\n", "", "", "clean_line", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "clean_line", ")", "#delete extra spaces", "\n", "print", "(", "clean_line", ")", "\n", "if", "clean_line", "[", "0", "]", "==", "' '", ":", "\n", "        ", "clean_line", "=", "clean_line", "[", "1", ":", "]", "\n", "", "return", "clean_line", "", "", ""]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.augment.gen_eda": [[55, 70], ["open", "open().readlines", "enumerate", "open.close", "print", "line[].split", "eda.eda", "open", "open.write", "str"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.eda"], ["", "def", "gen_eda", "(", "train_orig", ",", "output_file", ",", "alpha_sr", ",", "alpha_ri", ",", "alpha_rs", ",", "alpha_rd", ",", "num_aug", "=", "9", ")", ":", "\n", "\n", "    ", "writer", "=", "open", "(", "output_file", ",", "'w'", ")", "\n", "lines", "=", "open", "(", "train_orig", ",", "'r'", ")", ".", "readlines", "(", ")", "\n", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "parts", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "'\\t'", ")", "\n", "label", "=", "parts", "[", "0", "]", "\n", "sentence", "=", "parts", "[", "1", "]", "\n", "aug_sentences", "=", "eda", "(", "sentence", ",", "alpha_sr", "=", "alpha_sr", ",", "alpha_ri", "=", "alpha_ri", ",", "alpha_rs", "=", "alpha_rs", ",", "p_rd", "=", "alpha_rd", ",", "num_aug", "=", "num_aug", ")", "\n", "for", "aug_sentence", "in", "aug_sentences", ":", "\n", "            ", "writer", ".", "write", "(", "label", "+", "\"\\t\"", "+", "aug_sentence", "+", "'\\n'", ")", "\n", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "print", "(", "\"generated augmented sentences with eda for \"", "+", "train_orig", "+", "\" to \"", "+", "output_file", "+", "\" with num_aug=\"", "+", "str", "(", "num_aug", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars": [[33, 54], ["line.lower.replace", "line.lower.replace", "line.lower.replace", "line.lower.replace", "line.lower.replace", "line.lower.lower", "re.sub"], "function", ["None"], ["def", "get_only_chars", "(", "line", ")", ":", "\n", "\n", "    ", "clean_line", "=", "\"\"", "\n", "\n", "line", "=", "line", ".", "replace", "(", "\"\u2019\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"'\"", ",", "\"\"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"-\"", ",", "\" \"", ")", "#replace hyphens with spaces", "\n", "line", "=", "line", ".", "replace", "(", "\"\\t\"", ",", "\" \"", ")", "\n", "line", "=", "line", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "line", "=", "line", ".", "lower", "(", ")", "\n", "\n", "for", "char", "in", "line", ":", "\n", "        ", "if", "char", "in", "'qwertyuiopasdfghjklzxcvbnm '", ":", "\n", "            ", "clean_line", "+=", "char", "\n", "", "else", ":", "\n", "            ", "clean_line", "+=", "' '", "\n", "\n", "", "", "clean_line", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "clean_line", ")", "#delete extra spaces", "\n", "if", "clean_line", "[", "0", "]", "==", "' '", ":", "\n", "        ", "clean_line", "=", "clean_line", "[", "1", ":", "]", "\n", "", "return", "clean_line", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.synonym_replacement": [[65, 85], ["words.copy", "list", "random.shuffle", "sentence.split", "set", "eda.get_synonyms", "len", "random.choice", "list"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_synonyms"], ["def", "synonym_replacement", "(", "words", ",", "n", ")", ":", "\n", "\t", "new_words", "=", "words", ".", "copy", "(", ")", "\n", "random_word_list", "=", "list", "(", "set", "(", "[", "word", "for", "word", "in", "words", "if", "word", "not", "in", "stop_words", "]", ")", ")", "\n", "random", ".", "shuffle", "(", "random_word_list", ")", "\n", "num_replaced", "=", "0", "\n", "for", "random_word", "in", "random_word_list", ":", "\n", "\t\t", "synonyms", "=", "get_synonyms", "(", "random_word", ")", "\n", "if", "len", "(", "synonyms", ")", ">=", "1", ":", "\n", "\t\t\t", "synonym", "=", "random", ".", "choice", "(", "list", "(", "synonyms", ")", ")", "\n", "new_words", "=", "[", "synonym", "if", "word", "==", "random_word", "else", "word", "for", "word", "in", "new_words", "]", "\n", "#print(\"replaced\", random_word, \"with\", synonym)", "\n", "num_replaced", "+=", "1", "\n", "", "if", "num_replaced", ">=", "n", ":", "#only replace up to n words", "\n", "\t\t\t", "break", "\n", "\n", "#this is stupid but we need it, trust me", "\n", "", "", "sentence", "=", "' '", ".", "join", "(", "new_words", ")", "\n", "new_words", "=", "sentence", ".", "split", "(", "' '", ")", "\n", "\n", "return", "new_words", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_synonyms": [[86, 96], ["set", "nltk.corpus.wordnet.synsets", "list", "syn.lemmas", "set.remove", "l.name().replace().replace().lower", "set.add", "l.name().replace().replace", "l.name().replace", "l.name"], "function", ["None"], ["", "def", "get_synonyms", "(", "word", ")", ":", "\n", "\t", "synonyms", "=", "set", "(", ")", "\n", "for", "syn", "in", "wordnet", ".", "synsets", "(", "word", ")", ":", "\n", "\t\t", "for", "l", "in", "syn", ".", "lemmas", "(", ")", ":", "\n", "\t\t\t", "synonym", "=", "l", ".", "name", "(", ")", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", ".", "replace", "(", "\"-\"", ",", "\" \"", ")", ".", "lower", "(", ")", "\n", "synonym", "=", "\"\"", ".", "join", "(", "[", "char", "for", "char", "in", "synonym", "if", "char", "in", "' qwertyuiopasdfghjklzxcvbnm'", "]", ")", "\n", "synonyms", ".", "add", "(", "synonym", ")", "\n", "", "", "if", "word", "in", "synonyms", ":", "\n", "\t\t", "synonyms", ".", "remove", "(", "word", ")", "\n", "", "return", "list", "(", "synonyms", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.random_deletion": [[102, 121], ["len", "random.uniform", "len", "random.randint", "new_words.append", "len"], "function", ["None"], ["", "def", "random_deletion", "(", "words", ",", "p", ")", ":", "\n", "\n", "#obviously, if there's only one word, don't delete it", "\n", "\t", "if", "len", "(", "words", ")", "==", "1", ":", "\n", "\t\t", "return", "words", "\n", "\n", "#randomly delete words with probability p", "\n", "", "new_words", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "\t\t", "r", "=", "random", ".", "uniform", "(", "0", ",", "1", ")", "\n", "if", "r", ">", "p", ":", "\n", "\t\t\t", "new_words", ".", "append", "(", "word", ")", "\n", "\n", "#if you end up deleting all words, just return a random word", "\n", "", "", "if", "len", "(", "new_words", ")", "==", "0", ":", "\n", "\t\t", "rand_int", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "words", ")", "-", "1", ")", "\n", "return", "[", "words", "[", "rand_int", "]", "]", "\n", "\n", "", "return", "new_words", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.random_swap": [[127, 132], ["words.copy", "range", "eda.swap_word"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.swap_word"], ["", "def", "random_swap", "(", "words", ",", "n", ")", ":", "\n", "\t", "new_words", "=", "words", ".", "copy", "(", ")", "\n", "for", "_", "in", "range", "(", "n", ")", ":", "\n", "\t\t", "new_words", "=", "swap_word", "(", "new_words", ")", "\n", "", "return", "new_words", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.swap_word": [[133, 144], ["random.randint", "random.randint", "len", "len"], "function", ["None"], ["", "def", "swap_word", "(", "new_words", ")", ":", "\n", "\t", "random_idx_1", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "new_words", ")", "-", "1", ")", "\n", "random_idx_2", "=", "random_idx_1", "\n", "counter", "=", "0", "\n", "while", "random_idx_2", "==", "random_idx_1", ":", "\n", "\t\t", "random_idx_2", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "new_words", ")", "-", "1", ")", "\n", "counter", "+=", "1", "\n", "if", "counter", ">", "3", ":", "\n", "\t\t\t", "return", "new_words", "\n", "", "", "new_words", "[", "random_idx_1", "]", ",", "new_words", "[", "random_idx_2", "]", "=", "new_words", "[", "random_idx_2", "]", ",", "new_words", "[", "random_idx_1", "]", "\n", "return", "new_words", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.random_insertion": [[150, 155], ["words.copy", "range", "eda.add_word"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.add_word"], ["", "def", "random_insertion", "(", "words", ",", "n", ")", ":", "\n", "\t", "new_words", "=", "words", ".", "copy", "(", ")", "\n", "for", "_", "in", "range", "(", "n", ")", ":", "\n", "\t\t", "add_word", "(", "new_words", ")", "\n", "", "return", "new_words", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.add_word": [[156, 168], ["random.randint", "new_words.insert", "len", "eda.get_synonyms", "len", "random.randint", "len"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_synonyms"], ["", "def", "add_word", "(", "new_words", ")", ":", "\n", "\t", "synonyms", "=", "[", "]", "\n", "counter", "=", "0", "\n", "while", "len", "(", "synonyms", ")", "<", "1", ":", "\n", "\t\t", "random_word", "=", "new_words", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "new_words", ")", "-", "1", ")", "]", "\n", "synonyms", "=", "get_synonyms", "(", "random_word", ")", "\n", "counter", "+=", "1", "\n", "if", "counter", ">=", "10", ":", "\n", "\t\t\t", "return", "\n", "", "", "random_synonym", "=", "synonyms", "[", "0", "]", "\n", "random_idx", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "new_words", ")", "-", "1", ")", "\n", "new_words", ".", "insert", "(", "random_idx", ",", "random_synonym", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.eda": [[173, 224], ["eda.get_only_chars", "get_only_chars.split", "len", "random.shuffle", "augmented_sentences.append", "int", "max", "range", "max", "range", "max", "range", "range", "eda.get_only_chars", "int", "eda.synonym_replacement", "augmented_sentences.append", "int", "eda.random_insertion", "augmented_sentences.append", "int", "eda.random_swap", "augmented_sentences.append", "eda.random_deletion", "augmented_sentences.append", "len", "random.uniform"], "function", ["home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.get_only_chars", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.synonym_replacement", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.random_insertion", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.random_swap", "home.repos.pwc.inspect_result.jasonwei20_eda_nlp.code.eda.random_deletion"], ["", "def", "eda", "(", "sentence", ",", "alpha_sr", "=", "0.1", ",", "alpha_ri", "=", "0.1", ",", "alpha_rs", "=", "0.1", ",", "p_rd", "=", "0.1", ",", "num_aug", "=", "9", ")", ":", "\n", "\n", "\t", "sentence", "=", "get_only_chars", "(", "sentence", ")", "\n", "words", "=", "sentence", ".", "split", "(", "' '", ")", "\n", "words", "=", "[", "word", "for", "word", "in", "words", "if", "word", "is", "not", "''", "]", "\n", "num_words", "=", "len", "(", "words", ")", "\n", "\n", "augmented_sentences", "=", "[", "]", "\n", "num_new_per_technique", "=", "int", "(", "num_aug", "/", "4", ")", "+", "1", "\n", "\n", "#sr", "\n", "if", "(", "alpha_sr", ">", "0", ")", ":", "\n", "\t\t", "n_sr", "=", "max", "(", "1", ",", "int", "(", "alpha_sr", "*", "num_words", ")", ")", "\n", "for", "_", "in", "range", "(", "num_new_per_technique", ")", ":", "\n", "\t\t\t", "a_words", "=", "synonym_replacement", "(", "words", ",", "n_sr", ")", "\n", "augmented_sentences", ".", "append", "(", "' '", ".", "join", "(", "a_words", ")", ")", "\n", "\n", "#ri", "\n", "", "", "if", "(", "alpha_ri", ">", "0", ")", ":", "\n", "\t\t", "n_ri", "=", "max", "(", "1", ",", "int", "(", "alpha_ri", "*", "num_words", ")", ")", "\n", "for", "_", "in", "range", "(", "num_new_per_technique", ")", ":", "\n", "\t\t\t", "a_words", "=", "random_insertion", "(", "words", ",", "n_ri", ")", "\n", "augmented_sentences", ".", "append", "(", "' '", ".", "join", "(", "a_words", ")", ")", "\n", "\n", "#rs", "\n", "", "", "if", "(", "alpha_rs", ">", "0", ")", ":", "\n", "\t\t", "n_rs", "=", "max", "(", "1", ",", "int", "(", "alpha_rs", "*", "num_words", ")", ")", "\n", "for", "_", "in", "range", "(", "num_new_per_technique", ")", ":", "\n", "\t\t\t", "a_words", "=", "random_swap", "(", "words", ",", "n_rs", ")", "\n", "augmented_sentences", ".", "append", "(", "' '", ".", "join", "(", "a_words", ")", ")", "\n", "\n", "#rd", "\n", "", "", "if", "(", "p_rd", ">", "0", ")", ":", "\n", "\t\t", "for", "_", "in", "range", "(", "num_new_per_technique", ")", ":", "\n", "\t\t\t", "a_words", "=", "random_deletion", "(", "words", ",", "p_rd", ")", "\n", "augmented_sentences", ".", "append", "(", "' '", ".", "join", "(", "a_words", ")", ")", "\n", "\n", "", "", "augmented_sentences", "=", "[", "get_only_chars", "(", "sentence", ")", "for", "sentence", "in", "augmented_sentences", "]", "\n", "shuffle", "(", "augmented_sentences", ")", "\n", "\n", "#trim so that we have the desired number of augmented sentences", "\n", "if", "num_aug", ">=", "1", ":", "\n", "\t\t", "augmented_sentences", "=", "augmented_sentences", "[", ":", "num_aug", "]", "\n", "", "else", ":", "\n", "\t\t", "keep_prob", "=", "num_aug", "/", "len", "(", "augmented_sentences", ")", "\n", "augmented_sentences", "=", "[", "s", "for", "s", "in", "augmented_sentences", "if", "random", ".", "uniform", "(", "0", ",", "1", ")", "<", "keep_prob", "]", "\n", "\n", "#append the original sentence", "\n", "", "augmented_sentences", ".", "append", "(", "sentence", ")", "\n", "\n", "return", "augmented_sentences", "", "", ""]]}