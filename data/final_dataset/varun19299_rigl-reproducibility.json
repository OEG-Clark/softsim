{"home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.main.train": [[31, 126], ["model.train", "sparselearning.utils.smoothen_value.SmoothenValue", "tqdm.tqdm", "loss.LabelSmoothingCrossEntropy", "enumerate", "logging.info", "optimizer.zero_grad", "model", "loss.LabelSmoothingCrossEntropy.", "smooth_CE.backward", "sparselearning.utils.smoothen_value.SmoothenValue.add_value", "lr_scheduler.step", "tqdm.tqdm.update", "len", "data.to", "target.to", "smooth_CE.item", "mask.update_connections", "stepper.step", "tqdm.tqdm.set_description", "wandb.log", "wandb.log", "log_dict.items", "sparselearning.utils.layer_wise_density.wandb_bar", "lr_scheduler.get_lr"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.main.train", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.smoothen_value.AverageValue.add_value", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.step", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.update_connections", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.step", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density.wandb_bar", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.warmup_scheduler.WarmUpLR.get_lr"], ["", "def", "train", "(", "\n", "model", ":", "\"nn.Module\"", ",", "\n", "mask", ":", "\"Masking\"", ",", "\n", "train_loader", ":", "\"DataLoader\"", ",", "\n", "optimizer", ":", "\"optim\"", ",", "\n", "lr_scheduler", ":", "\"lr_scheduler\"", ",", "\n", "global_step", ":", "int", ",", "\n", "epoch", ":", "int", ",", "\n", "device", ":", "torch", ".", "device", ",", "\n", "label_smoothing", ":", "float", "=", "0.0", ",", "\n", "log_interval", ":", "int", "=", "100", ",", "\n", "use_wandb", ":", "bool", "=", "False", ",", "\n", "masking_apply_when", ":", "str", "=", "\"epoch_end\"", ",", "\n", "masking_interval", ":", "int", "=", "1", ",", "\n", "masking_end_when", ":", "int", "=", "-", "1", ",", "\n", "masking_print_FLOPs", ":", "bool", "=", "False", ",", "\n", ")", "->", "\"Union[float,int]\"", ":", "\n", "    ", "assert", "masking_apply_when", "in", "[", "\"step_end\"", ",", "\"epoch_end\"", "]", "\n", "model", ".", "train", "(", ")", "\n", "_mask_update_counter", "=", "0", "\n", "_loss_collector", "=", "SmoothenValue", "(", ")", "\n", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "train_loader", ")", ",", "dynamic_ncols", "=", "True", ")", "\n", "smooth_CE", "=", "LabelSmoothingCrossEntropy", "(", "label_smoothing", ")", "\n", "\n", "for", "batch_idx", ",", "(", "data", ",", "target", ")", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "        ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "output", "=", "model", "(", "data", ")", "\n", "loss", "=", "smooth_CE", "(", "output", ",", "target", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "# L2 Regularization", "\n", "\n", "# Exp avg collection", "\n", "_loss_collector", ".", "add_value", "(", "loss", ".", "item", "(", ")", ")", "\n", "\n", "# Mask the gradient step", "\n", "stepper", "=", "mask", "if", "mask", "else", "optimizer", "\n", "if", "(", "\n", "mask", "\n", "and", "masking_apply_when", "==", "\"step_end\"", "\n", "and", "global_step", "<", "masking_end_when", "\n", "and", "(", "(", "global_step", "+", "1", ")", "%", "masking_interval", ")", "==", "0", "\n", ")", ":", "\n", "            ", "mask", ".", "update_connections", "(", ")", "\n", "_mask_update_counter", "+=", "1", "\n", "", "else", ":", "\n", "            ", "stepper", ".", "step", "(", ")", "\n", "\n", "# Lr scheduler", "\n", "", "lr_scheduler", ".", "step", "(", ")", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "batch_idx", "%", "log_interval", "==", "0", ":", "\n", "            ", "msg", "=", "f\"Train Epoch {epoch} Iters {global_step} Mask Updates {_mask_update_counter} Train loss {_loss_collector.smooth:.6f}\"", "\n", "pbar", ".", "set_description", "(", "msg", ")", "\n", "\n", "if", "use_wandb", ":", "\n", "                ", "log_dict", "=", "{", "\"train_loss\"", ":", "loss", ",", "\"lr\"", ":", "lr_scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "}", "\n", "if", "mask", ":", "\n", "                    ", "density", "=", "mask", ".", "stats", ".", "total_density", "\n", "log_dict", "=", "{", "\n", "**", "log_dict", ",", "\n", "\"prune_rate\"", ":", "mask", ".", "prune_rate", ",", "\n", "\"density\"", ":", "density", ",", "\n", "}", "\n", "", "wandb", ".", "log", "(", "\n", "log_dict", ",", "\n", "step", "=", "global_step", ",", "\n", ")", "\n", "\n", "", "", "", "density", "=", "mask", ".", "stats", ".", "total_density", "if", "mask", "else", "1.0", "\n", "msg", "=", "f\"Train Epoch {epoch} Iters {global_step} Mask Updates {_mask_update_counter} Train loss {_loss_collector.smooth:.6f} Prune Rate {mask.prune_rate if mask else 0:.5f} Density {density:.5f}\"", "\n", "\n", "if", "masking_print_FLOPs", ":", "\n", "        ", "log_dict", "=", "{", "\n", "\"Inference FLOPs\"", ":", "mask", ".", "inference_FLOPs", "/", "mask", ".", "dense_FLOPs", ",", "\n", "\"Avg Inference FLOPs\"", ":", "mask", ".", "avg_inference_FLOPs", "/", "mask", ".", "dense_FLOPs", ",", "\n", "}", "\n", "\n", "log_dict_str", "=", "\" \"", ".", "join", "(", "[", "f\"{k}: {v:.4f}\"", "for", "(", "k", ",", "v", ")", "in", "log_dict", ".", "items", "(", ")", "]", ")", "\n", "msg", "=", "f\"{msg} {log_dict_str}\"", "\n", "if", "use_wandb", ":", "\n", "            ", "wandb", ".", "log", "(", "\n", "{", "\n", "**", "log_dict", ",", "\n", "\"layer-wise-density\"", ":", "layer_wise_density", ".", "wandb_bar", "(", "mask", ")", ",", "\n", "}", ",", "\n", "step", "=", "global_step", ",", "\n", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "msg", ")", "\n", "\n", "return", "_loss_collector", ".", "smooth", ",", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.main.evaluate": [[128, 179], ["model.eval", "tqdm.tqdm", "loss.LabelSmoothingCrossEntropy", "tqdm.tqdm.set_description", "logging.info", "torch.no_grad", "len", "torch.tensor().mean", "torch.tensor().mean", "wandb.log", "wandb.log", "wandb.log", "len", "model", "loss.LabelSmoothingCrossEntropy.item", "sparselearning.utils.accuracy_helper.get_topk_accuracy", "top_1_accuracy_ll.append", "top_5_accuracy_ll.append", "tqdm.tqdm.update", "val_or_test.capitalize", "data.to", "target.to", "torch.tensor", "torch.tensor", "loss.LabelSmoothingCrossEntropy."], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.accuracy_helper.get_topk_accuracy"], ["", "def", "evaluate", "(", "\n", "model", ":", "\"nn.Module\"", ",", "\n", "loader", ":", "\"DataLoader\"", ",", "\n", "global_step", ":", "int", ",", "\n", "epoch", ":", "int", ",", "\n", "device", ":", "torch", ".", "device", ",", "\n", "is_test_set", ":", "bool", "=", "False", ",", "\n", "use_wandb", ":", "bool", "=", "False", ",", "\n", ")", "->", "\"Union[float, float]\"", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "\n", "loss", "=", "0", "\n", "correct", "=", "0", "\n", "n", "=", "0", "\n", "pbar", "=", "tqdm", "(", "total", "=", "len", "(", "loader", ")", ",", "dynamic_ncols", "=", "True", ")", "\n", "smooth_CE", "=", "LabelSmoothingCrossEntropy", "(", "0.0", ")", "# No smoothing for val", "\n", "\n", "top_1_accuracy_ll", "=", "[", "]", "\n", "top_5_accuracy_ll", "=", "[", "]", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "data", ",", "target", "in", "loader", ":", "\n", "            ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "\n", "output", "=", "model", "(", "data", ")", "\n", "loss", "+=", "smooth_CE", "(", "output", ",", "target", ")", ".", "item", "(", ")", "# sum up batch loss", "\n", "\n", "top_1_accuracy", ",", "top_5_accuracy", "=", "get_topk_accuracy", "(", "\n", "output", ",", "target", ",", "topk", "=", "(", "1", ",", "5", ")", "\n", ")", "\n", "top_1_accuracy_ll", ".", "append", "(", "top_1_accuracy", ")", "\n", "top_5_accuracy_ll", ".", "append", "(", "top_5_accuracy", ")", "\n", "\n", "pbar", ".", "update", "(", "1", ")", "\n", "\n", "", "loss", "/=", "len", "(", "loader", ")", "\n", "top_1_accuracy", "=", "torch", ".", "tensor", "(", "top_1_accuracy_ll", ")", ".", "mean", "(", ")", "\n", "top_5_accuracy", "=", "torch", ".", "tensor", "(", "top_5_accuracy_ll", ")", ".", "mean", "(", ")", "\n", "\n", "", "val_or_test", "=", "\"val\"", "if", "not", "is_test_set", "else", "\"test\"", "\n", "msg", "=", "f\"{val_or_test.capitalize()} Epoch {epoch} Iters {global_step} {val_or_test} loss {loss:.6f} top-1 accuracy {top_1_accuracy:.4f} top-5 accuracy {top_5_accuracy:.4f}\"", "\n", "pbar", ".", "set_description", "(", "msg", ")", "\n", "logging", ".", "info", "(", "msg", ")", "\n", "\n", "# Log loss, accuracy", "\n", "if", "use_wandb", ":", "\n", "        ", "wandb", ".", "log", "(", "{", "f\"{val_or_test}_loss\"", ":", "loss", "}", ",", "step", "=", "global_step", ")", "\n", "wandb", ".", "log", "(", "{", "f\"{val_or_test}_accuracy\"", ":", "top_1_accuracy", "}", ",", "step", "=", "global_step", ")", "\n", "wandb", ".", "log", "(", "{", "f\"{val_or_test}_top_5_accuracy\"", ":", "top_5_accuracy", "}", ",", "step", "=", "global_step", ")", "\n", "\n", "", "return", "loss", ",", "top_1_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.main.single_seed_run": [[181, 384], ["print", "torch.manual_seed", "data.get_dataloaders", "model_class().to", "int", "int", "cfg.masking.get", "sparselearning.utils.train_helper.get_optimizer", "sparselearning.utils.train_helper.load_weights", "cfg.optimizer.get", "range", "main.evaluate", "omegaconf.OmegaConf.to_yaml", "torch.cuda.is_available", "torch.device", "torch.device", "models.registry.keys", "wandb.init", "wandb.watch", "int", "sparselearning.core.Masking", "pathlib.Path", "sparselearning.core.Masking.add_module", "len", "main.train", "main.evaluate", "wandb.join", "model_class", "open", "f.read().strip", "cfg.masking.get", "wandb.log", "main.evaluate", "models.registry.keys", "omegaconf.OmegaConf.to_container", "len", "sparselearning.utils.layer_wise_density.wandb_bar", "cfg.masking.get", "sparselearning.utils.train_helper.save_weights", "sparselearning.core.Masking.update_connections", "f.read"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.data.get_dataloaders", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.train_helper.get_optimizer", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.train_helper.load_weights", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.main.evaluate", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.init", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.add_module", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.main.train", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.main.evaluate", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.main.evaluate", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density.wandb_bar", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.train_helper.save_weights", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.update_connections"], ["", "def", "single_seed_run", "(", "cfg", ":", "DictConfig", ")", "->", "float", ":", "\n", "    ", "print", "(", "OmegaConf", ".", "to_yaml", "(", "cfg", ")", ")", "\n", "\n", "# Manual seeds", "\n", "torch", ".", "manual_seed", "(", "cfg", ".", "seed", ")", "\n", "\n", "# Set device", "\n", "if", "cfg", ".", "device", "==", "\"cuda\"", "and", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "cfg", ".", "device", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "# Get data", "\n", "", "train_loader", ",", "val_loader", ",", "test_loader", "=", "get_dataloaders", "(", "**", "cfg", ".", "dataset", ")", "\n", "\n", "# Select model", "\n", "assert", "(", "\n", "cfg", ".", "model", "in", "model_registry", ".", "keys", "(", ")", "\n", ")", ",", "f\"Select from {','.join(model_registry.keys())}\"", "\n", "model_class", ",", "model_args", "=", "model_registry", "[", "cfg", ".", "model", "]", "\n", "_small_density", "=", "cfg", ".", "masking", ".", "density", "if", "cfg", ".", "masking", ".", "name", "==", "\"Small_Dense\"", "else", "1.0", "\n", "model", "=", "model_class", "(", "*", "model_args", ",", "_small_density", ")", ".", "to", "(", "device", ")", "\n", "\n", "# wandb", "\n", "if", "cfg", ".", "wandb", ".", "use", ":", "\n", "        ", "with", "open", "(", "cfg", ".", "wandb", ".", "api_key", ")", "as", "f", ":", "\n", "            ", "os", ".", "environ", "[", "\"WANDB_API_KEY\"", "]", "=", "f", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "os", ".", "environ", "[", "\"WANDB_START_METHOD\"", "]", "=", "\"thread\"", "\n", "\n", "", "wandb", ".", "init", "(", "\n", "entity", "=", "cfg", ".", "wandb", ".", "entity", ",", "\n", "config", "=", "OmegaConf", ".", "to_container", "(", "cfg", ",", "resolve", "=", "True", ")", ",", "\n", "project", "=", "cfg", ".", "wandb", ".", "project", ",", "\n", "name", "=", "cfg", ".", "wandb", ".", "name", ",", "\n", "reinit", "=", "True", ",", "\n", "save_code", "=", "True", ",", "\n", ")", "\n", "wandb", ".", "watch", "(", "model", ")", "\n", "\n", "# Training multiplier", "\n", "", "cfg", ".", "optimizer", ".", "decay_frequency", "*=", "cfg", ".", "optimizer", ".", "training_multiplier", "\n", "cfg", ".", "optimizer", ".", "decay_frequency", "=", "int", "(", "cfg", ".", "optimizer", ".", "decay_frequency", ")", "\n", "\n", "cfg", ".", "optimizer", ".", "epochs", "*=", "cfg", ".", "optimizer", ".", "training_multiplier", "\n", "cfg", ".", "optimizer", ".", "epochs", "=", "int", "(", "cfg", ".", "optimizer", ".", "epochs", ")", "\n", "\n", "if", "cfg", ".", "masking", ".", "get", "(", "\"end_when\"", ",", "None", ")", ":", "\n", "        ", "cfg", ".", "masking", ".", "end_when", "*=", "cfg", ".", "optimizer", ".", "training_multiplier", "\n", "cfg", ".", "masking", ".", "end_when", "=", "int", "(", "cfg", ".", "masking", ".", "end_when", ")", "\n", "\n", "# Setup optimizers, lr schedulers", "\n", "", "optimizer", ",", "(", "lr_scheduler", ",", "warmup_scheduler", ")", "=", "get_optimizer", "(", "model", ",", "**", "cfg", ".", "optimizer", ")", "\n", "\n", "# Setup mask", "\n", "mask", "=", "None", "\n", "if", "not", "cfg", ".", "masking", ".", "dense", ":", "\n", "        ", "max_iter", "=", "(", "\n", "cfg", ".", "masking", ".", "end_when", "\n", "if", "cfg", ".", "masking", ".", "apply_when", "==", "\"step_end\"", "\n", "else", "cfg", ".", "masking", ".", "end_when", "*", "len", "(", "train_loader", ")", "\n", ")", "\n", "\n", "kwargs", "=", "{", "\"prune_rate\"", ":", "cfg", ".", "masking", ".", "prune_rate", ",", "\"T_max\"", ":", "max_iter", "}", "\n", "\n", "if", "cfg", ".", "masking", ".", "decay_schedule", "==", "\"magnitude-prune\"", ":", "\n", "            ", "kwargs", "=", "{", "\n", "\"final_sparsity\"", ":", "1", "-", "cfg", ".", "masking", ".", "final_density", ",", "\n", "\"T_max\"", ":", "max_iter", ",", "\n", "\"T_start\"", ":", "cfg", ".", "masking", ".", "start_when", ",", "\n", "\"interval\"", ":", "cfg", ".", "masking", ".", "interval", ",", "\n", "}", "\n", "\n", "", "decay", "=", "decay_registry", "[", "cfg", ".", "masking", ".", "decay_schedule", "]", "(", "**", "kwargs", ")", "\n", "\n", "mask", "=", "Masking", "(", "\n", "optimizer", ",", "\n", "decay", ",", "\n", "density", "=", "cfg", ".", "masking", ".", "density", ",", "\n", "dense_gradients", "=", "cfg", ".", "masking", ".", "dense_gradients", ",", "\n", "sparse_init", "=", "cfg", ".", "masking", ".", "sparse_init", ",", "\n", "prune_mode", "=", "cfg", ".", "masking", ".", "prune_mode", ",", "\n", "growth_mode", "=", "cfg", ".", "masking", ".", "growth_mode", ",", "\n", "redistribution_mode", "=", "cfg", ".", "masking", ".", "redistribution_mode", ",", "\n", ")", "\n", "# Support for lottery mask", "\n", "lottery_mask_path", "=", "Path", "(", "cfg", ".", "masking", ".", "get", "(", "\"lottery_mask_path\"", ",", "\"\"", ")", ")", "\n", "mask", ".", "add_module", "(", "model", ",", "lottery_mask_path", ")", "\n", "\n", "# Load from checkpoint", "\n", "", "model", ",", "optimizer", ",", "mask", ",", "step", ",", "start_epoch", ",", "best_val_loss", "=", "load_weights", "(", "\n", "model", ",", "optimizer", ",", "mask", ",", "ckpt_dir", "=", "cfg", ".", "ckpt_dir", ",", "resume", "=", "cfg", ".", "resume", "\n", ")", "\n", "\n", "# Train model", "\n", "epoch", "=", "0", "\n", "warmup_steps", "=", "cfg", ".", "optimizer", ".", "get", "(", "\"warmup_steps\"", ",", "0", ")", "\n", "warmup_epochs", "=", "warmup_steps", "/", "len", "(", "train_loader", ")", "\n", "\n", "if", "(", "cfg", ".", "masking", ".", "print_FLOPs", "and", "cfg", ".", "wandb", ".", "use", ")", "and", "(", "start_epoch", ",", "step", "==", "(", "0", ",", "0", ")", ")", ":", "\n", "        ", "if", "mask", ":", "\n", "# Log initial inference flops etc", "\n", "            ", "log_dict", "=", "{", "\n", "\"Inference FLOPs\"", ":", "mask", ".", "inference_FLOPs", "/", "mask", ".", "dense_FLOPs", ",", "\n", "\"Avg Inference FLOPs\"", ":", "mask", ".", "avg_inference_FLOPs", "/", "mask", ".", "dense_FLOPs", ",", "\n", "\"layer-wise-density\"", ":", "layer_wise_density", ".", "wandb_bar", "(", "mask", ")", ",", "\n", "}", "\n", "wandb", ".", "log", "(", "log_dict", ",", "step", "=", "0", ")", "\n", "\n", "", "", "for", "epoch", "in", "range", "(", "start_epoch", ",", "cfg", ".", "optimizer", ".", "epochs", ")", ":", "\n", "# step here is training iters not global steps", "\n", "        ", "_masking_args", "=", "{", "}", "\n", "if", "mask", ":", "\n", "            ", "_masking_args", "=", "{", "\n", "\"masking_apply_when\"", ":", "cfg", ".", "masking", ".", "apply_when", ",", "\n", "\"masking_interval\"", ":", "cfg", ".", "masking", ".", "interval", ",", "\n", "\"masking_end_when\"", ":", "cfg", ".", "masking", ".", "end_when", ",", "\n", "\"masking_print_FLOPs\"", ":", "cfg", ".", "masking", ".", "get", "(", "\"print_FLOPs\"", ",", "False", ")", ",", "\n", "}", "\n", "\n", "", "scheduler", "=", "lr_scheduler", "if", "(", "epoch", ">=", "warmup_epochs", ")", "else", "warmup_scheduler", "\n", "_", ",", "step", "=", "train", "(", "\n", "model", ",", "\n", "mask", ",", "\n", "train_loader", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "step", ",", "\n", "epoch", "+", "1", ",", "\n", "device", ",", "\n", "label_smoothing", "=", "cfg", ".", "optimizer", ".", "label_smoothing", ",", "\n", "log_interval", "=", "cfg", ".", "log_interval", ",", "\n", "use_wandb", "=", "cfg", ".", "wandb", ".", "use", ",", "\n", "**", "_masking_args", ",", "\n", ")", "\n", "\n", "# Run validation", "\n", "if", "epoch", "%", "cfg", ".", "val_interval", "==", "0", ":", "\n", "            ", "val_loss", ",", "val_accuracy", "=", "evaluate", "(", "\n", "model", ",", "\n", "val_loader", ",", "\n", "step", ",", "\n", "epoch", "+", "1", ",", "\n", "device", ",", "\n", "use_wandb", "=", "cfg", ".", "wandb", ".", "use", ",", "\n", ")", "\n", "\n", "# Save weights", "\n", "if", "(", "epoch", "+", "1", "==", "cfg", ".", "optimizer", ".", "epochs", ")", "or", "(", "\n", "(", "epoch", "+", "1", ")", "%", "cfg", ".", "ckpt_interval", "==", "0", "\n", ")", ":", "\n", "                ", "if", "val_loss", "<", "best_val_loss", ":", "\n", "                    ", "is_min", "=", "True", "\n", "best_val_loss", "=", "val_loss", "\n", "", "else", ":", "\n", "                    ", "is_min", "=", "False", "\n", "\n", "", "save_weights", "(", "\n", "model", ",", "\n", "optimizer", ",", "\n", "mask", ",", "\n", "val_loss", ",", "\n", "step", ",", "\n", "epoch", "+", "1", ",", "\n", "ckpt_dir", "=", "cfg", ".", "ckpt_dir", ",", "\n", "is_min", "=", "is_min", ",", "\n", ")", "\n", "\n", "# Apply mask", "\n", "", "", "if", "(", "\n", "mask", "\n", "and", "cfg", ".", "masking", ".", "apply_when", "==", "\"epoch_end\"", "\n", "and", "epoch", "<", "cfg", ".", "masking", ".", "end_when", "\n", ")", ":", "\n", "            ", "if", "epoch", "%", "cfg", ".", "masking", ".", "interval", "==", "0", ":", "\n", "                ", "mask", ".", "update_connections", "(", ")", "\n", "\n", "", "", "", "if", "not", "epoch", ":", "\n", "# Run val anyway", "\n", "        ", "epoch", "=", "cfg", ".", "optimizer", ".", "epochs", "-", "1", "\n", "val_loss", ",", "val_accuracy", "=", "evaluate", "(", "\n", "model", ",", "\n", "val_loader", ",", "\n", "step", ",", "\n", "epoch", "+", "1", ",", "\n", "device", ",", "\n", "use_wandb", "=", "cfg", ".", "wandb", ".", "use", ",", "\n", ")", "\n", "\n", "", "evaluate", "(", "\n", "model", ",", "\n", "test_loader", ",", "\n", "step", ",", "\n", "epoch", "+", "1", ",", "\n", "device", ",", "\n", "is_test_set", "=", "True", ",", "\n", "use_wandb", "=", "cfg", ".", "wandb", ".", "use", ",", "\n", ")", "\n", "\n", "if", "cfg", ".", "wandb", ".", "use", ":", "\n", "# Close wandb context", "\n", "        ", "wandb", ".", "join", "(", ")", "\n", "\n", "", "return", "val_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.main.main": [[386, 401], ["hydra.main", "main.single_seed_run", "copy.deepcopy", "main.single_seed_run", "val_accuracy_ll.append", "sum", "len"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.redist_inference_plot.main", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.main.single_seed_run", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.main.single_seed_run"], ["", "@", "hydra", ".", "main", "(", "config_name", "=", "\"config\"", ",", "config_path", "=", "\"conf\"", ")", "\n", "def", "main", "(", "cfg", ":", "DictConfig", ")", "->", "float", ":", "\n", "    ", "if", "cfg", ".", "multi_seed", ":", "\n", "        ", "val_accuracy_ll", "=", "[", "]", "\n", "for", "seed", "in", "cfg", ".", "multi_seed", ":", "\n", "            ", "run_cfg", "=", "deepcopy", "(", "cfg", ")", "\n", "run_cfg", ".", "seed", "=", "seed", "\n", "run_cfg", ".", "ckpt_dir", "=", "f\"{cfg.ckpt_dir}_seed={seed}\"", "\n", "val_accuracy", "=", "single_seed_run", "(", "run_cfg", ")", "\n", "val_accuracy_ll", ".", "append", "(", "val_accuracy", ")", "\n", "\n", "", "return", "sum", "(", "val_accuracy_ll", ")", "/", "len", "(", "val_accuracy_ll", ")", "\n", "", "else", ":", "\n", "        ", "val_accuracy", "=", "single_seed_run", "(", "cfg", ")", "\n", "return", "val_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.data.DatasetSplitter.__post_init__": [[29, 34], ["len", "ValueError", "data.DatasetSplitter.index_map.any", "numpy.array", "range", "len"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ")", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Dataset split {self.split} is not positive\"", ")", "\n", "", "if", "not", "self", ".", "index_map", ".", "any", "(", ")", ":", "\n", "            ", "self", ".", "index_map", "=", "np", ".", "array", "(", "range", "(", "len", "(", "self", ".", "parent_dataset", ")", ")", ",", "dtype", "=", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.data.DatasetSplitter.__len__": [[35, 40], ["data.DatasetSplitter.split.indices", "len", "len", "range"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "# absolute indices", "\n", "        ", "_indices", "=", "self", ".", "split", ".", "indices", "(", "len", "(", "(", "self", ".", "parent_dataset", ")", ")", ")", "\n", "# compute length", "\n", "return", "len", "(", "range", "(", "*", "_indices", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.data.DatasetSplitter.__getitem__": [[41, 45], ["len", "int"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "assert", "index", "<", "len", "(", "self", ")", ",", "\"index out of bounds in split_datset\"", "\n", "index", "=", "self", ".", "index_map", "[", "index", "+", "int", "(", "self", ".", "split", ".", "start", "or", "0", ")", "]", "\n", "return", "self", ".", "parent_dataset", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.data._get_CIFAR10_dataset": [[47, 78], ["torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torchvision.transforms.Pad", "torchvision.transforms.RandomCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "", "def", "_get_CIFAR10_dataset", "(", "root", ":", "\"Path\"", ")", "->", "\"Tuple[Dataset,Dataset]\"", ":", "\n", "    ", "\"\"\"\n    Returns CIFAR10 Dataset\n\n    :param root: path to download to / load from\n    :type root: Path\n    :return: train+val, test dataset\n    :rtype: Tuple[Dataset,Dataset]\n    \"\"\"", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.2023", ",", "0.1994", ",", "0.2010", ")", ")", "\n", "\n", "train_transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "Pad", "(", "4", ",", "padding_mode", "=", "\"reflect\"", ")", ",", "\n", "transforms", ".", "RandomCrop", "(", "32", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", "\n", ")", "\n", "\n", "test_transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", ")", "\n", "\n", "full_dataset", "=", "datasets", ".", "CIFAR10", "(", "\n", "root", ",", "train", "=", "True", ",", "transform", "=", "train_transform", ",", "download", "=", "True", "\n", ")", "\n", "test_dataset", "=", "datasets", ".", "CIFAR10", "(", "\n", "root", ",", "train", "=", "False", ",", "transform", "=", "test_transform", ",", "download", "=", "False", "\n", ")", "\n", "\n", "return", "full_dataset", ",", "test_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.data._get_CIFAR100_dataset": [[80, 110], ["torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "_get_CIFAR100_dataset", "(", "root", ":", "\"Path\"", ")", "->", "\"Tuple[Dataset,Dataset]\"", ":", "\n", "    ", "\"\"\"\n    Returns CIFAR100 Dataset\n\n    :param root: path to download to / load from\n    :type root: Path\n    :return: train+val, test dataset\n    :rtype: Tuple[Dataset,Dataset]\n    \"\"\"", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "(", "0.5071", ",", "0.4865", ",", "0.4409", ")", ",", "(", "0.2673", ",", "0.2564", ",", "0.2762", ")", ")", "\n", "\n", "train_transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "32", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", "\n", ")", "\n", "\n", "test_transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", ")", "\n", "\n", "full_dataset", "=", "datasets", ".", "CIFAR100", "(", "\n", "root", ",", "train", "=", "True", ",", "transform", "=", "train_transform", ",", "download", "=", "True", "\n", ")", "\n", "test_dataset", "=", "datasets", ".", "CIFAR100", "(", "\n", "root", ",", "train", "=", "False", ",", "transform", "=", "test_transform", ",", "download", "=", "False", "\n", ")", "\n", "\n", "return", "full_dataset", ",", "test_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.data._get_Mini_Imagenet_dataset": [[112, 144], ["torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "_get_Mini_Imagenet_dataset", "(", "root", ":", "\"Path\"", ")", "->", "\"Tuple[Dataset,Dataset]\"", ":", "\n", "    ", "\"\"\"\n    Returns Mini-Imagenet Dataset\n    (https://github.com/yaoyao-liu/mini-imagenet-tools)\n\n    :param root: path to download to / load from\n    :type root: Path\n    :return: train+val, test dataset\n    :rtype: Tuple[Dataset,Dataset]\n    \"\"\"", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "\n", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", "\n", ")", "\n", "\n", "# Original Inception paper reported good performance", "\n", "# with dramatic scales from 0.08 to 1.0 for cropping", "\n", "# https://discuss.pytorch.org/t/is-transforms-randomresizedcrop-used-for-data-augmentation/16716", "\n", "train_transform", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "84", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "normalize", ",", "\n", "]", "\n", ")", "\n", "\n", "test_transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", ")", "\n", "\n", "full_dataset", "=", "datasets", ".", "ImageFolder", "(", "root", "/", "\"train_val\"", ",", "transform", "=", "train_transform", ",", ")", "\n", "test_dataset", "=", "datasets", ".", "ImageFolder", "(", "root", "/", "\"test\"", ",", "transform", "=", "test_transform", ",", ")", "\n", "\n", "return", "full_dataset", ",", "test_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.data._get_MNIST_dataset": [[146, 162], ["torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.transforms.ToTensor"], "function", ["None"], ["", "def", "_get_MNIST_dataset", "(", "root", ":", "\"Path\"", ")", "->", "\"Tuple[Dataset,Dataset]\"", ":", "\n", "    ", "\"\"\"\n    Returns MNIST Dataset\n\n    :param root: path to download to / load from\n    :type root: Path\n    :return: train+val, test dataset\n    :rtype: Tuple[Dataset,Dataset]\n    \"\"\"", "\n", "normalize", "=", "transforms", ".", "Normalize", "(", "(", "0.1307", ",", ")", ",", "(", "0.3081", ",", ")", ")", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalize", "]", ")", "\n", "\n", "full_dataset", "=", "datasets", ".", "MNIST", "(", "root", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "datasets", ".", "MNIST", "(", "root", ",", "train", "=", "False", ",", "transform", "=", "transform", ")", "\n", "\n", "return", "full_dataset", ",", "test_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.data.get_dataloaders": [[164, 258], ["max", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "logging.info", "logging.info", "logging.info", "registry.keys", "pathlib.Path", "numpy.array", "int", "data.DatasetSplitter", "data.DatasetSplitter", "torch.utils.data.DataLoader", "logging.info", "list", "index_map_path.exists", "math.floor", "slice", "slice", "range", "pathlib.Path", "logging.info", "numpy.load", "numpy.random.shuffle", "logging.info", "numpy.save", "len", "len", "len", "len", "len"], "function", ["None"], ["", "def", "get_dataloaders", "(", "\n", "name", ":", "str", ",", "\n", "root", ":", "\"Path\"", ",", "\n", "batch_size", ":", "int", "=", "1", ",", "\n", "test_batch_size", ":", "int", "=", "1", ",", "\n", "validation_split", ":", "float", "=", "0.0", ",", "\n", "max_threads", ":", "int", "=", "3", ",", "\n", "fixed_shuffle", ":", "bool", "=", "False", ",", "\n", ")", "->", "\"Tuple[DataLoader, DataLoader, DataLoader]\"", ":", "\n", "    ", "\"\"\"\n    Creates augmented train, validation, and test data loaders.\n\n    :param name: dataset name\n    :type name: str\n    :param root: Path to download to / load from\n    :type root: Path\n    :param batch_size: mini batch for train/val split\n    :type batch_size: int\n    :param test_batch_size: mini batch for test split\n    :type test_batch_size: int\n    :param validation_split: 0-> no val\n    :type validation_split: float\n    :param max_threads: Max threads to use for dataloaders\n    :type max_threads: int\n    :param fixed_shuffle: whether to shuffle once and save shuffled indices.\n    Useful when using ImageFolderDataset and want reproducible shuffling\n    :type fixed_shuffle: bool\n    :return: train, val, test loaders\n    :rtype: Tuple[DataLoader, DataLoader, DataLoader]\n    \"\"\"", "\n", "\n", "assert", "name", "in", "registry", ".", "keys", "(", ")", "\n", "full_dataset", ",", "test_dataset", "=", "registry", "[", "name", "]", "(", "Path", "(", "root", ")", ")", "\n", "\n", "# we need at least two threads in total", "\n", "max_threads", "=", "max", "(", "2", ",", "max_threads", ")", "\n", "val_threads", "=", "2", "if", "max_threads", ">=", "6", "else", "1", "\n", "train_threads", "=", "max_threads", "-", "val_threads", "\n", "\n", "# Split into train and val", "\n", "train_dataset", "=", "full_dataset", "\n", "if", "validation_split", ":", "\n", "        ", "index_map", "=", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_dataset", ")", ")", ")", ",", "dtype", "=", "int", ")", "\n", "\n", "if", "fixed_shuffle", ":", "\n", "            ", "index_map_path", "=", "Path", "(", "root", ")", "/", "\"index_map.npy\"", "\n", "if", "index_map_path", ".", "exists", "(", ")", ":", "\n", "                ", "logging", ".", "info", "(", "f\"Loading index map from {index_map_path}\"", ")", "\n", "index_map", "=", "np", ".", "load", "(", "index_map_path", ",", "allow_pickle", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "index_map", ")", "\n", "logging", ".", "info", "(", "f\"Saving index map to {index_map_path}\"", ")", "\n", "np", ".", "save", "(", "index_map_path", ",", "index_map", ")", "\n", "\n", "", "", "split", "=", "int", "(", "floor", "(", "(", "1.0", "-", "validation_split", ")", "*", "len", "(", "full_dataset", ")", ")", ")", "\n", "train_dataset", "=", "DatasetSplitter", "(", "full_dataset", ",", "slice", "(", "None", ",", "split", ")", ",", "index_map", ")", "\n", "val_dataset", "=", "DatasetSplitter", "(", "full_dataset", ",", "slice", "(", "split", ",", "None", ")", ",", "index_map", ")", "\n", "\n", "", "train_loader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "\n", "batch_size", ",", "\n", "num_workers", "=", "train_threads", ",", "\n", "pin_memory", "=", "False", ",", "\n", "shuffle", "=", "True", ",", "\n", "multiprocessing_context", "=", "\"fork\"", ",", "\n", ")", "\n", "\n", "if", "validation_split", ":", "\n", "        ", "valid_loader", "=", "DataLoader", "(", "\n", "val_dataset", ",", "\n", "test_batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "val_threads", ",", "\n", "pin_memory", "=", "False", ",", "\n", "multiprocessing_context", "=", "\"fork\"", ",", "\n", ")", "\n", "\n", "", "test_loader", "=", "DataLoader", "(", "\n", "test_dataset", ",", "\n", "test_batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "1", ",", "\n", "pin_memory", "=", "False", ",", "\n", "multiprocessing_context", "=", "\"fork\"", ",", "\n", ")", "\n", "logging", ".", "info", "(", "f\"Train dataset length {len(train_dataset)}\"", ")", "\n", "logging", ".", "info", "(", "f\"Val dataset length {len(val_dataset) if validation_split else 0}\"", ")", "\n", "logging", ".", "info", "(", "f\"Test dataset length {len(test_dataset)}\"", ")", "\n", "\n", "if", "not", "validation_split", ":", "\n", "        ", "logging", ".", "info", "(", "\"Running periodic eval on test data.\"", ")", "\n", "valid_loader", "=", "test_loader", "\n", "\n", "", "return", "train_loader", ",", "valid_loader", ",", "test_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.loss.LabelSmoothingCrossEntropy.__init__": [[39, 43], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.LinearDecay.__init__"], ["def", "__init__", "(", "self", ",", "epsilon", ":", "float", "=", "0.1", ",", "reduction", ":", "str", "=", "\"mean\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "reduction", "=", "reduction", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.loss.LabelSmoothingCrossEntropy.forward": [[44, 49], ["loss._reduce_loss", "torch.nll_loss", "loss._linear_combination", "log_preds.size", "log_preds.sum"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.loss._reduce_loss", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.loss._linear_combination"], ["", "def", "forward", "(", "self", ",", "log_preds", ":", "\"Tensor\"", ",", "target", ":", "\"Tensor\"", ")", "->", "\"Tensor\"", ":", "\n", "        ", "num_classes", "=", "log_preds", ".", "size", "(", ")", "[", "-", "1", "]", "\n", "loss", "=", "_reduce_loss", "(", "-", "log_preds", ".", "sum", "(", "dim", "=", "-", "1", ")", ",", "self", ".", "reduction", ")", "\n", "nll", "=", "F", ".", "nll_loss", "(", "log_preds", ",", "target", ",", "reduction", "=", "self", ".", "reduction", ")", "\n", "return", "_linear_combination", "(", "loss", "/", "num_classes", ",", "nll", ",", "self", ".", "epsilon", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.loss._linear_combination": [[13, 20], ["None"], "function", ["None"], ["", "def", "_linear_combination", "(", "\n", "x", ":", "\"Union[float, Tensor]\"", ",", "y", ":", "\"Union[float, Tensor]\"", ",", "epsilon", "\n", ")", "->", "\"Union[float, Tensor]\"", ":", "\n", "    ", "\"\"\"\n    Affine combination of x, y\n    \"\"\"", "\n", "return", "epsilon", "*", "x", "+", "(", "1", "-", "epsilon", ")", "*", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.loss._reduce_loss": [[22, 29], ["loss.mean", "loss.sum"], "function", ["None"], ["", "def", "_reduce_loss", "(", "loss", ",", "reduction", "=", "\"mean\"", ")", ":", "\n", "    ", "return", "(", "\n", "loss", ".", "mean", "(", ")", "\n", "if", "reduction", "==", "\"mean\"", "\n", "else", "loss", ".", "sum", "(", ")", "\n", "if", "reduction", "==", "\"sum\"", "\n", "else", "loss", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.alpha_deltaT.get_stats": [[37, 111], ["pandas.DataFrame", "logging.info", "enumerate", "df.reset_index.sort_values", "df.reset_index.dropna", "runs_dict.keys", "[].mean().astype", "[].mean().astype", "df.reset_index.reset_index", "runs_dict[].append", "[].mean", "[].mean", "range", "range"], "function", ["None"], ["def", "get_stats", "(", "runs", ",", "reorder", ":", "bool", "=", "True", ",", ")", "->", "pd", ".", "DataFrame", ":", "\n", "    ", "\"\"\"\n    Get stats saved on W&B.\n\n    List all possible choices for (masking, init, density, dataset).\n    We'll try matching the exhaustive caretesian product.\n\n    :param runs: Experiment run\n    :type runs: wandb.api.runs\n    :param reorder: sort methods alphabetically\n    :type reorder: bool\n    :return: Dataframe containing test accuracies of methods\n    :rtype: pd.DataFrame\n    \"\"\"", "\n", "columns", "=", "[", "\n", "\"Method\"", ",", "\n", "\"Init\"", ",", "\n", "\"Density\"", ",", "\n", "\"alpha\"", ",", "\n", "\"Delta T\"", ",", "\n", "\"Val Acc (seed 0)\"", ",", "\n", "\"Val Acc (seed 1)\"", ",", "\n", "\"Val Acc (seed 2)\"", ",", "\n", "\"Test Acc (seed 0)\"", ",", "\n", "\"Test Acc (seed 1)\"", ",", "\n", "\"Test Acc (seed 2)\"", ",", "\n", "\"Val Acc\"", ",", "\n", "\"Test Acc\"", ",", "\n", "]", "\n", "df", "=", "pd", ".", "DataFrame", "(", "columns", "=", "columns", ")", "\n", "\n", "# Pre-process", "\n", "logging", ".", "info", "(", "\"Grouping runs by name\"", ")", "\n", "runs_dict", "=", "{", "}", "\n", "for", "run", "in", "runs", ":", "\n", "        ", "if", "run", ".", "name", "not", "in", "runs_dict", ":", "\n", "            ", "runs_dict", "[", "run", ".", "name", "]", "=", "[", "run", "]", "\n", "", "else", ":", "\n", "            ", "runs_dict", "[", "run", ".", "name", "]", ".", "append", "(", "run", ")", "\n", "\n", "", "", "for", "e", ",", "run_name", "in", "enumerate", "(", "runs_dict", ".", "keys", "(", ")", ")", ":", "\n", "        ", "run_ll", "=", "runs_dict", "[", "run_name", "]", "\n", "masking", "=", "run_ll", "[", "0", "]", ".", "config", "[", "\"masking\"", "]", "[", "\"name\"", "]", "\n", "init", "=", "(", "\n", "\"ERK\"", "\n", "if", "run_ll", "[", "0", "]", ".", "config", "[", "\"masking\"", "]", "[", "\"sparse_init\"", "]", "==", "\"erdos-renyi-kernel\"", "\n", "else", "\"Random\"", "\n", ")", "\n", "density", "=", "run_ll", "[", "0", "]", ".", "config", "[", "\"masking\"", "]", "[", "\"density\"", "]", "\n", "alpha", "=", "run_ll", "[", "0", "]", ".", "config", "[", "\"masking\"", "]", "[", "\"prune_rate\"", "]", "\n", "deltaT", "=", "run_ll", "[", "0", "]", ".", "config", "[", "\"masking\"", "]", "[", "\"interval\"", "]", "\n", "\n", "df", ".", "loc", "[", "e", "]", "=", "[", "masking", ",", "init", ",", "density", ",", "alpha", ",", "deltaT", ",", "*", "(", "[", "None", ",", "None", "]", "*", "4", ")", "]", "\n", "\n", "for", "run", "in", "run_ll", ":", "\n", "            ", "val_accuracy", "=", "run", ".", "summary", ".", "val_accuracy", "*", "100", "\n", "test_accuracy", "=", "run", ".", "summary", ".", "test_accuracy", "*", "100", "\n", "seed", "=", "run", ".", "config", "[", "\"seed\"", "]", "\n", "df", ".", "loc", "[", "e", ",", "f\"Val Acc (seed {seed})\"", "]", "=", "val_accuracy", "\n", "df", ".", "loc", "[", "e", ",", "f\"Test Acc (seed {seed})\"", "]", "=", "test_accuracy", "\n", "\n", "", "df", ".", "loc", "[", "e", ",", "\"Val Acc\"", "]", "=", "(", "\n", "df", ".", "loc", "[", "e", "]", "[", "[", "f\"Val Acc (seed {i})\"", "for", "i", "in", "range", "(", "3", ")", "]", "]", ".", "mean", "(", ")", ".", "astype", "(", "float", ")", "\n", ")", "\n", "df", ".", "loc", "[", "e", ",", "\"Test Acc\"", "]", "=", "(", "\n", "df", ".", "loc", "[", "e", "]", "[", "[", "f\"Test Acc (seed {i})\"", "for", "i", "in", "range", "(", "3", ")", "]", "]", ".", "mean", "(", ")", ".", "astype", "(", "float", ")", "\n", ")", "\n", "\n", "", "df", "=", "df", ".", "sort_values", "(", "by", "=", "[", "\"Method\"", ",", "\"Init\"", ",", "\"Density\"", ",", "\"alpha\"", ",", "\"Delta T\"", "]", ")", "\n", "df", "=", "df", ".", "dropna", "(", ")", "\n", "\n", "if", "reorder", ":", "\n", "        ", "df", "=", "df", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.alpha_deltaT.alpha_deltaT_plot": [[113, 157], ["enumerate", "itertools.product", "sub_df[].astype", "sub_df[].astype", "sub_df[].astype().to_numpy", "matplotlib.pyplot.tricontourf", "matplotlib.pyplot.plot", "matplotlib.pyplot.plot", "matplotlib.pyplot.colorbar", "plt.colorbar.set_label", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.ylim", "matplotlib.pyplot.savefig", "matplotlib.pyplot.show", "sub_df[].astype().idxmax", "sub_df[].astype", "hydra.utils.get_original_cwd", "dataset.lower", "sub_df[].astype"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density.plot", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density.plot"], ["", "def", "alpha_deltaT_plot", "(", "\n", "df", ":", "pd", ".", "DataFrame", ",", "\n", "dataset", ":", "str", "=", "\"CIFAR10\"", ",", "\n", "init_ll", ":", "\"List[str]\"", "=", "[", "\"ERK\"", ",", "\"Random\"", "]", ",", "\n", "density_ll", ":", "\"List[float]\"", "=", "[", "0.1", ",", "0.2", ",", "0.5", "]", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Plot contour plot depicting alpha-deltaT trial space\n\n    :param df: Dataframe containing main results\n    :type df: pd.DataFrame\n    :param dataset: dataset to plot\n    :type dataset: str\n    :param init_ll: List of initialization schemes to plot\n    :type init_ll: List[str]\n    :param density_ll: List of densities to plot\n    :type density_ll: List[float]\n    \"\"\"", "\n", "for", "e", ",", "(", "init", ",", "density", ")", "in", "enumerate", "(", "itertools", ".", "product", "(", "init_ll", ",", "density_ll", ")", ")", ":", "\n", "        ", "sub_df", "=", "df", ".", "loc", "[", "(", "df", "[", "\"Init\"", "]", "==", "init", ")", "&", "(", "df", "[", "\"Density\"", "]", "==", "density", ")", "]", "\n", "row", "=", "sub_df", ".", "loc", "[", "sub_df", "[", "\"Test Acc\"", "]", ".", "astype", "(", "float", ")", ".", "idxmax", "(", ")", "]", "\n", "\n", "alpha_ll", "=", "sub_df", "[", "\"alpha\"", "]", ".", "astype", "(", "float", ")", "\n", "deltaT_ll", "=", "sub_df", "[", "\"Delta T\"", "]", ".", "astype", "(", "float", ")", "\n", "test_accuracy_ll", "=", "sub_df", "[", "\"Test Acc\"", "]", ".", "astype", "(", "float", ")", ".", "to_numpy", "(", ")", "\n", "\n", "plt", ".", "tricontourf", "(", "alpha_ll", ",", "deltaT_ll", ",", "test_accuracy_ll", ",", "levels", "=", "10", ",", "cmap", "=", "\"plasma\"", ")", "\n", "plt", ".", "plot", "(", "0.3", ",", "100", ",", "\"ko\"", ",", "markersize", "=", "10", ")", "\n", "plt", ".", "plot", "(", "row", "[", "\"alpha\"", "]", ",", "row", "[", "\"Delta T\"", "]", ",", "\"^\"", ",", "color", "=", "\"black\"", ",", "markersize", "=", "10", ")", "\n", "\n", "cbar", "=", "plt", ".", "colorbar", "(", ")", "\n", "cbar", ".", "set_label", "(", "\"Accuracy (Test)\"", ")", "\n", "\n", "plt", ".", "xlabel", "(", "r\"$\\alpha$\"", ")", "\n", "plt", ".", "ylabel", "(", "r\"$\\Delta T$\"", ")", "\n", "\n", "plt", ".", "ylim", "(", "50", ",", "1000", ")", "\n", "\n", "plt", ".", "savefig", "(", "\n", "f\"{hydra.utils.get_original_cwd()}/outputs/plots/{dataset.lower()}_alpha_deltaT_{init}_density_{density}.pdf\"", ",", "\n", "dpi", "=", "150", ",", "\n", ")", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.alpha_deltaT.main": [[159, 185], ["hydra.main", "wandb.Api", "wandb.Api.runs", "alpha_deltaT.get_stats", "get_stats.to_csv", "alpha_deltaT.alpha_deltaT_plot", "open", "f.read", "pandas.option_context", "print", "hydra.utils.get_original_cwd", "cfg.dataset.name.lower"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.redist_inference_plot.main", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.lr_tuning.get_stats", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.alpha_deltaT.alpha_deltaT_plot"], ["", "", "@", "hydra", ".", "main", "(", "config_name", "=", "\"config\"", ",", "config_path", "=", "\"../conf\"", ")", "\n", "def", "main", "(", "cfg", ":", "DictConfig", ")", ":", "\n", "# Authenticate API", "\n", "    ", "with", "open", "(", "cfg", ".", "wandb", ".", "api_key", ")", "as", "f", ":", "\n", "        ", "os", ".", "environ", "[", "\"WANDB_API_KEY\"", "]", "=", "f", ".", "read", "(", ")", "\n", "\n", "# Get runs", "\n", "", "api", "=", "wandb", ".", "Api", "(", ")", "\n", "runs", "=", "api", ".", "runs", "(", "\n", "f\"{cfg.wandb.entity}/{cfg.wandb.project}\"", ",", "filters", "=", "{", "\"state\"", ":", "\"finished\"", "}", "\n", ")", "\n", "\n", "df", "=", "get_stats", "(", "runs", ")", "\n", "\n", "# Set longer length", "\n", "pd", ".", "options", ".", "display", ".", "max_rows", "=", "150", "\n", "with", "pd", ".", "option_context", "(", "\"display.float_format\"", ",", "\"{:.3f}\"", ".", "format", ")", ":", "\n", "        ", "print", "(", "df", ")", "\n", "\n", "", "df", ".", "to_csv", "(", "\n", "f\"{hydra.utils.get_original_cwd()}/outputs/csv/{cfg.dataset.name.lower()}_alpha_deltaT.csv\"", "\n", ")", "\n", "\n", "# Plot it", "\n", "alpha_deltaT_plot", "(", "\n", "df", ",", "init_ll", "=", "[", "\"ERK\"", ",", "\"Random\"", "]", ",", "density_ll", "=", "[", "0.1", ",", "0.2", ",", "0.5", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.erk_vs_random_FLOPs.FLOPs_vs_sparsity": [[34, 103], ["print", "numpy.linspace", "matplotlib.pyplot.figure", "matplotlib.pyplot.plot", "matplotlib.pyplot.plot", "matplotlib.pyplot.legend", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.subplots_adjust", "matplotlib.pyplot.grid", "matplotlib.pyplot.savefig", "matplotlib.pyplot.show", "print", "print", "train_FLOPs_dict[].append", "zip", "print", "sparselearning.counting.inference_train_FLOPs.RigL_train_FLOPs", "print", "train_FLOPs_dict[].append", "init_name.capitalize"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density.plot", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density.plot", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.RigL_train_FLOPs"], ["def", "FLOPs_vs_sparsity", "(", "model", ":", "str", "=", "\"wrn-22-2\"", ")", ":", "\n", "    ", "\"\"\"\n    FLOPs vs sparsity for Random, ERK initializations\n    :param model: model name (wrn-22-2, resnet50) to use.\n    :type model: str\n    \"\"\"", "\n", "assert", "model", "in", "[", "\"wrn-22-2\"", ",", "\"resnet50\"", "]", ",", "f\"Model {model} not found\"", "\n", "\n", "dense_FLOPs", "=", "registry", "[", "model", "]", "(", "density", "=", "1.0", ")", "\n", "dense_train_FLOPs", "=", "3", "*", "dense_FLOPs", "# gradient of param and activation", "\n", "print", "(", "f\"WRN-22-2 Dense FLOPS: {dense_FLOPs:,} \\n\"", ")", "\n", "\n", "# Masking", "\n", "interval", "=", "100", "\n", "\n", "train_FLOPs_dict", "=", "{", "\"Random\"", ":", "[", "]", ",", "\"ERK\"", ":", "[", "]", ",", "\"density\"", ":", "[", "]", "}", "\n", "\n", "for", "density", "in", "np", ".", "linspace", "(", "0.01", ",", "0.6", ",", "num", "=", "15", ")", ":", "\n", "        ", "Random_FLOPs", "=", "registry", "[", "model", "]", "(", "\"random\"", ",", "density", ")", "\n", "ERK_FLOPs", "=", "registry", "[", "model", "]", "(", "\"erdos-renyi-kernel\"", ",", "density", ")", "\n", "\n", "print", "(", "\n", "f\"Random Density: {density:.3f} Inference FLOPs:{Random_FLOPs:,} Proportion:{Random_FLOPs / dense_FLOPs:.4f}\"", "\n", ")", "\n", "print", "(", "\n", "f\"ERK Density: {density:.3f} Inference FLOPs:{ERK_FLOPs:,} Proportion:{ERK_FLOPs / dense_FLOPs:.4f}\"", "\n", ")", "\n", "\n", "train_FLOPs_dict", "[", "\"density\"", "]", ".", "append", "(", "density", ")", "\n", "\n", "for", "sparse_FLOPs", ",", "init_name", "in", "zip", "(", "\n", "[", "Random_FLOPs", ",", "ERK_FLOPs", "]", ",", "[", "\"Random\"", ",", "\"ERK\"", "]", "\n", ")", ":", "\n", "            ", "rigl_train_FLOPs", "=", "RigL_train_FLOPs", "(", "sparse_FLOPs", ",", "dense_FLOPs", ",", "interval", ")", "\n", "\n", "print", "(", "\n", "f\"RigL {init_name.capitalize()} Density: {density:.3f} Train FLOPs:{rigl_train_FLOPs:,} Proportion:{rigl_train_FLOPs / dense_train_FLOPs:.4f}\"", "\n", ")", "\n", "train_FLOPs_dict", "[", "init_name", "]", ".", "append", "(", "rigl_train_FLOPs", ")", "\n", "\n", "", "print", "(", "\"-----------\\n\"", ")", "\n", "\n", "", "plt", ".", "figure", "(", "figsize", "=", "(", "4", ",", "6", ")", ")", "\n", "plt", ".", "plot", "(", "\n", "train_FLOPs_dict", "[", "\"density\"", "]", ",", "\n", "train_FLOPs_dict", "[", "\"ERK\"", "]", ",", "\n", "linewidth", "=", "LINE_WIDTH", ",", "\n", "alpha", "=", "ALPHA", ",", "\n", ")", "\n", "plt", ".", "plot", "(", "\n", "train_FLOPs_dict", "[", "\"density\"", "]", ",", "\n", "train_FLOPs_dict", "[", "\"Random\"", "]", ",", "\n", "linewidth", "=", "LINE_WIDTH", ",", "\n", "alpha", "=", "ALPHA", ",", "\n", ")", "\n", "\n", "plt", ".", "legend", "(", "[", "\"ERK\"", ",", "\"Random\"", "]", ")", "\n", "\n", "plt", ".", "xlabel", "(", "\"Density (1-sparsity)\"", ")", "\n", "plt", ".", "ylabel", "(", "\"Train FLOPs\"", ")", "\n", "\n", "plt", ".", "subplots_adjust", "(", "left", "=", "0.15", ",", "bottom", "=", "0.125", ")", "\n", "plt", ".", "grid", "(", ")", "\n", "\n", "plt", ".", "savefig", "(", "\n", "f\"outputs/plots/{model}_ERK_vs_Random_train_FLOPs.pdf\"", ",", "dpi", "=", "150", ",", "\n", ")", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.erk_vs_random_FLOPs.accuracy_vs_FLOPs": [[105, 272], ["sparselearning.counting.inference_train_FLOPs.wrn_22_2_FLOPs", "sparselearning.counting.inference_train_FLOPs.resnet50_FLOPs", "pandas.DataFrame", "matplotlib.pyplot.figure", "matplotlib.pyplot.bar", "matplotlib.pyplot.bar", "matplotlib.pyplot.xticks", "matplotlib.pyplot.ylim", "matplotlib.pyplot.legend", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.savefig", "matplotlib.pyplot.show", "matplotlib.pyplot.figure", "matplotlib.pyplot.bar", "matplotlib.pyplot.bar", "matplotlib.pyplot.xticks", "matplotlib.pyplot.ylim", "matplotlib.pyplot.legend", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.savefig", "matplotlib.pyplot.show", "sparselearning.counting.inference_train_FLOPs.RigL_train_FLOPs", "sparselearning.counting.inference_train_FLOPs.RigL_train_FLOPs", "sparselearning.counting.inference_train_FLOPs.RigL_train_FLOPs", "sparselearning.counting.inference_train_FLOPs.RigL_train_FLOPs", "sparselearning.counting.inference_train_FLOPs.RigL_train_FLOPs", "sparselearning.counting.inference_train_FLOPs.RigL_train_FLOPs", "numpy.arange", "numpy.arange", "sparselearning.counting.inference_train_FLOPs.wrn_22_2_FLOPs", "sparselearning.counting.inference_train_FLOPs.wrn_22_2_FLOPs", "sparselearning.counting.inference_train_FLOPs.wrn_22_2_FLOPs", "sparselearning.counting.inference_train_FLOPs.resnet50_FLOPs", "sparselearning.counting.inference_train_FLOPs.resnet50_FLOPs", "sparselearning.counting.inference_train_FLOPs.resnet50_FLOPs", "numpy.arange", "numpy.arange", "numpy.arange", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.RigL_train_FLOPs", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.RigL_train_FLOPs", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.RigL_train_FLOPs", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.RigL_train_FLOPs", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.RigL_train_FLOPs", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.RigL_train_FLOPs"], ["", "def", "accuracy_vs_FLOPs", "(", ")", ":", "\n", "    ", "\"\"\"\n    Plot test accuracy vs FLOPs for ERK, Random init\n    \"\"\"", "\n", "wrn_22_2_dense_FLOPs", "=", "wrn_22_2_FLOPs", "(", "density", "=", "1.0", ")", "\n", "wrn_22_2_dense_train_FLOPs", "=", "(", "\n", "3", "*", "wrn_22_2_dense_FLOPs", "\n", ")", "# gradient of param and activation", "\n", "\n", "resnet50_dense_FLOPs", "=", "resnet50_FLOPs", "(", "density", "=", "1.0", ")", "\n", "resnet50_dense_train_FLOPs", "=", "(", "\n", "3", "*", "resnet50_dense_FLOPs", "\n", ")", "# gradient of param and activation", "\n", "\n", "columns", "=", "[", "\"Model\"", ",", "\"Init\"", ",", "\"FLOPs\"", ",", "\"Test Acc Mean\"", ",", "\"Test Acc Std\"", "]", "\n", "df", "=", "pd", ".", "DataFrame", "(", "columns", "=", "columns", ")", "\n", "\n", "# TODO: can we fetch this directly from W&B?", "\n", "df", ".", "loc", "[", "0", "]", "=", "[", "\n", "\"wrn-22-2\"", ",", "\n", "\"Random\"", ",", "\n", "RigL_train_FLOPs", "(", "wrn_22_2_FLOPs", "(", "\"random\"", ",", "0.1", ")", ",", "wrn_22_2_dense_train_FLOPs", ")", ",", "\n", "91.71666666666665", ",", "\n", "0.18009256878986557", ",", "\n", "]", "\n", "df", ".", "loc", "[", "1", "]", "=", "[", "\n", "\"wrn-22-2\"", ",", "\n", "\"Random\"", ",", "\n", "RigL_train_FLOPs", "(", "wrn_22_2_FLOPs", "(", "\"random\"", ",", "0.2", ")", ",", "wrn_22_2_dense_train_FLOPs", ")", ",", "\n", "92.60666666666667", ",", "\n", "0.3100537587795598", ",", "\n", "]", "\n", "df", ".", "loc", "[", "2", "]", "=", "[", "\n", "\"wrn-22-2\"", ",", "\n", "\"Random\"", ",", "\n", "RigL_train_FLOPs", "(", "wrn_22_2_FLOPs", "(", "\"random\"", ",", "0.5", ")", ",", "wrn_22_2_dense_train_FLOPs", ")", ",", "\n", "93.26666666666667", ",", "\n", "0.07234178138069844", ",", "\n", "]", "\n", "\n", "df", ".", "loc", "[", "3", "]", "=", "[", "\n", "\"wrn-22-2\"", ",", "\n", "\"ERK\"", ",", "\n", "df", ".", "loc", "[", "0", "]", "[", "\"FLOPs\"", "]", ",", "\n", "91.43", ",", "\n", "0.015", ",", "\n", "]", "\n", "df", ".", "loc", "[", "4", "]", "=", "[", "\n", "\"wrn-22-2\"", ",", "\n", "\"ERK\"", ",", "\n", "df", ".", "loc", "[", "1", "]", "[", "\"FLOPs\"", "]", ",", "\n", "92.22", ",", "\n", "0.1189", ",", "\n", "]", "\n", "df", ".", "loc", "[", "5", "]", "=", "[", "\"wrn-22-2\"", ",", "\"ERK\"", ",", "df", ".", "loc", "[", "2", "]", "[", "\"FLOPs\"", "]", ",", "93.28", ",", "0.1545", "]", "\n", "\n", "df", ".", "loc", "[", "6", "]", "=", "[", "\n", "\"resnet50\"", ",", "\n", "\"Random\"", ",", "\n", "RigL_train_FLOPs", "(", "resnet50_FLOPs", "(", "\"random\"", ",", "0.1", ")", ",", "resnet50_dense_train_FLOPs", ")", ",", "\n", "71.769513686498", ",", "\n", "0.3318907357554385", ",", "\n", "]", "\n", "df", ".", "loc", "[", "7", "]", "=", "[", "\n", "\"resnet50\"", ",", "\n", "\"Random\"", ",", "\n", "RigL_train_FLOPs", "(", "resnet50_FLOPs", "(", "\"random\"", ",", "0.2", ")", ",", "resnet50_dense_train_FLOPs", ")", ",", "\n", "73.53639205296834", ",", "\n", "0.04310600094182424", ",", "\n", "]", "\n", "df", ".", "loc", "[", "8", "]", "=", "[", "\n", "\"resnet50\"", ",", "\n", "\"Random\"", ",", "\n", "RigL_train_FLOPs", "(", "resnet50_FLOPs", "(", "\"random\"", ",", "0.5", ")", ",", "resnet50_dense_train_FLOPs", ")", ",", "\n", "74.27149415016174", ",", "\n", "0.3129347072329389", ",", "\n", "]", "\n", "\n", "df", ".", "loc", "[", "9", "]", "=", "[", "\n", "\"resnet50\"", ",", "\n", "\"ERK\"", ",", "\n", "df", ".", "loc", "[", "6", "]", "[", "\"FLOPs\"", "]", ",", "\n", "71.07", ",", "\n", "0.3936", ",", "\n", "]", "\n", "df", ".", "loc", "[", "10", "]", "=", "[", "\n", "\"resnet50\"", ",", "\n", "\"ERK\"", ",", "\n", "df", ".", "loc", "[", "7", "]", "[", "\"FLOPs\"", "]", ",", "\n", "71.98", ",", "\n", "0.3021", ",", "\n", "]", "\n", "df", ".", "loc", "[", "11", "]", "=", "[", "\n", "\"resnet50\"", ",", "\n", "\"ERK\"", ",", "\n", "df", ".", "loc", "[", "8", "]", "[", "\"FLOPs\"", "]", ",", "\n", "74.18", ",", "\n", "0.4284", ",", "\n", "]", "\n", "\n", "WIDTH", "=", "0.3", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "6", ")", ")", "\n", "\n", "sub_df", "=", "df", ".", "loc", "[", "df", "[", "\"Model\"", "]", "==", "\"wrn-22-2\"", "]", "\n", "\n", "erk_sub_df", "=", "sub_df", ".", "loc", "[", "sub_df", "[", "\"Init\"", "]", "==", "\"ERK\"", "]", "\n", "plt", ".", "bar", "(", "\n", "np", ".", "arange", "(", "1", ",", "4", ")", "-", "WIDTH", "/", "2", ",", "\n", "erk_sub_df", "[", "\"Test Acc Mean\"", "]", ",", "\n", "width", "=", "WIDTH", ",", "\n", "yerr", "=", "erk_sub_df", "[", "\"Test Acc Std\"", "]", ",", "\n", ")", "\n", "\n", "random_sub_df", "=", "sub_df", ".", "loc", "[", "sub_df", "[", "\"Init\"", "]", "==", "\"Random\"", "]", "\n", "plt", ".", "bar", "(", "\n", "np", ".", "arange", "(", "1", ",", "4", ")", "+", "WIDTH", "/", "2", ",", "\n", "random_sub_df", "[", "\"Test Acc Mean\"", "]", ",", "\n", "width", "=", "WIDTH", ",", "\n", "yerr", "=", "random_sub_df", "[", "\"Test Acc Std\"", "]", ",", "\n", ")", "\n", "\n", "plt", ".", "xticks", "(", "np", ".", "arange", "(", "1", ",", "4", ")", ",", "[", "f\"{x:.2e}\"", "for", "x", "in", "erk_sub_df", "[", "\"FLOPs\"", "]", "]", ")", "\n", "plt", ".", "ylim", "(", "88", ",", "94", ")", "\n", "\n", "plt", ".", "legend", "(", "[", "\"ERK\"", ",", "\"Random\"", "]", ")", "\n", "plt", ".", "xlabel", "(", "\"Train FLOPs\"", ")", "\n", "plt", ".", "ylabel", "(", "\"Accuracy (Test)\"", ")", "\n", "\n", "plt", ".", "savefig", "(", "\n", "\"outputs/plots/wrn-22-2_ERK_vs_Random_acc_vs_train_FLOPs.pdf\"", ",", "dpi", "=", "150", ",", "\n", ")", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "6", ")", ")", "\n", "\n", "sub_df", "=", "df", ".", "loc", "[", "df", "[", "\"Model\"", "]", "==", "\"resnet50\"", "]", "\n", "\n", "erk_sub_df", "=", "sub_df", ".", "loc", "[", "sub_df", "[", "\"Init\"", "]", "==", "\"ERK\"", "]", "\n", "plt", ".", "bar", "(", "\n", "np", ".", "arange", "(", "1", ",", "4", ")", "-", "WIDTH", "/", "2", ",", "\n", "erk_sub_df", "[", "\"Test Acc Mean\"", "]", ",", "\n", "width", "=", "WIDTH", ",", "\n", "yerr", "=", "erk_sub_df", "[", "\"Test Acc Std\"", "]", ",", "\n", ")", "\n", "\n", "random_sub_df", "=", "sub_df", ".", "loc", "[", "sub_df", "[", "\"Init\"", "]", "==", "\"Random\"", "]", "\n", "plt", ".", "bar", "(", "\n", "np", ".", "arange", "(", "1", ",", "4", ")", "+", "WIDTH", "/", "2", ",", "\n", "random_sub_df", "[", "\"Test Acc Mean\"", "]", ",", "\n", "width", "=", "WIDTH", ",", "\n", "yerr", "=", "random_sub_df", "[", "\"Test Acc Std\"", "]", ",", "\n", ")", "\n", "\n", "plt", ".", "xticks", "(", "np", ".", "arange", "(", "1", ",", "4", ")", ",", "[", "f\"{x:.2e}\"", "for", "x", "in", "erk_sub_df", "[", "\"FLOPs\"", "]", "]", ")", "\n", "plt", ".", "ylim", "(", "67", ",", "75", ")", "\n", "\n", "plt", ".", "legend", "(", "[", "\"ERK\"", ",", "\"Random\"", "]", ")", "\n", "plt", ".", "xlabel", "(", "\"Train FLOPs\"", ")", "\n", "plt", ".", "ylabel", "(", "\"Accuracy (Test)\"", ")", "\n", "\n", "plt", ".", "savefig", "(", "\n", "\"outputs/plots/resnet50_ERK_vs_Random_acc_vs_train_FLOPs.pdf\"", ",", "dpi", "=", "150", ",", "\n", ")", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.lr_tuning.get_stats": [[39, 154], ["pandas.DataFrame", "logging.info", "enumerate", "df.reset_index.sort_values", "itertools.product", "logging.debug", "runs_dict.get", "df.reset_index.reset_index", "runs_dict[].append"], "function", ["None"], ["def", "get_stats", "(", "\n", "runs", ",", "\n", "masking_ll", ":", "\"List[str]\"", "=", "[", "\"RigL\"", "]", ",", "\n", "init_ll", ":", "\"List[str]\"", "=", "[", "\"Random\"", "]", ",", "\n", "suffix_ll", ":", "\"List[str]\"", "=", "[", "\"grid_lr\"", "]", ",", "\n", "density_ll", ":", "\"List[float]\"", "=", "[", "0.1", "]", ",", "\n", "lr_ll", ":", "\"List[float]\"", "=", "[", "0.1", "]", ",", "\n", "alpha_ll", ":", "\"List[float]\"", "=", "[", "0.3", "]", ",", "\n", "deltaT_ll", ":", "\"List[float]\"", "=", "[", "100", "]", ",", "\n", "dataset_ll", ":", "\"List[str]\"", "=", "[", "\"CIFAR10\"", "]", ",", "\n", "reorder", ":", "bool", "=", "True", ",", "\n", ")", "->", "pd", ".", "DataFrame", ":", "\n", "    ", "\"\"\"\n    Get stats saved on W&B.\n\n    List all possible choices for (masking, init, density, dataset).\n\n    We'll try matching the exhaustive caretesian product of\n    (masking_ll x init_ll x suffix_ll x density_ll etc).\n\n    :param runs: Experiment run\n    :type runs: wandb.api.runs\n    :param masking_ll: List of sparse training techniques\n    :type masking_ll: List[str]\n    :param init_ll: List of sparsity initialization schemes\n    :type init_ll: List[str]\n    :param suffix_ll: List of method suffixes.\n    :type suffix_ll: List[str]\n    :param density_ll: List of density values (1 - sparsity)\n    :type density_ll: List[float]\n    :param lr_ll: List of learning rates\n    :type lr_ll: List[float]\n    :param alpha_ll: List of alphas (initial pruning rate)\n    :type alpha_ll: List[float]\n    :param deltaT_ll: List of deltaT's to plot\n    :type deltaT_ll: List[float]\n    :param dataset_ll: List of datasets\n    :type dataset_ll: List[str]\n    :param reorder: sort methods alphabetically\n    :type reorder: bool\n    :return: Dataframe containing test accuracies of methods\n    :rtype: pd.DataFrame\n    \"\"\"", "\n", "columns", "=", "[", "\n", "\"Method\"", ",", "\n", "\"Init\"", ",", "\n", "\"Density\"", ",", "\n", "\"alpha\"", ",", "\n", "\"Delta T\"", ",", "\n", "\"LR\"", ",", "\n", "\"Val Acc\"", ",", "\n", "\"Test Acc\"", ",", "\n", "]", "\n", "df", "=", "pd", ".", "DataFrame", "(", "columns", "=", "columns", ")", "\n", "\n", "# Pre-process", "\n", "logging", ".", "info", "(", "\"Grouping runs by name\"", ")", "\n", "runs_dict", "=", "{", "}", "\n", "for", "run", "in", "runs", ":", "\n", "        ", "if", "run", ".", "name", "not", "in", "runs_dict", ":", "\n", "            ", "runs_dict", "[", "run", ".", "name", "]", "=", "[", "run", "]", "\n", "", "else", ":", "\n", "            ", "runs_dict", "[", "run", ".", "name", "]", ".", "append", "(", "run", ")", "\n", "\n", "", "", "for", "e", ",", "(", "dataset", ",", "masking", ",", "suffix", ",", "init", ",", "density", ",", "alpha", ",", "deltaT", ",", "lr", ")", "in", "enumerate", "(", "\n", "itertools", ".", "product", "(", "\n", "dataset_ll", ",", "\n", "masking_ll", ",", "\n", "suffix_ll", ",", "\n", "init_ll", ",", "\n", "density_ll", ",", "\n", "alpha_ll", ",", "\n", "deltaT_ll", ",", "\n", "lr_ll", ",", "\n", ")", "\n", ")", ":", "\n", "\n", "        ", "tags", "=", "[", "\n", "dataset", ",", "\n", "masking", ",", "\n", "init", ",", "\n", "suffix", ",", "\n", "f\"density_{density}\"", ",", "\n", "f\"alpha_{alpha}\"", ",", "\n", "f\"deltaT_{deltaT}\"", ",", "\n", "f\"lr_{lr}\"", ",", "\n", "]", "\n", "name", "=", "\"_\"", ".", "join", "(", "[", "tag", "for", "tag", "in", "tags", "if", "tag", "]", ")", "\n", "logging", ".", "debug", "(", "name", ")", "\n", "runs", "=", "runs_dict", ".", "get", "(", "name", ",", "None", ")", "\n", "\n", "if", "not", "runs", ":", "\n", "            ", "continue", "\n", "\n", "", "accuracy_ll", "=", "[", "None", ",", "None", "]", "\n", "for", "run", "in", "runs", ":", "\n", "            ", "if", "not", "(", "\"test_accuracy\"", "in", "run", ".", "summary", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "not", "(", "\"val_accuracy\"", "in", "run", ".", "summary", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "accuracy_ll", "[", "0", "]", "=", "run", ".", "summary", ".", "val_accuracy", "*", "100", "\n", "accuracy_ll", "[", "1", "]", "=", "run", ".", "summary", ".", "test_accuracy", "*", "100", "\n", "break", "\n", "\n", "", "if", "suffix", ":", "\n", "            ", "masking", "=", "f\"{masking}_{suffix}\"", "\n", "", "df", ".", "loc", "[", "e", "]", "=", "[", "masking", ",", "init", ",", "density", ",", "alpha", ",", "deltaT", ",", "lr", ",", "*", "accuracy_ll", "]", "\n", "\n", "", "df", "=", "df", ".", "sort_values", "(", "by", "=", "[", "\"Method\"", ",", "\"Init\"", ",", "\"Density\"", ",", "\"alpha\"", ",", "\"Delta T\"", ",", "\"LR\"", "]", ")", "\n", "\n", "if", "reorder", ":", "\n", "        ", "df", "=", "df", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.lr_tuning.lr_tuning_plot": [[156, 223], ["itertools.product", "itertools.product", "matplotlib.pyplot.legend", "matplotlib.pyplot.xticks", "matplotlib.pyplot.gca", "plt.gca.set_xlim", "matplotlib.pyplot.grid", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.subplots_adjust", "matplotlib.pyplot.savefig", "matplotlib.pyplot.show", "matplotlib.pyplot.semilogx", "legend.append", "plt.gca.get_xlim", "hydra.utils.get_original_cwd", "dataset.lower"], "function", ["None"], ["", "def", "lr_tuning_plot", "(", "\n", "df", ":", "pd", ".", "DataFrame", ",", "\n", "dataset", ":", "str", "=", "\"CIFAR10\"", ",", "\n", "init_ll", ":", "\"List[str]\"", "=", "[", "\"ERK\"", ",", "\"Random\"", "]", ",", "\n", "density_ll", "=", "[", "0.1", ",", "0.2", ",", "0.5", "]", ",", "\n", "lr_ll", ":", "\"List[float]\"", "=", "[", "0.1", "]", ",", "\n", "alpha_ll", ":", "\"List[float]\"", "=", "[", "0.3", "]", ",", "\n", "deltaT_ll", ":", "\"List[float]\"", "=", "[", "100", "]", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Plot LR tuning trials\n\n    :param df: Dataframe containing main results\n    :type df: pd.DataFrame\n    :param dataset: dataset to plot\n    :type dataset: str\n    :param init_ll: List of initialization schemes to plot\n    :type init_ll: List[str]\n    :param density_ll: List of densities to plot\n    :type density_ll: List[float]\n    :param lr_ll: List of learning rates\n    :type lr_ll: List[float]\n    :param alpha_ll: List of alphas (initial pruning rate)\n    :type alpha_ll: List[float]\n    :param deltaT_ll: List of deltaT's to plot\n    :type deltaT_ll: List[float]\n    \"\"\"", "\n", "for", "(", "init", ",", "density", ")", "in", "itertools", ".", "product", "(", "init_ll", ",", "density_ll", ")", ":", "\n", "        ", "sub_df", "=", "df", ".", "loc", "[", "(", "df", "[", "\"Init\"", "]", "==", "init", ")", "&", "(", "df", "[", "\"Density\"", "]", "==", "density", ")", "]", "\n", "legend", "=", "[", "]", "\n", "for", "(", "alpha", ",", "deltaT", ")", "in", "itertools", ".", "product", "(", "alpha_ll", ",", "deltaT_ll", ")", ":", "\n", "            ", "rows", "=", "sub_df", ".", "loc", "[", "(", "df", "[", "\"alpha\"", "]", "==", "alpha", ")", "&", "(", "df", "[", "\"Delta T\"", "]", "==", "deltaT", ")", "]", "\n", "if", "rows", ".", "empty", ":", "\n", "                ", "continue", "\n", "\n", "", "test_acc_exists", "=", "{", "\n", "lr", ":", "not", "rows", "[", "rows", "[", "\"LR\"", "]", "==", "lr", "]", "[", "\"Test Acc\"", "]", ".", "empty", "for", "lr", "in", "lr_ll", "\n", "}", "\n", "test_acc_ll", "=", "[", "\n", "rows", "[", "rows", "[", "\"LR\"", "]", "==", "lr", "]", "[", "\"Test Acc\"", "]", ".", "iloc", "[", "0", "]", "\n", "for", "lr", "in", "lr_ll", "\n", "if", "test_acc_exists", "[", "lr", "]", "\n", "]", "\n", "lr_ll", "=", "[", "lr", "for", "lr", "in", "lr_ll", "if", "test_acc_exists", "[", "lr", "]", "]", "\n", "\n", "plt", ".", "semilogx", "(", "lr_ll", ",", "test_acc_ll", ",", "linewidth", "=", "LINE_WIDTH", ",", "alpha", "=", "ALPHA", ")", "\n", "legend", ".", "append", "(", "rf\"$\\alpha=${alpha},$\\Delta T=${deltaT}\"", ")", "\n", "\n", "", "plt", ".", "legend", "(", "legend", ",", "loc", "=", "\"lower left\"", ")", "\n", "plt", ".", "xticks", "(", "lr_ll", ",", "lr_ll", ")", "\n", "\n", "# grab a reference to the current axes", "\n", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "\n", "# set the xlimits to be the reverse of the current xlimits", "\n", "ax", ".", "set_xlim", "(", "ax", ".", "get_xlim", "(", ")", "[", ":", ":", "-", "1", "]", ")", "\n", "\n", "plt", ".", "grid", "(", ")", "\n", "plt", ".", "xlabel", "(", "\"Learning rate\"", ")", "\n", "plt", ".", "ylabel", "(", "\"Accuracy (Test)\"", ")", "\n", "\n", "plt", ".", "subplots_adjust", "(", "bottom", "=", "0.125", ")", "\n", "plt", ".", "savefig", "(", "\n", "f\"{hydra.utils.get_original_cwd()}/outputs/plots/{dataset.lower()}_lr_tuning_{init}_density_{density}.pdf\"", ",", "\n", "dpi", "=", "150", ",", "\n", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.lr_tuning.main": [[225, 265], ["hydra.main", "wandb.Api", "wandb.Api.runs", "lr_tuning.get_stats", "get_stats.to_csv", "lr_tuning.lr_tuning_plot", "open", "f.read", "pandas.option_context", "print", "hydra.utils.get_original_cwd", "cfg.dataset.name.lower"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.redist_inference_plot.main", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.lr_tuning.get_stats", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.lr_tuning.lr_tuning_plot"], ["", "", "@", "hydra", ".", "main", "(", "config_name", "=", "\"config\"", ",", "config_path", "=", "\"../conf\"", ")", "\n", "def", "main", "(", "cfg", ":", "DictConfig", ")", ":", "\n", "# Authenticate API", "\n", "    ", "with", "open", "(", "cfg", ".", "wandb", ".", "api_key", ")", "as", "f", ":", "\n", "        ", "os", ".", "environ", "[", "\"WANDB_API_KEY\"", "]", "=", "f", ".", "read", "(", ")", "\n", "\n", "# Get runs", "\n", "", "api", "=", "wandb", ".", "Api", "(", ")", "\n", "runs", "=", "api", ".", "runs", "(", "f\"{cfg.wandb.entity}/{cfg.wandb.project}\"", ")", "\n", "\n", "df", "=", "get_stats", "(", "\n", "runs", ",", "\n", "masking_ll", "=", "[", "\n", "\"RigL\"", ",", "\n", "]", ",", "\n", "init_ll", "=", "[", "\"Random\"", ",", "\"ERK\"", "]", ",", "\n", "density_ll", "=", "[", "0.1", ",", "0.2", ",", "0.5", "]", ",", "\n", "dataset_ll", "=", "[", "cfg", ".", "dataset", ".", "name", "]", ",", "\n", "lr_ll", "=", "[", "0.005", ",", "0.01", ",", "0.05", ",", "0.1", ",", "0.2", "]", ",", "\n", "alpha_ll", "=", "[", "0.3", ",", "0.4", ",", "0.5", "]", ",", "\n", "deltaT_ll", "=", "[", "100", ",", "200", ",", "500", ",", "750", "]", ",", "\n", ")", "\n", "\n", "# Set longer length", "\n", "pd", ".", "options", ".", "display", ".", "max_rows", "=", "150", "\n", "with", "pd", ".", "option_context", "(", "\"display.float_format\"", ",", "\"{:.3f}\"", ".", "format", ")", ":", "\n", "        ", "print", "(", "df", ")", "\n", "\n", "", "df", ".", "to_csv", "(", "\n", "f\"{hydra.utils.get_original_cwd()}/outputs/csv/{cfg.dataset.name.lower()}_lr_tuning.csv\"", "\n", ")", "\n", "\n", "# Plot it", "\n", "lr_tuning_plot", "(", "\n", "df", ",", "\n", "init_ll", "=", "[", "\"ERK\"", ",", "\"Random\"", "]", ",", "\n", "density_ll", "=", "[", "0.1", ",", "0.2", ",", "0.5", "]", ",", "\n", "lr_ll", "=", "[", "0.005", ",", "0.01", ",", "0.05", ",", "0.1", "]", ",", "\n", "alpha_ll", "=", "[", "0.3", ",", "0.4", ",", "0.5", "]", ",", "\n", "deltaT_ll", "=", "[", "100", ",", "200", ",", "500", ",", "750", "]", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.density_distribution.get_layer_wise_density": [[62, 85], ["multipledispatch.dispatch", "model_class", "torch.load", "density_distribution.get_layer_wise_density", "sparselearning.utils.model_serialization.load_state_dict", "torch.device", "sparselearning.utils.model_serialization.load_state_dict"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.density_distribution.get_layer_wise_density", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.model_serialization.load_state_dict", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.model_serialization.load_state_dict"], ["", "@", "dispatch", "(", "str", ")", "\n", "def", "get_layer_wise_density", "(", "model_path", ":", "str", ")", "->", "\"Tuple[List[str], List[float]]\"", ":", "\n", "    ", "\"\"\"\n    Layer-wise density list\n\n    :param model_path: Path to model's ckpt\n    :type model_path: str\n    :return: layer names, density\n    :rtype: Tuple[List[str], List[float]]\n    \"\"\"", "\n", "model_class", ",", "args", "=", "model_registry", "[", "\"wrn-22-2\"", "]", "\n", "model", "=", "model_class", "(", "*", "args", ")", "\n", "\n", "ckpt", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "\n", "if", "\"model\"", "in", "ckpt", ":", "\n", "        ", "load_state_dict", "(", "model", ",", "ckpt", "[", "\"model\"", "]", ")", "\n", "", "elif", "\"state_dict\"", "in", "ckpt", ":", "\n", "        ", "load_state_dict", "(", "model", ",", "ckpt", "[", "\"state_dict\"", "]", ")", "\n", "", "else", ":", "\n", "        ", "raise", "KeyError", "\n", "\n", "", "return", "get_layer_wise_density", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.plot_col_vs_density": [[33, 69], ["matplotlib.plot", "matplotlib.axhline", "numpy.array", "list"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density.plot"], ["def", "plot_col_vs_density", "(", "y_key", ",", "data", ",", "method", ",", "init", ",", "**", "plot_kwargs", ")", ":", "\n", "    ", "\"\"\"Plot a particular column vs density for a single method + init combination.\n\n    :param y_key: The name of the column to plot (\"Mean Acc\" or \"Acc Seed 0\" for example)\n    :param data: Pandas DataFrame\n    :param method: Method to plot\n    :param init: Initialization scheme (\"Random\" or \"ERK\")\n    :param plot_kwargs: Additional keyword arguments to pass through to the plt.plot call\n    \"\"\"", "\n", "\n", "dat", "=", "data", ".", "loc", "[", "data", "[", "\"Method\"", "]", "==", "method", "]", "\n", "\n", "if", "method", "==", "\"Dense\"", ":", "\n", "        ", "y", "=", "np", ".", "array", "(", "dat", "[", "y_key", "]", ")", "[", "0", "]", "\n", "line", "=", "plt", ".", "axhline", "(", "\n", "y", ",", "\n", "#             **{**plot_kwargs, 'alpha':0.65},", "\n", "**", "plot_kwargs", ",", "\n", "linewidth", "=", "4", ",", "\n", ")", "\n", "return", "line", "\n", "\n", "", "if", "not", "list", "(", "dat", "[", "\"Init\"", "]", ")", "[", "0", "]", "is", "np", ".", "nan", ":", "\n", "        ", "dat", "=", "dat", ".", "loc", "[", "dat", "[", "\"Init\"", "]", "==", "init", "]", "\n", "\n", "", "x", "=", "dat", "[", "\"Density\"", "]", "\n", "y", "=", "dat", "[", "y_key", "]", "\n", "\n", "(", "line", ",", ")", "=", "plt", ".", "plot", "(", "\n", "x", ",", "\n", "y", ",", "\n", "style", "[", "init", "]", ",", "\n", "**", "plot_kwargs", ",", "\n", ")", "\n", "\n", "return", "line", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.plot_method": [[71, 116], ["main_plots.plot_col_vs_density", "main_plots.plot_col_vs_density", "main_plots.plot_col_vs_density"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.plot_col_vs_density", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.plot_col_vs_density", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.plot_col_vs_density"], ["", "def", "plot_method", "(", "data", ",", "method", ",", "init", ",", "color", ")", ":", "\n", "    ", "\"\"\"Plot the mean accuracy vs density of a method + init combination along with\n    marker plots for each seed.\n\n    :param data: Pandas DataFrame\n    :param method: Method to plot\n    :param init: Initialization scheme (\"Random\" or \"ERK\")\n    :param color: Color of the line plot and markers\n    \"\"\"", "\n", "if", "method", "==", "\"Pruning\"", ":", "\n", "        ", "init", "=", "\"Random\"", "\n", "\n", "", "if", "method", "in", "[", "\"Dense\"", "]", ":", "\n", "        ", "plot_col_vs_density", "(", "\n", "\"Mean Acc\"", ",", "\n", "data", ",", "\n", "method", ",", "\n", "init", "=", "\"Random\"", ",", "\n", "color", "=", "color", ",", "\n", "label", "=", "method", ",", "\n", "alpha", "=", "line_alpha", ",", "\n", ")", "\n", "return", "\n", "\n", "", "for", "ykey", "in", "[", "\"Acc seed 0\"", ",", "\"Acc seed 1\"", ",", "\"Acc seed 2\"", "]", ":", "\n", "        ", "plot_col_vs_density", "(", "\n", "ykey", ",", "\n", "data", ",", "\n", "method", ",", "\n", "init", "=", "init", ",", "\n", "color", "=", "color", ",", "\n", "marker", "=", "\"x\"", ",", "\n", "markeredgewidth", "=", "marker_edge_width", ",", "\n", "linewidth", "=", "0", ",", "\n", "markersize", "=", "marker_size", ",", "\n", "alpha", "=", "marker_alpha", ",", "\n", ")", "\n", "", "plot_col_vs_density", "(", "\n", "\"Mean Acc\"", ",", "\n", "data", ",", "\n", "method", ",", "\n", "init", "=", "init", ",", "\n", "color", "=", "color", ",", "\n", "label", "=", "method", "+", "(", "\" (ERK)\"", "if", "init", "==", "\"ERK\"", "else", "\"\"", ")", ",", "\n", "alpha", "=", "line_alpha", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.create_plot_from_spec": [[119, 148], ["matplotlib.figure", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "matplotlib.savefig", "matplotlib.show", "main_plots.plot_method", "hydra.utils.get_original_cwd"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.plot_method"], ["", "def", "create_plot_from_spec", "(", "data", ",", "plot_spec", ",", "ylimits", ",", "name", ")", ":", "\n", "    ", "\"\"\"Create and save a plot using the data based on plot_spec.\n\n    The plot_spec is list of tuples with each tuple corresponding to one plot of\n    accuracy vs density. The tuple should have three entries -  the method, the\n    initialization scheme, and the color of the plot.\n\n    :param data: Pandas DataFrame containing data about runs\n    :param plot_spec: List of tuples (<method>, <init_scheme>, <color_of_line>)\n    :param ylimits: y limits of the plot\n    :param name: Name of save file\n    \"\"\"", "\n", "plt", ".", "figure", "(", "figsize", "=", "figure_size", ")", "\n", "\n", "for", "method", ",", "init", ",", "color", "in", "plot_spec", ":", "\n", "        ", "plot_method", "(", "data", ",", "method", ",", "init", ",", "color", ")", "\n", "\n", "", "plt", ".", "ylim", "(", "ylimits", ")", "\n", "plt", ".", "xlabel", "(", "\"Density (1 - sparsity)\"", ")", "\n", "plt", ".", "ylabel", "(", "\"Accuracy (Test)\"", ")", "\n", "\n", "plt", ".", "legend", "(", ")", "\n", "\n", "plt", ".", "savefig", "(", "\n", "f\"{hydra.utils.get_original_cwd()}/outputs/plots/{name}.pdf\"", ",", "\n", "bbox_inches", "=", "\"tight\"", ",", "\n", ")", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.cifar10plots": [[150, 185], ["pandas.read_csv", "main_plots.create_plot_from_spec", "main_plots.create_plot_from_spec", "main_plots.create_plot_from_spec", "hydra.utils.get_original_cwd"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.create_plot_from_spec", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.create_plot_from_spec", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.create_plot_from_spec"], ["", "def", "cifar10plots", "(", ")", ":", "\n", "    ", "\"\"\"Create plots for the CIFAR10 dataset (Figs. 1a, 1b and 1c).\"\"\"", "\n", "dataset", "=", "\"cifar10\"", "\n", "csv_path", "=", "(", "\n", "f\"{hydra.utils.get_original_cwd()}/outputs/csv/{dataset}_main_results.csv\"", "\n", ")", "\n", "data", "=", "pd", ".", "read_csv", "(", "csv_path", ")", "\n", "\n", "if", "data", "[", "\"Mean Acc\"", "]", "[", "0", "]", "<", "1", ":", "\n", "        ", "for", "col", "in", "[", "\"Mean Acc\"", ",", "\"Acc seed 0\"", ",", "\"Acc seed 1\"", ",", "\"Acc seed 2\"", "]", ":", "\n", "            ", "data", "[", "col", "]", "*=", "100", "\n", "\n", "", "", "ylimits", "=", "(", "90", ",", "94", ")", "\n", "\n", "# fig 1a", "\n", "name", "=", "f\"{dataset}_random_markers\"", "\n", "plot_spec", "=", "[", "(", "method", ",", "\"Random\"", ",", "COLORS", "[", "method", "]", ")", "for", "method", "in", "methods", "]", "\n", "create_plot_from_spec", "(", "data", ",", "plot_spec", ",", "ylimits", ",", "name", ")", "\n", "\n", "# fig 1b", "\n", "name", "=", "f\"{dataset}_ERK_markers\"", "\n", "plot_spec", "=", "[", "(", "method", ",", "\"ERK\"", ",", "COLORS", "[", "method", "]", ")", "for", "method", "in", "methods", "]", "\n", "create_plot_from_spec", "(", "data", ",", "plot_spec", ",", "ylimits", ",", "name", ")", "\n", "\n", "# fig 1c", "\n", "name", "=", "f\"{dataset}_2x_markers\"", "\n", "plot_spec", "=", "[", "\n", "(", "\"Dense\"", ",", "\"Random\"", ",", "COLORS", "[", "\"Dense\"", "]", ")", ",", "\n", "(", "\"Pruning\"", ",", "\"Random\"", ",", "COLORS", "[", "\"Pruning\"", "]", ")", ",", "\n", "(", "\"RigL\"", ",", "\"ERK\"", ",", "COLORS", "[", "\"RigL\"", "]", ")", ",", "\n", "(", "\"RigL_2x\"", ",", "\"Random\"", ",", "COLORS", "[", "\"RigL\"", "]", ")", ",", "\n", "(", "\"SET_2x\"", ",", "\"Random\"", ",", "COLORS", "[", "\"SET\"", "]", ")", ",", "\n", "(", "\"Static_2x\"", ",", "\"Random\"", ",", "COLORS", "[", "\"Static\"", "]", ")", ",", "\n", "]", "\n", "create_plot_from_spec", "(", "data", ",", "plot_spec", ",", "ylimits", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.cifar100plots": [[187, 216], ["pandas.read_csv", "main_plots.create_plot_from_spec", "main_plots.create_plot_from_spec", "hydra.utils.get_original_cwd"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.create_plot_from_spec", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.create_plot_from_spec"], ["", "def", "cifar100plots", "(", ")", ":", "\n", "    ", "\"\"\"Create plots for the CIFAR100 dataset (Figs. 2a and 2b).\"\"\"", "\n", "dataset", "=", "\"cifar100\"", "\n", "csv_path", "=", "(", "\n", "f\"{hydra.utils.get_original_cwd()}/outputs/csv/{dataset}_main_results.csv\"", "\n", ")", "\n", "data", "=", "pd", ".", "read_csv", "(", "csv_path", ")", "\n", "\n", "if", "data", "[", "\"Mean Acc\"", "]", "[", "0", "]", "<", "1", ":", "\n", "        ", "for", "col", "in", "[", "\"Mean Acc\"", ",", "\"Acc seed 0\"", ",", "\"Acc seed 1\"", ",", "\"Acc seed 2\"", "]", ":", "\n", "            ", "data", "[", "col", "]", "*=", "100", "\n", "\n", "# fig 2a", "\n", "", "", "name", "=", "f\"{dataset}_random_markers\"", "\n", "plot_spec", "=", "[", "(", "method", ",", "\"Random\"", ",", "COLORS", "[", "method", "]", ")", "for", "method", "in", "methods", "]", "\n", "create_plot_from_spec", "(", "data", ",", "plot_spec", ",", "(", "68", ",", "76", ")", ",", "name", ")", "\n", "\n", "# fig 2b", "\n", "name", "=", "f\"{dataset}_ERKand2x_markers\"", "\n", "plot_spec", "=", "[", "\n", "(", "\"Dense\"", ",", "\"Random\"", ",", "COLORS", "[", "\"Dense\"", "]", ")", ",", "\n", "(", "\"Pruning\"", ",", "\"Random\"", ",", "COLORS", "[", "\"Pruning\"", "]", ")", ",", "\n", "(", "\"RigL\"", ",", "\"ERK\"", ",", "COLORS", "[", "\"RigL\"", "]", ")", ",", "\n", "(", "\"RigL_2x\"", ",", "\"Random\"", ",", "\"xkcd:magenta\"", ")", ",", "\n", "(", "\"RigL_2x\"", ",", "\"ERK\"", ",", "\"xkcd:magenta\"", ")", ",", "\n", "(", "\"RigL_3x\"", ",", "\"Random\"", ",", "\"violet\"", ")", ",", "\n", "(", "\"SNFS\"", ",", "\"ERK\"", ",", "COLORS", "[", "\"SNFS\"", "]", ")", ",", "\n", "]", "\n", "create_plot_from_spec", "(", "data", ",", "plot_spec", ",", "(", "71", ",", "75.6", ")", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.main": [[218, 224], ["hydra.main", "main_plots.cifar10plots", "main_plots.cifar100plots"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.redist_inference_plot.main", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.cifar10plots", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_plots.cifar100plots"], ["", "@", "hydra", ".", "main", "(", "config_name", "=", "\"config\"", ",", "config_path", "=", "\"../conf\"", ")", "\n", "def", "main", "(", "cfg", ":", "DictConfig", ")", ":", "\n", "    ", "if", "cfg", ".", "dataset", ".", "name", "==", "\"CIFAR10\"", ":", "\n", "        ", "cifar10plots", "(", ")", "\n", "", "if", "cfg", ".", "dataset", ".", "name", "==", "\"CIFAR100\"", ":", "\n", "        ", "cifar100plots", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_results.get_stats_table": [[22, 115], ["pandas.DataFrame", "logging.info", "enumerate", "df.reset_index.sort_values", "df[].mean", "df[].std", "itertools.product", "logging.debug", "runs_dict.get", "df.reset_index.reset_index", "runs_dict[].append", "str", "range", "range"], "function", ["None"], ["", "def", "get_stats_table", "(", "\n", "runs", ",", "\n", "masking_ll", ":", "\"List[str]\"", "=", "[", "\"RigL\"", "]", ",", "\n", "init_ll", ":", "\"List[str]\"", "=", "[", "\"Random\"", "]", ",", "\n", "suffix_ll", ":", "\"List[str]\"", "=", "[", "\"\"", "]", ",", "\n", "density_ll", ":", "\"List[float]\"", "=", "[", "0.1", "]", ",", "\n", "dataset_ll", ":", "\"List[str]\"", "=", "[", "\"CIFAR10\"", "]", ",", "\n", "reorder", ":", "bool", "=", "True", ",", "\n", "correct_SET", ":", "bool", "=", "False", ",", "\n", ")", "->", "pd", ".", "DataFrame", ":", "\n", "    ", "\"\"\"\n    Get stats saved on W&B.\n\n    List all possible choices for (masking, init, density, dataset).\n\n    We'll try matching the exhaustive caretesian product of\n    (masking_ll x init_ll x suffix_ll x density_ll etc).\n\n    :param runs: Experiment run\n    :type runs: wandb.api.runs\n    :param masking_ll: List of sparse training techniques\n    :type masking_ll: List[str]\n    :param init_ll: List of sparsity initialization schemes\n    :type init_ll: List[str]\n    :param suffix_ll: List of method suffixes.\n    :type suffix_ll: List[str]\n    :param density_ll: List of density values (1 - sparsity)\n    :type density_ll: List[float]\n    :param dataset_ll: List of datasets\n    :type dataset_ll: List[str]\n    :param reorder: sort methods alphabetically\n    :type reorder: bool\n    :param correct_SET: manually correct SET results, which collapsed.\n    :type correct_SET: bool\n    :return: Dataframe containing test accuracies of methods\n    :rtype: pd.DataFrame\n    \"\"\"", "\n", "columns", "=", "[", "\"Method\"", ",", "\"Init\"", ",", "\"Density\"", ",", "\"Acc seed 0\"", ",", "\"Acc seed 1\"", ",", "\"Acc seed 2\"", "]", "\n", "df", "=", "pd", ".", "DataFrame", "(", "columns", "=", "columns", ")", "\n", "\n", "# Pre-process", "\n", "logging", ".", "info", "(", "\"Grouping runs by name\"", ")", "\n", "runs_dict", "=", "{", "}", "\n", "for", "run", "in", "runs", ":", "\n", "        ", "if", "run", ".", "name", "not", "in", "runs_dict", ":", "\n", "            ", "runs_dict", "[", "run", ".", "name", "]", "=", "[", "run", "]", "\n", "", "else", ":", "\n", "            ", "runs_dict", "[", "run", ".", "name", "]", ".", "append", "(", "run", ")", "\n", "\n", "", "", "for", "e", ",", "(", "dataset", ",", "masking", ",", "suffix", ",", "init", ",", "density", ")", "in", "enumerate", "(", "\n", "itertools", ".", "product", "(", "dataset_ll", ",", "masking_ll", ",", "suffix_ll", ",", "init_ll", ",", "density_ll", ")", "\n", ")", ":", "\n", "\n", "        ", "tags", "=", "[", "dataset", ",", "masking", ",", "suffix", ",", "init", ",", "\"density_\"", "+", "str", "(", "density", ")", "]", "\n", "name", "=", "\"_\"", ".", "join", "(", "[", "tag", "for", "tag", "in", "tags", "if", "tag", "]", ")", "\n", "logging", ".", "debug", "(", "name", ")", "\n", "runs", "=", "runs_dict", ".", "get", "(", "name", ",", "None", ")", "\n", "if", "not", "runs", ":", "\n", "            ", "continue", "\n", "\n", "", "accuracy_ll", "=", "[", "None", ",", "None", ",", "None", "]", "\n", "for", "run", "in", "runs", ":", "\n", "            ", "if", "not", "(", "\"test_accuracy\"", "in", "run", ".", "summary", ")", ":", "\n", "                ", "continue", "\n", "\n", "# Admit seeds 0,1,2 only", "\n", "", "if", "run", ".", "config", "[", "\"seed\"", "]", ">", "2", ":", "\n", "                ", "continue", "\n", "", "accuracy_ll", "[", "run", ".", "config", "[", "\"seed\"", "]", "]", "=", "run", ".", "summary", ".", "test_accuracy", "*", "100", "\n", "\n", "if", "correct_SET", ":", "\n", "# Correct SET Random 0.05", "\n", "# Seeds 1,2 suffered from collapse", "\n", "                ", "if", "(", "masking", ",", "suffix", ",", "init", ",", "density", ")", "==", "(", "\"SET\"", ",", "None", ",", "\"Random\"", ",", "0.05", ")", ":", "\n", "                    ", "accuracy_ll", "[", "1", "]", "=", "0.9010", "*", "100", "\n", "accuracy_ll", "[", "2", "]", "=", "0.9000", "*", "100", "\n", "\n", "", "", "", "if", "suffix", ":", "\n", "            ", "masking", "=", "f\"{masking}_{suffix}\"", "\n", "", "df", ".", "loc", "[", "e", "]", "=", "[", "masking", ",", "init", ",", "density", ",", "*", "accuracy_ll", "]", "\n", "\n", "", "df", "=", "df", ".", "sort_values", "(", "by", "=", "[", "\"Method\"", ",", "\"Init\"", ",", "\"Density\"", "]", ")", "\n", "\n", "if", "reorder", ":", "\n", "        ", "df", "=", "df", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "# Compute Mean", "\n", "", "df", "[", "\"Mean Acc\"", "]", "=", "df", "[", "[", "f\"Acc seed {i}\"", "for", "i", "in", "range", "(", "3", ")", "]", "]", ".", "mean", "(", "axis", "=", "1", ")", "\n", "\n", "# Compute std dev", "\n", "df", "[", "\"Std. Dev\"", "]", "=", "df", "[", "[", "f\"Acc seed {i}\"", "for", "i", "in", "range", "(", "3", ")", "]", "]", ".", "std", "(", "axis", "=", "1", ")", "\n", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_results.main": [[117, 155], ["hydra.main", "wandb.Api", "wandb.Api.runs", "main_results.get_stats_table", "get_stats_table.to_csv", "open", "f.read", "pandas.option_context", "print", "hydra.utils.get_original_cwd", "cfg.dataset.name.lower"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.redist_inference_plot.main", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.main_results.get_stats_table"], ["", "@", "hydra", ".", "main", "(", "config_name", "=", "\"config\"", ",", "config_path", "=", "\"../conf\"", ")", "\n", "def", "main", "(", "cfg", ":", "DictConfig", ")", ":", "\n", "# Authenticate API", "\n", "    ", "with", "open", "(", "cfg", ".", "wandb", ".", "api_key", ")", "as", "f", ":", "\n", "        ", "os", ".", "environ", "[", "\"WANDB_API_KEY\"", "]", "=", "f", ".", "read", "(", ")", "\n", "\n", "# Get runs", "\n", "", "api", "=", "wandb", ".", "Api", "(", ")", "\n", "runs", "=", "api", ".", "runs", "(", "f\"{cfg.wandb.entity}/{cfg.wandb.project}\"", ")", "\n", "\n", "df", "=", "get_stats_table", "(", "\n", "runs", ",", "\n", "masking_ll", "=", "[", "\n", "\"RigL\"", ",", "\n", "\"RigL-SG\"", ",", "\n", "\"RigL-SM\"", ",", "\n", "\"SNFS\"", ",", "\n", "\"SET\"", ",", "\n", "\"Small_Dense\"", ",", "\n", "\"Dense\"", ",", "\n", "\"Static\"", ",", "\n", "\"Pruning\"", ",", "\n", "]", ",", "\n", "init_ll", "=", "[", "\"Random\"", ",", "\"ERK\"", ",", "None", "]", ",", "\n", "suffix_ll", "=", "[", "None", ",", "\"corrected\"", ",", "\"no_val\"", ",", "\"2x\"", ",", "\"3x\"", "]", ",", "\n", "density_ll", "=", "[", "0.05", ",", "0.1", ",", "0.2", ",", "0.5", ",", "1", "]", ",", "\n", "dataset_ll", "=", "[", "cfg", ".", "dataset", ".", "name", "]", ",", "\n", "correct_SET", "=", "cfg", ".", "dataset", ".", "name", "==", "\"CIFAR10\"", ",", "\n", ")", "\n", "\n", "# Set longer length", "\n", "pd", ".", "options", ".", "display", ".", "max_rows", "=", "150", "\n", "\n", "with", "pd", ".", "option_context", "(", "\"display.float_format\"", ",", "\"{:.3f}\"", ".", "format", ")", ":", "\n", "        ", "print", "(", "df", ")", "\n", "\n", "", "df", ".", "to_csv", "(", "\n", "f\"{hydra.utils.get_original_cwd()}/outputs/csv/{cfg.dataset.name.lower()}_main_results.csv\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.redist_inference_plot._export_legend": [[31, 36], ["fig.canvas.draw", "legend.get_window_extent().transformed", "fig.savefig", "fig.dpi_scale_trans.inverted", "legend.get_window_extent"], "function", ["None"], ["def", "_export_legend", "(", "legend", ",", "filename", "=", "\"legend.png\"", ")", ":", "\n", "    ", "fig", "=", "legend", ".", "figure", "\n", "fig", ".", "canvas", ".", "draw", "(", ")", "\n", "bbox", "=", "legend", ".", "get_window_extent", "(", ")", ".", "transformed", "(", "fig", ".", "dpi_scale_trans", ".", "inverted", "(", ")", ")", "\n", "fig", ".", "savefig", "(", "filename", ",", "dpi", "=", "\"figure\"", ",", "bbox_inches", "=", "bbox", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.redist_inference_plot._get_steps_and_col": [[38, 49], ["numpy.array", "numpy.array", "numpy.where", "numpy.where", "numpy.isnan", "numpy.array"], "function", ["None"], ["", "def", "_get_steps_and_col", "(", "df", ",", "col", ",", "max_steps", "=", "None", ")", ":", "\n", "    ", "steps", "=", "np", ".", "array", "(", "df", "[", "\"_step\"", "]", ")", "\n", "vals", "=", "np", ".", "array", "(", "df", "[", "col", "]", ")", "\n", "ii", "=", "np", ".", "where", "(", "~", "np", ".", "isnan", "(", "np", ".", "array", "(", "vals", ")", ")", ")", "\n", "steps", "=", "steps", "[", "ii", "]", "\n", "vals", "=", "vals", "[", "ii", "]", "\n", "if", "max_steps", ":", "\n", "        ", "jj", "=", "np", ".", "where", "(", "steps", "<", "max_steps", ")", "\n", "steps", "=", "steps", "[", "jj", "]", "\n", "vals", "=", "vals", "[", "jj", "]", "\n", "", "return", "steps", ",", "vals", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.redist_inference_plot.main": [[51, 129], ["hydra.main", "wandb.Api", "list", "riglsg.history", "riglsm.history", "enumerate", "matplotlib.figure", "matplotlib.axhline", "matplotlib.axhline", "matplotlib.plot", "matplotlib.plot", "matplotlib.legend", "matplotlib.grid", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.tight_layout", "matplotlib.grid", "matplotlib.savefig", "matplotlib.show", "open", "f.read", "wandb.Api.runs", "matplotlib.rcParams[].by_key", "redist_inference_plot._get_steps_and_col", "redist_inference_plot._get_steps_and_col", "hydra.utils.get_original_cwd"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.redist_inference_plot.main", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density.plot", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density.plot", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.redist_inference_plot._get_steps_and_col", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.visualization.redist_inference_plot._get_steps_and_col"], ["", "@", "hydra", ".", "main", "(", "config_name", "=", "\"config\"", ",", "config_path", "=", "\"../conf\"", ")", "\n", "def", "main", "(", "cfg", ":", "DictConfig", ")", ":", "\n", "# Authenticate API", "\n", "    ", "with", "open", "(", "cfg", ".", "wandb", ".", "api_key", ")", "as", "f", ":", "\n", "        ", "os", ".", "environ", "[", "\"WANDB_API_KEY\"", "]", "=", "f", ".", "read", "(", ")", "\n", "\n", "", "api", "=", "wandb", ".", "Api", "(", ")", "\n", "\n", "riglsg", ",", "riglsm", "=", "list", "(", "\n", "api", ".", "runs", "(", "\n", "f\"{cfg.wandb.entity}/{cfg.wandb.project}\"", ",", "\n", "filters", "=", "{", "\n", "\"state\"", ":", "\"finished\"", ",", "\n", "\"config.seed\"", ":", "3", ",", "\n", "\"config.masking.density\"", ":", "0.2", ",", "\n", "\"config.masking.sparse_init\"", ":", "\"random\"", ",", "\n", "\"config.masking.name\"", ":", "\"RigL\"", ",", "\n", "}", ",", "\n", ")", "\n", ")", "\n", "\n", "random_name", "=", "\"Random\"", "\n", "erk_name", "=", "\"ERK\"", "\n", "sg_name", "=", "\"Sparse Grad\"", "\n", "sm_name", "=", "\"Sparse Mmt\"", "\n", "\n", "rigl_random_flops", "=", "0.2", "\n", "rigl_erk_flops", "=", "0.38", "\n", "\n", "flop_col", "=", "\"Avg Inference FLOPs\"", "\n", "sg_history", "=", "riglsg", ".", "history", "(", "samples", "=", "MAX_SAMPLES", ")", "\n", "sm_history", "=", "riglsm", ".", "history", "(", "samples", "=", "MAX_SAMPLES", ")", "\n", "\n", "default_mpl_cycle", "=", "plt", ".", "rcParams", "[", "\"axes.prop_cycle\"", "]", ".", "by_key", "(", ")", "[", "\"color\"", "]", "\n", "\n", "names", "=", "[", "random_name", ",", "erk_name", ",", "sg_name", ",", "sm_name", "]", "\n", "\n", "COLORS", "=", "{", "}", "\n", "for", "i", ",", "k", "in", "enumerate", "(", "names", ")", ":", "\n", "        ", "COLORS", "[", "k", "]", "=", "default_mpl_cycle", "[", "i", "]", "\n", "\n", "", "plt", ".", "figure", "(", "figsize", "=", "(", "5", ",", "5", ")", ")", "\n", "\n", "plt", ".", "axhline", "(", "\n", "rigl_random_flops", ",", "\n", "label", "=", "random_name", ",", "\n", "alpha", "=", "line_alpha", ",", "\n", "color", "=", "COLORS", "[", "random_name", "]", ",", "\n", ")", "\n", "plt", ".", "axhline", "(", "\n", "rigl_erk_flops", ",", "label", "=", "erk_name", ",", "alpha", "=", "line_alpha", ",", "color", "=", "COLORS", "[", "erk_name", "]", "\n", ")", "\n", "plt", ".", "plot", "(", "\n", "*", "_get_steps_and_col", "(", "sg_history", ",", "flop_col", ",", "max_steps", "=", "3.5e4", ")", ",", "\n", "label", "=", "sg_name", ",", "\n", "alpha", "=", "line_alpha", ",", "\n", "color", "=", "COLORS", "[", "sg_name", "]", ",", "\n", ")", "\n", "plt", ".", "plot", "(", "\n", "*", "_get_steps_and_col", "(", "sm_history", ",", "flop_col", ",", "max_steps", "=", "3.5e4", ")", ",", "\n", "label", "=", "sm_name", ",", "\n", "alpha", "=", "line_alpha", ",", "\n", "color", "=", "COLORS", "[", "sm_name", "]", ",", "\n", ")", "\n", "\n", "plt", ".", "legend", "(", "loc", "=", "\"upper right\"", ")", "\n", "\n", "plt", ".", "grid", "(", ")", "\n", "plt", ".", "xlabel", "(", "\"Train Step\"", ")", "\n", "plt", ".", "ylabel", "(", "\"Forward FLOPs\"", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "grid", "(", ")", "\n", "plt", ".", "savefig", "(", "\n", "f\"{hydra.utils.get_original_cwd()}/outputs/plots/{cfg.wandb.project}_redist_inference_flops.pdf\"", ",", "\n", "dpi", "=", "150", ",", "\n", ")", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.scratch.ERK.tim_ERK": [[11, 72], ["enumerate", "enumerate", "module.named_parameters", "logging.info", "module.named_parameters", "torch.zeros_like().to", "module.named_parameters", "weight.numel", "abs", "module.named_parameters", "logging.info", "max", "sum", "numpy.prod", "torch.zeros_like", "int", "weight.numel", "sum", "torch.rand"], "function", ["None"], ["def", "tim_ERK", "(", "module", ",", "density", ",", "tolerance", ":", "int", "=", "5", ",", "growth_factor", ":", "float", "=", "0.5", ")", ":", "\n", "    ", "total_params", "=", "0", "\n", "baseline_nonzero", "=", "0", "\n", "masks", "=", "{", "}", "\n", "for", "e", ",", "(", "name", ",", "weight", ")", "in", "enumerate", "(", "module", ".", "named_parameters", "(", ")", ")", ":", "\n", "# Exclude first layer", "\n", "        ", "if", "e", "==", "0", ":", "\n", "            ", "continue", "\n", "# Exclude bias", "\n", "", "if", "\"bias\"", "in", "name", ":", "\n", "            ", "continue", "\n", "# Exclude batchnorm", "\n", "", "if", "\"bn\"", "in", "name", ":", "\n", "            ", "continue", "\n", "\n", "", "device", "=", "weight", ".", "device", "\n", "masks", "[", "name", "]", "=", "torch", ".", "zeros_like", "(", "\n", "weight", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "False", "\n", ")", ".", "to", "(", "device", ")", "\n", "\n", "", "for", "e", ",", "(", "name", ",", "weight", ")", "in", "enumerate", "(", "module", ".", "named_parameters", "(", ")", ")", ":", "\n", "        ", "if", "name", "not", "in", "masks", ":", "\n", "            ", "continue", "\n", "", "total_params", "+=", "weight", ".", "numel", "(", ")", "\n", "\n", "", "target_params", "=", "total_params", "*", "density", "\n", "current_params", "=", "0", "\n", "epsilon", "=", "10.0", "\n", "\n", "# searching for the right epsilon for a specific sparsity level", "\n", "while", "abs", "(", "current_params", "-", "target_params", ")", ">", "tolerance", ":", "\n", "        ", "new_nonzeros", "=", "0.0", "\n", "for", "name", ",", "weight", "in", "module", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "name", "not", "in", "masks", ":", "\n", "                ", "continue", "\n", "# original SET formulation for fully connected weights: num_weights = epsilon * (noRows + noCols)", "\n", "# we adapt the same formula for convolutional weights", "\n", "", "growth", "=", "max", "(", "int", "(", "epsilon", "*", "sum", "(", "weight", ".", "shape", ")", ")", ",", "weight", ".", "numel", "(", ")", ")", "\n", "new_nonzeros", "+=", "growth", "\n", "", "current_params", "=", "new_nonzeros", "\n", "if", "current_params", ">", "target_params", ":", "\n", "            ", "epsilon", "*=", "1.0", "-", "growth_factor", "\n", "", "else", ":", "\n", "            ", "epsilon", "*=", "1.0", "+", "growth_factor", "\n", "", "growth_factor", "*=", "0.95", "\n", "\n", "", "density_dict", "=", "{", "}", "\n", "for", "name", ",", "weight", "in", "module", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "name", "not", "in", "masks", ":", "\n", "            ", "continue", "\n", "", "growth", "=", "epsilon", "*", "sum", "(", "weight", ".", "shape", ")", "\n", "prob", "=", "growth", "/", "np", ".", "prod", "(", "weight", ".", "shape", ")", "\n", "density_dict", "[", "name", "]", "=", "prob", "\n", "logging", ".", "info", "(", "f\"ERK {name}: {weight.shape} prob {prob}\"", ")", "\n", "\n", "device", "=", "weight", ".", "device", "\n", "masks", "[", "name", "]", "=", "(", "torch", ".", "rand", "(", "weight", ".", "shape", ")", "<", "prob", ")", ".", "float", "(", ")", ".", "data", ".", "to", "(", "device", ")", "\n", "baseline_nonzero", "+=", "(", "masks", "[", "name", "]", "!=", "0", ")", ".", "sum", "(", ")", ".", "int", "(", ")", ".", "item", "(", ")", "\n", "", "logging", ".", "info", "(", "f\"Overall sparsity {baseline_nonzero/total_params}\"", ")", "\n", "\n", "return", "density_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.scratch.ERK.googleAI_ERK": [[74, 190], ["enumerate", "set", "masks.items", "logging.info", "module.named_parameters", "torch.zeros_like().to", "weight.numel", "masks.items", "numpy.max", "numpy.prod", "logging.info", "numpy.prod", "list", "raw_probabilities.items", "mask.numel", "torch.zeros_like", "raw_probabilities.values", "logging.info", "set.add", "numpy.sum", "numpy.prod"], "function", ["None"], ["", "def", "googleAI_ERK", "(", "module", ",", "density", ",", "erk_power_scale", ":", "float", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"Given the method, returns the sparsity of individual layers as a dict.\n    It ensures that the non-custom layers have a total parameter count as the one\n    with uniform sparsities. In other words for the layers which are not in the\n    custom_sparsity_map the following equation should be satisfied.\n    # eps * (p_1 * N_1 + p_2 * N_2) = (1 - default_sparsity) * (N_1 + N_2)\n    Args:\n      module: \n      density: float, between 0 and 1.\n      erk_power_scale: float, if given used to take power of the ratio. Use\n        scale<1 to make the erdos_renyi softer.\n    Returns:\n      density_dict, dict of where keys() are equal to all_masks and individiual\n        masks are mapped to the their densities.\n    \"\"\"", "\n", "# Obtain masks", "\n", "masks", "=", "{", "}", "\n", "total_params", "=", "0", "\n", "for", "e", ",", "(", "name", ",", "weight", ")", "in", "enumerate", "(", "module", ".", "named_parameters", "(", ")", ")", ":", "\n", "# Exclude first layer", "\n", "        ", "if", "e", "==", "0", ":", "\n", "            ", "continue", "\n", "# Exclude bias", "\n", "", "if", "\"bias\"", "in", "name", ":", "\n", "            ", "continue", "\n", "# Exclude batchnorm", "\n", "", "if", "\"bn\"", "in", "name", ":", "\n", "            ", "continue", "\n", "\n", "", "device", "=", "weight", ".", "device", "\n", "masks", "[", "name", "]", "=", "torch", ".", "zeros_like", "(", "\n", "weight", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "False", "\n", ")", ".", "to", "(", "device", ")", "\n", "total_params", "+=", "weight", ".", "numel", "(", ")", "\n", "\n", "# We have to enforce custom sparsities and then find the correct scaling", "\n", "# factor.", "\n", "\n", "", "is_epsilon_valid", "=", "False", "\n", "# # The following loop will terminate worst case when all masks are in the", "\n", "# custom_sparsity_map. This should probably never happen though, since once", "\n", "# we have a single variable or more with the same constant, we have a valid", "\n", "# epsilon. Note that for each iteration we add at least one variable to the", "\n", "# custom_sparsity_map and therefore this while loop should terminate.", "\n", "dense_layers", "=", "set", "(", ")", "\n", "while", "not", "is_epsilon_valid", ":", "\n", "# We will start with all layers and try to find right epsilon. However if", "\n", "# any probablity exceeds 1, we will make that layer dense and repeat the", "\n", "# process (finding epsilon) with the non-dense layers.", "\n", "# We want the total number of connections to be the same. Let say we have", "\n", "# for layers with N_1, ..., N_4 parameters each. Let say after some", "\n", "# iterations probability of some dense layers (3, 4) exceeded 1 and", "\n", "# therefore we added them to the dense_layers set. Those layers will not", "\n", "# scale with erdos_renyi, however we need to count them so that target", "\n", "# paratemeter count is achieved. See below.", "\n", "# eps * (p_1 * N_1 + p_2 * N_2) + (N_3 + N_4) =", "\n", "#    (1 - default_sparsity) * (N_1 + N_2 + N_3 + N_4)", "\n", "# eps * (p_1 * N_1 + p_2 * N_2) =", "\n", "#    (1 - default_sparsity) * (N_1 + N_2) - default_sparsity * (N_3 + N_4)", "\n", "# eps = rhs / (\\sum_i p_i * N_i) = rhs / divisor.", "\n", "\n", "        ", "divisor", "=", "0", "\n", "rhs", "=", "0", "\n", "raw_probabilities", "=", "{", "}", "\n", "for", "name", ",", "mask", "in", "masks", ".", "items", "(", ")", ":", "\n", "            ", "n_param", "=", "np", ".", "prod", "(", "mask", ".", "shape", ")", "\n", "n_zeros", "=", "n_param", "*", "(", "1", "-", "density", ")", "\n", "n_ones", "=", "n_param", "*", "density", "\n", "\n", "if", "name", "in", "dense_layers", ":", "\n", "# See `- default_sparsity * (N_3 + N_4)` part of the equation above.", "\n", "                ", "rhs", "-=", "n_zeros", "\n", "\n", "", "else", ":", "\n", "# Corresponds to `(1 - default_sparsity) * (N_1 + N_2)` part of the", "\n", "# equation above.", "\n", "                ", "rhs", "+=", "n_ones", "\n", "# Erdos-Renyi probability: epsilon * (n_in + n_out / n_in * n_out).", "\n", "raw_probabilities", "[", "name", "]", "=", "(", "\n", "np", ".", "sum", "(", "mask", ".", "shape", ")", "/", "np", ".", "prod", "(", "mask", ".", "shape", ")", "\n", ")", "**", "erk_power_scale", "\n", "# Note that raw_probabilities[mask] * n_param gives the individual", "\n", "# elements of the divisor.", "\n", "divisor", "+=", "raw_probabilities", "[", "name", "]", "*", "n_param", "\n", "# By multipliying individual probabilites with epsilon, we should get the", "\n", "# number of parameters per layer correctly.", "\n", "", "", "epsilon", "=", "rhs", "/", "divisor", "\n", "# If epsilon * raw_probabilities[mask.name] > 1. We set the sparsities of that", "\n", "# mask to 0., so they become part of dense_layers sets.", "\n", "max_prob", "=", "np", ".", "max", "(", "list", "(", "raw_probabilities", ".", "values", "(", ")", ")", ")", "\n", "max_prob_one", "=", "max_prob", "*", "epsilon", "\n", "if", "max_prob_one", ">", "1", ":", "\n", "            ", "is_epsilon_valid", "=", "False", "\n", "for", "mask_name", ",", "mask_raw_prob", "in", "raw_probabilities", ".", "items", "(", ")", ":", "\n", "                ", "if", "mask_raw_prob", "==", "max_prob", ":", "\n", "                    ", "logging", ".", "info", "(", "f\"Sparsity of var:{mask_name} had to be set to 0.\"", ")", "\n", "dense_layers", ".", "add", "(", "mask_name", ")", "\n", "", "", "", "else", ":", "\n", "            ", "is_epsilon_valid", "=", "True", "\n", "\n", "", "", "density_dict", "=", "{", "}", "\n", "total_nonzero", "=", "0.0", "\n", "# With the valid epsilon, we can set sparsities of the remaning layers.", "\n", "for", "name", ",", "mask", "in", "masks", ".", "items", "(", ")", ":", "\n", "        ", "n_param", "=", "np", ".", "prod", "(", "mask", ".", "shape", ")", "\n", "if", "name", "in", "dense_layers", ":", "\n", "            ", "density_dict", "[", "name", "]", "=", "1.0", "\n", "", "else", ":", "\n", "            ", "probability_one", "=", "epsilon", "*", "raw_probabilities", "[", "name", "]", "\n", "density_dict", "[", "name", "]", "=", "probability_one", "\n", "", "logging", ".", "info", "(", "\n", "f\"layer: {name}, shape: {mask.shape}, density: {density_dict[name]}\"", "\n", ")", "\n", "total_nonzero", "+=", "density_dict", "[", "name", "]", "*", "mask", ".", "numel", "(", ")", "\n", "", "logging", ".", "info", "(", "f\"Overall sparsity {total_nonzero/total_params}\"", ")", "\n", "return", "density_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.wide_resnet.WideResNet.__init__": [[28, 92], ["torch.Module.__init__", "numpy.sqrt", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "wide_resnet.NetworkBlock", "wide_resnet.NetworkBlock", "wide_resnet.NetworkBlock", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "wide_resnet.WideResNet.modules", "int", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_", "isinstance", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.LinearDecay.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "depth", ":", "int", "=", "22", ",", "\n", "widen_factor", ":", "int", "=", "2", ",", "\n", "num_classes", ":", "int", "=", "10", ",", "\n", "dropRate", ":", "float", "=", "0.3", ",", "\n", "small_dense_density", ":", "float", "=", "1.0", ",", "\n", ")", ":", "\n", "        ", "super", "(", "WideResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "small_dense_multiplier", "=", "np", ".", "sqrt", "(", "small_dense_density", ")", "\n", "nChannels", "=", "[", "16", ",", "16", "*", "widen_factor", ",", "32", "*", "widen_factor", ",", "64", "*", "widen_factor", "]", "\n", "nChannels", "=", "[", "int", "(", "c", "*", "small_dense_multiplier", ")", "for", "c", "in", "nChannels", "]", "\n", "assert", "(", "depth", "-", "4", ")", "%", "6", "==", "0", "\n", "n", "=", "(", "depth", "-", "4", ")", "/", "6", "\n", "block", "=", "BasicBlock", "\n", "# 1st conv before any network block", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "3", ",", "nChannels", "[", "0", "]", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", "\n", ")", "\n", "# 1st block", "\n", "self", ".", "block1", "=", "NetworkBlock", "(", "\n", "n", ",", "\n", "nChannels", "[", "0", "]", ",", "\n", "nChannels", "[", "1", "]", ",", "\n", "block", ",", "\n", "1", ",", "\n", "dropRate", ",", "\n", ")", "\n", "# 2nd block", "\n", "self", ".", "block2", "=", "NetworkBlock", "(", "\n", "n", ",", "\n", "nChannels", "[", "1", "]", ",", "\n", "nChannels", "[", "2", "]", ",", "\n", "block", ",", "\n", "2", ",", "\n", "dropRate", ",", "\n", ")", "\n", "# 3rd block", "\n", "self", ".", "block3", "=", "NetworkBlock", "(", "\n", "n", ",", "\n", "nChannels", "[", "2", "]", ",", "\n", "nChannels", "[", "3", "]", ",", "\n", "block", ",", "\n", "2", ",", "\n", "dropRate", ",", "\n", ")", "\n", "# global average pooling and classifier", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "nChannels", "[", "3", "]", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "nChannels", "[", "3", "]", ",", "num_classes", ")", "\n", "self", ".", "nChannels", "=", "nChannels", "[", "3", "]", "\n", "self", ".", "feats", "=", "[", "]", "\n", "self", ".", "densities", "=", "[", "]", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.0", "/", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.wide_resnet.WideResNet.forward": [[93, 104], ["wide_resnet.WideResNet.conv1", "wide_resnet.WideResNet.block1", "wide_resnet.WideResNet.block2", "wide_resnet.WideResNet.block3", "wide_resnet.WideResNet.relu", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "wide_resnet.WideResNet.view", "wide_resnet.WideResNet.fc", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "wide_resnet.WideResNet.bn1"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "block1", "(", "out", ")", "\n", "out", "=", "self", ".", "block2", "(", "out", ")", "\n", "out", "=", "self", ".", "block3", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "relu", "(", "self", ".", "bn1", "(", "out", ")", ")", "\n", "out", "=", "F", ".", "avg_pool2d", "(", "out", ",", "8", ")", "\n", "out", "=", "out", ".", "view", "(", "-", "1", ",", "self", ".", "nChannels", ")", "\n", "out", "=", "self", ".", "fc", "(", "out", ")", "\n", "return", "F", ".", "log_softmax", "(", "out", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.wide_resnet.BasicBlock.__init__": [[123, 158], ["torch.Module.__init__", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.LinearDecay.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "in_planes", ":", "int", ",", "\n", "out_planes", ":", "int", ",", "\n", "stride", ":", "int", ",", "\n", "dropRate", ":", "float", "=", "0.0", ",", "\n", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "in_planes", ")", "\n", "self", ".", "relu1", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "\n", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "out_planes", ")", "\n", "self", ".", "relu2", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "\n", "out_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "droprate", "=", "dropRate", "\n", "self", ".", "equalInOut", "=", "in_planes", "==", "out_planes", "\n", "self", ".", "convShortcut", "=", "(", "\n", "(", "not", "self", ".", "equalInOut", ")", "\n", "and", "nn", ".", "Conv2d", "(", "\n", "in_planes", ",", "\n", "out_planes", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "0", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "or", "None", "\n", ")", "\n", "self", ".", "feats", "=", "[", "]", "\n", "self", ".", "densities", "=", "[", "]", "\n", "self", ".", "in_planes", "=", "in_planes", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.wide_resnet.BasicBlock.forward": [[159, 175], ["wide_resnet.BasicBlock.conv1", "wide_resnet.BasicBlock.relu2", "wide_resnet.BasicBlock.conv2", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "torch.add", "wide_resnet.BasicBlock.relu1", "wide_resnet.BasicBlock.relu1", "wide_resnet.BasicBlock.bn2", "torch.dropout", "torch.dropout", "torch.dropout", "wide_resnet.BasicBlock.bn1", "wide_resnet.BasicBlock.bn1", "wide_resnet.BasicBlock.convShortcut"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "not", "self", ".", "equalInOut", ":", "\n", "            ", "x", "=", "self", ".", "relu1", "(", "self", ".", "bn1", "(", "x", ")", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "self", ".", "relu1", "(", "self", ".", "bn1", "(", "x", ")", ")", "\n", "\n", "", "out0", "=", "self", ".", "conv1", "(", "out", "if", "self", ".", "equalInOut", "else", "x", ")", "\n", "\n", "out", "=", "self", ".", "relu2", "(", "self", ".", "bn2", "(", "out0", ")", ")", "\n", "\n", "if", "self", ".", "droprate", ">", "0", ":", "\n", "            ", "out", "=", "F", ".", "dropout", "(", "out", ",", "p", "=", "self", ".", "droprate", ",", "training", "=", "self", ".", "training", ")", "\n", "\n", "", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "\n", "return", "torch", ".", "add", "(", "x", "if", "self", ".", "equalInOut", "else", "self", ".", "convShortcut", "(", "x", ")", ",", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.wide_resnet.NetworkBlock.__init__": [[199, 214], ["torch.Module.__init__", "wide_resnet.NetworkBlock._make_layer"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.LinearDecay.__init__", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.ResNet._make_layer"], ["def", "__init__", "(", "\n", "self", ",", "\n", "nb_layers", ":", "int", ",", "\n", "in_planes", ":", "int", ",", "\n", "out_planes", ":", "int", ",", "\n", "block", ":", "BasicBlock", ",", "\n", "stride", ":", "int", ",", "\n", "dropRate", ":", "float", "=", "0.0", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", "NetworkBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "feats", "=", "[", "]", "\n", "self", ".", "densities", "=", "[", "]", "\n", "self", ".", "layer", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "in_planes", ",", "out_planes", ",", "nb_layers", ",", "stride", ",", "dropRate", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.wide_resnet.NetworkBlock._make_layer": [[216, 228], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "int", "layers.append", "block"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "block", ",", "in_planes", ",", "out_planes", ",", "nb_layers", ",", "stride", ",", "dropRate", ")", ":", "\n", "        ", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "nb_layers", ")", ")", ":", "\n", "            ", "layers", ".", "append", "(", "\n", "block", "(", "\n", "i", "==", "0", "and", "in_planes", "or", "out_planes", ",", "\n", "out_planes", ",", "\n", "i", "==", "0", "and", "stride", "or", "1", ",", "\n", "dropRate", ",", "\n", ")", "\n", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.wide_resnet.NetworkBlock.forward": [[229, 233], ["layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layer", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.BasicBlock.__init__": [[39, 79], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.LinearDecay.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ":", "int", ",", "out_channels", ":", "int", ",", "stride", ":", "int", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# residual function", "\n", "self", ".", "residual_function", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "kernel_size", "=", "3", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "\n", "out_channels", ",", "\n", "out_channels", "*", "BasicBlock", ".", "expansion", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", "*", "BasicBlock", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "# shortcut", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "\n", "# the shortcut output dimension is not the same with residual function", "\n", "# use 1*1 convolution to match the dimension", "\n", "if", "stride", "!=", "1", "or", "in_channels", "!=", "BasicBlock", ".", "expansion", "*", "out_channels", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", "*", "BasicBlock", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", "*", "BasicBlock", ".", "expansion", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.BasicBlock.forward": [[81, 83], ["torch.ReLU", "torch.ReLU", "resnet.BasicBlock.residual_function", "resnet.BasicBlock.shortcut"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "(", "self", ".", "residual_function", "(", "x", ")", "+", "self", ".", "shortcut", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.BottleNeck.__init__": [[99, 136], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.LinearDecay.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ":", "int", ",", "out_channels", ":", "int", ",", "stride", ":", "int", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "residual_function", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "\n", "out_channels", ",", "\n", "out_channels", ",", "\n", "stride", "=", "stride", ",", "\n", "kernel_size", "=", "3", ",", "\n", "padding", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "\n", "out_channels", ",", "\n", "out_channels", "*", "BottleNeck", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", "*", "BottleNeck", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "\n", "if", "stride", "!=", "1", "or", "in_channels", "!=", "out_channels", "*", "BottleNeck", ".", "expansion", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "in_channels", ",", "\n", "out_channels", "*", "BottleNeck", ".", "expansion", ",", "\n", "stride", "=", "stride", ",", "\n", "kernel_size", "=", "1", ",", "\n", "bias", "=", "False", ",", "\n", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_channels", "*", "BottleNeck", ".", "expansion", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.BottleNeck.forward": [[138, 140], ["torch.ReLU", "torch.ReLU", "resnet.BottleNeck.residual_function", "resnet.BottleNeck.shortcut"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "(", "self", ".", "residual_function", "(", "x", ")", "+", "self", ".", "shortcut", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.ResNet.__init__": [[166, 220], ["torch.Module.__init__", "numpy.sqrt", "int", "torch.Sequential", "torch.Sequential", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Linear", "torch.Linear", "resnet.ResNet.modules", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "int", "int", "int", "int", "isinstance", "resnet.ResNet.modules", "int", "int", "int", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.LinearDecay.__init__", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.ResNet._make_layer"], ["def", "__init__", "(", "\n", "self", ",", "\n", "block", ":", "\"Union[BasicBlock, BottleNeck]\"", ",", "\n", "num_block", ":", "\"List[int]\"", ",", "\n", "num_classes", ":", "int", "=", "100", ",", "\n", "small_dense_density", ":", "float", "=", "1.0", ",", "\n", "zero_init_residual", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "small_dense_density", "=", "np", ".", "sqrt", "(", "small_dense_density", ")", "\n", "\n", "self", ".", "in_channels", "=", "int", "(", "64", "*", "small_dense_density", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "\n", "3", ",", "int", "(", "64", "*", "small_dense_density", ")", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "False", "\n", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "int", "(", "64", "*", "small_dense_density", ")", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", ")", "\n", "# we use a different inputsize than the original paper", "\n", "# so conv2_x's stride is 1", "\n", "self", ".", "conv2_x", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "int", "(", "64", "*", "small_dense_density", ")", ",", "num_block", "[", "0", "]", ",", "1", "\n", ")", "\n", "self", ".", "conv3_x", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "int", "(", "128", "*", "small_dense_density", ")", ",", "num_block", "[", "1", "]", ",", "2", "\n", ")", "\n", "self", ".", "conv4_x", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "int", "(", "256", "*", "small_dense_density", ")", ",", "num_block", "[", "2", "]", ",", "2", "\n", ")", "\n", "self", ".", "conv5_x", "=", "self", ".", "_make_layer", "(", "\n", "block", ",", "int", "(", "512", "*", "small_dense_density", ")", ",", "num_block", "[", "3", "]", ",", "2", "\n", ")", "\n", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "\n", "int", "(", "512", "*", "small_dense_density", ")", "*", "block", ".", "expansion", ",", "num_classes", "\n", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "\"fan_out\"", ",", "nonlinearity", "=", "\"relu\"", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "(", "nn", ".", "BatchNorm2d", ",", "nn", ".", "GroupNorm", ")", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n", "# Zero-initialize the last BN in each residual branch,", "\n", "# so that the residual branch starts with zeros, and each residual block behaves like an identity.", "\n", "# This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677", "\n", "", "", "if", "zero_init_residual", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "BottleNeck", ")", "or", "isinstance", "(", "m", ",", "BasicBlock", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "residual_function", "[", "-", "1", "]", ".", "weight", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.ResNet._make_layer": [[221, 253], ["torch.Sequential", "torch.Sequential", "layers.append", "block"], "methods", ["None"], ["", "", "", "", "def", "_make_layer", "(", "\n", "self", ",", "\n", "block", ":", "\"Union[BasicBlock, BottleNeck]\"", ",", "\n", "out_channels", ":", "int", ",", "\n", "num_blocks", ":", "int", ",", "\n", "stride", ":", "int", ",", "\n", ")", "->", "nn", ".", "Sequential", ":", "\n", "        ", "\"\"\"\n        Make resnet layers(by layer i didnt mean this 'layer' was the\n        same as a neuron netowork layer, ex. conv layer), one layer may\n        contain more than one residual block.\n\n        :param block: Block type, Basic or Bottleneck\n        :type block: Union[BasicBlock, BottleNeck]\n        :param out_channels: output depth channel number of this layer\n        :type out_channels: int\n        :param num_blocks: how many blocks per layer\n        :type num_blocks: int\n        :param stride: the stride of the first block of this layer\n        :type stride: int\n        :return: return a resnet layer\n        :rtype: nn.Sequential\n        \"\"\"", "\n", "# we have num_block blocks per layer, the first block", "\n", "# could be 1 or 2, other blocks would always be 1", "\n", "strides", "=", "[", "stride", "]", "+", "[", "1", "]", "*", "(", "num_blocks", "-", "1", ")", "\n", "layers", "=", "[", "]", "\n", "for", "stride", "in", "strides", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "in_channels", ",", "out_channels", ",", "stride", ")", ")", "\n", "self", ".", "in_channels", "=", "out_channels", "*", "block", ".", "expansion", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.ResNet.forward": [[254, 265], ["resnet.ResNet.conv1", "resnet.ResNet.conv2_x", "resnet.ResNet.conv3_x", "resnet.ResNet.conv4_x", "resnet.ResNet.conv5_x", "resnet.ResNet.avg_pool", "resnet.ResNet.view", "resnet.ResNet.fc", "torch.log_softmax", "torch.log_softmax", "resnet.ResNet.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output", "=", "self", ".", "conv1", "(", "x", ")", "\n", "output", "=", "self", ".", "conv2_x", "(", "output", ")", "\n", "output", "=", "self", ".", "conv3_x", "(", "output", ")", "\n", "output", "=", "self", ".", "conv4_x", "(", "output", ")", "\n", "output", "=", "self", ".", "conv5_x", "(", "output", ")", "\n", "output", "=", "self", ".", "avg_pool", "(", "output", ")", "\n", "output", "=", "output", ".", "view", "(", "output", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "output", "=", "self", ".", "fc", "(", "output", ")", "\n", "\n", "return", "F", ".", "log_softmax", "(", "output", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.resnet18": [[267, 272], ["resnet.ResNet"], "function", ["None"], ["", "", "def", "resnet18", "(", ")", ":", "\n", "    ", "\"\"\"\n    return a ResNet-18 model\n    \"\"\"", "\n", "return", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.resnet34": [[274, 279], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet34", "(", ")", ":", "\n", "    ", "\"\"\"\n    return a ResNet-34 model\n    \"\"\"", "\n", "return", "ResNet", "(", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.resnet50": [[281, 286], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet50", "(", ")", ":", "\n", "    ", "\"\"\"\n    return a ResNet-50 model\n    \"\"\"", "\n", "return", "ResNet", "(", "BottleNeck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.resnet101": [[288, 293], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet101", "(", ")", ":", "\n", "    ", "\"\"\"\n    return a ResNet-101 model\n    \"\"\"", "\n", "return", "ResNet", "(", "BottleNeck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.models.resnet.resnet152": [[295, 300], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet152", "(", ")", ":", "\n", "    ", "\"\"\"\n    return a ResNet-152 model\n    \"\"\"", "\n", "return", "ResNet", "(", "BottleNeck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.LayerStats.load_state_dict": [[66, 72], ["setattr", "setattr"], "methods", ["None"], ["def", "load_state_dict", "(", "self", ",", "*", "initial_data", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "dictionary", "in", "initial_data", ":", "\n", "            ", "for", "key", "in", "dictionary", ":", "\n", "                ", "setattr", "(", "self", ",", "key", ",", "dictionary", "[", "key", "]", ")", "\n", "", "", "for", "key", "in", "kwargs", ":", "\n", "            ", "setattr", "(", "self", ",", "key", ",", "kwargs", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.LayerStats.state_dict": [[73, 85], ["None"], "methods", ["None"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "_state_dict", "=", "{", "\n", "\"variance_dict\"", ":", "self", ".", "variance_dict", ",", "\n", "\"zeros_dict\"", ":", "self", ".", "zeros_dict", ",", "\n", "\"nonzeros_dict\"", ":", "self", ".", "nonzeros_dict", ",", "\n", "\"removed_dict\"", ":", "self", ".", "removed_dict", ",", "\n", "\"total_variance\"", ":", "self", ".", "total_variance", ",", "\n", "\"total_zero\"", ":", "self", ".", "total_zero", ",", "\n", "\"total_nonzero\"", ":", "self", ".", "total_nonzero", ",", "\n", "\"total_removed\"", ":", "self", ".", "total_removed", ",", "\n", "}", "\n", "return", "_state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.LayerStats.total_density": [[86, 91], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "total_density", "(", "self", ")", ":", "\n", "        ", "if", "not", "(", "self", ".", "total_zero", "+", "self", ".", "total_nonzero", ")", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "self", ".", "total_nonzero", "/", "(", "self", ".", "total_zero", "+", "self", ".", "total_nonzero", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.LayerStats.__repr__": [[92, 109], ["enumerate", "_str_dict.items", "len"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "_str_dict", "=", "{", "\n", "\"total_variance\"", ":", "self", ".", "total_variance", ",", "\n", "\"total_zero\"", ":", "self", ".", "total_zero", ",", "\n", "\"total_nonzero\"", ":", "self", ".", "total_nonzero", ",", "\n", "\"total_removed\"", ":", "self", ".", "total_removed", ",", "\n", "\"total_density\"", ":", "self", ".", "total_density", ",", "\n", "}", "\n", "\n", "_str", "=", "\"LayerStats(\"", "\n", "for", "e", ",", "(", "name", ",", "value", ")", "in", "enumerate", "(", "_str_dict", ".", "items", "(", ")", ")", ":", "\n", "            ", "if", "e", "==", "len", "(", "_str_dict", ")", "-", "1", ":", "\n", "                ", "_str", "+=", "f\"{name}={value})\"", "\n", "", "else", ":", "\n", "                ", "_str", "+=", "f\"{name}={value}, \"", "\n", "\n", "", "", "return", "_str", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.__post_init__": [[169, 199], ["core.LayerStats", "sparselearning.utils.smoothen_value.AverageValue", "sparselearning.funcs.grow.registry.keys", "sparselearning.funcs.prune.registry.keys", "sparselearning.funcs.redistribute.registry.keys", "sparselearning.funcs.init_scheme.registry.keys", "sparselearning.funcs.grow.registry.keys", "sparselearning.funcs.prune.registry.keys", "sparselearning.funcs.redistribute.registry.keys"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "baseline_nonzero", "=", "0", "\n", "self", ".", "total_params", "=", "0", "\n", "\n", "# Growth adjustment", "\n", "self", ".", "adjusted_growth", "=", "0", "\n", "self", ".", "adjustments", "=", "[", "]", "\n", "\n", "self", ".", "name2prune_rate", "=", "{", "}", "\n", "# layer-wise statistics", "\n", "self", ".", "stats", "=", "LayerStats", "(", ")", "\n", "\n", "# FLOPs", "\n", "self", ".", "_dense_FLOPs", "=", "None", "\n", "self", ".", "_inference_FLOPs_collector", "=", "AverageValue", "(", ")", "\n", "\n", "# Assertions", "\n", "assert", "(", "\n", "self", ".", "sparse_init", "in", "init_registry", "\n", ")", ",", "f\"Sparse init {self.sparse_init} not found. Available {init_registry.keys()}\"", "\n", "assert", "(", "\n", "self", ".", "growth_mode", "in", "grow_registry", ".", "keys", "(", ")", "\n", ")", ",", "f\"Available growth modes: {','.join(grow_registry.keys())}\"", "\n", "\n", "assert", "(", "\n", "self", ".", "prune_mode", "in", "prune_registry", ".", "keys", "(", ")", "\n", ")", ",", "f\"Available prune modes: {','.join(prune_registry.keys())}\"", "\n", "assert", "(", "\n", "self", ".", "redistribution_mode", "in", "redistribute_registry", ".", "keys", "(", ")", "\n", ")", ",", "f\"Available redistribute modes: {','.join(redistribute_registry.keys())}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.add_module": [[220, 249], ["logging.info", "core.Masking.module.named_parameters", "core.Masking.to_module_device_", "logging.info", "core.Masking.remove_weight_partial_name", "logging.info", "core.Masking.remove_type", "logging.info", "core.Masking.remove_type", "core.Masking.init", "logging.info", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.to_module_device_", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.remove_weight_partial_name", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.remove_type", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.remove_type", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.init"], ["def", "add_module", "(", "self", ",", "module", ",", "lottery_mask_path", ":", "\"Path\"", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Store dict of parameters to mask\n\n        :param module: to mask\n        :param lottery_mask_path: initialize from an existing model's mask.\n        :return:\n        \"\"\"", "\n", "self", ".", "module", "=", "module", "\n", "logging", ".", "info", "(", "f\"Dense FLOPs {self.dense_FLOPs:,}\"", ")", "\n", "for", "name", ",", "weight", "in", "self", ".", "module", ".", "named_parameters", "(", ")", ":", "\n", "            ", "self", ".", "mask_dict", "[", "name", "]", "=", "torch", ".", "zeros_like", "(", "\n", "weight", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "False", "\n", ")", "\n", "\n", "# Send to appropriate device, same as weights", "\n", "", "self", ".", "to_module_device_", "(", ")", "\n", "\n", "# Remove bias, batchnorms", "\n", "logging", ".", "info", "(", "\"Removing biases...\"", ")", "\n", "self", ".", "remove_weight_partial_name", "(", "\"bias\"", ")", "\n", "logging", ".", "info", "(", "\"Removing 2D batch norms...\"", ")", "\n", "self", ".", "remove_type", "(", "nn", ".", "BatchNorm2d", ")", "\n", "logging", ".", "info", "(", "\"Removing 1D batch norms...\"", ")", "\n", "self", ".", "remove_type", "(", "nn", ".", "BatchNorm1d", ")", "\n", "\n", "# Call init", "\n", "self", ".", "init", "(", "lottery_mask_path", ")", "\n", "logging", ".", "info", "(", "f\"Inference (Sparse) FLOPs (at init) {self.inference_FLOPs:,}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.adjust_prune_rate": [[250, 269], ["core.Masking.mask_dict.items", "mask.numel", "len", "min", "core.Masking.stats.variance_dict.keys"], "methods", ["None"], ["", "def", "adjust_prune_rate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Modify prune rate for layers with low sparsity\n        \"\"\"", "\n", "for", "name", ",", "mask", "in", "self", ".", "mask_dict", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "name2prune_rate", "[", "name", "]", "=", "self", ".", "prune_rate", "\n", "\n", "sparsity", "=", "self", ".", "stats", ".", "zeros_dict", "[", "name", "]", "/", "mask", ".", "numel", "(", ")", "\n", "if", "sparsity", "<", "0.2", ":", "\n", "# determine if matrix is relatively dense but still growing", "\n", "                ", "expected_variance", "=", "1.0", "/", "len", "(", "self", ".", "stats", ".", "variance_dict", ".", "keys", "(", ")", ")", "\n", "actual_variance", "=", "self", ".", "stats", ".", "variance_dict", "[", "name", "]", "\n", "expected_vs_actual", "=", "expected_variance", "/", "actual_variance", "\n", "\n", "# if weights aren't steady yet, i.e., can change significantly", "\n", "if", "expected_vs_actual", "<", "1.0", ":", "\n", "# growing", "\n", "                    ", "self", ".", "name2prune_rate", "[", "name", "]", "=", "min", "(", "\n", "sparsity", ",", "self", ".", "name2prune_rate", "[", "name", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.apply_mask": [[271, 279], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "core.Masking.module.named_parameters"], "methods", ["None"], ["", "", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "apply_mask", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Applies boolean mask to modules\n        \"\"\"", "\n", "for", "name", ",", "weight", "in", "self", ".", "module", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "name", "in", "self", ".", "mask_dict", ":", "\n", "                ", "weight", ".", "data", "=", "weight", ".", "data", "*", "self", ".", "mask_dict", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.apply_mask_gradients": [[280, 288], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "core.Masking.module.named_parameters"], "methods", ["None"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "apply_mask_gradients", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Applies boolean mask to modules's gradients\n        \"\"\"", "\n", "for", "name", ",", "weight", "in", "self", ".", "module", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "name", "in", "self", ".", "mask_dict", ":", "\n", "                ", "weight", ".", "grad", "=", "weight", ".", "grad", "*", "self", ".", "mask_dict", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.avg_inference_FLOPs": [[289, 297], ["core.Masking._inference_FLOPs_collector.add_value"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.smoothen_value.AverageValue.add_value"], ["", "", "", "@", "property", "\n", "def", "avg_inference_FLOPs", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        :return: running average of inference FLOPs\n        :rtype: float\n        \"\"\"", "\n", "self", ".", "_inference_FLOPs_collector", ".", "add_value", "(", "self", ".", "inference_FLOPs", ")", "\n", "return", "self", ".", "_inference_FLOPs_collector", ".", "smooth", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.calc_redistributed_densities": [[298, 360], ["print", "len", "round", "len", "math.floor"], "methods", ["None"], ["", "def", "calc_redistributed_densities", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Computes layer-wise density\n        given a redistribution scheme.\n\n        Ensures that layer-wise densities\n        are valid (i.e. 0 <= density <= 1).\n\n        :return: Layer-wise valid densities.\n        :rtype: Dict[str, float]\n        \"\"\"", "\n", "# TODO: try clarifying the logic used", "\n", "# original source:", "\n", "# https://github.com/TimDettmers/sparse_learning/blob/f99c2f2ee1e89a786e942c73c054c11912866488/sparselearning/core.py#L454", "\n", "residual", "=", "9999", "\n", "mean_residual", "=", "0", "\n", "name2regrowth", "=", "{", "}", "\n", "i", "=", "0", "\n", "while", "residual", ">", "0", "and", "i", "<", "1000", ":", "\n", "            ", "residual", "=", "0", "\n", "for", "name", "in", "self", ".", "stats", ".", "variance_dict", ":", "\n", "                ", "num_remove", "=", "self", ".", "stats", ".", "removed_dict", "[", "name", "]", "\n", "num_zero", "=", "self", ".", "stats", ".", "zeros_dict", "[", "name", "]", "\n", "max_regrowth", "=", "num_zero", "+", "num_remove", "\n", "\n", "if", "name", "in", "name2regrowth", ":", "\n", "                    ", "regrowth", "=", "name2regrowth", "[", "name", "]", "\n", "", "else", ":", "\n", "                    ", "regrowth", "=", "round", "(", "\n", "self", ".", "stats", ".", "variance_dict", "[", "name", "]", "\n", "*", "(", "self", ".", "stats", ".", "total_removed", "+", "self", ".", "adjusted_growth", ")", "\n", ")", "\n", "", "regrowth", "+=", "mean_residual", "\n", "\n", "if", "regrowth", ">", "0.99", "*", "max_regrowth", ":", "\n", "                    ", "name2regrowth", "[", "name", "]", "=", "0.99", "*", "max_regrowth", "\n", "residual", "+=", "regrowth", "-", "name2regrowth", "[", "name", "]", "\n", "", "else", ":", "\n", "                    ", "name2regrowth", "[", "name", "]", "=", "regrowth", "\n", "", "", "if", "len", "(", "name2regrowth", ")", "==", "0", ":", "\n", "                ", "mean_residual", "=", "0", "\n", "", "else", ":", "\n", "                ", "mean_residual", "=", "residual", "/", "len", "(", "name2regrowth", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "if", "i", "==", "1000", ":", "\n", "            ", "print", "(", "\n", "f\"Error resolving the residual! Layers are too full! Residual left over: {residual}\"", "\n", ")", "\n", "\n", "", "if", "self", ".", "prune_mode", "==", "\"global_magnitude\"", ":", "\n", "            ", "for", "name", "in", "self", ".", "mask_dict", ":", "\n", "                ", "expected_removed", "=", "self", ".", "baseline_nonzero", "*", "self", ".", "name2prune_rate", "[", "name", "]", "\n", "if", "expected_removed", "==", "0.0", ":", "\n", "                    ", "name2regrowth", "[", "name", "]", "=", "0.0", "\n", "", "else", ":", "\n", "                    ", "expected_vs_actual", "=", "self", ".", "stats", ".", "total_removed", "/", "expected_removed", "\n", "name2regrowth", "[", "name", "]", "=", "math", ".", "floor", "(", "\n", "expected_vs_actual", "*", "name2regrowth", "[", "name", "]", "\n", ")", "\n", "\n", "", "", "", "return", "name2regrowth", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.dense_FLOPs": [[361, 374], ["sparselearning.counting.ops.get_inference_FLOPs", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.ops.get_inference_FLOPs"], ["", "@", "property", "\n", "def", "dense_FLOPs", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Calculates dense inference FLOPs of the model\n\n        :return: dense FLOPs\n        :rtype: int\n        \"\"\"", "\n", "if", "not", "self", ".", "_dense_FLOPs", ":", "\n", "            ", "self", ".", "_dense_FLOPs", "=", "get_inference_FLOPs", "(", "self", ",", "torch", ".", "rand", "(", "*", "self", ".", "input_size", ")", ")", "\n", "return", "self", ".", "_dense_FLOPs", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_dense_FLOPs", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.inference_FLOPs": [[375, 384], ["sparselearning.counting.ops.get_inference_FLOPs", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.ops.get_inference_FLOPs"], ["", "", "@", "property", "\n", "def", "inference_FLOPs", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Calculates dense inference FLOPs of the model\n\n        :return: inference FLOPs\n        :rtype: float\n        \"\"\"", "\n", "return", "get_inference_FLOPs", "(", "self", ",", "torch", ".", "rand", "(", "*", "self", ".", "input_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.init": [[385, 421], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "core.Masking.sparsify", "core.Masking.to_module_device_", "core.Masking.apply_mask", "core.Masking.print_nonzero_counts", "core.Masking.module.named_modules", "logging.info", "core.Masking.mask_dict.items", "logging.info", "logging.info", "logging.info", "hasattr", "weight.numel", "module.weight.numel", "getattr", "module.bias.numel"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.sparsify", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.to_module_device_", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.apply_mask", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.print_nonzero_counts"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "init", "(", "self", ",", "lottery_mask_path", ":", "\"Path\"", ")", ":", "\n", "        ", "\"\"\"\n        Sparsity initialization\n\n        :param lottery_mask_path: Mask path,\n            if using Lottery Ticket Hypothesis\n            (Frankle & Carbin 2018).\n        :type lottery_mask_path: Path\n        \"\"\"", "\n", "# Performs weight initialization", "\n", "self", ".", "sparsify", "(", "lottery_mask_path", "=", "lottery_mask_path", ")", "\n", "self", ".", "to_module_device_", "(", ")", "\n", "self", ".", "apply_mask", "(", ")", "\n", "self", ".", "print_nonzero_counts", "(", ")", "\n", "\n", "total_size", "=", "0", "\n", "for", "name", ",", "module", "in", "self", ".", "module", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "module", ",", "\"weight\"", ")", ":", "\n", "                ", "total_size", "+=", "module", ".", "weight", ".", "numel", "(", ")", "\n", "", "if", "getattr", "(", "module", ",", "\"bias\"", ",", "None", ")", "is", "not", "None", ":", "\n", "                ", "total_size", "+=", "module", ".", "bias", ".", "numel", "(", ")", "\n", "", "", "logging", ".", "info", "(", "f\"Total Model parameters: {total_size}.\"", ")", "\n", "\n", "total_size", "=", "0", "\n", "for", "name", ",", "weight", "in", "self", ".", "mask_dict", ".", "items", "(", ")", ":", "\n", "            ", "total_size", "+=", "weight", ".", "numel", "(", ")", "\n", "\n", "", "self", ".", "stats", ".", "total_nonzero", "=", "self", ".", "baseline_nonzero", "\n", "self", ".", "stats", ".", "total_zero", "=", "self", ".", "total_params", "-", "self", ".", "baseline_nonzero", "\n", "logging", ".", "info", "(", "f\"Total parameters after removed layers: {total_size}.\"", ")", "\n", "logging", ".", "info", "(", "\n", "f\"Total parameters under sparsity level of {self.density}: {self.baseline_nonzero}\"", "\n", ")", "\n", "logging", ".", "info", "(", "\n", "f\"Achieved sparsity at init (w/o BN, bias): {self.baseline_nonzero/self.total_params:.4f}\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.gather_statistics": [[423, 462], ["core.Masking.module.named_parameters", "core.LayerStats", "core.Masking.redistribution_func", "numpy.isnan"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.redistribution_func"], ["", "def", "gather_statistics", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Gather layer-wise & global stats.\n        Typically performed before each mask update.\n        \"\"\"", "\n", "variance_dict", "=", "{", "}", "\n", "nonzeros_dict", "=", "{", "}", "\n", "zeros_dict", "=", "{", "}", "\n", "\n", "total_variance", "=", "0.0", "\n", "total_nonzero", "=", "0", "\n", "total_zero", "=", "0", "\n", "for", "name", ",", "weight", "in", "self", ".", "module", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "name", "not", "in", "self", ".", "mask_dict", ":", "\n", "                ", "continue", "\n", "", "mask", "=", "self", ".", "mask_dict", "[", "name", "]", "\n", "\n", "# redistribution", "\n", "variance_dict", "[", "name", "]", "=", "self", ".", "redistribution_func", "(", "self", ",", "name", ",", "weight", ",", "mask", ")", "\n", "\n", "if", "not", "np", ".", "isnan", "(", "variance_dict", "[", "name", "]", ")", ":", "\n", "                ", "total_variance", "+=", "variance_dict", "[", "name", "]", "\n", "", "nonzeros_dict", "[", "name", "]", "=", "(", "mask", "==", "1", ")", ".", "sum", "(", ")", ".", "int", "(", ")", ".", "item", "(", ")", "\n", "zeros_dict", "[", "name", "]", "=", "(", "mask", "==", "0", ")", ".", "sum", "(", ")", ".", "int", "(", ")", ".", "item", "(", ")", "\n", "\n", "total_nonzero", "+=", "nonzeros_dict", "[", "name", "]", "\n", "total_zero", "+=", "zeros_dict", "[", "name", "]", "\n", "\n", "", "assert", "total_variance", ",", "\"Total variance is zero!\"", "\n", "for", "name", "in", "variance_dict", ":", "\n", "            ", "variance_dict", "[", "name", "]", "/=", "total_variance", "\n", "\n", "", "self", ".", "stats", "=", "LayerStats", "(", "\n", "variance_dict", "=", "variance_dict", ",", "\n", "nonzeros_dict", "=", "nonzeros_dict", ",", "\n", "zeros_dict", "=", "zeros_dict", ",", "\n", "total_variance", "=", "total_variance", ",", "\n", "total_nonzero", "=", "total_nonzero", ",", "\n", "total_zero", "=", "total_zero", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.growth_func": [[464, 467], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "growth_func", "(", "self", ")", ":", "\n", "        ", "return", "grow_registry", "[", "self", ".", "growth_mode", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.global_prune": [[468, 471], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "global_prune", "(", "self", ")", ":", "\n", "        ", "return", "\"global\"", "in", "self", ".", "prune_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.get_momentum_for_weight": [[472, 492], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt"], "methods", ["None"], ["", "def", "get_momentum_for_weight", "(", "self", ",", "weight", ":", "str", ")", "->", "\"Tensor\"", ":", "\n", "        ", "\"\"\"\n        Return momentum from optimizer (SGD or Adam)\n\n        :param weight: weight name\n        :type weight: str\n        :return: Momentum buffer for layer\n        :rtype: torch.Tensor\n        \"\"\"", "\n", "momentum", "=", "[", "]", "\n", "# Adam", "\n", "if", "\"exp_avg\"", "in", "self", ".", "optimizer", ".", "state", "[", "weight", "]", ":", "\n", "            ", "adam_m1", "=", "self", ".", "optimizer", ".", "state", "[", "weight", "]", "[", "\"exp_avg\"", "]", "\n", "adam_m2", "=", "self", ".", "optimizer", ".", "state", "[", "weight", "]", "[", "\"exp_avg_sq\"", "]", "\n", "momentum", "=", "adam_m1", "/", "(", "torch", ".", "sqrt", "(", "adam_m2", ")", "+", "1e-08", ")", "\n", "# SGD", "\n", "", "elif", "\"momentum_buffer\"", "in", "self", ".", "optimizer", ".", "state", "[", "weight", "]", ":", "\n", "            ", "momentum", "=", "self", ".", "optimizer", ".", "state", "[", "weight", "]", "[", "\"momentum_buffer\"", "]", "\n", "\n", "", "return", "momentum", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.load_state_dict": [[493, 505], ["kwargs.items", "state_dict.items", "core.Masking.stats.load_state_dict", "setattr", "core.Masking.stats.load_state_dict", "setattr"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.model_serialization.load_state_dict", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.model_serialization.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "*", "initial_data", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "state_dict", "in", "initial_data", ":", "\n", "            ", "for", "key", ",", "value", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "==", "\"stats\"", ":", "\n", "                    ", "self", ".", "stats", ".", "load_state_dict", "(", "value", ")", "\n", "", "else", ":", "\n", "                    ", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "", "", "", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "==", "\"stats\"", ":", "\n", "                ", "self", ".", "stats", ".", "load_state_dict", "(", "kwargs", "[", "key", "]", ")", "\n", "", "else", ":", "\n", "                ", "setattr", "(", "self", ",", "key", ",", "kwargs", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.print_nonzero_counts": [[506, 522], ["core.Masking.mask_dict.items", "logging.debug", "logging.debug", "float", "mask.numel"], "methods", ["None"], ["", "", "", "def", "print_nonzero_counts", "(", "self", ")", ":", "\n", "        ", "for", "name", ",", "mask", "in", "self", ".", "mask_dict", ".", "items", "(", ")", ":", "\n", "            ", "num_nonzeros", "=", "(", "mask", "!=", "0", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "if", "name", "in", "self", ".", "stats", ".", "variance_dict", ":", "\n", "                ", "log_str", "=", "(", "\n", "f\"{name}: {self.stats.nonzeros_dict[name]}->{num_nonzeros}, \"", "\n", "f\"density: {num_nonzeros / float(mask.numel()):.3f}, \"", "\n", "f\"proportion: {self.stats.variance_dict[name]:.4f}\"", "\n", ")", "\n", "\n", "", "else", ":", "\n", "                ", "log_str", "=", "f\"{name}: {num_nonzeros}\"", "\n", "", "logging", ".", "debug", "(", "log_str", ")", "\n", "\n", "", "logging", ".", "debug", "(", "f\"Prune rate: {self.prune_rate}.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.prune_func": [[523, 532], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "prune_func", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Calls prune func from the  registry.\n\n        We use @property, so that it is always\n        synced with prune_mode\n        \"\"\"", "\n", "return", "prune_registry", "[", "self", ".", "prune_mode", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.prune_rate": [[533, 539], ["core.Masking.prune_rate_decay.get_dr"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.get_dr"], ["", "@", "property", "\n", "def", "prune_rate", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Get prune rate from the decay object\n        \"\"\"", "\n", "return", "self", ".", "prune_rate_decay", ".", "get_dr", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.redistribution_func": [[540, 549], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "redistribution_func", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Calls redistribution func from the  registry.\n\n        We use @property, so that it is always\n        synced with redistribution_mode\n        \"\"\"", "\n", "return", "redistribute_registry", "[", "self", ".", "redistribution_mode", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.remove_weight": [[550, 569], ["logging.debug", "core.Masking.mask_dict.pop", "logging.debug", "core.Masking.mask_dict.pop", "logging.error", "core.Masking.mask_dict[].numel", "core.Masking.mask_dict[].numel"], "methods", ["None"], ["", "def", "remove_weight", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"\n        Remove layer by complete name\n\n        :param name: layer name\n        :type name: str\n        \"\"\"", "\n", "if", "name", "in", "self", ".", "mask_dict", ":", "\n", "            ", "logging", ".", "debug", "(", "\n", "f\"Removing {name} of size {self.mask_dict[name].shape} = {self.mask_dict[name].numel()} parameters.\"", "\n", ")", "\n", "self", ".", "mask_dict", ".", "pop", "(", "name", ")", "\n", "", "elif", "name", "+", "\".weight\"", "in", "self", ".", "mask_dict", ":", "\n", "            ", "logging", ".", "debug", "(", "\n", "f\"Removing {name} of size {self.mask_dict[name + '.weight'].shape} = {self.mask_dict[name + '.weight'].numel()} parameters.\"", "\n", ")", "\n", "self", ".", "mask_dict", ".", "pop", "(", "name", "+", "\".weight\"", ")", "\n", "", "else", ":", "\n", "            ", "logging", ".", "error", "(", "f\"ERROR {name} not found.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.remove_weight_partial_name": [[570, 587], ["list", "logging.debug", "core.Masking.mask_dict.keys", "logging.debug", "core.Masking.mask_dict.pop", "core.Masking.mask_dict[].numel"], "methods", ["None"], ["", "", "def", "remove_weight_partial_name", "(", "self", ",", "partial_name", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Remove module by partial name (eg: conv).\n\n        :param partial_name: partial layer name\n        :type partial_name: str\n        \"\"\"", "\n", "_removed", "=", "0", "\n", "for", "name", "in", "list", "(", "self", ".", "mask_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "partial_name", "in", "name", ":", "\n", "                ", "logging", ".", "debug", "(", "\n", "f\"Removing {name} of size {self.mask_dict[name].shape} with {self.mask_dict[name].numel()} parameters.\"", "\n", ")", "\n", "_removed", "+=", "1", "\n", "self", ".", "mask_dict", ".", "pop", "(", "name", ")", "\n", "\n", "", "", "logging", ".", "debug", "(", "f\"Removed {_removed} layers.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.remove_type": [[588, 598], ["core.Masking.module.named_modules", "isinstance", "core.Masking.remove_weight"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.remove_weight"], ["", "def", "remove_type", "(", "self", ",", "nn_type", ")", ":", "\n", "        ", "\"\"\"\n        Remove layer by type (eg: nn.Linear, nn.Conv2d, etc.)\n\n        :param nn_type: type of layer\n        :type nn_type: nn.Module\n        \"\"\"", "\n", "for", "name", ",", "module", "in", "self", ".", "module", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "module", ",", "nn_type", ")", ":", "\n", "                ", "self", ".", "remove_weight", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.__repr__": [[599, 627], ["enumerate", "core.Masking.mask_dict.keys", "_str_dict.items", "len"], "methods", ["None"], ["", "", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "_str_dict", "=", "{", "\n", "\"baseline_nonzero\"", ":", "self", ".", "baseline_nonzero", ",", "\n", "\"density\"", ":", "self", ".", "density", ",", "\n", "\"dense_gradients\"", ":", "self", ".", "dense_gradients", ",", "\n", "\"growth_increment\"", ":", "self", ".", "growth_increment", ",", "\n", "\"growth_mode\"", ":", "self", ".", "growth_mode", ",", "\n", "\"growth_threshold\"", ":", "self", ".", "growth_threshold", ",", "\n", "\"increment\"", ":", "self", ".", "increment", ",", "\n", "\"layer_names\"", ":", "self", ".", "mask_dict", ".", "keys", "(", ")", ",", "\n", "\"mask_step\"", ":", "self", ".", "mask_step", ",", "\n", "\"prune_mode\"", ":", "self", ".", "prune_mode", ",", "\n", "\"prune_threshold\"", ":", "self", ".", "prune_threshold", ",", "\n", "\"redistribution_mode\"", ":", "self", ".", "redistribution_mode", ",", "\n", "\"sparse_init\"", ":", "self", ".", "sparse_init", ",", "\n", "\"stats\"", ":", "self", ".", "stats", ",", "\n", "\"tolerance\"", ":", "self", ".", "tolerance", ",", "\n", "\"total_params\"", ":", "self", ".", "total_params", ",", "\n", "}", "\n", "\n", "_str", "=", "\"Masking(\"", "\n", "for", "e", ",", "(", "name", ",", "value", ")", "in", "enumerate", "(", "_str_dict", ".", "items", "(", ")", ")", ":", "\n", "            ", "if", "e", "==", "len", "(", "_str_dict", ")", "-", "1", ":", "\n", "                ", "_str", "+=", "f\"{name}={value})\"", "\n", "", "else", ":", "\n", "                ", "_str", "+=", "f\"{name}={value}, \"", "\n", "\n", "", "", "return", "_str", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.reset_momentum": [[628, 653], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "core.Masking.module.named_parameters"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "reset_momentum", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Mask momentum buffers\n        \"\"\"", "\n", "for", "name", ",", "weight", "in", "self", ".", "module", ".", "named_parameters", "(", ")", ":", "\n", "# Skip modules we aren't masking", "\n", "            ", "if", "name", "not", "in", "self", ".", "mask_dict", ":", "\n", "                ", "continue", "\n", "\n", "", "param_state", "=", "self", ".", "optimizer", ".", "state", "[", "weight", "]", "\n", "mask", "=", "self", ".", "mask_dict", "[", "name", "]", "\n", "\n", "# mask the momentum matrix", "\n", "# Adam", "\n", "if", "\"exp_avg\"", "in", "param_state", ":", "\n", "                ", "param_state", "[", "\"exp_avg\"", "]", "*=", "mask", "\n", "param_state", "[", "\"exp_avg_sq\"", "]", "*=", "mask", "\n", "\n", "# SGD", "\n", "", "elif", "(", "\n", "\"momentum_buffer\"", "in", "param_state", "\n", "and", "param_state", "[", "\"momentum_buffer\"", "]", "is", "not", "None", "\n", ")", ":", "\n", "                ", "param_state", "[", "\"momentum_buffer\"", "]", "*=", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.sparsify": [[654, 660], ["None"], "methods", ["None"], ["", "", "", "def", "sparsify", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Call sparsity init func\n        (see sparselearning/funcs/init_scheme.py)\n        \"\"\"", "\n", "init_registry", "[", "self", ".", "sparse_init", "]", "(", "self", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.state_dict": [[661, 671], ["core.Masking.stats.state_dict"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.state_dict"], ["", "def", "state_dict", "(", "self", ")", "->", "\"Dict\"", ":", "\n", "# Won't store hyperparams here", "\n", "        ", "_state_dict", "=", "{", "\n", "\"baseline_nonzero\"", ":", "self", ".", "baseline_nonzero", ",", "\n", "\"masks\"", ":", "self", ".", "mask_dict", ",", "\n", "\"stats\"", ":", "self", ".", "stats", ".", "state_dict", "(", ")", ",", "\n", "\"mask_step\"", ":", "self", ".", "mask_step", ",", "\n", "\"total_params\"", ":", "self", ".", "total_params", ",", "\n", "}", "\n", "return", "_state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.step": [[672, 693], ["core.Masking.optimizer.step", "core.Masking.apply_mask", "core.Masking.reset_momentum", "core.Masking.prune_rate_decay.step", "core.Masking.prune_rate_decay.step"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.step", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.apply_mask", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.reset_momentum", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.step", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.step"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Performs an optimizer step\n        (i.e, no update to mask topology).\n        \"\"\"", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "self", ".", "apply_mask", "(", ")", "\n", "\n", "if", "not", "self", ".", "dense_gradients", ":", "\n", "            ", "self", ".", "reset_momentum", "(", ")", "\n", "\n", "# Get updated prune rate", "\n", "", "if", "self", ".", "prune_rate_decay", ".", "mode", "==", "\"cumulative\"", ":", "\n", "            ", "current_sparsity", "=", "(", "\n", "1", "-", "self", ".", "stats", ".", "total_density", "\n", ")", "# Useful for pruning where we want a target sparsity", "\n", "self", ".", "prune_rate_decay", ".", "step", "(", "self", ".", "mask_step", ",", "current_sparsity", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "prune_rate_decay", ".", "step", "(", "self", ".", "mask_step", ")", "\n", "\n", "", "self", ".", "mask_step", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.to_module_device_": [[694, 702], ["core.Masking.module.named_parameters", "core.Masking.mask_dict[].to"], "methods", ["None"], ["", "def", "to_module_device_", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Send to module's device\n        \"\"\"", "\n", "for", "name", ",", "weight", "in", "self", ".", "module", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "name", "in", "self", ".", "mask_dict", ":", "\n", "                ", "device", "=", "weight", ".", "device", "\n", "self", ".", "mask_dict", "[", "name", "]", "=", "self", ".", "mask_dict", "[", "name", "]", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.truncate_weights": [[703, 782], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "core.Masking.gather_statistics", "core.Masking.adjust_prune_rate", "core.Masking.apply_mask", "core.Masking.adjustments.append", "core.Masking.gather_statistics", "core.Masking.prune_func", "core.Masking.module.named_parameters", "core.Masking.module.named_parameters", "core.Masking.reset_momentum", "core.Masking.apply_mask_gradients", "numpy.mean", "logging.debug", "core.Masking.prune_func", "core.Masking.calc_redistributed_densities", "core.Masking.growth_func", "core.Masking.sum().item", "core.Masking.mask_dict.pop", "core.Masking.float", "int", "core.Masking.sum().item", "core.Masking.sum", "core.Masking.sum"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.gather_statistics", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.adjust_prune_rate", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.apply_mask", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.gather_statistics", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.prune_func", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.reset_momentum", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.apply_mask_gradients", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.prune_func", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.calc_redistributed_densities", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.growth_func"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "truncate_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Perform grow / prune / redistribution step\n        \"\"\"", "\n", "self", ".", "gather_statistics", "(", ")", "\n", "self", ".", "adjust_prune_rate", "(", ")", "\n", "\n", "total_nonzero_new", "=", "0", "\n", "if", "self", ".", "global_prune", ":", "\n", "            ", "self", ".", "stats", ".", "total_removed", "=", "self", ".", "prune_func", "(", "self", ")", "\n", "", "else", ":", "\n", "            ", "for", "name", ",", "weight", "in", "self", ".", "module", ".", "named_parameters", "(", ")", ":", "\n", "# Skip modules we aren't masking", "\n", "                ", "if", "name", "not", "in", "self", ".", "mask_dict", ":", "\n", "                    ", "continue", "\n", "\n", "", "mask", "=", "self", ".", "mask_dict", "[", "name", "]", "\n", "\n", "# prune", "\n", "new_mask", "=", "self", ".", "prune_func", "(", "self", ",", "mask", ",", "weight", ",", "name", ")", "\n", "removed", "=", "self", ".", "stats", ".", "nonzeros_dict", "[", "name", "]", "-", "int", "(", "new_mask", ".", "sum", "(", ")", ".", "item", "(", ")", ")", "\n", "self", ".", "stats", ".", "total_removed", "+=", "removed", "\n", "self", ".", "stats", ".", "removed_dict", "[", "name", "]", "=", "removed", "\n", "self", ".", "mask_dict", "[", "name", "]", "=", "new_mask", "\n", "\n", "", "", "if", "self", ".", "growth_mode", "==", "\"none\"", ":", "\n", "            ", "total_nonzero_new", "=", "self", ".", "stats", ".", "total_nonzero", "-", "self", ".", "stats", ".", "total_removed", "\n", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "redistribution_mode", "not", "in", "[", "\"nonzero\"", ",", "\"none\"", "]", ":", "\n", "                ", "name2regrowth", "=", "self", ".", "calc_redistributed_densities", "(", ")", "\n", "\n", "", "for", "name", ",", "weight", "in", "self", ".", "module", ".", "named_parameters", "(", ")", ":", "\n", "# Skip modules we aren't masking", "\n", "                ", "if", "name", "not", "in", "self", ".", "mask_dict", ":", "\n", "                    ", "continue", "\n", "\n", "# growth", "\n", "", "if", "self", ".", "redistribution_mode", "not", "in", "[", "\"nonzero\"", ",", "\"none\"", "]", ":", "\n", "                    ", "num_growth", "=", "name2regrowth", "[", "name", "]", "\n", "", "else", ":", "\n", "                    ", "num_growth", "=", "self", ".", "stats", ".", "removed_dict", "[", "name", "]", "\n", "\n", "", "new_mask", "=", "self", ".", "growth_func", "(", "self", ",", "name", ",", "num_growth", ",", "weight", ")", "\n", "new_nonzero", "=", "new_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "# exchanging masks", "\n", "self", ".", "mask_dict", ".", "pop", "(", "name", ")", "\n", "self", ".", "mask_dict", "[", "name", "]", "=", "new_mask", ".", "float", "(", ")", "\n", "total_nonzero_new", "+=", "new_nonzero", "\n", "\n", "", "", "self", ".", "apply_mask", "(", ")", "\n", "\n", "if", "not", "self", ".", "dense_gradients", ":", "\n", "            ", "self", ".", "reset_momentum", "(", ")", "\n", "self", ".", "apply_mask_gradients", "(", ")", "\n", "\n", "", "self", ".", "mask_step", "+=", "1", "\n", "\n", "# Some growth techniques and redistribution are probablistic", "\n", "# we might not grow enough weights or too much weights", "\n", "# Here we run an exponential smoothing over (prune-growth) residuals to adjust future growth", "\n", "self", ".", "adjustments", ".", "append", "(", "\n", "self", ".", "baseline_nonzero", "-", "total_nonzero_new", "\n", ")", "# will be zero if deterministic", "\n", "self", ".", "adjusted_growth", "=", "(", "\n", "0.25", "*", "self", ".", "adjusted_growth", "\n", "+", "(", "0.75", "*", "self", ".", "adjustments", "[", "-", "1", "]", ")", "\n", "+", "np", ".", "mean", "(", "self", ".", "adjustments", ")", "\n", ")", "\n", "if", "self", ".", "stats", ".", "total_nonzero", ">", "0", ":", "\n", "            ", "logging", ".", "debug", "(", "\n", "f\"Nonzero before/after: {self.stats.total_nonzero}/{total_nonzero_new}. \"", "\n", "f\"Growth adjustment: {self.adjusted_growth:.2f}.\"", "\n", ")", "\n", "\n", "# Update stats", "\n", "", "self", ".", "gather_statistics", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.update_connections": [[783, 792], ["core.Masking.truncate_weights", "logging.getLogger().getEffectiveLevel", "core.Masking.print_nonzero_counts", "logging.getLogger"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.truncate_weights", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.print_nonzero_counts"], ["", "def", "update_connections", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Performs a mask update\n        (i.e, update to mask topology).\n        \"\"\"", "\n", "self", ".", "truncate_weights", "(", ")", "\n", "if", "logging", ".", "getLogger", "(", ")", ".", "getEffectiveLevel", "(", ")", "==", "logging", ".", "DEBUG", ":", "\n", "# debug logged", "\n", "            ", "self", ".", "print_nonzero_counts", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.smoothen_value.SmoothenValue.__post_init__": [[13, 15], ["None"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_mov_avg", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.smoothen_value.SmoothenValue.add_value": [[16, 26], ["None"], "methods", ["None"], ["", "def", "add_value", "(", "self", ",", "val", ":", "float", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Add `val` to calculate updated smoothed value.\n\n        :param val: value to add\n        :type val: float\n        \"\"\"", "\n", "self", ".", "n", "+=", "1", "\n", "self", ".", "_mov_avg", "=", "self", ".", "beta", "*", "self", ".", "_mov_avg", "+", "(", "1", "-", "self", ".", "beta", ")", "*", "val", "\n", "self", ".", "smooth", "=", "self", ".", "_mov_avg", "/", "(", "1", "-", "self", ".", "beta", "**", "self", ".", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.smoothen_value.AverageValue.__post_init__": [[35, 37], ["None"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_mov_avg", "=", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.smoothen_value.AverageValue.add_value": [[38, 48], ["None"], "methods", ["None"], ["", "def", "add_value", "(", "self", ",", "val", ":", "float", ")", ":", "\n", "        ", "\"\"\"\n        Add `val` to calculate updated smoothed value.\n\n        :param val: value to add\n        :type val: float\n        \"\"\"", "\n", "self", ".", "_mov_avg", "=", "(", "val", "+", "self", ".", "n", "*", "self", ".", "_mov_avg", ")", "/", "(", "self", ".", "n", "+", "1", ")", "\n", "self", ".", "smooth", "=", "self", ".", "_mov_avg", "\n", "self", ".", "n", "+=", "1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.model_serialization.align_and_update_state_dicts": [[15, 62], ["sorted", "sorted", "torch.as_tensor().view", "torch.as_tensor().view.max", "logging.getLogger", "enumerate", "list", "list", "len", "len", "max", "max", "idxs.tolist", "logging.getLogger.debug", "model_state_dict.keys", "loaded_state_dict.keys", "i.endswith", "len", "torch.as_tensor", "log_str_template.format", "len", "len", "tuple"], "function", ["None"], ["def", "align_and_update_state_dicts", "(", "model_state_dict", ",", "loaded_state_dict", ")", ":", "\n", "    ", "\"\"\"\n    Strategy: suppose that the models that we will create will have prefixes appended\n    to each of its keys, for example due to an extra level of nesting that the original\n    pre-trained weights from ImageNet won't contain. For example, model.state_dict()\n    might return backbone[0].body.res2.conv1.weight, while the pre-trained model contains\n    res2.conv1.weight. We thus want to match both parameters together.\n    For that, we look for each model weight, look among all loaded keys if there is one\n    that is a suffix of the current weight name, and use it if that's the case.\n    If multiple matches exist, take the one with longest size\n    of the corresponding name. For example, for the same model as before, the pretrained\n    weight file can contain both res2.conv1.weight, as well as conv1.weight. In this case,\n    we want to match backbone[0].body.conv1.weight to conv1.weight, and\n    backbone[0].body.res2.conv1.weight to res2.conv1.weight.\n    \"\"\"", "\n", "current_keys", "=", "sorted", "(", "list", "(", "model_state_dict", ".", "keys", "(", ")", ")", ")", "\n", "loaded_keys", "=", "sorted", "(", "list", "(", "loaded_state_dict", ".", "keys", "(", ")", ")", ")", "\n", "# get a matrix of string matches, where each (i, j) entry correspond to the size of the", "\n", "# loaded_key string, if it matches", "\n", "match_matrix", "=", "[", "\n", "len", "(", "j", ")", "if", "i", ".", "endswith", "(", "j", ")", "else", "0", "for", "i", "in", "current_keys", "for", "j", "in", "loaded_keys", "\n", "]", "\n", "match_matrix", "=", "torch", ".", "as_tensor", "(", "match_matrix", ")", ".", "view", "(", "\n", "len", "(", "current_keys", ")", ",", "len", "(", "loaded_keys", ")", "\n", ")", "\n", "max_match_size", ",", "idxs", "=", "match_matrix", ".", "max", "(", "1", ")", "\n", "# remove indices that correspond to no-match", "\n", "idxs", "[", "max_match_size", "==", "0", "]", "=", "-", "1", "\n", "\n", "# used for logging", "\n", "max_size", "=", "max", "(", "[", "len", "(", "key", ")", "for", "key", "in", "current_keys", "]", ")", "if", "current_keys", "else", "1", "\n", "max_size_loaded", "=", "max", "(", "[", "len", "(", "key", ")", "for", "key", "in", "loaded_keys", "]", ")", "if", "loaded_keys", "else", "1", "\n", "log_str_template", "=", "\"{: <{}} loaded from {: <{}} of shape {}\"", "\n", "logger", "=", "logging", ".", "getLogger", "(", "__name__", ")", "\n", "for", "idx_new", ",", "idx_old", "in", "enumerate", "(", "idxs", ".", "tolist", "(", ")", ")", ":", "\n", "        ", "if", "idx_old", "==", "-", "1", ":", "\n", "            ", "continue", "\n", "", "key", "=", "current_keys", "[", "idx_new", "]", "\n", "key_old", "=", "loaded_keys", "[", "idx_old", "]", "\n", "model_state_dict", "[", "key", "]", "=", "loaded_state_dict", "[", "key_old", "]", "\n", "logger", ".", "debug", "(", "\n", "log_str_template", ".", "format", "(", "\n", "key", ",", "\n", "max_size", ",", "\n", "key_old", ",", "\n", "max_size_loaded", ",", "\n", "tuple", "(", "loaded_state_dict", "[", "key_old", "]", ".", "shape", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.model_serialization.strip_prefix_if_present": [[66, 74], ["sorted", "collections.OrderedDict", "state_dict.items", "state_dict.keys", "all", "key.startswith", "key.replace"], "function", ["None"], ["", "", "def", "strip_prefix_if_present", "(", "state_dict", ",", "prefix", ")", ":", "\n", "    ", "keys", "=", "sorted", "(", "state_dict", ".", "keys", "(", ")", ")", "\n", "if", "not", "all", "(", "key", ".", "startswith", "(", "prefix", ")", "for", "key", "in", "keys", ")", ":", "\n", "        ", "return", "state_dict", "\n", "", "stripped_state_dict", "=", "OrderedDict", "(", ")", "\n", "for", "key", ",", "value", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "        ", "stripped_state_dict", "[", "key", ".", "replace", "(", "prefix", ",", "\"\"", ")", "]", "=", "value", "\n", "", "return", "stripped_state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.model_serialization.load_state_dict": [[76, 86], ["model.state_dict", "model_serialization.strip_prefix_if_present", "model_serialization.align_and_update_state_dicts", "model.load_state_dict"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.state_dict", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.model_serialization.strip_prefix_if_present", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.model_serialization.align_and_update_state_dicts", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.model_serialization.load_state_dict"], ["", "def", "load_state_dict", "(", "model", ",", "loaded_state_dict", ")", ":", "\n", "    ", "model_state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "# if the state_dict comes from a model that was wrapped in a", "\n", "# DataParallel or DistributedDataParallel during serialization,", "\n", "# remove the \"module\" prefix before performing the matching", "\n", "loaded_state_dict", "=", "strip_prefix_if_present", "(", "loaded_state_dict", ",", "prefix", "=", "\"module.\"", ")", "\n", "align_and_update_state_dicts", "(", "model_state_dict", ",", "loaded_state_dict", ")", "\n", "\n", "# use strict loading", "\n", "model", ".", "load_state_dict", "(", "model_state_dict", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density._get_density_ll": [[14, 20], ["numpy.array", "numpy.array", "list", "list", "masking.stats.nonzeros_dict.values", "masking.stats.zeros_dict.values"], "function", ["None"], ["", "def", "_get_density_ll", "(", "masking", ":", "\"Masking\"", ")", "->", "\"List[float]\"", ":", "\n", "    ", "non_zero_ll", "=", "np", ".", "array", "(", "list", "(", "masking", ".", "stats", ".", "nonzeros_dict", ".", "values", "(", ")", ")", ")", "\n", "zero_ll", "=", "np", ".", "array", "(", "list", "(", "masking", ".", "stats", ".", "zeros_dict", ".", "values", "(", ")", ")", ")", "\n", "density_ll", "=", "non_zero_ll", "/", "(", "non_zero_ll", "+", "zero_ll", ")", "\n", "\n", "return", "density_ll", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density.plot": [[21, 48], ["layer_wise_density._get_density_ll", "mplot.clf", "mplot.bar", "mplot.ylabel", "mplot.xlabel", "numpy.arange", "len"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density._get_density_ll"], ["", "def", "plot", "(", "masking", ":", "\"Masking\"", ",", "mplot", ":", "plt", ")", "->", "plt", ":", "\n", "    ", "\"\"\"\n    Plot layer wise density bar plot.\n\n    :param masking: Masking instance\n    :type masking: sparselearning.core.Masking\n    :param mplot: matplotlib object\n    :type mplot: pyplot\n    :return: matplotlib plot\n    :rtype: pyplot\n    \"\"\"", "\n", "\n", "density_ll", "=", "_get_density_ll", "(", "masking", ")", "\n", "bin_ll", "=", "np", ".", "arange", "(", "len", "(", "density_ll", ")", ")", "+", "1", "\n", "width", "=", "0.8", "\n", "\n", "mplot", ".", "clf", "(", ")", "\n", "mplot", ".", "bar", "(", "bin_ll", ",", "density_ll", ",", "width", ",", "color", "=", "\"b\"", ")", "\n", "\n", "# Gets too crowded when including layer names", "\n", "# layer_name_ll = list(masking.masks.keys())", "\n", "# plt.xticks(bin_ll, layer_name_ll)", "\n", "\n", "mplot", ".", "ylabel", "(", "\"Density\"", ")", "\n", "mplot", ".", "xlabel", "(", "\"Layer Number\"", ")", "\n", "\n", "return", "mplot", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density.wandb_bar": [[50, 65], ["layer_wise_density._get_density_ll", "list", "wandb.Table", "wandb.plot.bar", "masking.stats.nonzeros_dict.keys", "zip"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density._get_density_ll"], ["", "def", "wandb_bar", "(", "masking", ":", "\"Masking\"", ")", "->", "wandb", ".", "plot", ".", "bar", ":", "\n", "    ", "\"\"\"\n    Plot layer wise density as W&B bar plot.\n\n    :param masking: Masking instance\n    :type masking: sparselearning.core.Masking\n    :return: W&B bar plot\n    :rtype: wandb.plot.bar\n    \"\"\"", "\n", "density_ll", "=", "_get_density_ll", "(", "masking", ")", "\n", "label_ll", "=", "list", "(", "masking", ".", "stats", ".", "nonzeros_dict", ".", "keys", "(", ")", ")", "\n", "\n", "data", "=", "[", "[", "label", ",", "density", "]", "for", "(", "label", ",", "density", ")", "in", "zip", "(", "label_ll", ",", "density_ll", ")", "]", "\n", "table", "=", "wandb", ".", "Table", "(", "data", "=", "data", ",", "columns", "=", "[", "\"layer name\"", ",", "\"density\"", "]", ")", "\n", "return", "wandb", ".", "plot", ".", "bar", "(", "table", ",", "\"layer name\"", ",", "\"density\"", ",", "title", "=", "\"Layer-wise Density\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density.plot_as_image": [[67, 98], ["matplotlib.figure.Figure", "matplotlib.backends.backend_agg.FigureCanvasAgg", "matplotlib.figure.Figure.gca", "layer_wise_density._get_density_ll", "fig.gca.bar", "fig.gca.set_ylabel", "fig.gca.set_xlabel", "matplotlib.backends.backend_agg.FigureCanvasAgg.draw", "numpy.fromstring().reshape", "numpy.arange", "matplotlib.figure.Figure.get_size_inches", "matplotlib.figure.Figure.get_dpi", "int", "int", "len", "numpy.fromstring", "matplotlib.backends.backend_agg.FigureCanvasAgg.tostring_rgb"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density._get_density_ll"], ["", "def", "plot_as_image", "(", "masking", ":", "\"Masking\"", ")", "->", "\"Array\"", ":", "\n", "    ", "\"\"\"\n    Plot layer wise density as bar plot figure.\n\n    :param masking: Masking instance\n    :type masking: sparselearning.core.Masking\n    :return: Numpy array representing figure (H, W, 3)\n    :rtype: np.ndarray\n    \"\"\"", "\n", "fig", "=", "Figure", "(", ")", "\n", "canvas", "=", "FigureCanvas", "(", "fig", ")", "\n", "ax", "=", "fig", ".", "gca", "(", ")", "\n", "\n", "density_ll", "=", "_get_density_ll", "(", "masking", ")", "\n", "bin_ll", "=", "np", ".", "arange", "(", "len", "(", "density_ll", ")", ")", "+", "1", "\n", "width", "=", "0.8", "\n", "\n", "ax", ".", "bar", "(", "bin_ll", ",", "density_ll", ",", "width", ",", "color", "=", "\"b\"", ")", "\n", "\n", "ax", ".", "set_ylabel", "(", "\"Density\"", ")", "\n", "ax", ".", "set_xlabel", "(", "\"Layer Number\"", ")", "\n", "\n", "canvas", ".", "draw", "(", ")", "# draw the canvas, cache the renderer", "\n", "\n", "width", ",", "height", "=", "fig", ".", "get_size_inches", "(", ")", "*", "fig", ".", "get_dpi", "(", ")", "\n", "width", ",", "height", "=", "int", "(", "width", ")", ",", "int", "(", "height", ")", "\n", "image", "=", "np", ".", "fromstring", "(", "canvas", ".", "tostring_rgb", "(", ")", ",", "dtype", "=", "\"uint8\"", ")", ".", "reshape", "(", "\n", "height", ",", "width", ",", "3", "\n", ")", "\n", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.ops.random_perm": [[4, 15], ["torch.randperm", "[].reshape", "a.nelement", "a.reshape"], "function", ["None"], ["def", "random_perm", "(", "a", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Random shuffle a tensor.\n\n    :param a: input Tensor\n    :type a: torch.Tensor\n    :return: shuffled Tensor\n    :rtype: torch.Tensor\n    \"\"\"", "\n", "idx", "=", "torch", ".", "randperm", "(", "a", ".", "nelement", "(", ")", ")", "\n", "return", "a", ".", "reshape", "(", "-", "1", ")", "[", "idx", "]", ".", "reshape", "(", "a", ".", "shape", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.accuracy_helper.get_topk_accuracy": [[13, 46], ["torch.no_grad", "max", "output.topk", "pred.t.t", "pred.t.eq", "target.reshape().expand_as", "correct[].reshape().float().sum", "res.append", "target.reshape", "correct[].reshape().float", "correct[].reshape"], "function", ["None"], ["", "def", "get_topk_accuracy", "(", "\n", "output", ":", "\"Tensor\"", ",", "target", ":", "\"Tensor\"", ",", "topk", ":", "\"Tuple\"", "=", "(", "1", ",", ")", "\n", ")", "->", "\"List[float]\"", ":", "\n", "    ", "\"\"\"\n    Computes the accuracy over the k top predictions for the specified values of k.\n\n    :param output: predicted labels\n    :type output: torch.Tensor\n    :param target: groundtruth labels\n    :type target: torch.Tensor\n    :param topk: k for which top-k should be evaluted\n    :type topk: Tuple[int]\n    :return: Top-k accuracies for each value of k supplied\n    :rtype: List[int]\n    \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "shape", "[", "0", "]", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "\n", "k", "=", "maxk", ",", "\n", "dim", "=", "1", ",", "\n", "largest", "=", "True", ",", "\n", "sorted", "=", "True", ",", "\n", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "reshape", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "            ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "reshape", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "res", ".", "append", "(", "correct_k", "/", "batch_size", ")", "\n", "", "return", "res", "\n", "", "", ""]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.tqdm_logging.TqdmLoggingHandler.emit": [[10, 19], ["tqdm_logging.TqdmLoggingHandler.format", "tqdm.tqdm.tqdm.write", "tqdm_logging.TqdmLoggingHandler.flush", "tqdm_logging.TqdmLoggingHandler.handleError"], "methods", ["None"], ["def", "emit", "(", "self", ",", "record", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "msg", "=", "self", ".", "format", "(", "record", ")", "\n", "tqdm", ".", "write", "(", "msg", ")", "\n", "self", ".", "flush", "(", ")", "\n", "", "except", "(", "KeyboardInterrupt", ",", "SystemExit", ")", ":", "\n", "            ", "raise", "\n", "", "except", ":", "\n", "            ", "self", ".", "handleError", "(", "record", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.train_helper.get_optimizer": [[16, 60], ["torch.optim.lr_scheduler.StepLR", "kwargs.get", "torch.optim.SGD", "sparselearning.utils.warmup_scheduler.WarmUpLR", "logging.info", "train_helper._add_weight_decay", "model.parameters", "torch.optim.Adam", "Exception", "model.parameters"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.train_helper._add_weight_decay"], ["", "def", "get_optimizer", "(", "model", ":", "\"nn.Module\"", ",", "**", "kwargs", ")", "->", "\"Tuple[optim, Tuple[lr_scheduler]]\"", ":", "\n", "    ", "\"\"\"\n    Get model optimizer\n\n    :param model: Pytorch model\n    :type model: nn.Module\n    :return: Optimizer, LR Scheduler(s)\n    :rtype: Tuple[optim, Tuple[lr_scheduler]]\n    \"\"\"", "\n", "name", "=", "kwargs", "[", "\"name\"", "]", "\n", "lr", "=", "kwargs", "[", "\"lr\"", "]", "\n", "weight_decay", "=", "kwargs", "[", "\"weight_decay\"", "]", "\n", "decay_frequency", "=", "kwargs", "[", "\"decay_frequency\"", "]", "\n", "decay_factor", "=", "kwargs", "[", "\"decay_factor\"", "]", "\n", "\n", "if", "name", "==", "\"SGD\"", ":", "\n", "# Pytorch weight decay erroneously includes", "\n", "# biases and batchnorms", "\n", "        ", "if", "weight_decay", ":", "\n", "            ", "logging", ".", "info", "(", "\"Excluding bias and batchnorm layers from weight decay.\"", ")", "\n", "parameters", "=", "_add_weight_decay", "(", "model", ",", "weight_decay", ")", "\n", "weight_decay", "=", "0", "\n", "", "else", ":", "\n", "            ", "parameters", "=", "model", ".", "parameters", "(", ")", "\n", "", "optimizer", "=", "optim", ".", "SGD", "(", "\n", "parameters", ",", "\n", "lr", "=", "lr", ",", "\n", "momentum", "=", "kwargs", "[", "\"momentum\"", "]", ",", "\n", "weight_decay", "=", "weight_decay", ",", "\n", "nesterov", "=", "kwargs", "[", "\"use_nesterov\"", "]", ",", "\n", ")", "\n", "", "elif", "name", "==", "\"Adam\"", ":", "\n", "        ", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "weight_decay", "=", "weight_decay", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Unknown optimizer.\"", ")", "\n", "\n", "", "lr_scheduler", "=", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "\n", "optimizer", ",", "decay_frequency", ",", "gamma", "=", "decay_factor", "\n", ")", "\n", "\n", "warmup_steps", "=", "kwargs", ".", "get", "(", "\"warmup_steps\"", ",", "0", ")", "\n", "warmup_scheduler", "=", "WarmUpLR", "(", "optimizer", ",", "warmup_steps", ")", "if", "warmup_steps", "else", "None", "\n", "\n", "return", "optimizer", ",", "(", "lr_scheduler", ",", "warmup_scheduler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.train_helper._add_weight_decay": [[62, 88], ["model.named_parameters", "no_decay.append", "decay.append", "len"], "function", ["None"], ["", "def", "_add_weight_decay", "(", "model", ",", "weight_decay", "=", "1e-5", ",", "skip_list", "=", "(", ")", ")", "->", "\"Tuple[Dict[str, float],Dict[str, float]]\"", ":", "\n", "    ", "\"\"\"\n    Excludes batchnorm and bias from weight decay\n\n    :param model: Pytorch model\n    :type model: nn.Module\n    :param weight_decay: L2 Weight decay to use\n    :type weight_decay: float\n    :param skip_list: names of layers to skip\n    :type skip_list: Tuple[str]\n    :return: Two dictionaries, with layers to apply weight decay to.\n    :rtype: Tuple[Dict[str, float],Dict[str, float]]\n    \"\"\"", "\n", "decay", "=", "[", "]", "\n", "no_decay", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "not", "param", ".", "requires_grad", ":", "\n", "            ", "continue", "\n", "# Bias, BN have shape 1", "\n", "", "if", "len", "(", "param", ".", "shape", ")", "==", "1", "or", "name", "in", "skip_list", ":", "\n", "            ", "no_decay", ".", "append", "(", "param", ")", "\n", "", "else", ":", "\n", "            ", "decay", ".", "append", "(", "param", ")", "\n", "", "", "return", "(", "\n", "{", "\"params\"", ":", "no_decay", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "{", "\"params\"", ":", "decay", ",", "\"weight_decay\"", ":", "weight_decay", "}", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.train_helper.save_weights": [[91, 141], ["logging.info", "torch.save", "model.state_dict", "optimizer.state_dict", "mask.state_dict", "pathlib.Path", "torch.save", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.state_dict", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.state_dict", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.state_dict"], ["", "def", "save_weights", "(", "\n", "model", ":", "\"nn.Module\"", ",", "\n", "optimizer", ":", "\"optim\"", ",", "\n", "mask", ":", "\"Masking\"", ",", "\n", "val_loss", ":", "float", ",", "\n", "step", ":", "int", ",", "\n", "epoch", ":", "int", ",", "\n", "ckpt_dir", ":", "str", ",", "\n", "is_min", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Save progress.\n\n    :param model: Pytorch model\n    :type model: nn.Module\n    :param optimizer: model optimizer\n    :type optimizer: torch.optim.Optimizer\n    :param mask: Masking instance\n    :type mask: sparselearning.core.Masking\n    :param val_loss: Current validation loss\n    :type val_loss: float\n    :param step: Current step\n    :type step: int\n    :param epoch: Current epoch\n    :type epoch: int\n    :param ckpt_dir: Checkpoint directory\n    :type ckpt_dir: Path\n    :param is_min: Whether current model achieves least val loss\n    :type is_min: bool\n    \"\"\"", "\n", "logging", ".", "info", "(", "f\"Epoch {epoch} saving weights\"", ")", "\n", "\n", "state_dict", "=", "{", "\n", "\"step\"", ":", "step", ",", "\n", "\"epoch\"", ":", "epoch", ",", "\n", "\"model\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"val_loss\"", ":", "val_loss", ",", "\n", "}", "\n", "\n", "if", "mask", ":", "\n", "        ", "state_dict", "[", "\"mask\"", "]", "=", "mask", ".", "state_dict", "(", ")", "\n", "\n", "", "model_path", "=", "Path", "(", "ckpt_dir", ")", "/", "f\"epoch_{epoch}.pth\"", "\n", "\n", "torch", ".", "save", "(", "state_dict", ",", "model_path", ")", "\n", "\n", "if", "is_min", ":", "\n", "        ", "model_path", "=", "Path", "(", "ckpt_dir", ")", "/", "\"best_model.pth\"", "\n", "torch", ".", "save", "(", "state_dict", ",", "model_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.train_helper.load_weights": [[143, 214], ["pathlib.Path", "pathlib.Path.mkdir", "list", "max", "logging.info", "torch.load", "sparselearning.utils.model_serialization.load_state_dict", "torch.load.get", "torch.load.get", "torch.load.get", "logging.info", "logging.info", "pathlib.Path.glob", "logging.info", "list", "mask.load_state_dict", "mask.to_module_device_", "torch.load", "torch.load.get", "logging.info", "int", "pathlib.Path.glob", "torch.device", "torch.device", "pathlib.Path.resolve", "re.findall", "torch.load.get"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.model_serialization.load_state_dict", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.model_serialization.load_state_dict", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.to_module_device_"], ["", "", "def", "load_weights", "(", "\n", "model", ":", "\"nn.Module\"", ",", "\n", "optimizer", ":", "\"optim\"", ",", "\n", "mask", ":", "\"Masking\"", ",", "\n", "ckpt_dir", ":", "str", ",", "\n", "resume", ":", "bool", "=", "True", ",", "\n", ")", "->", "\"Tuple[nn.Module, optim, Masking, int, int, float]\"", ":", "\n", "    ", "\"\"\"\n    Load model, optimizers, mask from a checkpoint file (.pth).\n\n    :param model: Pytorch model\n    :type model: nn.Module\n    :param optimizer: model optimizer\n    :type optimizer: torch.optim.Optimizer\n    :param mask: Masking instance\n    :type mask: sparselearning.core.Masking\n    :param ckpt_dir: Checkpoint directory\n    :type ckpt_dir: Path\n    :param resume: resume or not, if not do nothing\n    :type resume: bool\n    :return: model, optimizer, mask, step, epoch, best_val_loss\n    :rtype: Tuple[nn.Module, optim, Masking, int, int, float]\n    \"\"\"", "\n", "# Defaults", "\n", "step", "=", "0", "\n", "epoch", "=", "0", "\n", "best_val_loss", "=", "1e6", "\n", "\n", "if", "not", "resume", ":", "\n", "        ", "logging", ".", "info", "(", "f\"Not resuming, training from scratch.\"", ")", "\n", "return", "model", ",", "optimizer", ",", "mask", ",", "step", ",", "epoch", ",", "best_val_loss", "\n", "\n", "", "ckpt_dir", "=", "Path", "(", "ckpt_dir", ")", "\n", "ckpt_dir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "pth_files", "=", "list", "(", "ckpt_dir", ".", "glob", "(", "\"epoch_*.pth\"", ")", ")", "\n", "\n", "if", "not", "pth_files", ":", "\n", "        ", "logging", ".", "info", "(", "f\"No checkpoint found at {ckpt_dir.resolve()}.\"", ")", "\n", "return", "model", ",", "optimizer", ",", "mask", ",", "step", ",", "epoch", ",", "best_val_loss", "\n", "\n", "# Extract latest epoch", "\n", "", "latest_epoch", "=", "max", "(", "[", "int", "(", "re", ".", "findall", "(", "\"\\d+\"", ",", "file", ".", "name", ")", "[", "-", "1", "]", ")", "for", "file", "in", "pth_files", "]", ")", "\n", "\n", "# Extract latest model", "\n", "model_path", "=", "list", "(", "ckpt_dir", ".", "glob", "(", "f\"*_{latest_epoch}.pth\"", ")", ")", "[", "0", "]", "\n", "\n", "logging", ".", "info", "(", "f\"Loading checkpoint from {model_path}.\"", ")", "\n", "\n", "ckpt", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "load_state_dict", "(", "model", ",", "ckpt", "[", "\"model\"", "]", ")", "\n", "\n", "if", "mask", "and", "\"mask\"", "in", "ckpt", ":", "\n", "        ", "mask", ".", "load_state_dict", "(", "ckpt", "[", "\"mask\"", "]", ")", "\n", "mask", ".", "to_module_device_", "(", ")", "\n", "\n", "", "epoch", "=", "ckpt", ".", "get", "(", "\"epoch\"", ",", "0", ")", "\n", "step", "=", "ckpt", ".", "get", "(", "\"step\"", ",", "0", ")", "\n", "val_loss", "=", "ckpt", ".", "get", "(", "\"val_loss\"", ",", "\"not stored\"", ")", "\n", "\n", "logging", ".", "info", "(", "f\"Model has val loss of {val_loss}.\"", ")", "\n", "\n", "# Extract best loss", "\n", "best_model_path", "=", "ckpt_dir", "/", "\"best_model.pth\"", "\n", "if", "best_model_path", ":", "\n", "        ", "ckpt", "=", "torch", ".", "load", "(", "model_path", ",", "map_location", "=", "torch", ".", "device", "(", "\"cpu\"", ")", ")", "\n", "best_val_loss", "=", "ckpt", ".", "get", "(", "\"val_loss\"", ",", "\"not stored\"", ")", "\n", "logging", ".", "info", "(", "\n", "f\"Best model has val loss of {best_val_loss} at epoch {ckpt.get('epoch',1)-1}.\"", "\n", ")", "\n", "\n", "", "return", "model", ",", "optimizer", ",", "mask", ",", "step", ",", "epoch", ",", "best_val_loss", "\n", "", ""]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.warmup_scheduler.WarmUpLR.__init__": [[21, 24], ["torch.optim.lr_scheduler._LRScheduler.__init__"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.LinearDecay.__init__"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "total_iters", ":", "int", ",", "last_epoch", ":", "int", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "total_iters", "=", "total_iters", "\n", "super", "(", ")", ".", "__init__", "(", "optimizer", ",", "last_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.warmup_scheduler.WarmUpLR.get_lr": [[25, 33], ["None"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        We will use the first m batches, and set the learning\n        rate to base_lr * m / total_iters\n        \"\"\"", "\n", "return", "[", "\n", "base_lr", "*", "self", ".", "last_epoch", "/", "(", "self", ".", "total_iters", "+", "1e-8", ")", "\n", "for", "base_lr", "in", "self", ".", "base_lrs", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.MicroNetCounter.__init__": [[322, 328], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "all_ops", ",", "add_bits_base", "=", "32", ",", "mul_bits_base", "=", "32", ")", ":", "\n", "        ", "self", ".", "all_ops", "=", "all_ops", "\n", "# Full precision add is counted one.", "\n", "self", ".", "add_bits_base", "=", "add_bits_base", "\n", "# Full precision multiply is counted one.", "\n", "self", ".", "mul_bits_base", "=", "mul_bits_base", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.MicroNetCounter._aggregate_list": [[329, 331], ["numpy.array().sum", "numpy.array"], "methods", ["None"], ["", "def", "_aggregate_list", "(", "self", ",", "counts", ")", ":", "\n", "        ", "return", "np", ".", "array", "(", "counts", ")", ".", "sum", "(", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.MicroNetCounter.process_counts": [[332, 338], ["int"], "methods", ["None"], ["", "def", "process_counts", "(", "self", ",", "total_params", ",", "total_mults", ",", "total_adds", ",", "mul_bits", ",", "add_bits", ")", ":", "\n", "# converting to Mbytes.", "\n", "        ", "total_params", "=", "int", "(", "total_params", ")", "/", "8.0", "/", "1e6", "\n", "total_mults", "=", "total_mults", "*", "mul_bits", "/", "self", ".", "mul_bits_base", "/", "1e6", "\n", "total_adds", "=", "total_adds", "*", "add_bits", "/", "self", ".", "add_bits_base", "/", "1e6", "\n", "return", "total_params", ",", "total_mults", ",", "total_adds", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.MicroNetCounter._print_header": [[339, 353], ["micronet_challenge.MicroNetCounter._header_str.format", "print", "print"], "methods", ["None"], ["", "def", "_print_header", "(", "self", ")", ":", "\n", "        ", "output_string", "=", "self", ".", "_header_str", ".", "format", "(", "\n", "\"op_name\"", ",", "\n", "\"inp_size\"", ",", "\n", "\"kernel_size\"", ",", "\n", "\"in channels\"", ",", "\n", "\"out channels\"", ",", "\n", "\"params(MBytes)\"", ",", "\n", "\"mults(M)\"", ",", "\n", "\"adds(M)\"", ",", "\n", "\"MFLOPS\"", ",", "\n", ")", "\n", "print", "(", "output_string", ")", "\n", "print", "(", "\"\"", ".", "join", "(", "[", "\"=\"", "]", "*", "125", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.MicroNetCounter._print_line": [[354, 386], ["micronet_challenge.MicroNetCounter.process_counts", "base_str.format", "print"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.MicroNetCounter.process_counts"], ["", "def", "_print_line", "(", "\n", "self", ",", "\n", "name", ",", "\n", "input_size", ",", "\n", "kernel_size", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "param_count", ",", "\n", "flop_mults", ",", "\n", "flop_adds", ",", "\n", "mul_bits", ",", "\n", "add_bits", ",", "\n", "base_str", "=", "None", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Prints a single line of operation counts.\"\"\"", "\n", "op_pc", ",", "op_mu", ",", "op_ad", "=", "self", ".", "process_counts", "(", "\n", "param_count", ",", "flop_mults", ",", "flop_adds", ",", "mul_bits", ",", "add_bits", "\n", ")", "\n", "if", "base_str", "is", "None", ":", "\n", "            ", "base_str", "=", "self", ".", "_line_str", "\n", "", "output_string", "=", "base_str", ".", "format", "(", "\n", "name", ",", "\n", "input_size", ",", "\n", "kernel_size", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "op_pc", ",", "\n", "op_mu", ",", "\n", "op_ad", ",", "\n", "op_mu", "+", "op_ad", ",", "\n", ")", "\n", "print", "(", "output_string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.MicroNetCounter.print_summary": [[387, 480], ["micronet_challenge.MicroNetCounter._print_header", "micronet_challenge.MicroNetCounter._print_line", "op_name.startswith", "micronet_challenge.MicroNetCounter._print_line", "micronet_challenge.MicroNetCounter._aggregate_list", "micronet_challenge.get_info", "micronet_challenge.count_ops", "micronet_challenge.get_info", "micronet_challenge.count_ops", "micronet_challenge.get_info", "micronet_challenge.MicroNetCounter._print_line", "micronet_challenge.count_ops"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.MicroNetCounter._print_header", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.MicroNetCounter._print_line", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.MicroNetCounter._print_line", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.MicroNetCounter._aggregate_list", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.get_info", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.count_ops", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.get_info", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.count_ops", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.get_info", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.MicroNetCounter._print_line", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.count_ops"], ["", "def", "print_summary", "(", "\n", "self", ",", "sparsity", ",", "param_bits", ",", "add_bits", ",", "mul_bits", ",", "summarize_blocks", "=", "True", "\n", ")", ":", "\n", "        ", "\"\"\"Prints all operations with given options.\n\n    Args:\n      sparsity: float, between 0,1 defines how sparse each parametric layer is.\n      param_bits: int, bits in which parameters are stored.\n      add_bits: float, number of bits used for accumulator.\n      mul_bits: float, number of bits inputs represented for multiplication.\n      summarize_blocks: bool, if True counts within a block are aggregated and\n        reported in a single line.\n\n    \"\"\"", "\n", "self", ".", "_print_header", "(", ")", "\n", "# Let's count starting from zero.", "\n", "total_params", ",", "total_mults", ",", "total_adds", "=", "[", "0", "]", "*", "3", "\n", "for", "op_name", ",", "op_template", "in", "self", ".", "all_ops", ":", "\n", "            ", "if", "op_name", ".", "startswith", "(", "\"block\"", ")", ":", "\n", "                ", "if", "not", "summarize_blocks", ":", "\n", "# If debug print the ops inside a block.", "\n", "                    ", "for", "block_op_name", ",", "block_op_template", "in", "op_template", ":", "\n", "                        ", "param_count", ",", "flop_mults", ",", "flop_adds", "=", "count_ops", "(", "\n", "block_op_template", ",", "sparsity", ",", "param_bits", "\n", ")", "\n", "temp_res", "=", "get_info", "(", "block_op_template", ")", "\n", "input_size", ",", "kernel_size", ",", "in_channels", ",", "out_channels", "=", "temp_res", "\n", "self", ".", "_print_line", "(", "\n", "\"%s_%s\"", "%", "(", "op_name", ",", "block_op_name", ")", ",", "\n", "input_size", ",", "\n", "kernel_size", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "param_count", ",", "\n", "flop_mults", ",", "\n", "flop_adds", ",", "\n", "mul_bits", ",", "\n", "add_bits", ",", "\n", ")", "\n", "# Count and sum all ops within a block.", "\n", "", "", "param_count", ",", "flop_mults", ",", "flop_adds", "=", "self", ".", "_aggregate_list", "(", "\n", "[", "\n", "count_ops", "(", "template", ",", "sparsity", ",", "param_bits", ")", "\n", "for", "_", ",", "template", "in", "op_template", "\n", "]", "\n", ")", "\n", "# Let's extract the input_size and in_channels from the first operation.", "\n", "input_size", ",", "_", ",", "in_channels", ",", "_", "=", "get_info", "(", "op_template", "[", "0", "]", "[", "1", "]", ")", "\n", "# Since we don't know what is inside a block we don't know the following", "\n", "# fields.", "\n", "kernel_size", "=", "out_channels", "=", "-", "1", "\n", "", "else", ":", "\n", "# If it is a single operation just count.", "\n", "                ", "param_count", ",", "flop_mults", ",", "flop_adds", "=", "count_ops", "(", "\n", "op_template", ",", "sparsity", ",", "param_bits", "\n", ")", "\n", "temp_res", "=", "get_info", "(", "op_template", ")", "\n", "input_size", ",", "kernel_size", ",", "in_channels", ",", "out_channels", "=", "temp_res", "\n", "# At this point param_count, flop_mults, flop_adds should be read.", "\n", "", "total_params", "+=", "param_count", "\n", "total_mults", "+=", "flop_mults", "\n", "total_adds", "+=", "flop_adds", "\n", "# Print the operation.", "\n", "self", ".", "_print_line", "(", "\n", "op_name", ",", "\n", "input_size", ",", "\n", "kernel_size", ",", "\n", "in_channels", ",", "\n", "out_channels", ",", "\n", "param_count", ",", "\n", "flop_mults", ",", "\n", "flop_adds", ",", "\n", "mul_bits", ",", "\n", "add_bits", ",", "\n", ")", "\n", "\n", "# Print Total values.", "\n", "# New string since we are passing empty strings instead of integers.", "\n", "", "out_str", "=", "(", "\n", "\"{:25s} {:10s} {:13s} {:13s} {:13s} {:15.3f} {:10.3f} {:10.3f} \"", "\"{:10.3f}\"", "\n", ")", "\n", "self", ".", "_print_line", "(", "\n", "\"total\"", ",", "\n", "\"\"", ",", "\n", "\"\"", ",", "\n", "\"\"", ",", "\n", "\"\"", ",", "\n", "total_params", ",", "\n", "total_mults", ",", "\n", "total_adds", ",", "\n", "mul_bits", ",", "\n", "add_bits", ",", "\n", "base_str", "=", "out_str", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.get_flops_per_activation": [[98, 118], ["ValueError"], "function", ["None"], ["def", "get_flops_per_activation", "(", "activation", ")", ":", "\n", "    ", "\"\"\"Returns the number of multiplication ands additions of an activation.\n\n  Args:\n    activation: str, type of activation applied to the output.\n  Returns:\n    n_muls, n_adds\n  \"\"\"", "\n", "if", "activation", "==", "\"relu\"", ":", "\n", "# For the purposes of the \"freebie\" quantization scoring, ReLUs can be", "\n", "# assumed to be performed on 16-bit inputs. Thus, we track them as", "\n", "# multiplications in our accounting, which can also be assumed to be", "\n", "# performed on reduced precision inputs.", "\n", "        ", "return", "1", ",", "0", "\n", "", "elif", "activation", "==", "\"swish\"", ":", "# Swish: x / (1 + exp(-bx))", "\n", "        ", "return", "3", ",", "1", "\n", "", "elif", "activation", "==", "\"sigmoid\"", ":", "# Sigmoid: exp(x) / (1 + exp(x))", "\n", "        ", "return", "2", ",", "1", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"activation: %s is not valid\"", "%", "activation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.get_sparse_size": [[120, 137], ["numpy.prod"], "function", ["None"], ["", "", "def", "get_sparse_size", "(", "tensor_shape", ",", "param_bits", ",", "sparsity", ")", ":", "\n", "    ", "\"\"\"Given a tensor shape returns #bits required to store the tensor sparse.\n\n  If sparsity is greater than 0, we do have to store a bit mask to represent\n  sparsity.\n  Args:\n    tensor_shape: list<int>, shape of the tensor\n    param_bits: int, number of bits the elements of the tensor represented in.\n    sparsity: float, sparsity level. 0 means dense.\n  Returns:\n    int, number of bits required to represented the tensor in sparse format.\n  \"\"\"", "\n", "n_elements", "=", "np", ".", "prod", "(", "tensor_shape", ")", "\n", "c_size", "=", "n_elements", "*", "param_bits", "*", "(", "1", "-", "sparsity", ")", "\n", "if", "sparsity", ">", "0", ":", "\n", "        ", "c_size", "+=", "n_elements", "# 1 bit binary mask.", "\n", "", "return", "c_size", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.get_conv_output_size": [[139, 159], ["numpy.ceil", "int", "NotImplementedError"], "function", ["None"], ["", "def", "get_conv_output_size", "(", "image_size", ",", "filter_size", ",", "padding", ",", "stride", ")", ":", "\n", "    ", "\"\"\"Calculates the output size of convolution.\n\n  The input, filter and the strides are assumed to be square.\n  Arguments:\n    image_size: int, Dimensions of the input image (square assumed).\n    filter_size: int, Dimensions of the kernel (square assumed).\n    padding: str, padding added to the input image. 'same' or 'valid'\n    stride: int, stride with which the kernel is applied (square assumed).\n  Returns:\n    int, output size.\n  \"\"\"", "\n", "if", "padding", "==", "\"same\"", ":", "\n", "        ", "pad", "=", "filter_size", "//", "2", "\n", "", "elif", "padding", "==", "\"valid\"", ":", "\n", "        ", "pad", "=", "0", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Padding: %s should be `same` or `valid`.\"", "%", "padding", ")", "\n", "", "out_size", "=", "np", ".", "ceil", "(", "(", "image_size", "-", "filter_size", "+", "1.0", "+", "2", "*", "pad", ")", "/", "stride", ")", "\n", "return", "int", "(", "out_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.count_ops": [[161, 286], ["isinstance", "micronet_challenge.get_sparse_size", "isinstance", "micronet_challenge.get_flops_per_activation", "micronet_challenge.get_sparse_size", "isinstance", "micronet_challenge.get_conv_output_size", "micronet_challenge.get_flops_per_activation", "isinstance", "micronet_challenge.get_conv_output_size", "isinstance", "isinstance", "micronet_challenge.get_sparse_size", "ValueError", "micronet_challenge.get_flops_per_activation", "str"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.get_sparse_size", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.get_flops_per_activation", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.get_sparse_size", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.get_conv_output_size", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.get_flops_per_activation", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.get_conv_output_size", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.get_sparse_size", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.get_flops_per_activation"], ["", "def", "count_ops", "(", "op", ",", "sparsity", ",", "param_bits", ")", ":", "\n", "    ", "\"\"\"Given a operation class returns the flop and parameter statistics.\n\n  Args:\n    op: namedtuple, operation definition.\n    sparsity: float, sparsity of parameterized operations. Sparsity only effects\n      Conv and FC layers; since activations are dense.\n    param_bits: int, number of bits required to represent a parameter.\n  Returns:\n    param_count: number of bits required to store parameters\n    n_mults: number of multiplications made per input sample.\n    n_adds: number of multiplications made per input sample.\n  \"\"\"", "\n", "flop_mults", "=", "flop_adds", "=", "param_count", "=", "0", "\n", "if", "isinstance", "(", "op", ",", "Conv2D", ")", ":", "\n", "# Square kernel expected.", "\n", "        ", "assert", "op", ".", "kernel_shape", "[", "0", "]", "==", "op", ".", "kernel_shape", "[", "1", "]", "\n", "k_size", ",", "_", ",", "c_in", ",", "c_out", "=", "op", ".", "kernel_shape", "\n", "\n", "# Size of the possibly sparse convolutional tensor.", "\n", "param_count", "+=", "get_sparse_size", "(", "\n", "[", "k_size", ",", "k_size", ",", "c_in", ",", "c_out", "]", ",", "param_bits", ",", "sparsity", "\n", ")", "\n", "\n", "# Square stride expected.", "\n", "assert", "op", ".", "strides", "[", "0", "]", "==", "op", ".", "strides", "[", "1", "]", "\n", "stride", "=", "op", ".", "strides", "[", "0", "]", "\n", "\n", "# Each application of the kernel can be thought as a dot product between", "\n", "# the flattened kernel and patches of the image.", "\n", "vector_length", "=", "(", "k_size", "*", "k_size", "*", "c_in", ")", "*", "(", "1", "-", "sparsity", ")", "\n", "# Number of elements in the output is OUT_SIZE * OUT_SIZE * OUT_CHANNEL", "\n", "n_output_elements", "=", "(", "\n", "get_conv_output_size", "(", "op", ".", "input_size", ",", "k_size", ",", "op", ".", "padding", ",", "stride", ")", "**", "2", "*", "c_out", "\n", ")", "\n", "# Each output is the product of a one dot product. Dot product of two", "\n", "# vectors of size n needs n multiplications and n - 1 additions.", "\n", "flop_mults", "+=", "vector_length", "*", "n_output_elements", "\n", "flop_adds", "+=", "(", "vector_length", "-", "1", ")", "*", "n_output_elements", "\n", "\n", "if", "op", ".", "use_bias", ":", "\n", "# For each output channel we need a bias term.", "\n", "            ", "param_count", "+=", "c_out", "*", "param_bits", "\n", "# If we have bias we need one more addition per dot product.", "\n", "flop_adds", "+=", "n_output_elements", "\n", "\n", "", "if", "op", ".", "activation", ":", "\n", "# We would apply the activaiton to every single output element.", "\n", "            ", "n_muls", ",", "n_adds", "=", "get_flops_per_activation", "(", "op", ".", "activation", ")", "\n", "flop_mults", "+=", "n_muls", "*", "n_output_elements", "\n", "flop_adds", "+=", "n_adds", "*", "n_output_elements", "\n", "\n", "", "", "elif", "isinstance", "(", "op", ",", "DepthWiseConv2D", ")", ":", "\n", "# Square kernel expected.", "\n", "        ", "assert", "op", ".", "kernel_shape", "[", "0", "]", "==", "op", ".", "kernel_shape", "[", "1", "]", "\n", "# Last dimension of the kernel should be 1.", "\n", "assert", "op", ".", "kernel_shape", "[", "3", "]", "==", "1", "\n", "k_size", ",", "_", ",", "channels", ",", "_", "=", "op", ".", "kernel_shape", "\n", "\n", "# Size of the possibly sparse convolutional tensor.", "\n", "param_count", "+=", "get_sparse_size", "(", "[", "k_size", ",", "k_size", ",", "channels", "]", ",", "param_bits", ",", "sparsity", ")", "\n", "\n", "# Square stride expected.", "\n", "assert", "op", ".", "strides", "[", "0", "]", "==", "op", ".", "strides", "[", "1", "]", "\n", "stride", "=", "op", ".", "strides", "[", "0", "]", "\n", "\n", "# Each application of the kernel can be thought as a dot product between", "\n", "# the flattened kernel and patches of the image.", "\n", "vector_length", "=", "(", "k_size", "*", "k_size", ")", "*", "(", "1", "-", "sparsity", ")", "\n", "# Number of elements in the output tensor.", "\n", "\n", "n_output_elements", "=", "(", "\n", "get_conv_output_size", "(", "op", ".", "input_size", ",", "k_size", ",", "op", ".", "padding", ",", "stride", ")", "**", "2", "\n", "*", "channels", "\n", ")", "\n", "\n", "# Each output is the product of a one dot product. Dot product of two", "\n", "# vectors of size n needs n multiplications and n - 1 additions.", "\n", "flop_mults", "+=", "vector_length", "*", "n_output_elements", "\n", "flop_adds", "+=", "(", "vector_length", "-", "1", ")", "*", "n_output_elements", "\n", "\n", "if", "op", ".", "use_bias", ":", "\n", "# For each output channel we need a bias term.", "\n", "            ", "param_count", "+=", "channels", "*", "param_bits", "\n", "# If we have bias we need one more addition per dot product.", "\n", "flop_adds", "+=", "n_output_elements", "\n", "\n", "", "if", "op", ".", "activation", ":", "\n", "# We would apply the activaiton to every single output element.", "\n", "            ", "n_muls", ",", "n_adds", "=", "get_flops_per_activation", "(", "op", ".", "activation", ")", "\n", "flop_mults", "+=", "n_muls", "*", "n_output_elements", "\n", "flop_adds", "+=", "n_adds", "*", "n_output_elements", "\n", "", "", "elif", "isinstance", "(", "op", ",", "GlobalAvg", ")", ":", "\n", "# For each output channel we will make a division.", "\n", "        ", "flop_mults", "+=", "op", ".", "n_channels", "\n", "# We have to add values over spatial dimensions.", "\n", "flop_adds", "+=", "(", "op", ".", "input_size", "*", "op", ".", "input_size", "-", "1", ")", "*", "op", ".", "n_channels", "\n", "", "elif", "isinstance", "(", "op", ",", "Scale", ")", ":", "\n", "# Number of elements many multiplications.", "\n", "        ", "flop_mults", "+=", "op", ".", "input_size", "*", "op", ".", "input_size", "*", "op", ".", "n_channels", "\n", "", "elif", "isinstance", "(", "op", ",", "Add", ")", ":", "\n", "# Number of elements many additions.", "\n", "        ", "flop_adds", "+=", "op", ".", "input_size", "*", "op", ".", "input_size", "*", "op", ".", "n_channels", "\n", "", "elif", "isinstance", "(", "op", ",", "FullyConnected", ")", ":", "\n", "        ", "c_in", ",", "c_out", "=", "op", ".", "kernel_shape", "\n", "# Size of the possibly sparse weight matrix.", "\n", "param_count", "+=", "get_sparse_size", "(", "[", "c_in", ",", "c_out", "]", ",", "param_bits", ",", "sparsity", ")", "\n", "\n", "# number of non-zero elements for the sparse dot product.", "\n", "n_elements", "=", "c_in", "*", "(", "1", "-", "sparsity", ")", "\n", "flop_mults", "+=", "n_elements", "*", "c_out", "\n", "# We have one less addition than the number of multiplications per output", "\n", "# channel.", "\n", "flop_adds", "+=", "(", "n_elements", "-", "1", ")", "*", "c_out", "\n", "\n", "if", "op", ".", "use_bias", ":", "\n", "            ", "param_count", "+=", "c_out", "*", "param_bits", "\n", "flop_adds", "+=", "c_out", "\n", "", "if", "op", ".", "activation", ":", "\n", "            ", "n_muls", ",", "n_adds", "=", "get_flops_per_activation", "(", "op", ".", "activation", ")", "\n", "flop_mults", "+=", "n_muls", "*", "c_out", "\n", "flop_adds", "+=", "n_adds", "*", "c_out", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Encountered unknown operation %s.\"", "%", "str", "(", "op", ")", ")", "\n", "", "return", "param_count", ",", "flop_mults", ",", "flop_adds", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.get_info": [[289, 310], ["isinstance", "isinstance", "isinstance", "isinstance", "ValueError", "str"], "function", ["None"], ["", "def", "get_info", "(", "op", ")", ":", "\n", "    ", "\"\"\"Given an op extracts some common information.\"\"\"", "\n", "input_size", ",", "kernel_size", ",", "in_channels", ",", "out_channels", "=", "[", "-", "1", "]", "*", "4", "\n", "if", "isinstance", "(", "op", ",", "(", "DepthWiseConv2D", ",", "Conv2D", ")", ")", ":", "\n", "# square kernel assumed.", "\n", "        ", "kernel_size", ",", "_", ",", "in_channels", ",", "out_channels", "=", "op", ".", "kernel_shape", "\n", "input_size", "=", "op", ".", "input_size", "\n", "", "elif", "isinstance", "(", "op", ",", "GlobalAvg", ")", ":", "\n", "        ", "in_channels", "=", "op", ".", "n_channels", "\n", "out_channels", "=", "1", "\n", "input_size", "=", "op", ".", "input_size", "\n", "", "elif", "isinstance", "(", "op", ",", "(", "Add", ",", "Scale", ")", ")", ":", "\n", "        ", "in_channels", "=", "op", ".", "n_channels", "\n", "out_channels", "=", "op", ".", "n_channels", "\n", "input_size", "=", "op", ".", "input_size", "\n", "", "elif", "isinstance", "(", "op", ",", "FullyConnected", ")", ":", "\n", "        ", "in_channels", ",", "out_channels", "=", "op", ".", "kernel_shape", "\n", "input_size", "=", "1", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Encountered unknown operation %s.\"", "%", "str", "(", "op", ")", ")", "\n", "", "return", "input_size", ",", "kernel_size", ",", "in_channels", ",", "out_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.ops.get_inference_FLOPs": [[13, 88], ["torch.no_grad", "sparselearning.counting.helper.get_pre_activations_dict", "masking.module.named_modules", "int", "logging.debug", "isinstance", "sparselearning.counting.micronet_challenge.count_ops", "logging.debug", "isinstance", "isinstance", "weight.numel", "sparselearning.counting.micronet_challenge.DepthWiseConv2D", "sparselearning.counting.micronet_challenge.Conv2D", "isinstance", "sparselearning.counting.micronet_challenge.FullyConnected"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.helper.get_pre_activations_dict", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.micronet_challenge.count_ops"], ["idx", "=", "torch", ".", "randperm", "(", "a", ".", "nelement", "(", ")", ")", "\n", "return", "a", ".", "reshape", "(", "-", "1", ")", "[", "idx", "]", ".", "reshape", "(", "a", ".", "shape", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.helper.get_pre_activations_dict": [[7, 46], ["net.named_modules", "net.named_parameters", "net", "module.register_forward_hook", "device_ll.append", "len", "input_tensor.to", "input[].detach", "helper.get_pre_activations_dict._get_activation"], "function", ["None"], ["", "def", "get_pre_activations_dict", "(", "net", ":", "\"nn.Module\"", ",", "input_tensor", ":", "\"Tensor\"", ")", "->", "\"Dict[str, Tensor]\"", ":", "\n", "    ", "\"\"\"\n    Find pre-activation dict for every possible module in network\n\n    :param net: Pytorch model\n    :type net: nn.Module\n    :param input_tensor: input tensor, supports only single input\n    :type input_tensor: Tensor\n    :return: dictionary mapping layers to pre-activations\n    :rtype: Dict[str, Tensor]\n    \"\"\"", "\n", "\"\"\"\n    \"\"\"", "\n", "# TODO: this function invokes the warning", "\n", "# torch/nn/modules/container.py:434: UserWarning: Setting attributes on ParameterList is not supported.", "\n", "# warnings.warn(\"Setting attributes on ParameterList is not supported.\")", "\n", "# Why?", "\n", "\n", "activation_dict", "=", "{", "}", "\n", "\n", "def", "_get_activation", "(", "name", ")", ":", "\n", "        ", "def", "hook", "(", "model", ",", "input", ",", "output", ")", ":", "\n", "# activation_dict[name] = output.detach()", "\n", "            ", "activation_dict", "[", "name", "]", "=", "input", "[", "0", "]", ".", "detach", "(", ")", "\n", "\n", "", "return", "hook", "\n", "\n", "", "for", "name", ",", "module", "in", "net", ".", "named_modules", "(", ")", ":", "\n", "        ", "module", ".", "register_forward_hook", "(", "_get_activation", "(", "name", ")", ")", "\n", "\n", "", "device_ll", "=", "[", "]", "\n", "for", "name", ",", "weight", "in", "net", ".", "named_parameters", "(", ")", ":", "\n", "        ", "device_ll", ".", "append", "(", "weight", ".", "device", ")", "\n", "", "assert", "len", "(", "set", "(", "device_ll", ")", ")", "==", "1", ",", "\"No support for multi-device modules yet!\"", "\n", "device", "=", "device_ll", "[", "0", "]", "\n", "\n", "net", "(", "input_tensor", ".", "to", "(", "device", ")", ")", "\n", "\n", "return", "activation_dict", "\n", "", ""]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.print_stats.print_stats": [[18, 99], ["functools.partial", "functools.partial.", "print", "functools.partial.", "functools.partial.", "functools.partial.", "sparselearning.funcs.decay.MagnitudePruneDecay", "print", "print", "print", "sparselearning.counting.inference_train_FLOPs.Pruning_inference_FLOPs", "print", "print", "print", "zip", "sparselearning.counting.inference_train_FLOPs.Pruning_train_FLOPs", "print", "print", "print", "sparselearning.counting.inference_train_FLOPs.SET_train_FLOPs", "sparselearning.counting.inference_train_FLOPs.SNFS_train_FLOPs", "sparselearning.counting.inference_train_FLOPs.RigL_train_FLOPs", "print", "print", "print", "print", "init_name.capitalize", "init_name.capitalize", "init_name.capitalize"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.Pruning_inference_FLOPs", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.Pruning_train_FLOPs", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.SET_train_FLOPs", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.SNFS_train_FLOPs", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.RigL_train_FLOPs"], ["", "def", "print_stats", "(", "model_name", ":", "str", ",", "input_size", ":", "\"Tuple\"", "=", "(", "1", ",", "3", ",", "32", ",", "32", ")", ")", ":", "\n", "    ", "\"\"\"\n    Print FLOP statistics for (Dense, Pruning, RigL, SET, SNFS) models\n\n    :param model_name: Model to use (wrn-22-2 or resnet-50)\n    :type model_name: str\n    :param input_size: Shape of input tensor, single input only\n    :type input_size: Tuple[int]\n    \"\"\"", "\n", "_model_FLOPs", "=", "partial", "(", "\n", "model_inference_FLOPs", ",", "model_name", "=", "model_name", ",", "input_size", "=", "input_size", "\n", ")", "\n", "\n", "dense_FLOPs", "=", "_model_FLOPs", "(", "density", "=", "1.0", ")", "\n", "dense_train_FLOPs", "=", "3", "*", "dense_FLOPs", "# gradient of param and activation", "\n", "print", "(", "f\"{model_name} Dense FLOPS: {dense_FLOPs:,} \\n\"", ")", "\n", "\n", "# Pruning & Masking", "\n", "total_steps", "=", "87891", "\n", "T_max", "=", "65918", "\n", "interval", "=", "100", "\n", "# Pruning", "\n", "T_start", "=", "700", "\n", "\n", "for", "density", "in", "[", "0.05", ",", "0.1", ",", "0.2", ",", "0.5", "]", ":", "\n", "        ", "Random_FLOPs", "=", "_model_FLOPs", "(", "\"random\"", ",", "density", ")", "\n", "ER_FLOPs", "=", "_model_FLOPs", "(", "\"erdos-renyi\"", ",", "density", ")", "\n", "ERK_FLOPs", "=", "_model_FLOPs", "(", "\"erdos-renyi-kernel\"", ",", "density", ")", "\n", "\n", "pruning_decay", "=", "MagnitudePruneDecay", "(", "\n", "final_sparsity", "=", "1", "-", "density", ",", "T_max", "=", "T_max", ",", "T_start", "=", "T_start", ",", "interval", "=", "interval", "\n", ")", "\n", "\n", "print", "(", "\n", "f\"Random Density: {density} Inference FLOPs:{Random_FLOPs:,} Proportion:{Random_FLOPs / dense_FLOPs:.4f}\"", "\n", ")", "\n", "print", "(", "\n", "f\"ER Density: {density} Inference FLOPs:{ER_FLOPs:,} Proportion:{ER_FLOPs / dense_FLOPs:.4f}\"", "\n", ")", "\n", "print", "(", "\n", "f\"ERK Density: {density} Inference FLOPs:{ERK_FLOPs:,} Proportion:{ERK_FLOPs / dense_FLOPs:.4f}\"", "\n", ")", "\n", "\n", "pruning_inference_FLOPs", "=", "Pruning_inference_FLOPs", "(", "\n", "dense_FLOPs", ",", "pruning_decay", ",", "total_steps", "=", "total_steps", "\n", ")", "\n", "print", "(", "\n", "f\"Pruning Density: {density} Inference FLOPs:{pruning_inference_FLOPs:,} Proportion:{pruning_inference_FLOPs / dense_FLOPs:.4f}\"", "\n", ")", "\n", "print", "(", "f\"[PS: This is approximate, assuming final dist is nearly random like.]\"", ")", "\n", "\n", "print", "(", "\"\\n\"", ")", "\n", "\n", "for", "sparse_FLOPs", ",", "init_name", "in", "zip", "(", "\n", "[", "Random_FLOPs", ",", "ERK_FLOPs", "]", ",", "[", "\"Random\"", ",", "\"ERK\"", "]", "\n", ")", ":", "\n", "            ", "set_train_FLOPs", "=", "SET_train_FLOPs", "(", "sparse_FLOPs", ",", "dense_FLOPs", ",", "interval", ")", "\n", "snfs_train_FLOPs", "=", "SNFS_train_FLOPs", "(", "sparse_FLOPs", ",", "dense_FLOPs", ",", "interval", ")", "\n", "rigl_train_FLOPs", "=", "RigL_train_FLOPs", "(", "sparse_FLOPs", ",", "dense_FLOPs", ",", "interval", ")", "\n", "\n", "print", "(", "\n", "f\"SET {init_name.capitalize()} Density: {density} Train FLOPs:{set_train_FLOPs:,} Proportion:{set_train_FLOPs / dense_train_FLOPs:.4f}\"", "\n", ")", "\n", "print", "(", "\n", "f\"SNFS at init {init_name.capitalize()} Density: {density} Train FLOPs:{snfs_train_FLOPs:,} Proportion:{snfs_train_FLOPs / dense_train_FLOPs:.4f}\"", "\n", ")", "\n", "print", "(", "\n", "f\"RigL {init_name.capitalize()} Density: {density} Train FLOPs:{rigl_train_FLOPs:,} Proportion:{rigl_train_FLOPs / dense_train_FLOPs:.4f}\"", "\n", ")", "\n", "\n", "print", "(", "\"\\n\"", ")", "\n", "\n", "", "pruning_train_FLOPs", "=", "Pruning_train_FLOPs", "(", "\n", "dense_FLOPs", ",", "pruning_decay", ",", "total_steps", "=", "total_steps", "\n", ")", "\n", "print", "(", "\n", "f\"Pruning Density: {density} Train FLOPs:{pruning_train_FLOPs:,} Proportion:{pruning_train_FLOPs / dense_train_FLOPs:.4f}\"", "\n", ")", "\n", "print", "(", "f\"[PS: This is approximate, assuming final dist is nearly random like.]\"", ")", "\n", "\n", "print", "(", "\"-----------\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.Pruning_inference_FLOPs": [[12, 39], ["range", "decay.cumulative_sparsity"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.cumulative_sparsity"], ["def", "Pruning_inference_FLOPs", "(", "\n", "dense_FLOPs", ":", "int", ",", "decay", ":", "MagnitudePruneDecay", ",", "total_steps", ":", "int", "=", "87891", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Inference FLOPs for Iterative Pruning, Zhu and Gupta 2018.\n    Note, assumes FLOPs \\propto average sparsity,\n    which is approximately true in practice.\n\n    For our report, we accurately calculate train FLOPs by evaluating FLOPs\n    during each pruning iteration.\n\n    :param dense_FLOPs: FLOPs consumed for dense model's forward pass\n    :type dense_FLOPs: int\n    :param decay: Pruning schedule used\n    :type decay: sparselearning.funcs.decay.MagnitudePruneDecay\n    :param total_steps: Total train steps\n    :type total_steps: int\n    :return: Pruning inference FLOPs\n    :rtype: float\n    \"\"\"", "\n", "avg_sparsity", "=", "0.0", "\n", "for", "i", "in", "range", "(", "0", ",", "total_steps", ")", ":", "\n", "        ", "avg_sparsity", "+=", "decay", ".", "cumulative_sparsity", "(", "i", ")", "\n", "\n", "", "avg_sparsity", "/=", "total_steps", "\n", "\n", "return", "dense_FLOPs", "*", "(", "1", "-", "avg_sparsity", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.Pruning_train_FLOPs": [[41, 68], ["range", "decay.cumulative_sparsity"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.cumulative_sparsity"], ["", "def", "Pruning_train_FLOPs", "(", "\n", "dense_FLOPs", ":", "int", ",", "decay", ":", "MagnitudePruneDecay", ",", "total_steps", ":", "int", "=", "87891", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Train FLOPs for Iterative Pruning, Zhu and Gupta 2018.\n    Note, assumes FLOPs \\propto average sparsity,\n    which is approximately true in practice.\n\n    For our report, we accurately calculate train FLOPs by evaluating FLOPs\n    during each pruning iteration.\n\n    :param dense_FLOPs: FLOPs consumed for dense model's forward pass\n    :type dense_FLOPs: int\n    :param decay: Pruning schedule used\n    :type decay: sparselearning.funcs.decay.MagnitudePruneDecay\n    :param total_steps: Total train steps\n    :type total_steps: int\n    :return: Pruning train FLOPs\n    :rtype: float\n    \"\"\"", "\n", "avg_sparsity", "=", "0.0", "\n", "for", "i", "in", "range", "(", "0", ",", "total_steps", ")", ":", "\n", "        ", "avg_sparsity", "+=", "decay", ".", "cumulative_sparsity", "(", "i", ")", "\n", "\n", "", "avg_sparsity", "/=", "total_steps", "\n", "\n", "return", "2", "*", "dense_FLOPs", "*", "(", "1", "-", "avg_sparsity", ")", "+", "dense_FLOPs", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.RigL_train_FLOPs": [[70, 87], ["None"], "function", ["None"], ["", "def", "RigL_train_FLOPs", "(", "\n", "sparse_FLOPs", ":", "int", ",", "dense_FLOPs", ":", "int", ",", "mask_interval", ":", "int", "=", "100", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Train FLOPs for Rigging the Lottery (RigL), Evci et al. 2020.\n\n    :param sparse_FLOPs: FLOPs consumed for sparse model's forward pass\n    :type sparse_FLOPs: int\n    :param dense_FLOPs: FLOPs consumed for dense model's forward pass\n    :type dense_FLOPs: int\n    :param mask_interval: Mask update interval\n    :type mask_interval: int\n    :return: RigL train FLOPs\n    :rtype: float\n    \"\"\"", "\n", "return", "(", "2", "*", "sparse_FLOPs", "+", "dense_FLOPs", "+", "3", "*", "sparse_FLOPs", "*", "mask_interval", ")", "/", "(", "\n", "mask_interval", "+", "1", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.SNFS_train_FLOPs": [[90, 106], ["None"], "function", ["None"], ["", "def", "SNFS_train_FLOPs", "(", "\n", "sparse_FLOPs", ":", "int", ",", "dense_FLOPs", ":", "int", ",", "mask_interval", ":", "int", "=", "100", "\n", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Train FLOPs for Sparse Networks from Scratch (SNFS), Dettmers et al. 2020.\n\n    :param sparse_FLOPs: FLOPs consumed for sparse model's forward pass\n    :type sparse_FLOPs: int\n    :param dense_FLOPs: FLOPs consumed for dense model's forward pass\n    :type dense_FLOPs: int\n    :param mask_interval: Mask update interval\n    :type mask_interval: int\n    :return: SNFS train FLOPs\n    :rtype: int\n    \"\"\"", "\n", "return", "2", "*", "sparse_FLOPs", "+", "dense_FLOPs", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.SET_train_FLOPs": [[108, 124], ["None"], "function", ["None"], ["", "def", "SET_train_FLOPs", "(", "\n", "sparse_FLOPs", ":", "int", ",", "dense_FLOPs", ":", "int", ",", "mask_interval", ":", "int", "=", "100", "\n", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Train FLOPs for Sparse Evolutionary Training (SET), Mocanu et al. 2018.\n\n    :param sparse_FLOPs: FLOPs consumed for sparse model's forward pass\n    :type sparse_FLOPs: int\n    :param dense_FLOPs: FLOPs consumed for dense model's forward pass\n    :type dense_FLOPs: int\n    :param mask_interval: Mask update interval\n    :type mask_interval: int\n    :return: SET train FLOPs\n    :rtype: int\n    \"\"\"", "\n", "return", "3", "*", "sparse_FLOPs", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.inference_train_FLOPs.model_inference_FLOPs": [[126, 158], ["model_class", "sparselearning.funcs.decay.CosineDecay", "torch.optim.SGD", "sparselearning.core.Masking", "sparselearning.core.Masking.add_module", "sparselearning.counting.ops.get_inference_FLOPs", "model_class.parameters", "torch.rand"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.add_module", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.counting.ops.get_inference_FLOPs"], ["", "def", "model_inference_FLOPs", "(", "\n", "sparse_init", ":", "str", "=", "\"random\"", ",", "\n", "density", ":", "float", "=", "0.2", ",", "\n", "model_name", ":", "str", "=", "\"wrn-22-2\"", ",", "\n", "input_size", ":", "\"Tuple\"", "=", "(", "1", ",", "3", ",", "32", ",", "32", ")", ",", "\n", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Obtain inference FLOPs for a model.\n\n    Only for models trained with a constant FLOP sparsifying technique.\n    eg: SNFS, Pruning are not supported here.\n\n    :param sparse_init: Initialization scheme used (Random / ER / ERK)\n    :type sparse_init: str\n    :param density: Overall parameter density (non-zero / capacity)\n    :type density: float\n    :param model_name: model to use (WideResNet-22-2 or ResNet-50)\n    :type model_name: str\n    :param input_size: shape of input tensor\n    :type input_size: Tuple\n    :return:\n    :rtype:\n    \"\"\"", "\n", "model_class", ",", "args", "=", "model_registry", "[", "model_name", "]", "\n", "model", "=", "model_class", "(", "*", "args", ")", "\n", "decay", "=", "CosineDecay", "(", ")", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "0.1", ")", "\n", "\n", "mask", "=", "Masking", "(", "optimizer", ",", "decay", ",", "sparse_init", "=", "sparse_init", ",", "density", "=", "density", ")", "\n", "mask", ".", "add_module", "(", "model", ")", "\n", "\n", "return", "get_inference_FLOPs", "(", "mask", ",", "torch", ".", "rand", "(", "*", "input_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.grow.momentum_growth": [[25, 56], ["masking.mask_dict[].data.bool", "masking.get_momentum_for_weight", "torch.sort", "torch.abs().flatten", "masking.mask_dict[].data.bool.data.view", "torch.abs", "int"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.get_momentum_for_weight"], ["", "def", "momentum_growth", "(", "\n", "masking", ":", "\"Masking\"", ",", "\n", "name", ":", "str", ",", "\n", "total_regrowth", ":", "int", ",", "\n", "weight", ":", "\"Tensor\"", ",", "\n", ")", "->", "\"Tensor\"", ":", "\n", "    ", "\"\"\"\n    Grows weights in places where the momentum is largest.\n\n    :param masking: Masking instance\n    :type masking: sparselearning.core.Masking\n    :param name: layer name\n    :type name: str\n    :param total_regrowth: amount to re-grow\n    :type total_regrowth: int\n    :param weight: layer weight\n    :type weight: torch.Tensor\n    :return: New boolean mask\n    :rtype: torch.Tensor\n    \"\"\"", "\n", "new_mask", "=", "masking", ".", "mask_dict", "[", "name", "]", ".", "data", ".", "bool", "(", ")", "\n", "\n", "momentum", "=", "masking", ".", "get_momentum_for_weight", "(", "weight", ")", "\n", "if", "momentum", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "        ", "momentum", "=", "momentum", "*", "(", "new_mask", "==", "0", ")", ".", "half", "(", ")", "\n", "", "else", ":", "\n", "        ", "momentum", "=", "momentum", "*", "(", "new_mask", "==", "0", ")", ".", "float", "(", ")", "\n", "", "y", ",", "idx", "=", "torch", ".", "sort", "(", "torch", ".", "abs", "(", "momentum", ")", ".", "flatten", "(", ")", ",", "descending", "=", "True", ")", "\n", "new_mask", ".", "data", ".", "view", "(", "-", "1", ")", "[", "idx", "[", ":", "int", "(", "total_regrowth", ")", "]", "]", "=", "1.0", "\n", "\n", "return", "new_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.grow.abs_grad_growth": [[58, 98], ["masking.mask_dict[].data.bool", "torch.sort", "torch.abs().flatten", "masking.mask_dict[].data.bool.data.view", "weight.data.view", "torch.abs", "int", "int"], "function", ["None"], ["", "def", "abs_grad_growth", "(", "\n", "masking", ":", "\"Masking\"", ",", "\n", "name", ":", "str", ",", "\n", "total_regrowth", ":", "int", ",", "\n", "weight", ":", "\"Tensor\"", ",", "\n", ")", "->", "\"Tensor\"", ":", "\n", "    ", "\"\"\"\n    Grows weights in places where the abs(grad) is largest\n    (among present zero'ed weights).\n\n    :param masking: Masking instance\n    :type masking: sparselearning.core.Masking\n    :param name: layer name\n    :type name: str\n    :param total_regrowth: amount to re-grow\n    :type total_regrowth: int\n    :param weight: layer weight\n    :type weight: torch.Tensor\n    :return: New boolean mask\n    :rtype: torch.Tensor\n    \"\"\"", "\n", "new_mask", "=", "masking", ".", "mask_dict", "[", "name", "]", ".", "data", ".", "bool", "(", ")", "\n", "\n", "# If dense, skip", "\n", "n", "=", "(", "new_mask", "==", "0", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "if", "n", "==", "0", ":", "\n", "        ", "return", "new_mask", "\n", "\n", "", "grad", "=", "weight", ".", "grad", "\n", "if", "grad", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "        ", "grad", "=", "grad", "*", "(", "new_mask", "==", "0", ")", ".", "half", "(", ")", "\n", "", "else", ":", "\n", "        ", "grad", "=", "grad", "*", "(", "new_mask", "==", "0", ")", ".", "float", "(", ")", "\n", "", "y", ",", "idx", "=", "torch", ".", "sort", "(", "torch", ".", "abs", "(", "grad", ")", ".", "flatten", "(", ")", ",", "descending", "=", "True", ")", "\n", "new_mask", ".", "data", ".", "view", "(", "-", "1", ")", "[", "idx", "[", ":", "int", "(", "total_regrowth", ")", "]", "]", "=", "1.0", "\n", "\n", "# init new weights to 0", "\n", "weight", ".", "data", ".", "view", "(", "-", "1", ")", "[", "idx", "[", ":", "int", "(", "total_regrowth", ")", "]", "]", "=", "0.0", "\n", "\n", "return", "new_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.grow.random_growth": [[100, 138], ["masking.mask_dict[].data.bool", "torch.zeros_like().bool", "torch.rand_like", "masking.mask_dict[].data.bool.bool", "torch.zeros_like().bool.bool", "torch.zeros_like", "new_weights[].float"], "function", ["None"], ["", "def", "random_growth", "(", "\n", "masking", ":", "\"Masking\"", ",", "\n", "name", ":", "str", ",", "\n", "total_regrowth", ":", "int", ",", "\n", "weight", ":", "\"Tensor\"", ",", "\n", ")", "->", "\"Tensor\"", ":", "\n", "    ", "\"\"\"\n    Random growth.\n\n    :param masking: Masking instance\n    :type masking: sparselearning.core.Masking\n    :param name: layer name\n    :type name: str\n    :param total_regrowth: amount to re-grow\n    :type total_regrowth: int\n    :param weight: layer weight\n    :type weight: torch.Tensor\n    :return: New boolean mask\n    :rtype: torch.Tensor\n    \"\"\"", "\n", "new_mask", "=", "masking", ".", "mask_dict", "[", "name", "]", ".", "data", ".", "bool", "(", ")", "\n", "\n", "# If dense, skip", "\n", "n", "=", "(", "new_mask", "==", "0", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "if", "n", "==", "0", ":", "\n", "        ", "return", "new_mask", "\n", "", "expeced_growth_probability", "=", "total_regrowth", "/", "n", "\n", "new_weights", "=", "torch", ".", "zeros_like", "(", "new_mask", ")", ".", "bool", "(", ")", "\n", "new_weights", "[", "new_mask", "==", "0", "]", "=", "(", "\n", "torch", ".", "rand_like", "(", "new_weights", "[", "new_mask", "==", "0", "]", ".", "float", "(", ")", ")", "<", "expeced_growth_probability", "\n", ")", "\n", "new_mask", "=", "new_mask", ".", "bool", "(", ")", "|", "new_weights", ".", "bool", "(", ")", "\n", "\n", "# init new weights to 0", "\n", "weight", ".", "data", "[", "new_weights", "==", "1", "]", "=", "0.0", "\n", "weight", ".", "data", "[", "new_mask", "==", "0", "]", "=", "0.0", "\n", "\n", "return", "new_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.grow.no_growth": [[140, 163], ["masking.mask_dict[].data.bool"], "function", ["None"], ["", "def", "no_growth", "(", "\n", "masking", ":", "\"Masking\"", ",", "\n", "name", ":", "str", ",", "\n", "total_regrowth", ":", "int", ",", "\n", "weight", ":", "\"Tensor\"", ",", "\n", ")", "->", "\"Tensor\"", ":", "\n", "    ", "\"\"\"\n    No growth.\n\n    :param masking: Masking instance\n    :type masking: sparselearning.core.Masking\n    :param name: layer name\n    :type name: str\n    :param total_regrowth: amount to re-grow\n    :type total_regrowth: int\n    :param weight: layer weight\n    :type weight: torch.Tensor\n    :return: New boolean mask\n    :rtype: torch.Tensor\n    \"\"\"", "\n", "new_mask", "=", "masking", ".", "mask_dict", "[", "name", "]", ".", "data", ".", "bool", "(", ")", "\n", "\n", "return", "new_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.grow.struct_abs_grad_growth": [[165, 214], ["masking.mask_dict[].data.bool", "criterion", "torch.sort", "einops.rearrange", "torch.abs().flatten", "masking.mask_dict[].data.bool.data.view", "weight.data.view", "torch.abs", "int", "int"], "function", ["None"], ["", "def", "struct_abs_grad_growth", "(", "\n", "masking", ":", "\"Masking\"", ",", "\n", "name", ":", "str", ",", "\n", "total_regrowth", ":", "int", ",", "\n", "weight", ":", "\"Tensor\"", ",", "\n", "criterion", ":", "Callable", "=", "torch", ".", "mean", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Performs absolute gradient growth channel-wise.\n\n    :param masking: Masking instance\n    :type masking: sparselearning.core.Masking\n    :param name: layer name\n    :type name: str\n    :param total_regrowth: amount to re-grow\n    :type total_regrowth: int\n    :param weight: layer weight\n    :type weight: torch.Tensor\n    :param criterion: callable to perform reduction\n    :type criterion: Callable\n    :return: New boolean mask\n    :rtype: torch.Tensor\n    \"\"\"", "\n", "new_mask", "=", "masking", ".", "mask_dict", "[", "name", "]", ".", "data", ".", "bool", "(", ")", "\n", "\n", "# If dense, skip", "\n", "n", "=", "(", "new_mask", "==", "0", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "if", "n", "==", "0", ":", "\n", "        ", "return", "new_mask", "\n", "\n", "", "grad", "=", "weight", ".", "grad", "\n", "if", "grad", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "        ", "grad", "=", "grad", "*", "(", "new_mask", "==", "0", ")", ".", "half", "(", ")", "\n", "", "else", ":", "\n", "        ", "grad", "=", "grad", "*", "(", "new_mask", "==", "0", ")", ".", "float", "(", ")", "\n", "\n", "", "c_in", ",", "c_out", ",", "h", ",", "w", "=", "weight", ".", "shape", "\n", "kernel_size", "=", "h", "*", "w", "\n", "\n", "reduced", "=", "criterion", "(", "rearrange", "(", "grad", ",", "\"c_in c_out h w -> c_in c_out (h w)\"", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n", "y", ",", "idx", "=", "torch", ".", "sort", "(", "torch", ".", "abs", "(", "reduced", ")", ".", "flatten", "(", ")", ",", "descending", "=", "True", ")", "\n", "\n", "new_mask", ".", "data", ".", "view", "(", "-", "1", ",", "h", ",", "w", ")", "[", "idx", "[", ":", "int", "(", "total_regrowth", "/", "kernel_size", ")", "]", ",", ":", ",", ":", "]", "=", "1.0", "\n", "\n", "# init new weights to 0", "\n", "weight", ".", "data", ".", "view", "(", "-", "1", ",", "h", ",", "w", ")", "[", "idx", "[", ":", "int", "(", "total_regrowth", "/", "kernel_size", ")", "]", ",", ":", ",", ":", "]", "=", "0.0", "\n", "\n", "return", "new_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.Decay.__init__": [[15, 17], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "mode", "=", "\"current\"", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.Decay.step": [[18, 20], ["None"], "methods", ["None"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.Decay.get_dr": [[21, 23], ["None"], "methods", ["None"], ["", "def", "get_dr", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.CosineDecay.__init__": [[39, 55], ["decay.Decay.__init__", "torch.SGD", "torch.SGD", "torch.optim.lr_scheduler.CosineAnnealingLR", "torch.optim.lr_scheduler.CosineAnnealingLR", "torch.optim.lr_scheduler.CosineAnnealingLR", "torch.optim.lr_scheduler.CosineAnnealingLR", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.ParameterList", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.LinearDecay.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "prune_rate", ":", "float", "=", "0.3", ",", "\n", "T_max", ":", "int", "=", "1000", ",", "\n", "eta_min", ":", "float", "=", "0.0", ",", "\n", "last_epoch", ":", "int", "=", "-", "1", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "T_max", "=", "T_max", "\n", "\n", "self", ".", "sgd", "=", "optim", ".", "SGD", "(", "\n", "torch", ".", "nn", ".", "ParameterList", "(", "[", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ")", ")", "]", ")", ",", "lr", "=", "prune_rate", "\n", ")", "\n", "self", ".", "cosine_stepper", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "CosineAnnealingLR", "(", "\n", "self", ".", "sgd", ",", "T_max", ",", "eta_min", ",", "last_epoch", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.CosineDecay.step": [[57, 68], ["decay.CosineDecay.cosine_stepper.step", "decay.CosineDecay.cosine_stepper.step"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.step", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.step"], ["", "def", "step", "(", "self", ",", "step", ":", "int", "=", "-", "1", ")", ":", "\n", "        ", "if", "step", ">=", "0", ":", "\n", "            ", "if", "self", ".", "_step", "<", "self", ".", "T_max", ":", "\n", "                ", "self", ".", "cosine_stepper", ".", "step", "(", "step", ")", "\n", "self", ".", "_step", "=", "step", "+", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "_step", "=", "self", ".", "T_max", "\n", "", "return", "\n", "", "if", "self", ".", "_step", "<", "self", ".", "T_max", ":", "\n", "            ", "self", ".", "cosine_stepper", ".", "step", "(", ")", "\n", "self", ".", "_step", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.CosineDecay.get_dr": [[69, 71], ["None"], "methods", ["None"], ["", "", "def", "get_dr", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sgd", ".", "param_groups", "[", "0", "]", "[", "\"lr\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.LinearDecay.__init__": [[83, 93], ["decay.Decay.__init__", "float"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.LinearDecay.__init__"], ["def", "__init__", "(", "self", ",", "prune_rate", ":", "float", "=", "0.3", ",", "T_max", ":", "int", "=", "1000", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "T_max", "=", "T_max", "\n", "\n", "self", ".", "decrement", "=", "prune_rate", "/", "float", "(", "T_max", ")", "\n", "self", ".", "current_prune_rate", "=", "prune_rate", "\n", "self", ".", "initial_prune_rate", "=", "prune_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.LinearDecay.step": [[94, 107], ["None"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "step", ":", "int", "=", "-", "1", ")", ":", "\n", "        ", "if", "step", ">=", "0", ":", "\n", "            ", "if", "self", ".", "_step", "<", "self", ".", "T_max", ":", "\n", "                ", "self", ".", "current_prune_rate", "=", "self", ".", "initial_prune_rate", "-", "self", ".", "decrement", "*", "(", "\n", "step", "+", "1", "\n", ")", "\n", "self", ".", "_step", "=", "step", "+", "1", "\n", "", "else", ":", "\n", "                ", "self", ".", "_step", "=", "self", ".", "T_max", "\n", "", "return", "\n", "", "if", "self", ".", "_step", "<", "self", ".", "T_max", ":", "\n", "            ", "self", ".", "current_prune_rate", "-=", "self", ".", "decrement", "\n", "self", ".", "_step", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.LinearDecay.get_dr": [[108, 110], ["None"], "methods", ["None"], ["", "", "def", "get_dr", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "current_prune_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.__post_init__": [[127, 131], ["None"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "mode", "=", "\"cumulative\"", "\n", "self", ".", "current_prune_rate", "=", "0.0", "\n", "self", ".", "_step", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.cumulative_sparsity": [[132, 143], ["None"], "methods", ["None"], ["", "def", "cumulative_sparsity", "(", "self", ",", "step", ")", ":", "\n", "        ", "if", "step", "<", "self", ".", "T_start", ":", "\n", "            ", "return", "self", ".", "initial_sparsity", "\n", "", "elif", "step", "<", "self", ".", "T_max", ":", "\n", "            ", "mul", "=", "(", "1", "-", "(", "step", "-", "self", ".", "T_start", ")", "/", "(", "self", ".", "T_max", "-", "self", ".", "T_start", ")", ")", "**", "3", "\n", "return", "(", "\n", "self", ".", "final_sparsity", "\n", "+", "(", "self", ".", "initial_sparsity", "-", "self", ".", "final_sparsity", ")", "*", "mul", "\n", ")", "\n", "", "elif", "step", ">=", "self", ".", "T_max", ":", "\n", "            ", "return", "self", ".", "final_sparsity", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.step": [[144, 156], ["max", "decay.MagnitudePruneDecay.cumulative_sparsity", "decay.MagnitudePruneDecay.cumulative_sparsity"], "methods", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.cumulative_sparsity", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.cumulative_sparsity"], ["", "", "def", "step", "(", "self", ",", "step", ":", "int", "=", "-", "1", ",", "current_sparsity", "=", "-", "1", ")", ":", "\n", "        ", "if", "step", "==", "-", "1", ":", "\n", "            ", "step", "=", "self", ".", "_step", "\n", "\n", "", "if", "current_sparsity", "==", "-", "1", ":", "\n", "            ", "current_sparsity", "=", "self", ".", "cumulative_sparsity", "(", "step", "-", "self", ".", "interval", ")", "\n", "\n", "# Threshold by 0", "\n", "", "self", ".", "current_prune_rate", "=", "max", "(", "self", ".", "cumulative_sparsity", "(", "step", ")", "-", "current_sparsity", ",", "0", ")", "\n", "\n", "step", "+=", "1", "\n", "self", ".", "_step", "=", "step", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.get_dr": [[157, 159], ["None"], "methods", ["None"], ["", "def", "get_dr", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "current_prune_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay._decay_test": [[161, 181], ["decay.MagnitudePruneDecay", "range", "plt.plot", "plt.show", "plt.plot", "plt.show", "i_ll.append", "decay.MagnitudePruneDecay.step", "prune_rate.append", "sparsity.append", "decay.MagnitudePruneDecay.get_dr", "decay.MagnitudePruneDecay.cumulative_sparsity"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density.plot", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.layer_wise_density.plot", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.step", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.get_dr", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.cumulative_sparsity"], ["", "", "def", "_decay_test", "(", ")", ":", "\n", "    ", "from", "matplotlib", "import", "pyplot", "as", "plt", "\n", "\n", "decay", "=", "MagnitudePruneDecay", "(", "\n", "initial_sparsity", "=", "0.0", ",", "final_sparsity", "=", "0.8", ",", "T_max", "=", "65000", ",", "T_start", "=", "700", ",", "interval", "=", "100", "\n", ")", "\n", "\n", "prune_rate", "=", "[", "]", "\n", "sparsity", "=", "[", "]", "\n", "i_ll", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "65000", ",", "100", ")", ":", "\n", "        ", "i_ll", ".", "append", "(", "i", ")", "\n", "decay", ".", "step", "(", "i", ")", "\n", "prune_rate", ".", "append", "(", "decay", ".", "get_dr", "(", ")", ")", "\n", "sparsity", ".", "append", "(", "decay", ".", "cumulative_sparsity", "(", "i", ")", ")", "\n", "\n", "", "plt", ".", "plot", "(", "i_ll", ",", "sparsity", ")", "\n", "plt", ".", "show", "(", ")", "\n", "plt", ".", "plot", "(", "i_ll", ",", "prune_rate", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.init_scheme._remove_fc_adjust_density": [[15, 38], ["enumerate", "masking.module.named_modules", "isinstance", "isinstance", "masking.remove_weight", "logging.info", "module.weight.numel", "module.weight.numel", "module.weight.numel"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.remove_weight"], ["def", "_remove_fc_adjust_density", "(", "masking", ":", "\"Masking\"", ")", ":", "\n", "    ", "\"\"\"\n    Remove fully connected layers from masking\n    (make it dense)\n    and lower density of remaining layers to\n    retain previous density.\n    \"\"\"", "\n", "n_fc", "=", "0", "\n", "n_conv", "=", "0", "\n", "\n", "for", "i", ",", "(", "name", ",", "module", ")", "in", "enumerate", "(", "masking", ".", "module", ".", "named_modules", "(", ")", ")", ":", "\n", "        ", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", ":", "\n", "            ", "masking", ".", "remove_weight", "(", "name", ")", "\n", "logging", ".", "info", "(", "\n", "f\"Removing layer {name} of size {module.weight.numel()} parameters.\"", "\n", ")", "\n", "n_fc", "+=", "module", ".", "weight", ".", "numel", "(", ")", "\n", "continue", "\n", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "n_conv", "+=", "module", ".", "weight", ".", "numel", "(", ")", "\n", "\n", "", "", "masking", ".", "density", "=", "(", "masking", ".", "density", "*", "(", "n_conv", "+", "n_fc", ")", "-", "n_fc", ")", "/", "n_conv", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.init_scheme.get_erdos_renyi_dist": [[40, 145], ["set", "masking.module.named_parameters", "masking.mask_dict.items", "numpy.max", "numpy.prod", "int", "int", "list", "raw_probabilities.items", "raw_probabilities.values", "logging.info", "set.add", "numpy.sum", "numpy.prod"], "function", ["None"], ["", "def", "get_erdos_renyi_dist", "(", "\n", "masking", ":", "\"Masking\"", ",", "is_kernel", ":", "bool", "=", "True", "\n", ")", "->", "\"Dict[str, float]\"", ":", "\n", "    ", "\"\"\"\n    Get layer-wise densities distributed according to\n    ER or ERK (erdos-renyi or erdos-renyi-kernel).\n\n    Ensures resulting densities do not cross 1\n    for any layer.\n\n    :param masking: Masking instance\n    :param is_kernel: use ERK (True), ER (False)\n    :return: Layer-wise density dict\n    \"\"\"", "\n", "# Same as Erdos Renyi with modification for conv", "\n", "# initialization used in sparse evolutionary training", "\n", "# scales the number of non-zero weights linearly proportional", "\n", "# to the product of all dimensions, that is input*output", "\n", "# for fully connected layers, and h*w*in_c*out_c for conv", "\n", "# layers.", "\n", "_erk_power_scale", "=", "1.0", "\n", "\n", "epsilon", "=", "1.0", "\n", "is_epsilon_valid", "=", "False", "\n", "# # The following loop will terminate worst case when all masks are in the", "\n", "# custom_sparsity_map. This should probably never happen though, since once", "\n", "# we have a single variable or more with the same constant, we have a valid", "\n", "# epsilon. Note that for each iteration we add at least one variable to the", "\n", "# custom_sparsity_map and therefore this while loop should terminate.", "\n", "_dense_layers", "=", "set", "(", ")", "\n", "while", "not", "is_epsilon_valid", ":", "\n", "# We will start with all layers and try to find right epsilon. However if", "\n", "# any probablity exceeds 1, we will make that layer dense and repeat the", "\n", "# process (finding epsilon) with the non-dense layers.", "\n", "# We want the total number of connections to be the same. Let say we have", "\n", "# for layers with N_1, ..., N_4 parameters each. Let say after some", "\n", "# iterations probability of some dense layers (3, 4) exceeded 1 and", "\n", "# therefore we added them to the dense_layers set. Those layers will not", "\n", "# scale with erdos_renyi, however we need to count them so that target", "\n", "# paratemeter count is achieved. See below.", "\n", "# eps * (p_1 * N_1 + p_2 * N_2) + (N_3 + N_4) =", "\n", "#    (1 - default_sparsity) * (N_1 + N_2 + N_3 + N_4)", "\n", "# eps * (p_1 * N_1 + p_2 * N_2) =", "\n", "#    (1 - default_sparsity) * (N_1 + N_2) - default_sparsity * (N_3 + N_4)", "\n", "# eps = rhs / (\\sum_i p_i * N_i) = rhs / divisor.", "\n", "\n", "        ", "divisor", "=", "0", "\n", "rhs", "=", "0", "\n", "raw_probabilities", "=", "{", "}", "\n", "for", "name", ",", "mask", "in", "masking", ".", "mask_dict", ".", "items", "(", ")", ":", "\n", "            ", "n_param", "=", "np", ".", "prod", "(", "mask", ".", "shape", ")", "\n", "n_zeros", "=", "int", "(", "n_param", "*", "(", "1", "-", "masking", ".", "density", ")", ")", "\n", "n_ones", "=", "int", "(", "n_param", "*", "masking", ".", "density", ")", "\n", "\n", "if", "name", "in", "_dense_layers", ":", "\n", "# See `- default_sparsity * (N_3 + N_4)` part of the equation above.", "\n", "                ", "rhs", "-=", "n_zeros", "\n", "\n", "", "else", ":", "\n", "# Corresponds to `(1 - default_sparsity) * (N_1 + N_2)` part of the", "\n", "# equation above.", "\n", "                ", "rhs", "+=", "n_ones", "\n", "\n", "if", "is_kernel", ":", "\n", "# Erdos-Renyi probability: epsilon * (n_in + n_out / n_in * n_out).", "\n", "                    ", "raw_probabilities", "[", "name", "]", "=", "(", "\n", "np", ".", "sum", "(", "mask", ".", "shape", ")", "/", "np", ".", "prod", "(", "mask", ".", "shape", ")", "\n", ")", "**", "_erk_power_scale", "\n", "# Note that raw_probabilities[mask] * n_param gives the individual", "\n", "# elements of the divisor.", "\n", "", "else", ":", "\n", "# Cin and Cout for a conv kernel", "\n", "                    ", "n_in", ",", "n_out", "=", "mask", ".", "shape", "[", ":", "2", "]", "\n", "raw_probabilities", "[", "name", "]", "=", "(", "n_in", "+", "n_out", ")", "/", "(", "n_in", "*", "n_out", ")", "\n", "", "divisor", "+=", "raw_probabilities", "[", "name", "]", "*", "n_param", "\n", "# By multipliying individual probabilites with epsilon, we should get the", "\n", "# number of parameters per layer correctly.", "\n", "", "", "epsilon", "=", "rhs", "/", "divisor", "\n", "# If epsilon * raw_probabilities[mask.name] > 1. We set the sparsities of that", "\n", "# mask to 0., so they become part of dense_layers sets.", "\n", "max_prob", "=", "np", ".", "max", "(", "list", "(", "raw_probabilities", ".", "values", "(", ")", ")", ")", "\n", "max_prob_one", "=", "max_prob", "*", "epsilon", "\n", "if", "max_prob_one", ">", "1", ":", "\n", "            ", "is_epsilon_valid", "=", "False", "\n", "for", "mask_name", ",", "mask_raw_prob", "in", "raw_probabilities", ".", "items", "(", ")", ":", "\n", "                ", "if", "mask_raw_prob", "==", "max_prob", ":", "\n", "                    ", "logging", ".", "info", "(", "f\"Density of layer:{mask_name} set to 1.0\"", ")", "\n", "_dense_layers", ".", "add", "(", "mask_name", ")", "\n", "", "", "", "else", ":", "\n", "            ", "is_epsilon_valid", "=", "True", "\n", "\n", "", "", "prob_dict", "=", "{", "}", "\n", "# With the valid epsilon, we can set sparsities of the remaning layers.", "\n", "for", "name", ",", "weight", "in", "masking", ".", "module", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "name", "not", "in", "masking", ".", "mask_dict", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "name", "in", "_dense_layers", ":", "\n", "            ", "prob", "=", "1.0", "\n", "", "else", ":", "\n", "            ", "prob", "=", "epsilon", "*", "raw_probabilities", "[", "name", "]", "\n", "\n", "", "prob_dict", "[", "name", "]", "=", "prob", "\n", "\n", "", "return", "prob_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.init_scheme.erdos_renyi_init": [[147, 159], ["init_scheme.get_erdos_renyi_dist", "masking.module.named_parameters", "logging.debug", "weight.numel", "torch.rand"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.init_scheme.get_erdos_renyi_dist"], ["", "def", "erdos_renyi_init", "(", "masking", ":", "\"Masking\"", ",", "is_kernel", ":", "bool", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "prob_dict", "=", "get_erdos_renyi_dist", "(", "masking", ",", "is_kernel", ")", "\n", "\n", "for", "name", ",", "weight", "in", "masking", ".", "module", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "name", "not", "in", "masking", ".", "mask_dict", ":", "\n", "            ", "continue", "\n", "", "prob", "=", "prob_dict", "[", "name", "]", "\n", "logging", ".", "debug", "(", "f\"ERK {name}: {weight.shape} prob {prob:.4f}\"", ")", "\n", "\n", "masking", ".", "mask_dict", "[", "name", "]", "=", "(", "torch", ".", "rand", "(", "weight", ".", "shape", ")", "<", "prob", ")", ".", "float", "(", ")", ".", "data", "\n", "masking", ".", "baseline_nonzero", "+=", "(", "masking", ".", "mask_dict", "[", "name", "]", "!=", "0", ")", ".", "sum", "(", ")", ".", "int", "(", ")", ".", "item", "(", ")", "\n", "masking", ".", "total_params", "+=", "weight", ".", "numel", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.init_scheme.lottery_ticket_init": [[161, 185], ["lottery_mask_path.is_file", "torch.load", "setattr", "masking.module.named_parameters", "logging.info", "masking.mask_dict[].sum().int().item", "weight.numel", "sparselearning.utils.ops.random_perm", "masking.mask_dict[].sum().int", "masking.mask_dict[].sum"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.ops.random_perm"], ["", "", "def", "lottery_ticket_init", "(", "\n", "masking", ":", "\"Masking\"", ",", "lottery_mask_path", ":", "\"Path\"", ",", "shuffle", ":", "bool", "=", "False", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Shuffle: use layer wise densities, but not exact mask\n    \"\"\"", "\n", "assert", "lottery_mask_path", ".", "is_file", "(", ")", ",", "f\"No .pth file at {lottery_mask_path}\"", "\n", "state_dict", "=", "torch", ".", "load", "(", "lottery_mask_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "assert", "\"mask\"", "in", "state_dict", ",", "f\"No mask found at {lottery_mask_path}\"", "\n", "setattr", "(", "masking", ",", "\"masks\"", ",", "state_dict", "[", "\"mask\"", "]", "[", "\"masks\"", "]", ")", "\n", "\n", "for", "name", ",", "weight", "in", "masking", ".", "module", ".", "named_parameters", "(", ")", ":", "\n", "# Skip modules we arent masking", "\n", "        ", "if", "name", "not", "in", "masking", ".", "mask_dict", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "shuffle", ":", "\n", "            ", "masking", ".", "mask_dict", "[", "name", "]", "=", "random_perm", "(", "masking", ".", "mask_dict", "[", "name", "]", ")", "\n", "\n", "", "masking", ".", "baseline_nonzero", "+=", "masking", ".", "mask_dict", "[", "name", "]", ".", "sum", "(", ")", ".", "int", "(", ")", ".", "item", "(", ")", "\n", "masking", ".", "total_params", "+=", "weight", ".", "numel", "(", ")", "\n", "\n", "", "logging", ".", "info", "(", "\n", "f\"Loaded mask from {lottery_mask_path} with density: {masking.baseline_nonzero/masking.total_params}\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.init_scheme.random_init": [[188, 213], ["enumerate", "masking.module.named_parameters", "logging.debug", "masking.mask_dict[].sum().int().item", "weight.numel", "masking.remove_weight", "logging.info", "masking.mask_dict[].sum().int", "weight.numel", "torch.rand", "masking.mask_dict[].sum"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.remove_weight"], ["", "def", "random_init", "(", "masking", ":", "\"Masking\"", ",", "**", "kwargs", ")", ":", "\n", "# initializes each layer with a random percentage of dense weights", "\n", "# each layer will have weight.numel()*density weights.", "\n", "# weight.numel()*density == weight.numel()*(1.0-sparsity)", "\n", "\n", "    ", "for", "e", ",", "(", "name", ",", "weight", ")", "in", "enumerate", "(", "masking", ".", "module", ".", "named_parameters", "(", ")", ")", ":", "\n", "# In random init, skip first layer", "\n", "        ", "if", "e", "==", "0", ":", "\n", "            ", "masking", ".", "remove_weight", "(", "name", ")", "\n", "logging", ".", "info", "(", "\n", "f\"Removing (first layer) {name} of size {weight.numel()} parameters.\"", "\n", ")", "\n", "continue", "\n", "\n", "# Skip modules we arent masking", "\n", "", "if", "name", "not", "in", "masking", ".", "mask_dict", ":", "\n", "            ", "continue", "\n", "\n", "", "logging", ".", "debug", "(", "\n", "f\"Structured Random {name}: {weight.shape} prob {masking.density:.4f}\"", "\n", ")", "\n", "\n", "masking", ".", "mask_dict", "[", "name", "]", "=", "(", "torch", ".", "rand", "(", "weight", ".", "shape", ")", "<", "masking", ".", "density", ")", ".", "float", "(", ")", ".", "data", "\n", "masking", ".", "baseline_nonzero", "+=", "masking", ".", "mask_dict", "[", "name", "]", ".", "sum", "(", ")", ".", "int", "(", ")", ".", "item", "(", ")", "\n", "masking", ".", "total_params", "+=", "weight", ".", "numel", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.init_scheme.resume_init": [[215, 233], ["masking.module.named_parameters", "logging.info", "masking.mask_dict[].sum().int().item", "weight.numel", "logging.debug", "masking.mask_dict[].sum().int", "masking.mask_dict[].sum", "weight.numel"], "function", ["None"], ["", "", "def", "resume_init", "(", "masking", ":", "\"Masking\"", ",", "**", "kwargs", ")", ":", "\n", "# Initializes the mask according to the weights", "\n", "# which are currently zero-valued. This is required", "\n", "# if you want to resume a sparse model but did not", "\n", "# save the mask.", "\n", "    ", "for", "name", ",", "weight", "in", "masking", ".", "module", ".", "named_parameters", "(", ")", ":", "\n", "# Skip modules we arent masking", "\n", "        ", "if", "name", "not", "in", "masking", ".", "mask_dict", ":", "\n", "            ", "continue", "\n", "\n", "", "masking", ".", "mask_dict", "[", "name", "]", "=", "(", "weight", "!=", "0.0", ")", ".", "float", "(", ")", ".", "data", "\n", "masking", ".", "baseline_nonzero", "+=", "masking", ".", "mask_dict", "[", "name", "]", ".", "sum", "(", ")", ".", "int", "(", ")", ".", "item", "(", ")", "\n", "masking", ".", "total_params", "+=", "weight", ".", "numel", "(", ")", "\n", "logging", ".", "debug", "(", "\n", "f\"{name} shape : {weight.shape} non-zero: {(weight != 0.0).sum().int().item()} density: {(weight != 0.0).sum().int().item() / weight.numel()}\"", "\n", ")", "\n", "\n", "", "logging", ".", "info", "(", "f\"Overall sparsity {masking.baseline_nonzero / masking.total_params}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.init_scheme.struct_erdos_renyi_init": [[235, 257], ["init_scheme._remove_fc_adjust_density", "init_scheme.get_erdos_renyi_dist", "enumerate", "masking.module.named_parameters", "logging.debug", "einops.repeat", "masking.mask_dict[].sum().int().item", "weight.numel", "masking.mask_dict[].sum().int", "torch.rand", "masking.mask_dict[].sum"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.init_scheme._remove_fc_adjust_density", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.init_scheme.get_erdos_renyi_dist"], ["", "def", "struct_erdos_renyi_init", "(", "masking", ":", "\"Masking\"", ",", "is_kernel", ":", "bool", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "_remove_fc_adjust_density", "(", "masking", ")", "\n", "\n", "prob_dict", "=", "get_erdos_renyi_dist", "(", "masking", ",", "is_kernel", ")", "\n", "\n", "for", "i", ",", "(", "name", ",", "weight", ")", "in", "enumerate", "(", "masking", ".", "module", ".", "named_parameters", "(", ")", ")", ":", "\n", "# Skip modules we arent masking", "\n", "        ", "if", "name", "not", "in", "masking", ".", "mask_dict", ":", "\n", "            ", "continue", "\n", "\n", "", "prob", "=", "prob_dict", "[", "name", "]", "\n", "logging", ".", "debug", "(", "f\"Structured ERK {name}: {weight.shape} prob {prob:.4f}\"", ")", "\n", "\n", "# Allocate channel wise", "\n", "c_in", ",", "c_out", ",", "h", ",", "w", "=", "weight", ".", "shape", "\n", "A", "=", "(", "torch", ".", "rand", "(", "c_in", ",", "c_out", ",", "1", ",", "1", ")", "<", "prob", ")", ".", "float", "(", ")", "\n", "A", "=", "repeat", "(", "A", ",", "f\"c_in c_out 1 1 -> c_in c_out {h} {w}\"", ")", "\n", "\n", "masking", ".", "mask_dict", "[", "name", "]", "=", "A", "\n", "\n", "masking", ".", "baseline_nonzero", "+=", "masking", ".", "mask_dict", "[", "name", "]", ".", "sum", "(", ")", ".", "int", "(", ")", ".", "item", "(", ")", "\n", "masking", ".", "total_params", "+=", "weight", ".", "numel", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.init_scheme.struct_random_init": [[259, 280], ["init_scheme._remove_fc_adjust_density", "enumerate", "masking.module.named_parameters", "logging.debug", "einops.repeat", "masking.mask_dict[].sum().int().item", "weight.numel", "masking.mask_dict[].sum().int", "torch.rand", "masking.mask_dict[].sum"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.init_scheme._remove_fc_adjust_density"], ["", "", "def", "struct_random_init", "(", "masking", ":", "\"Masking\"", ",", "**", "kwargs", ")", ":", "\n", "    ", "_remove_fc_adjust_density", "(", "masking", ")", "\n", "\n", "for", "i", ",", "(", "name", ",", "weight", ")", "in", "enumerate", "(", "masking", ".", "module", ".", "named_parameters", "(", ")", ")", ":", "\n", "# Skip modules we arent masking", "\n", "        ", "if", "name", "not", "in", "masking", ".", "mask_dict", ":", "\n", "            ", "continue", "\n", "\n", "", "logging", ".", "debug", "(", "\n", "f\"Structured Random {name}: {weight.shape} prob {masking.density:.4f}\"", "\n", ")", "\n", "\n", "# Allocate channel wise", "\n", "c_in", ",", "c_out", ",", "h", ",", "w", "=", "weight", ".", "shape", "\n", "A", "=", "(", "torch", ".", "rand", "(", "c_in", ",", "c_out", ",", "1", ",", "1", ")", "<", "masking", ".", "density", ")", ".", "float", "(", ")", "\n", "A", "=", "repeat", "(", "A", ",", "f\"c_in c_out 1 1 -> c_in c_out {h} {w}\"", ")", "\n", "\n", "masking", ".", "mask_dict", "[", "name", "]", "=", "A", "\n", "\n", "masking", ".", "baseline_nonzero", "+=", "masking", ".", "mask_dict", "[", "name", "]", ".", "sum", "(", ")", ".", "int", "(", ")", ".", "item", "(", ")", "\n", "masking", ".", "total_params", "+=", "weight", ".", "numel", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.redistribute.momentum_redistribution": [[19, 40], ["masking.get_momentum_for_weight", "torch.abs().mean().item", "torch.abs().mean", "torch.abs", "mask.bool"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.get_momentum_for_weight"], ["def", "momentum_redistribution", "(", "masking", ",", "name", ",", "weight", ",", "mask", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Calculates momentum redistribution statistics.\n\n    :param masking: Masking instance\n    :type masking: sparselearning.core.Masking\n    :param name: layer name\n    :type name: str\n    :param weight: layer weight\n    :type weight: torch.Tensor\n    :param mask: layer mask\n    :type mask: torch.Tensor\n    :return: Layer Statistic---unnormalized layer statistics\n            for the layer. Normalizing across layers gives\n            the density distribution.\n    :rtype: float\n    \"\"\"", "\n", "momentum", "=", "masking", ".", "get_momentum_for_weight", "(", "weight", ")", "\n", "\n", "mean_magnitude", "=", "torch", ".", "abs", "(", "momentum", "[", "mask", ".", "bool", "(", ")", "]", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "return", "mean_magnitude", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.redistribute.grad_redistribution": [[42, 62], ["torch.abs().mean().item", "torch.abs().mean", "torch.abs", "mask.bool"], "function", ["None"], ["", "def", "grad_redistribution", "(", "masking", ",", "name", ",", "weight", ",", "mask", ")", ":", "\n", "    ", "\"\"\"\n    Calculates gradient redistribution statistics.\n\n    :param masking: Masking instance\n    :type masking: sparselearning.core.Masking\n    :param name: layer name\n    :type name: str\n    :param weight: layer weight\n    :type weight: torch.Tensor\n    :param mask: layer mask\n    :type mask: torch.Tensor\n    :return: Layer Statistic---unnormalized layer statistics\n            for the layer. Normalizing across layers gives\n            the density distribution.\n    :rtype: float\n    \"\"\"", "\n", "grad", "=", "weight", ".", "grad", "\n", "mean_grad", "=", "torch", ".", "abs", "(", "grad", "[", "mask", ".", "bool", "(", ")", "]", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "return", "mean_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.redistribute.nonzero_redistribution": [[64, 87], ["None"], "function", ["None"], ["", "def", "nonzero_redistribution", "(", "masking", ",", "name", ",", "weight", ",", "mask", ")", ":", "\n", "    ", "\"\"\"\n    Calculates non-zero redistribution statistics.\n    Ideally, this just preserves the older distribution,\n    upto numerical error.\n    In practice, we prefer to skip redistribution if\n    non-zero is chosen.\n\n    :param masking: Masking instance\n    :type masking: sparselearning.core.Masking\n    :param name: layer name\n    :type name: str\n    :param weight: layer weight\n    :type weight: torch.Tensor\n    :param mask: layer mask\n    :type mask: torch.Tensor\n    :return: Layer Statistic---unnormalized layer statistics\n            for the layer. Normalizing across layers gives\n            the density distribution.\n    :rtype: float\n    \"\"\"", "\n", "nonzero", "=", "(", "weight", "!=", "0.0", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "nonzero", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.prune.magnitude_prune": [[24, 52], ["math.ceil", "torch.sort", "torch.abs", "mask.data.view", "weight.data.view"], "function", ["None"], ["", "def", "magnitude_prune", "(", "\n", "masking", ":", "\"Masking\"", ",", "mask", ":", "\"Tensor\"", ",", "weight", ":", "\"Tensor\"", ",", "name", ":", "str", "\n", ")", "->", "\"Tensor\"", ":", "\n", "    ", "\"\"\"\n    Prunes the weights with smallest magnitude.\n\n    :param masking: Masking instance\n    :type masking: sparselearning.core.Masking\n    :param mask: layer mask\n    :type mask: torch.Tensor\n    :param weight: layer weight\n    :type weight: torch.Tensor\n    :param name: layer name\n    :type name: str\n    :return: pruned mask\n    :rtype: torch.Tensor\n    \"\"\"", "\n", "num_remove", "=", "math", ".", "ceil", "(", "\n", "masking", ".", "name2prune_rate", "[", "name", "]", "*", "masking", ".", "stats", ".", "nonzeros_dict", "[", "name", "]", "\n", ")", "\n", "if", "num_remove", "==", "0.0", ":", "\n", "        ", "return", "mask", "\n", "", "num_zeros", "=", "masking", ".", "stats", ".", "zeros_dict", "[", "name", "]", "\n", "k", "=", "num_zeros", "+", "num_remove", "\n", "\n", "x", ",", "idx", "=", "torch", ".", "sort", "(", "torch", ".", "abs", "(", "weight", ".", "data", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "mask", ".", "data", ".", "view", "(", "-", "1", ")", "[", "idx", "[", ":", "k", "]", "]", "=", "0.0", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.prune.global_magnitude_prune": [[54, 105], ["math.ceil", "int", "masking.module.named_parameters", "abs", "masking.module.named_parameters", "torch.abs", "torch.abs"], "function", ["None"], ["", "def", "global_magnitude_prune", "(", "masking", ":", "\"Masking\"", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Global Magnitude (L1) pruning. Modifies in-place.\n\n    :param masking: Masking instance\n    :type masking: sparselearning.core.Masking\n    :return: number of weights removed\n    :rtype: int\n    \"\"\"", "\n", "tokill", "=", "math", ".", "ceil", "(", "masking", ".", "prune_rate", "*", "masking", ".", "baseline_nonzero", ")", "\n", "if", "tokill", "<=", "0", ":", "\n", "        ", "return", "0", "\n", "", "total_removed", "=", "0", "\n", "prev_removed", "=", "0", "\n", "\n", "if", "tokill", ":", "\n", "        ", "increment", "=", "masking", ".", "increment", "\n", "tries_before_breaking", "=", "10", "\n", "tries", "=", "0", "\n", "\n", "while", "abs", "(", "total_removed", "-", "tokill", ")", ">", "tokill", "*", "masking", ".", "tolerance", ":", "\n", "            ", "total_removed", "=", "0", "\n", "for", "name", ",", "weight", "in", "masking", ".", "module", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "name", "not", "in", "masking", ".", "mask_dict", ":", "\n", "                    ", "continue", "\n", "", "remain", "=", "(", "torch", ".", "abs", "(", "weight", ".", "data", ")", ">", "masking", ".", "prune_threshold", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "total_removed", "+=", "masking", ".", "stats", ".", "nonzeros_dict", "[", "name", "]", "-", "remain", "\n", "\n", "", "if", "prev_removed", "==", "total_removed", ":", "\n", "                ", "tries", "+=", "1", "\n", "if", "tries", "==", "tries_before_breaking", ":", "\n", "                    ", "break", "\n", "", "", "else", ":", "\n", "                ", "tries", "=", "0", "\n", "\n", "", "prev_removed", "=", "total_removed", "\n", "if", "total_removed", ">", "tokill", "*", "(", "1.0", "+", "masking", ".", "tolerance", ")", ":", "\n", "                ", "masking", ".", "prune_threshold", "*=", "1.0", "-", "increment", "\n", "increment", "*=", "0.99", "\n", "", "elif", "total_removed", "<", "tokill", "*", "(", "1.0", "-", "masking", ".", "tolerance", ")", ":", "\n", "                ", "masking", ".", "prune_threshold", "*=", "1.0", "+", "increment", "\n", "increment", "*=", "0.99", "\n", "\n", "", "", "for", "name", ",", "weight", "in", "masking", ".", "module", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "name", "not", "in", "masking", ".", "mask_dict", ":", "\n", "                ", "continue", "\n", "", "masking", ".", "mask_dict", "[", "name", "]", "[", ":", "]", "=", "(", "\n", "torch", ".", "abs", "(", "weight", ".", "data", ")", ">", "masking", ".", "prune_threshold", "\n", ")", "\n", "\n", "", "", "return", "int", "(", "total_removed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.prune.struct_magnitude_prune": [[107, 155], ["math.ceil", "int", "criterion", "torch.sort", "einops.rearrange", "torch.abs", "mask.data.view", "criterion.view"], "function", ["None"], ["", "def", "struct_magnitude_prune", "(", "\n", "masking", ":", "\"Masking\"", ",", "\n", "mask", ":", "\"Tensor\"", ",", "\n", "weight", ":", "\"Tensor\"", ",", "\n", "name", ":", "str", ",", "\n", "criterion", ":", "Callable", "=", "torch", ".", "mean", ",", "\n", ")", "->", "\"Tensor\"", ":", "\n", "    ", "\"\"\"\n    Prunes the weights channel-wise,\n    with reduced smallest magnitude.\n\n    :param masking: Masking instance\n    :type masking: sparselearning.core.Masking\n    :param mask: layer mask\n    :type mask: torch.Tensor\n    :param weight: layer weight\n    :type weight: torch.Tensor\n    :param name: layer name\n    :type name: str\n    :param criterion: determines reduction function.\n        (reduces a kernel to a single statisitc,\n        eg: mean/max/min).\n    :type criterion: Callable\n    :return: pruned mask\n    :rtype: torch.Tensor\n    \"\"\"", "\n", "c_in", ",", "c_out", ",", "h", ",", "w", "=", "weight", ".", "shape", "\n", "\n", "kernel_size", "=", "h", "*", "w", "\n", "\n", "num_remove", "=", "math", ".", "ceil", "(", "\n", "masking", ".", "name2prune_rate", "[", "name", "]", "*", "masking", ".", "stats", ".", "nonzeros_dict", "[", "name", "]", "/", "kernel_size", "\n", ")", "\n", "\n", "if", "num_remove", "==", "0.0", ":", "\n", "        ", "return", "mask", "\n", "\n", "", "num_zeros", "=", "masking", ".", "stats", ".", "zeros_dict", "[", "name", "]", "/", "kernel_size", "\n", "k", "=", "int", "(", "num_zeros", "+", "num_remove", ")", "\n", "\n", "reduced", "=", "criterion", "(", "\n", "rearrange", "(", "weight", ".", "data", ",", "\"c_in c_out h w -> c_in c_out (h w)\"", ")", ",", "dim", "=", "-", "1", "\n", ")", "\n", "\n", "x", ",", "idx", "=", "torch", ".", "sort", "(", "torch", ".", "abs", "(", "reduced", ".", "view", "(", "-", "1", ")", ")", ")", "\n", "\n", "mask", ".", "data", ".", "view", "(", "-", "1", ",", "h", ",", "w", ")", "[", "idx", "[", ":", "k", "]", ",", ":", ",", ":", "]", "=", "0.0", "\n", "return", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_data.test_splitter": [[18, 29], ["torch.rand", "torch.rand", "torch.utils.data.TensorDataset", "pytest.raises", "data.DatasetSplitter", "print", "slice"], "function", ["None"], ["def", "test_splitter", "(", ")", ":", "\n", "    ", "\"\"\"\n    Test data splitting using DatasetSplitter\n    \"\"\"", "\n", "train_x", "=", "torch", ".", "rand", "(", "10", ",", "3", ",", "32", ",", "32", ")", "\n", "train_y", "=", "torch", ".", "rand", "(", "10", ",", "10", ")", "\n", "dataset", "=", "TensorDataset", "(", "train_x", ",", "train_y", ")", "\n", "with", "pytest", ".", "raises", "(", "Exception", ")", "as", "e_info", ":", "\n", "# Should raise Value error on slice", "\n", "        ", "DatasetSplitter", "(", "dataset", ",", "slice", "(", "3", ",", "1", ")", ")", "\n", "print", "(", "e_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_data.test_registry": [[31, 40], ["pytest.mark.parametrize", "pathlib.Path"], "function", ["None"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"dataset\"", ",", "[", "\"CIFAR10\"", ",", "\"CIFAR100\"", ",", "\"MNIST\"", "]", ")", "\n", "def", "test_registry", "(", "dataset", ")", ":", "\n", "    ", "\"\"\"\n    Test get_dataset functions\n\n    :param dataset: Dataset to use\n    :type dataset: str\n    \"\"\"", "\n", "full_dataset", ",", "test_dataset", "=", "registry", "[", "dataset", "]", "(", "root", "=", "Path", "(", "f\"datasets/{dataset}\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_data._loader_loop": [[42, 49], ["tqdm.tqdm", "len", "len"], "function", ["None"], ["", "def", "_loader_loop", "(", "loader", ")", ":", "\n", "    ", "\"\"\"\n    Test dataloader\n    \"\"\"", "\n", "for", "x", ",", "y", "in", "tqdm", "(", "loader", ")", ":", "\n", "        ", "assert", "len", "(", "x", ".", "shape", ")", "==", "4", "# NCHWW", "\n", "assert", "len", "(", "y", ".", "shape", ")", "==", "1", "# class ID", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_data.test_get_loaders": [[51, 71], ["pytest.mark.parametrize", "logging.info", "data.get_dataloaders", "logging.info", "test_data._loader_loop"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.None.data.get_dataloaders", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_data._loader_loop"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"dataset\"", ",", "[", "\"CIFAR10\"", ",", "\"CIFAR100\"", ",", "\"MNIST\"", "]", ")", "\n", "def", "test_get_loaders", "(", "dataset", ")", ":", "\n", "    ", "\"\"\"\n    Test dataloader\n\n    :param dataset: Dataset to use\n    :type dataset: str\n    \"\"\"", "\n", "logging", ".", "info", "(", "f\"Loading dataloaders for {dataset}\"", ")", "\n", "loaders", "=", "get_dataloaders", "(", "\n", "dataset", ",", "\n", "root", "=", "f\"datasets/{dataset}\"", ",", "\n", "batch_size", "=", "128", ",", "\n", "test_batch_size", "=", "128", ",", "\n", "validation_split", "=", "0.1", ",", "\n", "fixed_shuffle", "=", "True", ",", "\n", ")", "\n", "logging", ".", "info", "(", "f\"Looping through dataset {dataset}\"", ")", "\n", "for", "loader", "in", "loaders", ":", "\n", "        ", "_loader_loop", "(", "loader", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_mask_loading_saving._save": [[14, 24], ["pathlib.Path", "pathlib.Path.parent.mkdir", "torch.save", "model.state_dict", "mask.state_dict", "optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.state_dict", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.state_dict", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.state_dict"], ["", "def", "_save", "(", "model", ":", "\"nn.Module\"", ",", "optimizer", ":", "\"optim\"", ",", "mask", ":", "\"Masking\"", ",", "step", ":", "int", ")", ":", "\n", "    ", "state_dict", "=", "{", "\n", "\"step\"", ":", "step", ",", "\n", "\"model\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"mask\"", ":", "mask", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", "save_path", "=", "Path", "(", "f\"/tmp/tests/test_save_{step}.pth\"", ")", "\n", "save_path", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ",", "parents", "=", "True", ")", "\n", "torch", ".", "save", "(", "state_dict", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_mask_loading_saving._load": [[26, 36], ["pathlib.Path", "torch.load", "mask.load_state_dict", "model.load_state_dict", "optimizer.load_state_dict"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.model_serialization.load_state_dict", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.model_serialization.load_state_dict", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.utils.model_serialization.load_state_dict"], ["", "def", "_load", "(", "model", ":", "\"nn.Module\"", ",", "optimizer", ":", "\"optim\"", ",", "mask", ":", "\"Masking\"", ",", "step", ":", "int", ")", ":", "\n", "    ", "save_path", "=", "Path", "(", "f\"/tmp/tests/test_save_{step}.pth\"", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "save_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "\n", "step", "=", "state_dict", "[", "\"step\"", "]", "\n", "mask", ".", "load_state_dict", "(", "state_dict", "[", "\"mask\"", "]", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", "[", "\"model\"", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "state_dict", "[", "\"optimizer\"", "]", ")", "\n", "\n", "return", "model", ",", "optimizer", ",", "mask", ",", "step", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_mask_loading_saving.test_save_load": [[38, 92], ["models.wide_resnet.WideResNet", "torch.optim.SGD", "sparselearning.funcs.decay.CosineDecay", "sparselearning.core.Masking", "sparselearning.core.Masking.add_module", "test_mask_loading_saving._save", "test_mask_loading_saving._load", "range", "test_mask_loading_saving._save", "test_mask_loading_saving._load", "models.wide_resnet.WideResNet", "torch.optim.SGD", "sparselearning.funcs.decay.CosineDecay", "sparselearning.core.Masking", "sparselearning.core.Masking.add_module", "models.wide_resnet.WideResNet.parameters", "torch.rand", "models.wide_resnet.WideResNet.", "torch.nn.functional.mse_loss", "F.mse_loss.backward", "print", "models.wide_resnet.WideResNet.parameters", "torch.zeros_like", "sparselearning.core.Masking.update_connections", "sparselearning.core.Masking.step"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.add_module", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_mask_loading_saving._save", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_mask_loading_saving._load", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_mask_loading_saving._save", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_mask_loading_saving._load", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.add_module", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.update_connections", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.step"], ["", "def", "test_save_load", "(", ")", ":", "\n", "    ", "\"\"\"\n    1. Initialise\n    2. Save\n    3. Load\n        Assert if equal\n    4. Perform optim step\n    \"\"\"", "\n", "# Initialise", "\n", "model", "=", "WideResNet", "(", "depth", "=", "22", ",", "widen_factor", "=", "2", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ",", "momentum", "=", "0.9", ")", "\n", "\n", "decay", "=", "CosineDecay", "(", ")", "\n", "mask", "=", "Masking", "(", "optimizer", ",", "decay", ")", "\n", "mask", ".", "add_module", "(", "model", ")", "\n", "\n", "step", "=", "0", "\n", "\n", "_save", "(", "model", ",", "optimizer", ",", "mask", ",", "step", ")", "\n", "new_model", ",", "new_optimizer", ",", "new_mask", ",", "new_step", "=", "_load", "(", "model", ",", "optimizer", ",", "mask", ",", "step", ")", "\n", "\n", "assert", "new_step", "==", "step", "\n", "assert", "new_model", "==", "model", "\n", "assert", "new_mask", "==", "mask", "\n", "\n", "for", "step", "in", "range", "(", "5", ")", ":", "\n", "        ", "dummy_input", "=", "torch", ".", "rand", "(", "1", ",", "3", ",", "32", ",", "32", ")", "\n", "output", "=", "model", "(", "dummy_input", ")", "\n", "loss", "=", "F", ".", "mse_loss", "(", "output", ",", "torch", ".", "zeros_like", "(", "output", ")", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "assert", "model", "==", "mask", ".", "module", "\n", "\n", "print", "(", "f\"Loss {loss}\"", ")", "\n", "\n", "if", "step", "==", "5", ":", "\n", "            ", "mask", ".", "update_connections", "(", ")", "\n", "", "else", ":", "\n", "            ", "mask", ".", "step", "(", ")", "\n", "\n", "", "", "_save", "(", "model", ",", "optimizer", ",", "mask", ",", "step", ")", "\n", "new_model", ",", "new_optimizer", ",", "new_mask", ",", "new_step", "=", "_load", "(", "model", ",", "optimizer", ",", "mask", ",", "step", ")", "\n", "\n", "assert", "new_step", "==", "step", "\n", "assert", "new_model", "==", "model", "\n", "assert", "new_mask", ".", "stats", ".", "total_density", "==", "mask", ".", "stats", ".", "total_density", "\n", "\n", "# Re-initialise", "\n", "model", "=", "WideResNet", "(", "depth", "=", "22", ",", "widen_factor", "=", "2", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ",", "momentum", "=", "0.9", ")", "\n", "\n", "decay", "=", "CosineDecay", "(", ")", "\n", "mask", "=", "Masking", "(", "optimizer", ",", "decay", ")", "\n", "mask", ".", "add_module", "(", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_struct_sparse.is_channel_sparse": [[14, 27], ["einops.repeat", "bool"], "function", ["None"], ["", "def", "is_channel_sparse", "(", "mask", ":", "\"Masking\"", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Checks if the conv mask is channel-wise sparse.\n\n    :param mask: Masking instance\n    :type mask: Masking\n    :return: True if channel-wise sparse\n    :rtype: bool\n    \"\"\"", "\n", "c_in", ",", "c_out", ",", "h", ",", "w", "=", "mask", ".", "shape", "\n", "\n", "blocked", "=", "repeat", "(", "mask", "[", ":", ",", ":", ",", "0", ",", "0", "]", ",", "\"c_in c_out -> c_in c_out h w\"", ",", "h", "=", "h", ",", "w", "=", "w", ")", "\n", "return", "bool", "(", "(", "blocked", "==", "mask", ")", ".", "all", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_struct_sparse.test_struct_init": [[29, 62], ["pytest.mark.parametrize", "model_class", "sparselearning.funcs.decay.CosineDecay", "torch.optim.SGD", "sparselearning.core.Masking", "sparselearning.core.Masking.add_module", "sparselearning.core.Masking.gather_statistics", "sparselearning.core.Masking.adjust_prune_rate", "sparselearning.core.Masking.mask_dict.values", "model_class.parameters", "test_struct_sparse.is_channel_sparse"], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.add_module", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.gather_statistics", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.adjust_prune_rate", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_struct_sparse.is_channel_sparse"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"init_scheme\"", ",", "\n", "[", "\n", "\"struct-erdos-renyi\"", ",", "\n", "\"struct-erdos-renyi-kernel\"", ",", "\n", "\"struct-random\"", ",", "\n", "]", ",", "\n", ")", "\n", "def", "test_struct_init", "(", "init_scheme", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Test structured sparsity for various init schemes\n\n    :param init_scheme: Random/ER/ERK\n    :type init_scheme: str\n    \"\"\"", "\n", "model_class", ",", "args", "=", "model_registry", "[", "\"resnet50\"", "]", "\n", "model", "=", "model_class", "(", "*", "args", ")", "\n", "decay", "=", "CosineDecay", "(", ")", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "0.2", ")", "\n", "\n", "masking", "=", "Masking", "(", "\n", "optimizer", ",", "\n", "decay", ",", "\n", "redistribution_mode", "=", "\"none\"", ",", "\n", "sparse_init", "=", "init_scheme", ",", "\n", "density", "=", "0.5", ",", "\n", ")", "\n", "masking", ".", "add_module", "(", "model", ")", "\n", "masking", ".", "gather_statistics", "(", ")", "\n", "masking", ".", "adjust_prune_rate", "(", ")", "\n", "\n", "for", "mask", "in", "masking", ".", "mask_dict", ".", "values", "(", ")", ":", "\n", "        ", "assert", "is_channel_sparse", "(", "mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_struct_sparse.test_struct_prune_growth": [[64, 110], ["pytest.mark.parametrize", "pytest.mark.parametrize", "model_class", "sparselearning.funcs.decay.CosineDecay", "torch.optim.SGD", "sparselearning.core.Masking", "sparselearning.core.Masking.add_module", "sparselearning.core.Masking.gather_statistics", "sparselearning.core.Masking.adjust_prune_rate", "torch.randn", "optim.SGD.zero_grad", "model_class.abs().mean", "model().abs().mean.backward", "sparselearning.core.Masking.step", "sparselearning.core.Masking.update_connections", "sparselearning.core.Masking.mask_dict.values", "model_class.parameters", "test_struct_sparse.is_channel_sparse", "model_class.abs", "model_class."], "function", ["home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.add_module", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.gather_statistics", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.adjust_prune_rate", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.funcs.decay.MagnitudePruneDecay.step", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.sparselearning.core.Masking.update_connections", "home.repos.pwc.inspect_result.varun19299_rigl-reproducibility.tests.test_struct_sparse.is_channel_sparse"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"prune_mode\"", ",", "[", "\"struct-magnitude-max\"", ",", "\"struct-magnitude-mean\"", "]", "\n", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\n", "\"growth_mode\"", ",", "[", "\"struct-absolute-gradient-min\"", ",", "\"struct-absolute-gradient-mean\"", "]", "\n", ")", "\n", "def", "test_struct_prune_growth", "(", "prune_mode", ",", "growth_mode", ")", ":", "\n", "    ", "\"\"\"\n    Test structured sparsity across prune, growth modes.\n    See sparselearning.funcs.prune,growth\n\n    :param prune_mode: prune mode\n    :type prune_mode: str\n    :param growth_mode: growth mode\n    :type growth_mode: str\n    \"\"\"", "\n", "model_class", ",", "args", "=", "model_registry", "[", "\"resnet50\"", "]", "\n", "model", "=", "model_class", "(", "*", "args", ")", "\n", "decay", "=", "CosineDecay", "(", ")", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "0.2", ")", "\n", "\n", "masking", "=", "Masking", "(", "\n", "optimizer", ",", "\n", "decay", ",", "\n", "redistribution_mode", "=", "\"none\"", ",", "\n", "sparse_init", "=", "\"struct-random\"", ",", "\n", "prune_mode", "=", "prune_mode", ",", "\n", "growth_mode", "=", "growth_mode", ",", "\n", "density", "=", "0.5", ",", "\n", ")", "\n", "\n", "masking", ".", "add_module", "(", "model", ")", "\n", "masking", ".", "gather_statistics", "(", ")", "\n", "masking", ".", "adjust_prune_rate", "(", ")", "\n", "\n", "inp", "=", "torch", ".", "randn", "(", "16", ",", "3", ",", "32", ",", "32", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "model", "(", "inp", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "masking", ".", "step", "(", ")", "\n", "masking", ".", "update_connections", "(", ")", "\n", "\n", "for", "mask", "in", "masking", ".", "mask_dict", ".", "values", "(", ")", ":", "\n", "        ", "assert", "is_channel_sparse", "(", "mask", ")", "\n", "", "", ""]]}