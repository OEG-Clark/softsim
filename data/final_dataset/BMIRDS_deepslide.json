{"home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split": [[15, 138], ["utils.get_subfolder_paths", "utils_split.split.write_to_csv"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.3_repiece_jpg_tiles.get_subfolder_paths"], ["def", "split", "(", "keep_orig_copy", ":", "bool", ",", "wsi_train", ":", "Path", ",", "wsi_val", ":", "Path", ",", "wsi_test", ":", "Path", ",", "\n", "classes", ":", "List", "[", "str", "]", ",", "all_wsi", ":", "Path", ",", "val_wsi_per_class", ":", "int", ",", "\n", "test_wsi_per_class", ":", "int", ",", "labels_train", ":", "Path", ",", "labels_test", ":", "Path", ",", "\n", "labels_val", ":", "Path", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Main function for splitting data. Note that we want the\n    validation and test sets to be balanced.\n\n    Args:\n        keep_orig_copy: Whether to move or copy the WSI when splitting into training, validation, and test sets.\n        wsi_train: Location to be created to store WSI for training.\n        wsi_val: Location to be created to store WSI for validation.\n        wsi_test: Location to be created to store WSI for testing.\n        classes: Names of the classes in the dataset.\n        all_wsi: Location of the WSI organized in subfolders by class.\n        val_wsi_per_class: Number of WSI per class to use in the validation set.\n        test_wsi_per_class: Number of WSI per class to use in the test set.\n        labels_train: Location to store the CSV file labels for training.\n        labels_test: Location to store the CSV file labels for testing.\n        labels_val: Location to store the CSV file labels for validation.\n    \"\"\"", "\n", "# Based on whether we want to move or keep the files.", "\n", "head", "=", "shutil", ".", "copyfile", "if", "keep_orig_copy", "else", "shutil", ".", "move", "\n", "\n", "# Create folders.", "\n", "for", "f", "in", "(", "wsi_train", ",", "wsi_val", ",", "wsi_test", ")", ":", "\n", "        ", "subfolders", "=", "[", "f", ".", "joinpath", "(", "_class", ")", "for", "_class", "in", "classes", "]", "\n", "\n", "for", "subfolder", "in", "subfolders", ":", "\n", "# Confirm the output directory exists.", "\n", "            ", "subfolder", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "", "train_img_to_label", "=", "{", "}", "\n", "val_img_to_label", "=", "{", "}", "\n", "test_img_to_label", "=", "{", "}", "\n", "\n", "def", "move_set", "(", "folder", ":", "Path", ",", "image_files", ":", "List", "[", "Path", "]", ",", "\n", "ops", ":", "shutil", ")", "->", "Dict", "[", "Path", ",", "str", "]", ":", "\n", "        ", "\"\"\"\n        Moves the sets to the desired output directories.\n\n        Args:\n            folder: Folder to move images to.\n            image_files: Image files to move.\n            ops: Whether to move or copy the files.\n\n        Return:\n            A dictionary mapping image filenames to classes.\n        \"\"\"", "\n", "def", "remove_topdir", "(", "filepath", ":", "Path", ")", "->", "Path", ":", "\n", "            ", "\"\"\"\n            Remove the top directory since the filepath needs to be\n            a relative path (i.e., a/b/c.jpg -> b/c.jpg).\n\n            Args:\n                filepath: Path to remove top directory from.\n\n            Returns:\n                Path with top directory removed.\n            \"\"\"", "\n", "return", "Path", "(", "*", "filepath", ".", "parts", "[", "1", ":", "]", ")", "\n", "\n", "", "img_to_label", "=", "{", "}", "\n", "for", "image_file", "in", "image_files", ":", "\n", "# Copy or move the files.", "\n", "            ", "ops", "(", "src", "=", "image_file", ",", "\n", "dst", "=", "folder", ".", "joinpath", "(", "remove_topdir", "(", "filepath", "=", "image_file", ")", ")", ")", "\n", "\n", "img_to_label", "[", "Path", "(", "image_file", ".", "name", ")", "]", "=", "image_file", ".", "parent", ".", "name", "\n", "\n", "", "return", "img_to_label", "\n", "\n", "# Sort the images and move/copy them appropriately.", "\n", "", "subfolder_paths", "=", "get_subfolder_paths", "(", "folder", "=", "all_wsi", ")", "\n", "for", "subfolder", "in", "subfolder_paths", ":", "\n", "        ", "image_paths", "=", "get_image_paths", "(", "folder", "=", "subfolder", ")", "\n", "\n", "# Make sure we have enough slides in each class.", "\n", "assert", "len", "(", "\n", "image_paths", "\n", ")", ">", "val_wsi_per_class", "+", "test_wsi_per_class", ",", "\"Not enough slides in each class.\"", "\n", "\n", "# Assign training, test, and validation images.", "\n", "test_idx", "=", "len", "(", "image_paths", ")", "-", "test_wsi_per_class", "\n", "val_idx", "=", "test_idx", "-", "val_wsi_per_class", "\n", "train_images", "=", "image_paths", "[", ":", "val_idx", "]", "\n", "val_images", "=", "image_paths", "[", "val_idx", ":", "test_idx", "]", "\n", "test_images", "=", "image_paths", "[", "test_idx", ":", "]", "\n", "print", "(", "f\"class {Path(subfolder).name} \"", "\n", "f\"#train={len(train_images)} \"", "\n", "f\"#val={len(val_images)} \"", "\n", "f\"#test={len(test_images)}\"", ")", "\n", "\n", "# Move the training images.", "\n", "train_img_to_label", ".", "update", "(", "\n", "move_set", "(", "folder", "=", "wsi_train", ",", "image_files", "=", "train_images", ",", "ops", "=", "head", ")", ")", "\n", "\n", "# Move the validation images.", "\n", "val_img_to_label", ".", "update", "(", "\n", "move_set", "(", "folder", "=", "wsi_val", ",", "image_files", "=", "val_images", ",", "ops", "=", "head", ")", ")", "\n", "\n", "# Move the testing images.", "\n", "test_img_to_label", ".", "update", "(", "\n", "move_set", "(", "folder", "=", "wsi_test", ",", "image_files", "=", "test_images", ",", "ops", "=", "head", ")", ")", "\n", "\n", "", "def", "write_to_csv", "(", "dest_filename", ":", "Path", ",", "\n", "image_label_dict", ":", "Dict", "[", "Path", ",", "str", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Write the image names and corresponding labels to a CSV file.\n\n        Args:\n            dest_filename: Destination filename for the CSV file.\n            image_label_dict: Dictionary mapping filenames to labels.\n        \"\"\"", "\n", "with", "dest_filename", ".", "open", "(", "mode", "=", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "\"img,gt\\n\"", ")", "\n", "for", "img", "in", "sorted", "(", "image_label_dict", ".", "keys", "(", ")", ")", ":", "\n", "                ", "writer", ".", "write", "(", "f\"{img},{image_label_dict[img]}\\n\"", ")", "\n", "\n", "", "", "", "write_to_csv", "(", "dest_filename", "=", "labels_train", ",", "\n", "image_label_dict", "=", "train_img_to_label", ")", "\n", "write_to_csv", "(", "dest_filename", "=", "labels_val", ",", "image_label_dict", "=", "val_img_to_label", ")", "\n", "write_to_csv", "(", "dest_filename", "=", "labels_test", ",", "image_label_dict", "=", "test_img_to_label", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.is_purple": [[28, 56], ["skimage.measure.block_reduce"], "function", ["None"], ["def", "is_purple", "(", "crop", ":", "np", ".", "ndarray", ",", "purple_threshold", ":", "int", ",", "\n", "purple_scale_size", ":", "int", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Determines if a given portion of an image is purple.\n\n    Args:\n        crop: Portion of the image to check for being purple.\n        purple_threshold: Number of purple points for region to be considered purple.\n        purple_scale_size: Scalar to use for reducing image to check for purple.\n\n    Returns:\n        A boolean representing whether the image is purple or not.\n    \"\"\"", "\n", "block_size", "=", "(", "crop", ".", "shape", "[", "0", "]", "//", "purple_scale_size", ",", "\n", "crop", ".", "shape", "[", "1", "]", "//", "purple_scale_size", ",", "1", ")", "\n", "pooled", "=", "block_reduce", "(", "image", "=", "crop", ",", "block_size", "=", "block_size", ",", "func", "=", "np", ".", "average", ")", "\n", "\n", "# Calculate boolean arrays for determining if portion is purple.", "\n", "r", ",", "g", ",", "b", "=", "pooled", "[", "...", ",", "0", "]", ",", "pooled", "[", "...", ",", "1", "]", ",", "pooled", "[", "...", ",", "2", "]", "\n", "cond1", "=", "r", ">", "g", "-", "10", "\n", "cond2", "=", "b", ">", "g", "-", "10", "\n", "cond3", "=", "(", "(", "r", "+", "b", ")", "/", "2", ")", ">", "g", "+", "20", "\n", "\n", "# Find the indexes of pooled satisfying all 3 conditions.", "\n", "pooled", "=", "pooled", "[", "cond1", "&", "cond2", "&", "cond3", "]", "\n", "num_purple", "=", "pooled", ".", "shape", "[", "0", "]", "\n", "\n", "return", "num_purple", ">", "purple_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.get_folder_size_and_num_images": [[63, 82], ["utils.get_image_paths", "len", "image_path.stat"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.4_anonymize.get_image_paths"], ["", "def", "get_folder_size_and_num_images", "(", "folder", ":", "Path", ")", "->", "Tuple", "[", "float", ",", "int", "]", ":", "\n", "    ", "\"\"\"\n    Finds the number and size of images in a folder path.\n    Used to decide how much to slide windows.\n\n    Args:\n        folder: Folder containing images.\n\n    Returns:\n        A tuple containing the total size of the images and the number of images.\n    \"\"\"", "\n", "image_paths", "=", "get_image_paths", "(", "folder", "=", "folder", ")", "\n", "\n", "file_size", "=", "0", "\n", "for", "image_path", "in", "image_paths", ":", "\n", "        ", "file_size", "+=", "image_path", ".", "stat", "(", ")", ".", "st_size", "\n", "\n", "", "file_size_mb", "=", "file_size", "/", "1e6", "\n", "return", "file_size_mb", ",", "len", "(", "image_paths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.get_subfolder_to_overlap": [[84, 115], ["utils_processing.get_folder_size_and_num_images", "max", "print", "math.pow", "math.sqrt"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.get_folder_size_and_num_images"], ["", "def", "get_subfolder_to_overlap", "(", "subfolders", ":", "List", "[", "Path", "]", ",", "\n", "desired_crops_per_class", ":", "int", "\n", ")", "->", "Dict", "[", "Path", ",", "float", "]", ":", "\n", "    ", "\"\"\"\n    Find how much the inverse overlap factor should be for each folder so that\n    the class distributions are approximately equal.\n\n    Args:\n        subfolders: Subfolders to calculate the overlap factors for.\n        desired_crops_per_class: Desired number of patches per class.\n\n    Returns:\n        A dictionary mapping subfolder paths to inverse overlap factor.\n    \"\"\"", "\n", "subfolder_to_overlap_factor", "=", "{", "}", "\n", "for", "subfolder", "in", "subfolders", ":", "\n", "        ", "subfolder_size", ",", "subfolder_num_images", "=", "get_folder_size_and_num_images", "(", "\n", "folder", "=", "subfolder", ")", "\n", "\n", "# Each image is 13KB = 0.013MB, idk I just added two randomly.", "\n", "overlap_factor", "=", "max", "(", "\n", "1.0", ",", "\n", "math", ".", "pow", "(", "\n", "math", ".", "sqrt", "(", "desired_crops_per_class", "/", "(", "subfolder_size", "/", "0.013", ")", ")", ",", "\n", "1.5", ")", ")", "\n", "subfolder_to_overlap_factor", "[", "subfolder", "]", "=", "overlap_factor", "\n", "print", "(", "f\"{subfolder}: {subfolder_size}MB, \"", "\n", "f\"{subfolder_num_images} images, \"", "\n", "f\"overlap_factor={overlap_factor:.2f}\"", ")", "\n", "\n", "", "return", "subfolder_to_overlap_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.gen_train_patches": [[117, 158], ["utils.get_subfolder_paths", "print", "utils_processing.get_subfolder_to_overlap", "print", "utils_processing.produce_patches", "output_folder.joinpath"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.3_repiece_jpg_tiles.get_subfolder_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.get_subfolder_to_overlap", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.produce_patches"], ["", "def", "gen_train_patches", "(", "input_folder", ":", "Path", ",", "output_folder", ":", "Path", ",", "\n", "num_train_per_class", ":", "int", ",", "num_workers", ":", "int", ",", "\n", "patch_size", ":", "int", ",", "purple_threshold", ":", "int", ",", "\n", "purple_scale_size", ":", "int", ",", "image_ext", ":", "str", ",", "\n", "type_histopath", ":", "bool", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Generates all patches for subfolders in the training set.\n\n    Args:\n        input_folder: Folder containing the subfolders containing WSI.\n        output_folder: Folder to save the patches to.\n        num_train_per_class: The desired number of training patches per class.\n        num_workers: Number of workers to use for IO.\n        patch_size: Size of the patches extracted from the WSI.\n        purple_threshold: Number of purple points for region to be considered purple.\n        purple_scale_size: Scalar to use for reducing image to check for purple.\n        image_ext: Image extension for saving patches.\n        type_histopath: Only look for purple histopathology images and filter whitespace.\n    \"\"\"", "\n", "# Find the subfolders and how much patches should overlap for each.", "\n", "subfolders", "=", "get_subfolder_paths", "(", "folder", "=", "input_folder", ")", "\n", "print", "(", "f\"{subfolders} subfolders found from {input_folder}\"", ")", "\n", "subfolder_to_overlap_factor", "=", "get_subfolder_to_overlap", "(", "\n", "subfolders", "=", "subfolders", ",", "desired_crops_per_class", "=", "num_train_per_class", ")", "\n", "\n", "# Produce the patches.", "\n", "for", "input_subfolder", "in", "subfolders", ":", "\n", "        ", "produce_patches", "(", "input_folder", "=", "input_subfolder", ",", "\n", "output_folder", "=", "output_folder", ".", "joinpath", "(", "\n", "input_subfolder", ".", "name", ")", ",", "\n", "inverse_overlap_factor", "=", "subfolder_to_overlap_factor", "[", "\n", "input_subfolder", "]", ",", "\n", "by_folder", "=", "False", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "patch_size", "=", "patch_size", ",", "\n", "purple_threshold", "=", "purple_threshold", ",", "\n", "purple_scale_size", "=", "purple_scale_size", ",", "\n", "image_ext", "=", "image_ext", ",", "\n", "type_histopath", "=", "type_histopath", ")", "\n", "\n", "", "print", "(", "\"\\nfinished all folders\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.gen_val_patches": [[160, 197], ["utils.get_subfolder_paths", "print", "print", "utils_processing.produce_patches", "len", "output_folder.joinpath"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.3_repiece_jpg_tiles.get_subfolder_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.produce_patches"], ["", "def", "gen_val_patches", "(", "input_folder", ":", "Path", ",", "output_folder", ":", "Path", ",", "\n", "overlap_factor", ":", "float", ",", "num_workers", ":", "int", ",", "patch_size", ":", "int", ",", "\n", "purple_threshold", ":", "int", ",", "purple_scale_size", ":", "int", ",", "\n", "image_ext", ":", "str", ",", "type_histopath", ":", "bool", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Generates all patches for subfolders in the validation set.\n\n    Args:\n        input_folder: Folder containing the subfolders containing WSI.\n        output_folder: Folder to save the patches to.\n        overlap_factor: The amount of overlap between patches.\n        num_workers: Number of workers to use for IO.\n        patch_size: Size of the patches extracted from the WSI.\n        purple_threshold: Number of purple points for region to be considered purple.\n        purple_scale_size: Scalar to use for reducing image to check for purple.\n        image_ext: Image extension for saving patches.\n        type_histopath: Only look for purple histopathology images and filter whitespace.\n    \"\"\"", "\n", "# Find the subfolders and how much patches should overlap for each.", "\n", "subfolders", "=", "get_subfolder_paths", "(", "folder", "=", "input_folder", ")", "\n", "print", "(", "f\"{len(subfolders)} subfolders found from {input_folder}\"", ")", "\n", "\n", "# Produce the patches.", "\n", "for", "input_subfolder", "in", "subfolders", ":", "\n", "        ", "produce_patches", "(", "input_folder", "=", "input_subfolder", ",", "\n", "output_folder", "=", "output_folder", ".", "joinpath", "(", "\n", "input_subfolder", ".", "name", ")", ",", "\n", "inverse_overlap_factor", "=", "overlap_factor", ",", "\n", "by_folder", "=", "False", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "patch_size", "=", "patch_size", ",", "\n", "purple_threshold", "=", "purple_threshold", ",", "\n", "purple_scale_size", "=", "purple_scale_size", ",", "\n", "image_ext", "=", "image_ext", ",", "\n", "type_histopath", "=", "type_histopath", ")", "\n", "\n", "", "print", "(", "\"\\nfinished all folders\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.duplicate_until_n": [[204, 226], ["print", "range", "len", "image_path.name.split", "shutil.copyfile", "pathlib.Path", "len", "len"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split"], ["", "def", "duplicate_until_n", "(", "image_paths", ":", "List", "[", "Path", "]", ",", "n", ":", "int", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Duplicate the underrepresented classes to balance class distributions.\n\n    Args:\n        image_paths: Image paths to check for balance.\n        n: Desired number of images.\n    \"\"\"", "\n", "num_dupls", "=", "n", "-", "len", "(", "image_paths", ")", "\n", "\n", "print", "(", "f\"balancing {image_paths[0].parent} by duplicating {num_dupls}\"", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_dupls", ")", ":", "\n", "        ", "image_path", "=", "image_paths", "[", "i", "%", "len", "(", "image_paths", ")", "]", "\n", "\n", "xys", "=", "image_path", ".", "name", ".", "split", "(", "\"_\"", ")", "\n", "x", "=", "xys", "[", ":", "-", "2", "]", "\n", "y", "=", "xys", "[", "-", "2", ":", "]", "\n", "\n", "copyfile", "(", "src", "=", "image_path", ",", "\n", "dst", "=", "Path", "(", "\n", "image_path", ".", "parent", ",", "f\"{'_'.join(x)}dup\"", "\n", "f\"{(i // len(image_paths)) + 2}_\"", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.balance_classes": [[230, 254], ["utils.get_subfolder_paths", "max", "print", "utils.get_image_paths", "utils_processing.duplicate_until_n", "len"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.3_repiece_jpg_tiles.get_subfolder_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.4_anonymize.get_image_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.duplicate_until_n"], ["", "", "def", "balance_classes", "(", "training_folder", ":", "Path", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Balancing class distribution so that training isn't skewed.\n\n    Args:\n        training_folder: Folder containing the subfolders to be balanced.\n    \"\"\"", "\n", "subfolders", "=", "get_subfolder_paths", "(", "folder", "=", "training_folder", ")", "\n", "subfolder_to_images", "=", "{", "\n", "subfolder", ":", "get_image_paths", "(", "folder", "=", "subfolder", ")", "\n", "for", "subfolder", "in", "subfolders", "\n", "}", "\n", "\n", "# Find the class with the most images.", "\n", "biggest_size", "=", "max", "(", "{", "\n", "subfolder", ":", "len", "(", "subfolder_to_images", "[", "subfolder", "]", ")", "\n", "for", "subfolder", "in", "subfolders", "\n", "}", ".", "values", "(", ")", ")", "\n", "\n", "for", "subfolder", "in", "subfolder_to_images", ":", "\n", "        ", "duplicate_until_n", "(", "image_paths", "=", "subfolder_to_images", "[", "subfolder", "]", ",", "\n", "n", "=", "biggest_size", ")", "\n", "\n", "", "print", "(", "f\"balanced all training classes to have {biggest_size} images\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.find_patch_mp": [[256, 273], ["in_queue.get", "out_queue.put", "func"], "function", ["None"], ["", "def", "find_patch_mp", "(", "func", ":", "Callable", "[", "[", "Tuple", "[", "int", ",", "int", "]", "]", ",", "int", "]", ",", "in_queue", ":", "Queue", ",", "\n", "out_queue", ":", "Queue", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Find the patches from the WSI using multiprocessing.\n    Helper function to ensure values are sent to each process\n    correctly.\n\n    Args:\n        func: Function to call in multiprocessing.\n        in_queue: Queue containing input data.\n        out_queue: Queue to put output in.\n    \"\"\"", "\n", "while", "True", ":", "\n", "        ", "xy", "=", "in_queue", ".", "get", "(", ")", "\n", "if", "xy", "is", "None", ":", "\n", "            ", "break", "\n", "", "out_queue", ".", "put", "(", "obj", "=", "func", "(", "xy", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.find_patch": [[275, 327], ["output_folder.joinpath", "output_subsubfolder.joinpath.joinpath", "output_subsubfolder.joinpath.mkdir", "output_subsubfolder.joinpath.joinpath", "output_folder.joinpath", "utils_processing.is_purple", "imageio.imsave", "pathlib.Path().with_suffix", "imageio.imsave", "pathlib.Path", "str().zfill", "str().zfill", "str", "str"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.is_purple"], ["", "", "def", "find_patch", "(", "xy_start", ":", "Tuple", "[", "int", ",", "int", "]", ",", "output_folder", ":", "Path", ",", "\n", "image", ":", "np", ".", "ndarray", ",", "by_folder", ":", "bool", ",", "image_loc", ":", "Path", ",", "\n", "patch_size", ":", "int", ",", "image_ext", ":", "str", ",", "type_histopath", ":", "bool", ",", "\n", "purple_threshold", ":", "int", ",", "purple_scale_size", ":", "int", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Find the patches for a WSI.\n\n    Args:\n        output_folder: Folder to save the patches to.\n        image: WSI to extract patches from.\n        xy_start: Starting coordinates of the patch.\n        by_folder: Whether to generate the patches by folder or by image.\n        image_loc: Location of the image to use for creating output filename.\n        patch_size: Size of the patches extracted from the WSI.\n        image_ext: Image extension for saving patches.\n        type_histopath: Only look for purple histopathology images and filter whitespace.\n        purple_threshold: Number of purple points for region to be considered purple.\n        purple_scale_size: Scalar to use for reducing image to check for purple.\n\n    Returns:\n        The number 1 if the image was saved successfully and a 0 otherwise.\n        Used to determine the number of patches produced per WSI.\n    \"\"\"", "\n", "x_start", ",", "y_start", "=", "xy_start", "\n", "\n", "patch", "=", "image", "[", "x_start", ":", "x_start", "+", "patch_size", ",", "y_start", ":", "y_start", "+", "\n", "patch_size", ",", ":", "]", "\n", "# Sometimes the images are RGBA instead of RGB. Only keep RGB channels.", "\n", "patch", "=", "patch", "[", "...", ",", "[", "0", ",", "1", ",", "2", "]", "]", "\n", "\n", "if", "by_folder", ":", "\n", "        ", "output_subsubfolder", "=", "output_folder", ".", "joinpath", "(", "\n", "Path", "(", "image_loc", ".", "name", ")", ".", "with_suffix", "(", "\"\"", ")", ")", "\n", "output_subsubfolder", "=", "output_subsubfolder", ".", "joinpath", "(", "\n", "output_subsubfolder", ".", "name", ")", "\n", "output_subsubfolder", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "output_path", "=", "output_subsubfolder", ".", "joinpath", "(", "\n", "f\"{str(x_start).zfill(5)};{str(y_start).zfill(5)}.{image_ext}\"", ")", "\n", "", "else", ":", "\n", "        ", "output_path", "=", "output_folder", ".", "joinpath", "(", "\n", "f\"{image_loc.stem}_{x_start}_{y_start}.{image_ext}\"", ")", "\n", "\n", "", "if", "type_histopath", ":", "\n", "        ", "if", "is_purple", "(", "crop", "=", "patch", ",", "\n", "purple_threshold", "=", "purple_threshold", ",", "\n", "purple_scale_size", "=", "purple_scale_size", ")", ":", "\n", "            ", "imsave", "(", "uri", "=", "output_path", ",", "im", "=", "patch", ")", "\n", "", "else", ":", "\n", "            ", "return", "0", "\n", "", "", "else", ":", "\n", "        ", "imsave", "(", "uri", "=", "output_path", ",", "im", "=", "patch", ")", "\n", "", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_processing.produce_patches": [[329, 433], ["output_folder.mkdir", "print", "time.time", "utils.get_all_image_paths", "utils.get_image_names", "imageio.imread", "multiprocessing.RawArray", "numpy.frombuffer().reshape", "numpy.copyto", "int", "multiprocessing.Queue", "multiprocessing.Queue", "itertools.product", "range", "sum", "print", "int", "int", "multiprocessing.Process", "p.start", "range", "range", "multiprocessing.Queue.put", "multiprocessing.Queue.put", "p.join", "print", "len", "numpy.ctypeslib.as_ctypes_type", "numpy.frombuffer", "range", "multiprocessing.Queue.get", "input_folder.joinpath", "range", "functools.partial", "time.time"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.get_all_image_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.get_image_names"], ["", "def", "produce_patches", "(", "input_folder", ":", "Path", ",", "output_folder", ":", "Path", ",", "\n", "inverse_overlap_factor", ":", "float", ",", "by_folder", ":", "bool", ",", "\n", "num_workers", ":", "int", ",", "patch_size", ":", "int", ",", "purple_threshold", ":", "int", ",", "\n", "purple_scale_size", ":", "int", ",", "image_ext", ":", "str", ",", "\n", "type_histopath", ":", "bool", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Produce the patches from the WSI in parallel.\n\n    Args:\n        input_folder: Folder containing the WSI.\n        output_folder: Folder to save the patches to.\n        inverse_overlap_factor: Overlap factor used in patch creation.\n        by_folder: Whether to generate the patches by folder or by image.\n        num_workers: Number of workers to use for IO.\n        patch_size: Size of the patches extracted from the WSI.\n        purple_threshold: Number of purple points for region to be considered purple.\n        purple_scale_size: Scalar to use for reducing image to check for purple.\n        image_ext: Image extension for saving patches.\n        type_histopath: Only look for purple histopathology images and filter whitespace.\n    \"\"\"", "\n", "output_folder", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "image_locs", "=", "get_all_image_paths", "(", "\n", "master_folder", "=", "input_folder", ")", "if", "by_folder", "else", "get_image_names", "(", "\n", "folder", "=", "input_folder", ")", "\n", "outputted_patches", "=", "0", "\n", "\n", "print", "(", "f\"\\ngetting small crops from {len(image_locs)} \"", "\n", "f\"images in {input_folder} \"", "\n", "f\"with inverse overlap factor {inverse_overlap_factor:.2f} \"", "\n", "f\"outputting in {output_folder}\"", ")", "\n", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "image_loc", "in", "image_locs", ":", "\n", "        ", "image", "=", "imread", "(", "\n", "uri", "=", "(", "image_loc", "if", "by_folder", "else", "input_folder", ".", "joinpath", "(", "image_loc", ")", ")", ")", "\n", "\n", "# Sources:", "\n", "# 1. https://research.wmz.ninja/articles/2018/03/on-sharing-large-arrays-when-using-pythons-multiprocessing.html", "\n", "# 2. https://stackoverflow.com/questions/33247262/the-corresponding-ctypes-type-of-a-numpy-dtype", "\n", "# 3. https://stackoverflow.com/questions/7894791/use-numpy-array-in-shared-memory-for-multiprocessing", "\n", "img", "=", "RawArray", "(", "\n", "typecode_or_type", "=", "np", ".", "ctypeslib", ".", "as_ctypes_type", "(", "dtype", "=", "image", ".", "dtype", ")", ",", "\n", "size_or_initializer", "=", "image", ".", "size", ")", "\n", "img_np", "=", "np", ".", "frombuffer", "(", "buffer", "=", "img", ",", "\n", "dtype", "=", "image", ".", "dtype", ")", ".", "reshape", "(", "image", ".", "shape", ")", "\n", "np", ".", "copyto", "(", "dst", "=", "img_np", ",", "src", "=", "image", ")", "\n", "\n", "# Number of x starting points.", "\n", "x_steps", "=", "int", "(", "(", "image", ".", "shape", "[", "0", "]", "-", "patch_size", ")", "/", "patch_size", "*", "\n", "inverse_overlap_factor", ")", "+", "1", "\n", "# Number of y starting points.", "\n", "y_steps", "=", "int", "(", "(", "image", ".", "shape", "[", "1", "]", "-", "patch_size", ")", "/", "patch_size", "*", "\n", "inverse_overlap_factor", ")", "+", "1", "\n", "# Step size, same for x and y.", "\n", "step_size", "=", "int", "(", "patch_size", "/", "inverse_overlap_factor", ")", "\n", "\n", "# Create the queues for passing data back and forth.", "\n", "in_queue", "=", "Queue", "(", ")", "\n", "out_queue", "=", "Queue", "(", "maxsize", "=", "-", "1", ")", "\n", "\n", "# Create the processes for multiprocessing.", "\n", "processes", "=", "[", "\n", "Process", "(", "target", "=", "find_patch_mp", ",", "\n", "args", "=", "(", "functools", ".", "partial", "(", "\n", "find_patch", ",", "\n", "output_folder", "=", "output_folder", ",", "\n", "image", "=", "img_np", ",", "\n", "by_folder", "=", "by_folder", ",", "\n", "image_loc", "=", "image_loc", ",", "\n", "purple_threshold", "=", "purple_threshold", ",", "\n", "purple_scale_size", "=", "purple_scale_size", ",", "\n", "image_ext", "=", "image_ext", ",", "\n", "type_histopath", "=", "type_histopath", ",", "\n", "patch_size", "=", "patch_size", ")", ",", "in_queue", ",", "out_queue", ")", ")", "\n", "for", "__", "in", "range", "(", "num_workers", ")", "\n", "]", "\n", "for", "p", "in", "processes", ":", "\n", "            ", "p", ".", "daemon", "=", "True", "\n", "p", ".", "start", "(", ")", "\n", "\n", "# Put the (x, y) coordinates in the input queue.", "\n", "", "for", "xy", "in", "itertools", ".", "product", "(", "range", "(", "0", ",", "x_steps", "*", "step_size", ",", "step_size", ")", ",", "\n", "range", "(", "0", ",", "y_steps", "*", "step_size", ",", "step_size", ")", ")", ":", "\n", "            ", "in_queue", ".", "put", "(", "obj", "=", "xy", ")", "\n", "\n", "# Store num_workers None values so the processes exit when not enough jobs left.", "\n", "", "for", "__", "in", "range", "(", "num_workers", ")", ":", "\n", "            ", "in_queue", ".", "put", "(", "obj", "=", "None", ")", "\n", "\n", "", "num_patches", "=", "sum", "(", "[", "out_queue", ".", "get", "(", ")", "for", "__", "in", "range", "(", "x_steps", "*", "y_steps", ")", "]", ")", "\n", "\n", "# Join the processes as they finish.", "\n", "for", "p", "in", "processes", ":", "\n", "            ", "p", ".", "join", "(", "timeout", "=", "1", ")", "\n", "\n", "", "if", "by_folder", ":", "\n", "            ", "print", "(", "f\"{image_loc}: num outputted windows: {num_patches}\"", ")", "\n", "", "else", ":", "\n", "            ", "outputted_patches", "+=", "num_patches", "\n", "\n", "", "", "if", "not", "by_folder", ":", "\n", "        ", "print", "(", "\n", "f\"finished patches from {input_folder} \"", "\n", "f\"with inverse overlap factor {inverse_overlap_factor:.2f} in {time.time() - start_time:.2f} seconds \"", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.compute_stats.compute_stats": [[18, 101], ["compute_stats.compute_stats.online_mean_and_sd"], "function", ["None"], ["def", "compute_stats", "(", "folderpath", ":", "Path", ",", "\n", "image_ext", ":", "str", ")", "->", "Tuple", "[", "List", "[", "float", "]", ",", "List", "[", "float", "]", "]", ":", "\n", "    ", "\"\"\"\n    Compute the mean and standard deviation of the images found in folderpath.\n\n    Args:\n        folderpath: Path containing images.\n        image_ext: Extension of the image files.\n\n    Returns:\n        A tuple containing the mean and standard deviation for the images over the channel, height, and width axes.\n\n    This implementation is based on the discussion from: \n        https://discuss.pytorch.org/t/about-normalization-using-pre-trained-vgg16-networks/23560/9\n    \"\"\"", "\n", "class", "MyDataset", "(", "torch", ".", "utils", ".", "data", ".", "Dataset", ")", ":", "\n", "        ", "\"\"\"\n        Creates a dataset by reading images.\n\n        Attributes:\n            data: List of the string image filenames.\n        \"\"\"", "\n", "def", "__init__", "(", "self", ",", "folder", ":", "Path", ")", "->", "None", ":", "\n", "            ", "\"\"\"\n            Create the MyDataset object.\n\n            Args:\n                folder: Path to the images.\n            \"\"\"", "\n", "self", ".", "data", "=", "[", "]", "\n", "\n", "for", "file", "in", "folder", ".", "rglob", "(", "f\"*{image_ext}\"", ")", ":", "\n", "                ", "if", "not", "file", ".", "name", ".", "startswith", "(", "\".\"", ")", ":", "\n", "                    ", "self", ".", "data", ".", "append", "(", "file", ")", "\n", "\n", "", "", "", "def", "__getitem__", "(", "self", ",", "index", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "            ", "\"\"\"\n            Finds the specified image and outputs in correct format.\n\n            Args:\n                index: Index of the desired image.\n\n            Returns:\n                A PyTorch Tensor in the correct color space.\n            \"\"\"", "\n", "return", "ToTensor", "(", ")", "(", "Image", ".", "open", "(", "self", ".", "data", "[", "index", "]", ")", ".", "convert", "(", "\"RGB\"", ")", ")", "\n", "\n", "", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "            ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n", "", "", "def", "online_mean_and_sd", "(", "loader", ":", "torch", ".", "utils", ".", "data", ".", "DataLoader", "\n", ")", "->", "Tuple", "[", "List", "[", "float", "]", ",", "List", "[", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Computes the mean and standard deviation online.\n            Var[x] = E[X^2] - (E[X])^2\n\n        Args:\n            loader: The PyTorch DataLoader containing the images to iterate over.\n\n        Returns:\n            A tuple containing the mean and standard deviation for the images over the channel, height, and width axes.\n        \"\"\"", "\n", "cnt", "=", "0", "\n", "fst_moment", "=", "torch", ".", "empty", "(", "3", ")", "\n", "snd_moment", "=", "torch", ".", "empty", "(", "3", ")", "\n", "\n", "for", "data", "in", "loader", ":", "\n", "            ", "b", ",", "__", ",", "h", ",", "w", "=", "data", ".", "shape", "\n", "nb_pixels", "=", "b", "*", "h", "*", "w", "\n", "fst_moment", "=", "(", "cnt", "*", "fst_moment", "+", "\n", "torch", ".", "sum", "(", "data", ",", "dim", "=", "[", "0", ",", "2", ",", "3", "]", ")", ")", "/", "(", "cnt", "+", "nb_pixels", ")", "\n", "snd_moment", "=", "(", "cnt", "*", "snd_moment", "+", "torch", ".", "sum", "(", "\n", "data", "**", "2", ",", "dim", "=", "[", "0", ",", "2", ",", "3", "]", ")", ")", "/", "(", "cnt", "+", "nb_pixels", ")", "\n", "cnt", "+=", "nb_pixels", "\n", "", "return", "fst_moment", ".", "tolist", "(", ")", ",", "torch", ".", "sqrt", "(", "snd_moment", "-", "\n", "fst_moment", "**", "2", ")", ".", "tolist", "(", ")", "\n", "\n", "", "return", "online_mean_and_sd", "(", "\n", "loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "MyDataset", "(", "\n", "folder", "=", "folderpath", ")", ",", "\n", "batch_size", "=", "1", ",", "\n", "num_workers", "=", "1", ",", "\n", "shuffle", "=", "False", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.Random90Rotation.__init__": [[68, 76], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "degrees", ":", "Tuple", "[", "int", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Randomly rotate the image for training. Credits to Naofumi Tomita.\n\n        Args:\n            degrees: Degrees available for rotation.\n        \"\"\"", "\n", "self", ".", "degrees", "=", "(", "0", ",", "90", ",", "180", ",", "270", ")", "if", "(", "degrees", "is", "None", ")", "else", "degrees", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.Random90Rotation.__call__": [[77, 88], ["im.rotate", "random.sample"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "im", ":", "Image", ")", "->", "Image", ":", "\n", "        ", "\"\"\"\n        Produces a randomly rotated image every time the instance is called.\n\n        Args:\n            im: The image to rotate.\n\n        Returns:    \n            Randomly rotated image.\n        \"\"\"", "\n", "return", "im", ".", "rotate", "(", "angle", "=", "random", ".", "sample", "(", "population", "=", "self", ".", "degrees", ",", "k", "=", "1", ")", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.calculate_confusion_matrix": [[31, 65], ["pandas.Series", "pandas.Series", "pandas.crosstab", "pd.crosstab.style.hide_index", "print", "pandas.Categorical", "pandas.Categorical", "range", "pandas.Series().replace", "pandas.Series().replace", "pandas.Series", "pandas.Series"], "function", ["None"], ["def", "calculate_confusion_matrix", "(", "all_labels", ":", "np", ".", "ndarray", ",", "\n", "all_predicts", ":", "np", ".", "ndarray", ",", "classes", ":", "List", "[", "str", "]", ",", "\n", "num_classes", ":", "int", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Prints the confusion matrix from the given data.\n\n    Args:\n        all_labels: The ground truth labels.\n        all_predicts: The predicted labels.\n        classes: Names of the classes in the dataset.\n        num_classes: Number of classes in the dataset.\n    \"\"\"", "\n", "remap_classes", "=", "{", "x", ":", "classes", "[", "x", "]", "for", "x", "in", "range", "(", "num_classes", ")", "}", "\n", "\n", "# Set print options.", "\n", "# Sources:", "\n", "#   1. https://stackoverflow.com/questions/42735541/customized-float-formatting-in-a-pandas-dataframe", "\n", "#   2. https://stackoverflow.com/questions/11707586/how-do-i-expand-the-output-display-to-see-more-columns-of-a-pandas-dataframe", "\n", "#   3. https://pandas.pydata.org/pandas-docs/stable/user_guide/style.html", "\n", "pd", ".", "options", ".", "display", ".", "float_format", "=", "\"{:.2f}\"", ".", "format", "\n", "pd", ".", "options", ".", "display", ".", "width", "=", "0", "\n", "\n", "actual", "=", "pd", ".", "Series", "(", "pd", ".", "Categorical", "(", "\n", "pd", ".", "Series", "(", "all_labels", ")", ".", "replace", "(", "remap_classes", ")", ",", "categories", "=", "classes", ")", ",", "\n", "name", "=", "\"Actual\"", ")", "\n", "\n", "predicted", "=", "pd", ".", "Series", "(", "pd", ".", "Categorical", "(", "\n", "pd", ".", "Series", "(", "all_predicts", ")", ".", "replace", "(", "remap_classes", ")", ",", "categories", "=", "classes", ")", ",", "\n", "name", "=", "\"Predicted\"", ")", "\n", "\n", "cm", "=", "pd", ".", "crosstab", "(", "index", "=", "actual", ",", "columns", "=", "predicted", ",", "normalize", "=", "\"index\"", ",", "dropna", "=", "False", ")", "\n", "\n", "cm", ".", "style", ".", "hide_index", "(", ")", "\n", "print", "(", "cm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.create_model": [[90, 115], ["getattr", "getattr.", "getattr.state_dict", "model_constructor.load_state_dict", "pretrained[].size", "getattr."], "function", ["None"], ["", "", "def", "create_model", "(", "num_layers", ":", "int", ",", "num_classes", ":", "int", ",", "\n", "pretrain", ":", "bool", ")", "->", "torchvision", ".", "models", ".", "resnet", ".", "ResNet", ":", "\n", "    ", "\"\"\"\n    Instantiate the ResNet model.\n\n    Args:\n        num_layers: Number of layers to use in the ResNet model from [18, 34, 50, 101, 152].\n        num_classes: Number of classes in the dataset.\n        pretrain: Use pretrained ResNet weights.\n\n    Returns:\n        The instantiated ResNet model with the requested parameters.\n    \"\"\"", "\n", "assert", "num_layers", "in", "(", "\n", "18", ",", "34", ",", "50", ",", "101", ",", "152", "\n", ")", ",", "f\"Invalid number of ResNet Layers. Must be one of [18, 34, 50, 101, 152] and not {num_layers}\"", "\n", "model_constructor", "=", "getattr", "(", "torchvision", ".", "models", ",", "f\"resnet{num_layers}\"", ")", "\n", "model", "=", "model_constructor", "(", "num_classes", "=", "num_classes", ")", "\n", "\n", "if", "pretrain", ":", "\n", "        ", "pretrained", "=", "model_constructor", "(", "pretrained", "=", "True", ")", ".", "state_dict", "(", ")", "\n", "if", "num_classes", "!=", "pretrained", "[", "\"fc.weight\"", "]", ".", "size", "(", "0", ")", ":", "\n", "            ", "del", "pretrained", "[", "\"fc.weight\"", "]", ",", "pretrained", "[", "\"fc.bias\"", "]", "\n", "", "model", ".", "load_state_dict", "(", "state_dict", "=", "pretrained", ",", "strict", "=", "False", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.get_data_transforms": [[117, 154], ["torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.ColorJitter", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.RandomVerticalFlip", "utils_model.Random90Rotation", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "function", ["None"], ["", "def", "get_data_transforms", "(", "color_jitter_brightness", ":", "float", ",", "\n", "color_jitter_contrast", ":", "float", ",", "\n", "color_jitter_saturation", ":", "float", ",", "\n", "color_jitter_hue", ":", "float", ",", "path_mean", ":", "List", "[", "float", "]", ",", "\n", "path_std", ":", "List", "[", "float", "]", "\n", ")", "->", "Dict", "[", "str", ",", "torchvision", ".", "transforms", ".", "Compose", "]", ":", "\n", "    ", "\"\"\"\n    Sets up the dataset transforms for training and validation.\n\n    Args:\n        color_jitter_brightness: Random brightness jitter to use in data augmentation for ColorJitter() transform.\n        color_jitter_contrast: Random contrast jitter to use in data augmentation for ColorJitter() transform.\n        color_jitter_saturation: Random saturation jitter to use in data augmentation for ColorJitter() transform.\n        color_jitter_hue: Random hue jitter to use in data augmentation for ColorJitter() transform.\n        path_mean: Means of the WSIs for each dimension.\n        path_std: Standard deviations of the WSIs for each dimension.\n\n    Returns:\n        A dictionary mapping training and validation strings to data transforms.\n    \"\"\"", "\n", "return", "{", "\n", "\"train\"", ":", "\n", "transforms", ".", "Compose", "(", "transforms", "=", "[", "\n", "transforms", ".", "ColorJitter", "(", "brightness", "=", "color_jitter_brightness", ",", "\n", "contrast", "=", "color_jitter_contrast", ",", "\n", "saturation", "=", "color_jitter_saturation", ",", "\n", "hue", "=", "color_jitter_hue", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "RandomVerticalFlip", "(", ")", ",", "\n", "Random90Rotation", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "path_mean", ",", "std", "=", "path_std", ")", "\n", "]", ")", ",", "\n", "\"val\"", ":", "\n", "transforms", ".", "Compose", "(", "transforms", "=", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "path_mean", ",", "std", "=", "path_std", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.print_params": [[158, 183], ["print"], "function", ["None"], ["", "def", "print_params", "(", "train_folder", ":", "Path", ",", "num_epochs", ":", "int", ",", "num_layers", ":", "int", ",", "\n", "learning_rate", ":", "float", ",", "batch_size", ":", "int", ",", "weight_decay", ":", "float", ",", "\n", "learning_rate_decay", ":", "float", ",", "resume_checkpoint", ":", "bool", ",", "\n", "resume_checkpoint_path", ":", "Path", ",", "save_interval", ":", "int", ",", "\n", "checkpoints_folder", ":", "Path", ",", "pretrain", ":", "bool", ",", "\n", "log_csv", ":", "Path", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Print the configuration of the model.\n\n    Args:\n        train_folder: Location of the automatically built training input folder.\n        num_epochs: Number of epochs for training.\n        num_layers: Number of layers to use in the ResNet model from [18, 34, 50, 101, 152].\n        learning_rate: Learning rate to use for gradient descent.\n        batch_size: Mini-batch size to use for training.\n        weight_decay: Weight decay (L2 penalty) to use in optimizer.\n        learning_rate_decay: Learning rate decay amount per epoch.\n        resume_checkpoint: Resume model from checkpoint file.\n        resume_checkpoint_path: Path to the checkpoint file for resuming training.\n        save_interval: Number of epochs between saving checkpoints.\n        checkpoints_folder: Directory to save model checkpoints to.\n        pretrain: Use pretrained ResNet weights.\n        log_csv: Name of the CSV file containing the logs.\n    \"\"\"", "\n", "print", "(", "f\"train_folder: {train_folder}\\n\"", "\n", "f\"num_epochs: {num_epochs}\\n\"", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.train_helper": [[203, 370], ["time.time", "torch.empty().cpu", "torch.empty().cpu", "torch.empty().cpu", "torch.empty().cpu", "torch.empty().cpu", "torch.empty().cpu", "torch.empty().cpu", "torch.empty().cpu", "torch.empty().cpu", "torch.empty().cpu", "torch.empty().cpu", "torch.empty().cpu", "range", "print", "model.train", "enumerate", "utils_model.calculate_confusion_matrix", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model.train", "enumerate", "utils_model.calculate_confusion_matrix", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "scheduler.step", "writer.write", "print", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "inputs.to", "labels.to", "optimizer.zero_grad", "torch.sum", "torch.sum", "torch.sum", "labels.to.detach().cpu", "train_preds.detach().cpu", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "val_inputs.to.to", "val_labels.to.to", "torch.sum", "torch.sum", "torch.sum", "val_labels.to.detach().cpu", "val_preds.detach().cpu", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "checkpoints_folder.joinpath", "checkpoints_folder.joinpath.parent.mkdir", "torch.save", "torch.save", "torch.save", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "model", "torch.max", "torch.max", "torch.max", "criterion", "criterion.backward", "optimizer.step", "criterion.item", "inputs.to.size", "torch.empty().cpu.numpy", "torch.empty().cpu.numpy", "torch.set_grad_enabled", "torch.set_grad_enabled", "torch.set_grad_enabled", "model", "torch.max", "torch.max", "torch.max", "criterion", "criterion.item", "val_inputs.to.size", "torch.empty().cpu.numpy", "torch.empty().cpu.numpy", "labels.to.detach", "train_preds.detach", "val_labels.to.detach", "val_preds.detach", "str", "model.state_dict", "optimizer.state_dict", "scheduler.state_dict", "time.time"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.calculate_confusion_matrix", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.calculate_confusion_matrix"], ["", "def", "train_helper", "(", "model", ":", "torchvision", ".", "models", ".", "resnet", ".", "ResNet", ",", "\n", "dataloaders", ":", "Dict", "[", "str", ",", "torch", ".", "utils", ".", "data", ".", "DataLoader", "]", ",", "\n", "dataset_sizes", ":", "Dict", "[", "str", ",", "int", "]", ",", "\n", "criterion", ":", "torch", ".", "nn", ".", "modules", ".", "loss", ",", "optimizer", ":", "torch", ".", "optim", ",", "\n", "scheduler", ":", "torch", ".", "optim", ".", "lr_scheduler", ",", "num_epochs", ":", "int", ",", "\n", "writer", ":", "IO", ",", "device", ":", "torch", ".", "device", ",", "start_epoch", ":", "int", ",", "\n", "batch_size", ":", "int", ",", "save_interval", ":", "int", ",", "checkpoints_folder", ":", "Path", ",", "\n", "num_layers", ":", "int", ",", "classes", ":", "List", "[", "str", "]", ",", "\n", "num_classes", ":", "int", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Function for training ResNet.\n\n    Args:\n        model: ResNet model for training.\n        dataloaders: Dataloaders for IO pipeline.\n        dataset_sizes: Sizes of the training and validation dataset.\n        criterion: Metric used for calculating loss.\n        optimizer: Optimizer to use for gradient descent.\n        scheduler: Scheduler to use for learning rate decay.\n        start_epoch: Starting epoch for training.\n        writer: Writer to write logging information.\n        device: Device to use for running model.\n        num_epochs: Total number of epochs to train for.\n        batch_size: Mini-batch size to use for training.\n        save_interval: Number of epochs between saving checkpoints.\n        checkpoints_folder: Directory to save model checkpoints to.\n        num_layers: Number of layers to use in the ResNet model from [18, 34, 50, 101, 152].\n        classes: Names of the classes in the dataset.\n        num_classes: Number of classes in the dataset.\n    \"\"\"", "\n", "since", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Initialize all the tensors to be used in training and validation.", "\n", "# Do this outside the loop since it will be written over entirely at each", "\n", "# epoch and doesn't need to be reallocated each time.", "\n", "train_all_labels", "=", "torch", ".", "empty", "(", "size", "=", "(", "dataset_sizes", "[", "\"train\"", "]", ",", ")", ",", "\n", "dtype", "=", "torch", ".", "long", ")", ".", "cpu", "(", ")", "\n", "train_all_predicts", "=", "torch", ".", "empty", "(", "size", "=", "(", "dataset_sizes", "[", "\"train\"", "]", ",", ")", ",", "\n", "dtype", "=", "torch", ".", "long", ")", ".", "cpu", "(", ")", "\n", "val_all_labels", "=", "torch", ".", "empty", "(", "size", "=", "(", "dataset_sizes", "[", "\"val\"", "]", ",", ")", ",", "\n", "dtype", "=", "torch", ".", "long", ")", ".", "cpu", "(", ")", "\n", "val_all_predicts", "=", "torch", ".", "empty", "(", "size", "=", "(", "dataset_sizes", "[", "\"val\"", "]", ",", ")", ",", "\n", "dtype", "=", "torch", ".", "long", ")", ".", "cpu", "(", ")", "\n", "\n", "# Train for specified number of epochs.", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "num_epochs", ")", ":", "\n", "\n", "# Training phase.", "\n", "        ", "model", ".", "train", "(", "mode", "=", "True", ")", "\n", "\n", "train_running_loss", "=", "0.0", "\n", "train_running_corrects", "=", "0", "\n", "\n", "# Train over all training data.", "\n", "for", "idx", ",", "(", "inputs", ",", "labels", ")", "in", "enumerate", "(", "dataloaders", "[", "\"train\"", "]", ")", ":", "\n", "            ", "train_inputs", "=", "inputs", ".", "to", "(", "device", "=", "device", ")", "\n", "train_labels", "=", "labels", ".", "to", "(", "device", "=", "device", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# Forward and backpropagation.", "\n", "with", "torch", ".", "set_grad_enabled", "(", "mode", "=", "True", ")", ":", "\n", "                ", "train_outputs", "=", "model", "(", "train_inputs", ")", "\n", "__", ",", "train_preds", "=", "torch", ".", "max", "(", "train_outputs", ",", "dim", "=", "1", ")", "\n", "train_loss", "=", "criterion", "(", "input", "=", "train_outputs", ",", "\n", "target", "=", "train_labels", ")", "\n", "train_loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Update training diagnostics.", "\n", "", "train_running_loss", "+=", "train_loss", ".", "item", "(", ")", "*", "train_inputs", ".", "size", "(", "0", ")", "\n", "train_running_corrects", "+=", "torch", ".", "sum", "(", "\n", "train_preds", "==", "train_labels", ".", "data", ",", "dtype", "=", "torch", ".", "double", ")", "\n", "\n", "start", "=", "idx", "*", "batch_size", "\n", "end", "=", "start", "+", "batch_size", "\n", "\n", "train_all_labels", "[", "start", ":", "end", "]", "=", "train_labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "train_all_predicts", "[", "start", ":", "end", "]", "=", "train_preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "", "calculate_confusion_matrix", "(", "all_labels", "=", "train_all_labels", ".", "numpy", "(", ")", ",", "\n", "all_predicts", "=", "train_all_predicts", ".", "numpy", "(", ")", ",", "\n", "classes", "=", "classes", ",", "\n", "num_classes", "=", "num_classes", ")", "\n", "\n", "# Store training diagnostics.", "\n", "train_loss", "=", "train_running_loss", "/", "dataset_sizes", "[", "\"train\"", "]", "\n", "train_acc", "=", "train_running_corrects", "/", "dataset_sizes", "[", "\"train\"", "]", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "# Validation phase.", "\n", "", "model", ".", "train", "(", "mode", "=", "False", ")", "\n", "\n", "val_running_loss", "=", "0.0", "\n", "val_running_corrects", "=", "0", "\n", "\n", "# Feed forward over all the validation data.", "\n", "for", "idx", ",", "(", "val_inputs", ",", "val_labels", ")", "in", "enumerate", "(", "dataloaders", "[", "\"val\"", "]", ")", ":", "\n", "            ", "val_inputs", "=", "val_inputs", ".", "to", "(", "device", "=", "device", ")", "\n", "val_labels", "=", "val_labels", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "# Feed forward.", "\n", "with", "torch", ".", "set_grad_enabled", "(", "mode", "=", "False", ")", ":", "\n", "                ", "val_outputs", "=", "model", "(", "val_inputs", ")", "\n", "_", ",", "val_preds", "=", "torch", ".", "max", "(", "val_outputs", ",", "dim", "=", "1", ")", "\n", "val_loss", "=", "criterion", "(", "input", "=", "val_outputs", ",", "target", "=", "val_labels", ")", "\n", "\n", "# Update validation diagnostics.", "\n", "", "val_running_loss", "+=", "val_loss", ".", "item", "(", ")", "*", "val_inputs", ".", "size", "(", "0", ")", "\n", "val_running_corrects", "+=", "torch", ".", "sum", "(", "val_preds", "==", "val_labels", ".", "data", ",", "\n", "dtype", "=", "torch", ".", "double", ")", "\n", "\n", "start", "=", "idx", "*", "batch_size", "\n", "end", "=", "start", "+", "batch_size", "\n", "\n", "val_all_labels", "[", "start", ":", "end", "]", "=", "val_labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "val_all_predicts", "[", "start", ":", "end", "]", "=", "val_preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "", "calculate_confusion_matrix", "(", "all_labels", "=", "val_all_labels", ".", "numpy", "(", ")", ",", "\n", "all_predicts", "=", "val_all_predicts", ".", "numpy", "(", ")", ",", "\n", "classes", "=", "classes", ",", "\n", "num_classes", "=", "num_classes", ")", "\n", "\n", "# Store validation diagnostics.", "\n", "val_loss", "=", "val_running_loss", "/", "dataset_sizes", "[", "\"val\"", "]", "\n", "val_acc", "=", "val_running_corrects", "/", "dataset_sizes", "[", "\"val\"", "]", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "", "scheduler", ".", "step", "(", ")", "\n", "\n", "current_lr", "=", "None", "\n", "for", "group", "in", "optimizer", ".", "param_groups", ":", "\n", "            ", "current_lr", "=", "group", "[", "\"lr\"", "]", "\n", "\n", "# Remaining things related to training.", "\n", "", "if", "epoch", "%", "save_interval", "==", "0", ":", "\n", "            ", "epoch_output_path", "=", "checkpoints_folder", ".", "joinpath", "(", "\n", "f\"resnet{num_layers}_e{epoch}_va{val_acc:.5f}.pt\"", ")", "\n", "\n", "# Confirm the output directory exists.", "\n", "epoch_output_path", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Save the model as a state dictionary.", "\n", "torch", ".", "save", "(", "obj", "=", "{", "\n", "\"model_state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer_state_dict\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"scheduler_state_dict\"", ":", "scheduler", ".", "state_dict", "(", ")", ",", "\n", "\"epoch\"", ":", "epoch", "+", "1", "\n", "}", ",", "\n", "f", "=", "str", "(", "epoch_output_path", ")", ")", "\n", "\n", "", "writer", ".", "write", "(", "f\"{epoch},{train_loss:.4f},\"", "\n", "f\"{train_acc:.4f},{val_loss:.4f},{val_acc:.4f}\\n\"", ")", "\n", "\n", "# Print the diagnostics for each epoch.", "\n", "print", "(", "f\"Epoch {epoch} with lr \"", "\n", "f\"{current_lr:.15f}: \"", "\n", "f\"t_loss: {train_loss:.4f} \"", "\n", "f\"t_acc: {train_acc:.4f} \"", "\n", "f\"v_loss: {val_loss:.4f} \"", "\n", "f\"v_acc: {val_acc:.4f}\\n\"", ")", "\n", "\n", "# Print training information at the end.", "\n", "", "print", "(", "f\"\\ntraining complete in \"", "\n", "f\"{(time.time() - since) // 60:.2f} minutes\"", ")", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.train_resnet": [[373, 499], ["utils_model.get_data_transforms", "print", "utils_model.create_model", "model.to.to", "torch.Adam", "torch.optim.lr_scheduler.ExponentialLR", "utils_model.print_params", "log_csv.parent.mkdir", "torchvision.datasets.ImageFolder", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "torch.load", "torch.load", "torch.load", "model.to.load_state_dict", "optim.Adam.load_state_dict", "lr_scheduler.ExponentialLR.load_state_dict", "print", "log_csv.open", "writer.write", "utils_model.train_helper", "model.to.parameters", "str", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.CrossEntropyLoss", "train_folder.joinpath", "len", "len"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.get_data_transforms", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.create_model", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.print_params", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.train_helper"], ["", "def", "train_resnet", "(", "\n", "train_folder", ":", "Path", ",", "batch_size", ":", "int", ",", "num_workers", ":", "int", ",", "\n", "device", ":", "torch", ".", "device", ",", "classes", ":", "List", "[", "str", "]", ",", "learning_rate", ":", "float", ",", "\n", "weight_decay", ":", "float", ",", "learning_rate_decay", ":", "float", ",", "\n", "resume_checkpoint", ":", "bool", ",", "resume_checkpoint_path", ":", "Path", ",", "log_csv", ":", "Path", ",", "\n", "color_jitter_brightness", ":", "float", ",", "color_jitter_contrast", ":", "float", ",", "\n", "color_jitter_hue", ":", "float", ",", "color_jitter_saturation", ":", "float", ",", "\n", "path_mean", ":", "List", "[", "float", "]", ",", "path_std", ":", "List", "[", "float", "]", ",", "num_classes", ":", "int", ",", "\n", "num_layers", ":", "int", ",", "pretrain", ":", "bool", ",", "checkpoints_folder", ":", "Path", ",", "\n", "num_epochs", ":", "int", ",", "save_interval", ":", "int", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Main function for training ResNet.\n\n    Args:\n        train_folder: Location of the automatically built training input folder.\n        batch_size: Mini-batch size to use for training.\n        num_workers: Number of workers to use for IO.\n        device: Device to use for running model.\n        classes: Names of the classes in the dataset.\n        learning_rate: Learning rate to use for gradient descent.\n        weight_decay: Weight decay (L2 penalty) to use in optimizer.\n        learning_rate_decay: Learning rate decay amount per epoch.\n        resume_checkpoint: Resume model from checkpoint file.\n        resume_checkpoint_path: Path to the checkpoint file for resuming training.\n        log_csv: Name of the CSV file containing the logs.\n        color_jitter_brightness: Random brightness jitter to use in data augmentation for ColorJitter() transform.\n        color_jitter_contrast: Random contrast jitter to use in data augmentation for ColorJitter() transform.\n        color_jitter_hue: Random hue jitter to use in data augmentation for ColorJitter() transform.\n        color_jitter_saturation: Random saturation jitter to use in data augmentation for ColorJitter() transform.\n        path_mean: Means of the WSIs for each dimension.\n        path_std: Standard deviations of the WSIs for each dimension.\n        num_classes: Number of classes in the dataset.\n        num_layers: Number of layers to use in the ResNet model from [18, 34, 50, 101, 152].\n        pretrain: Use pretrained ResNet weights.\n        checkpoints_folder: Directory to save model checkpoints to.\n        num_epochs: Number of epochs for training.\n        save_interval: Number of epochs between saving checkpoints.\n    \"\"\"", "\n", "# Loading in the data.", "\n", "data_transforms", "=", "get_data_transforms", "(", "\n", "color_jitter_brightness", "=", "color_jitter_brightness", ",", "\n", "color_jitter_contrast", "=", "color_jitter_contrast", ",", "\n", "color_jitter_hue", "=", "color_jitter_hue", ",", "\n", "color_jitter_saturation", "=", "color_jitter_saturation", ",", "\n", "path_mean", "=", "path_mean", ",", "\n", "path_std", "=", "path_std", ")", "\n", "\n", "image_datasets", "=", "{", "\n", "x", ":", "datasets", ".", "ImageFolder", "(", "root", "=", "str", "(", "train_folder", ".", "joinpath", "(", "x", ")", ")", ",", "\n", "transform", "=", "data_transforms", "[", "x", "]", ")", "\n", "for", "x", "in", "(", "\"train\"", ",", "\"val\"", ")", "\n", "}", "\n", "\n", "dataloaders", "=", "{", "\n", "x", ":", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "image_datasets", "[", "x", "]", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "(", "x", "is", "\"train\"", ")", ",", "\n", "num_workers", "=", "num_workers", ")", "\n", "for", "x", "in", "(", "\"train\"", ",", "\"val\"", ")", "\n", "}", "\n", "dataset_sizes", "=", "{", "x", ":", "len", "(", "image_datasets", "[", "x", "]", ")", "for", "x", "in", "(", "\"train\"", ",", "\"val\"", ")", "}", "\n", "\n", "print", "(", "f\"{num_classes} classes: {classes}\\n\"", "\n", "f\"num train images {len(dataloaders['train']) * batch_size}\\n\"", "\n", "f\"num val images {len(dataloaders['val']) * batch_size}\\n\"", "\n", "f\"CUDA is_available: {torch.cuda.is_available()}\"", ")", "\n", "\n", "model", "=", "create_model", "(", "num_classes", "=", "num_classes", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "pretrain", "=", "pretrain", ")", "\n", "model", "=", "model", ".", "to", "(", "device", "=", "device", ")", "\n", "optimizer", "=", "optim", ".", "Adam", "(", "params", "=", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "learning_rate", ",", "\n", "weight_decay", "=", "weight_decay", ")", "\n", "scheduler", "=", "lr_scheduler", ".", "ExponentialLR", "(", "optimizer", "=", "optimizer", ",", "\n", "gamma", "=", "learning_rate_decay", ")", "\n", "\n", "# Initialize the model.", "\n", "if", "resume_checkpoint", ":", "\n", "        ", "ckpt", "=", "torch", ".", "load", "(", "f", "=", "resume_checkpoint_path", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", "=", "ckpt", "[", "\"model_state_dict\"", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "state_dict", "=", "ckpt", "[", "\"optimizer_state_dict\"", "]", ")", "\n", "scheduler", ".", "load_state_dict", "(", "state_dict", "=", "ckpt", "[", "\"scheduler_state_dict\"", "]", ")", "\n", "start_epoch", "=", "ckpt", "[", "\"epoch\"", "]", "\n", "print", "(", "f\"model loaded from {resume_checkpoint_path}\"", ")", "\n", "", "else", ":", "\n", "        ", "start_epoch", "=", "0", "\n", "\n", "# Print the model hyperparameters.", "\n", "", "print_params", "(", "batch_size", "=", "batch_size", ",", "\n", "checkpoints_folder", "=", "checkpoints_folder", ",", "\n", "learning_rate", "=", "learning_rate", ",", "\n", "learning_rate_decay", "=", "learning_rate_decay", ",", "\n", "log_csv", "=", "log_csv", ",", "\n", "num_epochs", "=", "num_epochs", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "pretrain", "=", "pretrain", ",", "\n", "resume_checkpoint", "=", "resume_checkpoint", ",", "\n", "resume_checkpoint_path", "=", "resume_checkpoint_path", ",", "\n", "save_interval", "=", "save_interval", ",", "\n", "train_folder", "=", "train_folder", ",", "\n", "weight_decay", "=", "weight_decay", ")", "\n", "\n", "# Logging the model after every epoch.", "\n", "# Confirm the output directory exists.", "\n", "log_csv", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "with", "log_csv", ".", "open", "(", "mode", "=", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "\"epoch,train_loss,train_acc,val_loss,val_acc\\n\"", ")", "\n", "# Train the model.", "\n", "train_helper", "(", "model", "=", "model", ",", "\n", "dataloaders", "=", "dataloaders", ",", "\n", "dataset_sizes", "=", "dataset_sizes", ",", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ",", "\n", "optimizer", "=", "optimizer", ",", "\n", "scheduler", "=", "scheduler", ",", "\n", "start_epoch", "=", "start_epoch", ",", "\n", "writer", "=", "writer", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "checkpoints_folder", "=", "checkpoints_folder", ",", "\n", "device", "=", "device", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "save_interval", "=", "save_interval", ",", "\n", "num_epochs", "=", "num_epochs", ",", "\n", "classes", "=", "classes", ",", "\n", "num_classes", "=", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.parse_val_acc": [[506, 518], ["float", "model_path.name.split"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split"], ["", "", "def", "parse_val_acc", "(", "model_path", ":", "Path", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Parse the validation accuracy from the filename.\n\n    Args:\n        model_path: The model path to parse for the validation accuracy.\n\n    Returns:\n        The parsed validation accuracy.\n    \"\"\"", "\n", "return", "float", "(", "\n", "f\"{('.'.join(model_path.name.split('.')[:-1])).split('_')[-1][2:]}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.get_best_model": [[520, 535], ["max", "operator.itemgetter", "utils_model.parse_val_acc", "checkpoints_folder.rglob", "str"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.parse_val_acc"], ["", "def", "get_best_model", "(", "checkpoints_folder", ":", "Path", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Finds the model with the best validation accuracy.\n\n    Args:\n        checkpoints_folder: Folder containing the models to test.\n\n    Returns:\n        The location of the model with the best validation accuracy.\n    \"\"\"", "\n", "return", "max", "(", "{", "\n", "model", ":", "parse_val_acc", "(", "model_path", "=", "model", ")", "\n", "for", "model", "in", "[", "m", "for", "m", "in", "checkpoints_folder", ".", "rglob", "(", "\"*.pt\"", ")", "if", "\".DS_Store\"", "not", "in", "str", "(", "m", ")", "]", "\n", "}", ".", "items", "(", ")", ",", "\n", "key", "=", "operator", ".", "itemgetter", "(", "1", ")", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.get_predictions": [[537, 640], ["utils_model.create_model", "torch.load", "torch.load", "torch.load", "model.to.load_state_dict", "model.to.to", "model.to.train", "print", "time.time", "utils.get_subfolder_paths", "output_folder.mkdir", "print", "utils_model.get_best_model", "image_folder.joinpath.joinpath", "utils.get_image_paths", "print", "range", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "output_folder.joinpath().open", "writer.write", "enumerate", "print", "torch.max", "torch.max", "torch.max", "range", "torchvision.datasets.ImageFolder", "output_folder.joinpath", "[].split", "writer.write", "time.time", "torch.Softmax", "model.to.", "str", "torchvision.transforms.Compose", "test_inputs.to", "batch_window_names[].name.split", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "confidences[].data.item", "test_preds[].data.item"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.create_model", "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.3_repiece_jpg_tiles.get_subfolder_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_model.get_best_model", "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.4_anonymize.get_image_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split"], ["", "def", "get_predictions", "(", "patches_eval_folder", ":", "Path", ",", "output_folder", ":", "Path", ",", "\n", "checkpoints_folder", ":", "Path", ",", "auto_select", ":", "bool", ",", "\n", "eval_model", ":", "Path", ",", "device", ":", "torch", ".", "device", ",", "classes", ":", "List", "[", "str", "]", ",", "\n", "num_classes", ":", "int", ",", "path_mean", ":", "List", "[", "float", "]", ",", "\n", "path_std", ":", "List", "[", "float", "]", ",", "num_layers", ":", "int", ",", "pretrain", ":", "bool", ",", "\n", "batch_size", ":", "int", ",", "num_workers", ":", "int", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Main function for running the model on all of the generated patches.\n\n    Args:\n        patches_eval_folder: Folder containing patches to evaluate on.\n        output_folder: Folder to save the model results to.\n        checkpoints_folder: Directory to save model checkpoints to.\n        auto_select: Automatically select the model with the highest validation accuracy,\n        eval_model: Path to the model with the highest validation accuracy.\n        device: Device to use for running model.\n        classes: Names of the classes in the dataset.\n        num_classes: Number of classes in the dataset.\n        path_mean: Means of the WSIs for each dimension.\n        path_std: Standard deviations of the WSIs for each dimension.\n        num_layers: Number of layers to use in the ResNet model from [18, 34, 50, 101, 152].\n        pretrain: Use pretrained ResNet weights.\n        batch_size: Mini-batch size to use for training.\n        num_workers: Number of workers to use for IO.\n    \"\"\"", "\n", "# Initialize the model.", "\n", "model_path", "=", "get_best_model", "(", "\n", "checkpoints_folder", "=", "checkpoints_folder", ")", "if", "auto_select", "else", "eval_model", "\n", "\n", "model", "=", "create_model", "(", "num_classes", "=", "num_classes", ",", "\n", "num_layers", "=", "num_layers", ",", "\n", "pretrain", "=", "pretrain", ")", "\n", "ckpt", "=", "torch", ".", "load", "(", "f", "=", "model_path", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", "=", "ckpt", "[", "\"model_state_dict\"", "]", ")", "\n", "model", "=", "model", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "model", ".", "train", "(", "mode", "=", "False", ")", "\n", "print", "(", "f\"model loaded from {model_path}\"", ")", "\n", "\n", "# For outputting the predictions.", "\n", "class_num_to_class", "=", "{", "i", ":", "classes", "[", "i", "]", "for", "i", "in", "range", "(", "num_classes", ")", "}", "\n", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "# Load the data for each folder.", "\n", "image_folders", "=", "get_subfolder_paths", "(", "folder", "=", "patches_eval_folder", ")", "\n", "\n", "# Where we want to write out the predictions.", "\n", "# Confirm the output directory exists.", "\n", "output_folder", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# For each WSI.", "\n", "for", "image_folder", "in", "image_folders", ":", "\n", "\n", "# Temporary fix. Need not to make folders with no crops.", "\n", "        ", "try", ":", "\n", "# Load the image dataset.", "\n", "            ", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "datasets", ".", "ImageFolder", "(", "\n", "root", "=", "str", "(", "image_folder", ")", ",", "\n", "transform", "=", "transforms", ".", "Compose", "(", "transforms", "=", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "path_mean", ",", "std", "=", "path_std", ")", "\n", "]", ")", ")", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "num_workers", ")", "\n", "", "except", "RuntimeError", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: One of the image directories is empty. Skipping this directory.\"", "\n", ")", "\n", "continue", "\n", "\n", "", "num_test_image_windows", "=", "len", "(", "dataloader", ")", "*", "batch_size", "\n", "\n", "# Load the image names so we know the coordinates of the patches we are predicting.", "\n", "image_folder", "=", "image_folder", ".", "joinpath", "(", "image_folder", ".", "name", ")", "\n", "window_names", "=", "get_image_paths", "(", "folder", "=", "image_folder", ")", "\n", "\n", "print", "(", "f\"testing on {num_test_image_windows} crops from {image_folder}\"", ")", "\n", "\n", "with", "output_folder", ".", "joinpath", "(", "f\"{image_folder.name}.csv\"", ")", ".", "open", "(", "\n", "mode", "=", "\"w\"", ")", "as", "writer", ":", "\n", "\n", "            ", "writer", ".", "write", "(", "\"x,y,prediction,confidence\\n\"", ")", "\n", "\n", "# Loop through all of the patches.", "\n", "for", "batch_num", ",", "(", "test_inputs", ",", "test_labels", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "                ", "batch_window_names", "=", "window_names", "[", "batch_num", "*", "\n", "batch_size", ":", "batch_num", "*", "\n", "batch_size", "+", "batch_size", "]", "\n", "\n", "confidences", ",", "test_preds", "=", "torch", ".", "max", "(", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "(", "model", "(", "\n", "test_inputs", ".", "to", "(", "device", "=", "device", ")", ")", ")", ",", "\n", "dim", "=", "1", ")", "\n", "for", "i", "in", "range", "(", "test_preds", ".", "shape", "[", "0", "]", ")", ":", "\n", "# Find coordinates and predicted class.", "\n", "                    ", "xy", "=", "batch_window_names", "[", "i", "]", ".", "name", ".", "split", "(", "\".\"", ")", "[", "0", "]", ".", "split", "(", "\";\"", ")", "\n", "\n", "writer", ".", "write", "(", "\n", "f\"{','.join([xy[0], xy[1], f'{class_num_to_class[test_preds[i].data.item()]}', f'{confidences[i].data.item():.5f}'])}\\n\"", "\n", ")", "\n", "\n", "", "", "", "", "print", "(", "f\"time for {patches_eval_folder}: {time.time() - start:.2f} seconds\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.get_prediction": [[26, 65], ["list", "conf_thresholds.keys", "patches_pred_file.open", "patches_pred.readlines", "line[].split", "float", "sum", "pathlib.Path().with_suffix", "class_to_count.values", "max", "sum", "pathlib.Path", "class_to_percent.items", "class_to_count.values", "operator.itemgetter"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split"], ["def", "get_prediction", "(", "patches_pred_file", ":", "Path", ",", "conf_thresholds", ":", "Dict", "[", "str", ",", "float", "]", ",", "\n", "image_ext", ":", "str", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    Find the predicted class for a single WSI.\n\n    Args:\n        patches_pred_file: File containing the predicted classes for the patches that make up the WSI.\n        conf_thresholds: Confidence thresholds to determine membership in a class (filter out noise).\n        image_ext: Image extension for saving patches.\n\n    Returns:\n        A string containing the accuracy of classification for each class using the thresholds.\n    \"\"\"", "\n", "classes", "=", "list", "(", "conf_thresholds", ".", "keys", "(", ")", ")", "\n", "# Predicted class distribution per slide.", "\n", "class_to_count", "=", "{", "_class", ":", "0", "for", "_class", "in", "classes", "}", "\n", "\n", "# Looping through all the lines in the file and adding predictions.", "\n", "with", "patches_pred_file", ".", "open", "(", "mode", "=", "\"r\"", ")", "as", "patches_pred", ":", "\n", "\n", "        ", "patches_pred_lines", "=", "patches_pred", ".", "readlines", "(", ")", "[", "1", ":", "]", "\n", "\n", "for", "line", "in", "patches_pred_lines", ":", "\n", "            ", "line_items", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "\",\"", ")", "\n", "line_class", "=", "line_items", "[", "2", "]", "\n", "line_conf", "=", "float", "(", "line_items", "[", "3", "]", ")", "\n", "if", "line_class", "in", "classes", "and", "line_conf", ">", "conf_thresholds", "[", "\n", "line_class", "]", ":", "\n", "                ", "class_to_count", "[", "line_class", "]", "+=", "1", "\n", "", "", "if", "sum", "(", "class_to_count", ".", "values", "(", ")", ")", ">", "0", ":", "\n", "            ", "class_to_percent", "=", "{", "\n", "_class", ":", "class_to_count", "[", "_class", "]", "/", "sum", "(", "class_to_count", ".", "values", "(", ")", ")", "\n", "for", "_class", "in", "class_to_count", "\n", "}", "\n", "", "else", ":", "\n", "            ", "class_to_percent", "=", "{", "_class", ":", "0", "for", "_class", "in", "class_to_count", "}", "\n", "\n", "# Creating the line for output to CSV.", "\n", "", "", "return", "f\"{Path(patches_pred_file.name).with_suffix(f'.{image_ext}')},\"", "f\"{max(class_to_percent.items(), key=operator.itemgetter(1))[0]},\""]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.output_all_predictions": [[70, 105], ["output_folder.joinpath", "output_folder.joinpath.parent.mkdir", "output_folder.joinpath.open", "writer.write", "utils.get_csv_paths", "writer.write", "str", "utils_evaluation.get_prediction"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.get_csv_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.get_prediction"], ["", "def", "output_all_predictions", "(", "patches_pred_folder", ":", "Path", ",", "output_folder", ":", "Path", ",", "\n", "conf_thresholds", ":", "Dict", "[", "str", ",", "float", "]", ",", "\n", "classes", ":", "List", "[", "str", "]", ",", "image_ext", ":", "str", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Output the predictions for the WSI into a CSV file.\n\n    Args:\n        patches_pred_folder: Folder containing the predicted classes for each patch.\n        output_folder: Folder to save the predicted classes for each WSI for each threshold.\n        conf_thresholds: The confidence thresholds for determining membership in a class (filter out noise).\n        classes: Names of the classes in the dataset.\n        image_ext: Image extension for saving patches.\n    \"\"\"", "\n", "# Open a new CSV file for each set of confidence thresholds used on each set of WSI.", "\n", "output_file", "=", "\"\"", ".", "join", "(", "[", "\n", "f\"{_class}{str(conf_thresholds[_class])[1:]}_\"", "\n", "for", "_class", "in", "conf_thresholds", "\n", "]", ")", "\n", "\n", "output_csv_path", "=", "output_folder", ".", "joinpath", "(", "f\"{output_file[:-1]}.csv\"", ")", "\n", "\n", "# Confirm the output directory exists.", "\n", "output_csv_path", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Write to the output CSV.", "\n", "with", "output_csv_path", ".", "open", "(", "mode", "=", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "\n", "f\"img,predicted,\"", "\n", "f\"{','.join([f'percent_{_class}' for _class in classes])},\"", "\n", "f\"{','.join([f'count_{_class}' for _class in classes])}\\n\"", ")", "\n", "\n", "csv_paths", "=", "get_csv_paths", "(", "folder", "=", "patches_pred_folder", ")", "\n", "for", "csv_path", "in", "csv_paths", ":", "\n", "            ", "writer", ".", "write", "(", "\n", "f\"{get_prediction(patches_pred_file=csv_path, conf_thresholds=conf_thresholds, image_ext=image_ext)}\\n\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.grid_search": [[108, 129], ["utils_evaluation.output_all_predictions"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.output_all_predictions"], ["", "", "", "def", "grid_search", "(", "pred_folder", ":", "Path", ",", "inference_folder", ":", "Path", ",", "classes", ":", "List", "[", "str", "]", ",", "\n", "threshold_search", ":", "Tuple", "[", "float", "]", ",", "image_ext", ":", "str", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Main function for performing the grid search over the confidence thresholds. Initially outputs\n    predictions for each threshold.\n\n    Args:\n        pred_folder: Path containing the predictions.\n        inference_folder: Path to write predictions to.\n        classes: Names of the classes in the dataset.\n        threshold_search: Threshold values to search.\n        image_ext: Image extension for saving patches.\n    \"\"\"", "\n", "for", "threshold", "in", "threshold_search", ":", "\n", "        ", "output_all_predictions", "(", "\n", "patches_pred_folder", "=", "pred_folder", ",", "\n", "output_folder", "=", "inference_folder", ",", "\n", "conf_thresholds", "=", "{", "_class", ":", "threshold", "\n", "for", "_class", "in", "classes", "}", ",", "\n", "classes", "=", "classes", ",", "\n", "image_ext", "=", "image_ext", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.get_scores": [[134, 179], ["sorted", "sklearn.metrics.confusion_matrix", "gt_labels.keys", "sum", "len", "gts.append", "preds.append", "float", "list", "print", "class_to_acc.values"], "function", ["None"], ["", "", "def", "get_scores", "(", "gt_labels", ":", "Dict", "[", "str", ",", "str", "]", ",", "prediction_labels", ":", "Dict", "[", "str", ",", "str", "]", ",", "\n", "classes", ":", "List", "[", "str", "]", ")", "->", "Tuple", "[", "float", ",", "np", ".", "ndarray", "]", ":", "\n", "    ", "\"\"\"\n    Find the average class accuracy of the predictions.\n\n    Args:\n        gt_labels: Ground truth label dictionary from filenames to label strings.\n        prediction_labels: Predicted label dictionary from filenames to label strings.\n        classes: Names of the classes in the dataset.\n\n    Returns:\n        A tuple containing the average class accuracy and a confusion matrix.\n    \"\"\"", "\n", "class_to_gt_count", "=", "{", "_class", ":", "0", "for", "_class", "in", "classes", "}", "\n", "class_to_pred_count", "=", "{", "_class", ":", "0", "for", "_class", "in", "classes", "}", "\n", "gts", "=", "[", "]", "\n", "preds", "=", "[", "]", "\n", "\n", "for", "file", "in", "sorted", "(", "gt_labels", ".", "keys", "(", ")", ")", ":", "\n", "# Temporary fix. Need not to make folders with no crops.", "\n", "        ", "try", ":", "\n", "            ", "gt_label", "=", "gt_labels", "[", "file", "]", "\n", "pred_label", "=", "prediction_labels", "[", "file", "]", "\n", "gts", ".", "append", "(", "gt_label", ")", "\n", "preds", ".", "append", "(", "pred_label", ")", "\n", "\n", "# Predicted label is correct.", "\n", "if", "gt_label", "==", "pred_label", ":", "\n", "                ", "class_to_pred_count", "[", "gt_label", "]", "+=", "1", "\n", "\n", "# Add to total.", "\n", "", "class_to_gt_count", "[", "gt_label", "]", "+=", "1", "\n", "", "except", "KeyError", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: One of the image directories is empty. Skipping this directory.\"", "\n", ")", "\n", "continue", "\n", "\n", "", "", "conf_matrix", "=", "confusion_matrix", "(", "y_true", "=", "gts", ",", "y_pred", "=", "preds", ")", "\n", "class_to_acc", "=", "{", "\n", "_class", ":", "float", "(", "class_to_pred_count", "[", "_class", "]", ")", "/", "class_to_gt_count", "[", "_class", "]", "\n", "for", "_class", "in", "class_to_gt_count", "\n", "}", "\n", "avg_class_acc", "=", "sum", "(", "list", "(", "class_to_acc", ".", "values", "(", ")", ")", ")", "/", "len", "(", "class_to_acc", ")", "\n", "return", "avg_class_acc", ",", "conf_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.parse_thresholds": [[181, 200], ["str().split", "item.split", "float", "str", "pathlib.Path().with_suffix", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split"], ["", "def", "parse_thresholds", "(", "csv_path", ":", "Path", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "    ", "\"\"\"\n    Parse the CSV filename to find the classes for each threshold.\n\n    Args:\n        csv_path: Path to the CSV file containing the classes.\n\n    Returns:\n        A dictionary mapping class names to thresholds.\n    \"\"\"", "\n", "class_to_threshold", "=", "{", "}", "\n", "items", "=", "str", "(", "Path", "(", "csv_path", ".", "name", ")", ".", "with_suffix", "(", "\"\"", ")", ")", ".", "split", "(", "\"_\"", ")", "\n", "\n", "for", "item", "in", "items", ":", "\n", "        ", "subitems", "=", "item", ".", "split", "(", "\".\"", ")", "\n", "_class", "=", "subitems", "[", "0", "]", "\n", "class_to_threshold", "[", "_class", "]", "=", "float", "(", "f\"0.{subitems[1]}\"", ")", "\n", "\n", "", "return", "class_to_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.find_best_acc_and_thresh": [[202, 235], ["utils.create_labels", "utils.get_csv_paths", "print", "utils.create_labels", "utils_evaluation.get_scores", "print", "utils_evaluation.parse_thresholds", "utils_evaluation.parse_thresholds"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.create_labels", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.get_csv_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.create_labels", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.get_scores", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.parse_thresholds", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.parse_thresholds"], ["", "def", "find_best_acc_and_thresh", "(", "labels_csv", ":", "Path", ",", "\n", "inference_folder", ":", "Path", ",", "classes", ":", "List", "[", "str", "]", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "    ", "\"\"\"\n    Find the best accuracy and threshold for the given images.\n\n    Args:\n        labels_csv: CSV file containing the ground truth labels.\n        inference_folder: Folder containing the predicted labels. \n        classes: Names of the classes in the dataset.\n\n    Returns:\n        A dictionary mapping class names to the best thresholds.\n    \"\"\"", "\n", "gt_labels", "=", "create_labels", "(", "csv_path", "=", "labels_csv", ")", "\n", "prediction_csv_paths", "=", "get_csv_paths", "(", "folder", "=", "inference_folder", ")", "\n", "best_acc", "=", "0", "\n", "best_thresholds", "=", "None", "\n", "best_csv", "=", "None", "\n", "for", "prediction_csv_path", "in", "prediction_csv_paths", ":", "\n", "        ", "prediction_labels", "=", "create_labels", "(", "csv_path", "=", "prediction_csv_path", ")", "\n", "avg_class_acc", ",", "conf_matrix", "=", "get_scores", "(", "\n", "gt_labels", "=", "gt_labels", ",", "\n", "prediction_labels", "=", "prediction_labels", ",", "\n", "classes", "=", "classes", ")", "\n", "print", "(", "f\"thresholds {parse_thresholds(csv_path=prediction_csv_path)} \"", "\n", "f\"has average class accuracy {avg_class_acc:.5f}\"", ")", "\n", "if", "best_acc", "<", "avg_class_acc", ":", "\n", "            ", "best_acc", "=", "avg_class_acc", "\n", "best_csv", "=", "prediction_csv_path", "\n", "best_thresholds", "=", "parse_thresholds", "(", "csv_path", "=", "prediction_csv_path", ")", "\n", "", "", "print", "(", "f\"view these predictions in {best_csv}\"", ")", "\n", "return", "best_thresholds", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.print_final_test_results": [[237, 256], ["utils.create_labels", "utils.get_csv_paths", "utils.create_labels", "utils_evaluation.get_scores", "print"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.create_labels", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.get_csv_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.create_labels", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.get_scores"], ["", "def", "print_final_test_results", "(", "labels_csv", ":", "Path", ",", "inference_folder", ":", "Path", ",", "\n", "classes", ":", "List", "[", "str", "]", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Print the final accuracy and confusion matrix.\n\n    Args:\n        labels_csv: CSV file containing the ground truth labels.\n        inference_folder: Folder containing the predicted labels.\n        classes: Names of the classes in the dataset.\n    \"\"\"", "\n", "gt_labels", "=", "create_labels", "(", "csv_path", "=", "labels_csv", ")", "\n", "prediction_csv_paths", "=", "get_csv_paths", "(", "folder", "=", "inference_folder", ")", "\n", "for", "prediction_csv_path", "in", "prediction_csv_paths", ":", "\n", "        ", "prediction_labels", "=", "create_labels", "(", "csv_path", "=", "prediction_csv_path", ")", "\n", "avg_class_acc", ",", "conf_matrix", "=", "get_scores", "(", "\n", "gt_labels", "=", "gt_labels", ",", "\n", "prediction_labels", "=", "prediction_labels", ",", "\n", "classes", "=", "classes", ")", "\n", "print", "(", "f\"test set has final avg class acc: {avg_class_acc:.5f}\"", "\n", "f\"\\n{conf_matrix}\"", ")", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.color_to_np_color": [[262, 284], ["numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["None"], ["", "", "def", "color_to_np_color", "(", "color", ":", "str", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Convert strings to NumPy colors.\n\n    Args:\n        color: The desired color as a string.\n\n    Returns:\n        The NumPy ndarray representation of the color.\n    \"\"\"", "\n", "colors", "=", "{", "\n", "\"white\"", ":", "np", ".", "array", "(", "[", "255", ",", "255", ",", "255", "]", ")", ",", "\n", "\"pink\"", ":", "np", ".", "array", "(", "[", "255", ",", "108", ",", "180", "]", ")", ",", "\n", "\"black\"", ":", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", "]", ")", ",", "\n", "\"red\"", ":", "np", ".", "array", "(", "[", "255", ",", "0", ",", "0", "]", ")", ",", "\n", "\"purple\"", ":", "np", ".", "array", "(", "[", "225", ",", "225", ",", "0", "]", ")", ",", "\n", "\"yellow\"", ":", "np", ".", "array", "(", "[", "255", ",", "255", ",", "0", "]", ")", ",", "\n", "\"orange\"", ":", "np", ".", "array", "(", "[", "255", ",", "127", ",", "80", "]", ")", ",", "\n", "\"blue\"", ":", "np", ".", "array", "(", "[", "0", ",", "0", ",", "255", "]", ")", ",", "\n", "\"green\"", ":", "np", ".", "array", "(", "[", "0", ",", "255", ",", "0", "]", ")", "\n", "}", "\n", "return", "colors", "[", "color", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.add_predictions_to_image": [[286, 314], ["xy_to_pred_class.keys", "int", "int", "round", "round"], "function", ["None"], ["", "def", "add_predictions_to_image", "(", "\n", "xy_to_pred_class", ":", "Dict", "[", "Tuple", "[", "str", ",", "str", "]", ",", "Tuple", "[", "str", ",", "float", "]", "]", ",", "\n", "image", ":", "np", ".", "ndarray", ",", "prediction_to_color", ":", "Dict", "[", "str", ",", "np", ".", "ndarray", "]", ",", "\n", "patch_size", ":", "int", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Overlay the predicted dots (classes) on the WSI.\n\n    Args:\n        xy_to_pred_class: Dictionary mapping coordinates to predicted class along with the confidence.\n        image: WSI to add predicted dots to.\n        prediction_to_color: Dictionary mapping string color to NumPy ndarray color.\n        patch_size: Size of the patches extracted from the WSI.\n\n    Returns:\n        The WSI with the predicted class dots overlaid.\n    \"\"\"", "\n", "for", "x", ",", "y", "in", "xy_to_pred_class", ".", "keys", "(", ")", ":", "\n", "        ", "prediction", ",", "__", "=", "xy_to_pred_class", "[", "x", ",", "y", "]", "\n", "x", "=", "int", "(", "x", ")", "\n", "y", "=", "int", "(", "y", ")", "\n", "\n", "# Enlarge the dots so they are visible at larger scale.", "\n", "start", "=", "round", "(", "(", "0.9", "*", "patch_size", ")", "/", "2", ")", "\n", "end", "=", "round", "(", "(", "1.1", "*", "patch_size", ")", "/", "2", ")", "\n", "image", "[", "x", "+", "start", ":", "x", "+", "end", ",", "y", "+", "start", ":", "y", "+", "\n", "end", ",", ":", "]", "=", "prediction_to_color", "[", "prediction", "]", "\n", "\n", "", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.get_xy_to_pred_class": [[316, 343], ["window_prediction_folder.joinpath().with_suffix().open", "csv_lines_open.readlines", "line[].split", "float", "window_prediction_folder.joinpath().with_suffix", "window_prediction_folder.joinpath"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split"], ["", "def", "get_xy_to_pred_class", "(", "window_prediction_folder", ":", "Path", ",", "img_name", ":", "str", "\n", ")", "->", "Dict", "[", "Tuple", "[", "str", ",", "str", "]", ",", "Tuple", "[", "str", ",", "float", "]", "]", ":", "\n", "    ", "\"\"\"\n    Find the dictionary of predictions.\n\n    Args:\n        window_prediction_folder: Path to the folder containing a CSV file with the predicted classes.\n        img_name: Name of the image to find the predicted classes for.\n\n    Returns:\n        A dictionary mapping image coordinates to the predicted class and the confidence of the prediction.\n    \"\"\"", "\n", "xy_to_pred_class", "=", "{", "}", "\n", "\n", "with", "window_prediction_folder", ".", "joinpath", "(", "img_name", ")", ".", "with_suffix", "(", "\".csv\"", ")", ".", "open", "(", "\n", "mode", "=", "\"r\"", ")", "as", "csv_lines_open", ":", "\n", "        ", "csv_lines", "=", "csv_lines_open", ".", "readlines", "(", ")", "[", "1", ":", "]", "\n", "\n", "predictions", "=", "[", "line", "[", ":", "-", "1", "]", ".", "split", "(", "\",\"", ")", "for", "line", "in", "csv_lines", "]", "\n", "for", "prediction", "in", "predictions", ":", "\n", "            ", "x", "=", "prediction", "[", "0", "]", "\n", "y", "=", "prediction", "[", "1", "]", "\n", "pred_class", "=", "prediction", "[", "2", "]", "\n", "confidence", "=", "float", "(", "prediction", "[", "3", "]", ")", "\n", "# Implement thresholding.", "\n", "xy_to_pred_class", "[", "(", "x", ",", "y", ")", "]", "=", "(", "pred_class", ",", "confidence", ")", "\n", "", "", "return", "xy_to_pred_class", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.visualize": [[345, 403], ["utils.get_all_image_paths", "print", "print", "utils_evaluation.color_to_np_color", "print", "pathlib.Path", "pathlib.Path.parent.mkdir", "range", "imageio.imread", "imageio.imsave", "len", "print", "vis_folder.joinpath().with_suffix", "utils_evaluation.add_predictions_to_image", "vis_folder.joinpath", "utils_evaluation.get_xy_to_pred_class"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.get_all_image_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.color_to_np_color", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.add_predictions_to_image", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_evaluation.get_xy_to_pred_class"], ["", "def", "visualize", "(", "wsi_folder", ":", "Path", ",", "preds_folder", ":", "Path", ",", "vis_folder", ":", "Path", ",", "\n", "classes", ":", "List", "[", "str", "]", ",", "num_classes", ":", "int", ",", "colors", ":", "Tuple", "[", "str", "]", ",", "\n", "patch_size", ":", "int", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Main function for visualization.\n\n    Args:\n        wsi_folder: Path to WSI.\n        preds_folder: Path containing the predicted classes.\n        vis_folder: Path to output the WSI with overlaid classes to.\n        classes: Names of the classes in the dataset.\n        num_classes: Number of classes in the dataset.\n        colors: Colors to use for visualization.\n        patch_size: Size of the patches extracted from the WSI.\n    \"\"\"", "\n", "# Find list of WSI.", "\n", "whole_slides", "=", "get_all_image_paths", "(", "master_folder", "=", "wsi_folder", ")", "\n", "print", "(", "f\"{len(whole_slides)} whole slides found from {wsi_folder}\"", ")", "\n", "prediction_to_color", "=", "{", "\n", "classes", "[", "i", "]", ":", "color_to_np_color", "(", "color", "=", "colors", "[", "i", "]", ")", "\n", "for", "i", "in", "range", "(", "num_classes", ")", "\n", "}", "\n", "# Go over all of the WSI.", "\n", "for", "whole_slide", "in", "whole_slides", ":", "\n", "# Read in the image.", "\n", "        ", "whole_slide_numpy", "=", "imread", "(", "uri", "=", "whole_slide", ")", "[", "...", ",", "[", "0", ",", "1", ",", "2", "]", "]", "\n", "print", "(", "f\"visualizing {whole_slide} \"", "\n", "f\"of shape {whole_slide_numpy.shape}\"", ")", "\n", "\n", "assert", "whole_slide_numpy", ".", "shape", "[", "\n", "2", "]", "==", "3", ",", "f\"Expected 3 channels while your image has {whole_slide_numpy.shape[2]} channels.\"", "\n", "\n", "# Save it.", "\n", "output_path", "=", "Path", "(", "\n", "f\"{vis_folder.joinpath(whole_slide.name).with_suffix('')}\"", "\n", "f\"_predictions.jpg\"", ")", "\n", "\n", "# Confirm the output directory exists.", "\n", "output_path", ".", "parent", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Temporary fix. Need not to make folders with no crops.", "\n", "try", ":", "\n", "# Add the predictions to the image and save it.", "\n", "            ", "imsave", "(", "uri", "=", "output_path", ",", "\n", "im", "=", "add_predictions_to_image", "(", "\n", "xy_to_pred_class", "=", "get_xy_to_pred_class", "(", "\n", "window_prediction_folder", "=", "preds_folder", ",", "\n", "img_name", "=", "whole_slide", ".", "name", ")", ",", "\n", "image", "=", "whole_slide_numpy", ",", "\n", "prediction_to_color", "=", "prediction_to_color", ",", "\n", "patch_size", "=", "patch_size", ")", ")", "\n", "", "except", "FileNotFoundError", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: One of the image directories is empty. Skipping this directory\"", "\n", ")", "\n", "continue", "\n", "\n", "", "", "print", "(", "f\"find the visualizations in {vis_folder}\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.get_classes": [[16, 28], ["sorted", "folder.iterdir", "folder.joinpath().is_dir", "folder.joinpath"], "function", ["None"], ["def", "get_classes", "(", "folder", ":", "Path", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "\"\"\"\n    Find the classes for classification.\n\n    Args:\n        folder: Folder containing the subfolders named by class.\n\n    Returns:\n        A list of strings corresponding to the class names.\n    \"\"\"", "\n", "return", "sorted", "(", "[", "f", ".", "name", "for", "f", "in", "folder", ".", "iterdir", "(", ")", "if", "\n", "(", "(", "folder", ".", "joinpath", "(", "f", ".", "name", ")", ".", "is_dir", "(", ")", ")", "and", "(", "\".DS_Store\"", "not", "in", "f", ".", "name", ")", ")", "]", ",", "key", "=", "str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.get_log_csv_name": [[30, 43], ["datetime.datetime.now", "log_folder.joinpath"], "function", ["None"], ["", "def", "get_log_csv_name", "(", "log_folder", ":", "Path", ")", "->", "Path", ":", "\n", "    ", "\"\"\"\n    Find the name of the CSV file for logging.\n\n    Args:\n        log_folder: Folder to save logging CSV file in.\n\n    Returns:\n        The path including the filename of the logging CSV file with date information.\n    \"\"\"", "\n", "now", "=", "datetime", ".", "datetime", ".", "now", "(", ")", "\n", "\n", "return", "log_folder", ".", "joinpath", "(", "f\"log_{now.month}{now.day}{now.year}\"", "\n", "f\"_{now.hour}{now.minute}{now.second}.csv\"", ")", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.get_image_names": [[46, 58], ["sorted", "pathlib.Path", "folder.iterdir", "folder.joinpath().is_file", "f.suffix.casefold", "folder.joinpath"], "function", ["None"], ["", "def", "get_image_names", "(", "folder", ":", "Path", ")", "->", "List", "[", "Path", "]", ":", "\n", "    ", "\"\"\"\n    Find the names and paths of all of the images in a folder.\n\n    Args:\n        folder: Folder containing images (assume folder only contains images).\n\n    Returns:\n        A list of the names with paths of the images in a folder.\n    \"\"\"", "\n", "return", "sorted", "(", "[", "Path", "(", "f", ".", "name", ")", "for", "f", "in", "folder", ".", "iterdir", "(", ")", "if", "\n", "(", "(", "folder", ".", "joinpath", "(", "f", ".", "name", ")", ".", "is_file", "(", ")", ")", "and", "(", "\".DS_Store\"", "not", "in", "f", ".", "name", ")", "and", "(", "f", ".", "suffix", ".", "casefold", "(", ")", "in", "IMAGE_EXTS", ")", ")", "]", ",", "key", "=", "str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.get_image_paths": [[60, 72], ["sorted", "folder.joinpath", "folder.iterdir", "folder.joinpath().is_file", "f.suffix.casefold", "folder.joinpath"], "function", ["None"], ["", "def", "get_image_paths", "(", "folder", ":", "Path", ")", "->", "List", "[", "Path", "]", ":", "\n", "    ", "\"\"\"\n    Find the full paths of the images in a folder.\n\n    Args:\n        folder: Folder containing images (assume folder only contains images).\n\n    Returns:\n        A list of the full paths to the images in the folder.\n    \"\"\"", "\n", "return", "sorted", "(", "[", "folder", ".", "joinpath", "(", "f", ".", "name", ")", "for", "f", "in", "folder", ".", "iterdir", "(", ")", "if", "\n", "(", "(", "folder", ".", "joinpath", "(", "f", ".", "name", ")", ".", "is_file", "(", ")", ")", "and", "(", "\".DS_Store\"", "not", "in", "f", ".", "name", ")", "and", "(", "f", ".", "suffix", ".", "casefold", "(", ")", "in", "IMAGE_EXTS", ")", ")", "]", ",", "key", "=", "str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.get_subfolder_paths": [[74, 86], ["sorted", "folder.joinpath", "folder.iterdir", "folder.joinpath().is_dir", "folder.joinpath"], "function", ["None"], ["", "def", "get_subfolder_paths", "(", "folder", ":", "Path", ")", "->", "List", "[", "Path", "]", ":", "\n", "    ", "\"\"\"\n    Find the paths of subfolders.\n\n    Args:\n        folder: Folder to look for subfolders in.\n\n    Returns:\n        A list containing the paths of the subfolders.\n    \"\"\"", "\n", "return", "sorted", "(", "[", "folder", ".", "joinpath", "(", "f", ".", "name", ")", "for", "f", "in", "folder", ".", "iterdir", "(", ")", "if", "\n", "(", "(", "folder", ".", "joinpath", "(", "f", ".", "name", ")", ".", "is_dir", "(", ")", ")", "and", "(", "\".DS_Store\"", "not", "in", "f", ".", "name", ")", ")", "]", ",", "key", "=", "str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.get_all_image_paths": [[88, 106], ["utils.get_subfolder_paths", "len", "utils.get_image_paths", "utils.get_image_paths"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.3_repiece_jpg_tiles.get_subfolder_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.4_anonymize.get_image_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.4_anonymize.get_image_paths"], ["", "def", "get_all_image_paths", "(", "master_folder", ":", "Path", ")", "->", "List", "[", "Path", "]", ":", "\n", "    ", "\"\"\"\n    Finds all image paths in subfolders.\n\n    Args:\n        master_folder: Root folder containing subfolders.\n\n    Returns:\n        A list of the paths to the images found in the folder.\n    \"\"\"", "\n", "all_paths", "=", "[", "]", "\n", "subfolders", "=", "get_subfolder_paths", "(", "folder", "=", "master_folder", ")", "\n", "if", "len", "(", "subfolders", ")", ">", "1", ":", "\n", "        ", "for", "subfolder", "in", "subfolders", ":", "\n", "            ", "all_paths", "+=", "get_image_paths", "(", "folder", "=", "subfolder", ")", "\n", "", "", "else", ":", "\n", "        ", "all_paths", "=", "get_image_paths", "(", "folder", "=", "master_folder", ")", "\n", "", "return", "all_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.get_csv_paths": [[108, 121], ["sorted", "folder.joinpath", "folder.iterdir", "folder.joinpath().is_file", "folder.joinpath"], "function", ["None"], ["", "def", "get_csv_paths", "(", "folder", ":", "Path", ")", "->", "List", "[", "Path", "]", ":", "\n", "    ", "\"\"\"\n    Find the CSV files contained in a folder.\n\n    Args:\n        folder: Folder to search for CSV files.\n\n    Returns:\n        A list of the paths to the CSV files in the folder.\n    \"\"\"", "\n", "return", "sorted", "(", "[", "folder", ".", "joinpath", "(", "f", ".", "name", ")", "for", "f", "in", "folder", ".", "iterdir", "(", ")", "if", "(", "\n", "(", "folder", ".", "joinpath", "(", "f", ".", "name", ")", ".", "is_file", "(", ")", ")", "and", "(", "\"csv\"", "in", "f", ".", "name", ")", "and", "(", "\".DS_Store\"", "not", "in", "f", ".", "name", ")", ")", "]", ",", "\n", "key", "=", "str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils.create_labels": [[123, 146], ["csv_path.open", "lines_open.readlines", "len", "line[].split"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split"], ["", "def", "create_labels", "(", "csv_path", ":", "Path", ")", "->", "Dict", "[", "str", ",", "str", "]", ":", "\n", "    ", "\"\"\"\n    Read the labels from a CSV file.\n\n    Args:\n        csv_path: Path to the CSV file.\n\n    Returns:\n        A dictionary mapping string filenames to string labels.\n    \"\"\"", "\n", "with", "csv_path", ".", "open", "(", "mode", "=", "\"r\"", ")", "as", "lines_open", ":", "\n", "        ", "lines", "=", "lines_open", ".", "readlines", "(", ")", "[", "1", ":", "]", "\n", "\n", "file_to_gt_label", "=", "{", "}", "\n", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "if", "len", "(", "line", ")", ">", "3", ":", "\n", "                ", "pieces", "=", "line", "[", ":", "-", "1", "]", ".", "split", "(", "\",\"", ")", "\n", "file", "=", "pieces", "[", "0", "]", "\n", "gt_label", "=", "pieces", "[", "1", "]", "\n", "file_to_gt_label", "[", "file", "]", "=", "gt_label", "\n", "\n", "", "", "", "return", "file_to_gt_label", "\n", "", ""]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.1_rename_files.get_image_paths": [[7, 12], ["os.path.join", "os.path.join", "image_paths.remove", "os.listdir", "os.path.isfile", "os.path.join", "os.path.join"], "function", ["None"], ["def", "get_image_paths", "(", "folder", ")", ":", "\n", "    ", "image_paths", "=", "[", "join", "(", "folder", ",", "f", ")", "for", "f", "in", "listdir", "(", "folder", ")", "if", "isfile", "(", "join", "(", "folder", ",", "f", ")", ")", "]", "\n", "if", "join", "(", "folder", ",", "'.DS_Store'", ")", "in", "image_paths", ":", "\n", "        ", "image_paths", ".", "remove", "(", "join", "(", "folder", ",", "'.DS_Store'", ")", ")", "\n", "", "return", "image_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.2_svs_to_jpg_tiles.output_jpeg_tiles": [[15, 49], ["openslide.OpenSlide", "int", "int", "print", "range", "math.ceil", "math.ceil", "range", "min", "min", "openslide.OpenSlide.read_region", "img.read_region.load", "PIL.Image.new", "patch_rgb.resize.paste", "patch_rgb.resize.resize", "os.path.join", "os.path.join", "patch_rgb.resize.save", "os.path.exists", "os.makedirs", "int", "int", "img.read_region.split", "image_name.split", "str", "str", "image_name.split"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split"], ["def", "output_jpeg_tiles", "(", "image_name", ",", "output_path", ")", ":", "# converts svs image with meta data into just the jpeg image", "\n", "\n", "    ", "img", "=", "openslide", ".", "OpenSlide", "(", "image_name", ")", "\n", "width", ",", "height", "=", "img", ".", "level_dimensions", "[", "0", "]", "\n", "\n", "increment_x", "=", "int", "(", "ceil", "(", "width", "/", "window_size", ")", ")", "\n", "increment_y", "=", "int", "(", "ceil", "(", "height", "/", "window_size", ")", ")", "\n", "\n", "print", "(", "\"converting\"", ",", "image_name", ",", "\"with width\"", ",", "width", ",", "\"and height\"", ",", "height", ")", "\n", "\n", "for", "incre_x", "in", "range", "(", "increment_x", ")", ":", "# have to read the image in patches since it doesn't let me do it for larger things", "\n", "        ", "for", "incre_y", "in", "range", "(", "increment_y", ")", ":", "\n", "\n", "            ", "begin_x", "=", "window_size", "*", "incre_x", "\n", "end_x", "=", "min", "(", "width", ",", "begin_x", "+", "window_size", ")", "\n", "begin_y", "=", "window_size", "*", "incre_y", "\n", "end_y", "=", "min", "(", "height", ",", "begin_y", "+", "window_size", ")", "\n", "patch_width", "=", "end_x", "-", "begin_x", "\n", "patch_height", "=", "end_y", "-", "begin_y", "\n", "\n", "patch", "=", "img", ".", "read_region", "(", "(", "begin_x", ",", "begin_y", ")", ",", "0", ",", "(", "patch_width", ",", "patch_height", ")", ")", "\n", "patch", ".", "load", "(", ")", "\n", "patch_rgb", "=", "Image", ".", "new", "(", "\"RGB\"", ",", "patch", ".", "size", ",", "(", "255", ",", "255", ",", "255", ")", ")", "\n", "patch_rgb", ".", "paste", "(", "patch", ",", "mask", "=", "patch", ".", "split", "(", ")", "[", "3", "]", ")", "\n", "\n", "# compress the image", "\n", "patch_rgb", "=", "patch_rgb", ".", "resize", "(", "(", "int", "(", "patch_rgb", ".", "size", "[", "0", "]", "/", "compression_factor", ")", ",", "int", "(", "patch_rgb", ".", "size", "[", "1", "]", "/", "compression_factor", ")", ")", ",", "Image", ".", "ANTIALIAS", ")", "\n", "\n", "# save the image", "\n", "output_subfolder", "=", "join", "(", "output_path", ",", "image_name", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_subfolder", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "output_subfolder", ")", "\n", "", "output_image_name", "=", "join", "(", "output_subfolder", ",", "image_name", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", "+", "'_'", "+", "str", "(", "incre_x", ")", "+", "'_'", "+", "str", "(", "incre_y", ")", "+", "'.jpg'", ")", "\n", "patch_rgb", ".", "save", "(", "output_image_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.3_repiece_jpg_tiles.get_image_paths": [[14, 19], ["os.path.join", "os.path.join", "image_paths.remove", "os.listdir", "os.path.isfile", "os.path.join", "os.path.join"], "function", ["None"], ["def", "get_image_paths", "(", "folder", ")", ":", "\n", "    ", "image_paths", "=", "[", "join", "(", "folder", ",", "f", ")", "for", "f", "in", "listdir", "(", "folder", ")", "if", "isfile", "(", "join", "(", "folder", ",", "f", ")", ")", "]", "\n", "if", "join", "(", "folder", ",", "'.DS_Store'", ")", "in", "image_paths", ":", "\n", "        ", "image_paths", ".", "remove", "(", "join", "(", "folder", ",", "'.DS_Store'", ")", ")", "\n", "", "return", "image_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.3_repiece_jpg_tiles.get_subfolder_paths": [[21, 26], ["os.path.join", "os.path.join", "subfolder_paths.remove", "os.listdir", "os.path.join", "os.path.isdir", "os.path.join"], "function", ["None"], ["", "def", "get_subfolder_paths", "(", "folder", ")", ":", "\n", "    ", "subfolder_paths", "=", "[", "join", "(", "folder", ",", "f", ")", "for", "f", "in", "listdir", "(", "folder", ")", "if", "(", "isdir", "(", "join", "(", "folder", ",", "f", ")", ")", "and", "'.DS_Store'", "not", "in", "f", ")", "]", "\n", "if", "join", "(", "folder", ",", "'.DS_Store'", ")", "in", "subfolder_paths", ":", "\n", "        ", "subfolder_paths", ".", "remove", "(", "join", "(", "folder", ",", "'.DS_Store'", ")", ")", "\n", "", "return", "subfolder_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.3_repiece_jpg_tiles.get_num_horizontal_positions": [[28, 35], ["3_repiece_jpg_tiles.get_image_paths", "len", "int", "horizontal_positions.append", "set", "[].split", "[].split", "image_path.split"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.4_anonymize.get_image_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split"], ["", "def", "get_num_horizontal_positions", "(", "input_folder", ")", ":", "\n", "    ", "horizontal_positions", "=", "[", "]", "\n", "image_paths", "=", "get_image_paths", "(", "input_folder", ")", "\n", "for", "image_path", "in", "image_paths", ":", "\n", "        ", "x_increment", "=", "int", "(", "image_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "\n", "horizontal_positions", ".", "append", "(", "x_increment", ")", "\n", "", "return", "len", "(", "set", "(", "horizontal_positions", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.3_repiece_jpg_tiles.get_num_vertical_positions": [[37, 44], ["3_repiece_jpg_tiles.get_image_paths", "len", "int", "vertical_positions.append", "set", "[].split", "[].split", "image_path.split"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.4_anonymize.get_image_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split"], ["", "def", "get_num_vertical_positions", "(", "input_folder", ")", ":", "\n", "    ", "vertical_positions", "=", "[", "]", "\n", "image_paths", "=", "get_image_paths", "(", "input_folder", ")", "\n", "for", "image_path", "in", "image_paths", ":", "\n", "        ", "x_increment", "=", "int", "(", "image_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", ".", "split", "(", "'_'", ")", "[", "2", "]", ")", "\n", "vertical_positions", ".", "append", "(", "x_increment", ")", "\n", "", "return", "len", "(", "set", "(", "vertical_positions", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.3_repiece_jpg_tiles.output_repieced_image": [[46, 72], ["3_repiece_jpg_tiles.get_num_horizontal_positions", "3_repiece_jpg_tiles.get_num_vertical_positions", "3_repiece_jpg_tiles.get_image_paths", "map", "zip", "min", "min", "PIL.Image.new", "Image.new.save", "int", "int", "PIL.Image.open", "Image.new.paste", "[].split", "[].split", "[].split", "[].split", "image_path.split", "image_path.split"], "function", ["home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.3_repiece_jpg_tiles.get_num_horizontal_positions", "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.3_repiece_jpg_tiles.get_num_vertical_positions", "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.4_anonymize.get_image_paths", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split", "home.repos.pwc.inspect_result.BMIRDS_deepslide.code.utils_split.split"], ["", "def", "output_repieced_image", "(", "input_folder", ",", "output_image_path", ")", ":", "\n", "\n", "    ", "num_horizontal_positions", "=", "get_num_horizontal_positions", "(", "input_folder", ")", "\n", "num_vertical_positions", "=", "get_num_vertical_positions", "(", "input_folder", ")", "\n", "\n", "image_paths", "=", "get_image_paths", "(", "input_folder", ")", "\n", "images", "=", "map", "(", "Image", ".", "open", ",", "image_paths", ")", "\n", "widths", ",", "heights", "=", "zip", "(", "*", "(", "i", ".", "size", "for", "i", "in", "images", ")", ")", "\n", "\n", "last_width", "=", "min", "(", "widths", ")", "\n", "last_height", "=", "min", "(", "heights", ")", "\n", "\n", "total_width", "=", "(", "num_horizontal_positions", "-", "1", ")", "*", "compressed_window_size", "+", "last_width", "\n", "total_height", "=", "(", "num_vertical_positions", "-", "1", ")", "*", "compressed_window_size", "+", "last_height", "\n", "\n", "new_im", "=", "Image", ".", "new", "(", "'RGB'", ",", "(", "total_width", ",", "total_height", ")", ")", "\n", "\n", "for", "image_path", "in", "image_paths", ":", "\n", "\n", "        ", "x_increment", "=", "int", "(", "image_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", "\n", "y_increment", "=", "int", "(", "image_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", ".", "split", "(", "'_'", ")", "[", "2", "]", ")", "\n", "\n", "image", "=", "Image", ".", "open", "(", "image_path", ")", "\n", "new_im", ".", "paste", "(", "image", ",", "(", "compressed_window_size", "*", "x_increment", ",", "compressed_window_size", "*", "y_increment", ")", ")", "\n", "\n", "", "new_im", ".", "save", "(", "output_image_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.4_anonymize.get_image_paths": [[7, 10], ["os.path.join", "os.listdir", "os.path.isfile", "os.path.join"], "function", ["None"], ["def", "get_image_paths", "(", "folder", ")", ":", "\n", "    ", "image_paths", "=", "[", "join", "(", "folder", ",", "f", ")", "for", "f", "in", "listdir", "(", "folder", ")", "if", "isfile", "(", "join", "(", "folder", ",", "f", ")", ")", "and", "'.DS_Store'", "not", "in", "f", "]", "\n", "return", "image_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.4_anonymize.get_alpha_name": [[12, 18], ["int", "int"], "function", ["None"], ["", "def", "get_alpha_name", "(", "number", ")", ":", "\n", "    ", "alphas", "=", "\"abcdefghijklmnopqrstuvwxyz\"", "\n", "first", "=", "int", "(", "number", "/", "26", "/", "26", ")", "\n", "second", "=", "int", "(", "number", "/", "26", ")", "%", "26", "\n", "third", "=", "number", "%", "26", "\n", "return", "alphas", "[", "first", "]", "+", "alphas", "[", "second", "]", "+", "alphas", "[", "third", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.BMIRDS_deepslide.z_preprocessing.4_anonymize.confirm_output_folder": [[21, 24], ["os.path.exists", "os.makedirs"], "function", ["None"], ["", "def", "confirm_output_folder", "(", "output_folder", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "output_folder", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_folder", ")", "\n", "\n"]]}