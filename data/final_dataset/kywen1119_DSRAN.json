{"home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.i2t_rerank": [[15, 38], ["numpy.argsort", "numpy.argsort", "numpy.array", "range", "numpy.copy", "range", "numpy.argsort", "numpy.array", "numpy.append", "numpy.where"], "function", ["None"], ["def", "i2t_rerank", "(", "sim", ",", "K1", ",", "K2", ")", ":", "#(d,15,1)", "\n", "\n", "    ", "size_i", "=", "sim", ".", "shape", "[", "0", "]", "# d", "\n", "size_t", "=", "sim", ".", "shape", "[", "1", "]", "# 5d", "\n", "sort_i2t", "=", "np", ".", "argsort", "(", "-", "sim", ",", "1", ")", "\n", "sort_t2i", "=", "np", ".", "argsort", "(", "-", "sim", ",", "0", ")", "\n", "sort_i2t_re", "=", "np", ".", "copy", "(", "sort_i2t", ")", "[", ":", ",", ":", "K1", "]", "\n", "address", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "size_i", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "K1", ")", ":", "\n", "            ", "result_t", "=", "sort_i2t", "[", "i", "]", "[", "j", "]", "\n", "query", "=", "sort_t2i", "[", ":", ",", "result_t", "]", "\n", "# query = sort_t2i[:K2, result_t]", "\n", "address", "=", "np", ".", "append", "(", "address", ",", "np", ".", "where", "(", "query", "==", "i", ")", "[", "0", "]", "[", "0", "]", ")", "\n", "\n", "", "sort", "=", "np", ".", "argsort", "(", "address", ")", "\n", "sort_i2t_re", "[", "i", "]", "=", "sort_i2t_re", "[", "i", "]", "[", "sort", "]", "\n", "address", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "", "sort_i2t", "[", ":", ",", ":", "K1", "]", "=", "sort_i2t_re", "\n", "\n", "return", "sort_i2t", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.t2i_rerank": [[40, 71], ["numpy.argsort", "numpy.argsort", "numpy.array", "range", "numpy.copy", "range", "numpy.argsort", "numpy.array", "numpy.append", "numpy.where"], "function", ["None"], ["", "def", "t2i_rerank", "(", "sim", ",", "K1", ",", "K2", ")", ":", "\n", "\n", "    ", "size_i", "=", "sim", ".", "shape", "[", "0", "]", "\n", "size_t", "=", "sim", ".", "shape", "[", "1", "]", "\n", "sort_i2t", "=", "np", ".", "argsort", "(", "-", "sim", ",", "1", ")", "\n", "sort_t2i", "=", "np", ".", "argsort", "(", "-", "sim", ",", "0", ")", "\n", "sort_t2i_re", "=", "np", ".", "copy", "(", "sort_t2i", ")", "[", ":", "K1", ",", ":", "]", "\n", "address", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "size_t", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "K1", ")", ":", "\n", "            ", "result_i", "=", "sort_t2i", "[", "j", "]", "[", "i", "]", "\n", "query", "=", "sort_i2t", "[", "result_i", ",", ":", "]", "\n", "# print(query)", "\n", "# query = sort_t2i[:K2, result_t]", "\n", "ranks", "=", "1e20", "\n", "# for k in range(5):", "\n", "#     qewfo = i//5 * 5 + k", "\n", "# print(np.where(query == i))", "\n", "tmp", "=", "np", ".", "where", "(", "query", "==", "i", ")", "[", "0", "]", "[", "0", "]", "\n", "if", "tmp", "<", "ranks", ":", "\n", "                ", "ranks", "=", "tmp", "\n", "", "address", "=", "np", ".", "append", "(", "address", ",", "ranks", ")", "\n", "\n", "", "sort", "=", "np", ".", "argsort", "(", "address", ")", "\n", "sort_t2i_re", "[", ":", ",", "i", "]", "=", "sort_t2i_re", "[", ":", ",", "i", "]", "[", "sort", "]", "\n", "address", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "", "sort_t2i", "[", ":", "K1", ",", ":", "]", "=", "sort_t2i_re", "\n", "\n", "return", "sort_t2i", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.t2i_rerank_new": [[73, 108], ["numpy.argsort", "numpy.argsort", "numpy.argsort", "numpy.array", "range", "numpy.copy", "numpy.copy", "range", "numpy.argsort", "numpy.array", "range", "numpy.append", "numpy.where"], "function", ["None"], ["", "def", "t2i_rerank_new", "(", "sim", ",", "sim_T", ",", "K1", ",", "K2", ")", ":", "\n", "\n", "    ", "size_i", "=", "sim", ".", "shape", "[", "0", "]", "\n", "size_t", "=", "sim", ".", "shape", "[", "1", "]", "\n", "sort_i2t", "=", "np", ".", "argsort", "(", "-", "sim", ",", "1", ")", "\n", "sort_t2i", "=", "np", ".", "argsort", "(", "-", "sim", ",", "0", ")", "\n", "sort_t2i_re", "=", "np", ".", "copy", "(", "sort_t2i", ")", "[", ":", "K1", ",", ":", "]", "\n", "\n", "sort_t2t", "=", "np", ".", "argsort", "(", "-", "sim_T", ",", "1", ")", "# \u6309\u884c\u4ece\u5927\u5230\u5c0f\u6392\u5e8f", "\n", "# print(sort_t2t.shape)", "\n", "sort_t2t_re", "=", "np", ".", "copy", "(", "sort_t2t", ")", "[", ":", ",", ":", "K2", "]", "\n", "address", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "size_t", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "K1", ")", ":", "\n", "            ", "result_i", "=", "sort_t2i", "[", "j", "]", "[", "i", "]", "# Ij", "\n", "query", "=", "sort_i2t", "[", "result_i", ",", ":", "]", "# \u7b2cj\u5f20\u56fe\u7247\u5bf9\u5e94T\u7684\u6392\u5e8f", "\n", "# query = sort_t2i[:K2, result_t]", "\n", "ranks", "=", "1e20", "\n", "G", "=", "sort_t2t_re", "[", "i", "]", "\n", "for", "k", "in", "range", "(", "K2", ")", ":", "\n", "# qewfo = i//5 * 5 + k", "\n", "# print(qewfo)", "\n", "                ", "tmp", "=", "np", ".", "where", "(", "query", "==", "G", "[", "k", "]", ")", "[", "0", "]", "[", "0", "]", "\n", "if", "tmp", "<", "ranks", ":", "\n", "                    ", "ranks", "=", "tmp", "\n", "", "", "address", "=", "np", ".", "append", "(", "address", ",", "ranks", ")", "\n", "\n", "", "sort", "=", "np", ".", "argsort", "(", "address", ")", "\n", "sort_t2i_re", "[", ":", ",", "i", "]", "=", "sort_t2i_re", "[", ":", ",", "i", "]", "[", "sort", "]", "\n", "address", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "", "sort_t2i", "[", ":", "K1", ",", ":", "]", "=", "sort_t2i_re", "\n", "\n", "return", "sort_t2i", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.acc_i2t2": [[110, 139], ["numpy.zeros", "numpy.zeros", "range", "range", "len", "len", "len", "numpy.floor", "np.zeros.mean", "min", "len", "len", "len", "numpy.median", "numpy.where", "numpy.where", "numpy.where", "numpy.where"], "function", ["None"], ["", "def", "acc_i2t2", "(", "input", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k of i2t\"\"\"", "\n", "#input = collect_match(input).numpy()", "\n", "image_size", "=", "input", ".", "shape", "[", "0", "]", "\n", "ranks", "=", "np", ".", "zeros", "(", "image_size", ")", "\n", "top1", "=", "np", ".", "zeros", "(", "image_size", ")", "\n", "\n", "for", "index", "in", "range", "(", "image_size", ")", ":", "\n", "        ", "inds", "=", "input", "[", "index", "]", "\n", "# Score", "\n", "# if index == 197:", "\n", "# print('s')", "\n", "rank", "=", "1e20", "\n", "for", "i", "in", "range", "(", "5", "*", "index", ",", "min", "(", "5", "*", "index", "+", "5", ",", "image_size", "*", "5", ")", ",", "1", ")", ":", "\n", "            ", "tmp", "=", "np", ".", "where", "(", "inds", "==", "i", ")", "[", "0", "]", "[", "0", "]", "\n", "if", "tmp", "<", "rank", ":", "\n", "                ", "rank", "=", "tmp", "\n", "", "", "ranks", "[", "index", "]", "=", "rank", "\n", "top1", "[", "index", "]", "=", "inds", "[", "0", "]", "\n", "\n", "\n", "# Compute metrics", "\n", "", "r1", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "1", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r5", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "5", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r10", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "10", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "medr", "=", "np", ".", "floor", "(", "np", ".", "median", "(", "ranks", ")", ")", "+", "1", "\n", "meanr", "=", "ranks", ".", "mean", "(", ")", "+", "1", "\n", "\n", "return", "(", "r1", ",", "r5", ",", "r10", ",", "medr", ",", "meanr", ")", ",", "(", "ranks", ",", "top1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.acc_t2i2": [[141, 165], ["numpy.zeros", "numpy.zeros", "range", "range", "len", "len", "len", "numpy.floor", "np.zeros.mean", "len", "len", "len", "numpy.median", "numpy.where", "numpy.where", "numpy.where", "numpy.where"], "function", ["None"], ["", "def", "acc_t2i2", "(", "input", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k of t2i\"\"\"", "\n", "#input = collect_match(input).numpy()", "\n", "image_size", "=", "input", ".", "shape", "[", "0", "]", "\n", "ranks", "=", "np", ".", "zeros", "(", "5", "*", "image_size", ")", "\n", "top1", "=", "np", ".", "zeros", "(", "5", "*", "image_size", ")", "\n", "\n", "# --> (5N(caption), N(image))", "\n", "input", "=", "input", ".", "T", "\n", "\n", "for", "index", "in", "range", "(", "image_size", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "inds", "=", "input", "[", "5", "*", "index", "+", "i", "]", "\n", "ranks", "[", "5", "*", "index", "+", "i", "]", "=", "np", ".", "where", "(", "inds", "==", "index", ")", "[", "0", "]", "[", "0", "]", "\n", "top1", "[", "5", "*", "index", "+", "i", "]", "=", "inds", "[", "0", "]", "\n", "\n", "# Compute metrics", "\n", "", "", "r1", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "1", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r5", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "5", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r10", "=", "100.0", "*", "len", "(", "np", ".", "where", "(", "ranks", "<", "10", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "medr", "=", "np", ".", "floor", "(", "np", ".", "median", "(", "ranks", ")", ")", "+", "1", "\n", "meanr", "=", "ranks", ".", "mean", "(", ")", "+", "1", "\n", "\n", "return", "(", "r1", ",", "r5", ",", "r10", ",", "medr", ",", "meanr", ")", ",", "(", "ranks", ",", "top1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.main": [[167, 285], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "numpy.load", "numpy.load", "time.time", "rerank.i2t_rerank", "rerank.acc_i2t2", "rerank.acc_i2t2", "print", "print", "rerank.acc_t2i2", "print", "print", "print", "time.time", "print", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "range", "print", "print", "print", "print", "print", "numpy.load", "numpy.load", "time.time", "rerank.i2t_rerank", "rerank.acc_i2t2", "rerank.acc_i2t2", "print", "print", "rerank.acc_t2i2", "print", "time.time", "print", "numpy.argsort", "numpy.argsort", "numpy.load", "numpy.load", "time.time", "rerank.i2t_rerank", "rerank.acc_i2t2", "rerank.acc_i2t2", "print", "print", "rerank.acc_t2i2", "print", "time.time", "print", "print", "numpy.argsort", "numpy.argsort", "numpy.argsort", "numpy.array", "numpy.array", "numpy.argsort", "numpy.array"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.i2t_rerank", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.acc_i2t2", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.acc_i2t2", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.acc_t2i2", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.i2t_rerank", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.acc_i2t2", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.acc_i2t2", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.acc_t2i2", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.i2t_rerank", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.acc_i2t2", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.acc_i2t2", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.rerank.acc_t2i2"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--data_name'", ",", "default", "=", "'coco'", ",", "help", "=", "'data name'", ")", "\n", "parser", ".", "add_argument", "(", "'--fold'", ",", "action", "=", "'store_true'", ",", "help", "=", "'fold5'", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "data", "=", "opt", ".", "data_name", "\n", "fold", "=", "opt", ".", "fold", "\n", "# The accuracy computing", "\n", "# Input the prediction similarity score matrix (d * 5d)", "\n", "if", "data", "==", "'coco'", ":", "\n", "        ", "if", "fold", "==", "True", ":", "\n", "            ", "path1", "=", "''", "\n", "path", "=", "'coco_sims/'", "\n", "r1", "=", "np", ".", "array", "(", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "r1_t", "=", "np", ".", "array", "(", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "r2", "=", "np", ".", "array", "(", "(", "0", ",", "0", ",", "0", ")", ")", "# rerank", "\n", "r2_t", "=", "np", ".", "array", "(", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "                ", "d1", "=", "np", ".", "load", "(", "path1", "+", "'sims_full_%d.npy'", "%", "i", ")", "\n", "d2", "=", "np", ".", "load", "(", "path", "+", "'sims_full_%d.npy'", "%", "i", ")", "\n", "\n", "# d1T = np.load(path1+'sims_full_T_%d.npy' % i)", "\n", "# d2T = np.load(path+'sims_full_T_%d.npy' % i)", "\n", "\n", "d", "=", "d1", "+", "d2", "\n", "# d_T = d1T+d2T", "\n", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "# calculate the i2t score after rerank", "\n", "sort_rerank", "=", "i2t_rerank", "(", "d", ",", "15", ",", "1", ")", "\n", "(", "r1i", ",", "r5i", ",", "r10i", ",", "medri", ",", "meanri", ")", ",", "_", "=", "acc_i2t2", "(", "np", ".", "argsort", "(", "-", "d", ",", "1", ")", ")", "\n", "(", "r1i2", ",", "r5i2", ",", "r10i2", ",", "medri2", ",", "meanri2", ")", ",", "_", "=", "acc_i2t2", "(", "sort_rerank", ")", "\n", "\n", "print", "(", "r1i", ",", "r5i", ",", "r10i", ",", "medri", ",", "meanri", ")", "\n", "print", "(", "r1i2", ",", "r5i2", ",", "r10i2", ",", "medri2", ",", "meanri2", ")", "\n", "r1", "=", "r1", "+", "np", ".", "array", "(", "(", "r1i", ",", "r5i", ",", "r10i", ")", ")", "\n", "r2", "=", "r2", "+", "np", ".", "array", "(", "(", "r1i2", ",", "r5i2", ",", "r10i2", ")", ")", "\n", "\n", "# calculate the t2i score after rerank", "\n", "# sort_rerank = t2i_rerank(d, 20, 1)", "\n", "# sort_rerank = t2i_rerank_new(d, d_T, 20, 1)", "\n", "(", "r1t", ",", "r5t", ",", "r10t", ",", "medrt", ",", "meanrt", ")", ",", "_", "=", "acc_t2i2", "(", "np", ".", "argsort", "(", "-", "d", ",", "0", ")", ")", "\n", "# (r1t2, r5t2, r10t2, medrt2, meanrt2), _ = acc_t2i2(sort_rerank)", "\n", "\n", "print", "(", "r1t", ",", "r5t", ",", "r10t", ",", "medrt", ",", "meanrt", ")", "\n", "# print(r1t2, r5t2, r10t2, medrt2, meanrt2)", "\n", "# print((r1t, r5t, r10t))", "\n", "r1_t", "=", "r1_t", "+", "np", ".", "array", "(", "(", "r1t", ",", "r5t", ",", "r10t", ")", ")", "\n", "# r2_t = r2_t + np.array((r1t2, r5t2, r10t2))", "\n", "t2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "t2", "-", "t1", ")", "\n", "print", "(", "'--------------------'", ")", "\n", "", "print", "(", "'5-cross test'", ")", "\n", "print", "(", "r1", "/", "5", ")", "\n", "print", "(", "r1_t", "/", "5", ")", "\n", "print", "(", "'rerank!'", ")", "\n", "print", "(", "r2", "/", "5", ")", "\n", "# print(r2_t/5)", "\n", "", "else", ":", "\n", "            ", "path", "=", "'coco_sims/'", "\n", "path1", "=", "''", "\n", "d1", "=", "np", ".", "load", "(", "path", "+", "'sims_full_5k.npy'", ")", "\n", "d2", "=", "np", ".", "load", "(", "path1", "+", "'sims_full_5k.npy'", ")", "\n", "d", "=", "d1", "+", "d2", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "# calculate the i2t score after rerank", "\n", "sort_rerank", "=", "i2t_rerank", "(", "d", ",", "15", ",", "1", ")", "\n", "(", "r1i", ",", "r5i", ",", "r10i", ",", "medri", ",", "meanri", ")", ",", "_", "=", "acc_i2t2", "(", "np", ".", "argsort", "(", "-", "d", ",", "1", ")", ")", "\n", "(", "r1i2", ",", "r5i2", ",", "r10i2", ",", "medri2", ",", "meanri2", ")", ",", "_", "=", "acc_i2t2", "(", "sort_rerank", ")", "\n", "\n", "print", "(", "r1i", ",", "r5i", ",", "r10i", ",", "medri", ",", "meanri", ")", "\n", "print", "(", "r1i2", ",", "r5i2", ",", "r10i2", ",", "medri2", ",", "meanri2", ")", "\n", "\n", "# calculate the t2i score after rerank", "\n", "# sort_rerank = t2i_rerank(d, 20, 1)", "\n", "# sort_rerank = t2i_rerank_new(d, d_T, 12, 1)", "\n", "(", "r1t", ",", "r5t", ",", "r10t", ",", "medrt", ",", "meanrt", ")", ",", "_", "=", "acc_t2i2", "(", "np", ".", "argsort", "(", "-", "d", ",", "0", ")", ")", "\n", "# (r1t2, r5t2, r10t2, medrt2, meanrt2), _ = acc_t2i2(sort_rerank)", "\n", "\n", "print", "(", "r1t", ",", "r5t", ",", "r10t", ",", "medrt", ",", "meanrt", ")", "\n", "# print(r1t2, r5t2, r10t2, medrt2, meanrt2)", "\n", "t2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "t2", "-", "t1", ")", "\n", "\n", "", "", "else", ":", "\n", "\n", "        ", "d1", "=", "np", ".", "load", "(", "'flickr_sims/sims_f.npy'", ")", "\n", "d2", "=", "np", ".", "load", "(", "'sims_f.npy'", ")", "\n", "d", "=", "d1", "+", "d2", "\n", "# d1T = np.load('flickr_sims/sims_f_T.npy')", "\n", "# d2T = np.load('sims_f_T.npy')", "\n", "\n", "# d_T = d1T+d2T", "\n", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "# calculate the i2t score after rerank", "\n", "sort_rerank", "=", "i2t_rerank", "(", "d", ",", "15", ",", "1", ")", "\n", "(", "r1i", ",", "r5i", ",", "r10i", ",", "medri", ",", "meanri", ")", ",", "_", "=", "acc_i2t2", "(", "np", ".", "argsort", "(", "-", "d", ",", "1", ")", ")", "\n", "(", "r1i2", ",", "r5i2", ",", "r10i2", ",", "medri2", ",", "meanri2", ")", ",", "_", "=", "acc_i2t2", "(", "sort_rerank", ")", "\n", "\n", "print", "(", "r1i", ",", "r5i", ",", "r10i", ",", "medri", ",", "meanri", ")", "\n", "print", "(", "r1i2", ",", "r5i2", ",", "r10i2", ",", "medri2", ",", "meanri2", ")", "\n", "\n", "\n", "# calculate the t2i score after rerank", "\n", "\n", "# sort_rerank = t2i_rerank_new(d, d_T, 20, 4)", "\n", "(", "r1t", ",", "r5t", ",", "r10t", ",", "medrt", ",", "meanrt", ")", ",", "_", "=", "acc_t2i2", "(", "np", ".", "argsort", "(", "-", "d", ",", "0", ")", ")", "\n", "# (r1t2, r5t2, r10t2, medrt2, meanrt2), _ = acc_t2i2(sort_rerank)", "\n", "\n", "print", "(", "r1t", ",", "r5t", ",", "r10t", ",", "medrt", ",", "meanrt", ")", "\n", "# print(r1t2, r5t2, r10t2, medrt2, meanrt2)", "\n", "rsum", "=", "r1i", "+", "r5i", "+", "r10i", "+", "r1t", "+", "r5t", "+", "r10t", "\n", "print", "(", "'rsum:%f'", "%", "rsum", ")", "\n", "rsum_rr", "=", "r1i2", "+", "r5i2", "+", "r10i2", "+", "r1t", "+", "r5t", "+", "r10t", "\n", "print", "(", "'rsum_rr:%f'", "%", "rsum_rr", ")", "\n", "t2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "t2", "-", "t1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.CocoDataset.__init__": [[69, 90], ["isinstance", "isinstance", "list", "len", "len", "pycocotools.coco.COCO", "pycocotools.coco.COCO", "pycocotools.coco.COCO", "data_bert.CocoDataset.coco.anns.keys", "list", "list"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "json", ",", "tokenizer", ",", "feature_path", "=", "None", ",", "region_bbox_file", "=", "None", ",", "max_seq_len", "=", "32", ",", "transform", "=", "None", ",", "ids", "=", "None", ")", ":", "\n", "        ", "self", ".", "root", "=", "root", "\n", "if", "isinstance", "(", "json", ",", "tuple", ")", ":", "\n", "            ", "self", ".", "coco", "=", "(", "COCO", "(", "json", "[", "0", "]", ")", ",", "COCO", "(", "json", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "coco", "=", "(", "COCO", "(", "json", ")", ",", ")", "\n", "self", ".", "root", "=", "(", "root", ",", ")", "\n", "", "if", "ids", "is", "None", ":", "\n", "            ", "self", ".", "ids", "=", "list", "(", "self", ".", "coco", ".", "anns", ".", "keys", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ids", "=", "ids", "\n", "", "if", "isinstance", "(", "self", ".", "ids", ",", "tuple", ")", ":", "\n", "            ", "self", ".", "bp", "=", "len", "(", "self", ".", "ids", "[", "0", "]", ")", "\n", "self", ".", "ids", "=", "list", "(", "self", ".", "ids", "[", "0", "]", ")", "+", "list", "(", "self", ".", "ids", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bp", "=", "len", "(", "self", ".", "ids", ")", "\n", "", "self", ".", "transform", "=", "transform", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "self", ".", "region_bbox_file", "=", "region_bbox_file", "\n", "self", ".", "region_det_file_prefix", "=", "feature_path", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.CocoDataset.__getitem__": [[91, 99], ["data_bert.CocoDataset.get_raw_item", "data_bert.CocoDataset.get_text_input", "data_bert.CocoDataset.transform"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.CocoDataset.get_raw_item", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.FlickrDataset.get_text_input"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "root", ",", "caption", ",", "img_id", ",", "path", ",", "image", ",", "img_rcnn", ",", "img_pe", "=", "self", ".", "get_raw_item", "(", "index", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "image", "=", "self", ".", "transform", "(", "image", ")", "\n", "\n", "", "target", "=", "self", ".", "get_text_input", "(", "caption", ")", "\n", "return", "img_rcnn", ",", "img_pe", ",", "target", ",", "index", ",", "img_id", ",", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.CocoDataset.get_raw_item": [[100, 114], ["PIL.Image.open().convert", "data_bert.CocoDataset.get_rcnn", "coco.loadImgs", "PIL.Image.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.FlickrDataset.get_rcnn"], ["", "def", "get_raw_item", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "index", "<", "self", ".", "bp", ":", "\n", "            ", "coco", "=", "self", ".", "coco", "[", "0", "]", "\n", "root", "=", "self", ".", "root", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "coco", "=", "self", ".", "coco", "[", "1", "]", "\n", "root", "=", "self", ".", "root", "[", "1", "]", "\n", "", "ann_id", "=", "self", ".", "ids", "[", "index", "]", "\n", "caption", "=", "coco", ".", "anns", "[", "ann_id", "]", "[", "'caption'", "]", "\n", "img_id", "=", "coco", ".", "anns", "[", "ann_id", "]", "[", "'image_id'", "]", "\n", "path", "=", "coco", ".", "loadImgs", "(", "img_id", ")", "[", "0", "]", "[", "'file_name'", "]", "\n", "image", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "path", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "img_rcnn", ",", "img_pe", "=", "self", ".", "get_rcnn", "(", "path", ")", "\n", "return", "root", ",", "caption", ",", "img_id", ",", "path", ",", "image", ",", "img_rcnn", ",", "img_pe", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.CocoDataset.__len__": [[115, 117], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.CocoDataset.get_text_input": [[118, 128], ["data_bert.CocoDataset.tokenizer.tokenize", "data_bert.CocoDataset.tokenizer.convert_tokens_to_ids", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids"], ["", "def", "get_text_input", "(", "self", ",", "caption", ")", ":", "\n", "        ", "caption_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption", ")", "\n", "caption_tokens", "=", "[", "'[CLS]'", "]", "+", "caption_tokens", "+", "[", "'[SEP]'", "]", "\n", "caption_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "caption_tokens", ")", "\n", "if", "len", "(", "caption_ids", ")", ">=", "self", ".", "max_seq_len", ":", "\n", "            ", "caption_ids", "=", "caption_ids", "[", ":", "self", ".", "max_seq_len", "]", "\n", "", "else", ":", "\n", "            ", "caption_ids", "=", "caption_ids", "+", "[", "0", "]", "*", "(", "self", ".", "max_seq_len", "-", "len", "(", "caption_ids", ")", ")", "\n", "", "caption", "=", "torch", ".", "tensor", "(", "caption_ids", ")", "\n", "return", "caption", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.CocoDataset.get_rcnn": [[129, 154], ["rel_area.clamp_", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.normalize", "torch.normalize", "torch.normalize", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "[].split", "h5py.File", "h5py.File", "h5py.File", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "rel_area.view", "torch.layer_norm", "torch.layer_norm", "torch.layer_norm", "torch.layer_norm", "torch.layer_norm", "torch.layer_norm", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "path.split"], "methods", ["None"], ["", "def", "get_rcnn", "(", "self", ",", "path", ")", ":", "\n", "        ", "img_id", "=", "path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "with", "h5py", ".", "File", "(", "self", ".", "region_det_file_prefix", "+", "'_feat'", "+", "img_id", "[", "-", "3", ":", "]", "+", "'.h5'", ",", "'r'", ")", "as", "region_feat_f", ",", "h5py", ".", "File", "(", "self", ".", "region_det_file_prefix", "+", "'_cls'", "+", "img_id", "[", "-", "3", ":", "]", "+", "'.h5'", ",", "'r'", ")", "as", "region_cls_f", ",", "h5py", ".", "File", "(", "self", ".", "region_bbox_file", ",", "'r'", ")", "as", "region_bbox_f", ":", "\n", "\n", "            ", "img", "=", "torch", ".", "from_numpy", "(", "region_feat_f", "[", "img_id", "]", "[", ":", "]", ")", ".", "float", "(", ")", "\n", "cls_label", "=", "torch", ".", "from_numpy", "(", "region_cls_f", "[", "img_id", "]", "[", ":", "]", ")", ".", "float", "(", ")", "\n", "vis_pe", "=", "torch", ".", "from_numpy", "(", "region_bbox_f", "[", "img_id", "]", "[", ":", "]", ")", "\n", "\n", "# lazy normalization of the coordinates...", "\n", "\n", "", "w_est", "=", "torch", ".", "max", "(", "vis_pe", "[", ":", ",", "[", "0", ",", "2", "]", "]", ")", "*", "1.", "+", "1e-5", "\n", "h_est", "=", "torch", ".", "max", "(", "vis_pe", "[", ":", ",", "[", "1", ",", "3", "]", "]", ")", "*", "1.", "+", "1e-5", "\n", "vis_pe", "[", ":", ",", "[", "0", ",", "2", "]", "]", "/=", "w_est", "\n", "vis_pe", "[", ":", ",", "[", "1", ",", "3", "]", "]", "/=", "h_est", "\n", "rel_area", "=", "(", "vis_pe", "[", ":", ",", "3", "]", "-", "vis_pe", "[", ":", ",", "1", "]", ")", "*", "(", "vis_pe", "[", ":", ",", "2", "]", "-", "vis_pe", "[", ":", ",", "0", "]", ")", "\n", "rel_area", ".", "clamp_", "(", "0", ")", "\n", "\n", "vis_pe", "=", "torch", ".", "cat", "(", "(", "vis_pe", "[", ":", ",", ":", "4", "]", ",", "rel_area", ".", "view", "(", "-", "1", ",", "1", ")", ",", "vis_pe", "[", ":", ",", "5", ":", "]", ")", ",", "-", "1", ")", "# confident score", "\n", "normalized_coord", "=", "F", ".", "normalize", "(", "vis_pe", ".", "data", "[", ":", ",", ":", "5", "]", "-", "0.5", ",", "dim", "=", "-", "1", ")", "\n", "vis_pe", "=", "torch", ".", "cat", "(", "(", "F", ".", "layer_norm", "(", "vis_pe", ",", "[", "6", "]", ")", ",", "F", ".", "layer_norm", "(", "cls_label", ",", "[", "1601", "]", ")", ")", ",", "dim", "=", "-", "1", ")", "# 1601 hard coded...", "\n", "\n", "return", "img", ",", "vis_pe", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.FlickrDataset.__init__": [[158, 172], ["enumerate", "json.load", "open", "range", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "json", ",", "split", ",", "tokenizer", ",", "feature_path", "=", "None", ",", "region_bbox_file", "=", "None", ",", "max_seq_len", "=", "32", ",", "\n", "transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "root", "=", "root", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "dataset", "=", "jsonmod", ".", "load", "(", "open", "(", "json", ",", "'r'", ")", ")", "[", "'images'", "]", "\n", "self", ".", "ids", "=", "[", "]", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_seq_len", "=", "max_seq_len", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "self", ".", "dataset", ")", ":", "\n", "            ", "if", "d", "[", "'split'", "]", "==", "split", ":", "\n", "                ", "self", ".", "ids", "+=", "[", "(", "i", ",", "x", ")", "for", "x", "in", "range", "(", "len", "(", "d", "[", "'sentences'", "]", ")", ")", "]", "\n", "", "", "self", ".", "region_bbox_file", "=", "region_bbox_file", "\n", "self", ".", "feature_path", "=", "feature_path", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.FlickrDataset.__getitem__": [[173, 190], ["copy.deepcopy", "path.replace.replace.replace", "PIL.Image.open().convert", "data_bert.FlickrDataset.get_text_input", "data_bert.FlickrDataset.get_rcnn", "data_bert.FlickrDataset.transform", "os.path.join", "PIL.Image.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.FlickrDataset.get_text_input", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.FlickrDataset.get_rcnn"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "root", "=", "self", ".", "root", "\n", "ann_id", "=", "self", ".", "ids", "[", "index", "]", "\n", "img_id", "=", "ann_id", "[", "0", "]", "\n", "caption", "=", "self", ".", "dataset", "[", "img_id", "]", "[", "'sentences'", "]", "[", "ann_id", "[", "1", "]", "]", "[", "'raw'", "]", "\n", "path", "=", "self", ".", "dataset", "[", "img_id", "]", "[", "'filename'", "]", "\n", "path_orig", "=", "copy", ".", "deepcopy", "(", "path", ")", "\n", "path", "=", "path", ".", "replace", "(", "'.jpg'", ",", "'.npy'", ")", "\n", "feature_path", "=", "self", ".", "feature_path", "\n", "# orig image", "\n", "image_orig", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "path_orig", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "image_orig", "=", "self", ".", "transform", "(", "image_orig", ")", "\n", "", "target", "=", "self", ".", "get_text_input", "(", "caption", ")", "\n", "image", ",", "img_pos", "=", "self", ".", "get_rcnn", "(", "os", ".", "path", ".", "join", "(", "feature_path", ",", "path", ")", ")", "# return img-feature 100 2048 & pos-feature", "\n", "\n", "return", "image", ",", "img_pos", ",", "target", ",", "index", ",", "img_id", ",", "image_orig", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.FlickrDataset.get_rcnn": [[191, 216], ["os.path.exists", "os.path.exists", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "rel_area.clamp_", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.normalize", "torch.normalize", "torch.normalize", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "img_path.replace", "numpy.load", "[].split", "numpy.load", "h5py.File", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "img_path.replace", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "rel_area.view", "torch.layer_norm", "torch.layer_norm", "torch.layer_norm", "torch.layer_norm", "torch.layer_norm", "torch.layer_norm", "img_path.split"], "methods", ["None"], ["", "def", "get_rcnn", "(", "self", ",", "img_path", ")", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "img_path", ")", "and", "os", ".", "path", ".", "exists", "(", "img_path", ".", "replace", "(", "'.npy'", ",", "'_cls_prob.npy'", ")", ")", ":", "\n", "            ", "img", "=", "torch", ".", "from_numpy", "(", "np", ".", "load", "(", "img_path", ")", ")", "\n", "img_id", "=", "img_path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "cls_label", "=", "torch", ".", "from_numpy", "(", "np", ".", "load", "(", "img_path", ".", "replace", "(", "'.npy'", ",", "'_cls_prob.npy'", ")", ")", ")", "\n", "with", "h5py", ".", "File", "(", "self", ".", "region_bbox_file", ",", "'r'", ")", "as", "region_bbox_f", ":", "\n", "                ", "vis_pe", "=", "torch", ".", "from_numpy", "(", "region_bbox_f", "[", "img_id", "]", "[", ":", "]", ")", "\n", "\n", "# lazy normalization of the coordinates...", "\n", "\n", "", "w_est", "=", "torch", ".", "max", "(", "vis_pe", "[", ":", ",", "[", "0", ",", "2", "]", "]", ")", "*", "1.", "+", "1e-5", "\n", "h_est", "=", "torch", ".", "max", "(", "vis_pe", "[", ":", ",", "[", "1", ",", "3", "]", "]", ")", "*", "1.", "+", "1e-5", "\n", "vis_pe", "[", ":", ",", "[", "0", ",", "2", "]", "]", "/=", "w_est", "\n", "vis_pe", "[", ":", ",", "[", "1", ",", "3", "]", "]", "/=", "h_est", "\n", "rel_area", "=", "(", "vis_pe", "[", ":", ",", "3", "]", "-", "vis_pe", "[", ":", ",", "1", "]", ")", "*", "(", "vis_pe", "[", ":", ",", "2", "]", "-", "vis_pe", "[", ":", ",", "0", "]", ")", "\n", "rel_area", ".", "clamp_", "(", "0", ")", "\n", "\n", "vis_pe", "=", "torch", ".", "cat", "(", "(", "vis_pe", "[", ":", ",", ":", "4", "]", ",", "rel_area", ".", "view", "(", "-", "1", ",", "1", ")", ",", "vis_pe", "[", ":", ",", "5", ":", "]", ")", ",", "-", "1", ")", "# confident score", "\n", "normalized_coord", "=", "F", ".", "normalize", "(", "vis_pe", ".", "data", "[", ":", ",", ":", "5", "]", "-", "0.5", ",", "dim", "=", "-", "1", ")", "\n", "vis_pe", "=", "torch", ".", "cat", "(", "(", "F", ".", "layer_norm", "(", "vis_pe", ",", "[", "6", "]", ")", ",", "F", ".", "layer_norm", "(", "cls_label", ",", "[", "1601", "]", ")", ")", ",", "dim", "=", "-", "1", ")", "# 1601 hard coded...", "\n", "", "else", ":", "\n", "            ", "img", "=", "torch", ".", "randn", "(", "100", ",", "2048", ")", "\n", "vis_pe", "=", "torch", ".", "randn", "(", "100", ",", "1601", "+", "6", ")", "\n", "", "return", "img", ",", "vis_pe", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.FlickrDataset.get_text_input": [[217, 227], ["data_bert.FlickrDataset.tokenizer.tokenize", "data_bert.FlickrDataset.tokenizer.convert_tokens_to_ids", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids"], ["", "def", "get_text_input", "(", "self", ",", "caption", ")", ":", "\n", "        ", "caption_tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "caption", ")", "\n", "caption_tokens", "=", "[", "'[CLS]'", "]", "+", "caption_tokens", "+", "[", "'[SEP]'", "]", "\n", "caption_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "caption_tokens", ")", "\n", "if", "len", "(", "caption_ids", ")", ">=", "self", ".", "max_seq_len", ":", "\n", "            ", "caption_ids", "=", "caption_ids", "[", ":", "self", ".", "max_seq_len", "]", "\n", "", "else", ":", "\n", "            ", "caption_ids", "=", "caption_ids", "+", "[", "0", "]", "*", "(", "self", ".", "max_seq_len", "-", "len", "(", "caption_ids", ")", ")", "\n", "", "caption", "=", "torch", ".", "tensor", "(", "caption_ids", ")", "\n", "return", "caption", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.FlickrDataset.__len__": [[228, 230], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.AverageMeter.__init__": [[350, 352], ["data_bert.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.AverageMeter.reset"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.AverageMeter.reset": [[353, 358], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.AverageMeter.update": [[359, 364], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "0", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "(", ".0001", "+", "self", ".", "count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.AverageMeter.__str__": [[365, 369], ["str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "count", "==", "0", ":", "\n", "            ", "return", "str", "(", "self", ".", "val", ")", "\n", "", "return", "'%.4f (%.4f)'", "%", "(", "self", ".", "val", ",", "self", ".", "avg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.LogCollector.__init__": [[372, 374], ["collections.OrderedDict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "meters", "=", "OrderedDict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.LogCollector.update": [[375, 379], ["data_bert.LogCollector.meters[].update", "data_bert.AverageMeter"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update"], ["", "def", "update", "(", "self", ",", "k", ",", "v", ",", "n", "=", "0", ")", ":", "\n", "        ", "if", "k", "not", "in", "self", ".", "meters", ":", "\n", "            ", "self", ".", "meters", "[", "k", "]", "=", "AverageMeter", "(", ")", "\n", "", "self", ".", "meters", "[", "k", "]", ".", "update", "(", "v", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.LogCollector.__str__": [[380, 387], ["enumerate", "data_bert.LogCollector.meters.items", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "s", "=", "''", "\n", "for", "i", ",", "(", "k", ",", "v", ")", "in", "enumerate", "(", "self", ".", "meters", ".", "items", "(", ")", ")", ":", "\n", "            ", "if", "i", ">", "0", ":", "\n", "                ", "s", "+=", "'  '", "\n", "", "s", "+=", "k", "+", "' '", "+", "str", "(", "v", ")", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.LogCollector.tb_log": [[388, 391], ["data_bert.LogCollector.meters.items", "tb_logger.log_value"], "methods", ["None"], ["", "def", "tb_log", "(", "self", ",", "tb_logger", ",", "prefix", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "self", ".", "meters", ".", "items", "(", ")", ":", "\n", "            ", "tb_logger", ".", "log_value", "(", "prefix", "+", "k", ",", "v", ".", "val", ",", "step", "=", "step", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.get_paths": [[25, 65], ["os.path.join", "os.path.join", "numpy.load", "numpy.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "numpy.load", "os.path.join", "numpy.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["def", "get_paths", "(", "path", ",", "name", "=", "'coco'", ")", ":", "\n", "    ", "roots", "=", "{", "}", "\n", "ids", "=", "{", "}", "\n", "if", "'coco'", "==", "name", ":", "\n", "        ", "imgdir", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'images'", ")", "\n", "capdir", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'annotations'", ")", "\n", "roots", "[", "'train'", "]", "=", "{", "\n", "'img'", ":", "os", ".", "path", ".", "join", "(", "imgdir", ",", "'train2014'", ")", ",", "\n", "'cap'", ":", "os", ".", "path", ".", "join", "(", "capdir", ",", "'captions_train2014.json'", ")", "\n", "}", "\n", "roots", "[", "'val'", "]", "=", "{", "\n", "'img'", ":", "os", ".", "path", ".", "join", "(", "imgdir", ",", "'val2014'", ")", ",", "\n", "'cap'", ":", "os", ".", "path", ".", "join", "(", "capdir", ",", "'captions_val2014.json'", ")", "\n", "}", "\n", "roots", "[", "'test'", "]", "=", "{", "\n", "'img'", ":", "os", ".", "path", ".", "join", "(", "imgdir", ",", "'val2014'", ")", ",", "\n", "'cap'", ":", "os", ".", "path", ".", "join", "(", "capdir", ",", "'captions_val2014.json'", ")", "\n", "}", "\n", "roots", "[", "'trainrestval'", "]", "=", "{", "\n", "'img'", ":", "(", "roots", "[", "'train'", "]", "[", "'img'", "]", ",", "roots", "[", "'val'", "]", "[", "'img'", "]", ")", ",", "\n", "'cap'", ":", "(", "roots", "[", "'train'", "]", "[", "'cap'", "]", ",", "roots", "[", "'val'", "]", "[", "'cap'", "]", ")", "\n", "}", "\n", "ids", "[", "'train'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "capdir", ",", "'coco_train_ids.npy'", ")", ")", "\n", "ids", "[", "'val'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "capdir", ",", "'coco_dev_ids.npy'", ")", ")", "[", ":", "5000", "]", "\n", "ids", "[", "'test'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "capdir", ",", "'coco_test_ids.npy'", ")", ")", "\n", "ids", "[", "'trainrestval'", "]", "=", "(", "\n", "ids", "[", "'train'", "]", ",", "\n", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "capdir", ",", "'coco_restval_ids.npy'", ")", ")", ")", "\n", "\n", "roots", "[", "'train'", "]", "=", "roots", "[", "'trainrestval'", "]", "\n", "ids", "[", "'train'", "]", "=", "ids", "[", "'trainrestval'", "]", "\n", "", "elif", "'f30k'", "==", "name", ":", "\n", "        ", "imgdir", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'images'", ")", "\n", "cap", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'dataset_flickr30k.json'", ")", "\n", "roots", "[", "'train'", "]", "=", "{", "'img'", ":", "imgdir", ",", "'cap'", ":", "cap", "}", "\n", "roots", "[", "'val'", "]", "=", "{", "'img'", ":", "imgdir", ",", "'cap'", ":", "cap", "}", "\n", "roots", "[", "'test'", "]", "=", "{", "'img'", ":", "imgdir", ",", "'cap'", ":", "cap", "}", "\n", "ids", "=", "{", "'train'", ":", "None", ",", "'val'", ":", "None", ",", "'test'", ":", "None", "}", "\n", "\n", "", "return", "roots", ",", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.collate_fn": [[232, 239], ["zip", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "function", ["None"], ["", "", "def", "collate_fn", "(", "data", ")", ":", "\n", "    ", "images", ",", "img_pos", ",", "captions", ",", "ids", ",", "img_ids", ",", "image_orig", "=", "zip", "(", "*", "data", ")", "\n", "images", "=", "torch", ".", "stack", "(", "images", ",", "0", ")", "\n", "img_pos", "=", "torch", ".", "stack", "(", "img_pos", ",", "0", ")", "\n", "captions", "=", "torch", ".", "stack", "(", "captions", ",", "0", ")", "\n", "images_orig", "=", "torch", ".", "stack", "(", "image_orig", ",", "0", ")", "\n", "return", "images", ",", "images_orig", ",", "img_pos", ",", "captions", ",", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.get_tokenizer": [[241, 244], ["pytorch_pretrained_bert.tokenization.BertTokenizer"], "function", ["None"], ["", "def", "get_tokenizer", "(", "bert_path", ")", ":", "\n", "    ", "tokenizer", "=", "BertTokenizer", "(", "bert_path", "+", "'vocab.txt'", ")", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.get_loader_single": [[246, 273], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "data_bert.CocoDataset", "data_bert.FlickrDataset", "data_bert.get_tokenizer", "data_bert.get_tokenizer"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.get_tokenizer", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.get_tokenizer"], ["", "def", "get_loader_single", "(", "data_name", ",", "split", ",", "root", ",", "json", ",", "transform", ",", "\n", "batch_size", "=", "128", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "10", ",", "ids", "=", "None", ",", "collate_fn", "=", "collate_fn", ",", "\n", "feature_path", "=", "None", ",", "\n", "region_bbox_file", "=", "None", ",", "\n", "bert_path", "=", "None", "\n", ")", ":", "\n", "    ", "if", "'coco'", "in", "data_name", ":", "\n", "        ", "dataset", "=", "CocoDataset", "(", "root", "=", "root", ",", "json", "=", "json", ",", "\n", "feature_path", "=", "feature_path", ",", "\n", "region_bbox_file", "=", "region_bbox_file", ",", "\n", "tokenizer", "=", "get_tokenizer", "(", "bert_path", ")", ",", "\n", "max_seq_len", "=", "32", ",", "transform", "=", "transform", ",", "ids", "=", "ids", ")", "\n", "", "elif", "'f30k'", "in", "data_name", ":", "\n", "        ", "dataset", "=", "FlickrDataset", "(", "root", "=", "root", ",", "split", "=", "split", ",", "json", "=", "json", ",", "\n", "feature_path", "=", "feature_path", ",", "\n", "region_bbox_file", "=", "region_bbox_file", ",", "\n", "tokenizer", "=", "get_tokenizer", "(", "bert_path", ")", ",", "\n", "max_seq_len", "=", "32", ",", "transform", "=", "transform", ")", "\n", "\n", "", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "pin_memory", "=", "True", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "collate_fn", "=", "collate_fn", ")", "\n", "return", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.get_transform": [[275, 291], ["torchvision.Normalize", "torchvision.Compose", "torchvision.ToTensor", "torchvision.RandomResizedCrop", "torchvision.RandomHorizontalFlip", "torchvision.Resize", "torchvision.CenterCrop", "torchvision.Resize", "torchvision.CenterCrop"], "function", ["None"], ["", "def", "get_transform", "(", "data_name", ",", "split_name", ",", "opt", ")", ":", "\n", "    ", "normalizer", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "t_list", "=", "[", "]", "\n", "if", "split_name", "==", "'train'", ":", "\n", "        ", "t_list", "=", "[", "transforms", ".", "RandomResizedCrop", "(", "opt", ".", "crop_size", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", "]", "\n", "# t_list = [transforms.Resize(256), transforms.CenterCrop(224)]", "\n", "", "elif", "split_name", "==", "'val'", ":", "\n", "        ", "t_list", "=", "[", "transforms", ".", "Resize", "(", "256", ")", ",", "transforms", ".", "CenterCrop", "(", "224", ")", "]", "\n", "", "elif", "split_name", "==", "'test'", ":", "\n", "        ", "t_list", "=", "[", "transforms", ".", "Resize", "(", "256", ")", ",", "transforms", ".", "CenterCrop", "(", "224", ")", "]", "\n", "\n", "", "t_end", "=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalizer", "]", "\n", "transform", "=", "transforms", ".", "Compose", "(", "t_list", "+", "t_end", ")", "\n", "return", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.get_loaders": [[293, 325], ["os.path.join", "data_bert.get_paths", "data_bert.get_transform", "data_bert.get_loader_single", "data_bert.get_transform", "data_bert.get_loader_single"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_paths", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_transform", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_loader_single", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_transform", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_loader_single"], ["", "def", "get_loaders", "(", "data_name", ",", "batch_size", ",", "workers", ",", "opt", ")", ":", "\n", "    ", "dpath", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "data_path", ",", "data_name", ")", "\n", "roots", ",", "ids", "=", "get_paths", "(", "dpath", ",", "data_name", ")", "\n", "\n", "transform", "=", "get_transform", "(", "data_name", ",", "'train'", ",", "opt", ")", "\n", "train_loader", "=", "get_loader_single", "(", "opt", ".", "data_name", ",", "'train'", ",", "\n", "roots", "[", "'train'", "]", "[", "'img'", "]", ",", "\n", "roots", "[", "'train'", "]", "[", "'cap'", "]", ",", "\n", "transform", ",", "ids", "=", "ids", "[", "'train'", "]", ",", "\n", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "workers", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "feature_path", "=", "opt", ".", "feature_path", ",", "\n", "region_bbox_file", "=", "opt", ".", "region_bbox_file", ",", "\n", "bert_path", "=", "opt", ".", "bert_path", "\n", ")", "\n", "\n", "transform", "=", "get_transform", "(", "data_name", ",", "'val'", ",", "opt", ")", "\n", "\n", "val_loader", "=", "get_loader_single", "(", "opt", ".", "data_name", ",", "'val'", ",", "\n", "roots", "[", "'val'", "]", "[", "'img'", "]", ",", "\n", "roots", "[", "'val'", "]", "[", "'cap'", "]", ",", "\n", "transform", ",", "ids", "=", "ids", "[", "'val'", "]", ",", "\n", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "workers", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "feature_path", "=", "opt", ".", "feature_path", ",", "\n", "region_bbox_file", "=", "opt", ".", "region_bbox_file", ",", "\n", "bert_path", "=", "opt", ".", "bert_path", "\n", ")", "\n", "\n", "return", "train_loader", ",", "val_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data_bert.get_test_loader": [[327, 346], ["os.path.join", "data_bert.get_paths", "data_bert.get_transform", "data_bert.get_loader_single"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_paths", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_transform", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_loader_single"], ["", "def", "get_test_loader", "(", "split_name", ",", "data_name", ",", "batch_size", ",", "workers", ",", "opt", ")", ":", "\n", "    ", "dpath", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "data_path", ",", "data_name", ")", "\n", "\n", "roots", ",", "ids", "=", "get_paths", "(", "dpath", ",", "data_name", ")", "\n", "\n", "transform", "=", "get_transform", "(", "data_name", ",", "split_name", ",", "opt", ")", "\n", "test_loader", "=", "get_loader_single", "(", "opt", ".", "data_name", ",", "split_name", ",", "\n", "roots", "[", "split_name", "]", "[", "'img'", "]", ",", "\n", "roots", "[", "split_name", "]", "[", "'cap'", "]", ",", "\n", "transform", ",", "ids", "=", "ids", "[", "split_name", "]", ",", "\n", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "workers", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "feature_path", "=", "opt", ".", "feature_path", ",", "\n", "region_bbox_file", "=", "opt", ".", "region_bbox_file", ",", "\n", "bert_path", "=", "opt", ".", "bert_path", "\n", ")", "\n", "\n", "return", "test_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train_bert.main": [[24, 109], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "tensorboard_logger.configure", "data_bert.get_loaders", "len", "print", "model_bert.VSE", "range", "os.path.isfile", "train_bert.adjust_learning_rate", "train_bert.train", "max", "train_bert.save_checkpoint", "print", "torch.load", "model_bert.VSE.load_state_dict", "print", "print", "train_bert.validate", "train_bert.validate", "model_bert.VSE.state_dict"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_loaders", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.adjust_learning_rate", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.train", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.save_checkpoint", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.load_state_dict", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.validate", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.validate", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.state_dict"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--data_path'", ",", "default", "=", "'data'", ",", "\n", "help", "=", "'path to datasets'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_name'", ",", "default", "=", "'coco'", ",", "\n", "help", "=", "'{coco,f30k}'", ")", "\n", "parser", ".", "add_argument", "(", "'--margin'", ",", "default", "=", "0.2", ",", "type", "=", "float", ",", "\n", "help", "=", "'Rank loss margin.'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_epochs'", ",", "default", "=", "12", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of training epochs.'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "'Size of a training mini-batch.'", ")", "\n", "parser", ".", "add_argument", "(", "'--embed_size'", ",", "default", "=", "1024", ",", "type", "=", "int", ",", "\n", "help", "=", "'Dimensionality of the joint embedding.'", ")", "\n", "parser", ".", "add_argument", "(", "'--crop_size'", ",", "default", "=", "224", ",", "type", "=", "int", ",", "\n", "help", "=", "'Size of an image crop as the CNN input.'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "default", "=", "2e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "'Initial learning rate.'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_update'", ",", "default", "=", "6", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of epochs to update the learning rate.'", ")", "\n", "parser", ".", "add_argument", "(", "'--workers'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of data loader workers.'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_step'", ",", "default", "=", "100", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of steps to print and record the log.'", ")", "\n", "parser", ".", "add_argument", "(", "'--logger_name'", ",", "default", "=", "'runs/grg'", ",", "\n", "help", "=", "'Path to save the model and Tensorboard log.'", ")", "\n", "parser", ".", "add_argument", "(", "'--resume'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'path to latest checkpoint (default: none)'", ")", "\n", "parser", ".", "add_argument", "(", "'--img_dim'", ",", "default", "=", "2048", ",", "type", "=", "int", ",", "\n", "help", "=", "'Dimensionality of the image embedding.'", ")", "\n", "parser", ".", "add_argument", "(", "'--ft_res'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Fine-tune the image encoder.'", ")", "\n", "parser", ".", "add_argument", "(", "'--bert_path'", ",", "default", "=", "'uncased_L-12_H-768_A-12/'", ",", "\n", "help", "=", "'path of pre-trained BERT.'", ")", "\n", "parser", ".", "add_argument", "(", "'--ft_bert'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Fine-tune the text encoder.'", ")", "\n", "parser", ".", "add_argument", "(", "'--bert_size'", ",", "default", "=", "768", ",", "type", "=", "int", ",", "\n", "help", "=", "'Dimensionality of the text embedding'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup'", ",", "default", "=", "-", "1", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--K'", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "'num of JSR.'", ")", "\n", "parser", ".", "add_argument", "(", "'--feature_path'", ",", "default", "=", "'data/joint-pretrain/flickr30k/region_feat_gvd_wo_bgd/trainval/'", ",", "\n", "type", "=", "str", ",", "help", "=", "'path to the pre-computed image features'", ")", "\n", "parser", ".", "add_argument", "(", "'--region_bbox_file'", ",", "\n", "default", "=", "'data/joint-pretrain/flickr30k/region_feat_gvd_wo_bgd/flickr30k_detection_vg_thresh0.2_feat_gvd_checkpoint_trainvaltest.h5'", ",", "\n", "type", "=", "str", ",", "help", "=", "'path to the region_bbox_file(.h5)'", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s %(message)s'", ",", "level", "=", "logging", ".", "INFO", ")", "\n", "tb_logger", ".", "configure", "(", "opt", ".", "logger_name", ",", "flush_secs", "=", "5", ")", "\n", "\n", "train_loader", ",", "val_loader", "=", "data", ".", "get_loaders", "(", "opt", ".", "data_name", ",", "opt", ".", "batch_size", ",", "opt", ".", "workers", ",", "opt", ")", "\n", "opt", ".", "l_train", "=", "len", "(", "train_loader", ")", "\n", "print", "(", "opt", ")", "\n", "model", "=", "VSE", "(", "opt", ")", "\n", "best_rsum", "=", "0", "\n", "if", "opt", ".", "resume", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "opt", ".", "resume", ")", ":", "\n", "            ", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "opt", ".", "resume", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "resume", ")", "\n", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "best_rsum", "=", "checkpoint", "[", "'best_rsum'", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "model", ".", "Eiters", "=", "checkpoint", "[", "'Eiters'", "]", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {}, best_rsum {})\"", "\n", ".", "format", "(", "opt", ".", "resume", ",", "start_epoch", ",", "best_rsum", ")", ")", "\n", "validate", "(", "opt", ",", "val_loader", ",", "model", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"=> no checkpoint found at '{}'\"", ".", "format", "(", "opt", ".", "resume", ")", ")", "\n", "\n", "", "", "for", "epoch", "in", "range", "(", "opt", ".", "num_epochs", ")", ":", "\n", "\n", "        ", "adjust_learning_rate", "(", "opt", ",", "model", ".", "optimizer", ",", "epoch", ")", "\n", "\n", "train", "(", "opt", ",", "train_loader", ",", "model", ",", "epoch", ",", "val_loader", ")", "\n", "\n", "rsum", "=", "validate", "(", "opt", ",", "val_loader", ",", "model", ")", "[", "-", "1", "]", "\n", "\n", "is_best", "=", "rsum", ">", "best_rsum", "\n", "best_rsum", "=", "max", "(", "rsum", ",", "best_rsum", ")", "\n", "save_checkpoint", "(", "{", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "\n", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'best_rsum'", ":", "best_rsum", ",", "\n", "'opt'", ":", "opt", ",", "\n", "'Eiters'", ":", "model", ".", "Eiters", ",", "\n", "}", ",", "is_best", ",", "epoch", ",", "prefix", "=", "opt", ".", "logger_name", "+", "'/'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train_bert.train": [[111, 143], ["evaluation_bert.AverageMeter", "evaluation_bert.AverageMeter", "evaluation_bert.LogCollector", "model.train_start", "time.time", "enumerate", "evaluation_bert.AverageMeter.update", "model.train_emb", "evaluation_bert.AverageMeter.update", "time.time", "tensorboard_logger.log_value", "tensorboard_logger.log_value", "tensorboard_logger.log_value", "tensorboard_logger.log_value", "model.logger.tb_log", "logging.info", "time.time", "time.time", "len", "str"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.train_start", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.train_emb", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.tb_log"], ["", "", "def", "train", "(", "opt", ",", "train_loader", ",", "model", ",", "epoch", ",", "val_loader", ")", ":", "\n", "\n", "    ", "batch_time", "=", "AverageMeter", "(", ")", "\n", "data_time", "=", "AverageMeter", "(", ")", "\n", "train_logger", "=", "LogCollector", "(", ")", "\n", "\n", "model", ".", "train_start", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "train_data", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "\n", "        ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "model", ".", "logger", "=", "train_logger", "\n", "model", ".", "train_emb", "(", "*", "train_data", ")", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "model", ".", "Eiters", "%", "opt", ".", "log_step", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\n", "'Epoch: [{0}][{1}/{2}]\\t'", "\n", "'{e_log}\\t'", "\n", "'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'", "\n", "'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'", "\n", ".", "format", "(", "\n", "epoch", ",", "i", ",", "len", "(", "train_loader", ")", ",", "batch_time", "=", "batch_time", ",", "\n", "data_time", "=", "data_time", ",", "e_log", "=", "str", "(", "model", ".", "logger", ")", ")", ")", "\n", "\n", "", "tb_logger", ".", "log_value", "(", "'epoch'", ",", "epoch", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'step'", ",", "i", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'batch_time'", ",", "batch_time", ".", "val", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'data_time'", ",", "data_time", ".", "val", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "model", ".", "logger", ".", "tb_log", "(", "tb_logger", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train_bert.validate": [[145, 151], ["evaluation_bert.encode_data", "evaluation_bert.simrank"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.encode_data", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.simrank"], ["", "", "def", "validate", "(", "opt", ",", "val_loader", ",", "model", ")", ":", "\n", "    ", "_", ",", "_", ",", "sims", "=", "encode_data", "(", "\n", "model", ",", "val_loader", ",", "opt", ".", "log_step", ",", "logging", ".", "info", ")", "\n", "rs", "=", "simrank", "(", "sims", ")", "\n", "del", "sims", "\n", "return", "rs", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train_bert.save_checkpoint": [[153, 157], ["torch.save", "shutil.copyfile"], "function", ["None"], ["", "def", "save_checkpoint", "(", "state", ",", "is_best", ",", "epoch", ",", "filename", "=", "'checkpoint.pth.tar'", ",", "prefix", "=", "''", ")", ":", "\n", "    ", "torch", ".", "save", "(", "state", ",", "prefix", "+", "filename", ")", "\n", "if", "is_best", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "prefix", "+", "filename", ",", "prefix", "+", "'model_best.pth.tar'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train_bert.adjust_learning_rate": [[159, 163], ["None"], "function", ["None"], ["", "", "def", "adjust_learning_rate", "(", "opt", ",", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "lr", "=", "opt", ".", "learning_rate", "*", "(", "0.1", "**", "(", "epoch", "//", "opt", ".", "lr_update", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.main": [[28, 138], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "print", "logging.basicConfig", "tensorboard_logger.configure", "pickle.load", "len", "data.get_loaders", "model.VSE", "range", "open", "os.path.isfile", "train.adjust_learning_rate", "train.train", "train.validate", "max", "train.save_checkpoint", "os.path.join", "print", "torch.load", "model.VSE.load_state_dict", "print", "train.validate", "print", "model.VSE.state_dict"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_loaders", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.adjust_learning_rate", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.train", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.validate", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.save_checkpoint", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.load_state_dict", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.validate", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.state_dict"], ["def", "main", "(", ")", ":", "\n", "# Hyper Parameters", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--data_path'", ",", "default", "=", "'data'", ",", "\n", "help", "=", "'path to datasets'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_name'", ",", "default", "=", "'f30k'", ",", "\n", "help", "=", "'{coco,f8k,f30k,10crop}_precomp|coco|f8k|f30k'", ")", "\n", "parser", ".", "add_argument", "(", "'--vocab_path'", ",", "default", "=", "'vocab'", ",", "\n", "help", "=", "'Path to saved vocabulary pickle files.'", ")", "\n", "parser", ".", "add_argument", "(", "'--margin'", ",", "default", "=", "0.2", ",", "type", "=", "float", ",", "\n", "help", "=", "'Rank loss margin.'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_epochs'", ",", "default", "=", "30", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of training epochs.'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "'Size of a training mini-batch.'", ")", "\n", "parser", ".", "add_argument", "(", "'--word_dim'", ",", "default", "=", "300", ",", "type", "=", "int", ",", "\n", "help", "=", "'Dimensionality of the word embedding.'", ")", "\n", "parser", ".", "add_argument", "(", "'--embed_size'", ",", "default", "=", "1024", ",", "type", "=", "int", ",", "\n", "help", "=", "'Dimensionality of the joint embedding.'", ")", "\n", "parser", ".", "add_argument", "(", "'--grad_clip'", ",", "default", "=", "2.", ",", "type", "=", "float", ",", "\n", "help", "=", "'Gradient clipping threshold.'", ")", "\n", "parser", ".", "add_argument", "(", "'--crop_size'", ",", "default", "=", "224", ",", "type", "=", "int", ",", "\n", "help", "=", "'Size of an image crop as the CNN input.'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_layers'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of GRU layers.'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "default", "=", "2e-4", ",", "type", "=", "float", ",", "\n", "help", "=", "'Initial learning rate.'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr_update'", ",", "default", "=", "15", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of epochs to update the learning rate.'", ")", "\n", "parser", ".", "add_argument", "(", "'--workers'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of data loader workers.'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_step'", ",", "default", "=", "100", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of steps to print and record the log.'", ")", "\n", "parser", ".", "add_argument", "(", "'--val_step'", ",", "default", "=", "500", ",", "type", "=", "int", ",", "\n", "help", "=", "'Number of steps to run validation.'", ")", "\n", "parser", ".", "add_argument", "(", "'--logger_name'", ",", "default", "=", "'runs/test'", ",", "\n", "help", "=", "'Path to save the model and Tensorboard log.'", ")", "\n", "parser", ".", "add_argument", "(", "'--resume'", ",", "default", "=", "''", ",", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'path to latest checkpoint (default: none)'", ")", "\n", "parser", ".", "add_argument", "(", "'--img_dim'", ",", "default", "=", "2048", ",", "type", "=", "int", ",", "\n", "help", "=", "'Dimensionality of the image embedding.'", ")", "\n", "parser", ".", "add_argument", "(", "'--finetune'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Fine-tune the image encoder.'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_restval'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Use the restval data for training on MSCOCO.'", ")", "\n", "parser", ".", "add_argument", "(", "'--reset_train'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Ensure the training is always done in '", "\n", "'train mode (Not recommended).'", ")", "\n", "parser", ".", "add_argument", "(", "'--K'", ",", "default", "=", "2", ",", "type", "=", "int", ",", "help", "=", "'num of JSR.'", ")", "\n", "parser", ".", "add_argument", "(", "'--feature_path'", ",", "default", "=", "'data/joint-pretrain/flickr30k/region_feat_gvd_wo_bgd/trainval/'", ",", "\n", "type", "=", "str", ",", "help", "=", "'path to the pre-computed image features'", ")", "\n", "parser", ".", "add_argument", "(", "'--region_bbox_file'", ",", "\n", "default", "=", "'data/joint-pretrain/flickr30k/region_feat_gvd_wo_bgd/flickr30k_detection_vg_thresh0.2_feat_gvd_checkpoint_trainvaltest.h5'", ",", "\n", "type", "=", "str", ",", "help", "=", "'path to the region_bbox_file(.h5)'", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "print", "(", "opt", ")", "\n", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s %(message)s'", ",", "level", "=", "logging", ".", "INFO", ")", "\n", "tb_logger", ".", "configure", "(", "opt", ".", "logger_name", ",", "flush_secs", "=", "5", ")", "\n", "\n", "# Load Vocabulary Wrapper", "\n", "vocab", "=", "pickle", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "\n", "opt", ".", "vocab_path", ",", "'%s_vocab.pkl'", "%", "opt", ".", "data_name", ")", ",", "'rb'", ")", ")", "\n", "opt", ".", "vocab_size", "=", "len", "(", "vocab", ")", "\n", "\n", "# Load data loaders", "\n", "train_loader", ",", "val_loader", "=", "data", ".", "get_loaders", "(", "\n", "opt", ".", "data_name", ",", "vocab", ",", "opt", ".", "crop_size", ",", "opt", ".", "batch_size", ",", "opt", ".", "workers", ",", "opt", ")", "\n", "\n", "# Construct the model", "\n", "model", "=", "VSE", "(", "opt", ")", "\n", "best_rsum", "=", "0", "\n", "# optionally resume from a checkpoint", "\n", "if", "opt", ".", "resume", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "opt", ".", "resume", ")", ":", "\n", "            ", "print", "(", "\"=> loading checkpoint '{}'\"", ".", "format", "(", "opt", ".", "resume", ")", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "resume", ")", "\n", "start_epoch", "=", "checkpoint", "[", "'epoch'", "]", "\n", "best_rsum", "=", "checkpoint", "[", "'best_rsum'", "]", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "# Eiters is used to show logs as the continuation of another", "\n", "# training", "\n", "model", ".", "Eiters", "=", "checkpoint", "[", "'Eiters'", "]", "\n", "print", "(", "\"=> loaded checkpoint '{}' (epoch {}, best_rsum {})\"", "\n", ".", "format", "(", "opt", ".", "resume", ",", "start_epoch", ",", "best_rsum", ")", ")", "\n", "validate", "(", "opt", ",", "val_loader", ",", "model", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"=> no checkpoint found at '{}'\"", ".", "format", "(", "opt", ".", "resume", ")", ")", "\n", "", "del", "checkpoint", "\n", "# Train the Model", "\n", "\n", "", "for", "epoch", "in", "range", "(", "opt", ".", "num_epochs", ")", ":", "\n", "        ", "adjust_learning_rate", "(", "opt", ",", "model", ".", "optimizer", ",", "epoch", ")", "\n", "\n", "# train for one epoch", "\n", "train", "(", "opt", ",", "train_loader", ",", "model", ",", "epoch", ",", "val_loader", ")", "\n", "\n", "# evaluate on validation set", "\n", "rsum", "=", "validate", "(", "opt", ",", "val_loader", ",", "model", ")", "\n", "\n", "# remember best R@ sum and save checkpoint", "\n", "is_best", "=", "rsum", ">", "best_rsum", "\n", "best_rsum", "=", "max", "(", "rsum", ",", "best_rsum", ")", "\n", "save_checkpoint", "(", "{", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "\n", "'model'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'best_rsum'", ":", "best_rsum", ",", "\n", "'opt'", ":", "opt", ",", "\n", "'Eiters'", ":", "model", ".", "Eiters", ",", "\n", "}", ",", "is_best", ",", "epoch", ",", "prefix", "=", "opt", ".", "logger_name", "+", "'/'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.train": [[140, 186], ["evaluation.AverageMeter", "evaluation.AverageMeter", "evaluation.LogCollector", "model.train_start", "time.time", "enumerate", "evaluation.AverageMeter.update", "model.train_emb", "evaluation.AverageMeter.update", "time.time", "tensorboard_logger.log_value", "tensorboard_logger.log_value", "tensorboard_logger.log_value", "tensorboard_logger.log_value", "model.logger.tb_log", "model.train_start", "logging.info", "time.time", "time.time", "len", "str"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.train_start", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.train_emb", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.tb_log", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.train_start"], ["", "", "def", "train", "(", "opt", ",", "train_loader", ",", "model", ",", "epoch", ",", "val_loader", ")", ":", "\n", "# average meters to record the training statistics", "\n", "    ", "batch_time", "=", "AverageMeter", "(", ")", "\n", "data_time", "=", "AverageMeter", "(", ")", "\n", "train_logger", "=", "LogCollector", "(", ")", "\n", "\n", "# switch to train mode", "\n", "model", ".", "train_start", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "train_data", "in", "enumerate", "(", "train_loader", ")", ":", "\n", "        ", "if", "opt", ".", "reset_train", ":", "\n", "# Always reset to train mode, this is not the default behavior", "\n", "            ", "model", ".", "train_start", "(", ")", "\n", "\n", "# measure data loading time", "\n", "", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "\n", "# make sure train logger is used", "\n", "model", ".", "logger", "=", "train_logger", "\n", "\n", "# Update the model", "\n", "model", ".", "train_emb", "(", "*", "train_data", ")", "\n", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Print log info", "\n", "if", "model", ".", "Eiters", "%", "opt", ".", "log_step", "==", "0", ":", "\n", "            ", "logging", ".", "info", "(", "\n", "'Epoch: [{0}][{1}/{2}]\\t'", "\n", "'{e_log}\\t'", "\n", "'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'", "\n", "'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'", "\n", ".", "format", "(", "\n", "epoch", ",", "i", ",", "len", "(", "train_loader", ")", ",", "batch_time", "=", "batch_time", ",", "\n", "data_time", "=", "data_time", ",", "e_log", "=", "str", "(", "model", ".", "logger", ")", ")", ")", "\n", "\n", "# Record logs in tensorboard", "\n", "", "tb_logger", ".", "log_value", "(", "'epoch'", ",", "epoch", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'step'", ",", "i", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'batch_time'", ",", "batch_time", ".", "val", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'data_time'", ",", "data_time", ".", "val", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "model", ".", "logger", ".", "tb_log", "(", "tb_logger", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.validate": [[192, 223], ["evaluation.encode_data", "evaluation.i2t", "logging.info", "evaluation.t2i", "logging.info", "tensorboard_logger.log_value", "tensorboard_logger.log_value", "tensorboard_logger.log_value", "tensorboard_logger.log_value", "tensorboard_logger.log_value", "tensorboard_logger.log_value", "tensorboard_logger.log_value", "tensorboard_logger.log_value", "tensorboard_logger.log_value", "tensorboard_logger.log_value", "tensorboard_logger.log_value"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.encode_data", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.i2t", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.t2i"], ["", "", "def", "validate", "(", "opt", ",", "val_loader", ",", "model", ")", ":", "\n", "# compute the encoding for all the validation images and captions", "\n", "    ", "img_embs", ",", "cap_embs", "=", "encode_data", "(", "\n", "model", ",", "val_loader", ",", "opt", ".", "log_step", ",", "logging", ".", "info", ")", "\n", "\n", "# caption retrieval", "\n", "(", "r1", ",", "r5", ",", "r10", ",", "medr", ",", "meanr", ")", "=", "i2t", "(", "img_embs", ",", "cap_embs", ")", "\n", "logging", ".", "info", "(", "\"Image to text: %.1f, %.1f, %.1f, %.1f, %.1f\"", "%", "\n", "(", "r1", ",", "r5", ",", "r10", ",", "medr", ",", "meanr", ")", ")", "\n", "# image retrieval", "\n", "(", "r1i", ",", "r5i", ",", "r10i", ",", "medri", ",", "meanr", ")", "=", "t2i", "(", "\n", "img_embs", ",", "cap_embs", ")", "\n", "logging", ".", "info", "(", "\"Text to image: %.1f, %.1f, %.1f, %.1f, %.1f\"", "%", "\n", "(", "r1i", ",", "r5i", ",", "r10i", ",", "medri", ",", "meanr", ")", ")", "\n", "# sum of recalls to be used for early stopping", "\n", "currscore", "=", "r1", "+", "r5", "+", "r10", "+", "r1i", "+", "r5i", "+", "r10i", "\n", "\n", "# record metrics in tensorboard", "\n", "tb_logger", ".", "log_value", "(", "'r1'", ",", "r1", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'r5'", ",", "r5", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'r10'", ",", "r10", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'medr'", ",", "medr", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'meanr'", ",", "meanr", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'r1i'", ",", "r1i", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'r5i'", ",", "r5i", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'r10i'", ",", "r10i", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'medri'", ",", "medri", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'meanr'", ",", "meanr", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "tb_logger", ".", "log_value", "(", "'rsum'", ",", "currscore", ",", "step", "=", "model", ".", "Eiters", ")", "\n", "\n", "return", "currscore", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.save_checkpoint": [[225, 229], ["torch.save", "shutil.copyfile"], "function", ["None"], ["", "def", "save_checkpoint", "(", "state", ",", "is_best", ",", "epoch", ",", "filename", "=", "'checkpoint.pth.tar'", ",", "prefix", "=", "''", ")", ":", "\n", "    ", "torch", ".", "save", "(", "state", ",", "prefix", "+", "filename", ")", "\n", "if", "is_best", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "prefix", "+", "filename", ",", "prefix", "+", "'model_best.pth.tar'", ")", "\n", "# shutil.copyfile(prefix + filename, prefix + 'checkpoint'+str(epoch)+'.pth.tar')", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.adjust_learning_rate": [[232, 238], ["None"], "function", ["None"], ["", "", "def", "adjust_learning_rate", "(", "opt", ",", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "\"\"\"Sets the learning rate to the initial LR\n       decayed by 10 every 30 epochs\"\"\"", "\n", "lr", "=", "opt", ".", "learning_rate", "*", "(", "0.1", "**", "(", "epoch", "//", "opt", ".", "lr_update", ")", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.accuracy": [[240, 254], ["max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].view().float().sum", "res.append", "correct[].view().float().sum.mul_", "target.view", "correct[].view().float", "correct[].view"], "function", ["None"], ["", "", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the precision@k for the specified values of k\"\"\"", "\n", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "        ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "view", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.RcnnEncoder.__init__": [[33, 45], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "RcnnEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_size", "=", "opt", ".", "embed_size", "\n", "self", ".", "fc_image", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "opt", ".", "img_dim", ",", "opt", ".", "img_dim", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "opt", ".", "img_dim", ",", "self", ".", "embed_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "0.1", ")", ")", "\n", "self", ".", "fc_pos", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "6", "+", "1601", ",", "self", ".", "embed_size", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Dropout", "(", "0.1", ")", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "embed_size", "*", "2", ",", "self", ".", "embed_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.RcnnEncoder.forward": [[46, 51], ["model_bert.RcnnEncoder.fc_image", "model_bert.RcnnEncoder.fc_pos"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "images", ",", "img_pos", ")", ":", "# (b, 100, 2048) (b,100,1601+6)", "\n", "        ", "img_f", "=", "self", ".", "fc_image", "(", "images", ")", "\n", "img_pe", "=", "self", ".", "fc_pos", "(", "img_pos", ")", "\n", "img_embs", "=", "img_f", "+", "img_pe", "\n", "return", "img_embs", "# (b,100,768)", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.ImageEncoder.__init__": [[55, 66], ["torch.Module.__init__", "resnet.resnet152", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "print", "model_bert.ImageEncoder.cnn.parameters", "print"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.resnet152"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "ImageEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_size", "=", "opt", ".", "embed_size", "\n", "self", ".", "cnn", "=", "resnet152", "(", "pretrained", "=", "True", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "opt", ".", "img_dim", ",", "opt", ".", "embed_size", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Dropout", "(", "0.1", ")", ")", "\n", "if", "not", "opt", ".", "ft_res", ":", "\n", "            ", "print", "(", "'image-encoder-resnet no grad!'", ")", "\n", "for", "param", "in", "self", ".", "cnn", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "'image-encoder-resnet fine-tuning !'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.ImageEncoder.forward": [[84, 90], ["model_bert.ImageEncoder.cnn", "features_top.view().transpose", "model_bert.ImageEncoder.fc", "features_top.view", "features_top.size", "features_top.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "images", ")", ":", "\n", "        ", "features_orig", "=", "self", ".", "cnn", "(", "images", ")", "\n", "features_top", "=", "features_orig", "[", "-", "1", "]", "\n", "features", "=", "features_top", ".", "view", "(", "features_top", ".", "size", "(", "0", ")", ",", "features_top", ".", "size", "(", "1", ")", ",", "-", "1", ")", ".", "transpose", "(", "2", ",", "1", ")", "# b, 49, 2048", "\n", "features", "=", "self", ".", "fc", "(", "features", ")", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.TextEncoder.__init__": [[93, 104], ["torch.Module.__init__", "pytorch_pretrained_bert.modeling.BertModel.from_pretrained", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "model_bert.TextEncoder.bert.parameters", "print", "print", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "TextEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "opt", ".", "bert_path", ")", "\n", "if", "not", "opt", ".", "ft_bert", ":", "\n", "            ", "for", "param", "in", "self", ".", "bert", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "print", "(", "'text-encoder-bert no grad'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'text-encoder-bert fine-tuning !'", ")", "\n", "", "self", ".", "embed_size", "=", "opt", ".", "embed_size", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "opt", ".", "bert_size", ",", "opt", ".", "embed_size", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Dropout", "(", "0.1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.TextEncoder.forward": [[105, 110], ["model_bert.TextEncoder.bert", "model_bert.TextEncoder.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "captions", ")", ":", "\n", "        ", "all_encoders", ",", "pooled", "=", "self", ".", "bert", "(", "captions", ")", "\n", "out", "=", "all_encoders", "[", "-", "1", "]", "\n", "out", "=", "self", ".", "fc", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.GATopt.__init__": [[113, 119], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "num_layers", ")", ":", "\n", "        ", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "num_attention_heads", "=", "8", "\n", "self", ".", "hidden_dropout_prob", "=", "0.2", "\n", "self", ".", "attention_probs_dropout_prob", "=", "0.2", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.GAT.__init__": [[122, 126], ["torch.Module.__init__", "GAT.GATLayer", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config_gat", ")", ":", "\n", "        ", "super", "(", "GAT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layer", "=", "GATLayer", "(", "config_gat", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "layer", ")", "for", "_", "in", "range", "(", "config_gat", ".", "num_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.GAT.forward": [[127, 132], ["layer_module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_graph", ")", ":", "\n", "        ", "hidden_states", "=", "input_graph", "\n", "for", "layer_module", "in", "self", ".", "encoder", ":", "\n", "            ", "hidden_states", "=", "layer_module", "(", "hidden_states", ")", "\n", "", "return", "hidden_states", "# B, seq_len, D", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.ContrastiveLoss.__init__": [[139, 143], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "margin", "=", "0", ")", ":", "\n", "        ", "super", "(", "ContrastiveLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "sim", "=", "cosine_sim", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.ContrastiveLoss.forward": [[144, 166], ["model_bert.ContrastiveLoss.sim", "model_bert.ContrastiveLoss.diag().view", "model_bert.ContrastiveLoss.diag().view.expand_as", "model_bert.ContrastiveLoss.diag().view.t().expand_as", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "cost_s.masked_fill_.masked_fill_.masked_fill_", "cost_im.masked_fill_.masked_fill_.masked_fill_", "im.size", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "I.cuda.cuda.cuda", "cost_s.masked_fill_.masked_fill_.max", "cost_im.masked_fill_.masked_fill_.max", "cost_s.masked_fill_.masked_fill_.sum", "cost_im.masked_fill_.masked_fill_.sum", "model_bert.ContrastiveLoss.diag", "model_bert.ContrastiveLoss.diag().view.t", "model_bert.ContrastiveLoss.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "im", ",", "s", ")", ":", "\n", "        ", "scores", "=", "self", ".", "sim", "(", "im", ",", "s", ")", "\n", "diagonal", "=", "scores", ".", "diag", "(", ")", ".", "view", "(", "im", ".", "size", "(", "0", ")", ",", "1", ")", "\n", "\n", "d1", "=", "diagonal", ".", "expand_as", "(", "scores", ")", "\n", "d2", "=", "diagonal", ".", "t", "(", ")", ".", "expand_as", "(", "scores", ")", "\n", "im_sn", "=", "scores", "-", "d1", "\n", "c_sn", "=", "scores", "-", "d2", "\n", "cost_s", "=", "(", "self", ".", "margin", "+", "scores", "-", "d1", ")", ".", "clamp", "(", "min", "=", "0", ")", "\n", "\n", "cost_im", "=", "(", "self", ".", "margin", "+", "scores", "-", "d2", ")", ".", "clamp", "(", "min", "=", "0", ")", "\n", "\n", "mask", "=", "torch", ".", "eye", "(", "scores", ".", "size", "(", "0", ")", ")", ">", ".5", "\n", "I", "=", "Variable", "(", "mask", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "I", "=", "I", ".", "cuda", "(", ")", "\n", "", "cost_s", "=", "cost_s", ".", "masked_fill_", "(", "I", ",", "0", ")", "\n", "cost_im", "=", "cost_im", ".", "masked_fill_", "(", "I", ",", "0", ")", "\n", "\n", "cost_s", "=", "cost_s", ".", "max", "(", "1", ")", "[", "0", "]", "\n", "cost_im", "=", "cost_im", ".", "max", "(", "0", ")", "[", "0", "]", "\n", "return", "cost_s", ".", "sum", "(", ")", "+", "cost_im", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.Fusion.__init__": [[174, 182], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "Fusion", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "f_size", "=", "opt", ".", "embed_size", "\n", "self", ".", "gate0", "=", "nn", ".", "Linear", "(", "self", ".", "f_size", ",", "self", ".", "f_size", ")", "\n", "self", ".", "gate1", "=", "nn", ".", "Linear", "(", "self", ".", "f_size", ",", "self", ".", "f_size", ")", "\n", "\n", "self", ".", "fusion0", "=", "nn", ".", "Linear", "(", "self", ".", "f_size", ",", "self", ".", "f_size", ")", "\n", "self", ".", "fusion1", "=", "nn", ".", "Linear", "(", "self", ".", "f_size", ",", "self", ".", "f_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.Fusion.forward": [[183, 189], ["model_bert.Fusion.gate0", "model_bert.Fusion.gate1", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "model_bert.Fusion.fusion0", "model_bert.Fusion.fusion1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "vec1", ",", "vec2", ")", ":", "\n", "        ", "features_1", "=", "self", ".", "gate0", "(", "vec1", ")", "\n", "features_2", "=", "self", ".", "gate1", "(", "vec2", ")", "\n", "t", "=", "torch", ".", "sigmoid", "(", "self", ".", "fusion0", "(", "features_1", ")", "+", "self", ".", "fusion1", "(", "features_2", ")", ")", "\n", "f", "=", "t", "*", "features_1", "+", "(", "1", "-", "t", ")", "*", "features_2", "\n", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.DSRAN.__init__": [[192, 221], ["torch.Module.__init__", "model_bert.ImageEncoder", "model_bert.TextEncoder", "model_bert.RcnnEncoder", "model_bert.GATopt", "model_bert.GATopt", "model_bert.GATopt", "model_bert.GATopt", "model_bert.GAT", "model_bert.GAT", "model_bert.GAT", "model_bert.GAT", "model_bert.GAT", "model_bert.Fusion", "model_bert.GAT", "model_bert.GAT", "model_bert.GAT", "model_bert.Fusion", "model_bert.Fusion", "model_bert.Fusion"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "DSRAN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "img_enc", "=", "ImageEncoder", "(", "opt", ")", "\n", "self", ".", "txt_enc", "=", "TextEncoder", "(", "opt", ")", "\n", "self", ".", "rcnn_enc", "=", "RcnnEncoder", "(", "opt", ")", "\n", "\n", "config_img", "=", "GATopt", "(", "opt", ".", "embed_size", ",", "1", ")", "\n", "config_cap", "=", "GATopt", "(", "opt", ".", "embed_size", ",", "1", ")", "\n", "config_rcnn", "=", "GATopt", "(", "opt", ".", "embed_size", ",", "1", ")", "\n", "config_joint", "=", "GATopt", "(", "opt", ".", "embed_size", ",", "1", ")", "\n", "\n", "self", ".", "K", "=", "opt", ".", "K", "\n", "# SSR", "\n", "self", ".", "gat_1", "=", "GAT", "(", "config_img", ")", "\n", "self", ".", "gat_2", "=", "GAT", "(", "config_rcnn", ")", "\n", "self", ".", "gat_cap", "=", "GAT", "(", "config_cap", ")", "\n", "# JSR", "\n", "self", ".", "gat_cat", "=", "GAT", "(", "config_joint", ")", "\n", "if", "self", ".", "K", "==", "2", ":", "\n", "            ", "self", ".", "gat_cat_1", "=", "GAT", "(", "config_joint", ")", "\n", "self", ".", "fusion", "=", "Fusion", "(", "opt", ")", "\n", "", "elif", "self", ".", "K", "==", "4", ":", "\n", "            ", "self", ".", "gat_cat_1", "=", "GAT", "(", "config_joint", ")", "\n", "self", ".", "gat_cat_2", "=", "GAT", "(", "config_joint", ")", "\n", "self", ".", "gat_cat_3", "=", "GAT", "(", "config_joint", ")", "\n", "\n", "self", ".", "fusion", "=", "Fusion", "(", "opt", ")", "\n", "self", ".", "fusion_1", "=", "Fusion", "(", "opt", ")", "\n", "self", ".", "fusion_2", "=", "Fusion", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.DSRAN.forward": [[222, 252], ["model_bert.DSRAN.gat_1", "model_bert.DSRAN.rcnn_enc", "model_bert.DSRAN.gat_2", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_bert.DSRAN.gat_cat", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model_bert.l2norm", "model_bert.DSRAN.txt_enc", "model_bert.DSRAN.gat_cap", "model_bert.l2norm", "model_bert.DSRAN.img_enc", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model_bert.DSRAN.gat_cat_1", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model_bert.DSRAN.fusion", "model_bert.DSRAN.gat_cat_1", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model_bert.DSRAN.gat_cat_2", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model_bert.DSRAN.gat_cat_3", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model_bert.DSRAN.fusion_1", "model_bert.DSRAN.fusion_2", "model_bert.DSRAN.fusion"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.l2norm", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.l2norm"], ["", "", "def", "forward", "(", "self", ",", "images_orig", ",", "rcnn_fe", ",", "img_pos", ",", "captions", ")", ":", "\n", "\n", "        ", "img_emb_orig", "=", "self", ".", "gat_1", "(", "self", ".", "img_enc", "(", "images_orig", ")", ")", "\n", "rcnn_emb", "=", "self", ".", "rcnn_enc", "(", "rcnn_fe", ",", "img_pos", ")", "\n", "rcnn_emb", "=", "self", ".", "gat_2", "(", "rcnn_emb", ")", "\n", "img_cat", "=", "torch", ".", "cat", "(", "(", "img_emb_orig", ",", "rcnn_emb", ")", ",", "1", ")", "\n", "img_cat_1", "=", "self", ".", "gat_cat", "(", "img_cat", ")", "\n", "img_cat_1", "=", "torch", ".", "mean", "(", "img_cat_1", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "K", "==", "1", ":", "\n", "            ", "img_cat", "=", "img_cat_1", "\n", "", "elif", "self", ".", "K", "==", "2", ":", "\n", "            ", "img_cat_2", "=", "self", ".", "gat_cat_1", "(", "img_cat", ")", "\n", "img_cat_2", "=", "torch", ".", "mean", "(", "img_cat_2", ",", "dim", "=", "1", ")", "\n", "img_cat", "=", "self", ".", "fusion", "(", "img_cat_1", ",", "img_cat_2", ")", "\n", "", "elif", "self", ".", "K", "==", "4", ":", "\n", "            ", "img_cat_2", "=", "self", ".", "gat_cat_1", "(", "img_cat", ")", "\n", "img_cat_2", "=", "torch", ".", "mean", "(", "img_cat_2", ",", "dim", "=", "1", ")", "\n", "img_cat_3", "=", "self", ".", "gat_cat_2", "(", "img_cat", ")", "\n", "img_cat_3", "=", "torch", ".", "mean", "(", "img_cat_3", ",", "dim", "=", "1", ")", "\n", "img_cat_4", "=", "self", ".", "gat_cat_3", "(", "img_cat", ")", "\n", "img_cat_4", "=", "torch", ".", "mean", "(", "img_cat_4", ",", "dim", "=", "1", ")", "\n", "img_cat_1_1", "=", "self", ".", "fusion_1", "(", "img_cat_1", ",", "img_cat_2", ")", "\n", "img_cat_1_2", "=", "self", ".", "fusion_2", "(", "img_cat_3", ",", "img_cat_4", ")", "\n", "img_cat", "=", "self", ".", "fusion", "(", "img_cat_1_1", ",", "img_cat_1_2", ")", "\n", "", "img_emb", "=", "l2norm", "(", "img_cat", ")", "\n", "cap_emb", "=", "self", ".", "txt_enc", "(", "captions", ")", "\n", "cap_gat", "=", "self", ".", "gat_cap", "(", "cap_emb", ")", "\n", "cap_embs", "=", "l2norm", "(", "torch", ".", "mean", "(", "cap_gat", ",", "dim", "=", "1", ")", ")", "\n", "\n", "return", "img_emb", ",", "cap_embs", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.VSE.__init__": [[256, 275], ["model_bert.DSRAN", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model_bert.ContrastiveLoss", "list", "model_bert.get_optimizer", "model_bert.VSE.DSRAN.cuda", "model_bert.VSE.DSRAN.named_parameters", "any", "any"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.get_optimizer"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "DSRAN", "=", "DSRAN", "(", "opt", ")", "\n", "self", ".", "DSRAN", "=", "nn", ".", "DataParallel", "(", "self", ".", "DSRAN", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "DSRAN", ".", "cuda", "(", ")", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "", "self", ".", "criterion", "=", "ContrastiveLoss", "(", "margin", "=", "opt", ".", "margin", ")", "\n", "params", "=", "list", "(", "self", ".", "DSRAN", ".", "named_parameters", "(", ")", ")", "\n", "param_optimizer", "=", "params", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "t_total", "=", "opt", ".", "l_train", "*", "opt", ".", "num_epochs", "\n", "if", "opt", ".", "warmup", "==", "-", "1", ":", "\n", "            ", "t_total", "=", "-", "1", "\n", "", "self", ".", "optimizer", "=", "get_optimizer", "(", "params", "=", "optimizer_grouped_parameters", ",", "opt", "=", "opt", ",", "t_total", "=", "t_total", ")", "\n", "self", ".", "Eiters", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.VSE.state_dict": [[276, 279], ["model_bert.VSE.DSRAN.state_dict"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "state_dict", "=", "self", ".", "DSRAN", ".", "state_dict", "(", ")", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.VSE.load_state_dict": [[280, 282], ["model_bert.VSE.DSRAN.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "DSRAN", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.VSE.train_start": [[283, 285], ["model_bert.VSE.DSRAN.train"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.train"], ["", "def", "train_start", "(", "self", ")", ":", "\n", "        ", "self", ".", "DSRAN", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.VSE.val_start": [[286, 288], ["model_bert.VSE.DSRAN.eval"], "methods", ["None"], ["", "def", "val_start", "(", "self", ")", ":", "\n", "        ", "self", ".", "DSRAN", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.VSE.forward_emb": [[289, 299], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model_bert.VSE.DSRAN", "images_orig.cuda.cuda.cuda", "rcnn_fe.cuda.cuda.cuda", "img_pos.cuda.cuda.cuda", "captions.cuda.cuda.cuda"], "methods", ["None"], ["", "def", "forward_emb", "(", "self", ",", "images_orig", ",", "rcnn_fe", ",", "img_pos", ",", "captions", ")", ":", "\n", "        ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "images_orig", "=", "images_orig", ".", "cuda", "(", ")", "\n", "rcnn_fe", "=", "rcnn_fe", ".", "cuda", "(", ")", "\n", "img_pos", "=", "img_pos", ".", "cuda", "(", ")", "\n", "captions", "=", "captions", ".", "cuda", "(", ")", "\n", "\n", "", "img_emb", ",", "cap_emb", "=", "self", ".", "DSRAN", "(", "images_orig", ",", "rcnn_fe", ",", "img_pos", ",", "captions", ")", "\n", "\n", "return", "img_emb", ",", "cap_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.VSE.forward_loss": [[300, 304], ["model_bert.VSE.criterion", "model_bert.VSE.logger.update", "img_emb.size"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update"], ["", "def", "forward_loss", "(", "self", ",", "img_emb", ",", "cap_emb", ",", "**", "kwargs", ")", ":", "\n", "        ", "loss", "=", "self", ".", "criterion", "(", "img_emb", ",", "cap_emb", ")", "\n", "self", ".", "logger", ".", "update", "(", "'Le'", ",", "loss", ".", "data", ",", "img_emb", ".", "size", "(", "0", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.VSE.train_emb": [[305, 317], ["model_bert.VSE.logger.update", "model_bert.VSE.logger.update", "model_bert.VSE.forward_emb", "model_bert.VSE.optimizer.zero_grad", "model_bert.VSE.forward_loss", "model_bert.VSE.backward", "model_bert.VSE.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.forward_emb", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.forward_loss", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.optimization.BertAdam.step"], ["", "def", "train_emb", "(", "self", ",", "images", ",", "images_orig", ",", "img_pos", ",", "captions", ",", "ids", "=", "None", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "Eiters", "+=", "1", "\n", "self", ".", "logger", ".", "update", "(", "'Eit'", ",", "self", ".", "Eiters", ")", "\n", "self", ".", "logger", ".", "update", "(", "'lr'", ",", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", "\n", "\n", "img_emb", ",", "cap_emb", "=", "self", ".", "forward_emb", "(", "images_orig", ",", "images", ",", "img_pos", ",", "captions", ")", "\n", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "self", ".", "forward_loss", "(", "img_emb", ",", "cap_emb", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.l2norm": [[26, 30], ["torch.pow().sum().sqrt", "torch.pow().sum().sqrt", "torch.pow().sum().sqrt", "torch.pow().sum().sqrt", "torch.pow().sum().sqrt", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "function", ["None"], ["def", "l2norm", "(", "X", ")", ":", "\n", "    ", "norm", "=", "torch", ".", "pow", "(", "X", ",", "2", ")", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", ".", "sqrt", "(", ")", "\n", "X", "=", "torch", ".", "div", "(", "X", ",", "norm", ")", "\n", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.cosine_sim": [[134, 136], ["im.mm", "s.t"], "function", ["None"], ["", "", "def", "cosine_sim", "(", "im", ",", "s", ")", ":", "\n", "    ", "return", "im", ".", "mm", "(", "s", ".", "t", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model_bert.get_optimizer": [[168, 171], ["pytorch_pretrained_bert.optimization.BertAdam"], "function", ["None"], ["", "", "def", "get_optimizer", "(", "params", ",", "opt", ",", "t_total", "=", "-", "1", ")", ":", "\n", "    ", "bertadam", "=", "BertAdam", "(", "params", ",", "lr", "=", "opt", ".", "learning_rate", ",", "warmup", "=", "opt", ".", "warmup", ",", "t_total", "=", "t_total", ")", "\n", "return", "bertadam", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.CocoDataset.__init__": [[78, 109], ["isinstance", "isinstance", "list", "len", "len", "pycocotools.coco.COCO", "pycocotools.coco.COCO", "pycocotools.coco.COCO", "torch.CocoDataset.coco.anns.keys", "list", "list"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "root", ",", "json", ",", "vocab", ",", "region_bbox_file", ",", "region_det_file_prefix", ",", "transform", "=", "None", ",", "ids", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            root: image directory.\n            json: coco annotation file path.\n            vocab: vocabulary wrapper.\n            transform: transformer for image.\n        \"\"\"", "\n", "self", ".", "root", "=", "root", "\n", "# when using `restval`, two json files are needed", "\n", "if", "isinstance", "(", "json", ",", "tuple", ")", ":", "\n", "            ", "self", ".", "coco", "=", "(", "COCO", "(", "json", "[", "0", "]", ")", ",", "COCO", "(", "json", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "coco", "=", "(", "COCO", "(", "json", ")", ",", ")", "\n", "self", ".", "root", "=", "(", "root", ",", ")", "\n", "# if ids provided by get_paths, use split-specific ids", "\n", "", "if", "ids", "is", "None", ":", "\n", "            ", "self", ".", "ids", "=", "list", "(", "self", ".", "coco", ".", "anns", ".", "keys", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "ids", "=", "ids", "\n", "\n", "# if `restval` data is to be used, record the break point for ids", "\n", "", "if", "isinstance", "(", "self", ".", "ids", ",", "tuple", ")", ":", "\n", "            ", "self", ".", "bp", "=", "len", "(", "self", ".", "ids", "[", "0", "]", ")", "\n", "self", ".", "ids", "=", "list", "(", "self", ".", "ids", "[", "0", "]", ")", "+", "list", "(", "self", ".", "ids", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bp", "=", "len", "(", "self", ".", "ids", ")", "\n", "", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "region_bbox_file", "=", "region_bbox_file", "#'/remote-home/lyli/Workspace/burneddown/ECCV/joint-pretrain/COCO/region_feat_gvd_wo_bgd/coco_detection_vg_thresh0.2_feat_gvd_checkpoint_trainvaltest.h5'", "\n", "self", ".", "region_det_file_prefix", "=", "region_det_file_prefix", "#'/remote-home/lyli/Workspace/burneddown/ECCV/joint-pretrain/COCO/region_feat_gvd_wo_bgd/feat_cls_1000/coco_detection_vg_100dets_gvd_checkpoint_trainval'", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.CocoDataset.__getitem__": [[110, 129], ["torch.CocoDataset.get_raw_item", "nltk.tokenize.word_tokenize", "caption.append", "caption.extend", "caption.append", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.CocoDataset.transform", "str().lower().encode().decode", "vocab", "vocab", "vocab", "str().lower().encode", "str().lower", "str"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.CocoDataset.get_raw_item"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"This function returns a tuple that is further passed to collate_fn\n        \"\"\"", "\n", "vocab", "=", "self", ".", "vocab", "\n", "root", ",", "caption", ",", "img_id", ",", "path", ",", "image", ",", "img_rcnn", ",", "img_pe", "=", "self", ".", "get_raw_item", "(", "index", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "image", "=", "self", ".", "transform", "(", "image", ")", "\n", "\n", "# Convert caption (string) to word ids.", "\n", "", "tokens", "=", "nltk", ".", "tokenize", ".", "word_tokenize", "(", "\n", "str", "(", "caption", ")", ".", "lower", "(", ")", ".", "encode", "(", "'utf-8'", ")", ".", "decode", "(", "'utf-8'", ")", ")", "\n", "caption", "=", "[", "]", "\n", "caption", ".", "append", "(", "vocab", "(", "'<start>'", ")", ")", "\n", "caption", ".", "extend", "(", "[", "vocab", "(", "token", ")", "for", "token", "in", "tokens", "]", ")", "\n", "caption", ".", "append", "(", "vocab", "(", "'<end>'", ")", ")", "\n", "target", "=", "torch", ".", "Tensor", "(", "caption", ")", "\n", "\n", "return", "image", ",", "target", ",", "img_rcnn", ",", "img_pe", ",", "index", ",", "img_id", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.CocoDataset.get_raw_item": [[130, 145], ["PIL.Image.open().convert", "torch.CocoDataset.get_rcnn", "coco.loadImgs", "PIL.Image.open", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.FlickrDataset.get_rcnn"], ["", "def", "get_raw_item", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "index", "<", "self", ".", "bp", ":", "\n", "            ", "coco", "=", "self", ".", "coco", "[", "0", "]", "\n", "root", "=", "self", ".", "root", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "coco", "=", "self", ".", "coco", "[", "1", "]", "\n", "root", "=", "self", ".", "root", "[", "1", "]", "\n", "", "ann_id", "=", "self", ".", "ids", "[", "index", "]", "\n", "caption", "=", "coco", ".", "anns", "[", "ann_id", "]", "[", "'caption'", "]", "\n", "img_id", "=", "coco", ".", "anns", "[", "ann_id", "]", "[", "'image_id'", "]", "\n", "path", "=", "coco", ".", "loadImgs", "(", "img_id", ")", "[", "0", "]", "[", "'file_name'", "]", "\n", "image", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "path", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "img_rcnn", ",", "img_pe", "=", "self", ".", "get_rcnn", "(", "path", ")", "\n", "\n", "return", "root", ",", "caption", ",", "img_id", ",", "path", ",", "image", ",", "img_rcnn", ",", "img_pe", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.CocoDataset.get_rcnn": [[146, 153], ["torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "[].split", "h5py.File", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "path.split"], "methods", ["None"], ["", "def", "get_rcnn", "(", "self", ",", "path", ")", ":", "\n", "        ", "img_id", "=", "path", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "with", "h5py", ".", "File", "(", "self", ".", "region_det_file_prefix", "+", "'_feat'", "+", "img_id", "[", "-", "3", ":", "]", "+", "'.h5'", ",", "'r'", ")", "as", "region_feat_f", ":", "\n", "            ", "img", "=", "torch", ".", "from_numpy", "(", "region_feat_f", "[", "img_id", "]", "[", ":", "]", ")", ".", "float", "(", ")", "\n", "\n", "", "vis_pe", "=", "torch", ".", "randn", "(", "100", ",", "1601", "+", "6", ")", "# no position information", "\n", "return", "img", ",", "vis_pe", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.CocoDataset.__len__": [[154, 156], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.FlickrDataset.__init__": [[163, 175], ["enumerate", "json.load", "open", "range", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "root", ",", "json", ",", "split", ",", "vocab", ",", "region_bbox_file", ",", "feature_path", ",", "transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "root", "=", "root", "\n", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "dataset", "=", "jsonmod", ".", "load", "(", "open", "(", "json", ",", "'r'", ")", ")", "[", "'images'", "]", "\n", "self", ".", "ids", "=", "[", "]", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "self", ".", "dataset", ")", ":", "\n", "            ", "if", "d", "[", "'split'", "]", "==", "split", ":", "\n", "                ", "self", ".", "ids", "+=", "[", "(", "i", ",", "x", ")", "for", "x", "in", "range", "(", "len", "(", "d", "[", "'sentences'", "]", ")", ")", "]", "\n", "", "", "self", ".", "region_bbox_file", "=", "region_bbox_file", "#'/home/wenkeyu/wky/projects/pretrain/flickr30k/region_feat_gvd_wo_bgd/flickr30k_detection_vg_thresh0.2_feat_gvd_checkpoint_trainvaltest.h5'", "\n", "self", ".", "feature_path", "=", "feature_path", "#'/home/wenkeyu/wky/projects/pretrain/flickr30k/region_feat_gvd_wo_bgd/trainval/'", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.FlickrDataset.__getitem__": [[176, 206], ["PIL.Image.open().convert", "copy.deepcopy", "path.replace.replace.replace", "torch.FlickrDataset.get_rcnn", "nltk.tokenize.word_tokenize", "caption.append", "caption.extend", "caption.append", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.FlickrDataset.transform", "os.path.join", "str().lower().encode().decode", "vocab", "vocab", "PIL.Image.open", "vocab", "os.path.join", "str().lower().encode", "str().lower", "str"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.FlickrDataset.get_rcnn"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"This function returns a tuple that is further passed to collate_fn\n        \"\"\"", "\n", "vocab", "=", "self", ".", "vocab", "\n", "root", "=", "self", ".", "root", "+", "'/images'", "\n", "ann_id", "=", "self", ".", "ids", "[", "index", "]", "\n", "img_id", "=", "ann_id", "[", "0", "]", "\n", "caption", "=", "self", ".", "dataset", "[", "img_id", "]", "[", "'sentences'", "]", "[", "ann_id", "[", "1", "]", "]", "[", "'raw'", "]", "\n", "path", "=", "self", ".", "dataset", "[", "img_id", "]", "[", "'filename'", "]", "\n", "\n", "image", "=", "Image", ".", "open", "(", "os", ".", "path", ".", "join", "(", "root", ",", "path", ")", ")", ".", "convert", "(", "'RGB'", ")", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "image", "=", "self", ".", "transform", "(", "image", ")", "\n", "\n", "", "path_orig", "=", "copy", ".", "deepcopy", "(", "path", ")", "\n", "# print(path)", "\n", "path", "=", "path", ".", "replace", "(", "'.jpg'", ",", "'.npy'", ")", "\n", "feature_path", "=", "self", ".", "feature_path", "\n", "\n", "image_rcnn", ",", "img_pos", "=", "self", ".", "get_rcnn", "(", "os", ".", "path", ".", "join", "(", "feature_path", ",", "path", ")", ")", "# return img-feature 100 2048 & pos-feature", "\n", "\n", "# Convert caption (string) to word ids.", "\n", "tokens", "=", "nltk", ".", "tokenize", ".", "word_tokenize", "(", "\n", "str", "(", "caption", ")", ".", "lower", "(", ")", ".", "encode", "(", "'utf-8'", ")", ".", "decode", "(", "'utf-8'", ")", ")", "\n", "caption", "=", "[", "]", "\n", "caption", ".", "append", "(", "vocab", "(", "'<start>'", ")", ")", "\n", "caption", ".", "extend", "(", "[", "vocab", "(", "token", ")", "for", "token", "in", "tokens", "]", ")", "\n", "caption", ".", "append", "(", "vocab", "(", "'<end>'", ")", ")", "\n", "target", "=", "torch", ".", "Tensor", "(", "caption", ")", "\n", "return", "image", ",", "target", ",", "image_rcnn", ",", "img_pos", ",", "index", ",", "img_id", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.FlickrDataset.get_rcnn": [[207, 216], ["os.path.exists", "os.path.exists", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "img_path.replace", "numpy.load"], "methods", ["None"], ["", "def", "get_rcnn", "(", "self", ",", "img_path", ")", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "img_path", ")", "and", "os", ".", "path", ".", "exists", "(", "img_path", ".", "replace", "(", "'.npy'", ",", "'_cls_prob.npy'", ")", ")", ":", "\n", "# time1 = time.time()", "\n", "            ", "img", "=", "torch", ".", "from_numpy", "(", "np", ".", "load", "(", "img_path", ")", ")", "\n", "vis_pe", "=", "torch", ".", "randn", "(", "100", ",", "1601", "+", "6", ")", "# no position information", "\n", "", "else", ":", "\n", "            ", "img", "=", "torch", ".", "randn", "(", "100", ",", "2048", ")", "\n", "vis_pe", "=", "torch", ".", "randn", "(", "100", ",", "1601", "+", "6", ")", "\n", "", "return", "img", ",", "vis_pe", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.FlickrDataset.__len__": [[218, 220], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "ids", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_paths": [[25, 73], ["os.path.join", "os.path.join", "numpy.load", "numpy.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "numpy.load", "os.path.join", "numpy.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["def", "get_paths", "(", "path", ",", "name", "=", "'coco'", ",", "use_restval", "=", "False", ")", ":", "\n", "\n", "    ", "roots", "=", "{", "}", "\n", "ids", "=", "{", "}", "\n", "if", "'coco'", "==", "name", ":", "\n", "        ", "imgdir", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'images'", ")", "\n", "capdir", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'annotations'", ")", "\n", "roots", "[", "'train'", "]", "=", "{", "\n", "'img'", ":", "os", ".", "path", ".", "join", "(", "imgdir", ",", "'train2014'", ")", ",", "\n", "'cap'", ":", "os", ".", "path", ".", "join", "(", "capdir", ",", "'captions_train2014.json'", ")", "\n", "}", "\n", "roots", "[", "'val'", "]", "=", "{", "\n", "'img'", ":", "os", ".", "path", ".", "join", "(", "imgdir", ",", "'val2014'", ")", ",", "\n", "'cap'", ":", "os", ".", "path", ".", "join", "(", "capdir", ",", "'captions_val2014.json'", ")", "\n", "}", "\n", "roots", "[", "'test'", "]", "=", "{", "\n", "'img'", ":", "os", ".", "path", ".", "join", "(", "imgdir", ",", "'val2014'", ")", ",", "\n", "'cap'", ":", "os", ".", "path", ".", "join", "(", "capdir", ",", "'captions_val2014.json'", ")", "\n", "}", "\n", "roots", "[", "'trainrestval'", "]", "=", "{", "\n", "'img'", ":", "(", "roots", "[", "'train'", "]", "[", "'img'", "]", ",", "roots", "[", "'val'", "]", "[", "'img'", "]", ")", ",", "\n", "'cap'", ":", "(", "roots", "[", "'train'", "]", "[", "'cap'", "]", ",", "roots", "[", "'val'", "]", "[", "'cap'", "]", ")", "\n", "}", "\n", "ids", "[", "'train'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "capdir", ",", "'coco_train_ids.npy'", ")", ")", "\n", "ids", "[", "'val'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "capdir", ",", "'coco_dev_ids.npy'", ")", ")", "[", ":", "5000", "]", "\n", "ids", "[", "'test'", "]", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "capdir", ",", "'coco_test_ids.npy'", ")", ")", "\n", "ids", "[", "'trainrestval'", "]", "=", "(", "\n", "ids", "[", "'train'", "]", ",", "\n", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "capdir", ",", "'coco_restval_ids.npy'", ")", ")", ")", "\n", "if", "use_restval", ":", "\n", "            ", "roots", "[", "'train'", "]", "=", "roots", "[", "'trainrestval'", "]", "\n", "ids", "[", "'train'", "]", "=", "ids", "[", "'trainrestval'", "]", "\n", "", "", "elif", "'f8k'", "==", "name", ":", "\n", "        ", "imgdir", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'images'", ")", "\n", "cap", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'dataset_flickr8k.json'", ")", "\n", "roots", "[", "'train'", "]", "=", "{", "'img'", ":", "imgdir", ",", "'cap'", ":", "cap", "}", "\n", "roots", "[", "'val'", "]", "=", "{", "'img'", ":", "imgdir", ",", "'cap'", ":", "cap", "}", "\n", "roots", "[", "'test'", "]", "=", "{", "'img'", ":", "imgdir", ",", "'cap'", ":", "cap", "}", "\n", "ids", "=", "{", "'train'", ":", "None", ",", "'val'", ":", "None", ",", "'test'", ":", "None", "}", "\n", "", "elif", "'f30k'", "==", "name", ":", "\n", "        ", "imgdir", "=", "os", ".", "path", ".", "join", "(", "path", ",", "''", ")", "\n", "cap", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'dataset_flickr30k.json'", ")", "\n", "roots", "[", "'train'", "]", "=", "{", "'img'", ":", "imgdir", ",", "'cap'", ":", "cap", "}", "\n", "roots", "[", "'val'", "]", "=", "{", "'img'", ":", "imgdir", ",", "'cap'", ":", "cap", "}", "\n", "roots", "[", "'test'", "]", "=", "{", "'img'", ":", "imgdir", ",", "'cap'", ":", "cap", "}", "\n", "ids", "=", "{", "'train'", ":", "None", ",", "'val'", ":", "None", ",", "'test'", ":", "None", "}", "\n", "\n", "", "return", "roots", ",", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.collate_fn": [[222, 250], ["torch.sort", "zip", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "enumerate", "len", "torch.zeros", "torch.zeros", "torch.zeros", "len", "len", "max"], "function", ["None"], ["", "", "def", "collate_fn", "(", "data", ")", ":", "\n", "    ", "\"\"\"Build mini-batch tensors from a list of (image, caption) tuples.\n    Args:\n        data: list of (image, caption) tuple.\n            - image: torch tensor of shape (3, 256, 256).\n            - caption: torch tensor of shape (?); variable length.\n\n    Returns:\n        images: torch tensor of shape (batch_size, 3, 256, 256).\n        targets: torch tensor of shape (batch_size, padded_length).\n        lengths: list; valid length for each padded caption.\n    \"\"\"", "\n", "# Sort a data list by caption length", "\n", "data", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "1", "]", ")", ",", "reverse", "=", "True", ")", "\n", "images", ",", "captions", ",", "image_rcnn", ",", "img_pos", ",", "ids", ",", "img_ids", "=", "zip", "(", "*", "data", ")", "\n", "\n", "# Merge images (convert tuple of 3D tensor to 4D tensor)", "\n", "images", "=", "torch", ".", "stack", "(", "images", ",", "0", ")", "\n", "image_rcnn", "=", "torch", ".", "stack", "(", "image_rcnn", ",", "0", ")", "\n", "img_pos", "=", "torch", ".", "stack", "(", "img_pos", ",", "0", ")", "\n", "# Merget captions (convert tuple of 1D tensor to 2D tensor)", "\n", "lengths", "=", "[", "len", "(", "cap", ")", "for", "cap", "in", "captions", "]", "\n", "targets", "=", "torch", ".", "zeros", "(", "len", "(", "captions", ")", ",", "max", "(", "lengths", ")", ")", ".", "long", "(", ")", "\n", "for", "i", ",", "cap", "in", "enumerate", "(", "captions", ")", ":", "\n", "        ", "end", "=", "lengths", "[", "i", "]", "\n", "targets", "[", "i", ",", ":", "end", "]", "=", "cap", "[", ":", "end", "]", "\n", "\n", "", "return", "images", ",", "targets", ",", "image_rcnn", ",", "img_pos", ",", "lengths", ",", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_loader_single": [[252, 280], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "data.CocoDataset", "data.FlickrDataset"], "function", ["None"], ["", "def", "get_loader_single", "(", "data_name", ",", "split", ",", "root", ",", "json", ",", "vocab", ",", "transform", ",", "batch_size", "=", "100", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "2", ",", "ids", "=", "None", ",", "collate_fn", "=", "collate_fn", ",", "region_bbox_file", "=", "None", ",", "feature_path", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns torch.utils.data.DataLoader for custom coco dataset.\"\"\"", "\n", "if", "'coco'", "in", "data_name", ":", "\n", "# COCO custom dataset", "\n", "        ", "dataset", "=", "CocoDataset", "(", "root", "=", "root", ",", "\n", "json", "=", "json", ",", "\n", "vocab", "=", "vocab", ",", "\n", "region_bbox_file", "=", "region_bbox_file", ",", "\n", "region_det_file_prefix", "=", "feature_path", ",", "\n", "transform", "=", "transform", ",", "ids", "=", "ids", ")", "\n", "", "elif", "'f8k'", "in", "data_name", "or", "'f30k'", "in", "data_name", ":", "\n", "        ", "dataset", "=", "FlickrDataset", "(", "root", "=", "root", ",", "\n", "split", "=", "split", ",", "\n", "json", "=", "json", ",", "\n", "vocab", "=", "vocab", ",", "\n", "region_bbox_file", "=", "region_bbox_file", ",", "\n", "feature_path", "=", "feature_path", ",", "\n", "transform", "=", "transform", ")", "\n", "\n", "# Data loader", "\n", "", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", "=", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "pin_memory", "=", "True", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "collate_fn", "=", "collate_fn", ")", "\n", "return", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_transform": [[282, 297], ["torchvision.Normalize", "torchvision.Compose", "torchvision.ToTensor", "torchvision.RandomResizedCrop", "torchvision.RandomHorizontalFlip", "torchvision.Resize", "torchvision.CenterCrop", "torchvision.Resize", "torchvision.CenterCrop"], "function", ["None"], ["", "def", "get_transform", "(", "data_name", ",", "split_name", ",", "opt", ")", ":", "\n", "    ", "normalizer", "=", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "t_list", "=", "[", "]", "\n", "if", "split_name", "==", "'train'", ":", "\n", "        ", "t_list", "=", "[", "transforms", ".", "RandomResizedCrop", "(", "opt", ".", "crop_size", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", "]", "\n", "", "elif", "split_name", "==", "'val'", ":", "\n", "        ", "t_list", "=", "[", "transforms", ".", "Resize", "(", "256", ")", ",", "transforms", ".", "CenterCrop", "(", "224", ")", "]", "\n", "", "elif", "split_name", "==", "'test'", ":", "\n", "        ", "t_list", "=", "[", "transforms", ".", "Resize", "(", "256", ")", ",", "transforms", ".", "CenterCrop", "(", "224", ")", "]", "\n", "\n", "", "t_end", "=", "[", "transforms", ".", "ToTensor", "(", ")", ",", "normalizer", "]", "\n", "transform", "=", "transforms", ".", "Compose", "(", "t_list", "+", "t_end", ")", "\n", "return", "transform", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_loaders": [[299, 325], ["os.path.join", "data.get_paths", "data.get_transform", "data.get_loader_single", "data.get_transform", "data.get_loader_single"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_paths", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_transform", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_loader_single", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_transform", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_loader_single"], ["", "def", "get_loaders", "(", "data_name", ",", "vocab", ",", "crop_size", ",", "batch_size", ",", "workers", ",", "opt", ")", ":", "\n", "    ", "dpath", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "data_path", ",", "data_name", ")", "\n", "\n", "roots", ",", "ids", "=", "get_paths", "(", "dpath", ",", "data_name", ",", "opt", ".", "use_restval", ")", "\n", "\n", "transform", "=", "get_transform", "(", "data_name", ",", "'train'", ",", "opt", ")", "\n", "train_loader", "=", "get_loader_single", "(", "opt", ".", "data_name", ",", "'train'", ",", "\n", "roots", "[", "'train'", "]", "[", "'img'", "]", ",", "\n", "roots", "[", "'train'", "]", "[", "'cap'", "]", ",", "\n", "vocab", ",", "transform", ",", "ids", "=", "ids", "[", "'train'", "]", ",", "\n", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "workers", ",", "\n", "collate_fn", "=", "collate_fn", ",", "region_bbox_file", "=", "opt", ".", "region_bbox_file", ",", "\n", "feature_path", "=", "opt", ".", "feature_path", ")", "\n", "\n", "transform", "=", "get_transform", "(", "data_name", ",", "'val'", ",", "opt", ")", "\n", "val_loader", "=", "get_loader_single", "(", "opt", ".", "data_name", ",", "'val'", ",", "\n", "roots", "[", "'val'", "]", "[", "'img'", "]", ",", "\n", "roots", "[", "'val'", "]", "[", "'cap'", "]", ",", "\n", "vocab", ",", "transform", ",", "ids", "=", "ids", "[", "'val'", "]", ",", "\n", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "workers", ",", "\n", "collate_fn", "=", "collate_fn", ",", "region_bbox_file", "=", "opt", ".", "region_bbox_file", ",", "\n", "feature_path", "=", "opt", ".", "feature_path", ")", "\n", "\n", "return", "train_loader", ",", "val_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_test_loader": [[327, 344], ["os.path.join", "data.get_paths", "data.get_transform", "data.get_loader_single"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_paths", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_transform", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_loader_single"], ["", "def", "get_test_loader", "(", "split_name", ",", "data_name", ",", "vocab", ",", "crop_size", ",", "batch_size", ",", "\n", "workers", ",", "opt", ")", ":", "\n", "    ", "dpath", "=", "os", ".", "path", ".", "join", "(", "opt", ".", "data_path", ",", "data_name", ")", "\n", "\n", "roots", ",", "ids", "=", "get_paths", "(", "dpath", ",", "data_name", ",", "opt", ".", "use_restval", ")", "\n", "\n", "transform", "=", "get_transform", "(", "data_name", ",", "split_name", ",", "opt", ")", "\n", "test_loader", "=", "get_loader_single", "(", "opt", ".", "data_name", ",", "split_name", ",", "\n", "roots", "[", "split_name", "]", "[", "'img'", "]", ",", "\n", "roots", "[", "split_name", "]", "[", "'cap'", "]", ",", "\n", "vocab", ",", "transform", ",", "ids", "=", "ids", "[", "split_name", "]", ",", "\n", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "workers", ",", "\n", "collate_fn", "=", "collate_fn", ",", "region_bbox_file", "=", "opt", ".", "region_bbox_file", ",", "\n", "feature_path", "=", "opt", ".", "feature_path", ")", "\n", "\n", "return", "test_loader", "\n", "", ""]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.BasicBlock.__init__": [[23, 40], ["torch.Module.__init__", "resnet.conv3x3", "norm_layer", "torch.ReLU", "torch.ReLU", "resnet.conv3x3", "norm_layer", "ValueError", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.conv3x3", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "groups", "=", "1", ",", "\n", "base_width", "=", "64", ",", "dilation", "=", "1", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "if", "groups", "!=", "1", "or", "base_width", "!=", "64", ":", "\n", "            ", "raise", "ValueError", "(", "'BasicBlock only supports groups=1 and base_width=64'", ")", "\n", "", "if", "dilation", ">", "1", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Dilation > 1 not supported in BasicBlock\"", ")", "\n", "# Both self.conv1 and self.downsample layers downsample the input when stride != 1", "\n", "", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.BasicBlock.forward": [[41, 58], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.bn1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.bn2", "resnet.BasicBlock.relu", "resnet.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.Bottleneck.__init__": [[63, 79], ["torch.Module.__init__", "resnet.conv1x1", "norm_layer", "resnet.conv3x3", "norm_layer", "resnet.conv1x1", "norm_layer", "torch.ReLU", "torch.ReLU", "int"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.conv1x1", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.conv3x3", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.conv1x1"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ",", "groups", "=", "1", ",", "\n", "base_width", "=", "64", ",", "dilation", "=", "1", ",", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "width", "=", "int", "(", "planes", "*", "(", "base_width", "/", "64.", ")", ")", "*", "groups", "\n", "# Both self.conv2 and self.downsample layers downsample the input when stride != 1", "\n", "self", ".", "conv1", "=", "conv1x1", "(", "inplanes", ",", "width", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "width", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "width", ",", "width", ",", "stride", ",", "groups", ",", "dilation", ")", "\n", "self", ".", "bn2", "=", "norm_layer", "(", "width", ")", "\n", "self", ".", "conv3", "=", "conv1x1", "(", "width", ",", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "bn3", "=", "norm_layer", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.Bottleneck.forward": [[80, 101], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "resnet.Bottleneck.relu", "resnet.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "identity", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "identity", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "identity", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.ResNet.__init__": [[105, 155], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "norm_layer", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Linear", "torch.Linear", "resnet.ResNet.modules", "len", "ValueError", "isinstance", "resnet.ResNet.modules", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "isinstance", "isinstance", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "isinstance", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "num_classes", "=", "1000", ",", "zero_init_residual", "=", "False", ",", "\n", "groups", "=", "1", ",", "width_per_group", "=", "64", ",", "replace_stride_with_dilation", "=", "None", ",", "\n", "norm_layer", "=", "None", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "norm_layer", "is", "None", ":", "\n", "            ", "norm_layer", "=", "nn", ".", "BatchNorm2d", "\n", "", "self", ".", "_norm_layer", "=", "norm_layer", "\n", "\n", "self", ".", "inplanes", "=", "64", "\n", "self", ".", "dilation", "=", "1", "\n", "if", "replace_stride_with_dilation", "is", "None", ":", "\n", "# each element in the tuple indicates if we should replace", "\n", "# the 2x2 stride with a dilated convolution instead", "\n", "            ", "replace_stride_with_dilation", "=", "[", "False", ",", "False", ",", "False", "]", "\n", "", "if", "len", "(", "replace_stride_with_dilation", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "\"replace_stride_with_dilation should be None \"", "\n", "\"or a 3-element tuple, got {}\"", ".", "format", "(", "replace_stride_with_dilation", ")", ")", "\n", "", "self", ".", "groups", "=", "groups", "\n", "self", ".", "base_width", "=", "width_per_group", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "self", ".", "inplanes", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "norm_layer", "(", "self", ".", "inplanes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ",", "\n", "dilate", "=", "replace_stride_with_dilation", "[", "0", "]", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ",", "\n", "dilate", "=", "replace_stride_with_dilation", "[", "1", "]", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ",", "\n", "dilate", "=", "replace_stride_with_dilation", "[", "2", "]", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "(", "nn", ".", "BatchNorm2d", ",", "nn", ".", "GroupNorm", ")", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n", "# Zero-initialize the last BN in each residual branch,", "\n", "# so that the residual branch starts with zeros, and each residual block behaves like an identity.", "\n", "# This improves the model by 0.2~0.3% according to https://arxiv.org/abs/1706.02677", "\n", "", "", "if", "zero_init_residual", ":", "\n", "            ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "                ", "if", "isinstance", "(", "m", ",", "Bottleneck", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn3", ".", "weight", ",", "0", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "BasicBlock", ")", ":", "\n", "                    ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bn2", ".", "weight", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.ResNet._make_layer": [[156, 179], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "resnet.conv1x1", "norm_layer", "block"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.conv1x1"], ["", "", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ",", "dilate", "=", "False", ")", ":", "\n", "        ", "norm_layer", "=", "self", ".", "_norm_layer", "\n", "downsample", "=", "None", "\n", "previous_dilation", "=", "self", ".", "dilation", "\n", "if", "dilate", ":", "\n", "            ", "self", ".", "dilation", "*=", "stride", "\n", "stride", "=", "1", "\n", "", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "conv1x1", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "stride", ")", ",", "\n", "norm_layer", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ",", "self", ".", "groups", ",", "\n", "self", ".", "base_width", ",", "previous_dilation", ",", "norm_layer", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "_", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "groups", "=", "self", ".", "groups", ",", "\n", "base_width", "=", "self", ".", "base_width", ",", "dilation", "=", "self", ".", "dilation", ",", "\n", "norm_layer", "=", "norm_layer", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.ResNet.forward": [[180, 193], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "resnet.ResNet.maxpool", "resnet.ResNet.layer1", "resnet.ResNet.layer2", "resnet.ResNet.layer3", "resnet.ResNet.layer4"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x1", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x2", "=", "self", ".", "layer2", "(", "x1", ")", "\n", "x3", "=", "self", ".", "layer3", "(", "x2", ")", "\n", "x4", "=", "self", ".", "layer4", "(", "x3", ")", "# extract the output before avg pooling", "\n", "# print(x4.size())", "\n", "\n", "return", "x1", ",", "x2", ",", "x3", ",", "x4", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.conv3x3": [[9, 13], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ",", "groups", "=", "1", ",", "dilation", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "dilation", ",", "groups", "=", "groups", ",", "bias", "=", "False", ",", "dilation", "=", "dilation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.conv1x1": [[15, 18], ["torch.Conv2d"], "function", ["None"], ["", "def", "conv1x1", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"1x1 convolution\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet._resnet": [[195, 201], ["resnet.ResNet", "torch.load", "torch.load", "ResNet.load_state_dict"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.load_state_dict"], ["", "", "def", "_resnet", "(", "arch", ",", "block", ",", "layers", ",", "pretrained", ",", "progress", ",", "**", "kwargs", ")", ":", "\n", "    ", "model", "=", "ResNet", "(", "block", ",", "layers", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "state_dict", "=", "torch", ".", "load", "(", "RES_NET_file_path", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.resnet152": [[203, 212], ["resnet._resnet"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet._resnet"], ["", "def", "resnet152", "(", "pretrained", "=", "False", ",", "progress", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "r\"\"\"ResNet-50 model from\n    `\"Deep Residual Learning for Image Recognition\" <https://arxiv.org/pdf/1512.03385.pdf>'_\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n        progress (bool): If True, displays a progress bar of the download to stderr\n    \"\"\"", "\n", "return", "_resnet", "(", "'resnet152'", ",", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "pretrained", ",", "progress", ",", "\n", "**", "kwargs", ")", "", "", ""]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.GAT.MultiHeadAttention.__init__": [[16, 28], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "MultiHeadAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.GAT.MultiHeadAttention.transpose_for_scores": [[29, 33], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.GAT.MultiHeadAttention.forward": [[34, 61], ["GAT.MultiHeadAttention.query", "GAT.MultiHeadAttention.key", "GAT.MultiHeadAttention.value", "GAT.MultiHeadAttention.transpose_for_scores", "GAT.MultiHeadAttention.transpose_for_scores", "GAT.MultiHeadAttention.transpose_for_scores", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "GAT.MultiHeadAttention.dropout", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "nodes_new.view.view.permute().contiguous", "nodes_new.view.view.view", "GAT.MultiHeadAttention.transpose", "math.sqrt", "torch.nn.Softmax", "torch.nn.Softmax", "nodes_new.view.view.permute", "nodes_new.view.view.size"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "self", ",", "input_graph", ")", ":", "\n", "        ", "nodes_q", "=", "self", ".", "query", "(", "input_graph", ")", "\n", "nodes_k", "=", "self", ".", "key", "(", "input_graph", ")", "\n", "nodes_v", "=", "self", ".", "value", "(", "input_graph", ")", "\n", "\n", "nodes_q_t", "=", "self", ".", "transpose_for_scores", "(", "nodes_q", ")", "\n", "nodes_k_t", "=", "self", ".", "transpose_for_scores", "(", "nodes_k", ")", "\n", "nodes_v_t", "=", "self", ".", "transpose_for_scores", "(", "nodes_v", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "nodes_q_t", ",", "nodes_k_t", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "# Apply the attention mask is (precomputed for all layers in GATModel forward() function)", "\n", "attention_scores", "=", "attention_scores", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "nodes_new", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "nodes_v_t", ")", "\n", "nodes_new", "=", "nodes_new", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_nodes_shape", "=", "nodes_new", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "nodes_new", "=", "nodes_new", ".", "view", "(", "*", "new_nodes_shape", ")", "\n", "return", "nodes_new", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.GAT.GATLayer.__init__": [[64, 77], ["torch.nn.Module.__init__", "GAT.MultiHeadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.BatchNorm1d", "torch.nn.BatchNorm1d", "torch.nn.Dropout", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "GATLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mha", "=", "MultiHeadAttention", "(", "config", ")", "\n", "\n", "self", ".", "fc_in", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "bn_in", "=", "nn", ".", "BatchNorm1d", "(", "config", ".", "hidden_size", ")", "\n", "self", ".", "dropout_in", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "fc_int", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "self", ".", "fc_out", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "bn_out", "=", "nn", ".", "BatchNorm1d", "(", "config", ".", "hidden_size", ")", "\n", "self", ".", "dropout_out", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.GAT.GATLayer.forward": [[78, 89], ["GAT.GATLayer.mha", "GAT.GATLayer.fc_in", "GAT.GATLayer.dropout_in", "GAT.GATLayer.bn_in().permute", "GAT.GATLayer.fc_int", "torch.relu", "torch.relu", "GAT.GATLayer.fc_out", "GAT.GATLayer.dropout_out", "GAT.GATLayer.bn_out().permute", "GAT.GATLayer.bn_in", "GAT.GATLayer.bn_out"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_graph", ")", ":", "\n", "        ", "attention_output", "=", "self", ".", "mha", "(", "input_graph", ")", "# multi-head attention", "\n", "attention_output", "=", "self", ".", "fc_in", "(", "attention_output", ")", "\n", "attention_output", "=", "self", ".", "dropout_in", "(", "attention_output", ")", "\n", "attention_output", "=", "self", ".", "bn_in", "(", "(", "attention_output", "+", "input_graph", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "intermediate_output", "=", "self", ".", "fc_int", "(", "attention_output", ")", "\n", "intermediate_output", "=", "F", ".", "relu", "(", "intermediate_output", ")", "\n", "intermediate_output", "=", "self", ".", "fc_out", "(", "intermediate_output", ")", "\n", "intermediate_output", "=", "self", ".", "dropout_out", "(", "intermediate_output", ")", "\n", "graph_output", "=", "self", ".", "bn_out", "(", "(", "intermediate_output", "+", "attention_output", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ")", "\n", "return", "graph_output", "", "", "", ""]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.GATopt.__init__": [[38, 44], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "num_layers", ")", ":", "\n", "        ", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "num_attention_heads", "=", "8", "\n", "self", ".", "hidden_dropout_prob", "=", "0.2", "\n", "self", ".", "attention_probs_dropout_prob", "=", "0.2", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.GAT.__init__": [[47, 51], ["torch.Module.__init__", "GAT.GATLayer", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config_gat", ")", ":", "\n", "        ", "super", "(", "GAT", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layer", "=", "GATLayer", "(", "config_gat", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "layer", ")", "for", "_", "in", "range", "(", "config_gat", ".", "num_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.GAT.forward": [[52, 57], ["layer_module"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_graph", ")", ":", "\n", "        ", "hidden_states", "=", "input_graph", "\n", "for", "layer_module", "in", "self", ".", "encoder", ":", "\n", "            ", "hidden_states", "=", "layer_module", "(", "hidden_states", ")", "\n", "", "return", "hidden_states", "# B, seq_len, D", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.RcnnEncoder.__init__": [[60, 65], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "model.RcnnEncoder.init_weights"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.EncoderText.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "RcnnEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_size", "=", "opt", ".", "embed_size", "\n", "self", ".", "fc_image", "=", "nn", ".", "Linear", "(", "opt", ".", "img_dim", ",", "self", ".", "embed_size", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.RcnnEncoder.init_weights": [[66, 73], ["model.RcnnEncoder.fc_image.weight.data.uniform_", "model.RcnnEncoder.fc_image.bias.data.fill_", "numpy.sqrt", "numpy.sqrt"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Xavier initialization for the fully connected layer\n        \"\"\"", "\n", "r", "=", "np", ".", "sqrt", "(", "6.", ")", "/", "np", ".", "sqrt", "(", "self", ".", "fc_image", ".", "in_features", "+", "\n", "self", ".", "fc_image", ".", "out_features", ")", "\n", "self", ".", "fc_image", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "r", ",", "r", ")", "\n", "self", ".", "fc_image", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.RcnnEncoder.forward": [[74, 77], ["model.RcnnEncoder.fc_image"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "images", ",", "img_pos", ")", ":", "# (b, 100, 2048) (b,100,1601+6)", "\n", "        ", "img_f", "=", "self", ".", "fc_image", "(", "images", ")", "\n", "return", "img_f", "# (b,100,768)", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.EncoderImageFull.__init__": [[82, 100], ["torch.Module.__init__", "resnet.resnet152", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "model.EncoderImageFull.init_weights", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "print", "model.EncoderImageFull.cnn.parameters", "print"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.resnet.resnet152", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.EncoderText.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "\"\"\"Load pretrained VGG19 and replace top fc layer.\"\"\"", "\n", "super", "(", "EncoderImageFull", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_size", "=", "opt", ".", "embed_size", "\n", "\n", "self", ".", "cnn", "=", "resnet152", "(", "pretrained", "=", "True", ")", "\n", "# self.fc = nn.Sequential(nn.Linear(2048, self.embed_size), nn.ReLU(), nn.Dropout(0.1))", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "opt", ".", "img_dim", ",", "self", ".", "embed_size", ")", "\n", "if", "not", "opt", ".", "finetune", ":", "\n", "            ", "print", "(", "'image-encoder-resnet no grad!'", ")", "\n", "for", "param", "in", "self", ".", "cnn", ".", "parameters", "(", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "'image-encoder-resnet fine-tuning !'", ")", "\n", "\n", "", "self", ".", "init_weights", "(", ")", "\n", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.EncoderImageFull.load_state_dict": [[101, 120], ["super().load_state_dict"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"\n        Handle the models saved before commit pytorch/vision@989d52a\n        \"\"\"", "\n", "if", "'cnn.classifier.1.weight'", "in", "state_dict", ":", "\n", "            ", "state_dict", "[", "'cnn.classifier.0.weight'", "]", "=", "state_dict", "[", "\n", "'cnn.classifier.1.weight'", "]", "\n", "del", "state_dict", "[", "'cnn.classifier.1.weight'", "]", "\n", "state_dict", "[", "'cnn.classifier.0.bias'", "]", "=", "state_dict", "[", "\n", "'cnn.classifier.1.bias'", "]", "\n", "del", "state_dict", "[", "'cnn.classifier.1.bias'", "]", "\n", "state_dict", "[", "'cnn.classifier.3.weight'", "]", "=", "state_dict", "[", "\n", "'cnn.classifier.4.weight'", "]", "\n", "del", "state_dict", "[", "'cnn.classifier.4.weight'", "]", "\n", "state_dict", "[", "'cnn.classifier.3.bias'", "]", "=", "state_dict", "[", "\n", "'cnn.classifier.4.bias'", "]", "\n", "del", "state_dict", "[", "'cnn.classifier.4.bias'", "]", "\n", "\n", "", "super", "(", "EncoderImageFull", ",", "self", ")", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.EncoderImageFull.init_weights": [[121, 128], ["model.EncoderImageFull.fc.weight.data.uniform_", "model.EncoderImageFull.fc.bias.data.fill_", "numpy.sqrt", "numpy.sqrt"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"Xavier initialization for the fully connected layer\n        \"\"\"", "\n", "r", "=", "np", ".", "sqrt", "(", "6.", ")", "/", "np", ".", "sqrt", "(", "self", ".", "fc", ".", "in_features", "+", "\n", "self", ".", "fc", ".", "out_features", ")", "\n", "self", ".", "fc", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "r", ",", "r", ")", "\n", "self", ".", "fc", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.EncoderImageFull.forward": [[129, 136], ["model.EncoderImageFull.cnn", "features_top.view().transpose", "model.EncoderImageFull.fc", "features_top.view", "features_top.size", "features_top.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "images", ")", ":", "\n", "        ", "features_orig", "=", "self", ".", "cnn", "(", "images", ")", "\n", "features_top", "=", "features_orig", "[", "-", "1", "]", "\n", "features", "=", "features_top", ".", "view", "(", "features_top", ".", "size", "(", "0", ")", ",", "features_top", ".", "size", "(", "1", ")", ",", "-", "1", ")", ".", "transpose", "(", "2", ",", "1", ")", "# b, 49, 2048", "\n", "features", "=", "self", ".", "fc", "(", "features", ")", "\n", "\n", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.EncoderText.__init__": [[142, 154], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "pickle.load", "model.EncoderText.init_weights", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "open"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.EncoderText.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "EncoderText", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed_size", "=", "opt", ".", "embed_size", "\n", "# word embedding", "\n", "self", ".", "embed", "=", "nn", ".", "Embedding", "(", "opt", ".", "vocab_size", ",", "opt", ".", "word_dim", ")", "\n", "# caption embedding", "\n", "self", ".", "rnn", "=", "nn", ".", "GRU", "(", "opt", ".", "word_dim", ",", "opt", ".", "embed_size", ",", "opt", ".", "num_layers", ",", "batch_first", "=", "True", ")", "\n", "vocab", "=", "pickle", ".", "load", "(", "open", "(", "'vocab/'", "+", "opt", ".", "data_name", "+", "'_vocab.pkl'", ",", "'rb'", ")", ")", "\n", "word2idx", "=", "vocab", ".", "word2idx", "\n", "# self.init_weights()", "\n", "self", ".", "init_weights", "(", "'glove'", ",", "word2idx", ",", "opt", ".", "word_dim", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.EncoderText.init_weights": [[155, 181], ["wemb_type.lower", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "word2idx.items", "print", "wemb_type.lower", "torchtext.vocab.FastText", "wemb_type.lower", "torchtext.vocab.GloVe", "Exception", "word.replace().replace().replace.replace().replace().replace.replace().replace().replace", "missing_words.append", "len", "len", "len", "len", "word.replace().replace().replace.replace().replace().replace.replace().replace", "word.replace().replace().replace.replace().replace().replace.split", "word.replace().replace().replace.replace().replace().replace.replace"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ",", "wemb_type", ",", "word2idx", ",", "word_dim", ")", ":", "\n", "        ", "if", "wemb_type", ".", "lower", "(", ")", "==", "'random_init'", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "embed", ".", "weight", ")", "\n", "", "else", ":", "\n", "# Load pretrained word embedding", "\n", "            ", "if", "'fasttext'", "==", "wemb_type", ".", "lower", "(", ")", ":", "\n", "                ", "wemb", "=", "torchtext", ".", "vocab", ".", "FastText", "(", ")", "\n", "", "elif", "'glove'", "==", "wemb_type", ".", "lower", "(", ")", ":", "\n", "                ", "wemb", "=", "torchtext", ".", "vocab", ".", "GloVe", "(", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "'Unknown word embedding type: {}'", ".", "format", "(", "wemb_type", ")", ")", "\n", "", "assert", "wemb", ".", "vectors", ".", "shape", "[", "1", "]", "==", "word_dim", "\n", "\n", "# quick-and-dirty trick to improve word-hit rate", "\n", "missing_words", "=", "[", "]", "\n", "for", "word", ",", "idx", "in", "word2idx", ".", "items", "(", ")", ":", "\n", "                ", "if", "word", "not", "in", "wemb", ".", "stoi", ":", "\n", "                    ", "word", "=", "word", ".", "replace", "(", "'-'", ",", "''", ")", ".", "replace", "(", "'.'", ",", "''", ")", ".", "replace", "(", "\"'\"", ",", "''", ")", "\n", "if", "'/'", "in", "word", ":", "\n", "                        ", "word", "=", "word", ".", "split", "(", "'/'", ")", "[", "0", "]", "\n", "", "", "if", "word", "in", "wemb", ".", "stoi", ":", "\n", "                    ", "self", ".", "embed", ".", "weight", ".", "data", "[", "idx", "]", "=", "wemb", ".", "vectors", "[", "wemb", ".", "stoi", "[", "word", "]", "]", "\n", "", "else", ":", "\n", "                    ", "missing_words", ".", "append", "(", "word", ")", "\n", "", "", "print", "(", "'Words: {}/{} found in vocabulary; {} words missing'", ".", "format", "(", "\n", "len", "(", "word2idx", ")", "-", "len", "(", "missing_words", ")", ",", "len", "(", "word2idx", ")", ",", "len", "(", "missing_words", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.EncoderText.forward": [[182, 201], ["model.EncoderText.embed", "model.EncoderText.dropout", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "model.EncoderText.rnn", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "model.l2norm", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model.l2norm"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.l2norm", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.l2norm"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "lengths", ")", ":", "\n", "# return out", "\n", "        ", "x", "=", "self", ".", "embed", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "\n", "packed", "=", "pack_padded_sequence", "(", "x", ",", "lengths", ",", "batch_first", "=", "True", ")", "\n", "\n", "# Forward propagate RNN", "\n", "out", ",", "_", "=", "self", ".", "rnn", "(", "packed", ")", "\n", "\n", "# Reshape *final* output to (batch_size, hidden_size)", "\n", "padded", "=", "pad_packed_sequence", "(", "out", ",", "batch_first", "=", "True", ")", "\n", "cap_emb", ",", "cap_len", "=", "padded", "\n", "\n", "cap_emb", "=", "l2norm", "(", "cap_emb", ",", "dim", "=", "-", "1", ")", "\n", "cap_emb_mean", "=", "torch", ".", "mean", "(", "cap_emb", ",", "1", ")", "\n", "cap_emb_mean", "=", "l2norm", "(", "cap_emb_mean", ")", "\n", "\n", "return", "cap_emb", ",", "cap_emb_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.Fusion.__init__": [[204, 212], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "Fusion", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "f_size", "=", "opt", ".", "embed_size", "\n", "self", ".", "gate0", "=", "nn", ".", "Linear", "(", "self", ".", "f_size", ",", "self", ".", "f_size", ")", "\n", "self", ".", "gate1", "=", "nn", ".", "Linear", "(", "self", ".", "f_size", ",", "self", ".", "f_size", ")", "\n", "\n", "self", ".", "fusion0", "=", "nn", ".", "Linear", "(", "self", ".", "f_size", ",", "self", ".", "f_size", ")", "\n", "self", ".", "fusion1", "=", "nn", ".", "Linear", "(", "self", ".", "f_size", ",", "self", ".", "f_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.Fusion.forward": [[213, 219], ["model.Fusion.gate0", "model.Fusion.gate1", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "model.Fusion.fusion0", "model.Fusion.fusion1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "vec1", ",", "vec2", ")", ":", "\n", "        ", "features_1", "=", "self", ".", "gate0", "(", "vec1", ")", "\n", "features_2", "=", "self", ".", "gate1", "(", "vec2", ")", "\n", "t", "=", "torch", ".", "sigmoid", "(", "self", ".", "fusion0", "(", "features_1", ")", "+", "self", ".", "fusion1", "(", "features_2", ")", ")", "\n", "f", "=", "t", "*", "features_1", "+", "(", "1", "-", "t", ")", "*", "features_2", "\n", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.DSRAN.__init__": [[223, 249], ["torch.Module.__init__", "model.EncoderImageFull", "model.RcnnEncoder", "model.EncoderText", "model.GATopt", "model.GATopt", "model.GATopt", "model.GATopt", "model.GAT", "model.GAT", "model.GAT", "model.GAT", "model.GAT", "model.Fusion", "model.GAT", "model.GAT", "model.GAT", "model.Fusion", "model.Fusion", "model.Fusion"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "super", "(", "DSRAN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "K", "=", "opt", ".", "K", "\n", "self", ".", "img_enc", "=", "EncoderImageFull", "(", "opt", ")", "\n", "self", ".", "rcnn_enc", "=", "RcnnEncoder", "(", "opt", ")", "\n", "self", ".", "txt_enc", "=", "EncoderText", "(", "opt", ")", "\n", "config_rcnn", "=", "GATopt", "(", "opt", ".", "embed_size", ",", "1", ")", "\n", "config_img", "=", "GATopt", "(", "opt", ".", "embed_size", ",", "1", ")", "\n", "config_cap", "=", "GATopt", "(", "opt", ".", "embed_size", ",", "1", ")", "\n", "config_joint", "=", "GATopt", "(", "opt", ".", "embed_size", ",", "1", ")", "\n", "# SSR", "\n", "self", ".", "gat_1", "=", "GAT", "(", "config_rcnn", ")", "\n", "self", ".", "gat_2", "=", "GAT", "(", "config_img", ")", "\n", "self", ".", "gat_cap", "=", "GAT", "(", "config_cap", ")", "\n", "# JSR", "\n", "self", ".", "gat_cat_1", "=", "GAT", "(", "config_joint", ")", "\n", "if", "self", ".", "K", "==", "2", ":", "\n", "            ", "self", ".", "gat_cat_2", "=", "GAT", "(", "config_joint", ")", "\n", "self", ".", "fusion", "=", "Fusion", "(", "opt", ")", "\n", "", "elif", "self", ".", "K", "==", "4", ":", "\n", "            ", "self", ".", "gat_cat_2", "=", "GAT", "(", "config_joint", ")", "\n", "self", ".", "gat_cat_3", "=", "GAT", "(", "config_joint", ")", "\n", "self", ".", "gat_cat_4", "=", "GAT", "(", "config_joint", ")", "\n", "self", ".", "fusion", "=", "Fusion", "(", "opt", ")", "\n", "self", ".", "fusion2", "=", "Fusion", "(", "opt", ")", "\n", "self", ".", "fusion3", "=", "Fusion", "(", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.DSRAN.forward": [[250, 279], ["model.DSRAN.gat_2", "model.DSRAN.rcnn_enc", "model.DSRAN.gat_1", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.DSRAN.gat_cat_1", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model.l2norm", "model.DSRAN.txt_enc", "model.DSRAN.gat_cap", "model.l2norm", "model.DSRAN.img_enc", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model.DSRAN.gat_cat_2", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model.DSRAN.fusion", "model.DSRAN.gat_cat_2", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model.DSRAN.gat_cat_3", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model.DSRAN.gat_cat_4", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model.DSRAN.fusion", "model.DSRAN.fusion2", "model.DSRAN.fusion3"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.l2norm", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.l2norm"], ["", "", "def", "forward", "(", "self", ",", "images", ",", "img_rcnn", ",", "img_pos", ",", "captions", ",", "lengths", ")", ":", "\n", "        ", "img_emb_orig", "=", "self", ".", "gat_2", "(", "self", ".", "img_enc", "(", "images", ")", ")", "\n", "rcnn_emb", "=", "self", ".", "rcnn_enc", "(", "img_rcnn", ",", "img_pos", ")", "\n", "rcnn_emb", "=", "self", ".", "gat_1", "(", "rcnn_emb", ")", "\n", "img_cat", "=", "torch", ".", "cat", "(", "(", "img_emb_orig", ",", "rcnn_emb", ")", ",", "1", ")", "\n", "img_cat_1", "=", "self", ".", "gat_cat_1", "(", "img_cat", ")", "\n", "img_cat_1", "=", "torch", ".", "mean", "(", "img_cat_1", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "K", "==", "1", ":", "\n", "            ", "img_cat", "=", "img_cat_1", "\n", "", "elif", "self", ".", "K", "==", "2", ":", "\n", "            ", "img_cat_2", "=", "self", ".", "gat_cat_2", "(", "img_cat", ")", "\n", "img_cat_2", "=", "torch", ".", "mean", "(", "img_cat_2", ",", "dim", "=", "1", ")", "\n", "img_cat", "=", "self", ".", "fusion", "(", "img_cat_1", ",", "img_cat_2", ")", "\n", "", "elif", "self", ".", "K", "==", "4", ":", "\n", "            ", "img_cat_2", "=", "self", ".", "gat_cat_2", "(", "img_cat", ")", "\n", "img_cat_2", "=", "torch", ".", "mean", "(", "img_cat_2", ",", "dim", "=", "1", ")", "\n", "img_cat_3", "=", "self", ".", "gat_cat_3", "(", "img_cat", ")", "\n", "img_cat_3", "=", "torch", ".", "mean", "(", "img_cat_3", ",", "dim", "=", "1", ")", "\n", "img_cat_4", "=", "self", ".", "gat_cat_4", "(", "img_cat", ")", "\n", "img_cat_4", "=", "torch", ".", "mean", "(", "img_cat_4", ",", "dim", "=", "1", ")", "\n", "img_cat_1_1", "=", "self", ".", "fusion", "(", "img_cat_1", ",", "img_cat_2", ")", "\n", "img_cat_1_2", "=", "self", ".", "fusion2", "(", "img_cat_3", ",", "img_cat_4", ")", "\n", "img_cat", "=", "self", ".", "fusion3", "(", "img_cat_1_1", ",", "img_cat_1_2", ")", "\n", "", "img_emb", "=", "l2norm", "(", "img_cat", ")", "\n", "cap_emb", ",", "cap_emb_mean", "=", "self", ".", "txt_enc", "(", "captions", ",", "lengths", ")", "\n", "cap_gat", "=", "self", ".", "gat_cap", "(", "cap_emb", ")", "\n", "cap_embs", "=", "l2norm", "(", "torch", ".", "mean", "(", "cap_gat", ",", "dim", "=", "1", ")", ")", "\n", "\n", "return", "img_emb", ",", "cap_embs", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.ContrastiveLoss.__init__": [[291, 295], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "margin", "=", "0", ")", ":", "\n", "        ", "super", "(", "ContrastiveLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "margin", "=", "margin", "\n", "self", ".", "sim", "=", "cosine_sim", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.ContrastiveLoss.forward": [[296, 325], ["model.ContrastiveLoss.sim", "model.ContrastiveLoss.diag().view", "model.ContrastiveLoss.diag().view.expand_as", "model.ContrastiveLoss.diag().view.t().expand_as", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "cost_s.masked_fill_.masked_fill_.masked_fill_", "cost_im.masked_fill_.masked_fill_.masked_fill_", "im.size", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "torch.eye", "I.cuda.cuda.cuda", "cost_s.masked_fill_.masked_fill_.max", "cost_im.masked_fill_.masked_fill_.max", "cost_s.masked_fill_.masked_fill_.sum", "cost_im.masked_fill_.masked_fill_.sum", "model.ContrastiveLoss.diag", "model.ContrastiveLoss.diag().view.t", "model.ContrastiveLoss.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "im", ",", "s", ")", ":", "\n", "# compute image-sentence score matrix", "\n", "        ", "scores", "=", "self", ".", "sim", "(", "im", ",", "s", ")", "\n", "diagonal", "=", "scores", ".", "diag", "(", ")", ".", "view", "(", "im", ".", "size", "(", "0", ")", ",", "1", ")", "\n", "\n", "d1", "=", "diagonal", ".", "expand_as", "(", "scores", ")", "\n", "d2", "=", "diagonal", ".", "t", "(", ")", ".", "expand_as", "(", "scores", ")", "\n", "im_sn", "=", "scores", "-", "d1", "\n", "c_sn", "=", "scores", "-", "d2", "\n", "# compare every diagonal score to scores in its column", "\n", "# caption retrieval", "\n", "cost_s", "=", "(", "self", ".", "margin", "+", "scores", "-", "d1", ")", ".", "clamp", "(", "min", "=", "0", ")", "\n", "# compare every diagonal score to scores in its row", "\n", "# image retrieval", "\n", "cost_im", "=", "(", "self", ".", "margin", "+", "scores", "-", "d2", ")", ".", "clamp", "(", "min", "=", "0", ")", "\n", "# clear diagonals", "\n", "mask", "=", "torch", ".", "eye", "(", "scores", ".", "size", "(", "0", ")", ")", ">", ".5", "\n", "I", "=", "Variable", "(", "mask", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "I", "=", "I", ".", "cuda", "(", ")", "\n", "", "cost_s", "=", "cost_s", ".", "masked_fill_", "(", "I", ",", "0", ")", "\n", "cost_im", "=", "cost_im", ".", "masked_fill_", "(", "I", ",", "0", ")", "\n", "\n", "# keep the maximum violating negative for each query", "\n", "\n", "cost_s", "=", "cost_s", ".", "max", "(", "1", ")", "[", "0", "]", "\n", "cost_im", "=", "cost_im", ".", "max", "(", "0", ")", "[", "0", "]", "\n", "\n", "return", "cost_s", ".", "sum", "(", ")", "+", "cost_im", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.__init__": [[331, 349], ["model.DSRAN", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model.ContrastiveLoss", "list", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "model.VSE.DSRAN.cuda", "model.VSE.DSRAN.parameters"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "# tutorials/09 - Image Captioning", "\n", "# Build Models", "\n", "        ", "self", ".", "grad_clip", "=", "opt", ".", "grad_clip", "\n", "\n", "self", ".", "DSRAN", "=", "DSRAN", "(", "opt", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "self", ".", "DSRAN", ".", "cuda", "(", ")", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "# Loss and Optimizer", "\n", "", "self", ".", "criterion", "=", "ContrastiveLoss", "(", "margin", "=", "opt", ".", "margin", ")", "\n", "params", "=", "list", "(", "self", ".", "DSRAN", ".", "parameters", "(", ")", ")", "\n", "\n", "self", ".", "params", "=", "params", "\n", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "params", ",", "lr", "=", "opt", ".", "learning_rate", ")", "\n", "\n", "self", ".", "Eiters", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.state_dict": [[350, 353], ["model.VSE.DSRAN.state_dict"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "state_dict", "=", "[", "self", ".", "DSRAN", ".", "state_dict", "(", ")", "]", "\n", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.load_state_dict": [[354, 356], ["model.VSE.DSRAN.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "DSRAN", ".", "load_state_dict", "(", "state_dict", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.train_start": [[357, 361], ["model.VSE.DSRAN.train"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.train.train"], ["", "def", "train_start", "(", "self", ")", ":", "\n", "        ", "\"\"\"switch to train mode\n        \"\"\"", "\n", "self", ".", "DSRAN", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.val_start": [[362, 366], ["model.VSE.DSRAN.eval"], "methods", ["None"], ["", "def", "val_start", "(", "self", ")", ":", "\n", "        ", "\"\"\"switch to evaluate mode\n        \"\"\"", "\n", "self", ".", "DSRAN", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.forward_emb": [[367, 380], ["torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "model.VSE.DSRAN", "images.cuda.cuda.cuda", "captions.cuda.cuda.cuda", "img_rcnn.cuda.cuda.cuda", "img_pos.cuda.cuda.cuda"], "methods", ["None"], ["", "def", "forward_emb", "(", "self", ",", "images", ",", "captions", ",", "img_rcnn", ",", "img_pos", ",", "lengths", ",", "volatile", "=", "False", ")", ":", "\n", "        ", "\"\"\"Compute the image and caption embeddings\n        \"\"\"", "\n", "# Set mini-batch dataset", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "images", "=", "images", ".", "cuda", "(", ")", "\n", "captions", "=", "captions", ".", "cuda", "(", ")", "\n", "img_rcnn", "=", "img_rcnn", ".", "cuda", "(", ")", "\n", "img_pos", "=", "img_pos", ".", "cuda", "(", ")", "\n", "\n", "", "img_emb", ",", "cap_emb", "=", "self", ".", "DSRAN", "(", "images", ",", "img_rcnn", ",", "img_pos", ",", "captions", ",", "lengths", ")", "\n", "return", "img_emb", ",", "cap_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.forward_loss": [[381, 387], ["model.VSE.criterion", "model.VSE.logger.update", "img_emb.size"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update"], ["", "def", "forward_loss", "(", "self", ",", "img_emb", ",", "cap_emb", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Compute the loss given pairs of image and caption embeddings\n        \"\"\"", "\n", "loss", "=", "self", ".", "criterion", "(", "img_emb", ",", "cap_emb", ")", "\n", "self", ".", "logger", ".", "update", "(", "'Le'", ",", "loss", ".", "data", ",", "img_emb", ".", "size", "(", "0", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.train_emb": [[388, 406], ["model.VSE.logger.update", "model.VSE.logger.update", "model.VSE.forward_emb", "model.VSE.optimizer.zero_grad", "model.VSE.forward_loss", "model.VSE.backward", "model.VSE.optimizer.step", "torch.nn.utils.clip_grad.clip_grad_norm_", "torch.nn.utils.clip_grad.clip_grad_norm_", "torch.nn.utils.clip_grad.clip_grad_norm_", "torch.nn.utils.clip_grad.clip_grad_norm_"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.forward_emb", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.forward_loss", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.optimization.BertAdam.step"], ["", "def", "train_emb", "(", "self", ",", "images", ",", "captions", ",", "img_rcnn", ",", "img_pos", ",", "lengths", ",", "ids", "=", "None", ",", "*", "args", ")", ":", "\n", "        ", "\"\"\"One training step given images and captions.\n        \"\"\"", "\n", "self", ".", "Eiters", "+=", "1", "\n", "self", ".", "logger", ".", "update", "(", "'Eit'", ",", "self", ".", "Eiters", ")", "\n", "self", ".", "logger", ".", "update", "(", "'lr'", ",", "self", ".", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", "\n", "\n", "# compute the embeddings", "\n", "img_emb", ",", "cap_emb", "=", "self", ".", "forward_emb", "(", "images", ",", "captions", ",", "img_rcnn", ",", "img_pos", ",", "lengths", ")", "\n", "# measure accuracy and record loss", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "self", ".", "forward_loss", "(", "img_emb", ",", "cap_emb", ")", "\n", "\n", "# compute gradient and do SGD step", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "grad_clip", ">", "0", ":", "\n", "            ", "clip_grad_norm_", "(", "self", ".", "params", ",", "self", ".", "grad_clip", ")", "\n", "", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.l2norm": [[29, 35], ["torch.div", "torch.div", "torch.div", "torch.div", "torch.pow().sum().sqrt", "torch.pow().sum().sqrt", "torch.pow().sum().sqrt", "torch.pow().sum().sqrt", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "function", ["None"], ["def", "l2norm", "(", "X", ",", "dim", "=", "-", "1", ",", "eps", "=", "1e-12", ")", ":", "\n", "    ", "\"\"\"L2-normalize columns of X\n    \"\"\"", "\n", "norm", "=", "torch", ".", "pow", "(", "X", ",", "2", ")", ".", "sum", "(", "dim", "=", "dim", ",", "keepdim", "=", "True", ")", ".", "sqrt", "(", ")", "+", "eps", "\n", "X", "=", "torch", ".", "div", "(", "X", ",", "norm", ")", "\n", "return", "X", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.cosine_sim": [[281, 285], ["im.mm", "s.t"], "function", ["None"], ["", "", "def", "cosine_sim", "(", "im", ",", "s", ")", ":", "\n", "    ", "\"\"\"Cosine similarity between all the image and sentence pairs\n    \"\"\"", "\n", "return", "im", ".", "mm", "(", "s", ".", "t", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation_bert.AverageMeter.__init__": [[24, 26], ["evaluation_bert.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.AverageMeter.reset"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation_bert.AverageMeter.reset": [[27, 32], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation_bert.AverageMeter.update": [[33, 38], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "0", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "(", ".0001", "+", "self", ".", "count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation_bert.AverageMeter.__str__": [[39, 43], ["str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "count", "==", "0", ":", "\n", "            ", "return", "str", "(", "self", ".", "val", ")", "\n", "", "return", "'%.4f (%.4f)'", "%", "(", "self", ".", "val", ",", "self", ".", "avg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation_bert.LogCollector.__init__": [[46, 48], ["collections.OrderedDict"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "meters", "=", "OrderedDict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation_bert.LogCollector.update": [[49, 53], ["evaluation_bert.LogCollector.meters[].update", "evaluation_bert.AverageMeter"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update"], ["", "def", "update", "(", "self", ",", "k", ",", "v", ",", "n", "=", "0", ")", ":", "\n", "        ", "if", "k", "not", "in", "self", ".", "meters", ":", "\n", "            ", "self", ".", "meters", "[", "k", "]", "=", "AverageMeter", "(", ")", "\n", "", "self", ".", "meters", "[", "k", "]", ".", "update", "(", "v", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation_bert.LogCollector.__str__": [[54, 61], ["enumerate", "evaluation_bert.LogCollector.meters.items", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "s", "=", "''", "\n", "for", "i", ",", "(", "k", ",", "v", ")", "in", "enumerate", "(", "self", ".", "meters", ".", "items", "(", ")", ")", ":", "\n", "            ", "if", "i", ">", "0", ":", "\n", "                ", "s", "+=", "'  '", "\n", "", "s", "+=", "k", "+", "' '", "+", "str", "(", "v", ")", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation_bert.LogCollector.tb_log": [[62, 65], ["evaluation_bert.LogCollector.meters.items", "tb_logger.log_value"], "methods", ["None"], ["", "def", "tb_log", "(", "self", ",", "tb_logger", ",", "prefix", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "self", ".", "meters", ".", "items", "(", ")", ":", "\n", "            ", "tb_logger", ".", "log_value", "(", "prefix", "+", "k", ",", "v", ".", "val", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation_bert.encode_data": [[67, 111], ["evaluation_bert.AverageMeter", "evaluation_bert.LogCollector", "model.val_start", "time.time", "time.time", "time.time", "print", "torch.mm", "sims.cpu().numpy.cpu().numpy", "torch.no_grad", "enumerate", "torch.zeros().cuda.t", "model.forward_emb", "model.forward_loss", "evaluation_bert.AverageMeter.update", "time.time", "torch.zeros().cuda.size", "sims.cpu().numpy.cpu", "torch.zeros().cuda", "torch.zeros().cuda", "logging", "time.time", "torch.zeros", "torch.zeros", "len", "len", "img_emb.size", "len", "cap_emb.size", "str"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.val_start", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.forward_emb", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.forward_loss", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update"], ["", "", "", "def", "encode_data", "(", "model", ",", "data_loader", ",", "log_step", "=", "10", ",", "logging", "=", "print", ")", ":", "\n", "    ", "batch_time", "=", "AverageMeter", "(", ")", "\n", "val_logger", "=", "LogCollector", "(", ")", "\n", "model", ".", "val_start", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "img_embs", "=", "None", "\n", "cap_embs", "=", "None", "\n", "time_encode_start", "=", "time", ".", "time", "(", ")", "\n", "# device = torch.device(\"cuda:0\")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "(", "images", ",", "images_orig", ",", "img_pos", ",", "captions", ",", "ids", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "            ", "model", ".", "logger", "=", "val_logger", "\n", "\n", "img_emb", ",", "cap_emb", "=", "model", ".", "forward_emb", "(", "images_orig", ",", "images", ",", "img_pos", ",", "captions", ")", "\n", "\n", "if", "img_embs", "is", "None", ":", "\n", "                ", "img_embs", "=", "torch", ".", "zeros", "(", "len", "(", "data_loader", ".", "dataset", ")", ",", "img_emb", ".", "size", "(", "1", ")", ")", ".", "cuda", "(", ")", "\n", "cap_embs", "=", "torch", ".", "zeros", "(", "len", "(", "data_loader", ".", "dataset", ")", ",", "cap_emb", ".", "size", "(", "1", ")", ")", ".", "cuda", "(", ")", "\n", "\n", "", "img_embs", "[", "ids", "]", "=", "img_emb", "\n", "cap_embs", "[", "ids", "]", "=", "cap_emb", "\n", "\n", "model", ".", "forward_loss", "(", "img_emb", ",", "cap_emb", ")", "\n", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "i", "%", "log_step", "==", "0", ":", "\n", "                ", "logging", "(", "'Test: [{0}/{1}]\\t'", "\n", "'{e_log}\\t'", "\n", "'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'", "\n", ".", "format", "(", "\n", "i", ",", "len", "(", "data_loader", ")", ",", "batch_time", "=", "batch_time", ",", "\n", "e_log", "=", "str", "(", "model", ".", "logger", ")", ")", ")", "\n", "", "del", "images", ",", "captions", "\n", "", "", "time_encode_end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'encode_time:%f'", "%", "(", "time_encode_end", "-", "time_encode_start", ")", ")", "\n", "img_emb_new", "=", "img_embs", "[", "0", ":", "img_embs", ".", "size", "(", "0", ")", ":", "5", "]", "\n", "sims", "=", "torch", ".", "mm", "(", "img_emb_new", ",", "cap_embs", ".", "t", "(", ")", ")", "\n", "sims", "=", "sims", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "return", "img_embs", ",", "cap_embs", ",", "sims", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation_bert.evalrank": [[113, 203], ["torch.load", "print", "model_bert.VSE", "model_bert.VSE.load_state_dict", "print", "data_bert.get_test_loader", "print", "evaluation_bert.encode_data", "time.time", "print", "torch.mm", "torch.mm", "sims_T.cpu().numpy.cpu().numpy", "sims.cpu().numpy.cpu().numpy", "numpy.save", "numpy.save", "print", "evaluation_bert.simrank", "time.time", "print", "print", "print", "torch.mm", "torch.mm", "sims.cpu().numpy.cpu().numpy", "sims_T.cpu().numpy.cpu().numpy", "numpy.save", "numpy.save", "print", "evaluation_bert.simrank", "time.time", "print", "print", "range", "tuple", "print", "print", "print", "img_emb_new.size", "cap_embs.t", "cap_embs.t", "img_emb_new.size", "cap_embs.t", "cap_embs.t", "print", "torch.mm", "torch.mm", "sims_T.cpu().numpy.cpu().numpy", "sims.cpu().numpy.cpu().numpy", "numpy.save", "numpy.save", "print", "evaluation_bert.simrank", "print", "img_embs.size", "sims_T.cpu().numpy.cpu", "sims.cpu().numpy.cpu", "img_embs.size", "sims.cpu().numpy.cpu", "sims_T.cpu().numpy.cpu", "cap_emb_new.t", "cap_emb_new.t", "numpy.array", "numpy.array", "int", "int", "sims_T.cpu().numpy.cpu", "sims.cpu().numpy.cpu", "img_emb_new.size", "cap_emb_new.size", "img_embs.size", "cap_embs.size"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.load_state_dict", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_test_loader", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.encode_data", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.simrank", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.simrank", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.simrank"], ["", "def", "evalrank", "(", "model_path", ",", "data_path", "=", "None", ",", "split", "=", "'dev'", ",", "fold5", "=", "False", ",", "region_bbox_file", "=", "None", ",", "feature_path", "=", "None", ")", ":", "\n", "    ", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "\n", "if", "data_path", "is", "not", "None", ":", "\n", "        ", "opt", ".", "data_path", "=", "data_path", "\n", "", "if", "data_path", "is", "not", "None", ":", "\n", "        ", "opt", ".", "region_bbox_file", "=", "region_bbox_file", "\n", "", "if", "data_path", "is", "not", "None", ":", "\n", "        ", "opt", ".", "feature_path", "=", "feature_path", "\n", "\n", "", "print", "(", "opt", ")", "\n", "model", "=", "VSE", "(", "opt", ")", "\n", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "#", "\n", "\n", "print", "(", "'Loading dataset'", ")", "\n", "data_loader", "=", "get_test_loader", "(", "split", ",", "opt", ".", "data_name", ",", "opt", ".", "batch_size", ",", "opt", ".", "workers", ",", "opt", ")", "\n", "\n", "print", "(", "'Computing results...'", ")", "\n", "img_embs", ",", "cap_embs", ",", "sims", "=", "encode_data", "(", "model", ",", "data_loader", ")", "\n", "\n", "time_sim_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "not", "fold5", ":", "\n", "        ", "img_emb_new", "=", "img_embs", "[", "0", ":", "img_embs", ".", "size", "(", "0", ")", ":", "5", "]", "\n", "print", "(", "img_emb_new", ".", "size", "(", ")", ")", "\n", "sims", "=", "torch", ".", "mm", "(", "img_emb_new", ",", "cap_embs", ".", "t", "(", ")", ")", "\n", "sims_T", "=", "torch", ".", "mm", "(", "cap_embs", ",", "cap_embs", ".", "t", "(", ")", ")", "\n", "sims_T", "=", "sims_T", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "sims", "=", "sims", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "np", ".", "save", "(", "'sims_f.npy'", ",", "sims", ")", "\n", "np", ".", "save", "(", "'sims_f_T.npy'", ",", "sims_T", ")", "\n", "\n", "print", "(", "'Images: %d, Captions: %d'", "%", "\n", "(", "img_embs", ".", "shape", "[", "0", "]", "/", "5", ",", "cap_embs", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "r", "=", "simrank", "(", "sims", ")", "\n", "\n", "time_sim_end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'sims_time:%f'", "%", "(", "time_sim_end", "-", "time_sim_start", ")", ")", "\n", "del", "sims", "\n", "", "else", ":", "# fold5-especially for coco", "\n", "        ", "print", "(", "'5k---------------'", ")", "\n", "img_emb_new", "=", "img_embs", "[", "0", ":", "img_embs", ".", "size", "(", "0", ")", ":", "5", "]", "\n", "print", "(", "img_emb_new", ".", "size", "(", ")", ")", "\n", "\n", "sims", "=", "torch", ".", "mm", "(", "img_emb_new", ",", "cap_embs", ".", "t", "(", ")", ")", "\n", "sims_T", "=", "torch", ".", "mm", "(", "cap_embs", ",", "cap_embs", ".", "t", "(", ")", ")", "\n", "\n", "sims", "=", "sims", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "sims_T", "=", "sims_T", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "np", ".", "save", "(", "'sims_full_5k.npy'", ",", "sims", ")", "\n", "np", ".", "save", "(", "'sims_full_T_5k.npy'", ",", "sims_T", ")", "\n", "print", "(", "'Images: %d, Captions: %d'", "%", "\n", "(", "img_embs", ".", "shape", "[", "0", "]", "/", "5", ",", "cap_embs", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "r", "=", "simrank", "(", "sims", ")", "\n", "\n", "time_sim_end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'sims_time:%f'", "%", "(", "time_sim_end", "-", "time_sim_start", ")", ")", "\n", "del", "sims", ",", "sims_T", "\n", "print", "(", "'1k---------------'", ")", "\n", "r_", "=", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "print", "(", "i", ")", "\n", "img_emb_new", "=", "img_embs", "[", "i", "*", "5000", ":", "int", "(", "i", "*", "5000", "+", "img_embs", ".", "size", "(", "0", ")", "/", "5", ")", ":", "5", "]", "\n", "cap_emb_new", "=", "cap_embs", "[", "i", "*", "5000", ":", "int", "(", "i", "*", "5000", "+", "cap_embs", ".", "size", "(", "0", ")", "/", "5", ")", "]", "\n", "\n", "sims", "=", "torch", ".", "mm", "(", "img_emb_new", ",", "cap_emb_new", ".", "t", "(", ")", ")", "\n", "sims_T", "=", "torch", ".", "mm", "(", "cap_emb_new", ",", "cap_emb_new", ".", "t", "(", ")", ")", "\n", "sims_T", "=", "sims_T", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "sims", "=", "sims", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "np", ".", "save", "(", "'sims_full_%d.npy'", "%", "i", ",", "sims", ")", "\n", "np", ".", "save", "(", "'sims_full_T_%d'", "%", "i", ",", "sims_T", ")", "\n", "\n", "print", "(", "'Images: %d, Captions: %d'", "%", "\n", "(", "img_emb_new", ".", "size", "(", "0", ")", ",", "cap_emb_new", ".", "size", "(", "0", ")", ")", ")", "\n", "\n", "r", "=", "simrank", "(", "sims", ")", "\n", "r_", "=", "np", ".", "array", "(", "r_", ")", "+", "np", ".", "array", "(", "r", ")", "\n", "\n", "del", "sims", "\n", "print", "(", "'--------------------'", ")", "\n", "", "r_", "=", "tuple", "(", "r_", "/", "5", ")", "\n", "print", "(", "'I2T:%.1f %.1f %.1f'", "%", "r_", "[", "0", ":", "3", "]", ")", "\n", "print", "(", "'T2I:%.1f %.1f %.1f'", "%", "r_", "[", "3", ":", "6", "]", ")", "\n", "print", "(", "'Rsum:%.1f'", "%", "r_", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation_bert.i2t": [[205, 239], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "int", "print", "images[].reshape", "numpy.dot().flatten", "numpy.dot().flatten", "index_list.append", "range", "len", "len", "len", "numpy.floor", "numpy.floor", "numpy.zeros.mean", "numpy.argsort", "numpy.argsort", "len", "len", "len", "numpy.median", "numpy.median", "numpy.dot", "numpy.dot", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where"], "function", ["None"], ["", "", "def", "i2t", "(", "images", ",", "captions", ",", "npts", "=", "None", ",", "return_ranks", "=", "False", ")", ":", "\n", "    ", "if", "npts", "is", "None", ":", "\n", "        ", "npts", "=", "int", "(", "images", ".", "shape", "[", "0", "]", "/", "5", ")", "\n", "print", "(", "npts", ")", "\n", "", "index_list", "=", "[", "]", "\n", "\n", "ranks", "=", "numpy", ".", "zeros", "(", "npts", ")", "\n", "top1", "=", "numpy", ".", "zeros", "(", "npts", ")", "\n", "\n", "for", "index", "in", "range", "(", "npts", ")", ":", "\n", "\n", "        ", "im", "=", "images", "[", "5", "*", "index", "]", ".", "reshape", "(", "1", ",", "images", ".", "shape", "[", "1", "]", ")", "\n", "\n", "d", "=", "numpy", ".", "dot", "(", "im", ",", "captions", ".", "T", ")", ".", "flatten", "(", ")", "\n", "inds", "=", "numpy", ".", "argsort", "(", "d", ")", "[", ":", ":", "-", "1", "]", "\n", "index_list", ".", "append", "(", "inds", "[", "0", "]", ")", "\n", "\n", "rank", "=", "1e20", "\n", "for", "i", "in", "range", "(", "5", "*", "index", ",", "5", "*", "index", "+", "5", ",", "1", ")", ":", "\n", "            ", "tmp", "=", "numpy", ".", "where", "(", "inds", "==", "i", ")", "[", "0", "]", "[", "0", "]", "\n", "if", "tmp", "<", "rank", ":", "\n", "                ", "rank", "=", "tmp", "\n", "", "", "ranks", "[", "index", "]", "=", "rank", "\n", "top1", "[", "index", "]", "=", "inds", "[", "0", "]", "\n", "\n", "", "r1", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "1", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r5", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "5", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r10", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "10", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "medr", "=", "numpy", ".", "floor", "(", "numpy", ".", "median", "(", "ranks", ")", ")", "+", "1", "\n", "meanr", "=", "ranks", ".", "mean", "(", ")", "+", "1", "\n", "if", "return_ranks", ":", "\n", "        ", "return", "(", "r1", ",", "r5", ",", "r10", ",", "medr", ",", "meanr", ")", ",", "(", "ranks", ",", "top1", ")", "\n", "", "else", ":", "\n", "        ", "return", "(", "r1", ",", "r5", ",", "r10", ",", "medr", ",", "meanr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation_bert.t2i": [[241, 272], ["numpy.array", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "int", "print", "print", "numpy.dot", "numpy.zeros", "numpy.zeros", "print", "range", "len", "len", "len", "numpy.floor", "numpy.floor", "numpy.zeros.mean", "len", "len", "len", "len", "numpy.median", "numpy.median", "range", "numpy.argsort", "numpy.argsort", "len", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where"], "function", ["None"], ["", "", "def", "t2i", "(", "images", ",", "captions", ",", "npts", "=", "None", ",", "return_ranks", "=", "False", ")", ":", "\n", "    ", "if", "npts", "is", "None", ":", "\n", "        ", "npts", "=", "int", "(", "images", ".", "shape", "[", "0", "]", "/", "5", ")", "\n", "print", "(", "npts", ")", "\n", "", "ims", "=", "numpy", ".", "array", "(", "[", "images", "[", "i", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "images", ")", ",", "5", ")", "]", ")", "\n", "\n", "ranks", "=", "numpy", ".", "zeros", "(", "5", "*", "npts", ")", "\n", "top1", "=", "numpy", ".", "zeros", "(", "5", "*", "npts", ")", "\n", "\n", "for", "index", "in", "range", "(", "npts", ")", ":", "\n", "        ", "queries", "=", "captions", "[", "5", "*", "index", ":", "5", "*", "index", "+", "5", "]", "\n", "print", "(", "'3'", ")", "\n", "\n", "d", "=", "np", ".", "dot", "(", "queries", ",", "ims", ".", "T", ")", "\n", "\n", "inds", "=", "numpy", ".", "zeros", "(", "d", ".", "shape", ")", "\n", "print", "(", "'5'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "inds", ")", ")", ":", "\n", "            ", "inds", "[", "i", "]", "=", "numpy", ".", "argsort", "(", "d", "[", "i", "]", ")", "[", ":", ":", "-", "1", "]", "\n", "ranks", "[", "5", "*", "index", "+", "i", "]", "=", "numpy", ".", "where", "(", "inds", "[", "i", "]", "==", "index", ")", "[", "0", "]", "[", "0", "]", "\n", "top1", "[", "5", "*", "index", "+", "i", "]", "=", "inds", "[", "i", "]", "[", "0", "]", "\n", "\n", "", "", "r1", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "1", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r5", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "5", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r10", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "10", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "medr", "=", "numpy", ".", "floor", "(", "numpy", ".", "median", "(", "ranks", ")", ")", "+", "1", "\n", "meanr", "=", "ranks", ".", "mean", "(", ")", "+", "1", "\n", "if", "return_ranks", ":", "\n", "        ", "return", "(", "r1", ",", "r5", ",", "r10", ",", "medr", ",", "meanr", ")", ",", "(", "ranks", ",", "top1", ")", "\n", "", "else", ":", "\n", "        ", "return", "(", "r1", ",", "r5", ",", "r10", ",", "medr", ",", "meanr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation_bert.simrank": [[274, 326], ["print", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "print", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "print", "print", "index_list.append", "range", "len", "len", "len", "numpy.floor", "numpy.floor", "numpy.zeros.mean", "numpy.zeros", "numpy.zeros", "range", "len", "len", "len", "numpy.floor", "numpy.floor", "numpy.zeros.mean", "numpy.argsort", "numpy.argsort", "len", "len", "len", "numpy.median", "numpy.median", "len", "len", "len", "len", "numpy.median", "numpy.median", "numpy.where", "numpy.where", "numpy.argsort", "numpy.argsort", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where"], "function", ["None"], ["", "", "def", "simrank", "(", "similarity", ")", ":", "\n", "    ", "sims", "=", "similarity", "# similarity matrix 1k*5k", "\n", "# print(sims)", "\n", "img_size", ",", "cap_size", "=", "sims", ".", "shape", "\n", "print", "(", "\"imgs: %d, caps: %d\"", "%", "(", "img_size", ",", "cap_size", ")", ")", "\n", "# time.sleep(10)", "\n", "# i2t", "\n", "index_list", "=", "[", "]", "\n", "ranks", "=", "numpy", ".", "zeros", "(", "img_size", ")", "\n", "top1", "=", "numpy", ".", "zeros", "(", "img_size", ")", "\n", "for", "index", "in", "range", "(", "img_size", ")", ":", "\n", "        ", "d", "=", "sims", "[", "index", "]", "\n", "inds", "=", "numpy", ".", "argsort", "(", "d", ")", "[", ":", ":", "-", "1", "]", "\n", "index_list", ".", "append", "(", "inds", "[", "0", "]", ")", "\n", "rank", "=", "1e20", "\n", "for", "i", "in", "range", "(", "5", "*", "index", ",", "5", "*", "index", "+", "5", ",", "1", ")", ":", "\n", "            ", "tmp", "=", "numpy", ".", "where", "(", "inds", "==", "i", ")", "[", "0", "]", "\n", "if", "tmp", "<", "rank", ":", "\n", "                ", "rank", "=", "tmp", "\n", "", "", "ranks", "[", "index", "]", "=", "rank", "\n", "top1", "[", "index", "]", "=", "inds", "[", "0", "]", "\n", "\n", "", "r1", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "1", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r5", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "5", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r10", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "10", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "medr", "=", "numpy", ".", "floor", "(", "numpy", ".", "median", "(", "ranks", ")", ")", "+", "1", "\n", "meanr", "=", "ranks", ".", "mean", "(", ")", "+", "1", "\n", "print", "(", "'i2t:r1: %.1f, r5: %.1f, r10: %.1f'", "%", "(", "r1", ",", "r5", ",", "r10", ")", ")", "# , medr, meanr)", "\n", "rs", "=", "r1", "+", "r5", "+", "r10", "\n", "# t2i", "\n", "sims_t2i", "=", "sims", ".", "T", "\n", "ranks", "=", "numpy", ".", "zeros", "(", "cap_size", ")", "\n", "top1", "=", "numpy", ".", "zeros", "(", "cap_size", ")", "\n", "for", "index", "in", "range", "(", "img_size", ")", ":", "\n", "\n", "        ", "d", "=", "sims_t2i", "[", "5", "*", "index", ":", "5", "*", "index", "+", "5", "]", "# 5*1000", "\n", "inds", "=", "numpy", ".", "zeros", "(", "d", ".", "shape", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "inds", ")", ")", ":", "\n", "            ", "inds", "[", "i", "]", "=", "numpy", ".", "argsort", "(", "d", "[", "i", "]", ")", "[", ":", ":", "-", "1", "]", "\n", "ranks", "[", "5", "*", "index", "+", "i", "]", "=", "numpy", ".", "where", "(", "inds", "[", "i", "]", "==", "index", ")", "[", "0", "]", "[", "0", "]", "\n", "top1", "[", "5", "*", "index", "+", "i", "]", "=", "inds", "[", "i", "]", "[", "0", "]", "\n", "\n", "", "", "r1_", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "1", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r5_", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "5", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r10_", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "10", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "medr_", "=", "numpy", ".", "floor", "(", "numpy", ".", "median", "(", "ranks", ")", ")", "+", "1", "\n", "meanr_", "=", "ranks", ".", "mean", "(", ")", "+", "1", "\n", "rs_", "=", "r1_", "+", "r5_", "+", "r10_", "\n", "print", "(", "'t2i:r1: %.1f, r5: %.1f, r10: %.1f'", "%", "(", "r1_", ",", "r5_", ",", "r10_", ")", ")", "\n", "rsum", "=", "rs", "+", "rs_", "\n", "print", "(", "'rsum=%.1f'", "%", "rsum", ")", "\n", "return", "[", "r1", ",", "r5", ",", "r10", ",", "r1_", ",", "r5_", ",", "r10_", ",", "rsum", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation_bert.main": [[328, 341], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "evaluation_bert.evalrank"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.evalrank"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "default", "=", "'single_model'", ",", "help", "=", "'model name'", ")", "\n", "parser", ".", "add_argument", "(", "'--fold'", ",", "action", "=", "'store_true'", ",", "help", "=", "'fold5'", ")", "\n", "parser", ".", "add_argument", "(", "'--name'", ",", "default", "=", "'model_best'", ",", "help", "=", "'checkpoint name'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_path'", ",", "default", "=", "'data'", ",", "help", "=", "'data path'", ")", "\n", "parser", ".", "add_argument", "(", "'--region_bbox_file'", ",", "default", "=", "'data/joint-pretrain/flickr30k/region_feat_gvd_wo_bgd/flickr30k_detection_vg_thresh0.2_feat_gvd_checkpoint_trainvaltest.h5'", ",", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'path to region features bbox file'", ")", "\n", "parser", ".", "add_argument", "(", "'--feature_path'", ",", "default", "=", "'data/joint-pretrain/flickr30k/region_feat_gvd_wo_bgd/trainval/'", ",", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'path to region features'", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "evalrank", "(", "'runs/'", "+", "opt", ".", "model", "+", "'/'", "+", "opt", ".", "name", "+", "\".pth.tar\"", ",", "data_path", "=", "opt", ".", "data_path", ",", "split", "=", "\"test\"", ",", "fold5", "=", "opt", ".", "fold", ",", "region_bbox_file", "=", "opt", ".", "region_bbox_file", ",", "feature_path", "=", "opt", ".", "feature_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.AverageMeter.__init__": [[27, 29], ["evaluation.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.AverageMeter.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.AverageMeter.reset": [[30, 35], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.AverageMeter.update": [[36, 41], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "0", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "(", ".0001", "+", "self", ".", "count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.AverageMeter.__str__": [[42, 50], ["str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\"String representation for logging\n        \"\"\"", "\n", "# for values that should be recorded exactly e.g. iteration number", "\n", "if", "self", ".", "count", "==", "0", ":", "\n", "            ", "return", "str", "(", "self", ".", "val", ")", "\n", "# for stats", "\n", "", "return", "'%.4f (%.4f)'", "%", "(", "self", ".", "val", ",", "self", ".", "avg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.__init__": [[55, 58], ["collections.OrderedDict"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# to keep the order of logged variables deterministic", "\n", "        ", "self", ".", "meters", "=", "OrderedDict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update": [[59, 64], ["evaluation.LogCollector.meters[].update", "evaluation.AverageMeter"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update"], ["", "def", "update", "(", "self", ",", "k", ",", "v", ",", "n", "=", "0", ")", ":", "\n", "# create a new meter if previously not recorded", "\n", "        ", "if", "k", "not", "in", "self", ".", "meters", ":", "\n", "            ", "self", ".", "meters", "[", "k", "]", "=", "AverageMeter", "(", ")", "\n", "", "self", ".", "meters", "[", "k", "]", ".", "update", "(", "v", ",", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.__str__": [[65, 74], ["enumerate", "evaluation.LogCollector.meters.items", "str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Concatenate the meters in one log line\n        \"\"\"", "\n", "s", "=", "''", "\n", "for", "i", ",", "(", "k", ",", "v", ")", "in", "enumerate", "(", "self", ".", "meters", ".", "items", "(", ")", ")", ":", "\n", "            ", "if", "i", ">", "0", ":", "\n", "                ", "s", "+=", "'  '", "\n", "", "s", "+=", "k", "+", "' '", "+", "str", "(", "v", ")", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.tb_log": [[75, 80], ["evaluation.LogCollector.meters.items", "tb_logger.log_value"], "methods", ["None"], ["", "def", "tb_log", "(", "self", ",", "tb_logger", ",", "prefix", "=", "''", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"\"\"Log using tensorboard\n        \"\"\"", "\n", "for", "k", ",", "v", "in", "self", ".", "meters", ".", "items", "(", ")", ":", "\n", "            ", "tb_logger", ".", "log_value", "(", "prefix", "+", "k", ",", "v", ".", "val", ",", "step", "=", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.encode_data": [[82, 129], ["evaluation.AverageMeter", "evaluation.LogCollector", "model.val_start", "time.time", "torch.no_grad", "enumerate", "model.forward_emb", "model.forward_loss", "evaluation.AverageMeter.update", "time.time", "torch.zeros().cuda", "torch.zeros().cuda", "logging", "time.time", "torch.zeros", "torch.zeros", "len", "len", "img_emb.size", "len", "cap_emb.size", "str"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.val_start", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.forward_emb", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.forward_loss", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update"], ["", "", "", "def", "encode_data", "(", "model", ",", "data_loader", ",", "log_step", "=", "10", ",", "logging", "=", "print", ")", ":", "\n", "    ", "\"\"\"Encode all images and captions loadable by `data_loader`\n    \"\"\"", "\n", "batch_time", "=", "AverageMeter", "(", ")", "\n", "val_logger", "=", "LogCollector", "(", ")", "\n", "\n", "# switch to evaluate mode", "\n", "model", ".", "val_start", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "# numpy array to keep all the embeddings", "\n", "img_embs", "=", "None", "\n", "cap_embs", "=", "None", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", ",", "(", "images", ",", "captions", ",", "img_rcnn", ",", "img_pos", ",", "lengths", ",", "ids", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "# make sure val logger is used", "\n", "            ", "model", ".", "logger", "=", "val_logger", "\n", "\n", "# compute the embeddings", "\n", "img_emb", ",", "cap_emb", "=", "model", ".", "forward_emb", "(", "images", ",", "captions", ",", "img_rcnn", ",", "img_pos", ",", "lengths", ")", "\n", "\n", "# initialize the numpy arrays given the size of the embeddings", "\n", "if", "img_embs", "is", "None", ":", "\n", "                ", "img_embs", "=", "torch", ".", "zeros", "(", "len", "(", "data_loader", ".", "dataset", ")", ",", "img_emb", ".", "size", "(", "1", ")", ")", ".", "cuda", "(", ")", "\n", "cap_embs", "=", "torch", ".", "zeros", "(", "len", "(", "data_loader", ".", "dataset", ")", ",", "cap_emb", ".", "size", "(", "1", ")", ")", ".", "cuda", "(", ")", "\n", "\n", "", "img_embs", "[", "ids", "]", "=", "img_emb", "\n", "cap_embs", "[", "ids", "]", "=", "cap_emb", "\n", "\n", "# measure accuracy and record loss", "\n", "model", ".", "forward_loss", "(", "img_emb", ",", "cap_emb", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "i", "%", "log_step", "==", "0", ":", "\n", "                ", "logging", "(", "'Test: [{0}/{1}]\\t'", "\n", "'{e_log}\\t'", "\n", "'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'", "\n", ".", "format", "(", "\n", "i", ",", "len", "(", "data_loader", ")", ",", "batch_time", "=", "batch_time", ",", "\n", "e_log", "=", "str", "(", "model", ".", "logger", ")", ")", ")", "\n", "", "del", "images", ",", "captions", "\n", "\n", "", "", "return", "img_embs", ",", "cap_embs", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.evalrank": [[131, 233], ["torch.load", "len", "print", "model.VSE", "model.VSE.load_state_dict", "print", "data.get_test_loader", "print", "evaluation.encode_data", "time.time", "open", "pickle.load", "print", "torch.mm", "torch.mm", "sims_T.cpu().numpy.cpu().numpy", "sims.cpu().numpy.cpu().numpy", "numpy.save", "numpy.save", "print", "evaluation.simrank", "time.time", "print", "print", "print", "torch.mm", "torch.mm", "sims.cpu().numpy.cpu().numpy", "sims_T.cpu().numpy.cpu().numpy", "numpy.save", "numpy.save", "print", "evaluation.simrank", "time.time", "print", "print", "range", "tuple", "print", "print", "print", "os.path.join", "img_emb_new.size", "cap_embs.t", "cap_embs.t", "img_emb_new.size", "cap_embs.t", "cap_embs.t", "print", "torch.mm", "torch.mm", "sims_T.cpu().numpy.cpu().numpy", "sims.cpu().numpy.cpu().numpy", "numpy.save", "numpy.save", "print", "evaluation.simrank", "print", "img_embs.size", "sims_T.cpu().numpy.cpu", "sims.cpu().numpy.cpu", "img_embs.size", "sims.cpu().numpy.cpu", "sims_T.cpu().numpy.cpu", "cap_emb_new.t", "cap_emb_new.t", "numpy.array", "numpy.array", "int", "int", "sims_T.cpu().numpy.cpu", "sims.cpu().numpy.cpu", "img_emb_new.size", "cap_emb_new.size", "img_embs.size", "cap_embs.size"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.model.VSE.load_state_dict", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.data.get_test_loader", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.encode_data", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.simrank", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.simrank", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.simrank"], ["", "def", "evalrank", "(", "model_path", ",", "data_path", "=", "None", ",", "split", "=", "'dev'", ",", "fold5", "=", "False", ",", "region_bbox_file", "=", "None", ",", "feature_path", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Evaluate a trained model on either dev or test. If `fold5=True`, 5 fold\n    cross-validation is done (only for MSCOCO). Otherwise, the full data is\n    used for evaluation.\n    \"\"\"", "\n", "# load model and options", "\n", "checkpoint", "=", "torch", ".", "load", "(", "model_path", ")", "\n", "opt", "=", "checkpoint", "[", "'opt'", "]", "\n", "if", "data_path", "is", "not", "None", ":", "\n", "        ", "opt", ".", "data_path", "=", "data_path", "\n", "", "if", "region_bbox_file", "is", "not", "None", ":", "\n", "        ", "opt", ".", "region_bbox_file", "=", "region_bbox_file", "\n", "", "if", "feature_path", "is", "not", "None", ":", "\n", "        ", "opt", ".", "feature_path", "=", "feature_path", "\n", "\n", "# load vocabulary used by the model", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "opt", ".", "vocab_path", ",", "\n", "'%s_vocab.pkl'", "%", "opt", ".", "data_name", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "vocab", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "opt", ".", "vocab_size", "=", "len", "(", "vocab", ")", "\n", "print", "(", "opt", ")", "\n", "\n", "# construct model", "\n", "model", "=", "VSE", "(", "opt", ")", "\n", "# load model state", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "\n", "print", "(", "'Loading dataset'", ")", "\n", "data_loader", "=", "get_test_loader", "(", "split", ",", "opt", ".", "data_name", ",", "vocab", ",", "opt", ".", "crop_size", ",", "\n", "opt", ".", "batch_size", ",", "opt", ".", "workers", ",", "opt", ")", "\n", "print", "(", "'Computing results...'", ")", "\n", "img_embs", ",", "cap_embs", "=", "encode_data", "(", "model", ",", "data_loader", ")", "\n", "time_sim_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "not", "fold5", ":", "\n", "        ", "img_emb_new", "=", "img_embs", "[", "0", ":", "img_embs", ".", "size", "(", "0", ")", ":", "5", "]", "\n", "print", "(", "img_emb_new", ".", "size", "(", ")", ")", "\n", "\n", "sims", "=", "torch", ".", "mm", "(", "img_emb_new", ",", "cap_embs", ".", "t", "(", ")", ")", "\n", "sims_T", "=", "torch", ".", "mm", "(", "cap_embs", ",", "cap_embs", ".", "t", "(", ")", ")", "\n", "sims_T", "=", "sims_T", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "sims", "=", "sims", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "np", ".", "save", "(", "'sims_f.npy'", ",", "sims", ")", "\n", "np", ".", "save", "(", "'sims_f_T.npy'", ",", "sims_T", ")", "\n", "\n", "print", "(", "'Images: %d, Captions: %d'", "%", "\n", "(", "img_embs", ".", "shape", "[", "0", "]", "/", "5", ",", "cap_embs", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "r", "=", "simrank", "(", "sims", ")", "\n", "\n", "time_sim_end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'sims_time:%f'", "%", "(", "time_sim_end", "-", "time_sim_start", ")", ")", "\n", "del", "sims", "\n", "", "else", ":", "# fold5-especially for coco", "\n", "        ", "print", "(", "'5k---------------'", ")", "\n", "img_emb_new", "=", "img_embs", "[", "0", ":", "img_embs", ".", "size", "(", "0", ")", ":", "5", "]", "\n", "print", "(", "img_emb_new", ".", "size", "(", ")", ")", "\n", "\n", "sims", "=", "torch", ".", "mm", "(", "img_emb_new", ",", "cap_embs", ".", "t", "(", ")", ")", "\n", "sims_T", "=", "torch", ".", "mm", "(", "cap_embs", ",", "cap_embs", ".", "t", "(", ")", ")", "\n", "\n", "sims", "=", "sims", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "sims_T", "=", "sims_T", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "np", ".", "save", "(", "'sims_full_5k.npy'", ",", "sims", ")", "\n", "np", ".", "save", "(", "'sims_full_T_5k.npy'", ",", "sims_T", ")", "\n", "print", "(", "'Images: %d, Captions: %d'", "%", "\n", "(", "img_embs", ".", "shape", "[", "0", "]", "/", "5", ",", "cap_embs", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n", "r", "=", "simrank", "(", "sims", ")", "\n", "\n", "time_sim_end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'sims_time:%f'", "%", "(", "time_sim_end", "-", "time_sim_start", ")", ")", "\n", "del", "sims", ",", "sims_T", "\n", "print", "(", "'1k---------------'", ")", "\n", "r_", "=", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "print", "(", "i", ")", "\n", "img_emb_new", "=", "img_embs", "[", "i", "*", "5000", ":", "int", "(", "i", "*", "5000", "+", "img_embs", ".", "size", "(", "0", ")", "/", "5", ")", ":", "5", "]", "\n", "cap_emb_new", "=", "cap_embs", "[", "i", "*", "5000", ":", "int", "(", "i", "*", "5000", "+", "cap_embs", ".", "size", "(", "0", ")", "/", "5", ")", "]", "\n", "\n", "sims", "=", "torch", ".", "mm", "(", "img_emb_new", ",", "cap_emb_new", ".", "t", "(", ")", ")", "\n", "sims_T", "=", "torch", ".", "mm", "(", "cap_emb_new", ",", "cap_emb_new", ".", "t", "(", ")", ")", "\n", "sims_T", "=", "sims_T", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "sims", "=", "sims", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "np", ".", "save", "(", "'sims_full_%d.npy'", "%", "i", ",", "sims", ")", "\n", "np", ".", "save", "(", "'sims_full_T_%d'", "%", "i", ",", "sims_T", ")", "\n", "\n", "print", "(", "'Images: %d, Captions: %d'", "%", "\n", "(", "img_emb_new", ".", "size", "(", "0", ")", ",", "cap_emb_new", ".", "size", "(", "0", ")", ")", ")", "\n", "\n", "r", "=", "simrank", "(", "sims", ")", "\n", "r_", "=", "np", ".", "array", "(", "r_", ")", "+", "np", ".", "array", "(", "r", ")", "\n", "\n", "del", "sims", "\n", "print", "(", "'--------------------'", ")", "\n", "", "r_", "=", "tuple", "(", "r_", "/", "5", ")", "\n", "print", "(", "'I2T:%.1f %.1f %.1f'", "%", "r_", "[", "0", ":", "3", "]", ")", "\n", "print", "(", "'T2I:%.1f %.1f %.1f'", "%", "r_", "[", "3", ":", "6", "]", ")", "\n", "print", "(", "'Rsum:%.1f'", "%", "r_", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.simrank": [[235, 287], ["print", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "print", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "print", "print", "index_list.append", "range", "len", "len", "len", "numpy.floor", "numpy.floor", "numpy.zeros.mean", "numpy.zeros", "numpy.zeros", "range", "len", "len", "len", "numpy.floor", "numpy.floor", "numpy.zeros.mean", "numpy.argsort", "numpy.argsort", "len", "len", "len", "numpy.median", "numpy.median", "len", "len", "len", "len", "numpy.median", "numpy.median", "numpy.where", "numpy.where", "numpy.argsort", "numpy.argsort", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where"], "function", ["None"], ["", "", "def", "simrank", "(", "similarity", ")", ":", "\n", "    ", "sims", "=", "similarity", "\n", "img_size", ",", "cap_size", "=", "sims", ".", "shape", "\n", "print", "(", "\"imgs: %d, caps: %d\"", "%", "(", "img_size", ",", "cap_size", ")", ")", "\n", "# i2t", "\n", "index_list", "=", "[", "]", "\n", "ranks", "=", "numpy", ".", "zeros", "(", "img_size", ")", "\n", "top1", "=", "numpy", ".", "zeros", "(", "img_size", ")", "\n", "for", "index", "in", "range", "(", "img_size", ")", ":", "\n", "        ", "d", "=", "sims", "[", "index", "]", "\n", "inds", "=", "numpy", ".", "argsort", "(", "d", ")", "[", ":", ":", "-", "1", "]", "\n", "# print(inds)", "\n", "index_list", ".", "append", "(", "inds", "[", "0", "]", ")", "\n", "rank", "=", "1e20", "\n", "for", "i", "in", "range", "(", "5", "*", "index", ",", "5", "*", "index", "+", "5", ",", "1", ")", ":", "\n", "            ", "tmp", "=", "numpy", ".", "where", "(", "inds", "==", "i", ")", "[", "0", "]", "\n", "# print(tmp)", "\n", "if", "tmp", "<", "rank", ":", "\n", "                ", "rank", "=", "tmp", "\n", "", "", "ranks", "[", "index", "]", "=", "rank", "\n", "top1", "[", "index", "]", "=", "inds", "[", "0", "]", "\n", "\n", "", "r1", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "1", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r5", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "5", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r10", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "10", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "medr", "=", "numpy", ".", "floor", "(", "numpy", ".", "median", "(", "ranks", ")", ")", "+", "1", "\n", "meanr", "=", "ranks", ".", "mean", "(", ")", "+", "1", "\n", "print", "(", "'i2t:r1: %.1f, r5: %.1f, r10: %.1f'", "%", "(", "r1", ",", "r5", ",", "r10", ")", ")", "# , medr, meanr)", "\n", "rs", "=", "r1", "+", "r5", "+", "r10", "\n", "# t2i", "\n", "sims_t2i", "=", "sims", ".", "T", "\n", "ranks", "=", "numpy", ".", "zeros", "(", "cap_size", ")", "\n", "top1", "=", "numpy", ".", "zeros", "(", "cap_size", ")", "\n", "for", "index", "in", "range", "(", "img_size", ")", ":", "\n", "\n", "        ", "d", "=", "sims_t2i", "[", "5", "*", "index", ":", "5", "*", "index", "+", "5", "]", "# 5*1000", "\n", "inds", "=", "numpy", ".", "zeros", "(", "d", ".", "shape", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "inds", ")", ")", ":", "\n", "            ", "inds", "[", "i", "]", "=", "numpy", ".", "argsort", "(", "d", "[", "i", "]", ")", "[", ":", ":", "-", "1", "]", "\n", "ranks", "[", "5", "*", "index", "+", "i", "]", "=", "numpy", ".", "where", "(", "inds", "[", "i", "]", "==", "index", ")", "[", "0", "]", "[", "0", "]", "\n", "top1", "[", "5", "*", "index", "+", "i", "]", "=", "inds", "[", "i", "]", "[", "0", "]", "\n", "\n", "", "", "r1_", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "1", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r5_", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "5", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r10_", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "10", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "medr_", "=", "numpy", ".", "floor", "(", "numpy", ".", "median", "(", "ranks", ")", ")", "+", "1", "\n", "meanr_", "=", "ranks", ".", "mean", "(", ")", "+", "1", "\n", "rs_", "=", "r1_", "+", "r5_", "+", "r10_", "\n", "print", "(", "'t2i:r1: %.1f, r5: %.1f, r10: %.1f'", "%", "(", "r1_", ",", "r5_", ",", "r10_", ")", ")", "\n", "rsum", "=", "rs", "+", "rs_", "\n", "print", "(", "'rsum=%.1f'", "%", "rsum", ")", "\n", "return", "[", "r1", ",", "r5", ",", "r10", ",", "r1_", ",", "r5_", ",", "r10_", ",", "rsum", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.i2t": [[289, 334], ["images.cpu().numpy.cpu().numpy", "captions.cpu().numpy.cpu().numpy", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "int", "print", "images[].reshape", "numpy.dot().flatten", "numpy.dot().flatten", "index_list.append", "range", "len", "len", "len", "numpy.floor", "numpy.floor", "numpy.zeros.mean", "images.cpu().numpy.cpu", "captions.cpu().numpy.cpu", "numpy.argsort", "numpy.argsort", "len", "len", "len", "numpy.median", "numpy.median", "numpy.dot", "numpy.dot", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where"], "function", ["None"], ["", "def", "i2t", "(", "images", ",", "captions", ",", "npts", "=", "None", ",", "return_ranks", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Images->Text (Image Annotation)\n    Images: (5N, K) matrix of images\n    Captions: (5N, K) matrix of captions\n    \"\"\"", "\n", "images", "=", "images", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "captions", "=", "captions", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "npts", "is", "None", ":", "\n", "        ", "npts", "=", "int", "(", "images", ".", "shape", "[", "0", "]", "/", "5", ")", "\n", "print", "(", "npts", ")", "\n", "", "index_list", "=", "[", "]", "\n", "\n", "ranks", "=", "numpy", ".", "zeros", "(", "npts", ")", "\n", "top1", "=", "numpy", ".", "zeros", "(", "npts", ")", "\n", "for", "index", "in", "range", "(", "npts", ")", ":", "\n", "\n", "# Get query image", "\n", "        ", "im", "=", "images", "[", "5", "*", "index", "]", ".", "reshape", "(", "1", ",", "images", ".", "shape", "[", "1", "]", ")", "\n", "\n", "# Compute scores", "\n", "\n", "d", "=", "numpy", ".", "dot", "(", "im", ",", "captions", ".", "T", ")", ".", "flatten", "(", ")", "\n", "inds", "=", "numpy", ".", "argsort", "(", "d", ")", "[", ":", ":", "-", "1", "]", "\n", "index_list", ".", "append", "(", "inds", "[", "0", "]", ")", "\n", "\n", "# Score", "\n", "rank", "=", "1e20", "\n", "for", "i", "in", "range", "(", "5", "*", "index", ",", "5", "*", "index", "+", "5", ",", "1", ")", ":", "\n", "            ", "tmp", "=", "numpy", ".", "where", "(", "inds", "==", "i", ")", "[", "0", "]", "[", "0", "]", "\n", "if", "tmp", "<", "rank", ":", "\n", "                ", "rank", "=", "tmp", "\n", "", "", "ranks", "[", "index", "]", "=", "rank", "\n", "top1", "[", "index", "]", "=", "inds", "[", "0", "]", "\n", "\n", "# Compute metrics", "\n", "", "r1", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "1", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r5", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "5", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r10", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "10", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "medr", "=", "numpy", ".", "floor", "(", "numpy", ".", "median", "(", "ranks", ")", ")", "+", "1", "\n", "meanr", "=", "ranks", ".", "mean", "(", ")", "+", "1", "\n", "if", "return_ranks", ":", "\n", "        ", "return", "(", "r1", ",", "r5", ",", "r10", ",", "medr", ",", "meanr", ")", ",", "(", "ranks", ",", "top1", ")", "\n", "", "else", ":", "\n", "        ", "return", "(", "r1", ",", "r5", ",", "r10", ",", "medr", ",", "meanr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.t2i": [[336, 374], ["images.cpu().numpy.cpu().numpy", "captions.cpu().numpy.cpu().numpy", "numpy.array", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "int", "print", "numpy.dot", "numpy.dot", "numpy.zeros", "numpy.zeros", "range", "len", "len", "len", "numpy.floor", "numpy.floor", "numpy.zeros.mean", "images.cpu().numpy.cpu", "captions.cpu().numpy.cpu", "len", "len", "len", "len", "numpy.median", "numpy.median", "range", "numpy.argsort", "numpy.argsort", "len", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where", "numpy.where"], "function", ["None"], ["", "", "def", "t2i", "(", "images", ",", "captions", ",", "npts", "=", "None", ",", "return_ranks", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Text->Images (Image Search)\n    Images: (5N, K) matrix of images\n    Captions: (5N, K) matrix of captions\n    \"\"\"", "\n", "images", "=", "images", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "captions", "=", "captions", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "npts", "is", "None", ":", "\n", "        ", "npts", "=", "int", "(", "images", ".", "shape", "[", "0", "]", "/", "5", ")", "\n", "print", "(", "npts", ")", "\n", "", "ims", "=", "numpy", ".", "array", "(", "[", "images", "[", "i", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "images", ")", ",", "5", ")", "]", ")", "\n", "\n", "ranks", "=", "numpy", ".", "zeros", "(", "5", "*", "npts", ")", "\n", "top1", "=", "numpy", ".", "zeros", "(", "5", "*", "npts", ")", "\n", "for", "index", "in", "range", "(", "npts", ")", ":", "\n", "\n", "# Get query captions", "\n", "        ", "queries", "=", "captions", "[", "5", "*", "index", ":", "5", "*", "index", "+", "5", "]", "\n", "\n", "# Compute scores", "\n", "d", "=", "numpy", ".", "dot", "(", "queries", ",", "ims", ".", "T", ")", "\n", "inds", "=", "numpy", ".", "zeros", "(", "d", ".", "shape", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "inds", ")", ")", ":", "\n", "            ", "inds", "[", "i", "]", "=", "numpy", ".", "argsort", "(", "d", "[", "i", "]", ")", "[", ":", ":", "-", "1", "]", "\n", "ranks", "[", "5", "*", "index", "+", "i", "]", "=", "numpy", ".", "where", "(", "inds", "[", "i", "]", "==", "index", ")", "[", "0", "]", "[", "0", "]", "\n", "top1", "[", "5", "*", "index", "+", "i", "]", "=", "inds", "[", "i", "]", "[", "0", "]", "\n", "\n", "# Compute metrics", "\n", "", "", "r1", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "1", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r5", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "5", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "r10", "=", "100.0", "*", "len", "(", "numpy", ".", "where", "(", "ranks", "<", "10", ")", "[", "0", "]", ")", "/", "len", "(", "ranks", ")", "\n", "medr", "=", "numpy", ".", "floor", "(", "numpy", ".", "median", "(", "ranks", ")", ")", "+", "1", "\n", "meanr", "=", "ranks", ".", "mean", "(", ")", "+", "1", "\n", "if", "return_ranks", ":", "\n", "        ", "return", "(", "r1", ",", "r5", ",", "r10", ",", "medr", ",", "meanr", ")", ",", "(", "ranks", ",", "top1", ")", "\n", "", "else", ":", "\n", "        ", "return", "(", "r1", ",", "r5", ",", "r10", ",", "medr", ",", "meanr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.main": [[376, 389], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "evaluation.evalrank"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.evalrank"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "default", "=", "'single_model'", ",", "help", "=", "'model name'", ")", "\n", "parser", ".", "add_argument", "(", "'--fold'", ",", "action", "=", "'store_true'", ",", "help", "=", "'fold5'", ")", "\n", "parser", ".", "add_argument", "(", "'--name'", ",", "default", "=", "'model_best'", ",", "help", "=", "'checkpoint name'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_path'", ",", "default", "=", "'data'", ",", "help", "=", "'data path'", ")", "\n", "parser", ".", "add_argument", "(", "'--region_bbox_file'", ",", "default", "=", "'data/joint-pretrain/flickr30k/region_feat_gvd_wo_bgd/flickr30k_detection_vg_thresh0.2_feat_gvd_checkpoint_trainvaltest.h5'", ",", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'path to region features bbox file'", ")", "\n", "parser", ".", "add_argument", "(", "'--feature_path'", ",", "default", "=", "'data/joint-pretrain/flickr30k/region_feat_gvd_wo_bgd/trainval/'", ",", "type", "=", "str", ",", "metavar", "=", "'PATH'", ",", "\n", "help", "=", "'path to region features'", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "evalrank", "(", "'runs/'", "+", "opt", ".", "model", "+", "'/'", "+", "opt", ".", "name", "+", "\".pth.tar\"", ",", "data_path", "=", "opt", ".", "data_path", ",", "split", "=", "\"test\"", ",", "fold5", "=", "opt", ".", "fold", ",", "region_bbox_file", "=", "opt", ".", "region_bbox_file", ",", "feature_path", "=", "opt", ".", "feature_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.Vocabulary.__init__": [[27, 31], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "word2idx", "=", "{", "}", "\n", "self", ".", "idx2word", "=", "{", "}", "\n", "self", ".", "idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.Vocabulary.add_word": [[32, 37], ["None"], "methods", ["None"], ["", "def", "add_word", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "word", "not", "in", "self", ".", "word2idx", ":", "\n", "            ", "self", ".", "word2idx", "[", "word", "]", "=", "self", ".", "idx", "\n", "self", ".", "idx2word", "[", "self", ".", "idx", "]", "=", "word", "\n", "self", ".", "idx", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.Vocabulary.__call__": [[38, 42], ["None"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "word", "not", "in", "self", ".", "word2idx", ":", "\n", "            ", "return", "self", ".", "word2idx", "[", "'<unk>'", "]", "\n", "", "return", "self", ".", "word2idx", "[", "word", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.Vocabulary.__len__": [[43, 45], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "word2idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.from_coco_json": [[47, 55], ["COCO", "COCO.anns.keys", "enumerate", "captions.append", "str"], "function", ["None"], ["", "", "def", "from_coco_json", "(", "path", ")", ":", "\n", "    ", "coco", "=", "COCO", "(", "path", ")", "\n", "ids", "=", "coco", ".", "anns", ".", "keys", "(", ")", "\n", "captions", "=", "[", "]", "\n", "for", "i", ",", "idx", "in", "enumerate", "(", "ids", ")", ":", "\n", "        ", "captions", ".", "append", "(", "str", "(", "coco", ".", "anns", "[", "idx", "]", "[", "'caption'", "]", ")", ")", "\n", "\n", "", "return", "captions", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.from_flickr_json": [[57, 64], ["enumerate", "json.load", "open", "str"], "function", ["None"], ["", "def", "from_flickr_json", "(", "path", ")", ":", "\n", "    ", "dataset", "=", "json", ".", "load", "(", "open", "(", "path", ",", "'r'", ")", ")", "[", "'images'", "]", "\n", "captions", "=", "[", "]", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "dataset", ")", ":", "\n", "        ", "captions", "+=", "[", "str", "(", "x", "[", "'raw'", "]", ")", "for", "x", "in", "d", "[", "'sentences'", "]", "]", "\n", "\n", "", "return", "captions", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.from_txt": [[66, 72], ["open", "captions.append", "line.strip"], "function", ["None"], ["", "def", "from_txt", "(", "txt", ")", ":", "\n", "    ", "captions", "=", "[", "]", "\n", "with", "open", "(", "txt", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "captions", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "", "return", "captions", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.build_vocab": [[74, 118], ["collections.Counter", "collections.Counter.items", "sorted", "print", "vocab.Vocabulary", "vocab.Vocabulary.add_word", "vocab.Vocabulary.add_word", "vocab.Vocabulary.add_word", "vocab.Vocabulary.add_word", "print", "enumerate", "os.path.join", "enumerate", "len", "os.path.join", "vocab.from_coco_json", "nltk.tokenize.word_tokenize", "collections.Counter.update", "words.append", "counts.append", "vocab.Vocabulary.add_word", "print", "vocab.from_flickr_json", "vocab.from_txt", "caption.lower().encode().decode", "print", "caption.lower().encode", "len", "caption.lower"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.Vocabulary.add_word", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.Vocabulary.add_word", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.Vocabulary.add_word", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.Vocabulary.add_word", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.from_coco_json", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.Vocabulary.add_word", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.from_flickr_json", "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.from_txt"], ["", "def", "build_vocab", "(", "data_path", ",", "data_name", ",", "jsons", ",", "threshold", ")", ":", "\n", "    ", "\"\"\"Build a simple vocabulary wrapper.\"\"\"", "\n", "counter", "=", "Counter", "(", ")", "\n", "for", "path", "in", "jsons", "[", "data_name", "]", ":", "\n", "        ", "full_path", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "data_path", ",", "data_name", ")", ",", "path", ")", "\n", "if", "data_name", "==", "'coco'", ":", "\n", "            ", "captions", "=", "from_coco_json", "(", "full_path", ")", "\n", "", "elif", "data_name", "==", "'f8k'", "or", "data_name", "==", "'f30k'", ":", "\n", "            ", "captions", "=", "from_flickr_json", "(", "full_path", ")", "\n", "", "else", ":", "\n", "            ", "captions", "=", "from_txt", "(", "full_path", ")", "\n", "", "for", "i", ",", "caption", "in", "enumerate", "(", "captions", ")", ":", "\n", "            ", "tokens", "=", "nltk", ".", "tokenize", ".", "word_tokenize", "(", "\n", "caption", ".", "lower", "(", ")", ".", "encode", "(", "'utf-8'", ")", ".", "decode", "(", "'utf-8'", ")", ")", "\n", "counter", ".", "update", "(", "tokens", ")", "\n", "\n", "if", "i", "%", "1000", "==", "0", ":", "\n", "                ", "print", "(", "\"\\r[%d/%d] tokenized the captions.\"", "%", "(", "i", ",", "len", "(", "captions", ")", ")", ",", "end", "=", "''", ")", "\n", "# Discard if the occurrence of the word is less than min_word_cnt.", "\n", "", "", "", "words", "=", "[", "]", "\n", "counts", "=", "[", "]", "\n", "for", "word", ",", "cnt", "in", "counter", ".", "items", "(", ")", ":", "\n", "        ", "if", "cnt", ">=", "threshold", ":", "\n", "            ", "words", ".", "append", "(", "word", ")", "\n", "counts", ".", "append", "(", "(", "word", ",", "cnt", ")", ")", "\n", "# words = [word for word, cnt in counter.items() if cnt >= threshold]", "\n", "", "", "counts_new", "=", "sorted", "(", "counts", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "print", "(", "counts_new", ")", "\n", "# Create a vocab wrapper and add some special tokens.", "\n", "vocab", "=", "Vocabulary", "(", ")", "\n", "vocab", ".", "add_word", "(", "'<pad>'", ")", "\n", "vocab", ".", "add_word", "(", "'<start>'", ")", "\n", "vocab", ".", "add_word", "(", "'<end>'", ")", "\n", "vocab", ".", "add_word", "(", "'<unk>'", ")", "\n", "print", "(", "len", "(", "counts_new", ")", ")", "\n", "# Add words to the vocabulary.", "\n", "chosen_nums", "=", "256", "\n", "for", "i", ",", "word_cnt", "in", "enumerate", "(", "counts_new", ")", ":", "\n", "        ", "word", ",", "count", "=", "word_cnt", "\n", "# print(word)", "\n", "if", "i", "<", "chosen_nums", ":", "\n", "            ", "vocab", ".", "add_word", "(", "word", ")", "\n", "print", "(", "word", ")", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.main": [[120, 124], ["vocab.build_vocab", "open", "pickle.dump"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.vocab.build_vocab"], ["", "def", "main", "(", "data_path", ",", "data_name", ")", ":", "\n", "    ", "vocab", "=", "build_vocab", "(", "data_path", ",", "data_name", ",", "jsons", "=", "annotations", ",", "threshold", "=", "300", ")", "\n", "with", "open", "(", "'%s_vocab.pkl'", "%", "data_name", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "vocab", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "# print(\"Saved vocabulary file to \", '%s_vocab.pkl' % data_name)", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertConfig.__init__": [[139, 195], ["isinstance", "json.loads.items", "isinstance", "isinstance", "io.open", "json.loads", "ValueError", "reader.read"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "vocab_size_or_config_json_file", ",", "\n", "hidden_size", "=", "768", ",", "\n", "num_hidden_layers", "=", "12", ",", "\n", "num_attention_heads", "=", "12", ",", "\n", "intermediate_size", "=", "3072", ",", "\n", "hidden_act", "=", "\"gelu\"", ",", "\n", "hidden_dropout_prob", "=", "0.1", ",", "\n", "attention_probs_dropout_prob", "=", "0.1", ",", "\n", "max_position_embeddings", "=", "512", ",", "\n", "type_vocab_size", "=", "2", ",", "\n", "initializer_range", "=", "0.02", ")", ":", "\n", "        ", "\"\"\"Constructs BertConfig.\n\n        Args:\n            vocab_size_or_config_json_file: Vocabulary size of `inputs_ids` in `BertModel`.\n            hidden_size: Size of the encoder layers and the pooler layer.\n            num_hidden_layers: Number of hidden layers in the Transformer encoder.\n            num_attention_heads: Number of attention heads for each attention layer in\n                the Transformer encoder.\n            intermediate_size: The size of the \"intermediate\" (i.e., feed-forward)\n                layer in the Transformer encoder.\n            hidden_act: The non-linear activation function (function or string) in the\n                encoder and pooler. If string, \"gelu\", \"relu\" and \"swish\" are supported.\n            hidden_dropout_prob: The dropout probabilitiy for all fully connected\n                layers in the embeddings, encoder, and pooler.\n            attention_probs_dropout_prob: The dropout ratio for the attention\n                probabilities.\n            max_position_embeddings: The maximum sequence length that this model might\n                ever be used with. Typically set this to something large just in case\n                (e.g., 512 or 1024 or 2048).\n            type_vocab_size: The vocabulary size of the `token_type_ids` passed into\n                `BertModel`.\n            initializer_range: The sttdev of the truncated_normal_initializer for\n                initializing all weight matrices.\n        \"\"\"", "\n", "if", "isinstance", "(", "vocab_size_or_config_json_file", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "\n", "and", "isinstance", "(", "vocab_size_or_config_json_file", ",", "unicode", ")", ")", ":", "\n", "            ", "with", "open", "(", "vocab_size_or_config_json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "                ", "json_config", "=", "json", ".", "loads", "(", "reader", ".", "read", "(", ")", ")", "\n", "", "for", "key", ",", "value", "in", "json_config", ".", "items", "(", ")", ":", "\n", "                ", "self", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "", "elif", "isinstance", "(", "vocab_size_or_config_json_file", ",", "int", ")", ":", "\n", "            ", "self", ".", "vocab_size", "=", "vocab_size_or_config_json_file", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_attention_heads", "=", "num_attention_heads", "\n", "self", ".", "hidden_act", "=", "hidden_act", "\n", "self", ".", "intermediate_size", "=", "intermediate_size", "\n", "self", ".", "hidden_dropout_prob", "=", "hidden_dropout_prob", "\n", "self", ".", "attention_probs_dropout_prob", "=", "attention_probs_dropout_prob", "\n", "self", ".", "max_position_embeddings", "=", "max_position_embeddings", "\n", "self", ".", "type_vocab_size", "=", "type_vocab_size", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"First argument must be either a vocabulary size (int)\"", "\n", "\"or the path to a pretrained model config file (str)\"", ")", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertConfig.from_dict": [[197, 204], ["modeling.BertConfig", "json_object.items"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "json_object", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a Python dictionary of parameters.\"\"\"", "\n", "config", "=", "BertConfig", "(", "vocab_size_or_config_json_file", "=", "-", "1", ")", "\n", "for", "key", ",", "value", "in", "json_object", ".", "items", "(", ")", ":", "\n", "            ", "config", ".", "__dict__", "[", "key", "]", "=", "value", "\n", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertConfig.from_json_file": [[205, 211], ["cls.from_dict", "io.open", "reader.read", "json.loads"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ")", ":", "\n", "        ", "\"\"\"Constructs a `BertConfig` from a json file of parameters.\"\"\"", "\n", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "cls", ".", "from_dict", "(", "json", ".", "loads", "(", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertConfig.__repr__": [[212, 214], ["str", "modeling.BertConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertConfig.to_dict": [[215, 219], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertConfig.to_json_string": [[220, 223], ["json.dumps", "modeling.BertConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertConfig.to_json_file": [[224, 228], ["io.open", "writer.write", "modeling.BertConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertConfig.to_json_string"], ["", "def", "to_json_file", "(", "self", ",", "json_file_path", ")", ":", "\n", "        ", "\"\"\" Save this instance to a json file.\"\"\"", "\n", "with", "open", "(", "json_file_path", ",", "\"w\"", ",", "encoding", "=", "'utf-8'", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertEmbeddings.__init__": [[256, 266], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Embedding", "torch.nn.Embedding", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEmbeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "0", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "token_type_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "type_vocab_size", ",", "config", ".", "hidden_size", ")", "\n", "\n", "# self.LayerNorm is not snake-cased to stick with TensorFlow model variable name and be able to load", "\n", "# any TensorFlow checkpoint file", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertEmbeddings.forward": [[267, 282], ["input_ids.size", "torch.arange", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "modeling.BertEmbeddings.word_embeddings", "modeling.BertEmbeddings.position_embeddings", "modeling.BertEmbeddings.token_type_embeddings", "modeling.BertEmbeddings.LayerNorm", "modeling.BertEmbeddings.dropout", "torch.zeros_like", "position_ids.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ")", ":", "\n", "        ", "seq_length", "=", "input_ids", ".", "size", "(", "1", ")", "\n", "position_ids", "=", "torch", ".", "arange", "(", "seq_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand_as", "(", "input_ids", ")", "\n", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "", "words_embeddings", "=", "self", ".", "word_embeddings", "(", "input_ids", ")", "\n", "position_embeddings", "=", "self", ".", "position_embeddings", "(", "position_ids", ")", "\n", "token_type_embeddings", "=", "self", ".", "token_type_embeddings", "(", "token_type_ids", ")", "\n", "\n", "embeddings", "=", "words_embeddings", "+", "position_embeddings", "+", "token_type_embeddings", "\n", "embeddings", "=", "self", ".", "LayerNorm", "(", "embeddings", ")", "\n", "embeddings", "=", "self", ".", "dropout", "(", "embeddings", ")", "\n", "return", "embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertSelfAttention.__init__": [[285, 300], ["torch.nn.Module.__init__", "int", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "ValueError"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "config", ".", "hidden_size", "%", "config", ".", "num_attention_heads", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "hidden_size", ",", "config", ".", "num_attention_heads", ")", ")", "\n", "", "self", ".", "num_attention_heads", "=", "config", ".", "num_attention_heads", "\n", "self", ".", "attention_head_size", "=", "int", "(", "config", ".", "hidden_size", "/", "config", ".", "num_attention_heads", ")", "\n", "self", ".", "all_head_size", "=", "self", ".", "num_attention_heads", "*", "self", ".", "attention_head_size", "\n", "\n", "self", ".", "query", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "key", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "self", ".", "value", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "self", ".", "all_head_size", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attention_probs_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores": [[301, 305], ["x.view.view.view", "x.view.view.permute", "x.view.view.size"], "methods", ["None"], ["", "def", "transpose_for_scores", "(", "self", ",", "x", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "num_attention_heads", ",", "self", ".", "attention_head_size", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "\n", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertSelfAttention.forward": [[306, 333], ["modeling.BertSelfAttention.query", "modeling.BertSelfAttention.key", "modeling.BertSelfAttention.value", "modeling.BertSelfAttention.transpose_for_scores", "modeling.BertSelfAttention.transpose_for_scores", "modeling.BertSelfAttention.transpose_for_scores", "torch.matmul", "modeling.BertSelfAttention.dropout", "torch.matmul", "context_layer.view.view.permute().contiguous", "context_layer.view.view.view", "modeling.BertSelfAttention.transpose", "math.sqrt", "torch.nn.Softmax", "context_layer.view.view.permute", "context_layer.view.view.size"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertSelfAttention.transpose_for_scores"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ")", ":", "\n", "        ", "mixed_query_layer", "=", "self", ".", "query", "(", "hidden_states", ")", "\n", "mixed_key_layer", "=", "self", ".", "key", "(", "hidden_states", ")", "\n", "mixed_value_layer", "=", "self", ".", "value", "(", "hidden_states", ")", "\n", "\n", "query_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_query_layer", ")", "\n", "key_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_key_layer", ")", "\n", "value_layer", "=", "self", ".", "transpose_for_scores", "(", "mixed_value_layer", ")", "\n", "\n", "# Take the dot product between \"query\" and \"key\" to get the raw attention scores.", "\n", "attention_scores", "=", "torch", ".", "matmul", "(", "query_layer", ",", "key_layer", ".", "transpose", "(", "-", "1", ",", "-", "2", ")", ")", "\n", "attention_scores", "=", "attention_scores", "/", "math", ".", "sqrt", "(", "self", ".", "attention_head_size", ")", "\n", "# Apply the attention mask is (precomputed for all layers in BertModel forward() function)", "\n", "attention_scores", "=", "attention_scores", "+", "attention_mask", "\n", "\n", "# Normalize the attention scores to probabilities.", "\n", "attention_probs", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "attention_scores", ")", "\n", "\n", "# This is actually dropping out entire tokens to attend to, which might", "\n", "# seem a bit unusual, but is taken from the original Transformer paper.", "\n", "attention_probs", "=", "self", ".", "dropout", "(", "attention_probs", ")", "\n", "\n", "context_layer", "=", "torch", ".", "matmul", "(", "attention_probs", ",", "value_layer", ")", "\n", "context_layer", "=", "context_layer", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_context_layer_shape", "=", "context_layer", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "self", ".", "all_head_size", ",", ")", "\n", "context_layer", "=", "context_layer", ".", "view", "(", "*", "new_context_layer_shape", ")", "\n", "return", "context_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertSelfOutput.__init__": [[336, 341], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertSelfOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertSelfOutput.forward": [[342, 347], ["modeling.BertSelfOutput.dense", "modeling.BertSelfOutput.dropout", "modeling.BertSelfOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertAttention.__init__": [[350, 354], ["torch.nn.Module.__init__", "modeling.BertSelfAttention", "modeling.BertSelfOutput"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self", "=", "BertSelfAttention", "(", "config", ")", "\n", "self", ".", "output", "=", "BertSelfOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertAttention.forward": [[355, 359], ["modeling.BertAttention.self", "modeling.BertAttention.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_tensor", ",", "attention_mask", ")", ":", "\n", "        ", "self_output", "=", "self", ".", "self", "(", "input_tensor", ",", "attention_mask", ")", "\n", "attention_output", "=", "self", ".", "output", "(", "self_output", ",", "input_tensor", ")", "\n", "return", "attention_output", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertIntermediate.__init__": [[362, 369], ["torch.nn.Module.__init__", "torch.nn.Linear", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertIntermediate", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "intermediate_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "hidden_act", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "intermediate_act_fn", "=", "config", ".", "hidden_act", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertIntermediate.forward": [[370, 374], ["modeling.BertIntermediate.dense", "modeling.BertIntermediate.intermediate_act_fn"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "intermediate_act_fn", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertOutput.__init__": [[377, 382], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOutput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "intermediate_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertOutput.forward": [[383, 388], ["modeling.BertOutput.dense", "modeling.BertOutput.dropout", "modeling.BertOutput.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "input_tensor", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "dropout", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", "+", "input_tensor", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertLayer.__init__": [[391, 396], ["torch.nn.Module.__init__", "modeling.BertAttention", "modeling.BertIntermediate", "modeling.BertOutput"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "attention", "=", "BertAttention", "(", "config", ")", "\n", "self", ".", "intermediate", "=", "BertIntermediate", "(", "config", ")", "\n", "self", ".", "output", "=", "BertOutput", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertLayer.forward": [[397, 402], ["modeling.BertLayer.attention", "modeling.BertLayer.intermediate", "modeling.BertLayer.output"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ")", ":", "\n", "        ", "attention_output", "=", "self", ".", "attention", "(", "hidden_states", ",", "attention_mask", ")", "\n", "intermediate_output", "=", "self", ".", "intermediate", "(", "attention_output", ")", "\n", "layer_output", "=", "self", ".", "output", "(", "intermediate_output", ",", "attention_output", ")", "\n", "return", "layer_output", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertEncoder.__init__": [[405, 409], ["torch.nn.Module.__init__", "modeling.BertLayer", "torch.nn.ModuleList", "copy.deepcopy", "range"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "layer", "=", "BertLayer", "(", "config", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "layer", ")", "for", "_", "in", "range", "(", "config", ".", "num_hidden_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertEncoder.forward": [[410, 419], ["layer_module", "all_encoder_layers.append", "all_encoder_layers.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "True", ")", ":", "\n", "        ", "all_encoder_layers", "=", "[", "]", "\n", "for", "layer_module", "in", "self", ".", "layer", ":", "\n", "            ", "hidden_states", "=", "layer_module", "(", "hidden_states", ",", "attention_mask", ")", "\n", "if", "output_all_encoded_layers", ":", "\n", "                ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "all_encoder_layers", ".", "append", "(", "hidden_states", ")", "\n", "", "return", "all_encoder_layers", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertPooler.__init__": [[422, 426], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPooler", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertPooler.forward": [[427, 434], ["modeling.BertPooler.dense", "modeling.BertPooler.activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "# We \"pool\" the model by simply taking the hidden state corresponding", "\n", "# to the first token.", "\n", "        ", "first_token_tensor", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "pooled_output", "=", "self", ".", "dense", "(", "first_token_tensor", ")", "\n", "pooled_output", "=", "self", ".", "activation", "(", "pooled_output", ")", "\n", "return", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertPredictionHeadTransform.__init__": [[437, 445], ["torch.nn.Module.__init__", "torch.nn.Linear", "BertLayerNorm", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertPredictionHeadTransform", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "if", "isinstance", "(", "config", ".", "hidden_act", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "hidden_act", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "ACT2FN", "[", "config", ".", "hidden_act", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "transform_act_fn", "=", "config", ".", "hidden_act", "\n", "", "self", ".", "LayerNorm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "1e-12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertPredictionHeadTransform.forward": [[446, 451], ["modeling.BertPredictionHeadTransform.dense", "modeling.BertPredictionHeadTransform.transform_act_fn", "modeling.BertPredictionHeadTransform.LayerNorm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "dense", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "transform_act_fn", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "LayerNorm", "(", "hidden_states", ")", "\n", "return", "hidden_states", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertLMPredictionHead.__init__": [[454, 466], ["torch.nn.Module.__init__", "modeling.BertPredictionHeadTransform", "torch.nn.Linear", "torch.nn.Parameter", "bert_model_embedding_weights.size", "bert_model_embedding_weights.size", "torch.zeros", "bert_model_embedding_weights.size"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertLMPredictionHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transform", "=", "BertPredictionHeadTransform", "(", "config", ")", "\n", "\n", "# The output weights are the same as the input embeddings, but there is", "\n", "# an output-only bias for each token.", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "bert_model_embedding_weights", ".", "size", "(", "1", ")", ",", "\n", "bert_model_embedding_weights", ".", "size", "(", "0", ")", ",", "\n", "bias", "=", "False", ")", "\n", "# hidden , vocab", "\n", "self", ".", "decoder", ".", "weight", "=", "bert_model_embedding_weights", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "bert_model_embedding_weights", ".", "size", "(", "0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertLMPredictionHead.forward": [[467, 471], ["modeling.BertLMPredictionHead.transform", "modeling.BertLMPredictionHead.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ")", ":", "\n", "        ", "hidden_states", "=", "self", ".", "transform", "(", "hidden_states", ")", "\n", "hidden_states", "=", "self", ".", "decoder", "(", "hidden_states", ")", "+", "self", ".", "bias", "\n", "return", "hidden_states", "# B seqlen vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertOnlyMLMHead.__init__": [[474, 477], ["torch.nn.Module.__init__", "modeling.BertLMPredictionHead"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertOnlyMLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ",", "bert_model_embedding_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertOnlyMLMHead.forward": [[478, 483], ["modeling.BertOnlyMLMHead.predictions"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ")", ":", "\n", "# B seqlen hidden", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "# B seqlen vocab_size", "\n", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertOnlyNSPHead.__init__": [[486, 489], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertOnlyNSPHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertOnlyNSPHead.forward": [[490, 493], ["modeling.BertOnlyNSPHead.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pooled_output", ")", ":", "\n", "        ", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertPreTrainingHeads.__init__": [[496, 500], ["torch.nn.Module.__init__", "modeling.BertLMPredictionHead", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ",", "bert_model_embedding_weights", ")", ":", "\n", "        ", "super", "(", "BertPreTrainingHeads", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "predictions", "=", "BertLMPredictionHead", "(", "config", ",", "bert_model_embedding_weights", ")", "\n", "self", ".", "seq_relationship", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertPreTrainingHeads.forward": [[501, 505], ["modeling.BertPreTrainingHeads.predictions", "modeling.BertPreTrainingHeads.seq_relationship"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "sequence_output", ",", "pooled_output", ")", ":", "\n", "        ", "prediction_scores", "=", "self", ".", "predictions", "(", "sequence_output", ")", "\n", "seq_relationship_score", "=", "self", ".", "seq_relationship", "(", "pooled_output", ")", "\n", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertPreTrainedModel.__init__": [[512, 522], ["torch.nn.Module.__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "BertPreTrainedModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "BertConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `BertConfig`. \"", "\n", "\"To create a model from a Google pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", ")", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertPreTrainedModel.init_bert_weights": [[523, 535], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "init_bert_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "BertLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertPreTrainedModel.from_pretrained": [[536, 662], ["os.path.join", "modeling.BertConfig.from_json_file", "logger.info", "cls", "torch.load.keys", "zip", "getattr", "torch.load.copy", "modeling.BertPreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertConfig.from_json_file"], ["", "", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "state_dict", "=", "None", ",", "cache_dir", "=", "None", ",", "\n", "from_tf", "=", "False", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a BertPreTrainedModel from a pre-trained model file or a pytorch state dict.\n        Download and cache the pre-trained model file if needed.\n\n        Params:\n            pretrained_model_name_or_path: either:\n                - a str with the name of a pre-trained model to load selected in the list of:\n                    . `bert-base-uncased`\n                    . `bert-large-uncased`\n                    . `bert-base-cased`\n                    . `bert-large-cased`\n                    . `bert-base-multilingual-uncased`\n                    . `bert-base-multilingual-cased`\n                    . `bert-base-chinese`\n                - a path or url to a pretrained model archive containing:\n                    . `bert_config.json` a configuration file for the model\n                    . `pytorch_model.bin` a PyTorch dump of a BertForPreTraining instance\n                - a path or url to a pretrained model archive containing:\n                    . `bert_config.json` a configuration file for the model\n                    . `model.chkpt` a TensorFlow checkpoint\n            from_tf: should we load the weights from a locally saved TensorFlow checkpoint\n            cache_dir: an optional path to a folder in which the pre-trained models will be cached.\n            state_dict: an optional state dictionnary (collections.OrderedDict object) to use instead of Google pre-trained models\n            *inputs, **kwargs: additional input for the specific Bert class\n                (ex: num_labels for BertForSequenceClassification)\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_MODEL_ARCHIVE_MAP", ":", "\n", "            ", "archive_file", "=", "PRETRAINED_MODEL_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "", "else", ":", "\n", "            ", "archive_file", "=", "pretrained_model_name_or_path", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_MODEL_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading archive file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading archive file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "", "tempdir", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "resolved_archive_file", ")", "or", "from_tf", ":", "\n", "            ", "serialization_dir", "=", "resolved_archive_file", "\n", "", "else", ":", "\n", "# Extract archive to temp dir", "\n", "            ", "tempdir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "logger", ".", "info", "(", "\"extracting archive file {} to temp dir {}\"", ".", "format", "(", "\n", "resolved_archive_file", ",", "tempdir", ")", ")", "\n", "with", "tarfile", ".", "open", "(", "resolved_archive_file", ",", "'r:gz'", ")", "as", "archive", ":", "\n", "                ", "archive", ".", "extractall", "(", "tempdir", ")", "\n", "", "serialization_dir", "=", "tempdir", "\n", "# Load config", "\n", "", "config_file", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "CONFIG_NAME", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "config_file", ")", ":", "\n", "# Backward compatibility with old naming format", "\n", "            ", "config_file", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "BERT_CONFIG_NAME", ")", "\n", "", "config", "=", "BertConfig", ".", "from_json_file", "(", "config_file", ")", "\n", "logger", ".", "info", "(", "\"Model config {}\"", ".", "format", "(", "config", ")", ")", "\n", "# Instantiate model.", "\n", "model", "=", "cls", "(", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "weights_path", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "WEIGHTS_NAME", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "weights_path", ",", "map_location", "=", "'cpu'", ")", "\n", "", "if", "tempdir", ":", "\n", "# Clean up temp dir", "\n", "            ", "shutil", ".", "rmtree", "(", "tempdir", ")", "\n", "", "if", "from_tf", ":", "\n", "# Directly load from a TensorFlow checkpoint", "\n", "            ", "weights_path", "=", "os", ".", "path", ".", "join", "(", "serialization_dir", ",", "TF_WEIGHTS_NAME", ")", "\n", "return", "load_tf_weights_in_bert", "(", "model", ",", "weights_path", ")", "\n", "# Load from a PyTorch state_dict", "\n", "", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "            ", "new_key", "=", "None", "\n", "if", "'gamma'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "key", ":", "\n", "                ", "new_key", "=", "key", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "new_key", ":", "\n", "                ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "            ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "            ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "            ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                ", "if", "child", "is", "not", "None", ":", "\n", "                    ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "\n", "", "", "", "start_prefix", "=", "''", "\n", "if", "not", "hasattr", "(", "model", ",", "'bert'", ")", "and", "any", "(", "s", ".", "startswith", "(", "'bert.'", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "            ", "start_prefix", "=", "'bert.'", "\n", "", "load", "(", "model", ",", "prefix", "=", "start_prefix", ")", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Error(s) in loading state_dict for {}:\\n\\t{}'", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertModel.__init__": [[709, 715], ["modeling.BertPreTrainedModel.__init__", "modeling.BertEmbeddings", "modeling.BertEncoder", "modeling.BertPooler", "modeling.BertModel.apply"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "embeddings", "=", "BertEmbeddings", "(", "config", ")", "\n", "self", ".", "encoder", "=", "BertEncoder", "(", "config", ")", "\n", "self", ".", "pooler", "=", "BertPooler", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertModel.forward": [[716, 746], ["torch.ones_like.unsqueeze().unsqueeze", "extended_attention_mask.to.to.to", "modeling.BertModel.embeddings", "modeling.BertModel.encoder", "modeling.BertModel.pooler", "torch.ones_like", "torch.zeros_like", "torch.ones_like.unsqueeze", "next", "modeling.BertModel.parameters"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "output_all_encoded_layers", "=", "True", ")", ":", "\n", "        ", "if", "attention_mask", "is", "None", ":", "\n", "            ", "attention_mask", "=", "torch", ".", "ones_like", "(", "input_ids", ")", "\n", "", "if", "token_type_ids", "is", "None", ":", "\n", "            ", "token_type_ids", "=", "torch", ".", "zeros_like", "(", "input_ids", ")", "\n", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "", "extended_attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "extended_attention_mask", "=", "extended_attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "extended_attention_mask", "=", "(", "1.0", "-", "extended_attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "embedding_output", "=", "self", ".", "embeddings", "(", "input_ids", ",", "token_type_ids", ")", "\n", "encoded_layers", "=", "self", ".", "encoder", "(", "embedding_output", ",", "\n", "extended_attention_mask", ",", "\n", "output_all_encoded_layers", "=", "output_all_encoded_layers", ")", "\n", "sequence_output", "=", "encoded_layers", "[", "-", "1", "]", "\n", "pooled_output", "=", "self", ".", "pooler", "(", "sequence_output", ")", "\n", "if", "not", "output_all_encoded_layers", ":", "\n", "            ", "encoded_layers", "=", "encoded_layers", "[", "-", "1", "]", "\n", "", "return", "encoded_layers", ",", "pooled_output", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertForPreTraining.__init__": [[799, 804], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "modeling.BertPreTrainingHeads", "modeling.BertForPreTraining.apply"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForPreTraining", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertPreTrainingHeads", "(", "config", ",", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertForPreTraining.forward": [[805, 820], ["modeling.BertForPreTraining.bert", "modeling.BertForPreTraining.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "prediction_scores.view", "masked_lm_labels.view", "seq_relationship_score.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ",", "\n", "next_sentence_label", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "prediction_scores", ",", "seq_relationship_score", "=", "self", ".", "cls", "(", "sequence_output", ",", "pooled_output", ")", "\n", "# B seqlen vocab ", "\n", "if", "masked_lm_labels", "is", "not", "None", "and", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "# [B*seq_len,vocab]  [B*seq_len,1]", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "total_loss", "=", "masked_lm_loss", "+", "next_sentence_loss", "\n", "return", "total_loss", "\n", "", "else", ":", "\n", "            ", "return", "prediction_scores", ",", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertForMaskedLM.__init__": [[865, 870], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "modeling.BertOnlyMLMHead", "modeling.BertForMaskedLM.apply"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyMLMHead", "(", "config", ",", "self", ".", "bert", ".", "embeddings", ".", "word_embeddings", ".", "weight", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertForMaskedLM.forward": [[871, 882], ["modeling.BertForMaskedLM.bert", "modeling.BertForMaskedLM.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "masked_lm_labels", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "prediction_scores", "=", "self", ".", "cls", "(", "sequence_output", ")", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "masked_lm_loss", "\n", "", "else", ":", "\n", "            ", "return", "prediction_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertForNextSentencePrediction.__init__": [[928, 933], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "modeling.BertOnlyNSPHead", "modeling.BertForNextSentencePrediction.apply"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForNextSentencePrediction", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "cls", "=", "BertOnlyNSPHead", "(", "config", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertForNextSentencePrediction.forward": [[934, 945], ["modeling.BertForNextSentencePrediction.bert", "modeling.BertForNextSentencePrediction.cls", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForNextSentencePrediction.view", "next_sentence_label.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "next_sentence_label", "=", "None", ")", ":", "\n", "        ", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "seq_relationship_score", "=", "self", ".", "cls", "(", "pooled_output", ")", "\n", "\n", "if", "next_sentence_label", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "next_sentence_loss", "=", "loss_fct", "(", "seq_relationship_score", ".", "view", "(", "-", "1", ",", "2", ")", ",", "next_sentence_label", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "next_sentence_loss", "\n", "", "else", ":", "\n", "            ", "return", "seq_relationship_score", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertForSequenceClassification.__init__": [[993, 1000], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling.BertForSequenceClassification.apply"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "num_labels", ")", ":", "\n", "        ", "super", "(", "BertForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_labels", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertForSequenceClassification.forward": [[1001, 1012], ["modeling.BertForSequenceClassification.bert", "modeling.BertForSequenceClassification.dropout", "modeling.BertForSequenceClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling.BertForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "return", "loss", "\n", "", "else", ":", "\n", "            ", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertForMultipleChoice.__init__": [[1059, 1066], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling.BertForMultipleChoice.apply"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "num_choices", ")", ":", "\n", "        ", "super", "(", "BertForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_choices", "=", "num_choices", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertForMultipleChoice.forward": [[1067, 1083], ["input_ids.view", "token_type_ids.view", "attention_mask.view", "modeling.BertForMultipleChoice.bert", "modeling.BertForMultipleChoice.dropout", "modeling.BertForMultipleChoice.classifier", "modeling.BertForMultipleChoice.view", "input_ids.size", "token_type_ids.size", "attention_mask.size", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss."], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "\n", "_", ",", "pooled_output", "=", "self", ".", "bert", "(", "flat_input_ids", ",", "flat_token_type_ids", ",", "flat_attention_mask", ",", "\n", "output_all_encoded_layers", "=", "False", ")", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_choices", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "return", "loss", "\n", "", "else", ":", "\n", "            ", "return", "reshaped_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertForTokenClassification.__init__": [[1131, 1138], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "torch.nn.Dropout", "torch.nn.Linear", "modeling.BertForTokenClassification.apply"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ",", "num_labels", ")", ":", "\n", "        ", "super", "(", "BertForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_labels", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertForTokenClassification.forward": [[1139, 1157], ["modeling.BertForTokenClassification.bert", "modeling.BertForTokenClassification.dropout", "modeling.BertForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "modeling.BertForTokenClassification.view", "labels.view", "modeling.BertForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "return", "loss", "\n", "", "else", ":", "\n", "            ", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertForQuestionAnswering.__init__": [[1207, 1214], ["modeling.BertPreTrainedModel.__init__", "modeling.BertModel", "torch.nn.Linear", "modeling.BertForQuestionAnswering.apply"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "# TODO check with Google if it's normal there is no dropout on the token classifier of SQuAD in the TF version", "\n", "# self.dropout = nn.Dropout(config.hidden_dropout_prob)", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "2", ")", "\n", "self", ".", "apply", "(", "self", ".", "init_bert_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.BertForQuestionAnswering.forward": [[1215, 1240], ["modeling.BertForQuestionAnswering.bert", "modeling.BertForQuestionAnswering.qa_outputs", "modeling.BertForQuestionAnswering.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ")", ":", "\n", "        ", "sequence_output", ",", "_", "=", "self", ".", "bert", "(", "input_ids", ",", "token_type_ids", ",", "attention_mask", ",", "output_all_encoded_layers", "=", "False", ")", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "return", "total_loss", "\n", "", "else", ":", "\n", "            ", "return", "start_logits", ",", "end_logits", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.load_tf_weights_in_bert": [[52, 117], ["os.path.abspath", "print", "tf.train.list_variables", "zip", "print", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "any", "print", "torch.from_numpy", "print", "print", "re.fullmatch", "getattr", "re.split", "getattr", "len", "int", "np.transpose", "getattr", "getattr", "getattr", "getattr", "print"], "function", ["None"], ["def", "load_tf_weights_in_bert", "(", "model", ",", "tf_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "print", "(", "\"Loading a TensorFlow models in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "tf_checkpoint_path", ")", "\n", "print", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "print", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", ".", "split", "(", "'/'", ")", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "any", "(", "n", "in", "[", "\"adam_v\"", ",", "\"adam_m\"", ",", "\"global_step\"", "]", "for", "n", "in", "name", ")", ":", "\n", "            ", "print", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r'[A-Za-z]+_\\d+'", ",", "m_name", ")", ":", "\n", "                ", "l", "=", "re", ".", "split", "(", "r'_(\\d+)'", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "l", "=", "[", "m_name", "]", "\n", "", "if", "l", "[", "0", "]", "==", "'kernel'", "or", "l", "[", "0", "]", "==", "'gamma'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'output_bias'", "or", "l", "[", "0", "]", "==", "'beta'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'bias'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'output_weights'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "l", "[", "0", "]", "==", "'squad'", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "'classifier'", ")", "\n", "", "else", ":", "\n", "                ", "try", ":", "\n", "                    ", "pointer", "=", "getattr", "(", "pointer", ",", "l", "[", "0", "]", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "print", "(", "\"Skipping {}\"", ".", "format", "(", "\"/\"", ".", "join", "(", "name", ")", ")", ")", "\n", "continue", "\n", "", "", "if", "len", "(", "l", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "l", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "if", "m_name", "[", "-", "11", ":", "]", "==", "'_embeddings'", ":", "\n", "            ", "pointer", "=", "getattr", "(", "pointer", ",", "'weight'", ")", "\n", "", "elif", "m_name", "==", "'kernel'", ":", "\n", "            ", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "print", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.gelu": [[119, 126], ["torch.erf", "math.sqrt"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\"Implementation of the gelu activation function.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.modeling.swish": [[128, 130], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.optimization.BertAdam.__init__": [[67, 86], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", "=", "required", ",", "warmup", "=", "-", "1", ",", "t_total", "=", "-", "1", ",", "schedule", "=", "'warmup_linear'", ",", "\n", "b1", "=", "0.9", ",", "b2", "=", "0.999", ",", "e", "=", "1e-6", ",", "weight_decay", "=", "0.01", ",", "\n", "max_grad_norm", "=", "1.0", ")", ":", "\n", "        ", "if", "lr", "is", "not", "required", "and", "lr", "<", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {} - should be >= 0.0\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "schedule", "not", "in", "SCHEDULES", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid schedule parameter: {}\"", ".", "format", "(", "schedule", ")", ")", "\n", "", "if", "not", "0.0", "<=", "warmup", "<", "1.0", "and", "not", "warmup", "==", "-", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid warmup: {} - should be in [0.0, 1.0[ or -1\"", ".", "format", "(", "warmup", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b1", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b1 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b1", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b2", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b2 parameter: {} - should be in [0.0, 1.0[\"", ".", "format", "(", "b2", ")", ")", "\n", "", "if", "not", "e", ">=", "0.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {} - should be >= 0.0\"", ".", "format", "(", "e", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "schedule", "=", "schedule", ",", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "\n", "b1", "=", "b1", ",", "b2", "=", "b2", ",", "e", "=", "e", ",", "weight_decay", "=", "weight_decay", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", "BertAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.optimization.BertAdam.get_lr": [[87, 101], ["lr.append", "len", "schedule_fct"], "methods", ["None"], ["", "def", "get_lr", "(", "self", ")", ":", "\n", "        ", "lr", "=", "[", "]", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "return", "[", "0", "]", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "", "lr", ".", "append", "(", "lr_scheduled", ")", "\n", "", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.optimization.BertAdam.step": [[102, 181], ["closure", "next_m.mul_().add_", "next_v.mul_().addcmul_", "p.data.add_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.nn.utils.clip_grad_norm_", "next_m.mul_", "next_v.mul_", "next_v.sqrt", "schedule_fct", "logger.warning"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "warned_for_t_total", "=", "False", "\n", "\n", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "'Adam does not support sparse gradients, please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'next_m'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'next_v'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "next_m", ",", "next_v", "=", "state", "[", "'next_m'", "]", ",", "state", "[", "'next_v'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'b1'", "]", ",", "group", "[", "'b2'", "]", "\n", "\n", "# Add grad clipping", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "                    ", "clip_grad_norm_", "(", "p", ",", "group", "[", "'max_grad_norm'", "]", ")", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "# In-place operations to update the averages at the same time", "\n", "", "next_m", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "next_v", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "update", "=", "next_m", "/", "(", "next_v", ".", "sqrt", "(", ")", "+", "group", "[", "'e'", "]", ")", "\n", "\n", "# Just adding the square of the weights to the loss function is *not*", "\n", "# the correct way of using L2 regularization/weight decay with Adam,", "\n", "# since that will interact with the m and v parameters in strange ways.", "\n", "#", "\n", "# Instead we want to decay the weights in a manner that doesn't interact", "\n", "# with the m/v parameters. This is equivalent to adding the square", "\n", "# of the weights to the loss with plain (non-momentum) SGD.", "\n", "if", "group", "[", "'weight_decay'", "]", ">", "0.0", ":", "\n", "                    ", "update", "+=", "group", "[", "'weight_decay'", "]", "*", "p", ".", "data", "\n", "\n", "", "if", "group", "[", "'t_total'", "]", "!=", "-", "1", ":", "\n", "                    ", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "progress", "=", "state", "[", "'step'", "]", "/", "group", "[", "'t_total'", "]", "\n", "lr_scheduled", "=", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "progress", ",", "group", "[", "'warmup'", "]", ")", "\n", "# warning for exceeding t_total (only active with warmup_linear", "\n", "if", "group", "[", "'schedule'", "]", "==", "\"warmup_linear\"", "and", "progress", ">", "1.", "and", "not", "warned_for_t_total", ":", "\n", "                        ", "logger", ".", "warning", "(", "\n", "\"Training beyond specified 't_total' steps with schedule '{}'. Learning rate set to {}. \"", "\n", "\"Please set 't_total' of {} correctly.\"", ".", "format", "(", "group", "[", "'schedule'", "]", ",", "lr_scheduled", ",", "self", ".", "__class__", ".", "__name__", ")", ")", "\n", "warned_for_t_total", "=", "True", "\n", "# end warning", "\n", "", "", "else", ":", "\n", "                    ", "lr_scheduled", "=", "group", "[", "'lr'", "]", "\n", "\n", "", "update_with_lr", "=", "lr_scheduled", "*", "update", "\n", "p", ".", "data", ".", "add_", "(", "-", "update_with_lr", ")", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# step_size = lr_scheduled * math.sqrt(bias_correction2) / bias_correction1", "\n", "# No bias correction", "\n", "# bias_correction1 = 1 - beta1 ** state['step']", "\n", "# bias_correction2 = 1 - beta2 ** state['step']", "\n", "\n", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.optimization.warmup_cosine": [[26, 31], ["math.cos"], "function", ["None"], ["def", "warmup_cosine", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "x_", "=", "(", "x", "-", "warmup", ")", "/", "(", "1", "-", "warmup", ")", "# progress after warmup -", "\n", "return", "0.5", "*", "(", "1.", "+", "math", ".", "cos", "(", "math", ".", "pi", "*", "x_", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.optimization.warmup_constant": [[32, 38], ["None"], "function", ["None"], ["", "def", "warmup_constant", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "\"\"\" Linearly increases learning rate over `warmup`*`t_total` (as provided to BertAdam) training steps.\n        Learning rate is 1. afterwards. \"\"\"", "\n", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.optimization.warmup_linear": [[39, 45], ["max"], "function", ["None"], ["", "def", "warmup_linear", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "\"\"\" Specifies a triangular learning rate schedule where peak is reached at `warmup`*`t_total`-th (as provided to BertAdam) training step.\n        After `t_total`-th training step, learning rate is zero. \"\"\"", "\n", "if", "x", "<", "warmup", ":", "\n", "        ", "return", "x", "/", "warmup", "\n", "", "return", "max", "(", "(", "x", "-", "1.", ")", "/", "(", "warmup", "-", "1.", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.url_to_filename": [[42, 58], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["None"], ["def", "url_to_filename", "(", "url", ",", "etag", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "'utf-8'", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "'utf-8'", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "'.'", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.filename_to_url": [[60, 84], ["os.path.join", "isinstance", "str", "os.path.exists", "EnvironmentError", "os.path.exists", "EnvironmentError", "io.open", "json.load"], "function", ["None"], ["", "def", "filename_to_url", "(", "filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``EnvironmentError`` if `filename` or its stored metadata do not exist.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_PRETRAINED_BERT_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "'url'", "]", "\n", "etag", "=", "metadata", "[", "'etag'", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.cached_path": [[86, 114], ["urlparse", "isinstance", "str", "isinstance", "str", "file_utils.get_from_cache", "os.path.exists", "EnvironmentError", "ValueError"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.get_from_cache"], ["", "def", "cached_path", "(", "url_or_filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_PRETRAINED_BERT_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "\n", "if", "parsed", ".", "scheme", "in", "(", "'http'", ",", "'https'", ",", "'s3'", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "return", "get_from_cache", "(", "url_or_filename", ",", "cache_dir", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "return", "url_or_filename", "\n", "", "elif", "parsed", ".", "scheme", "==", "''", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.split_s3_path": [[116, 127], ["urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "", "def", "split_s3_path", "(", "url", ")", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.s3_request": [[129, 146], ["functools.wraps", "func", "int", "EnvironmentError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.s3_etag": [[148, 155], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Object"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ")", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.s3_get": [[157, 163], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.http_get": [[165, 175], ["requests.get", "requests.get.headers.get", "tqdm.tqdm", "requests.get.iter_content", "tqdm.tqdm.close", "int", "tqdm.tqdm.update", "temp_file.write", "len"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.None.evaluation.LogCollector.update"], ["", "def", "http_get", "(", "url", ",", "temp_file", ")", ":", "\n", "    ", "req", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ")", "\n", "content_length", "=", "req", ".", "headers", ".", "get", "(", "'Content-Length'", ")", "\n", "total", "=", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "unit", "=", "\"B\"", ",", "total", "=", "total", ")", "\n", "for", "chunk", "in", "req", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.get_from_cache": [[177, 235], ["url.startswith", "file_utils.url_to_filename", "os.path.join", "isinstance", "str", "os.path.exists", "os.makedirs", "file_utils.s3_etag", "requests.head", "requests.head.headers.get", "os.path.exists", "IOError", "tempfile.NamedTemporaryFile", "logger.info", "url.startswith", "temp_file.flush", "temp_file.seek", "logger.info", "logger.info", "logger.info", "file_utils.s3_get", "file_utils.http_get", "io.open", "shutil.copyfileobj", "io.open", "json.dump"], "function", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.url_to_filename", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.s3_etag", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.s3_get", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.http_get"], ["", "def", "get_from_cache", "(", "url", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding dataset in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "PYTORCH_PRETRAINED_BERT_CACHE", "\n", "", "if", "sys", ".", "version_info", "[", "0", "]", "==", "3", "and", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "cache_dir", ")", "\n", "\n", "# Get eTag to add to filename, if it exists.", "\n", "", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "        ", "etag", "=", "s3_etag", "(", "url", ")", "\n", "", "else", ":", "\n", "        ", "response", "=", "requests", ".", "head", "(", "url", ",", "allow_redirects", "=", "True", ")", "\n", "if", "response", ".", "status_code", "!=", "200", ":", "\n", "            ", "raise", "IOError", "(", "\"HEAD request failed for url {} with status code {}\"", "\n", ".", "format", "(", "url", ",", "response", ".", "status_code", ")", ")", "\n", "", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "\n", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "s3_get", "(", "url", ",", "temp_file", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ")", "\n", "\n", "# we are copying the file before closing it, so flush to avoid truncation", "\n", "", "temp_file", ".", "flush", "(", ")", "\n", "# shutil.copyfileobj() starts at the current position, so go to the start", "\n", "temp_file", ".", "seek", "(", "0", ")", "\n", "\n", "logger", ".", "info", "(", "\"copying %s to cache at %s\"", ",", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "with", "open", "(", "cache_path", ",", "'wb'", ")", "as", "cache_file", ":", "\n", "                ", "shutil", ".", "copyfileobj", "(", "temp_file", ",", "cache_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "'url'", ":", "url", ",", "'etag'", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "'.json'", "\n", "with", "open", "(", "meta_path", ",", "'w'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "                ", "json", ".", "dump", "(", "meta", ",", "meta_file", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"removing temp file %s\"", ",", "temp_file", ".", "name", ")", "\n", "\n", "", "", "return", "cache_path", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.read_set_from_file": [[237, 247], ["set", "io.open", "set.add", "line.rstrip"], "function", ["None"], ["", "def", "read_set_from_file", "(", "filename", ")", ":", "\n", "    ", "'''\n    Extract a de-duped collection (set) of text from a file.\n    Expected file format is one item per line.\n    '''", "\n", "collection", "=", "set", "(", ")", "\n", "with", "open", "(", "filename", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "file_", ":", "\n", "        ", "for", "line", "in", "file_", ":", "\n", "            ", "collection", ".", "add", "(", "line", ".", "rstrip", "(", ")", ")", "\n", "", "", "return", "collection", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.get_file_extension": [[249, 253], ["os.path.splitext", "ext.lower"], "function", ["None"], ["", "def", "get_file_extension", "(", "path", ",", "dot", "=", "True", ",", "lower", "=", "True", ")", ":", "\n", "    ", "ext", "=", "os", ".", "path", ".", "splitext", "(", "path", ")", "[", "1", "]", "\n", "ext", "=", "ext", "if", "dot", "else", "ext", "[", "1", ":", "]", "\n", "return", "ext", ".", "lower", "(", ")", "if", "lower", "else", "ext", "\n", "", ""]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BertTokenizer.__init__": [[78, 109], ["tokenization.load_vocab", "collections.OrderedDict", "tokenization.WordpieceTokenizer", "os.path.isfile", "ValueError", "tokenization.BasicTokenizer", "int", "tokenization.BertTokenizer.vocab.items"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.load_vocab"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "do_lower_case", "=", "True", ",", "max_len", "=", "None", ",", "do_basic_tokenize", "=", "True", ",", "\n", "never_split", "=", "(", "\"[UNK]\"", ",", "\"[SEP]\"", ",", "\"[PAD]\"", ",", "\"[CLS]\"", ",", "\"[MASK]\"", ")", ")", ":", "\n", "        ", "\"\"\"Constructs a BertTokenizer.\n\n        Args:\n          vocab_file: Path to a one-wordpiece-per-line vocabulary file\n          do_lower_case: Whether to lower case the input\n                         Only has an effect when do_wordpiece_only=False\n          do_basic_tokenize: Whether to do basic tokenization before wordpiece.\n          max_len: An artificial maximum length to truncate tokenized sequences to;\n                         Effective maximum length is always the minimum of this\n                         value (if specified) and the underlying BERT model's\n                         sequence length.\n          never_split: List of tokens which will never be split during tokenization.\n                         Only has an effect when do_wordpiece_only=False\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "vocab_file", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Can't find a vocabulary file at path '{}'. To load the vocabulary from a Google pretrained \"", "\n", "\"model use `tokenizer = BertTokenizer.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "self", ".", "vocab", "=", "load_vocab", "(", "vocab_file", ")", "\n", "\n", "self", ".", "ids_to_tokens", "=", "collections", ".", "OrderedDict", "(", "\n", "[", "(", "ids", ",", "tok", ")", "for", "tok", ",", "ids", "in", "self", ".", "vocab", ".", "items", "(", ")", "]", ")", "\n", "self", ".", "do_basic_tokenize", "=", "do_basic_tokenize", "\n", "if", "do_basic_tokenize", ":", "\n", "            ", "self", ".", "basic_tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ",", "\n", "never_split", "=", "never_split", ")", "\n", "", "self", ".", "wordpiece_tokenizer", "=", "WordpieceTokenizer", "(", "vocab", "=", "self", ".", "vocab", ")", "\n", "# print('core_vocab loaded_ (norm for squad gen)')", "\n", "self", ".", "max_len", "=", "max_len", "if", "max_len", "is", "not", "None", "else", "int", "(", "1e12", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BertTokenizer.tokenize": [[110, 119], ["tokenization.BertTokenizer.basic_tokenizer.tokenize", "tokenization.BertTokenizer.wordpiece_tokenizer.tokenize", "tokenization.BertTokenizer.wordpiece_tokenizer.tokenize", "tokenization.BertTokenizer.append"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.tokenize", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "split_tokens", "=", "[", "]", "\n", "if", "self", ".", "do_basic_tokenize", ":", "\n", "            ", "for", "token", "in", "self", ".", "basic_tokenizer", ".", "tokenize", "(", "text", ")", ":", "\n", "                ", "for", "sub_token", "in", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "token", ")", ":", "\n", "                    ", "split_tokens", ".", "append", "(", "sub_token", ")", "\n", "", "", "", "else", ":", "\n", "            ", "split_tokens", "=", "self", ".", "wordpiece_tokenizer", ".", "tokenize", "(", "text", ")", "\n", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BertTokenizer.convert_tokens_to_ids": [[120, 132], ["ids.append", "len", "logger.warning", "len"], "methods", ["None"], ["", "def", "convert_tokens_to_ids", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of tokens into ids using the vocab.\"\"\"", "\n", "ids", "=", "[", "]", "\n", "for", "token", "in", "tokens", ":", "\n", "            ", "ids", ".", "append", "(", "self", ".", "vocab", "[", "token", "]", ")", "\n", "", "if", "len", "(", "ids", ")", ">", "self", ".", "max_len", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Token indices sequence length is longer than the specified maximum \"", "\n", "\" sequence length for this BERT model ({} > {}). Running this\"", "\n", "\" sequence through BERT will result in indexing errors\"", ".", "format", "(", "len", "(", "ids", ")", ",", "self", ".", "max_len", ")", "\n", ")", "\n", "", "return", "ids", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BertTokenizer.convert_ids_to_tokens": [[133, 139], ["tokens.append"], "methods", ["None"], ["", "def", "convert_ids_to_tokens", "(", "self", ",", "ids", ")", ":", "\n", "        ", "\"\"\"Converts a sequence of ids in wordpiece tokens using the vocab.\"\"\"", "\n", "tokens", "=", "[", "]", "\n", "for", "i", "in", "ids", ":", "\n", "            ", "tokens", ".", "append", "(", "self", ".", "ids_to_tokens", "[", "i", "]", ")", "\n", "", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BertTokenizer.save_vocabulary": [[140, 154], ["os.path.isdir", "os.path.join", "io.open", "sorted", "tokenization.BertTokenizer.vocab.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "vocab_path", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary to a directory or file.\"\"\"", "\n", "index", "=", "0", "\n", "if", "os", ".", "path", ".", "isdir", "(", "vocab_path", ")", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "vocab_path", ",", "VOCAB_NAME", ")", "\n", "", "with", "open", "(", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "for", "token", ",", "token_index", "in", "sorted", "(", "self", ".", "vocab", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Saving vocabulary to {}: vocabulary indices are not consecutive.\"", "\n", "\" Please check that the vocabulary is not corrupted!\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "token", "+", "u'\\n'", ")", "\n", "index", "+=", "1", "\n", "", "", "return", "vocab_file", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BertTokenizer.from_pretrained": [[155, 202], ["os.path.isdir", "cls", "os.path.join", "file_utils.cached_path", "logger.info", "logger.info", "min", "kwargs.get", "logger.warning", "logger.error", "kwargs.get", "logger.warning", "int", "kwargs.get", "PRETRAINED_VOCAB_ARCHIVE_MAP.keys"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.file_utils.cached_path"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "cache_dir", "=", "None", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a PreTrainedBertModel from a pre-trained model file.\n        Download and cache the pre-trained model file if needed.\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_ARCHIVE_MAP", ":", "\n", "            ", "vocab_file", "=", "PRETRAINED_VOCAB_ARCHIVE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "if", "'-cased'", "in", "pretrained_model_name_or_path", "and", "kwargs", ".", "get", "(", "'do_lower_case'", ",", "True", ")", ":", "\n", "                ", "logger", ".", "warning", "(", "\"The pre-trained model you are loading is a cased model but you have not set \"", "\n", "\"`do_lower_case` to False. We are setting `do_lower_case=False` for you but \"", "\n", "\"you may want to check this behavior.\"", ")", "\n", "kwargs", "[", "'do_lower_case'", "]", "=", "False", "\n", "", "elif", "'-cased'", "not", "in", "pretrained_model_name_or_path", "and", "not", "kwargs", ".", "get", "(", "'do_lower_case'", ",", "True", ")", ":", "\n", "                ", "logger", ".", "warning", "(", "\"The pre-trained model you are loading is an uncased model but you have set \"", "\n", "\"`do_lower_case` to False. We are setting `do_lower_case=True` for you \"", "\n", "\"but you may want to check this behavior.\"", ")", "\n", "kwargs", "[", "'do_lower_case'", "]", "=", "True", "\n", "", "", "else", ":", "\n", "            ", "vocab_file", "=", "pretrained_model_name_or_path", "\n", "", "if", "os", ".", "path", ".", "isdir", "(", "vocab_file", ")", ":", "\n", "            ", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "vocab_file", ",", "VOCAB_NAME", ")", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "            ", "resolved_vocab_file", "=", "cached_path", "(", "vocab_file", ",", "cache_dir", "=", "cache_dir", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "logger", ".", "error", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url but couldn't find any file \"", "\n", "\"associated to this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "PRETRAINED_VOCAB_ARCHIVE_MAP", ".", "keys", "(", ")", ")", ",", "\n", "vocab_file", ")", ")", "\n", "return", "None", "\n", "", "if", "resolved_vocab_file", "==", "vocab_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {}\"", ".", "format", "(", "vocab_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading vocabulary file {} from cache at {}\"", ".", "format", "(", "\n", "vocab_file", ",", "resolved_vocab_file", ")", ")", "\n", "", "if", "pretrained_model_name_or_path", "in", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", ":", "\n", "# if we're using a pretrained model, ensure the tokenizer wont index sequences longer", "\n", "# than the number of positional embeddings", "\n", "            ", "max_len", "=", "PRETRAINED_VOCAB_POSITIONAL_EMBEDDINGS_SIZE_MAP", "[", "pretrained_model_name_or_path", "]", "\n", "kwargs", "[", "'max_len'", "]", "=", "min", "(", "kwargs", ".", "get", "(", "'max_len'", ",", "int", "(", "1e12", ")", ")", ",", "max_len", ")", "\n", "# Instantiate tokenizer.", "\n", "", "tokenizer", "=", "cls", "(", "resolved_vocab_file", ",", "*", "inputs", ",", "**", "kwargs", ")", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BasicTokenizer.__init__": [[207, 217], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "do_lower_case", "=", "True", ",", "\n", "never_split", "=", "(", "\"[UNK]\"", ",", "\"[SEP]\"", ",", "\"[PAD]\"", ",", "\"[CLS]\"", ",", "\"[MASK]\"", ")", ")", ":", "\n", "        ", "\"\"\"Constructs a BasicTokenizer.\n\n        Args:\n          do_lower_case: Whether to lower case the input.\n        \"\"\"", "\n", "self", ".", "do_lower_case", "=", "do_lower_case", "\n", "self", ".", "never_split", "=", "never_split", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BasicTokenizer.tokenize": [[218, 238], ["tokenization.BasicTokenizer._clean_text", "tokenization.BasicTokenizer._tokenize_chinese_chars", "tokenization.whitespace_tokenize", "tokenization.whitespace_tokenize", "split_tokens.extend", "tokenization.BasicTokenizer.lower", "tokenization.BasicTokenizer._run_strip_accents", "tokenization.BasicTokenizer._run_split_on_punc"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BasicTokenizer._clean_text", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BasicTokenizer._tokenize_chinese_chars", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.whitespace_tokenize", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_strip_accents", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_split_on_punc"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text.\"\"\"", "\n", "text", "=", "self", ".", "_clean_text", "(", "text", ")", "\n", "# This was added on November 1st, 2018 for the multilingual and Chinese", "\n", "# models. This is also applied to the English models now, but it doesn't", "\n", "# matter since the English models were not trained on any Chinese data", "\n", "# and generally don't have any Chinese data in them (there are Chinese", "\n", "# characters in the vocabulary because Wikipedia does have some Chinese", "\n", "# words in the English Wikipedia.).", "\n", "text", "=", "self", ".", "_tokenize_chinese_chars", "(", "text", ")", "\n", "orig_tokens", "=", "whitespace_tokenize", "(", "text", ")", "\n", "split_tokens", "=", "[", "]", "\n", "for", "token", "in", "orig_tokens", ":", "\n", "            ", "if", "self", ".", "do_lower_case", "and", "token", "not", "in", "self", ".", "never_split", ":", "\n", "                ", "token", "=", "token", ".", "lower", "(", ")", "\n", "token", "=", "self", ".", "_run_strip_accents", "(", "token", ")", "\n", "", "split_tokens", ".", "extend", "(", "self", ".", "_run_split_on_punc", "(", "token", ")", ")", "\n", "\n", "", "output_tokens", "=", "whitespace_tokenize", "(", "\" \"", ".", "join", "(", "split_tokens", ")", ")", "\n", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_strip_accents": [[239, 249], ["unicodedata.normalize", "unicodedata.category", "output.append"], "methods", ["None"], ["", "def", "_run_strip_accents", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Strips accents from a piece of text.\"\"\"", "\n", "text", "=", "unicodedata", ".", "normalize", "(", "\"NFD\"", ",", "text", ")", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Mn\"", ":", "\n", "                ", "continue", "\n", "", "output", ".", "append", "(", "char", ")", "\n", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BasicTokenizer._run_split_on_punc": [[250, 271], ["list", "len", "tokenization._is_punctuation", "output.append", "output[].append", "output.append"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization._is_punctuation"], ["", "def", "_run_split_on_punc", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Splits punctuation on a piece of text.\"\"\"", "\n", "if", "text", "in", "self", ".", "never_split", ":", "\n", "            ", "return", "[", "text", "]", "\n", "", "chars", "=", "list", "(", "text", ")", "\n", "i", "=", "0", "\n", "start_new_word", "=", "True", "\n", "output", "=", "[", "]", "\n", "while", "i", "<", "len", "(", "chars", ")", ":", "\n", "            ", "char", "=", "chars", "[", "i", "]", "\n", "if", "_is_punctuation", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "[", "char", "]", ")", "\n", "start_new_word", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "start_new_word", ":", "\n", "                    ", "output", ".", "append", "(", "[", "]", ")", "\n", "", "start_new_word", "=", "False", "\n", "output", "[", "-", "1", "]", ".", "append", "(", "char", ")", "\n", "", "i", "+=", "1", "\n", "\n", "", "return", "[", "\"\"", ".", "join", "(", "x", ")", "for", "x", "in", "output", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BasicTokenizer._tokenize_chinese_chars": [[272, 284], ["ord", "tokenization.BasicTokenizer._is_chinese_char", "output.append", "output.append", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BasicTokenizer._is_chinese_char"], ["", "def", "_tokenize_chinese_chars", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Adds whitespace around any CJK character.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "self", ".", "_is_chinese_char", "(", "cp", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "output", ".", "append", "(", "char", ")", "\n", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BasicTokenizer._is_chinese_char": [[285, 306], ["None"], "methods", ["None"], ["", "def", "_is_chinese_char", "(", "self", ",", "cp", ")", ":", "\n", "        ", "\"\"\"Checks whether CP is the codepoint of a CJK character.\"\"\"", "\n", "# This defines a \"chinese character\" as anything in the CJK Unicode block:", "\n", "#   https://en.wikipedia.org/wiki/CJK_Unified_Ideographs_(Unicode_block)", "\n", "#", "\n", "# Note that the CJK Unicode block is NOT all Japanese and Korean characters,", "\n", "# despite its name. The modern Korean Hangul alphabet is a different block,", "\n", "# as is Japanese Hiragana and Katakana. Those alphabets are used to write", "\n", "# space-separated words, so they are not treated specially and handled", "\n", "# like the all of the other languages.", "\n", "if", "(", "(", "cp", ">=", "0x4E00", "and", "cp", "<=", "0x9FFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x3400", "and", "cp", "<=", "0x4DBF", ")", "or", "#", "\n", "(", "cp", ">=", "0x20000", "and", "cp", "<=", "0x2A6DF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2A700", "and", "cp", "<=", "0x2B73F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B740", "and", "cp", "<=", "0x2B81F", ")", "or", "#", "\n", "(", "cp", ">=", "0x2B820", "and", "cp", "<=", "0x2CEAF", ")", "or", "\n", "(", "cp", ">=", "0xF900", "and", "cp", "<=", "0xFAFF", ")", "or", "#", "\n", "(", "cp", ">=", "0x2F800", "and", "cp", "<=", "0x2FA1F", ")", ")", ":", "#", "\n", "            ", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.BasicTokenizer._clean_text": [[307, 319], ["ord", "tokenization._is_whitespace", "tokenization._is_control", "output.append", "output.append"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization._is_whitespace", "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization._is_control"], ["", "def", "_clean_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Performs invalid character removal and whitespace cleanup on text.\"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "char", "in", "text", ":", "\n", "            ", "cp", "=", "ord", "(", "char", ")", "\n", "if", "cp", "==", "0", "or", "cp", "==", "0xfffd", "or", "_is_control", "(", "char", ")", ":", "\n", "                ", "continue", "\n", "", "if", "_is_whitespace", "(", "char", ")", ":", "\n", "                ", "output", ".", "append", "(", "\" \"", ")", "\n", "", "else", ":", "\n", "                ", "output", ".", "append", "(", "char", ")", "\n", "", "", "return", "\"\"", ".", "join", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.__init__": [[324, 328], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "vocab", ",", "unk_token", "=", "\"[UNK]\"", ",", "max_input_chars_per_word", "=", "100", ")", ":", "\n", "        ", "self", ".", "vocab", "=", "vocab", "\n", "self", ".", "unk_token", "=", "unk_token", "\n", "self", ".", "max_input_chars_per_word", "=", "max_input_chars_per_word", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.WordpieceTokenizer.tokenize": [[329, 379], ["tokenization.whitespace_tokenize", "list", "len", "output_tokens.append", "len", "len", "sub_tokens.append", "output_tokens.append", "output_tokens.extend"], "methods", ["home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.whitespace_tokenize"], ["", "def", "tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\"Tokenizes a piece of text into its word pieces.\n\n        This uses a greedy longest-match-first algorithm to perform tokenization\n        using the given vocabulary.\n\n        For example:\n          input = \"unaffable\"\n          output = [\"un\", \"##aff\", \"##able\"]\n\n        Args:\n          text: A single token or whitespace separated tokens. This should have\n            already been passed through `BasicTokenizer`.\n\n        Returns:\n          A list of wordpiece tokens.\n        \"\"\"", "\n", "\n", "output_tokens", "=", "[", "]", "\n", "for", "token", "in", "whitespace_tokenize", "(", "text", ")", ":", "\n", "            ", "chars", "=", "list", "(", "token", ")", "\n", "if", "len", "(", "chars", ")", ">", "self", ".", "max_input_chars_per_word", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "continue", "\n", "\n", "", "is_bad", "=", "False", "\n", "start", "=", "0", "\n", "sub_tokens", "=", "[", "]", "\n", "while", "start", "<", "len", "(", "chars", ")", ":", "\n", "                ", "end", "=", "len", "(", "chars", ")", "\n", "cur_substr", "=", "None", "\n", "while", "start", "<", "end", ":", "\n", "                    ", "substr", "=", "\"\"", ".", "join", "(", "chars", "[", "start", ":", "end", "]", ")", "\n", "if", "start", ">", "0", ":", "\n", "                        ", "substr", "=", "\"##\"", "+", "substr", "\n", "", "if", "substr", "in", "self", ".", "vocab", ":", "\n", "                        ", "cur_substr", "=", "substr", "\n", "break", "\n", "", "end", "-=", "1", "\n", "", "if", "cur_substr", "is", "None", ":", "\n", "                    ", "is_bad", "=", "True", "\n", "break", "\n", "", "sub_tokens", ".", "append", "(", "cur_substr", ")", "\n", "start", "=", "end", "\n", "\n", "", "if", "is_bad", ":", "\n", "                ", "output_tokens", ".", "append", "(", "self", ".", "unk_token", ")", "\n", "", "else", ":", "\n", "                ", "output_tokens", ".", "extend", "(", "sub_tokens", ")", "\n", "", "", "return", "output_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.load_vocab": [[51, 64], ["collections.OrderedDict", "io.open", "reader.readline", "token.strip.strip"], "function", ["None"], ["def", "load_vocab", "(", "vocab_file", ")", ":", "\n", "    ", "\"\"\"Loads a vocabulary file into a dictionary.\"\"\"", "\n", "vocab", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "index", "=", "0", "\n", "with", "open", "(", "vocab_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "token", "=", "reader", ".", "readline", "(", ")", "\n", "if", "not", "token", ":", "\n", "                ", "break", "\n", "", "token", "=", "token", ".", "strip", "(", ")", "\n", "vocab", "[", "token", "]", "=", "index", "\n", "index", "+=", "1", "\n", "", "", "return", "vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization.whitespace_tokenize": [[66, 73], ["text.strip.strip", "text.strip.split"], "function", ["None"], ["", "def", "whitespace_tokenize", "(", "text", ")", ":", "\n", "    ", "\"\"\"Runs basic whitespace cleaning and splitting on a piece of text.\"\"\"", "\n", "text", "=", "text", ".", "strip", "(", ")", "\n", "if", "not", "text", ":", "\n", "        ", "return", "[", "]", "\n", "", "tokens", "=", "text", ".", "split", "(", ")", "\n", "return", "tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization._is_whitespace": [[381, 391], ["unicodedata.category"], "function", ["None"], ["", "", "def", "_is_whitespace", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a whitespace character.\"\"\"", "\n", "# \\t, \\n, and \\r are technically contorl characters but we treat them", "\n", "# as whitespace since they are generally considered as such.", "\n", "if", "char", "==", "\" \"", "or", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", "==", "\"Zs\"", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization._is_control": [[393, 403], ["unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_control", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a control character.\"\"\"", "\n", "# These are technically control characters but we count them as whitespace", "\n", "# characters.", "\n", "if", "char", "==", "\"\\t\"", "or", "char", "==", "\"\\n\"", "or", "char", "==", "\"\\r\"", ":", "\n", "        ", "return", "False", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"C\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.kywen1119_DSRAN.pytorch_pretrained_bert.tokenization._is_punctuation": [[405, 419], ["ord", "unicodedata.category", "unicodedata.category.startswith"], "function", ["None"], ["", "def", "_is_punctuation", "(", "char", ")", ":", "\n", "    ", "\"\"\"Checks whether `chars` is a punctuation character.\"\"\"", "\n", "cp", "=", "ord", "(", "char", ")", "\n", "# We treat all non-letter/number ASCII as punctuation.", "\n", "# Characters such as \"^\", \"$\", and \"`\" are not in the Unicode", "\n", "# Punctuation class but we treat them as punctuation anyways, for", "\n", "# consistency.", "\n", "if", "(", "(", "33", "<=", "cp", "<=", "47", ")", "or", "(", "58", "<=", "cp", "<=", "64", ")", "or", "\n", "(", "91", "<=", "cp", "<=", "96", ")", "or", "(", "123", "<=", "cp", "<=", "126", ")", ")", ":", "\n", "        ", "return", "True", "\n", "", "cat", "=", "unicodedata", ".", "category", "(", "char", ")", "\n", "if", "cat", ".", "startswith", "(", "\"P\"", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]]}